Authors,Author full names,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,PubMed ID,Document Type,Publication Stage,Open Access,Source,EID
Abbott N.; Love T.,"Abbott, Noelle (57205190093); Love, Tracy (7006624283)",57205190093; 7006624283,Bridging the Divide: Brain and Behavior in Developmental Language Disorder,2023,Brain Sciences,13,11,1606,,,,0,10.3390/brainsci13111606,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178270290&doi=10.3390%2fbrainsci13111606&partnerID=40&md5=da972ffb9392b909d831c38025fb918e,"Developmental language disorder (DLD) is a heterogenous neurodevelopmental disorder that affects a child’s ability to comprehend and/or produce spoken and/or written language, yet it cannot be attributed to hearing loss or overt neurological damage. It is widely believed that some combination of genetic, biological, and environmental factors influences brain and language development in this population, but it has been difficult to bridge theoretical accounts of DLD with neuroimaging findings, due to heterogeneity in language impairment profiles across individuals and inconsistent neuroimaging findings. Therefore, the purpose of this overview is two-fold: (1) to summarize the neuroimaging literature (while drawing on findings from other language-impaired populations, where appropriate); and (2) to briefly review the theoretical accounts of language impairment patterns in DLD, with the goal of bridging the disparate findings. As will be demonstrated with this overview, the current state of the field suggests that children with DLD have atypical brain volume, laterality, and activation/connectivity patterns in key language regions that likely contribute to language difficulties. However, the precise nature of these differences and the underlying neural mechanisms contributing to them remain an open area of investigation. © 2023 by the authors.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85178270290
Draffan E.A.; Wald M.; Ding C.; Li Y.,"Draffan, E.A. (6508346744); Wald, Mike (23398970900); Ding, Chaohai (56178265600); Li, Yunjia (58550865100)",6508346744; 23398970900; 56178265600; 58550865100,Exploring Practical Metrics to Support Automatic Speech Recognition Evaluations,2023,Studies in Health Technology and Informatics,306,,,305,310,5,0,10.3233/SHTI230636,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168828952&doi=10.3233%2fSHTI230636&partnerID=40&md5=235a90196768d7fb9437cb7e4b4bea19,"Recent studies into the evaluation of automatic speech recognition for its quality of output in the form of text have shown that using word error rate to see how many mistakes exist in English does not necessarily help the developer of automatic transcriptions or captions. Confidence levels as to the type of errors being made remain low because mistranslations from speech to text are not always captured with a note that details the reason for the error. There have been situations in higher education where students requiring captions and transcriptions have found that some academic lecture results are littered with word errors which means that comprehension levels drop and those with cognitive, physical and sensory disabilities are particularly affected. Despite the incredible improvements in general understanding of conversational automatic speech recognition, academic situations tend to include numerous domain specific terms and the lecturers may be non-native speakers, coping with recording technology in noisy situations. This paper aims to discuss the way additional metrics are used to capture issues and feedback into the machine learning process to enable enhanced quality of output and more inclusive practices for those using virtual conferencing systems. The process goes beyond what is expressed and examines paralinguistic aspects such as timing, intonation, voice quality and speech understanding. © 2023 IOS Press. All rights reserved.",37638929,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85168828952
Paquette S.; Gouin S.; Lehmann A.,"Paquette, Sebastien (55666743700); Gouin, Samir (57338336400); Lehmann, Alexandre (55831591500)",55666743700; 57338336400; 55831591500,Improving emotion perception in cochlear implant users: insights from machine learning analysis of EEG signals,2024,BMC Neurology,24,1,115,,,,0,10.1186/s12883-024-03616-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189607412&doi=10.1186%2fs12883-024-03616-0&partnerID=40&md5=b120265b71fa269a5d5308ce4726b91e,"Background: Although cochlear implants can restore auditory inputs to deafferented auditory cortices, the quality of the sound signal transmitted to the brain is severely degraded, limiting functional outcomes in terms of speech perception and emotion perception. The latter deficit negatively impacts cochlear implant users’ social integration and quality of life; however, emotion perception is not currently part of rehabilitation. Developing rehabilitation programs incorporating emotional cognition requires a deeper understanding of cochlear implant users’ residual emotion perception abilities. Methods: To identify the neural underpinnings of these residual abilities, we investigated whether machine learning techniques could be used to identify emotion-specific patterns of neural activity in cochlear implant users. Using existing electroencephalography data from 22 cochlear implant users, we employed a random forest classifier to establish if we could model and subsequently predict from participants’ brain responses the auditory emotions (vocal and musical) presented to them. Results: Our findings suggest that consistent emotion-specific biomarkers exist in cochlear implant users, which could be used to develop effective rehabilitation programs incorporating emotion perception training. Conclusions: This study highlights the potential of machine learning techniques to improve outcomes for cochlear implant users, particularly in terms of emotion perception. © The Author(s) 2024.",38589815,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85189607412
Siminski C.; Benson J.C.; Carlson M.L.; Lane J.I.,"Siminski, Clayton (58252595300); Benson, John C (55986670500); Carlson, Matthew L (17342039300); Lane, John I (7401532558)",58252595300; 55986670500; 17342039300; 7401532558,Prevalence of Scarpa’s ganglion enhancement on high-resolution MRI imaging,2024,Neuroradiology Journal,,,,,,,0,10.1177/19714009231224415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182439311&doi=10.1177%2f19714009231224415&partnerID=40&md5=5eda64d55590168b761e421e51c1afdf,"Background and Purpose: The vestibular ganglion, or Scarpa’s ganglion, is a cluster of afferent vestibular neurons within the internal auditory canal (IAC). There is minimal literature describing enhancement of this region on magnetic resonance imaging (MRI) and its correlation to clinical symptoms. Here, we sought to find the prevalence of enhancement at Scarpa’s ganglion, and determine whether such enhancement correlates with demographics or clinical symptoms. Materials and Methods: A retrospective review was performed of consecutive patients with an MRI of the IAC between 3/1/2021 and 5/20/2021. Two neuroradiologists independently reviewed for T1 and FLAIR enhancement of the Scarpa’s ganglion on post-contrast fat-saturated T1 and post-contrast FLAIR images. Discrepancies were agreed upon by consensus. Clinical variables (hearing loss, vestibular symptoms, tinnitus, and MRI indication) were gathered from a retrospective chart review. Results: Eighty-nine patients were included (51 female); the mean age was 58 (range 19–85). The most common MRI indication was hearing loss (n = 53). FLAIR enhancement was present on the right in 7 patients, on the left in 7 patients, and bilaterally in 6 patients. No enhancement was seen on post-contrast T1 images. There was no statistically significant correlation between consensus FLAIR on at least one side and age (p =.74), gender (p =.29), hearing loss (p =.32), hearing loss side (p =.39), type of hearing loss (p =.87), vestibular symptoms (p =.71), or tinnitus (p =.81). Conclusions: Enhancement is present in the minority of patients on post-contrast FLAIR images. If seen, it should be considered an uncommon but not unexpected finding with no clinical significance. © The Author(s) 2024.",,Article,Article in press,,Scopus,2-s2.0-85182439311
Cox T.J.; Barker J.; Bailey W.; Graetzer S.; Akeroyd M.A.; Culling J.F.; Naylor G.,"Cox, Trevor J. (7203000240); Barker, Jon (7401680706); Bailey, Will (58830878800); Graetzer, Simone (56166652200); Akeroyd, Michael A. (7003932221); Culling, John F. (7004194328); Naylor, Graham (12761085700)",7203000240; 7401680706; 58830878800; 56166652200; 7003932221; 7004194328; 12761085700,Overview of the 2023 ICASSP SP Clarity Challenge: Speech Enhancement for Hearing Aids,2023,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",,,,,,,0,10.1109/ICASSP49357.2023.10433922,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185224716&doi=10.1109%2fICASSP49357.2023.10433922&partnerID=40&md5=6fcaccbb15ce6b54176964e8edc7131c,"This paper reports on the design and outcomes of the ICASSP SP Clarity Challenge: Speech Enhancement for Hearing Aids. The scenario was a listener attending to a target speaker in a noisy, domestic environment. There were multiple interferers and head rotation by the listener. The challenge extended the second Clarity Enhancement Challenge (CEC2) by fixing the amplification stage of the hearing aid; evaluating with a combined metric for speech intelligibility and quality; and providing two evaluation sets, one based on simulation and the other on real-room measurements. Five teams improved on the baseline system for the simulated evaluation set, but the performance on the measured evaluation set was much poorer. Investigations are on-going to determine the exact cause of the mismatch between the simulated and measured data sets. The presence of transducer noise in the measurements, lower order Ambisonics harming the ability for systems to exploit binaural cues and the differences between real and simulated room impulse responses are suggested causes. © 2023 IEEE.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85185224716
Chesnaye M.A.; Simpson D.M.; Schlittenlacher J.; Bell S.L.,"Chesnaye, M.A. (57201259215); Simpson, D.M. (55977688700); Schlittenlacher, J. (36635228400); Bell, S.L. (7401588148)",57201259215; 55977688700; 36635228400; 7401588148,Gaussian Processes for Hearing Threshold Estimation Using Auditory Brainstem Responses,2024,IEEE Transactions on Biomedical Engineering,71,3,,803,819,16,0,10.1109/TBME.2023.3318729,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173057207&doi=10.1109%2fTBME.2023.3318729&partnerID=40&md5=7eddb5c76b4928088e7d63e54537ad9b,"The Auditory Brainstem Response (ABR) plays an important role in diagnosing and managing hearing loss, but can be challenging and time-consuming to measure. Test times are especially long when multiple ABR measurements are needed, e.g., when estimating hearing threshold at a range of frequencies. While many detection methods have been developed to reduce ABR test times, the majority were designed to detect the ABR at a single stimulus level and do not consider correlations in ABR waveforms across levels. These correlations hold valuable information, and can be exploited for more efficient hearing threshold estimation. This was achieved in the current work using a Gaussian Process (GP), i.e., a Bayesian approach for non-linear regression. The function to estimate with the GP was the ABR's amplitude across stimulus levels, from which hearing threshold was ultimately inferred. Active learning rules were also designed to automatically adjust the stimulus level and efficiently locate hearing threshold. Simulation results show test time reductions of up to ∼50% for the GP compared to a sequentially applied Hotelling's T2 test, which does not consider correlations across ABR waveforms. A case study was also included to briefly assess the GP approach in ABR data from an adult volunteer. © 1964-2012 IEEE.",37768792,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85173057207
Robler S.K.; Platt A.; Jenson C.D.; Meade Inglis S.; Hofstetter P.; Ross A.A.; Wang N.-Y.; Labrique A.; Gallo J.J.; Egger J.R.; Emmett S.D.,"Robler, Samantha Kleindienst (57201022586); Platt, Alyssa (23480456100); Jenson, Cole D. (57200534638); Meade Inglis, S. (58396811400); Hofstetter, Philip (57205441590); Ross, Alexandra A. (57197754297); Wang, Nae-Yuh (7404340658); Labrique, Alain (6505557971); Gallo, Joseph J. (7101605709); Egger, Joseph R. (16439174800); Emmett, Susan D. (36052713800)",57201022586; 23480456100; 57200534638; 58396811400; 57205441590; 57197754297; 7404340658; 6505557971; 7101605709; 16439174800; 36052713800,Changing the Paradigm for School Hearing Screening Globally: Evaluation of Screening Protocols from Two Randomized Trials in Rural Alaska,2023,Ear and Hearing,44,4,,877,893,16,1,10.1097/AUD.0000000000001336,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163376021&doi=10.1097%2fAUD.0000000000001336&partnerID=40&md5=8a2495fa2b7efeddbcb8b40af639b6b3,"Objectives: Diagnostic accuracy was evaluated for various screening tools, including mobile health (mHealth) pure-Tone screening, tympanometry, distortion product otoacoustic emissions (DPOAE), and inclusion of high frequencies to determine the most accurate screening protocol for identifying children with hearing loss in rural Alaska where the prevalence of middle ear disease is high. Design: Hearing screening data were collected as part of two cluster randomized trials conducted in 15 communities in rural northwest Alaska. All children enrolled in school from preschool to 12th grade were eligible. Analysis was limited to data collected 2018 to 2019 (n = 1449), when both trials were running and measurement of high frequencies were included in the protocols. Analyses included estimates of diagnostic accuracy for each screening tool, as well as exploring performance by age and grade. Multiple imputation was used to assess diagnostic accuracy in younger children, where missing data were more prevalent due to requirements for conditioned responses. The audiometric reference standard included otoscopy, tympanometry, and high frequencies to ensure detection of infection-related and noise-induced hearing loss. Results: Both the mHealth pure-Tone screen and DPOAE screen performed better when tympanometry was added to the protocol (increase in sensitivity of 19.9%, 95% Confidence Interval (CI): 15.9 to 24.1 for mHealth screen, 17.9%, 95% CI: 14.0 to 21.8 for high-frequency mHealth screen, and 10.4%, 95% CI: 7.5 to 13.9 for DPOAE). The addition of 6 kHz to the mHealth pure-Tone screen provided an 8.7 percentage point improvement in sensitivity (95% CI: 6.5 to 11.3). Completeness of data for both the reference standard and the mHealth screening tool differed substantially by age, due to difficulty with behavioral testing in young children. By age 7, children were able to complete behavioral testing, and data indicated that high-frequency mHealth pure-Tone screen with tympanometry was the superior tool for children 7 years and older. For children 3 to 6 years of age, DPOAE plus tympanometry performed the best, both for complete data and multiply imputed data, which better approximates accuracy for children with missing data. Conclusions: This study directly evaluated pure-Tone, DPOAE, and tympanometry tools as part of school hearing screening in rural Alaskan children (3 to 18+ years). Results from this study indicate that tympanometry is a key component in the hearing screening protocol, particularly in environments with higher prevalence of infection-related hearing loss. DPOAE is the preferred hearing screening tool when evaluating children younger than 7 years of age (below 2nd grade in the United States) due to the frequency of missing data with behavioral testing in this age group. For children 7 years and older, the addition of high frequencies to pure-Tone screening increased the accuracy of screening, likely due to improved identification of hearing loss from noise exposure. The lack of a consistent reference standard in the literature makes comparing across studies challenging. In our study with a reference standard inclusive of otoscopy, tympanometry, and high frequencies, less than ideal sensitivities were found even for the most sensitive screening protocols, suggesting more investigation is necessary to ensure screening programs are appropriately identifying noise-and infection-related hearing loss in rural, low-resource settings. © 2023 Lippincott Williams and Wilkins. All rights reserved.",36907833,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85163376021
Merchant G.R.; Neely S.T.,"Merchant, Gabrielle R. (36664946800); Neely, Stephen T. (7003829177)",36664946800; 7003829177,Conductive Hearing Loss Estimated from Wideband Acoustic Immittance Measurements in Ears with Otitis Media with Effusion,2023,Ear and Hearing,44,4,,721,731,10,4,10.1097/AUD.0000000000001317,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163345635&doi=10.1097%2fAUD.0000000000001317&partnerID=40&md5=f77b86fcbb03aa9e99349f54036826b9,"Objectives: Previous work has shown that wideband acoustic immittance (WAI) is sensitive to the volume of effusion present in ears with otitis media with effusion (OME). Prior work also demonstrates that the volume of the effusion appears to drive, or at least play a significant role in, how much conductive hearing loss (CHL) a child has due to a given episode of OME. Given this association, the goal of this work was to determine how well CHL could be estimated directly from WAI in ears with OME. Design: Sixty-Three ears from a previously published study on OME (ages 9 months to 11 years, 2 months) were grouped based on effusion volume (full, partial, or clear) determined during tympanostomy tube placement surgery and compared with age-matched normal control ears. Audiometric thresholds were obtained for a subset of the 34 ears distributed across the four groups. An electrical-Analog model of ear-canal acoustics and middle-ear mechanics was fit to the measured WAI from individual ears. Initial estimates of CHL were derived from either (1) average absorbance or (2) the model component thought to represent damping in the ossicular chain. Results: The analog model produced good fits for all effusion-volume groups. The two initial CHL estimates were both well correlated (87% and 81%) with the pure-Tone average hearing thresholds used to define the CHL. However, in roughly a third of the ears (11/34), the estimate based on damping was too large by nearly a factor of two. This observation motivated improved CHL estimates. Conclusions: Our CHL estimation method can estimate behavioral audiometric thresholds (CHL) within a margin of error that is small enough to be clinically meaningful. The importance of this finding is increased by the challenges associated with behavioral audiometric testing in pediatric populations, where OME is the most common. In addition, the discovery of two clusters in the damping-related CHL estimate suggests the possible existence of two distinctly different types of ears: pressure detectors and power detectors. © 2023 Lippincott Williams and Wilkins. All rights reserved.",36607739,Article,Final,,Scopus,2-s2.0-85163345635
Liu Y.; Gong Q.,"Liu, Yin (57192571399); Gong, Qin (7201440945)",57192571399; 7201440945,Deep Learning Models for Predicting Hearing Thresholds Based on Swept-Tone Stimulus-Frequency Otoacoustic Emissions,2024,Ear and Hearing,45,2,,465,475,10,0,10.1097/AUD.0000000000001443,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185404954&doi=10.1097%2fAUD.0000000000001443&partnerID=40&md5=ff03ccbbe30d6ad7e30b40bd01c99264,"Objectives: This study aims to develop deep learning (DL) models for the quantitative prediction of hearing thresholds based on stimulus-frequency otoacoustic emissions (SFOAEs) evoked by swept tones. Design: A total of 174 ears with normal hearing and 388 ears with sensorineural hearing loss were studied. SFOAEs in the 0.3 to 4.3 kHz frequency range were recorded using linearly swept tones at a rate of 2 Hz/msec, with stimulus level changing from 40 to 60 dB SPL in 10 dB steps. Four DL models were used to predict hearing thresholds at octave frequencies from 0.5 to 4 kHz. The models - a conventional convolutional neural network (CNN), a hybrid CNN-k-nearest neighbor (KNN), a hybrid CNN-support vector machine (SVM), and a hybrid CNN-random forest (RF) - were individually built for each frequency. The input to the DL models was the measured raw SFOAE amplitude spectra and their corresponding signal to noise ratio spectra. All DL models shared a CNN-based feature self-extractor. They differed in that the conventional CNN utilized a fully connected layer to make the final regression decision, whereas the hybrid CNN-KNN, CNN-SVM, and CNN-RF models were designed by replacing the last fully connected layer of CNN model with a traditional machine learning (ML) regressor, that is, KNN, SVM, and RF, respectively. The model performance was evaluated using mean absolute error and SE averaged over 20 repetitions of 5 × 5 fold nested cross-validation. The performance of the proposed DL models was compared with two types of traditional ML models. Results: The proposed SFOAE-based DL models resulted in an optimal mean absolute error of 5.98, 5.22, 5.51, and 6.06 dB at 0.5, 1, 2, and 4 kHz, respectively, superior to that obtained by the traditional ML models. The produced SEs were 8.55, 7.27, 7.58, and 7.95 dB at 0.5, 1, 2, and 4 kHz, respectively. All the DL models outperformed any of the traditional ML models. Conclusions: The proposed swept-tone SFOAE-based DL models were capable of quantitatively predicting hearing thresholds with satisfactory performance. With DL techniques, the underlying relationship between SFOAEs and hearing thresholds at disparate frequencies was explored and captured, potentially improving the diagnostic value of SFOAEs. © 2024 Wolters Kluwer Health. All rights reserved.",37990395,Article,Final,,Scopus,2-s2.0-85185404954
Nicastri M.; Lo Castro F.; Giallini I.; Inguscio B.M.S.; Mariani L.; Portanova G.; Ruoppolo G.; Orlando M.P.; Dincer D'Alessandro H.; Mancini P.,"Nicastri, Maria (6507589124); Lo Castro, Fabio (13806101900); Giallini, Ilaria (57189901971); Inguscio, Bianca Maria Serena (57204127025); Mariani, Laura (56122815800); Portanova, Ginevra (57202151103); Ruoppolo, Giovanni (6701582439); Orlando, Maria Patrizia (57078149400); Dincer D'Alessandro, Hilal (57203864504); Mancini, Patrizia (56962761900)",6507589124; 13806101900; 57189901971; 57204127025; 56122815800; 57202151103; 6701582439; 57078149400; 57203864504; 56962761900,Vocal singing skills by cochlear implanted children without formal musical training: Familiar versus unfamiliar songs,2023,International Journal of Pediatric Otorhinolaryngology,170,,111605,,,,1,10.1016/j.ijporl.2023.111605,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160107869&doi=10.1016%2fj.ijporl.2023.111605&partnerID=40&md5=8eeb5633017aa8a867c7724814f7bb0b,"Objectives: Vocal singing skills in pediatric CI users are not much known due to the limited number of studies. The principal aim of the present study was to evaluate vocal singing skills in Italian pediatric CI users. A further aim was to investigate factors that may significantly influence their performance. Methods: The participants were twenty-two implanted children and twenty-two hearing peers. Their vocal singing skills for familiar (“Happy Birthday to You”) and unfamiliar songs (“Baton Twirler” from Pam Pam 2- Tribute to Gordon) were evaluated in relation to their music perception (the Gordon test). Acoustic analysis was performed using Praat and MATLAB software. Nonparametric statistical tests and principal component analysis (PCA) were used to analyze the data. Results: Hearing children outperformed implanted peers in both music perception and vocal singing tasks (all measures regarding intonation, vocal range, melody, and memory for the familiar song versus measures regarding intonation and overall melody production for the unfamiliar song). Music perception and vocal singing performances revealed strong correlations. For the familiar and unfamiliar songs, age-appropriate vocal singing was observed in 27.3% versus 45.4% of children, all implanted within 24 months of age. Age at implantation and duration of CI experience were moderately correlated with the total score obtained from the Gordon test. Conclusion: Implanted children show limited vocal singing skills in comparison to their hearing peers. However, some children implanted within 24 months of age seem to achieve vocal singing skills as good as their hearing peers. Future research could be useful to better understand the role of brain plasticity to implement specific training programs for both music perception and vocal singing. © 2023 Elsevier B.V.",37245390,Article,Final,,Scopus,2-s2.0-85160107869
Wu X.; Huang M.; Huang W.; Zhao S.; Xie J.; Liu G.; Chang S.,"Wu, Xionghui (57427332500); Huang, Min (55820720900); Huang, Weiqing (57427060500); Zhao, Sijun (57220101206); Xie, Jiang (57941685200); Liu, Guangliang (57836914500); Chang, Shuting (57427609500)",57427332500; 55820720900; 57427060500; 57220101206; 57941685200; 57836914500; 57427609500,Preliminary investigation of the diagnosis and gene function of deep learning PTPN11 gene mutation syndrome deafness,2023,Frontiers in Genetics,14,,1113095,,,,1,10.3389/fgene.2023.1113095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147668351&doi=10.3389%2ffgene.2023.1113095&partnerID=40&md5=6c219f47cb2f463f86cfa26a9b7ebddc,"Syndromic deafness caused by PTPN11 gene mutation has gradually come into the public’s view. In the past, many people did not understand its application mechanism and role and only focused on non-syndromic deafness, so the research on syndromic deafness is not in-depth and there is a large degree of lack of research in this area. In order to let the public know more about the diagnosis and gene function of deafness caused by PTPN11 gene mutation syndrome, this paper used deep learning technology to study the diagnosis and gene function of deafness caused by syndrome with the concept of intelligent medical treatment, and finally drew a feasible conclusion. This paper provided a theoretical and practical basis for the diagnosis of deafness caused by PTPN11 gene mutation syndrome and the study of gene function. This paper made a retrospective analysis of the clinical data of 85 deaf children who visited Hunan Children’s Hospital,P.R. China from January 2020 to December 2021. The conclusion were as follows: Children aged 1–6 years old had multiple syndrome deafness, while children under 1 year old and children aged 6–12 years old had relatively low probability of complex deafness; girls were not easy to have comprehensive deafness, but there was no specific basis to prove that the occurrence of comprehensive deafness was necessarily related to gender; the hearing loss of patients with Noonan Syndrome was mainly characterized by moderate and severe damage and abnormal inner ear and auditory nerve; most of the mutation genes in children were located in Exon1 and Exon3, with a total probability of 57.65%. In the course of the experiment, it was found that deep learning was effective in the diagnosis of deafness with PTPN11 gene mutation syndrome. This technology could be applied to medical diagnosis to facilitate the diagnosis and treatment of more patients with deafness with syndrome. Intelligent medical treatment was also becoming a hot topic nowadays. By using this concept to analyze and study the pathological characteristics of deafness caused by PTPN11 gene mutation syndrome, it not only promoted patients to find diseases in time, but also helped doctors to diagnose and treat such diseases, which was of great significance to patients and doctors. The study of PTPN11 gene mutation syndrome deafness was also of great significance in genetics. The analysis of its genes not only enriched the gene pool, but also provided reference for future research. Copyright © 2023 Wu, Huang, Huang, Zhao, Xie, Liu and Chang.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147668351
"MacDonald W.W.; Wakely P.E., Jr; Kalmar J.R.; Argyris P.P.","MacDonald, William W. (58879290000); Wakely, Paul E. (7005074776); Kalmar, John R. (7004264105); Argyris, Prokopios P. (36570007200)",58879290000; 7005074776; 7004264105; 36570007200,Fungal Otitis Externa (Otomycosis) Associated with Aspergillus Flavus: A Case Image,2024,Head and Neck Pathology,18,1,5,,,,0,10.1007/s12105-023-01606-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184730134&doi=10.1007%2fs12105-023-01606-1&partnerID=40&md5=9e6a2709e158070dfb14f08416f5d878,"A 48-year-old man presented with a chief complaint of intermittent right ear otorrhea of several-month duration, occasional otalgia and progressive unilateral hearing impairment. He also reported frequent episodes of headache and pressure in the sinuses and maxilla. Previous systemic treatment with antibiotics failed to alleviate the symptoms. A head/neck CT showed completely normal mastoid, middle ear and external auditory canal regions without any evidence of opacification or bone erosion. Otoscopic examination of the right ear disclosed aggregates of dried, brown, fibrillar material and debris occluding the external auditory canal and obstructing the otherwise intact tympanic membrane. Dilation of the external auditory canal or thickening of the tympanic membrane were not appreciated. The canal was debrided and the fibrillar material was placed in formalin. Histopathologic examination revealed numerous branching, septated fungal hyphae organized in densely-packed clusters. In other areas, the fungal hyphae abutted or were attached to lamellated collections of orthokeratin. As highlighted by GMS staining, the fungi were morphologically compatible with Aspergillus species. The clinicopathologic findings supported a diagnosis of fungal otitis externa, while the numerous anucleate squamous cells were compatible with colonization of an underlying, probably developing, cholesteatoma. Culture of material isolated from the external auditory canal confirmed the presence of Aspergillus flavus. In this illustrative case, we present the main clinical and microscopic characteristics of Aspergillus-related otomycosis developing in the setting of a tautochronous cholesteatoma. © The Author(s) 2024.",38334859,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85184730134
Mulay H.; Mangina E.; Redfern S.,"Mulay, Hrishikesh (58847550600); Mangina, Eleni (6602986948); Redfern, Sam (8068792100)",58847550600; 6602986948; 8068792100,Automated Lip Reading: Potential to enhance accessibility in XR,2023,ACM International Conference Proceeding Series,,,,42,,,0,10.1145/3633083.3633191,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183330317&doi=10.1145%2f3633083.3633191&partnerID=40&md5=26cde4f540de2d337f5657109b2c2211,"Existing research indicates that immersive technology will greatly influence the pedagogical practices in the coming years. Due to the visual nature of the XR (eXtended Reality) applications, lack of auditory support systems and high dependence on physical gestures and movements makes immersive tech inaccessible for people with special needs. However, the increasing influence and rise of the Metaverse has instigated an urgency to make XR environments accessible from the vulnerable segments of the society. Deaf and Hard of Hearing (DHH) participants often face social challenges such as illiteracy, unemployment, lack of growth in personal and professional life and social isolation. Recent advancements in Machine Learning have opened opportunities to perform Automated Lip Reading (ALR), which could be used as an assistive tool by DHH people within the Metaverse. This work in progress aspires to contribute towards the implementation of ALR systems in XR educational environments, and provide an ethically aligned design and standardization in its implementation, with ultimate aim to enhance accessibility measures in immersive technologies.  © 2023 Owner/Author.",,Conference paper,Final,,Scopus,2-s2.0-85183330317
Hong J.-P.; Lee J.-Y.; Kim M.-B.,"Hong, Joon-Pyo (57659505200); Lee, Jung-Yup (57205641916); Kim, Min-Beom (21834371200)",57659505200; 57205641916; 21834371200,Vestibular mapping in Ramsay-Hunt syndrome and idiopathic sudden sensorineural hearing loss,2023,European Archives of Oto-Rhino-Laryngology,280,12,,5251,5258,7,0,10.1007/s00405-023-08029-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160221678&doi=10.1007%2fs00405-023-08029-2&partnerID=40&md5=121af5d24e8022cc492da8cac6ad0576,"Purpose: To observe vestibular impairment patterns in patients with Ramsay Hunt syndrome with dizziness (RHS_D) and sudden sensorineural hearing loss with dizziness (SSNHL_D) using hierarchical cluster analysis (HCA) to interpret results with possible mechanisms. Methods: The data of 30 RHS_D and 81 SSNHL_D patients from January 2017 to August 2022 in a single tertiary referral center were retrospectively analyzed. Video head impulse test (vHIT) and vestibular evoked myogenic potential (VEMP) were used for vestibular analysis of peripheral vestibular organs, and the results of vHIT and VEMP were analyzed. HCA was used to analyze vestibular impairment patterns. Results: In RHS_D patients, the lateral semicircular canal (LSCC) was the most impaired semicircular canal (SCC), followed by the anterior semicircular canal (ASCC) and the posterior semicircular canal (PSCC), and the utricle was more impaired than the saccule. In SSNHL_D patients, the PSCC was the most impaired SCC, followed by the LSCC and the ASCC, and the utricle was more impaired than the saccule. In HCA of RHS_D patients, the ASCC and utricle were initially clustered, followed by the LSCC, PSCC and saccule in order. In the HCA of SSNHL_D patients, the PSCC was solely merged and independently clustered. Conclusion: There were different patterns of vestibular impairments between RHS_D and SSNHL_D patients. The vestibular analysis and HCA results of SSNHL_D showed tendency of skip lesion, which could be explained by vascular pathophysiology. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",37210462,Article,Final,,Scopus,2-s2.0-85160221678
Winship K.A.; Jones B.L.,"Winship, Kelley A. (56433241000); Jones, Brittany L. (56599546800)",56433241000; 56599546800,Acoustic Monitoring of Professionally Managed Marine Mammals for Health and Welfare Insights,2023,Animals,13,13,2124,,,,3,10.3390/ani13132124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164714220&doi=10.3390%2fani13132124&partnerID=40&md5=7034ce30997e7292eb14b013d1304995,"Research evaluating marine mammal welfare and opportunities for advancements in the care of species housed in a professional facility have rapidly increased in the past decade. While topics, such as comfortable housing, adequate social opportunities, stimulating enrichment, and a high standard of medical care, have continued to receive attention from managers and scientists, there is a lack of established acoustic consideration for monitoring the welfare of these animals. Marine mammals rely on sound production and reception for navigation and communication. Regulations governing anthropogenic sound production in our oceans have been put in place by many countries around the world, largely based on the results of research with managed and trained animals, due to the potential negative impacts that unrestricted noise can have on marine mammals. However, there has not been an established best practice for the acoustic welfare monitoring of marine mammals in professional care. By monitoring animal hearing and vocal behavior, a more holistic view of animal welfare can be achieved through the early detection of anthropogenic sound sources, the acoustic behavior of the animals, and even the features of the calls. In this review, the practice of monitoring cetacean acoustic welfare through behavioral hearing tests and auditory evoked potentials (AEPs), passive acoustic monitoring, such as the Welfare Acoustic Monitoring System (WAMS), as well as ideas for using advanced technologies for utilizing vocal biomarkers of health are introduced and reviewed as opportunities for integration into marine mammal welfare plans. © 2023 by the authors.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85164714220
Carlton A.J.; Jeng J.-Y.; Grandi F.C.; De Faveri F.; Amariutei A.E.; De Tomasi L.; O'Connor A.; Johnson S.L.; Furness D.N.; Brown S.D.M.; Ceriani F.; Bowl M.R.; Mustapha M.; Marcotti W.,"Carlton, Adam J. (57218213480); Jeng, Jing-Yi (57196222089); Grandi, Fiorella C. (57211987633); De Faveri, Francesca (57193292148); Amariutei, Ana E. (57225182312); De Tomasi, Lara (57195952070); O'Connor, Andrew (58965871400); Johnson, Stuart L. (58965470500); Furness, David N. (7003958281); Brown, Steve D.M. (57203968975); Ceriani, Federico (55330877600); Bowl, Michael R. (6506874735); Mustapha, Mirna (7003804040); Marcotti, Walter (6602070670)",57218213480; 57196222089; 57211987633; 57193292148; 57225182312; 57195952070; 58965871400; 58965470500; 7003958281; 57203968975; 55330877600; 6506874735; 7003804040; 6602070670,BAI1 localizes AMPA receptors at the cochlear afferent post-synaptic density and is essential for hearing,2024,Cell Reports,43,4,114025,,,,0,10.1016/j.celrep.2024.114025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189166542&doi=10.1016%2fj.celrep.2024.114025&partnerID=40&md5=f9b1bb914b4ca2b581d7c2fa6db30818,"Type I spiral ganglion neurons (SGNs) convey sound information to the central auditory pathway by forming synapses with inner hair cells (IHCs) in the mammalian cochlea. The molecular mechanisms regulating the formation of the post-synaptic density (PSD) in the SGN afferent terminals are still unclear. Here, we demonstrate that brain-specific angiogenesis inhibitor 1 (BAI1) is required for the clustering of AMPA receptors GluR2–4 (glutamate receptors 2–4) at the PSD. Adult Bai1-deficient mice have functional IHCs but fail to transmit information to the SGNs, leading to highly raised hearing thresholds. Despite the almost complete absence of AMPA receptor subunits, the SGN fibers innervating the IHCs do not degenerate. Furthermore, we show that AMPA receptors are still expressed in the cochlea of Bai1-deficient mice, highlighting a role for BAI1 in trafficking or anchoring GluR2–4 to the PSDs. These findings identify molecular and functional mechanisms required for sound encoding at cochlear ribbon synapses. © 2024 The Author(s)",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85189166542
Cheng Y.; Chen W.; Xu J.; Liu H.; Chen T.; Hu J.,"Cheng, Yajing (57199041646); Chen, Wenjin (58010567600); Xu, Jia (57869506800); Liu, Hang (58641640000); Chen, Ting (57766663600); Hu, Jun (57193628217)",57199041646; 58010567600; 57869506800; 58641640000; 57766663600; 57193628217,Genetic analysis of potential biomarkers and therapeutic targets in age-related hearing loss,2023,Hearing Research,439,,108894,,,,1,10.1016/j.heares.2023.108894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173874392&doi=10.1016%2fj.heares.2023.108894&partnerID=40&md5=1fb49f0d6d452ce910b23e8a0296cdc7,"Age-related hearing loss (ARHL) or presbycusis is the phenomenon of hearing loss due to the aging of auditory organs with age. It seriously affects the cognitive function and quality of life of the elderly. This study is based on comprehensive bioinformatic and machine learning methods to identify the critical genes of ARHL and explore its therapy targets and pathological mechanisms. The ARHL and normal samples were from GSE49543 datasets of the Gene Expression Omnibus (GEO) database. Weighted gene co-expression network analysis (WGCNA) was applied to obtain significant modules. The Limma R-package was used to identify differentially expressed genes (DEGs). The 15 common genes of the practical module and DEGs were screened. Functional enrichment analysis suggested that these genes were mainly associated with inflammation, immune response, and infection. Cytoscape software created the protein-protein interaction (PPI) layouts and cytoHubba, support vector machine-recursive feature elimination (SVM-RFE), and random forests (RF) algorithms screened hub genes. After validating the hub gene expressions in GSE6045 and GSE154833 datasets, Clec4n, Mpeg1, and Fcgr3 are highly expressed in ARHL and have higher diagnostic efficacy for ARHL, so they were identified as hub genes. In conclusion, Clec4n, Mpeg1, and Fcgr3 play essential roles in developing ARHL, and they might become vital targets in ARHL diagnosis and anti-inflammatory therapy. © 2023",37844444,Article,Final,,Scopus,2-s2.0-85173874392
Webster K.E.; George B.; Lee A.; Galbraith K.; Harrington-Benton N.A.; Judd O.; Kaski D.; Maarsingh O.R.; MacKeith S.; Murdin L.; Ray J.; Van Vugt V.A.; Burton M.J.,"Webster, Katie E (57216874757); George, Ben (57191633203); Lee, Ambrose (57224093689); Galbraith, Kevin (57194164532); Harrington-Benton, Natasha A (57392914200); Judd, Owen (27168804900); Kaski, Diego (6507711283); Maarsingh, Otto R (26423725400); MacKeith, Samuel (55663453800); Murdin, Louisa (56133414300); Ray, Jaydip (58294704300); Van Vugt, Vincent A (57192376990); Burton, Martin J (35561613100)",57216874757; 57191633203; 57224093689; 57194164532; 57392914200; 27168804900; 6507711283; 26423725400; 55663453800; 56133414300; 58294704300; 57192376990; 35561613100,Lifestyle and dietary interventions for Ménière’s disease,2023,Cochrane Database of Systematic Reviews,2023,2,CD015244,,,,2,10.1002/14651858.CD015244.pub2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148976101&doi=10.1002%2f14651858.CD015244.pub2&partnerID=40&md5=bc653faa01e1649acc8a438b8eac2d22,"Background: Ménière's disease is a condition that causes recurrent episodes of vertigo, associated with hearing loss and tinnitus. Lifestyle or dietary modifications (including reducing the amount of salt or caffeine in the diet) are sometimes suggested to be of benefit for this condition. The underlying cause of Ménière's disease is unknown, as is the way in which these interventions may work. The efficacy of these different interventions at preventing vertigo attacks, and their associated symptoms, is currently unclear. Objectives: To evaluate the benefits and harms of lifestyle and dietary interventions versus placebo or no treatment in people with Ménière's disease. Search methods: The Cochrane ENT Information Specialist searched the Cochrane ENT Register; Central Register of Controlled Trials (CENTRAL); Ovid MEDLINE; Ovid Embase; Web of Science; ClinicalTrials.gov; ICTRP and additional sources for published and unpublished trials. The date of the search was 14 September 2022. Selection criteria: We included randomised controlled trials (RCTs) and quasi-RCTs in adults with Ménière's disease comparing any lifestyle or dietary intervention with either placebo or no treatment. We excluded studies with follow-up of less than three months, or with a cross-over design (unless data from the first phase of the study could be identified). Data collection and analysis: We used standard Cochrane methods. Our primary outcomes were: 1) improvement in vertigo (assessed as a dichotomous outcome - improved or not improved), 2) change in vertigo (assessed as a continuous outcome, with a score on a numerical scale) and 3) serious adverse events. Our secondary outcomes were: 4) disease-specific health-related quality of life, 5) change in hearing, 6) change in tinnitus and 7) other adverse effects. We considered outcomes reported at three time points: 3 to < 6 months, 6 to ≤ 12 months and > 12 months. We used GRADE to assess the certainty of evidence for each outcome. Main results: We included two RCTs, one related to diet, and the other related to fluid intake and sleep. In a Swedish study, 51 participants were randomised to receive 'specially processed cereals' or standard cereals. The specially processed cereals are thought to stimulate the production of anti-secretory factor - a protein that reduces inflammation and fluid secretion. Participants received the cereals for three months. The only outcome reported by this study was disease-specific health-related quality of life. The second study was conducted in Japan. The participants (223) were randomised to receive abundant water intake (35 mL/kg/day), or to sleep in darkness (in an unlit room for six to seven hours per night), or to receive no intervention. The duration of follow-up was two years. The outcomes assessed were 'improvement in vertigo' and hearing. As these studies considered different interventions we were unable to carry out any meta-analysis, and for almost all outcomes the certainty of the evidence was very low. We are unable to draw meaningful conclusions from the numerical results. Authors' conclusions: The evidence for lifestyle or dietary interventions for Ménière's disease is very uncertain. We did not identify any placebo-controlled RCTs for interventions that are frequently recommended for those with Ménière's disease, such as salt restriction or caffeine restriction. We identified only two RCTs that compared a lifestyle or dietary intervention to placebo or no treatment, and the evidence that is currently available from these studies is of low or very low certainty. This means that we have very low confidence that the effects reported are accurate estimates of the true effect of these interventions. Consensus on the appropriate outcomes to measure in studies of Ménière's disease is needed (i.e. a core outcome set) in order to guide future studies in this area and enable meta-analyses of the results. This must include appropriate consideration of the potential harms of treatment, as well as the benefits. Copyright © 2023 The Authors. Cochrane Database of Systematic Reviews published by John Wiley & Sons, Ltd. on behalf of The Cochrane Collaboration.",36848645,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85148976101
Pan X.; Li Y.; Huang P.; Staecker H.; He M.,"Pan, Xiaoshu (57195471452); Li, Yanjun (57203122260); Huang, Peixin (57766086900); Staecker, Hinrich (7003979770); He, Mei (56844213200)",57195471452; 57203122260; 57766086900; 7003979770; 56844213200,Extracellular vesicles for developing targeted hearing loss therapy,2024,Journal of Controlled Release,366,,,460,478,18,0,10.1016/j.jconrel.2023.12.050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181977245&doi=10.1016%2fj.jconrel.2023.12.050&partnerID=40&md5=95a2773e4d4339c6ee5ce6cfd351c6e5,"Substantial efforts have been made for local administration of small molecules or biologics in treating hearing loss diseases caused by either trauma, genetic mutations, or drug ototoxicity. Recently, extracellular vesicles (EVs) naturally secreted from cells have drawn increasing attention on attenuating hearing impairment from both preclinical studies and clinical studies. Highly emerging field utilizing diverse bioengineering technologies for developing EVs as the bioderived therapeutic materials, along with artificial intelligence (AI)-based targeting toolkits, shed the light on the unique properties of EVs specific to inner ear delivery. This review will illuminate such exciting research field from fundamentals of hearing protective functions of EVs to biotechnology advancement and potential clinical translation of functionalized EVs. Specifically, the advancements in assessing targeting ligands using AI algorithms are systematically discussed. The overall translational potential of EVs is reviewed in the context of auditory sensing system for developing next generation gene therapy. © 2023",38182057,Review,Final,,Scopus,2-s2.0-85181977245
"Yang C.; Langworthy B.; Curhan S.; Vaden K.I., Jr; Curhan G.; Dubno J.R.; Wang M.","Yang, Ce (57783601000); Langworthy, Benjamin (57201032609); Curhan, Sharon (6506501242); Vaden, Kenneth I. (35316368100); Curhan, Gary (58942746200); Dubno, Judy R. (7003933859); Wang, Molin (12774321000)",57783601000; 57201032609; 6506501242; 35316368100; 58942746200; 7003933859; 12774321000,Soft classification and regression analysis of audiometric phenotypes of age-related hearing loss,2024,Biometrics,80,1,,,,,0,10.1093/biomtc/ujae013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187965794&doi=10.1093%2fbiomtc%2fujae013&partnerID=40&md5=de32018ced4223d0f497d417952daae2,"Age-related hearing loss has a complex etiology. Researchers have made efforts to classify relevant audiometric phenotypes, aiming to enhance medical interventions and improve hearing health. We leveraged existing pattern analyses of age-related hearing loss and implemented the phenotype classification via quadratic discriminant analysis (QDA). We herein propose a method for analyzing the exposure effects on the soft classification probabilities of the phenotypes via estimating equations. Under reasonable assumptions, the estimating equations are unbiased and lead to consistent estimators. The resulting estimator had good finite sample performances in simulation studies. As an illustrative example, we applied our proposed methods to assess the association between a dietary intake pattern, assessed as adherence scores for the dietary approaches to stop hypertension diet calculated using validated food-frequency questionnaires, and audiometric phenotypes (older-normal, metabolic, sensory, and metabolic plus sensory), determined based on data obtained in the Nurses' Health Study II Conservation of Hearing Study, the Audiology Assessment Arm. Our findings suggested that participants with a more healthful dietary pattern were less likely to develop the metabolic plus sensory phenotype of age-related hearing loss. © The Author(s) 2024. Published by Oxford University Press on behalf of The International Biometric Society.",38488465,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85187965794
,,,Speech Communication - 15th ITG Conference,2023,Speech Communication - 15th ITG Conference,,,,,,274,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183638327&partnerID=40&md5=cfd827c8547e3c114f2f7562649da198,The proceedings contain 55 papers. The topics discussed include: ad hoc distributed microphones clustering: a comparative analysis on using coherence and signal-specific features; exploiting an external microphone to improve time-difference-of-arrival estimates for Euclidean distance matrix-based source localization; hearing impairment in crowdsourced speech quality assessments: its effect and screening with digit triplet hearing test; long-term conversation analysis: exploring utility and privacy; towards a natural reproduction of binaural recordings: combining binaural cue adaptation and adaptive crosstalk cancellation; screening of Alzheimer’s dementia up to 12 years ahead from conversational speech of ILSE study; speaker’s articulatory strategy analysis: theoretical framework and preliminary experiment; and speech-based age and gender prediction with transformers.,,Conference review,Final,,Scopus,2-s2.0-85183638327
Shin S.; Nam H.-Y.,"Shin, Seunghyeon (56431750700); Nam, Hyun-Yeol (35084121800)",56431750700; 35084121800,Characteristics of brain glucose metabolism and metabolic connectivity in noise-induced hearing loss,2023,Scientific Reports,13,1,21889,,,,0,10.1038/s41598-023-48911-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179362627&doi=10.1038%2fs41598-023-48911-x&partnerID=40&md5=d9f74f37fb513adb5206e562ac248c2a,"The purpose of this study was to evaluate the differences in cerebral glucose metabolism and metabolic connectivity between noise-induced hearing loss (NIHL) subjects and normal subjects. Eighty-nine subjects who needed close observation for NIHL or were diagnosed with NIHL and 89 normal subjects were enrolled. After pre-processing of positron emission tomography images including co-registration, spatial normalization, and smoothing, a two-sample t-test was conducted to compare cerebral glucose metabolism between the two groups. To evaluate metabolic connectivity between two groups, BRAPH–BRain Analysis using graPH theory, a software package to perform graph theory analysis of the brain connectome was used. NIHL subjects showed hypometabolism compared to normal subjects in both insulae (x − 38, y − 18, z 4; × 42, y − 12, z 4) and right superior temporal gyrus (× 44, y 16, z − 20). No brain regions showed hypermetabolism in the NIHL subjects. In metabolic connectivity analysis, NIHL subjects showed decreased average strength, global efficiency, local efficiency, and mean clustering coefficient when compared with normal subjects. Decreased glucose metabolism and metabolic connectivity in NIHL subject might reflect decreased auditory function. It might be characteristic of sensorineural hearing loss. © 2023, The Author(s).",38081979,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85179362627
Lim S.J.; Jeon E.-T.; Baek N.; Chung Y.H.; Kim S.Y.; Song I.; Rah Y.C.; Oh K.H.; Choi J.,"Lim, Sung Jin (57364788600); Jeon, Eun-Tae (57195325591); Baek, Namyoung (57485382500); Chung, Young Han (58145310200); Kim, Sang Yeop (58145918800); Song, Insik (57193863698); Rah, Yoon Chan (36978238900); Oh, Kyoung Ho (56043191900); Choi, June (36019909600)",57364788600; 57195325591; 57485382500; 58145310200; 58145918800; 57193863698; 36978238900; 56043191900; 36019909600,Prediction of Hearing Prognosis After Intact Canal Wall Mastoidectomy With Tympanoplasty Using Artificial Intelligence,2023,Otolaryngology - Head and Neck Surgery (United States),169,6,,1597,1605,8,2,10.1002/ohn.472,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166776786&doi=10.1002%2fohn.472&partnerID=40&md5=db8035d4ae5a92cb829d77c45aca4f6e,"Objective: To evaluate the performance of a machine learning model and the effects of major prognostic factors on hearing outcomes following intact canal wall (ICW) mastoidectomy with tympanoplasty. Study Design: Retrospective cross-sectional study. Setting: Tertiary hospital. Methods: A total of 484 patients with chronic otitis media who underwent ICW tympanomastoidectomy between January 2007 and December 2020 were included in this study. Successful hearing outcomes were defined by a postoperative air-bone gap (ABG) of ≤20 dB and preoperative air conduction (AC)-postoperative AC value of ≥15 dB according to the Korean Otological Society guidelines for outcome reporting after chronic otitis media surgery. The light gradient boosting machine (LightGBM) and multilayer perceptron (MLP) models were tested as artificial intelligence models and compared using logistic regression. The main outcome assessed was the successful hearing outcome after surgery, measured using the area under the receiver operating characteristic curve (AUROC). Results: In the analysis using the postoperative ABG criterion, the LightGBM exhibited a significantly higher AUROC compared to those of the baseline model (mean, 0.811). According to the difference between preoperative and postoperative AC, the MLP showed a significantly higher AUROC than those of the baseline model (mean, 0.795). Conclusion: This study analyzed multiple factors that could affect the hearing outcome using different artificial intelligence models and found that preoperative hearing status was the most important factor. Our findings provide additional information regarding postoperative hearing for clinicians. © 2023 American Academy of Otolaryngology–Head and Neck Surgery Foundation.",37538032,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85166776786
Drabkin M.; Jean M.M.; Noy Y.; Halperin D.; Yogev Y.; Wormser O.; Proskorovski-Ohayon R.; Dolgin V.; Levaot N.; Brumfeld V.; Ovadia S.; Kishner M.; Kazenell U.; Avraham K.B.; Shelef I.; Birk O.S.,"Drabkin, Max (57194941097); Jean, Matan M. (58094321900); Noy, Yael (57267221600); Halperin, Daniel (57194629114); Yogev, Yuval (57194941000); Wormser, Ohad (57194947921); Proskorovski-Ohayon, Regina (57195930452); Dolgin, Vadim (57208337228); Levaot, Noam (45161489500); Brumfeld, Vlad (6701385172); Ovadia, Shira (7004093587); Kishner, Mor (57205462633); Kazenell, Udi (58565623200); Avraham, Karen B. (7007074258); Shelef, Ilan (6602149380); Birk, Ohad S. (6701619815)",57194941097; 58094321900; 57267221600; 57194629114; 57194941000; 57194947921; 57195930452; 57208337228; 45161489500; 6701385172; 7004093587; 57205462633; 58565623200; 7007074258; 6602149380; 6701619815,SMARCA4 mutation causes human otosclerosis and a similar phenotype in mice,2023,Journal of Medical Genetics,61,2,,117,124,7,0,10.1136/jmg-2023-109264,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170069610&doi=10.1136%2fjmg-2023-109264&partnerID=40&md5=e8ee91dfd4fbbcc785a9f69fcf13a914,"Background Otosclerosis is a common cause of adult-onset progressive hearing loss, affecting 0.3%-0.4% of the population. It results from dysregulation of bone homeostasis in the otic capsule, most commonly leading to fixation of the stapes bone, impairing sound conduction through the middle ear. Otosclerosis has a well-known genetic predisposition including familial cases with apparent autosomal dominant mode of inheritance. While linkage analysis and genome-wide association studies suggested an association with several genomic loci and with genes encoding structural proteins involved in bone formation or metabolism, the molecular genetic pathophysiology of human otosclerosis is yet mostly unknown. Methods Whole-exome sequencing, linkage analysis, generation of CRISPR mutant mice, hearing tests and micro-CT. Results Through genetic studies of kindred with seven individuals affected by apparent autosomal dominant otosclerosis, we identified a disease-causing variant in SMARCA4, encoding a key component of the PBAF chromatin remodelling complex. We generated CRISPR-Cas9 transgenic mice carrying the human mutation in the mouse SMARCA4 orthologue. Mutant Smarca4 +/E1548K mice exhibited marked hearing impairment demonstrated through acoustic startle response and auditory brainstem response tests. Isolated ossicles of the auditory bullae of mutant mice exhibited a highly irregular structure of the incus bone, and their in situ micro-CT studies demonstrated the anomalous structure of the incus bone, causing disruption in the ossicular chain. Conclusion We demonstrate that otosclerosis can be caused by a variant in SMARCA4, with a similar phenotype of hearing impairment and abnormal bone formation in the auditory bullae in transgenic mice carrying the human mutation in the mouse SMARCA4 orthologue.  © 2023 Annals of the Rheumatic Diseases. All rights reserved.",37399313,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85170069610
Miñope-Anchaya E.; Ramos-Cosi S.; Lulluy-Nuñez D.; Cieza-Terrones M.; Alva-Mantari A.,"Miñope-Anchaya, Estefani (58499330600); Ramos-Cosi, Sebastián (57225097710); Lulluy-Nuñez, David (58929614000); Cieza-Terrones, Michael (57216926089); Alva-Mantari, Alicia (57205596738)",58499330600; 57225097710; 58929614000; 57216926089; 57205596738,Systematic Review on Technological Devices for the Communication of Hearing-impaired Children from 2002 to 2023,2024,International Journal of Engineering Trends and Technology,72,2,,230,241,11,0,10.14445/22315381/IJETT-V72I2P124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187293615&doi=10.14445%2f22315381%2fIJETT-V72I2P124&partnerID=40&md5=1f0fa710c04a7348d6b0529daa404571,"Currently, the World Health Organization reports that more than 430 million people worldwide have hearing impairment, with a projection of 900 million by 2050. In particular, approximately 35 million children worldwide are affected by this condition. Early cortical auditory development plays a crucial role in a child's life, and any deficiency in auditory function during these formative years can hinder proper synaptic development. This systematic review aims to explore the landscape of technological devices designed to improve communication for children with hearing disabilities. This study analyzed existing literature through rigorous methodology, employing bibliometric network analysis to uncover key insights and utilizing the Scopus database in conjunction with Vosviewer and Visual Basic Applications. As a result, 8,827 scientific documents were obtained, wherein authors, countries, affiliations, document types, publication years, and keywords were analyzed. Articles constituted the majority of these documents, comprising over 64.1%, and the peak in document production occurred in 2022 with 620 documents. In conclusion, the development of technological devices has yielded significant results over the last 20 years, incorporating recent trends such as machine learning and artificial intelligence for creating new devices. However, there was limited consideration for children or the caregivers and family members of individuals with hearing disabilities. © 2024 Seventh Sense Research Group®",,Review,Final,,Scopus,2-s2.0-85187293615
Kim T.; Kim S.; Kim J.; Lee Y.; Choi J.,"Kim, Taewan (58154001000); Kim, Sangyeop (58145918800); Kim, Jaeyoung (57191685592); Lee, Yeonjoon (56416784300); Choi, June (36019909600)",58154001000; 58145918800; 57191685592; 56416784300; 36019909600,Toward Better Ear Disease Diagnosis: A Multi-Modal Multi-Fusion Model Using Endoscopic Images of the Tympanic Membrane and Pure-Tone Audiometry,2023,IEEE Access,11,,,116721,116731,10,0,10.1109/ACCESS.2023.3325346,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174827245&doi=10.1109%2fACCESS.2023.3325346&partnerID=40&md5=c5a75e090a93ded0f728ae2dafeaa431,"Chronic otitis media is characterized by recurrent infections, leading to serious complications, such as meningitis, facial palsy, and skull base osteomyelitis. Therefore, active treatment based on early diagnosis is essential. This study developed a multi-modal multi-fusion (MMMF) model that automatically diagnoses ear diseases by applying endoscopic images of the tympanic membrane (TM) and pure-tone audiometry (PTA) data to a deep learning model. The primary aim of the proposed MMMF model is adding 'normal with hearing loss' as a category, and improving the diagnostic accuracy of the conventional four ear diseases: normal, TM perforation, retraction, and cholesteatoma. To this end, the MMMF model was trained on 1,480 endoscopic images of the TM and PTA data to distinguish five ear disease states: normal, TM perforation, retraction, cholesteatoma, and normal (hearing loss). It employs a feature fusion strategy of cross-attention, concatenation, and gated multi-modal units in a multi-modal architecture encompassing a convolutional neural network (CNN) and multi-layer perceptron. We expanded the classification capability to include an additional category, normal (hearing loss), thereby enhancing the diagnostic performance of extant ear disease classification. The MMMF model demonstrated superior performance when implemented with EfficientNet-B7, achieving 92.9% accuracy and 90.9% recall, thereby outpacing the existing feature fusion methods. In addition, five-fold cross-validation experiments were conducted, in which the model consistently demonstrated robust performance when endoscopic images of the TM and PTA data were applied to the deep learning model across all datasets. The proposed MMMF model is the first to include a category of normal ear disease state with hearing loss. The developed model demonstrated superior performance compared to existing CNN models and feature fusion methods. Consequently, this study substantiates the utility of simultaneously applying PTA data and endoscopic images of the TM for the automated diagnosis of ear diseases in clinical settings and validates the usefulness of the multi-fusion method. © 2013 IEEE.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85174827245
Hohmann V.,"Hohmann, Volker (6602836905)",6602836905,The future of hearing aid technology: Can technology turn us into superheroes?; [Die Zukunft der Hörgerätetechnologie: Kann die Technologie uns in Superhelden verwandeln?],2023,Zeitschrift fur Gerontologie und Geriatrie,56,4,,283,289,6,2,10.1007/s00391-023-02179-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153971746&doi=10.1007%2fs00391-023-02179-y&partnerID=40&md5=c0ed9f87a7e719bd89255fa72b66d193,"Background: Hearing aid technology has proven to be successful in the rehabilitation of hearing loss, but its performance is still limited in difficult everyday conditions characterized by noise and reverberation. Objective: Introduction to the current state of hearing aid technology and presentation of the current state of research and future developments. Methods: The current literature was analyzed and several specific new developments are presented. Results: Both objective and subjective data from empirical studies show the limitations of the current technology. Examples of current research show the potential of machine learning-based algorithms and multimodal signal processing for improving speech processing and perception, of using virtual reality for improving hearing device fitting and of mobile health technology for improving hearing health services. Conclusion: Hearing device technology will remain a key factor in the rehabilitation of hearing impairments. New technology, such as machine learning and multimodal signal processing, virtual reality and mobile health technology, will improve speech enhancement, individual fitting and communication training, thus providing better support for all hearing-impaired patients, including older patients with disabilities or declining cognitive skills. © 2023, The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature.",37103645,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85153971746
Teggi R.; Colombo B.; Cugnata F.; Albera R.; Libonati G.A.; Balzanelli C.; Casani A.P.; Cangiano I.; Familiari M.; Lucisano S.; Mandalà M.; Neri G.; Pecci R.; Bussi M.; Filippi M.,"Teggi, Roberto (6503983560); Colombo, Bruno (7102440623); Cugnata, Federica (57113708000); Albera, Roberto (7003992485); Libonati, Giacinto Asprella (24576248100); Balzanelli, Cristiano (57190893499); Casani, Augusto Pietro (7003861787); Cangiano, Iacopo (57221672857); Familiari, Marco (57220083768); Lucisano, Sergio (56383873700); Mandalà, Marco (8634866600); Neri, Giampiero (7201766447); Pecci, Rudi (37665711100); Bussi, Mario (7006697063); Filippi, Massimo (7202268530)",6503983560; 7102440623; 57113708000; 7003992485; 24576248100; 57190893499; 7003861787; 57221672857; 57220083768; 56383873700; 8634866600; 7201766447; 37665711100; 7006697063; 7202268530,Phenotypes and clinical subgroups in vestibular migraine: a cross-sectional study with cluster analysis,2024,Neurological Sciences,45,3,,1209,1216,7,0,10.1007/s10072-023-07116-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174255303&doi=10.1007%2fs10072-023-07116-w&partnerID=40&md5=26204305544d0bdf1d9fe00fd5563f51,"Objective: The aim of this multicentric cross-sectional study was to collect phenotypes and clinical variability on a large sample of 244 patients enrolled in different university centers in Italy, trying to differentiate subtypes of VM. Background: VM is one of the most frequent episodic vertigo characterized by a great clinical variability for duration of attacks and accompanying symptoms. Diagnosis is based only on clinical history of episodic vertigo in 50% of cases associated with migrainous headache or photo/phonophobia. Methods: We enrolled in different university centers 244 patients affected by definite VM according to the criteria of the Barany Society between January 2022 and December 2022. An audiometric examination and a CNS MRI were performed before inclusion. Patients with low-frequency sensorineural hearing loss were not included, as well as patients with an MRI positive otherwise that for microischemic lesions. Patients were asked to characterize vestibular symptoms choosing among (multiple answers were allowed): internal vertigo, dizziness, visuo-vestibular symptoms/external vertigo; onset of vertigo and duration, neurovegetative, and cochlear accompanying symptoms (hearing loss, tinnitus, and fullness during attacks) were collected as well as migrainous headache and/or photo/phonophobia during vertigo; autoimmune disorders were also analyzed. A bedside examination was performed including study of spontaneous-positional nystagmus with infrared video goggles, post head shaking ny, skull vibration test, and video head impulse test. Results: We included 244 subjects, 181 were females (74.2%). The age of onset of the first vertigo was 36.6 ± 14.5 while of the first headache was 23.2 ± 10.1. A positive correlation has been found between the first headache and the first vertigo. The mean duration of vertigo attacks was 11 ± 16 h. We carried on a cluster analysis to identify subgroups of patients with common clinical features. Four variables allowed to aggregate clusters: age of onset of vertigo, duration of vertigo attacks, presence of migrainous headache during vertigo, and presence of cochlear symptoms during vertigo. We identified 5 clusters: cluster 1/group 1 (23 subjects, 9.4%) characterized by longer duration of vertigo attacks; cluster 2/group 2 (52 subjects, 21.3%) characterized by absence of migrainous headache and cochlear symptoms during vertigo; cluster 3/group 3 (44 subjects, 18%) characterized by presence of cochlear symptoms during vertigo but not headache; cluster 4/group 4 (57 subjects, 23.4%) by the presence of both cochlear symptoms and migrainous headache during vertigo; cluster 5/group 5 (68 subjects, 27.9%) characterized by migrainous headache but no cochlear symptoms during vertigo. Conclusion: VM is with any evidence a heterogeneous disorder and clinical presentations exhibit a great variability. In VM, both symptoms orienting toward a peripheral mechanism (cochlear symptoms) and central ones (long lasting positional non-paroxysmal vertigo) may coexist. Our study is the first published trying to characterize subgroups of VM subjects, thus orienting toward different pathophysiological mechanisms. © Fondazione Società Italiana di Neurologia 2023.",37845481,Article,Final,,Scopus,2-s2.0-85174255303
Jaisharma K.; Deepa N.,"Jaisharma, K. (57211329315); Deepa, N. (57209685004)",57211329315; 57209685004,An Automated Model for Child Language Impairment Prediction Using Hybrid Optimal BiLSTM,2023,IETE Journal of Research,,,,,,,0,10.1080/03772063.2023.2243881,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182810580&doi=10.1080%2f03772063.2023.2243881&partnerID=40&md5=54e9bf86ed63e44a521b149268ba6f3b,"Children without obvious disabilities (hearing loss/low intellectual capacity) may have language skill development issues due to specific language impairment (SLI), a communication disorder. The SLI has a significant impact on a child's speaking, listening, reading, and writing abilities. SLI is typically known as development language disorder, developmental dysphasia, or language delay. Recently, machine learning as well as deep learning techniques have been quite effective in predicting the early stage of SLI, analyzing the disorder severity, and predicting the treatment efficiency. Existing approaches primarily exploited auditory indicators to diagnose communication disorders, frequently leaving out hidden information acquired in the temporal domain. To overcome this drawback, an optimized Bidirectional Long Short Term Memory (BiLSTM) architecture is presented in this paper to handle the speech dynamics. The Improved Hybrid Aquila Optimizer and Flow Directional algorithm known as IHAOFDA is integrated with the BiLSTM architecture to optimize the hyperparameters of the BiLSTM structure. When assessed using the information from the SLI children in the Laboratory of Artificial Neural Network Applications (LANNA) dataset, the proposed model performs better. The IHAOFDA-optimized BiLSTM architecture improves accuracy in classifying different severity levels such as mild, moderate, and severe. © 2023 IETE.",,Article,Article in press,,Scopus,2-s2.0-85182810580
Raji N.R.; Kumar R.M.S.; Biji C.L.,"Raji, N.R. (57227847500); Kumar, R Mathusoothana S. (55966916700); Biji, C.L. (56584500800)",57227847500; 55966916700; 56584500800,Closing the gap: exploring the untapped potential of machine learning in deaf students and hearing students’ academic performance,2023,International Journal of Advanced Technology and Engineering Exploration,10,108,,1449,1475,26,0,10.19101/IJATEE.2023.10101685,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178402240&doi=10.19101%2fIJATEE.2023.10101685&partnerID=40&md5=e59544de09b0b33fc93beebb55261928,"Assessments and critical feedback play a crucial role in helping students not only master a skill but also apply it effectively. Educational data mining (EDM) and machine learning (ML) tools are aiding educators in tailoring teaching strategies to individual student needs. While predictive analytics are widely used for hearing students, there is a notable gap in research on deaf students. Assessing deaf students necessitates the expertise of trained specialists, and their feedback is particularly critical in assisting these students in skill mastery. Various strategies have been developed to analyze the academic performance of deaf children, but there is a lack of integration of data to create a model categorizing different methods of early classification based on student academic performance. As part of a broader effort to address challenges faced by students struggling with speech perception and language development, there is an opportunity to conduct a systematic study of early academic interventions for deaf students. Failure to address these issues can result in an increased risk of delays in social-emotional development. The findings from our review highlight several key aspects, including (i) ML and EDM-based applications for student performance analysis, (ii) factors influencing academic performance among deaf students, (iii) potential EDM methods useful for assessing deaf children, (iv) the absence of benchmark data and the need for interpretability in existing methods, (v) the necessity for ML approaches in predicting the performance of deaf students, and (vi) the anticipated major assessment trend in the future through deep learning models. Our findings have implications for various stakeholders in education, including teachers, students, administrators, and researchers. © 2023 Raji N R et al.",,Review,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85178402240
Kosters J.; Janus S.I.M.; van den Bosch K.A.; Andringa T.C.; Hoop E.O.-D.; de Boer M.R.; Elburg R.A.J.; Warmelink S.; Zuidema S.U.; Luijendijk H.J.,"Kosters, Janouk (57216343241); Janus, Sarah I.M. (56574967300); van den Bosch, Kirsten A. (56277860700); Andringa, Tjeerd C. (24340984400); Hoop, E. Oomen-de (57190986087); de Boer, Michiel R. (8518459100); Elburg, Ronald A.J. (58066580900); Warmelink, Steven (58066420600); Zuidema, Sytse U. (8943344800); Luijendijk, Hendrika J. (23973040300)",57216343241; 56574967300; 56277860700; 24340984400; 57190986087; 8518459100; 58066580900; 58066420600; 8943344800; 23973040300,Soundscape Awareness Intervention Reduced Neuropsychiatric Symptoms in Nursing Home Residents With Dementia: A Cluster-Randomized Trial With MoSART+,2023,Journal of the American Medical Directors Association,24,2,,192,1.98E+07,,2,10.1016/j.jamda.2022.11.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146335126&doi=10.1016%2fj.jamda.2022.11.010&partnerID=40&md5=32bb2c10a265518052ea9b4936b8619a,"Objectives: Auditory environments as perceived by an individual, also called soundscapes, are often suboptimal for nursing home residents. Poor soundscapes have been associated with neuropsychiatric symptoms (NPS). We evaluated the effect of the Mobile Soundscape Appraisal and Recording Technology sound awareness intervention (MoSART+) on NPS in nursing home residents with dementia. Design: A 15-month, stepped-wedge, cluster-randomized trial. Every 3 months, a nursing home switched from care as usual to the use of the intervention. Intervention: The 3-month MoSART+ intervention involved ambassador training, staff performing sound measurements with the MoSART application, meetings, and implementation of microinterventions. The goal was to raise awareness about soundscapes and their influence on residents. Setting and participants: We included 110 residents with dementia in 5 Dutch nursing homes. Exclusion criteria were palliative sedation and deafness. Methods: The primary outcome was NPS severity measured with the Neuropsychiatric Inventory–Nursing Home version (NPI-NH) by the resident's primary nurse. Secondary outcomes were quality of life (QUALIDEM), psychotropic drug use (ATC), staff workload (workload questionnaire), and staff job satisfaction (Maastricht Questionnaire of Job Satisfaction). Results: The mean age of the residents (n = 97) at enrollment was 86.5 ± 6.7 years, and 76 were female (76.8%). The mean NPI-NH score was 17.5 ± 17.3. One nursing home did not implement the intervention because of staff shortages. Intention-to-treat analysis showed a clinically relevant reduction in NPS between the study groups (−8.0, 95% CI –11.7, −2.6). There was no clear effect on quality of life [odds ratio (OR) 2.8, 95% CI –0.7, 6.3], psychotropic drug use (1.2, 95% CI 0.9, 1.7), staff workload (−0.3, 95% CI –0.3, 0.8), or staff job satisfaction (−0.2, 95% CI –1.2, 0.7). Conclusions and Implications: MoSART+ empowered staff to adapt the local soundscape, and the intervention effectively reduced staff-reported levels of NPS in nursing home residents with dementia. Nursing homes should consider implementing interventions to improve the soundscape. © 2022 The Authors",36528077,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85146335126
Rakhmanova I.V.; Matroskin A.G.; Kruglyakov A.Yu.; Dudarov S.P.; Kunievskiy V.V.; Nozhnitskaya S.Yu.,"Rakhmanova, Irina V. (6602079711); Matroskin, Alexander G. (55413558800); Kruglyakov, Andrey Yu. (57193930754); Dudarov, Sergey P. (56707467400); Kunievskiy, Valeriy V. (58974109000); Nozhnitskaya, Svetlana Yu. (58974109100)",6602079711; 55413558800; 57193930754; 56707467400; 58974109000; 58974109100,Diagnosis of Auditory Function in Infants with COVID-19 (Part I),2024,Otorhinolaryngology Eastern Europe,14,1,,79,88,9,0,10.34883/PI.2024.14.1.033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189626743&doi=10.34883%2fPI.2024.14.1.033&partnerID=40&md5=32cf0beffd4e0d4e9beb902b940a3054,"Purpose. Identify the possible influence of the SARS-CoV-2 virus on the auditory function of children of the first year of life. Materials and methods. An analysis of the auditory function of 100 children born to mothers who had undergone COVID-19 during pregnancy and had recovered independently during the first year of life, as well as epicrises of case histories of the mothers themselves and their children, was carried out. The work was retrospective prospective and consisted of 2 stages. At the first stage, discharge epicrises of case histories of children and their mothers were studied, and at the second stage, audiological examination was carried out for all children by the method of auditory induced potentials, otoacoustic emission and tympanometry. The data we obtained were processed by various statistical methods using Cohonen artificial neural network-based clustering and a rigid clustering procedure by age at the time of examination, followed by analysis of the resulting clusters. Results. Analysis of auditory function at the time of treatment showed that there was no record of induced otoacoustic emission in 27 children, of whom 10 were full-term and 17 premature. In 17 of the 27 children, 17% of the total number of children, sensorineural stiffness was detected, namely, bilateral in 12 children, unilateral in one child and bilateral deafness in 4 children. The cluster analysis revealed worse parameters of induced otoacoustic emission and auditory induced potentials in the group where mothers had COVID-19 during pregnancy than in the group where the children themselves were sick. Conclusion. The cases of children with sensorineural hearing loss identified in our work indirectly, as well as the results of cluster analysis, may indicate a possible direct effect of the SARS-CoV-2 virus on certain structures of the auditory analyzer. © 2024, Professionalnye Izdaniya. All rights reserved.",,Article,Final,,Scopus,2-s2.0-85189626743
Schilling A.; Sedley W.; Gerum R.; Metzner C.; Tziridis K.; Maier A.; Schulze H.; Zeng F.-G.; Friston K.J.; Krauss P.,"Schilling, Achim (57189988281); Sedley, William (36085035000); Gerum, Richard (55990645300); Metzner, Claus (7006045419); Tziridis, Konstantin (23111384000); Maier, Andreas (23392966100); Schulze, Holger (35249120200); Zeng, Fan-Gang (7202911218); Friston, Karl J (36080215500); Krauss, Patrick (55216351100)",57189988281; 36085035000; 55990645300; 7006045419; 23111384000; 23392966100; 35249120200; 7202911218; 36080215500; 55216351100,Predictive coding and stochastic resonance as fundamental principles of auditory phantom perception,2023,Brain,146,12,,4809,4825,16,5,10.1093/brain/awad255,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171279915&doi=10.1093%2fbrain%2fawad255&partnerID=40&md5=05ae6e9007148208e793725d569eddf4,"Mechanistic insight is achieved only when experiments are employed to test formal or computational models. Furthermore, in analogy to lesion studies, phantom perception may serve as a vehicle to understand the fundamental processing principles underlying healthy auditory perception. With a special focus on tinnitus - as the prime example of auditory phantom perception - we review recent work at the intersection of artificial intelligence, psychology and neuroscience. In particular, we discuss why everyone with tinnitus suffers from (at least hidden) hearing loss, but not everyone with hearing loss suffers from tinnitus. We argue that intrinsic neural noise is generated and amplified along the auditory pathway as a compensatory mechanism to restore normal hearing based on adaptive stochastic resonance. The neural noise increase can then be misinterpreted as auditory input and perceived as tinnitus. This mechanism can be formalized in the Bayesian brain framework, where the percept (posterior) assimilates a prior prediction (brain's expectations) and likelihood (bottom-up neural signal). A higher mean and lower variance (i.e. enhanced precision) of the likelihood shifts the posterior, evincing a misinterpretation of sensory evidence, which may be further confounded by plastic changes in the brain that underwrite prior predictions. Hence, two fundamental processing principles provide the most explanatory power for the emergence of auditory phantom perceptions: predictive coding as a top-down and adaptive stochastic resonance as a complementary bottom-up mechanism. We conclude that both principles also play a crucial role in healthy auditory perception. Finally, in the context of neuroscience-inspired artificial intelligence, both processing principles may serve to improve contemporary machine learning techniques.  © 2023 The Author(s).",37503725,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85171279915
Chemnad K.; Othman A.,"Chemnad, Khansa (57814166600); Othman, Achraf (35183809100)",57814166600; 35183809100,Digital accessibility in the era of artificial intelligence—Bibliometric analysis and systematic review,2024,Frontiers in Artificial Intelligence,7,,1349668,,,,1,10.3389/frai.2024.1349668,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186552799&doi=10.3389%2ffrai.2024.1349668&partnerID=40&md5=bd100e84bc4f7ae0d19223652accf030,"Introduction: Digital accessibility involves designing digital systems and services to enable access for individuals, including those with disabilities, including visual, auditory, motor, or cognitive impairments. Artificial intelligence (AI) has the potential to enhance accessibility for people with disabilities and improve their overall quality of life. Methods: This systematic review, covering academic articles from 2018 to 2023, focuses on AI applications for digital accessibility. Initially, 3,706 articles were screened from five scholarly databases—ACM Digital Library, IEEE Xplore, ScienceDirect, Scopus, and Springer. Results: The analysis narrowed down to 43 articles, presenting a classification framework based on applications, challenges, AI methodologies, and accessibility standards. Discussion: This research emphasizes the predominant focus on AI-driven digital accessibility for visual impairments, revealing a critical gap in addressing speech and hearing impairments, autism spectrum disorder, neurological disorders, and motor impairments. This highlights the need for a more balanced research distribution to ensure equitable support for all communities with disabilities. The study also pointed out a lack of adherence to accessibility standards in existing systems, stressing the urgency for a fundamental shift in designing solutions for people with disabilities. Overall, this research underscores the vital role of accessible AI in preventing exclusion and discrimination, urging a comprehensive approach to digital accessibility to cater to diverse disability needs. Copyright © 2024 Chemnad and Othman.",,Review,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85186552799
Wahyudi E.; Meidelfi D.; Nofrizal; Saam Z.; Juandi,"Wahyudi, Eri (58805417700); Meidelfi, Dwiny (57202991476); Nofrizal (35722480900); Saam, Zulfan (57211292783); Juandi (58650602200)",58805417700; 57202991476; 35722480900; 57211292783; 58650602200,The Implementation of the K-Medoid Clustering for Grouping Hearing Loss Function on Excessive Smartphone Use,2023,International Journal on Informatics Visualization,7,4,,2523,2531,8,0,10.30630/joiv.7.4.1873,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181944438&doi=10.30630%2fjoiv.7.4.1873&partnerID=40&md5=062cc51c6eb902975b8677c1aee34eee,"During the current pandemic, smartphones have become a means of learning for all students in Indonesia, including high school students. Students use smartphones to send assignments, learn via video calls, and conduct online exams. The prolonged use of smartphones, from the beginning of learning hours in the morning to study hours in the evening, has a terrible impact on the ear health of high school students in Padang. Excessive smartphone use caused a decrease in the student's hearing function. Therefore, this study aims to group the audiometry results of high school students in Padang who have a hearing loss function. The audiogram result is only performed as the result of a frequency test of the subject's hearing in both the left and right ear. Conventionally, an otolaryngologist concluded the final decision of hearing loss ability. This research proposed an automatic classification of audiometry results using machine learning methods. The K-Medoids clustering was selected to classify the audiometry data in this research. Of 210 audiometry data, 91 data is confirmed by an otolaryngologist as valid data. By using the K-Medoids clustering, 93 data is classified into Normal hearing, Mild Hearing loss, and Moderate Hearing loss. The proposed model successfully grouped the audiometry data into three categories. The confusion matrix is applied to measure the model performance, which has 28,3% accuracy, 64,3% precision, and 21,4% recall. © 2023, Politeknik Negeri Padang. All rights reserved.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85181944438
Sankari V.M.R.; Snekhalatha U.; Murugappan M.; Chowdhury M.E.H.; Chamkha Z.A.,"Sankari, V. M. Raja (57758805500); Snekhalatha, U. (57803525200); Murugappan, M. (25825367900); Chowdhury, Muhammad E. H. (8964151000); Chamkha, Zeinab A. (58261028900)",57758805500; 57803525200; 25825367900; 8964151000; 58261028900,Artificial Intelligence-Based Hearing Loss Detection Using Acoustic Threshold and Speech Perception Level,2023,Arabian Journal for Science and Engineering,48,11,,14883,14899,16,0,10.1007/s13369-023-07927-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159655682&doi=10.1007%2fs13369-023-07927-1&partnerID=40&md5=ea9ddfdff9f487de68fe6f803b44e2e6,"Hearing loss detection using automated audiometers and artificial intelligence methods has gained increasing attention in recent years. The proposed work aims: (a) to design an automated audiometer to diagnose hearing ability and to evaluate hearing intensity for healthy and profound hearing loss patients within 250 Hz to 8 kHz, (b) to compare the proposed automated audiometer with a conventional audiometer when estimating auditory perception level using pure tone and speech audiometers, and (c) to use the machine learning algorithms to classify hearing loss and normal subjects based on the selected features extracted from speech signals. Participants in the study included 50 healthy individuals and 50 patients with profound hearing loss. In the proposed hardware unit, the transmitted pure-tone signal and the speech signal stimulus are controlled automatically instead of being controlled manually. Using a digital potentiometer, a pure-tone audiometer can be automatically calibrated by varying the frequency and intensity of the generated tones according to the users’ responses. During speech audiometric measurements, pre-recorded speech and repeated speech signals are analyzed to estimate speech recognition threshold (SRT) and word recognition score (WRS). The designed audiometer plots the audiogram automatically, estimating SRT and WRS, and classifying the subject as normal or hearing impaired. This study demonstrates the feasibility of using Machine Learning to predict hearing impairment in patients. A support vector machine, a random forest, and an AdaBoost model produced accuracy rates of 98%, 96%, and 96%, respectively, when identifying normal and hearing loss subjects. The proposed audiometer system is miniaturized, portable, and user-friendly in comparison to conventional audiometers. Consequently, the prototype would make it possible for subjects to conduct their own audiometric tests independently and send the results along with their audiogram to a trained medical professional to receive advice. © 2023, King Fahd University of Petroleum & Minerals.",,Article,Final,,Scopus,2-s2.0-85159655682
Elmer S.; Kurthen I.; Meyer M.; Giroud N.,"Elmer, Stefan (6603796867); Kurthen, Ira (57201395125); Meyer, Martin (7403185338); Giroud, Nathalie (57192154805)",6603796867; 57201395125; 7403185338; 57192154805,A multidimensional characterization of the neurocognitive architecture underlying age-related temporal speech processing,2023,NeuroImage,278,,120285,,,,0,10.1016/j.neuroimage.2023.120285,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165707305&doi=10.1016%2fj.neuroimage.2023.120285&partnerID=40&md5=27c7301b73326aea8bce64634b937ee2,"Healthy aging is often associated with speech comprehension difficulties in everyday life situations despite a pure-tone hearing threshold in the normative range. Drawing on this background, we used a multidimensional approach to assess the functional and structural neural correlates underlying age-related temporal speech processing while controlling for pure-tone hearing acuity. Accordingly, we combined structural magnetic resonance imaging and electroencephalography, and collected behavioral data while younger and older adults completed a phonetic categorization and discrimination task with consonant-vowel syllables varying along a voice-onset time continuum. The behavioral results confirmed age-related temporal speech processing singularities which were reflected in a shift of the boundary of the psychometric categorization function, with older adults perceiving more syllable characterized by a short voice-onset time as /ta/ compared to younger adults. Furthermore, despite the absence of any between-group differences in phonetic discrimination abilities, older adults demonstrated longer N100/P200 latencies as well as increased P200 amplitudes while processing the consonant-vowel syllables varying in voice-onset time. Finally, older adults also exhibited a divergent anatomical gray matter infrastructure in bilateral auditory-related and frontal brain regions, as manifested in reduced cortical thickness and surface area. Notably, in the younger adults but not in the older adult cohort, cortical surface area in these two gross anatomical clusters correlated with the categorization of consonant-vowel syllables characterized by a short voice-onset time, suggesting the existence of a critical gray matter threshold that is crucial for consistent mapping of phonetic categories varying along the temporal dimension. Taken together, our results highlight the multifaceted dimensions of age-related temporal speech processing characteristics, and pave the way toward a better understanding of the relationships between hearing, speech and the brain in older age. © 2023 The Authors",37481009,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85165707305
Houben R.; Reinten I.; Dreschler W.A.; Mathijssen R.; Dijkstra T.M.H.,"Houben, Rolph (36150958900); Reinten, Ilja (56096121100); Dreschler, Wouter A. (7003763918); Mathijssen, Roland (57191333316); Dijkstra, Tjeerd M. H. (7005102605)",36150958900; 56096121100; 7003763918; 57191333316; 7005102605,Preferred Strength of Noise Reduction for Normally Hearing and Hearing-Impaired Listeners,2023,Trends in Hearing,27,,,,,,0,10.1177/23312165231211437,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177685972&doi=10.1177%2f23312165231211437&partnerID=40&md5=b00931512ac3151daa35245944d140c9,"Preference for noise reduction (NR) strength differs between individuals. The purpose of this study was (1) to investigate whether hearing loss influences this preference, (2) to find the number of distinct settings required to classify participants in similar groups based on their preference for NR strength, and (3) to estimate the number of paired comparisons needed to predict to which preference group a participant belongs. A paired comparison paradigm was used in which participants listened to pairs of speech-in-noise stimuli processed by NR with 10 different strength settings. Participants indicated their preferred sound sample. The 30 participants were divided into three groups according to hearing status (normal hearing, mild hearing loss, and moderate hearing loss). The results showed that (1) participants with moderate hearing loss preferred stronger NR than participants with normal hearing; (2) cluster analysis based solely on the preference for NR strength showed that the data could be described well by dividing the participants into three preference clusters; (3) the appropriate cluster membership could be found with 15 paired comparisons. We conclude that on average, a higher hearing loss is related to a preference for stronger NR, at least for our NR algorithm and our participants. The results show that it might be possible to use a limited set of pre-set NR strengths that can be chosen clinically. For our NR one might use three settings: no NR, intermediate NR, and strong NR. Paired comparisons might be used to find the optimal one of the three settings. © The Author(s) 2023.",37990543,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85177685972
Perez-Carpena P.; Lopez-Escamez J.A.; Gallego-Martinez Á.,"Perez-Carpena, Patricia (57207581221); Lopez-Escamez, Jose A. (7003654696); Gallego-Martinez, Álvaro (57192083125)",57207581221; 7003654696; 57192083125,A Systematic Review on the Genetic Contribution to Tinnitus,2024,JARO - Journal of the Association for Research in Otolaryngology,25,1,,13,33,20,0,10.1007/s10162-024-00925-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184511544&doi=10.1007%2fs10162-024-00925-6&partnerID=40&md5=867f52a9b74b2539b16ba3604d288bce,"Purpose: To assess the available evidence to support a genetic contribution and define the role of common and rare variants in tinnitus. Methods: After a systematic search and quality assessment, 31 records including 383,063 patients were selected (14 epidemiological studies and 17 genetic association studies). General information on the sample size, age, sex, tinnitus prevalence, severe tinnitus distribution, and sensorineural hearing loss was retrieved. Studies that did not include data on hearing assessment were excluded. Relative frequencies were used for qualitative variables to compare different studies and to obtain average values. Genetic variants and genes were listed and clustered according to their potential role in tinnitus development. Results: The average prevalence of tinnitus estimated from population-based studies was 26.3% for any tinnitus, and 20% of patients with tinnitus reported it as an annoying symptom. One study has reported population-specific differences in the prevalence of tinnitus, the white ancestry being the population with a higher prevalence. Genome-wide association studies have identified and replicated two common variants in the Chinese population (rs2846071; rs4149577) in the intron of TNFRSF1A, associated with noise-induced tinnitus. Moreover, gene burden analyses in sequencing data from Spanish and Swede patients with severe tinnitus have identified and replicated ANK2, AKAP9, and TSC2 genes. Conclusions: The genetic contribution to tinnitus is starting to be revealed and it shows population-specific effects in European and Asian populations. The common allelic variants associated with tinnitus that showed replication are associated with noise-induced tinnitus. Although severe tinnitus has been associated with rare variants with large effect, their role on hearing or hyperacusis has not been established. © The Author(s) 2024.",38334885,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85184511544
Uhm T.W.; Yi S.; Choi S.W.; Oh S.J.; Kong S.K.; Lee I.W.; Lee H.M.,"Uhm, Tae Woong (57205093500); Yi, Seongbaek (8160499000); Choi, Sung Won (55736595700); Oh, Se Joon (55948875500); Kong, Soo Keun (24831909300); Lee, Il Woo (56390540500); Lee, Hyun Min (57192204715)",57205093500; 8160499000; 55736595700; 55948875500; 24831909300; 56390540500; 57192204715,Hearing recovery prediction and prognostic factors of idiopathic sudden sensorineural hearing loss: a retrospective analysis with a deep neural network model,2023,Brazilian Journal of Otorhinolaryngology,89,4,101273,,,,2,10.1016/j.bjorl.2023.04.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161695588&doi=10.1016%2fj.bjorl.2023.04.001&partnerID=40&md5=89637ec44f00bf4eef364e840d9e392c,"Objective: Idiopathic Sudden Sensorineural Hearing Loss (ISSHL) is an otologic emergency, and an early prediction of prognosis may facilitate proper treatment. Therefore, we investigated the prognostic factors for predicting the recovery in patients with ISSHL treated with combined treatment method using machine learning models. Methods: We retrospectively reviewed the medical records of 298 patients with ISSHL at a tertiary medical institution between January 2015 and September 2020. Fifty-two variables were analyzed to predict hearing recovery. Recovery was defined using Siegel's criteria, and the patients were categorized into recovery and non-recovery groups. Recovery was predicted by various machine learning models. In addition, the prognostic factors were analyzed using the difference in the loss function. Results: There were significant differences in variables including age, hypertension, previous hearing loss, ear fullness, duration of hospital admission, initial hearing level of the affected and unaffected ears, and post-treatment hearing level between recovery and non-recovery groups. The deep neural network model showed the highest predictive performance (accuracy, 88.81%; area under the receiver operating characteristic curve, 0.9448). In addition, initial hearing level of affected and non-affected ear, post-treatment (2-weeks) hearing level of affected ear were significant factors for predicting the prognosis. Conclusion: The deep neural network model showed the highest predictive performance for recovery in patients with ISSHL. Some factors with prognostic value were identified. Further studies using a larger patient population are warranted. Level of evidence: Level 4. © 2023 Associação Brasileira de Otorrinolaringologia e Cirurgia Cérvico-Facial",37307713,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85161695588
Emmett S.D.; Platt A.; Gallo J.J.; Labrique A.B.; Wang N.-Y.; Inglis-Jenson M.; Jenson C.D.; Hofstetter P.; Hicks K.L.; Ross A.A.; Egger J.R.; Robler S.K.,"Emmett, Susan D. (36052713800); Platt, Alyssa (23480456100); Gallo, Joseph J. (7101605709); Labrique, Alain B. (6505557971); Wang, Nae-Yuh (7404340658); Inglis-Jenson, Meade (58539791900); Jenson, Cole D. (57200534638); Hofstetter, Philip (57205441590); Hicks, Kelli L. (57200938658); Ross, Alexandra A. (57197754297); Egger, Joseph R. (16439174800); Robler, Samantha Kleindienst (57201022586)",36052713800; 23480456100; 7101605709; 6505557971; 7404340658; 58539791900; 57200534638; 57205441590; 57200938658; 57197754297; 16439174800; 57201022586,Prevalence of Childhood Hearing Loss in Rural Alaska,2023,Ear and Hearing,44,5,,1240,1250,10,0,10.1097/AUD.0000000000001368,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168235831&doi=10.1097%2fAUD.0000000000001368&partnerID=40&md5=515efdd7619b6cadcb694c7efc2c45a2,"Objectives: Childhood hearing loss has well-known lifelong consequences. Certain rural populations are at higher risk for infection-related hearing loss. For Alaska Native children, historical data on hearing loss prevalence suggest a higher burden of infection-related hearing loss, but updated prevalence data are urgently needed in this high-risk population. Design: Hearing data were collected as part of two school-based cluster-randomized trials in 15 communities in rural northwest Alaska over two academic years (2017-2019). All enrolled children from preschool to 12th grade were eligible. Pure-tone thresholds were obtained using standard audiometry and conditioned play when indicated. The analysis included the first available audiometric assessment for each child (n = 1634 participants, 3 to 21 years), except for the high-frequency analysis, which was limited to year 2 when higher frequencies were collected. Multiple imputation was used to quantify the prevalence of hearing loss in younger children, where missing data were more frequent due to the need for behavioral responses. Hearing loss in either ear was evaluated using both the former World Health Organization (WHO) definition (pure-tone average [PTA] > 25 dB) and the new WHO definition (PTA ≥ 20 dB), which was published after the study. Analyses with the new definition were limited to children 7 years and older due to incomplete data obtained on younger children at lower thresholds. Results: The overall prevalence of hearing loss (PTA > 25 dB; 0.5, 1, 2, 4 kHz) was 10.5% (95% confidence interval [CI], 8.9 to 12.1). Hearing loss was predominately mild (PTA >25 to 40 dB; 8.9%, 95% CI, 7.4 to 10.5). The prevalence of unilateral hearing loss was 7.7% (95% CI, 6.3 to 9.0). Conductive hearing loss (air-bone gap of ≥ 10 dB) was the most common hearing loss type (9.1%, 95% CI, 7.6 to 10.7). Stratified by age, hearing loss (PTA >25 dB) was more common in children 3 to 6 years (14.9%, 95% CI, 11.4 to 18.5) compared to children 7 years and older (8.7%, 95% CI, 7.1 to 10.4). In children 7 years and older, the new WHO definition increased the prevalence of hearing loss to 23.4% (95% CI, 21.0 to 25.8) compared to the former definition (8.7%, 95% CI, 7.1 to 10.4). Middle ear disease prevalence was 17.6% (95% CI, 15.7 to 19.4) and was higher in younger children (23.6%, 95% CI, 19.7 to 27.6) compared to older children (15.2%, 95% CI, 13.2 to 17.3). High-frequency hearing loss (4, 6, 8kHz) was present in 20.5% (95% CI, 18.4 to 22.7 [PTA >25 dB]) of all children and 22.8% (95% CI, 20.3 to 25.3 [PTA >25 dB]) and 29.7% (95% CI, 27.0 to 32.4 [PTA ≥ 20 dB]) of children 7 years and older (limited to year 2). Conclusions: This analysis represents the first prevalence study on childhood hearing loss in Alaska in over 60 years and is the largest cohort with hearing data ever collected in rural Alaska. Our results highlight that hearing loss continues to be common in rural Alaska Native children, with middle ear disease more prevalent in younger children and high-frequency hearing loss more prevalent with increasing age. Prevention efforts may benefit from managing hearing loss type by age. Lastly, continued research is needed on the impact of the new WHO definition of hearing loss on field studies.  © Copyright 2023 The Authors.",37287104,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85168235831
Hong J.-P.; Lee J.-Y.; Kim M.-B.,"Hong, Joon-Pyo (57659505200); Lee, Jung-Yup (57205641916); Kim, Min-Beom (21834371200)",57659505200; 57205641916; 21834371200,A Comparative Study Using Vestibular Mapping in Sudden Sensorineural Hearing Loss With and Without Vertigo,2023,Otolaryngology - Head and Neck Surgery (United States),169,6,,1573,1581,8,1,10.1002/ohn.422,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164534321&doi=10.1002%2fohn.422&partnerID=40&md5=1436e8c279e4fa45c8437e1bf164cd5a,"Objective: To investigate the impairment patterns in peripheral vestibular organs in sudden sensorineural hearing loss (SSNHL) with and without vertigo. Study Design: Retrospective study. Setting: Single tertiary medical center. Methods: Data from 165 SSNHL patients in a tertiary referral center from January 2017 to December 2022 were retrospectively analyzed. All patients underwent a video head impulse test, vestibular evoked myogenic potential test, and pure-tone audiometry. Hierarchical cluster analysis was performed to investigate vestibular impairment patterns. The prognosis of the hearing was determined using American Academy of Otolaryngology–Head and Neck Surgery recommendations. Results: After excluding patients with vestibular schwannoma and Meniere's disease, 152 patients were included in this study. A total of 73 of 152 patients were categorized as SSNHL with vertigo (SSNHL_V) and showed an independent merge of the posterior semicircular canal (PSCC) in cluster analysis. A total of 79 of 152 patients were categorized as SSNHL without vertigo (SSNHL_N) and showed an independent merge of saccule in cluster analysis. The PSCC (56.2%) and saccule (20.3%) were the most frequently impaired vestibular organs in SSNHL_V and SSNHL_N, respectively. In terms of prognosis, 106 of 152 patients had partial/no recovery and showed an independent merge of the PSCC in cluster analysis. A total of 46 of 152 patients had a complete recovery and showed an independent merge of the saccule in cluster analysis. Conclusion: A tendency of isolated PSCC dysfunction was seen in SSNHL_V and partial/no recovery. A tendency of isolated saccular dysfunction was seen in SSNHL_N and complete recovery. Different treatments might be needed in SSNHL depending on the presence of vertigo. © 2023 American Academy of Otolaryngology–Head and Neck Surgery Foundation.",37418229,Article,Final,,Scopus,2-s2.0-85164534321
Islam T.; Ahmed F.; Ahmed N.; Naziullah S.; Islam M.N.; Rashid M.,"Islam, Thamina (58753393200); Ahmed, Firoz (58690858200); Ahmed, Nayem (57213257378); Naziullah, Shekh (57235392300); Islam, Md Nahidul (57221115971); Rashid, Mamunur (57217706501)",58753393200; 58690858200; 57213257378; 57235392300; 57221115971; 57217706501,Classification of EEG-Based Auditory Evoked Potentials Using Entropy-Based Features and Machine Learning Techniques,2023,"2023 International Conference on Information and Communication Technology for Sustainable Development, ICICT4SD 2023 - Proceedings",,,,124,128,4,0,10.1109/ICICT4SD59951.2023.10303426,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179138618&doi=10.1109%2fICICT4SD59951.2023.10303426&partnerID=40&md5=7d705cfc124cbb8c178bcf0f7ddcca6c,"Hearing loss is a prevalent impairment that disrupts interactions with others and individuals' learning abilities. Immediate and accurate diagnosis of hearing loss using Electroencephalogram (EEG) signals, particularly Auditory Evoked Potentials (AEP), is considered the most effective approach to address this issue. The AEP signals, generated in the cerebral cortex in response to auditory stimuli, serve as the most reliable method for diagnosing deafness. This study introduces a novel approach for detecting hearing ability through the classification of EEG-AEP signals. The current experiment makes use of a publicly available dataset that contains AEP responses from 16 people who responded to auditory stimuli on either the left or right side. Sample Entropy is employed to extract the feature, capturing the complex temporal dynamics of the EEG signals. Four popular machine learning-based classifiers, namely Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), and Logistic Regression (LR), are utilized for classification purposes. The results indicate that SVM achieves the highest classification accuracy of 99.37% with subject-4 and the average accuracy of 90.74% is achieved with all subjects. This finding shows the effectiveness of Sample Entropy as a feature extraction technique for characterizing AEPs and highlights the potential of SVM as a robust classifier for the accurate identification of auditory stimuli localization. The accuracy achieved in this study indicates a promising direction for the development of reliable and non-invasive methods for hearing-related diagnoses.  © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85179138618
Badh G.; Knowles T.,"Badh, Gursharan (57725644800); Knowles, Thea (57193128334)",57725644800; 57193128334,Acoustic and perceptual impact of face masks on speech: A scoping review,2023,PLoS ONE,18,08-Aug,e0285009,,,,1,10.1371/journal.pone.0285009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168740649&doi=10.1371%2fjournal.pone.0285009&partnerID=40&md5=3c67ecaf3ef3fdf1a672b9f097a47cf6,"During the COVID-19 pandemic, personal protective equipment such as facial masks and coverings were mandated all over the globe to protect against the virus. Although the primary aim of wearing face masks is to protect against viral transmission, they pose a potential burden on communication. The purpose of this scoping review was to identify the state of the evidence of the effect of facial coverings on acoustic and perceptual speech outcomes. The scoping review followed the framework created by Arksey & O'Malley (2005) and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews guidelines (PRISMA-ScR; Tricco et al., 2018). The search was completed in May 2021 across the following databases: PubMed, EMBASE, PsycINFO, Web of Science, and Google Scholar. A total of 3,846 records were retrieved from the database search. Following the removal of duplicates, 3,479 remained for the title/abstract screen and 149 were selected for the full-text review. Of these, 52 were included in the final review and relevant data were extracted. The 52 articles included in the final review consisted of; 11 studied perceptual outcomes only, 16 studied acoustic outcomes only, and 14 studied both perceptual and acoustic outcomes. 13 of these investigated acoustic features that could be used for mask classification. Although the findings varied from article to article, many trends stood out. Many articles revealed that face masks act as a low pass filter, dampening sounds at higher frequencies; however, the frequency range and the degree of attenuation varied based on face mask type. All but five articles that reported on perceptual outcomes showed a common trend that wearing a face mask was associated with poorer speech intelligibility. The findings of the scoping review provided evidence that facial coverings negatively impacted speech intelligibility, which is likely due to a combination of auditory and visual cue degradation. Due to the continued prevalence of mask use, how facial coverings affect a wider variety of speaker populations, such as those with communication impairments, and strategies for overcoming communication challenges should be explored.  © 2023 Badh, Knowles. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",37624795,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85168740649
Taylor K.; Sheikh W.,"Taylor, Kyra (57796504600); Sheikh, Waseem (22836360100)",57796504600; 22836360100,Automated hearing impairment diagnosis using machine-learning: An open-source software development undergraduate research project,2024,Computer Applications in Engineering Education,,,,,,,0,10.1002/cae.22724,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186599282&doi=10.1002%2fcae.22724&partnerID=40&md5=3623a19b867ddbccc3935a6b798e430f,"Approximately 700 million people will have disabling hearing loss by 2050. Underdeveloped and developing countries, which encompass a considerable proportion of people with disabling hearing impairment, have a sparse number of audiologists and otolaryngologists. The lack of specialists leaves most hearing impairments undiagnosed for a long time, resulting in negative societal and economic impacts. In this article, we propose an automated hearing impairment diagnosis software—based on machine learning—to support audiologists and otolaryngologists in accurately and efficiently diagnosing and classifying hearing loss. We present the design, implementation, and performance analysis of an open-source automated hearing impairment diagnosis software, which consists of two modules: a hearing test data-generation module and a machine-learning model. The data-generation module produces a diverse and exhaustive data set for training and evaluating the machine-learning model. By employing multiclass and ultilabel classification techniques to learn from the hearing test data, the model can swiftly predict the type, degree, and configuration of hearing loss with high reliability. Our proposed machine-learning model demonstrates promising results with a prediction time of 634 ms, a log-loss reduction rate of 0.9848 and accuracy, precision, recall, and f1-score of 1.0000—showing the model's applicability to assist audiologists and otolaryngologists in rapidly and accurately classifying the type, degree, and configuration of hearing loss. In addition to the technical contributions, this article also highlights the importance of involving undergraduate students in open-source software development projects which have a direct impact on improving the quality of human life. © 2024 Wiley Periodicals LLC.",,Article,Article in press,,Scopus,2-s2.0-85186599282
Leer P.; Bramslow L.; Jensen J.; Jensen J.; Tan Z.-H.; Ostergaard J.,"Leer, Peter (58957239600); Bramslow, Lars (6507661959); Jensen, Jesper (57191481131); Jensen, Jesper (57199943098); Tan, Zheng-Hua (7201599686); Ostergaard, Jan (24725256500)",58957239600; 6507661959; 57191481131; 57199943098; 7201599686; 24725256500,How to Train Your Ears: Auditory-Model Emulation for Large-Dynamic-Range Inputs and Mild-to-Severe Hearing Losses,2024,IEEE/ACM Transactions on Audio Speech and Language Processing,32,,,2006,2020,14,0,10.1109/TASLP.2024.3378099,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188662246&doi=10.1109%2fTASLP.2024.3378099&partnerID=40&md5=a3b2b37e86c4b486bf2ef9203ca0f555,"Advanced auditory models are useful in designing signal-processing algorithms for hearing-loss compensation or speech enhancement. Such auditory models provide rich and detailed descriptions of the auditory pathway, and might allow for individualization of signal-processing strategies, based on physiological measurements. However, these auditory models are often computationally demanding, requiring significant time to compute. To address this issue, previous studies have explored the use of deep neural networks to emulate auditory models and reduce inference time. While these deep neural networks offer impressive efficiency gains in terms of computational time, they may suffer from uneven emulation performance as a function of auditory-model frequency-channels and input sound pressure level, making them unsuitable for many tasks. In this study, we demonstrate that the conventional machine-learning optimization objective used in existing state-of-the-art methods is the primary source of this limitation. Specifically, the optimization objective fails to account for the frequency- and level-dependencies of the auditory model, caused by a large input dynamic range and different types of hearing losses emulated by the auditory model. To overcome this limitation, we propose a new optimization objective that explicitly embeds the frequency- and level-dependencies of the auditory model. Our results show that this new optimization objective significantly improves the emulation performance of deep neural networks across relevant input sound levels and auditory-model frequency channels, without increasing the computational load during inference. Addressing these limitations is essential for advancing the application of auditory models in signal-processing tasks, ensuring their efficacy in diverse scenarios.  © 2014 IEEE.",,Article,Final,,Scopus,2-s2.0-85188662246
Ahmed M.A.O.; Satar Y.A.; Darwish E.M.; Zanaty E.A.,"Ahmed, Muhammad Atta Othman (56727202900); Satar, Yasser Abdel (58813136700); Darwish, Eed M. (55953657500); Zanaty, Elnomery A. (24479945400)",56727202900; 58813136700; 55953657500; 24479945400,Synergistic integration of Multi-View Brain Networks and advanced machine learning techniques for auditory disorders diagnostics,2024,Brain Informatics,11,1,3,,,,0,10.1186/s40708-023-00214-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182404665&doi=10.1186%2fs40708-023-00214-7&partnerID=40&md5=b9d1c02b2fd32f555d33e70cfcab95a9,"In the field of audiology, achieving accurate discrimination of auditory impairments remains a formidable challenge. Conditions such as deafness and tinnitus exert a substantial impact on patients’ overall quality of life, emphasizing the urgent need for precise and efficient classification methods. This study introduces an innovative approach, utilizing Multi-View Brain Network data acquired from three distinct cohorts: 51 deaf patients, 54 with tinnitus, and 42 normal controls. Electroencephalogram (EEG) recording data were meticulously collected, focusing on 70 electrodes attached to an end-to-end key with 10 regions of interest (ROI). This data is synergistically integrated with machine learning algorithms. To tackle the inherently high-dimensional nature of brain connectivity data, principal component analysis (PCA) is employed for feature reduction, enhancing interpretability. The proposed approach undergoes evaluation using ensemble learning techniques, including Random Forest, Extra Trees, Gradient Boosting, and CatBoost. The performance of the proposed models is scrutinized across a comprehensive set of metrics, encompassing cross-validation accuracy (CVA), precision, recall, F1-score, Kappa, and Matthews correlation coefficient (MCC). The proposed models demonstrate statistical significance and effectively diagnose auditory disorders, contributing to early detection and personalized treatment, thereby enhancing patient outcomes and quality of life. Notably, they exhibit reliability and robustness, characterized by high Kappa and MCC values. This research represents a significant advancement in the intersection of audiology, neuroimaging, and machine learning, with transformative implications for clinical practice and care. © 2023, The Author(s).",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85182404665
Madahana M.C.I.; Ekoru J.E.D.; Sebothoma B.; Khoza-Shangase K.,"Madahana, Milka C. I. (57200249264); Ekoru, John E. D. (54419843400); Sebothoma, Ben (57194068315); Khoza-Shangase, Katijah (36005211600)",57200249264; 54419843400; 57194068315; 36005211600,Development of an artificial intelligence based occupational noise induced hearing loss early warning system for mine workers,2024,Frontiers in Neuroscience,18,,1321357,,,,0,10.3389/fnins.2024.1321357,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189209485&doi=10.3389%2ffnins.2024.1321357&partnerID=40&md5=a8bf79503b2c26e9fdc7c3526c4ede09,"Introduction: Occupational Noise Induced Hearing Loss (ONIHL) is one of the most prevalent conditions among mine workers globally. This reality is due to mine workers being exposed to noise produced by heavy machinery, rock drilling, blasting, and so on. This condition can be compounded by the fact that mine workers often work in confined workspaces for extended periods of time, where little to no attenuation of noise occurs. The objective of this research work is to present a preliminary study of the development of a hearing loss, early monitoring system for mine workers. Methodology: The system consists of a smart watch and smart hearing muff equipped with sound sensors which collect noise intensity levels and the frequency of exposure. The collected information is transferred to a database where machine learning algorithms namely the logistic regression, support vector machines, decision tree and Random Forest Classifier are used to classify and cluster it into levels of priority. Feedback is then sent from the database to a mine worker smart watch based on priority level. In cases where the priority level is extreme, indicating high levels of noise, the smart watch vibrates to alert the miner. The developed system was tested in a mock mine environment consisting of a 67 metres tunnel located in the basement of a building whose roof top represents the “surface” of a mine. The mock-mine shape, size of the tunnel, steel-support infrastructure, and ventilation system are analogous to deep hard-rock mine. The wireless channel propagation of the mock-mine is statistically characterized in 2.4–2.5 GHz frequency band. Actual underground mine material was used to build the mock mine to ensure it mimics a real mine as close as possible. The system was tested by 50 participants both male and female ranging from ages of 18 to 60 years. Results and discussion: Preliminary results of the system show decision tree had the highest accuracy compared to the other algorithms used. It has an average testing accuracy of 91.25% and average training accuracy of 99.79%. The system also showed a good response level in terms of detection of noise input levels of exposure, transmission of the information to the data base and communication of recommendations to the miner. The developed system is still undergoing further refinements and testing prior to being tested in an actual mine. Copyright © 2024 Madahana, Ekoru, Sebothoma and Khoza-Shangase.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85189209485
Divekar S.N.; Nigam M.K.,"Divekar, Sudhir Narsing (58532101100); Nigam, Manoj Kumar (55580281600)",58532101100; 55580281600,Machine Learning Based Dynamic Band Selection for Splitting Auditory Signals to Reduce Inner Ear Hearing Losses,2023,International Journal on Recent and Innovation Trends in Computing and Communication,11,6,,71,79,8,0,10.17762/ijritcc.v11i6.7059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167673345&doi=10.17762%2fijritcc.v11i6.7059&partnerID=40&md5=fa99dc67bddd47483c3b21150acb40de,"Quality of hearing has been severely impacted due to signal losses occurs in the human inner ear explicitly in the region of cochlea. Loudness recruitment, degraded frequency selectivity and auditory masking are the major outward effects of inner ear hearing losses. Splitting auditory signals into frequency bands and presenting dichotically to both ears became a comprehensive solution to reduce inner ear hearing losses. However, these methods divide input signal into the fix number of frequency bands, this limits their applicability where signals have large variations in their spectral characteristics. To address this challenge, we have proposed machine learning based intelligent band selection algorithm to split auditory signals dynamically. Proposed algorithm analyze input speech signal based on spectral characteristics to determine the optimum number of bands required to effectively present major acoustic cues of the signal. Further, dynamic splitting algorithm efficiently divides signal for dichotic presentation. Proposed method has been examined on large number of subjects from different age groups and gender having cochlear hearing impairment. Qualitative and quantitative assessment shown significant improvement in the recognition score with substantial reduction in the response time. © 2023 International Journal on Recent and Innovation Trends in Computing and Communication. All rights reserved.",,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85167673345
Niryukta M.; Snekhalatha U.; Rajalakshmi T.,"Niryukta, M. (58139984100); Snekhalatha, U. (57803525200); Rajalakshmi, T. (58632986600)",58139984100; 57803525200; 58632986600,Automated audiometer for home based health care based on mobile app,2023,AIP Conference Proceedings,2603,,30011,,,,0,10.1063/5.0126375,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159950202&doi=10.1063%2f5.0126375&partnerID=40&md5=943e929c9ba14ec327449f42b5732cd2,"Hearing deficiency is one of the most important issues that people experience these days. This hearing loss is assessed using an audiometer. An audiometer is an instrument that tests the efficacy or hearing capacity of the ear. In this proposed study, an Android app is created along with a bone conduction device that functions as an audiometer for bone conduction. The aim and objectives of the proposed study are as follows: i) to create an automatic bone conduction system for self-diagnosing a patient's hearing ability; ii) to use pure tone audiometry to assess auditory thresholds at various frequencies and classify the normal and hearing loss patients with different machine learning classifiers. The right and left ear features of normal and hearing loss patients were given as the input to the SVM, k-NN and Naive Bayes classifier. The Naive bayes classifier produced 100% accuracy and outperformed well compared to the SVM (98%) and k-NN classifier (98%). The developed mobile app would be used to conduct the self-audiometry test at home and reduce the expense of audiometry tests.  © 2023 Author(s).",,Conference paper,Final,,Scopus,2-s2.0-85159950202
Zha B.; Zhang Y.; Shi F.; Cheng L.; Rong Z.; Yu L.; Liu W.; Xue Q.; Ye M.; Yang J.; Qiu B.; Yang J.,"Zha, Bixiang (57215056393); Zhang, Yating (57265631400); Shi, Feifei (58973543200); Cheng, Ling (57275150500); Rong, Zhihao (58019700600); Yu, Leiyu (58974032400); Liu, Wanting (58973908000); Xue, Qiuju (57189579988); Ye, Min (57218703472); Yang, Jinying (57222628064); Qiu, Bensheng (7102407325); Yang, Jun (57029468700)",57215056393; 57265631400; 58973543200; 57275150500; 58019700600; 58974032400; 58973908000; 57189579988; 57218703472; 57222628064; 7102407325; 57029468700,Modulations of resting-static functional connectivity on insular by electroacupuncture in subjective tinnitus,2024,Frontiers in Neurology ,15,,1373390,,,,0,10.3389/fneur.2024.1373390,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189620759&doi=10.3389%2ffneur.2024.1373390&partnerID=40&md5=205007e6da46db3e318008bc9210a089,"Objective: To explore the modulations of electroacupuncture in subjective tinnitus (ST) by comparing the difference of functional connectivity (FC) in ST patients and healthy volunteers between the insular (INS) and the whole brain region. Methods: A total of 34 ST patients were selected into electroacupuncture group (EG) and 34 age- and sex-matched normal subjects were recruited into control group (CG). The EG received acupuncture at SI19 (Tinggong), GB11 (Touqiaoyin), TE17 (Yifeng), GV20 (Baihui), GV15 (Yamen), GV14 (Dazhui), SJ13 (Zhongzhu), among which the points of SI19 and GB11 were connected to the electroacupuncture instrument with the density wave of 2/50 Hz, and 3 treatments per week for 10 sessions in total. The severity of tinnitus was evaluated by Tinnitus Handicap Inventory (THI), the hearing status was recorded using pure tone audiometry, and resting-state functional magnetic resonance imaging (rs-fMRI) was performed on the brain before and after treatment, the CG received no intervention yet only rs-fMRI data were collected. Results: With the electroacupuncture treatment, the total THI score, average air conduction threshold of patients of EG were significantly lower than before (p < 0.01), and the total effective rate was 88.24%. Compared with CG, FC of ST patients between INS and left superior temporal gyrus and right hippocampal significantly decreased before treatment, while FC of ST patients between INS and right superior frontal gyrus, left middle frontal gyrus and right anterior cuneus significantly decreased after treatment (voxel p < 0.001, cluster p < 0.05, corrected with GRF). FC of ST patients between the INS and right middle frontal gyrus, left superior frontal gyrus and right paracentral lobule showed a significant decrease after treatment (voxel p < 0.001, cluster p < 0.05, corrected with GRF). In addition, THI score in EG was negatively correlated with the reduction of FC value in INS-left superior frontal gyrus before treatment (r = −0.41, p = 0.017). Therefore, this study suggests that abnormal FC of INS may be one of the significant central mechanisms of ST patients and can be modulated by electroacupuncture. Discussion: Electroacupuncture treatment can effectively reduce or eliminate tinnitus symptoms in ST patients and improve the hearing by decreasing FC between the INS and the frontal and temporal brain regions. Copyright © 2024 Zha, Zhang, Shi, Cheng, Rong, Yu, Liu, Xue, Ye, Yang, Qiu and Yang.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85189620759
Fawcett T.J.; Longenecker R.J.; Brunelle D.L.; Berger J.I.; Wallace M.N.; Galazyuk A.V.; Rosen M.J.; Salvi R.J.; Walton J.P.,"Fawcett, Timothy J. (7006446451); Longenecker, Ryan J. (53983239700); Brunelle, Dimitri L. (58028649700); Berger, Joel I. (55567500800); Wallace, Mark N. (7401942561); Galazyuk, Alex V. (6602931667); Rosen, Merri J. (7401478107); Salvi, Richard J. (7005412656); Walton, Joseph P. (7401785051)",7006446451; 53983239700; 58028649700; 55567500800; 7401942561; 6602931667; 7401478107; 7005412656; 7401785051,Universal automated classification of the acoustic startle reflex using machine learning,2023,Hearing Research,428,,108667,,,,3,10.1016/j.heares.2022.108667,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144630371&doi=10.1016%2fj.heares.2022.108667&partnerID=40&md5=b505c9c71b1de73e33747571cdd1e0c1,"The startle reflex (SR), a robust, motor response elicited by an intense auditory, visual, or somatosensory stimulus has been widely used as a tool to assess psychophysiology in humans and animals for almost a century in diverse fields such as schizophrenia, bipolar disorder, hearing loss, and tinnitus. Previously, SR waveforms have been ignored, or assessed with basic statistical techniques and/or simple template matching paradigms. This has led to considerable variability in SR studies from different laboratories, and species. In an effort to standardize SR assessment methods, we developed a machine learning algorithm and workflow to automatically classify SR waveforms in virtually any animal model including mice, rats, guinea pigs, and gerbils obtained with various paradigms and modalities from several laboratories. The universal features common to SR waveforms of various species and paradigms are examined and discussed in the context of each animal model. The procedure describes common results using the SR across species and how to fully implement the open-source R implementation. Since SR is widely used to investigate toxicological or pharmaceutical efficacy, a detailed and universal SR waveform classification protocol should be developed to aid in standardizing SR assessment procedures across different laboratories and species. This machine learning-based method will improve data reliability and translatability between labs that use the startle reflex paradigm. © 2022",36566642,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85144630371
Hicks K.L.; Robler S.K.; Simmons R.A.; Ross A.; Egger J.R.; Emmett S.D.,"Hicks, Kelli L. (57200938658); Robler, Samantha Kleindienst (57201022586); Simmons, Ryan A. (57193626025); Ross, Alexandra (57197754297); Egger, Joseph R. (16439174800); Emmett, Susan D. (36052713800)",57200938658; 57201022586; 57193626025; 57197754297; 16439174800; 36052713800,Hearing-related quality of life in children and adolescents in rural Alaska,2023,Laryngoscope Investigative Otolaryngology,8,1,,269,278,9,0,10.1002/lio2.973,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143429374&doi=10.1002%2flio2.973&partnerID=40&md5=d9c87a97e5f04da94c9b516300942439,"Objective: This study evaluated the Hearing Environments and Reflection on Quality of Life (HEAR-QL) questionnaire in rural Alaska, including an addendum crafted through community feedback to reflect the local context. The objectives were to assess whether HEAR-QL score was inversely correlated with hearing loss and middle ear disease in an Alaska Native population. Methods: The HEAR-QL questionnaires for children and adolescents were administered as part of a cluster randomized trial in rural Alaska from 2017 to 2019. Enrolled students completed an audiometric evaluation and HEAR-QL questionnaire on the same day. A cross-sectional evaluation of questionnaire data was utilized. Results: A total of 733 children (ages 7–12 years) and 440 adolescents (ages ≥13 years) completed the questionnaire. Median HEAR-QL scores were similar among children with and without hearing loss (Kruskal–Wallis, p =.39); however, adolescent HEAR-QL scores significantly decreased with increasing hearing loss (p <.001). Median HEAR-QL scores were significantly lower in both children (p =.02) and adolescents (p <.001) with middle ear disease compared with those without. In both children and adolescents, the addendum scores were strongly correlated with total HEAR-QL score (ρSpearman = 0.72 and 0.69, respectively). Conclusions: The expected negative association between hearing loss and HEAR-QL score was observed in adolescents. However, there was significant variability that could not be explained by hearing loss, and further investigation is warranted. The expected negative association was not observed in children. HEAR-QL scores were associated with middle ear disease in both children and adolescents, making it potentially valuable in populations where the prevalence of ear infections is high. Level of Evidence: Level 2. Clinicaltrials.gov registration numbers: NCT03309553. © 2022 The Authors. Laryngoscope Investigative Otolaryngology published by Wiley Periodicals LLC on behalf of The Triological Society.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85143429374
Alzaher M.; Strelnikov K.; Marx M.; Barone P.,"Alzaher, Mariam (57221110243); Strelnikov, Kuzma (55967530400); Marx, Mathieu (16310043700); Barone, Pascal (7102266372)",57221110243; 55967530400; 16310043700; 7102266372,Brain plasticity and auditory spatial adaptation in patients with unilateral hearing loss,2023,Cerebral Cortex,33,11,,7221,7236,15,0,10.1093/cercor/bhad033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160965255&doi=10.1093%2fcercor%2fbhad033&partnerID=40&md5=6bdefe1a22949a05005f2ff48a9c03c6,"The ability to localize sounds in patients with Unilateral Hearing Loss (UHL) is usually disrupted due to alteration in the integration of binaural cues. Nonetheless, some patients are able to compensate deficit using adaptive strategies. In this study, we explored the neural correlates underlying this adaptation. Twenty-one patients with UHL were separated into 3 groups using cluster analysis based on their binaural performance. The resulting clusters were referred to as better, moderate, and poorer performers cluster (BPC, MPC, and PPC). We measured the mismatch negativity (MMN) elicited by deviant sounds located at 10◦, 20◦, and 100◦ from a standard positioned at 50◦ ipsilateral to the deaf ear. The BPC exhibited significant MMN for all 3 deviants, similar to normal hearing (NH) subjects. In contrast, there was no significant MMN for 10◦ and 20◦ deviants for the PPC and for NH when one ear was plugged and muffed. Scalp distribution was maximal over central regions in BPC, while PPC showed more frontal MMN distribution. Thus, the BPC exhibited a contralateral activation pattern, similar to NH, while the PPC exhibited more symmetrical hemispheric activation. MMN can be used as a neural marker to reflect spatial adaptation in patients with UHL. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.",36806394,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85160965255
Zhang B.; Duan H.; Kavaler J.; Wei L.; Eberl D.F.; Lai E.C.,"Zhang, Binglong (57217861511); Duan, Hong (36719465900); Kavaler, Joshua (6603117265); Wei, Lu (55068191200); Eberl, Daniel F. (7004945066); Lai, Eric C. (55156015600)",57217861511; 36719465900; 6603117265; 55068191200; 7004945066; 55156015600,A nonneural miRNA cluster mediates hearing via repression of two neural targets,2023,Genes and Development,37,21-24,,1041,1051,10,0,10.1101/gad.351052.123,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181176668&doi=10.1101%2fgad.351052.123&partnerID=40&md5=bedb9f48c2ffb334394b64a73be7b573,"We show here that mir-279/996 are absolutely essential for development and function of Johnston’s organ (JO), the primary proprioceptive and auditory organ in Drosophila. Their deletion results in highly aberrant cell fate determination, including loss of scolopale cells and ectopic neurons, and mutants are electrophysiologically deaf. In vivo activity sensors and mosaic analyses indicate that these seed-related miRNAs function autonomously to suppress neural fate in nonneuronal cells. Finally, genetic interactions pinpoint two neural targets (elav and insensible) that underlie miRNA mutant JO phenotypes. This work uncovers how critical post-transcriptional regulation of specific miRNA targets governs cell specification and function of the auditory system. © 2023 Zhang et al. This article is distributed exclusively by Cold Spring Harbor Laboratory Press for the first six months after the full-issue publication date (see http://genesdev.cshlp.org/site/misc/terms.xhtml). After six months, it is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), as described at http://creativecommons.org/licenses/by-nc/4.0/.",38110249,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85181176668
Sodero A.O.; Castagna V.C.; Elorza S.D.; Gonzalez-Rodulfo S.M.; Paulazo M.A.; Ballestero J.A.; Martin M.G.; Gomez-Casati M.E.,"Sodero, Alejandro O. (31067492900); Castagna, Valeria C. (57203546489); Elorza, Setiembre D. (57608881800); Gonzalez-Rodulfo, Sara M. (58548481900); Paulazo, María A. (51461813700); Ballestero, Jimena A. (8668001200); Martin, Mauricio G. (55482096800); Gomez-Casati, María Eugenia (6507097087)",31067492900; 57203546489; 57608881800; 58548481900; 51461813700; 8668001200; 55482096800; 6507097087,"Phytosterols reverse antiretroviral-induced hearing loss, with potential implications for cochlear aging",2023,PLoS Biology,21,08-Aug,e3002257,,,,1,10.1371/journal.pbio.3002257,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168748358&doi=10.1371%2fjournal.pbio.3002257&partnerID=40&md5=886ca7f3c54e2f97b812f68e60f61a95,"AU Cholesterol: Pleaseconfirmthatallheadinglevelsarerepresentedcorrectly contributes to neuronal membrane integrity, supports : membrane protein clustering and function, and facilitates proper signal transduction. Extensive evidence has shown that cholesterol imbalances in the central nervous system occur in aging and in the development of neurodegenerative diseases. In this work, we characterize cholesterol homeostasis in the inner ear of young and aged mice as a new unexplored possibility for the prevention and treatment of hearing loss. Our results show that cholesterol levels in the inner ear are reduced during aging, an effect that is associated with an increased expression of the cholesterol 24-hydroxylase (CYP46A1), the main enzyme responsible for cholesterol turnover in the brain. In addition, we show that pharmacological activation of CYP46A1 with the antiretroviral drug efavirenz reduces the cholesterol content in outer hair cells (OHCs), leading to a decrease in prestin immunolabeling and resulting in an increase in the distortion product otoacoustic emissions (DPOAEs) thresholds. Moreover, dietary supplementation with phytosterols, plant sterols with structure and function similar to cholesterol, was able to rescue the effect of efavirenz administration on the auditory function. Altogether, our findings point towards the importance of cholesterol homeostasis in the inner ear as an innovative therapeutic strategy in preventing and/or delaying hearing loss. © 2023 Sodero et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",37619212,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85168748358
Wathour J.; Govaerts P.J.; Lacroix E.; Naïma D.,"Wathour, Justine (57041226200); Govaerts, Paul J. (7005148990); Lacroix, Emilie (56165282500); Naïma, Deggouj (58104152100)",57041226200; 7005148990; 56165282500; 58104152100,Effect of a CI Programming Fitting Tool with Artificial Intelligence in Experienced Cochlear Implant Patients,2023,Otology and Neurotology,44,3,,209,215,6,2,10.1097/MAO.0000000000003810,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148112871&doi=10.1097%2fMAO.0000000000003810&partnerID=40&md5=6e9e3a9a7d6f6eced65fc8edb5da58e0,"Objective Cochlear implants (CIs) are the treatment of choice for patients with severe to profound hearing loss. The hearing results, however, considerably vary across patients. This may partly be due to variability in the CI fitting. We investigated the effect of FOX, a software tool to program CIs using artificial intelligence (AI), on hearing outcomes. Methods Forty-seven experienced CI patients who came to our tertiary CI center for their annual follow-up between 2017 and 2020 were recruited for this study. They received a new CI map created by the AI software tool. CI parameters and auditory outcomes obtained with this new map were compared with those of the initial manual map after 15 days of take-home experience. Within-patient differences were assessed. At the end of the study, the patients were offered a choice to continue using the AI map or to revert to their old manual map. Results Several auditory outcomes improved with the AI map, namely, pure tone audiometric threshold at 6,000 Hz (median improvement 10 dB, range = -20 to 50 dB, Z = -2.608, p = 0.008), phonemic discrimination scores (median improvement 10%, range = 0% to 30%, Z = -4.061, p = 0.001), and soft-intensity (median improvement of 10%, range = -20% to 90%, Z = -4.412, p < 0.001) to normal-intensity (median improvement of 10%, range = -30% to 60%, Z = -3.35, p < 0.001) speech audiometric scores. Conclusion The AI-assisted CI mapping model as a potential assistive tool may improve audiological outcomes for experienced CI patients, including high-frequency pure tone audiometry and audiometric speech scores at low and normal presentation levels. Clinical trial registration: NCT03700268  © Wolters Kluwer Health, Inc. All rights reserved.",36728126,Article,Final,,Scopus,2-s2.0-85148112871
Kim J.H.; Bahng J.,"Kim, Jong Ha (58317620400); Bahng, Junghwa (15025830000)",58317620400; 15025830000,Research on Effective Methodology for Hearing Impairment Rehabilitation; Based on a Diary Study for Elderly Online-Auditory Training,2023,Audiology and Speech Research,19,4,,287,293,6,0,10.21848/asr.230126,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177775133&doi=10.21848%2fasr.230126&partnerID=40&md5=935e29b2b43f35a42ba9ce6d5ec0b3e6,"This study analyzes the utilization of online-based auditory training content by individuals aged 70 and above, who are the primary users of auditory training programs. Additionally, we explore effective methodologies for online-based auditory training programs by investigating the impact of differences in auditory training content on training outcomes. Two elderly individuals, one female and one male, wearing hearing aids, participated in this study. We assessed speech perception in noise at 5 dB SNR before and after auditory training. They completed a listening effort questionnaire and attended a total of 20 auditory training sessions over 7 weeks. During the training period, they maintained a “training diary” three times a week. We conducted interviews with the two audiologists who provided auditory training to objectively analyze the diary survey results. Both hearing aid users demonstrated improved speech perception in noise scores and reduced listening effort. The analysis of auditory training experiences categorized them into three types: ‘emotion-stimulating,’ ‘information-generating,’ and ‘participatory.’ These categories informed the development of strategies for online auditory training content, including: 1) personalized auditory training content using artificial intelligence, 2) integration of auditory training into senior education programs, and 3) creation of interactive online auditory rehabilitation content using bidirectional technology. The study emphasizes the need for continuous development of interactive content tailored to the demographic and lifestyle characteristics of the participants. In the context of online-based auditory training, individualized programs, such as group training and professional-led programs, are essential. Further studies are required to determine whether training outcomes can be enhanced through experience-based content. Copyright © 2023 Korean Academy of Audiology.",,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85177775133
Dmitriev D.A.; Shilov B.V.; Polunin M.M.; Zadorozhny A.D.; Lagunin A.A.,"Dmitriev, Dmitry A. (58781946500); Shilov, Boris V. (23475002400); Polunin, Michail M. (24477884500); Zadorozhny, Anton D. (57204364575); Lagunin, Alexey A. (6602271875)",58781946500; 23475002400; 24477884500; 57204364575; 6602271875,Predicting the Impact of OTOF Gene Missense Variants on Auditory Neuropathy Spectrum Disorder,2023,International Journal of Molecular Sciences,24,24,17240,,,,0,10.3390/ijms242417240,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180718135&doi=10.3390%2fijms242417240&partnerID=40&md5=402989b15f27fe6dd2afbad007e62d55,"Auditory neuropathy spectrum disorder (ANSD) associated with mutations of the OTOF gene is one of the common types of sensorineural hearing loss of a hereditary nature. Due to its high genetic heterogeneity, ANSD is considered one of the most difficult hearing disorders to diagnose. The dataset from 270 known annotated single amino acid substitutions (SAV) related to ANSD was created. It was used to estimate the accuracy of pathogenicity prediction using the known (from dbNSFP4.4) method and a new one. The new method (ConStruct) for the creation of the protein-centric classification model is based on the use of Random Forest for the analysis of missense variants in exons of the OTOF gene. A system of predictor variables was developed based on the modern understanding of the structure and function of the otoferlin protein and reflecting the location of changes in the tertiary structure of the protein due to mutations in the OTOF gene. The conservation values of nucleotide substitutions in genomes of 100 vertebrates and 30 primates were also used as variables. The average prediction of balanced accuracy and the AUC value calculated by the 5-fold cross-validation procedure were 0.866 and 0.903, respectively. The model shows good results for interpreting data from the targeted sequencing of the OTOF gene and can be implemented as an auxiliary tool for the diagnosis of ANSD in the early stages of ontogenesis. The created model, together with the results of the pathogenicity prediction of SAVs via other known accurate methods, were used for the evaluation of a manually created set of 1302 VUS related to ANSD. Based on the analysis of predicted results, 16 SAVs were selected as the new most probable pathogenic variants. © 2023 by the authors.",38139069,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85180718135
Boussaty E.C.; Tedeschi N.; Novotny M.; Ninoyu Y.; Du E.; Draf C.; Zhang Y.; Manor U.; Scheuermann R.H.; Friedman R.,"Boussaty, Ely Cheikh (57200815873); Tedeschi, Neil (56067582400); Novotny, Mark (24338839000); Ninoyu, Yuzuru (55258705800); Du, Eric (57192947602); Draf, Clara (37037210500); Zhang, Yun (57192559161); Manor, Uri (24342034100); Scheuermann, Richard H. (7006976175); Friedman, Rick (12806202500)",57200815873; 56067582400; 24338839000; 55258705800; 57192947602; 37037210500; 57192559161; 24342034100; 7006976175; 12806202500,Cochlear transcriptome analysis of an outbred mouse population (CFW),2023,Frontiers in Cellular Neuroscience,17,,1256619,,,,1,10.3389/fncel.2023.1256619,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179308997&doi=10.3389%2ffncel.2023.1256619&partnerID=40&md5=1ac73186ce8e0a5d5e53a63c098745ca,"Age-related hearing loss (ARHL) is the most common cause of hearing loss and one of the most prevalent conditions affecting the elderly worldwide. Despite evidence from our lab and others about its polygenic nature, little is known about the specific genes, cell types, and pathways involved in ARHL, impeding the development of therapeutic interventions. In this manuscript, we describe, for the first time, the complete cell-type specific transcriptome of the aging mouse cochlea using snRNA-seq in an outbred mouse model in relation to auditory threshold variation. Cochlear cell types were identified using unsupervised clustering and annotated via a three-tiered approach—first by linking to expression of known marker genes, then using the NSForest algorithm to select minimum cluster-specific marker genes and reduce dimensional feature space for statistical comparison of our clusters with existing publicly-available data sets on the gEAR website,1 and finally, by validating and refining the annotations using Multiplexed Error Robust Fluorescence In Situ Hybridization (MERFISH) and the cluster-specific marker genes as probes. We report on 60 unique cell-types expanding the number of defined cochlear cell types by more than two times. Importantly, we show significant specific cell type increases and decreases associated with loss of hearing acuity implicating specific subsets of hair cell subtypes, ganglion cell subtypes, and cell subtypes within the stria vascularis in this model of ARHL. These results provide a view into the cellular and molecular mechanisms responsible for age-related hearing loss and pathways for therapeutic targeting. Copyright © 2023 Boussaty, Tedeschi, Novotny, Ninoyu, Du, Draf, Zhang, Manor, Scheuermann and Friedman.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85179308997
Castaño-González K.; Köppl C.; Pyott S.J.,"Castaño-González, Karen (58955008900); Köppl, Christine (7004671795); Pyott, Sonja J. (6508242472)",58955008900; 7004671795; 6508242472,The crucial role of diverse animal models to investigate cochlear aging and hearing loss,2024,Hearing Research,445,,108989,,,,0,10.1016/j.heares.2024.108989,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188598610&doi=10.1016%2fj.heares.2024.108989&partnerID=40&md5=5e179c006c5f9910df4764b4e5e9f8a1,"Age-related hearing loss affects a large and growing segment of the population, with profound impacts on quality of life. Age-related pathology of the cochlea—the mammalian hearing organ—underlies age-related hearing loss. Because investigating age-related changes in the cochlea in humans is challenging and often impossible, animal models are indispensable to investigate these mechanisms as well as the complex consequences of age-related hearing loss on the brain and behavior. In this review, we advocate for a comparative and interdisciplinary approach while also addressing the challenges of comparing age-related hearing loss across species with varying lifespans. We describe the experimental advantages and limitations as well as areas for future research in well-established models of age-related hearing loss, including mice, rats, gerbils, chinchillas, and birds. We also indicate the need to expand characterization of age-related hearing loss in other established animal models, especially guinea pigs, cats, and non-human primates, in which auditory function is well characterized but age-related cochlear pathology is understudied. Finally, we highlight the potential of emerging animal models for advancing our understanding of age-related hearing loss, including deer mice, with their notably extended lifespans and preserved hearing, naked mole rats, with their exceptional longevity and extensive vocal communications, as well as zebrafish, which offer genetic tractability and suitability for drug screening. Ultimately, a comparative and interdisciplinary approach in auditory research, combining insights from various animal models with human studies, is key to robust and reliable research outcomes that better advance our understanding and treatment of age-related hearing loss. © 2024 The Author(s)",38518394,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85188598610
Wang Y.; Pan F.; Liu D.; Hu J.,"Wang, Yubo (58660035300); Pan, Fengzhou (58540010200); Liu, Danni (58539693800); Hu, Jiaxiong (58365400900)",58660035300; 58540010200; 58539693800; 58365400900,Music-to-Facial Expressions: Emotion-Based Music Visualization for the Hearing Impaired,2023,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",37,,,16096,16102,6,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168248690&partnerID=40&md5=bbabf3151776a86035aa1316df75f666,"While music is made to convey messages and emotions, auditory music is not equally accessible to everyone. Music visualization is a common approach to augment the listening experiences of the hearing users and to provide music experiences for the hearing-impaired. In this paper, we present a music visualization system that can turn the input of a piece of music into a series of facial expressions representative of the continuously changing sentiments in the music. The resulting facial expressions, recorded as action units, can later animate a static virtual avatar to be emotive synchronously with the music. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Conference paper,Final,,Scopus,2-s2.0-85168248690
Li H.; Han X.; Sang C.; Sui Y.; Ma G.,"Li, Haimei (57206828837); Han, Xiaowei (57201980312); Sang, Chunyu (12789581600); Sui, Yan (57226711335); Ma, Guolin (37004529100)",57206828837; 57201980312; 12789581600; 57226711335; 37004529100,Low-frequency fluctuation amplitude changes in resting-state brain functional magnetic resonance imaging and its correlation with clinical hearing levels in patients with unilateral hearing impairment; [单侧听力障碍患者静息态脑功能磁共振低频波动振幅差异及其与临床听力的相关分析],2023,National Medical Journal of China,103,25,,1911,1917,6,0,10.3760/cma.j.cn112137-20221107-02337,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164246507&doi=10.3760%2fcma.j.cn112137-20221107-02337&partnerID=40&md5=bdb1751e009d1da966fd320322ad77b6,"Objective To investigate low‑frequency fluctuation amplitude changes in resting‑state brain fMRI and its correlation with clinical hearing levels in patients with clinical hearing level in patients with unilateral hearing impairment. Methods Forty‑five patients with unilateral hearing impairment[12 males and 33 females, aged 36‑67 (46.0±9.7) years], and 31 controls with normal hearing[9 males and 22 females, aged 36‑67 (46.0±10.1) years], were retrospectively included. All subjects underwent blood oxygen level‑dependent (BOLD) resting‑state functional magnetic resonance imaging and high‑resolution T1‑weighted imaging. The patients were divided into the left‑sided hearing impaired group(24 cases), and the right‑sided hearing impaired group(21 cases). After data being preprocessed, differences in low frequency amplitude (ALFF) metrics between the evaluated patients and controls were calculated and analyzed, and the statistics were corrected for Gaussian random field (GFR). Results Overall comparative analysis of patients with hearing impairment showed that one‑way ANOVA among the three groups showed abnormal ALFF values only in the right anterior cuneiform lobe (GRF adjusted P=0.002). The ALFF value of the hearing impaired group was higher than that of the control group in one cluster (peak coordinates: X=9, Y=-72, Z=48, T=5.82), involving the left occipital gyrus, right anterior cuneiform lobe, left superior cuneiform lobe, left superior parietal gyrus, and left angular gyrus (GRF adjusted P=0.031). The ALFF value of the hearing impaired group was lower than that of the control group in three clusters (peak coordinates: X=57, Y=-48, Z=-24; T=-4.99; X=45, Y=-66, Z=0, T=-4.06; X=42, Y=-12, Z=36, T=-4.03), involving the right inferior temporal gyrus, the right middle temporal gyrus, and the right precentral gyrus (GRF adjusted P=0.009). Compared with the control group, the ALFF value of the left hearing impairment group was significantly higher than that of the control group in one cluster (peak coordinates: X=-12, Y=-75, Z=45, T=5.78), involving the left anterior cuneiform lobe, right anterior cuneiform lobe, left middle occipital gyrus, left superior parietal gyrus, left superior occipital gyrus, left cuneiform lobe, and right cuneiform lobe (P=0.023 after GRF correction). Compared with the control group, the right hearing impairment group had a significantly higher ALFF value in one cluster (peak coordinates: X=9, Y=-46, Z=22, T=6.06), involving the left middle occipital gyrus, right anterior cuneiform lobe, left cuneiform lobe, right cuneiform lobe, left superior occipital gyrus, and right superior occipital gyrus (GRF adjusted P=0.022); The brain area with reduced ALFF values is located in the right inferior temporal gyrus (GRF adjusted P=0.029). Spearman′s two‑tailed correlation analysis between ALFF values and pure tone average in the abnormal brain regions showed that ALFF values in the abnormal brain regions correlated to some extent with the pure tone average (PTA) only in the left‑sided hearing impaired group(PTA=2 000 Hz, r=0.318,P= 0.033; PTA=4 000 Hz, r=0.386, P=0.009). Conclusion The abnormal neural activity within the brain are different in patients with left‑sided and right‑sided hearing impairment, and the severity of hearing impairment is related to the difference in functional integration of brain regions. © 2023 Chinese Medical Association. All rights reserved.",37402672,Article,Final,,Scopus,2-s2.0-85164246507
Qiu Y.; Wang H.; Pan H.; Guan J.; Yan L.; Fan M.; Zhou H.; Zhou X.; Wu K.; Jia Z.; Zhuang Q.; Lei Z.; Li M.; Ding X.; Lin A.; Fu Y.; Zhang D.; Wang Q.; Yan Q.,"Qiu, Yue (57203950037); Wang, Hongyang (56178855800); Pan, Huaye (56954063400); Guan, Jing (57203308900); Yan, Lei (58095005700); Fan, Mingjie (56201576200); Zhou, Hui (57203947903); Zhou, Xuanhao (58094970900); Wu, Kaiwen (57061289700); Jia, Zexiao (57203948176); Zhuang, Qianqian (57221305165); Lei, Zhaoying (57212562515); Li, Mengyao (57539870300); Ding, Xue (57933974700); Lin, Aifu (35269500200); Fu, Yong (57204674420); Zhang, Dong (57226849183); Wang, Qiuju (15734255200); Yan, Qingfeng (37118230700)",57203950037; 56178855800; 56954063400; 57203308900; 58095005700; 56201576200; 57203947903; 58094970900; 57061289700; 57203948176; 57221305165; 57212562515; 57539870300; 57933974700; 35269500200; 57204674420; 57226849183; 15734255200; 37118230700,AIFM1 variants associated with auditory neuropathy spectrum disorder cause apoptosis due to impaired apoptosis-inducing factor dimerization; [听神经病相关 AIFM1 基因突变引起凋亡诱导因子二聚体形成障碍并导致细胞凋亡增加],2023,Journal of Zhejiang University: Science B,24,2,,172,184,12,4,10.1631/jzus.B2200081,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147608927&doi=10.1631%2fjzus.B2200081&partnerID=40&md5=73e5d5a84df264d0d90c90d260afd34d,"Auditory neuropathy spectrum disorder (ANSD) represents a variety of sensorineural deafness conditions characterized by abnormal inner hair cells and/or auditory nerve function, but with the preservation of outer hair cell function. ANSD represents up to 15% of individuals with hearing impairments. Through mutation screening, bioinformatic analysis and expression studies, we have previously identified several apoptosis-inducing factor (AIF) mitochondria-associated 1 (AIFM1) variants in ANSD families and in some other sporadic cases. Here, to elucidate the pathogenic mechanisms underlying each AIFM1 variant, we generated AIF-null cells using the clustered regularly interspersed short palindromic repeats (CRISPR)/CRISPR-associated protein 9 (Cas9) system and constructed AIF-wild type (WT) and AIF-mutant (mut) (p.T260A, p.R422W, and p.R451Q) stable transfection cell lines. We then analyzed AIF structure, coenzyme-binding affinity, apoptosis, and other aspects. Results revealed that these variants resulted in impaired dimerization, compromising AIF function. The reduction reaction of AIF variants had proceeded slower than that of AIF-WT. The average levels of AIF dimerization in AIF variant cells were only 34.5%–49.7% of that of AIF-WT cells, resulting in caspase-independent apoptosis. The average percentage of apoptotic cells in the variants was 12.3%–17.9%, which was significantly higher than that (6.9%–7.4%) in controls. However, nicotinamide adenine dinucleotide (NADH) treatment promoted the reduction of apoptosis by rescuing AIF dimerization in AIF variant cells. Our findings show that the impairment of AIF dimerization by AIFM1 variants causes apoptosis contributing to ANSD, and introduce NADH as a potential drug for ANSD treatment. Our results help elucidate the mechanisms of ANSD and may lead to the provision of novel therapies. © 2023, Zhejiang University Press.",36751702,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85147608927
Gathman T.J.; Choi J.S.; Vasdev R.M.S.; Schoephoerster J.A.; Adams M.E.,"Gathman, Tyler J. (57299533600); Choi, Janet S. (56046392400); Vasdev, Ranveer M.S. (57219352680); Schoephoerster, Jamee A. (57195629195); Adams, Meredith E. (16041571300)",57299533600; 56046392400; 57219352680; 57195629195; 16041571300,"Machine Learning Prediction of Objective Hearing Loss With Demographics, Clinical Factors, and Subjective Hearing Status",2023,Otolaryngology - Head and Neck Surgery (United States),169,3,,504,513,9,1,10.1002/ohn.288,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168703678&doi=10.1002%2fohn.288&partnerID=40&md5=1f64ff4297030ef4ae4a3b5624206c4a,"Objective: Hearing loss (HL) is highly prevalent, yet underrecognized and underdiagnosed. Lack of standardized screening, awareness, cost, and access to hearing testing present barriers to HL identification. To facilitate prescreening and selection of patients who warrant audiometric evaluation, we developed a machine learning (ML) model to predict speech-frequency pure-tone average (PTA). Study Design: Cross-sectional study. Setting: National Health and Nutrition Examination Survey (NHANES). Methods: The cohort included 8918 adults (≥20 years) who completed audiometric testing with NHANES (2012-2018). The primary outcome measure was the prediction of better hearing ear speech-frequency PTA. Relevant predictors included demographics, medical conditions, and subjective assessment of hearing. Supervised ML with a tree-based architecture was used. Regression performance was determined by the mean absolute error (MAE) with binary classification assessed with area under the receiver operating characteristic curve (AUC). Results: Using the full set of predictors, the test set MAE between the ML-predicted and actual PTA was 5.29 dB HL (95% confidence interval [CI]: 4.97-5.61). The 5 most influential predictors of higher PTA were increased age, worse subjective hearing, male gender, increased body mass index, and history of smoking. The 5-factor abbreviated model performed comparably to the extended feature set with MAE 5.36 (95% CI: 5.03-5.69) and AUC for PTA > 25 dB HL of 0.92 (95% CI: 0.90-0.94). Conclusion: The ML model was able to predict PTA with patient demographics, clinical factors, and subjective hearing status. ML-based prediction may be used to identify individuals who could benefit most from audiometric evaluation. © 2023 The Authors. Otolaryngology–Head and Neck Surgery published by Wiley Periodicals LLC on behalf of American Academy of Otolaryngology–Head and Neck Surgery Foundation.",36758959,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85168703678
Langworthy B.; Wu Y.; Wang M.,"Langworthy, Benjamin (57201032609); Wu, Yujie (57219527510); Wang, Molin (12774321000)",57201032609; 57219527510; 12774321000,An overview of propensity score matching methods for clustered data,2023,Statistical Methods in Medical Research,32,4,,641,655,14,5,10.1177/09622802221133556,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142751947&doi=10.1177%2f09622802221133556&partnerID=40&md5=e190a916543c885240c335eba1722a86,"Propensity score matching is commonly used in observational studies to control for confounding and estimate the causal effects of a treatment or exposure. Frequently, in observational studies data are clustered, which adds to the complexity of using propensity score techniques. In this article, we give an overview of propensity score matching methods for clustered data, and highlight how propensity score matching can be used to account for not just measured confounders, but also unmeasured cluster level confounders. We also consider using machine learning methods such as generalized boosted models to estimate the propensity score and show that accounting for clustering when using these methods can greatly reduce the performance, particularly when there are a large number of clusters and a small number of subjects per cluster. In order to get around this we highlight scenarios where it may be possible to control for measured covariates using propensity score matching, while using fixed effects regression in the outcome model to control for cluster level covariates. Using simulation studies we compare the performance of different propensity score matching methods for clustered data across a number of different settings. Finally, as an illustrative example we apply propensity score matching methods for clustered data to study the causal effect of aspirin on hearing deterioration using data from the conservation of hearing study. © The Author(s) 2022.",36426585,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85142751947
Sahni D.; Bhagat S.; Bhatia L.; Singh P.; Chawla S.; Kaur A.,"Sahni, Dimple (57217314158); Bhagat, Sanjeev (7102093409); Bhatia, Lovleen (58545888900); Singh, Parvinder (58591682700); Chawla, Sagar (58545605400); Kaur, Amandeep (58380619500)",57217314158; 7102093409; 58545888900; 58591682700; 58545605400; 58380619500,Association Between Metabolic Syndrome and Hearing Impairment: a Study on 200 Subjects,2024,Indian Journal of Otolaryngology and Head and Neck Surgery,76,1,,262,267,5,0,10.1007/s12070-023-04138-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168606817&doi=10.1007%2fs12070-023-04138-w&partnerID=40&md5=9e8a315e3dbcf0f9e1ca2f1e8512ce2a,"The metabolic syndrome (MS) is a cluster of conditions that occur. togehther, increase risk of heart disease, storke, type 2 diabetes mellitus and hypertension as a possible outcome. The previous research has shown a link between hearing loss and being overweight, diabetic, or suffering from heart disease. However, research on the possible link between hearing loss and metabolic syndrome is limited. Hearing loss due to metabolic syndrome was evaluated in the present investigation. Two hundred individuals with metabolic syndrome were included. All the patients were evaluated on three types of audiometry (pure tone, impedence, and DPOAE).Anthropometric data, blood pressure, blood sugar, and lipid profiles, were all collected from each patient. We also asked about their smoking and drinking habits in the past. SPSS v. 22.0 was used to conduct the statistical analysis. Overall, SNHL affected 58.5% of patients. Patients having moderate hearing loss were the largest demographic group (40%), followed by those with mild hearing loss (15%). Severe hearing loss only occurred in 3.5% of patients. Hearing loss was shown to be more prevalent in patients with more than three components of metabolic syndrome. Significant associations were found between hearing impairment and metabolic risk factors as waist circumference, fasting blood sugar, serum high-density lipoprotein, serum triglycerides, and systolic and diastolic blood pressure. Hearing loss was only marginally connected to smoking and excessive drinking. © Association of Otolaryngologists of India 2023.",,Article,Final,,Scopus,2-s2.0-85168606817
Oxenham A.J.,"Oxenham, Andrew J. (7003326429)",7003326429,Questions and controversies surrounding the perception and neural coding of pitch,2023,Frontiers in Neuroscience,16,,1074752,,,,2,10.3389/fnins.2022.1074752,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147035524&doi=10.3389%2ffnins.2022.1074752&partnerID=40&md5=f02aed6120f30971aeaa7ef0b55b0c0b,"Pitch is a fundamental aspect of auditory perception that plays an important role in our ability to understand speech, appreciate music, and attend to one sound while ignoring others. The questions surrounding how pitch is represented in the auditory system, and how our percept relates to the underlying acoustic waveform, have been a topic of inquiry and debate for well over a century. New findings and technological innovations have led to challenges of some long-standing assumptions and have raised new questions. This article reviews some recent developments in the study of pitch coding and perception and focuses on the topic of how pitch information is extracted from peripheral representations based on frequency-to-place mapping (tonotopy), stimulus-driven auditory-nerve spike timing (phase locking), or a combination of both. Although a definitive resolution has proved elusive, the answers to these questions have potentially important implications for mitigating the effects of hearing loss via devices such as cochlear implants. Copyright © 2023 Oxenham.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147035524
Chae M.; Yoon H.; Lee H.; Choi J.,"Chae, Minsu (58961792800); Yoon, Heesoo (58177092500); Lee, Hwamin (54995665800); Choi, June (36019909600)",58961792800; 58177092500; 54995665800; 36019909600,Hearing Recovery Prediction for Patients with Chronic Otitis Media Who Underwent Canal-Wall-Down Mastoidectomy,2024,Journal of Clinical Medicine,13,6,1557,,,,0,10.3390/jcm13061557,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188997545&doi=10.3390%2fjcm13061557&partnerID=40&md5=da8d5fa0166ab72029d5f2880ee9fb35,"Background: Chronic otitis media affects approximately 2% of the global population, causing significant hearing loss and diminishing the quality of life. However, there is a lack of studies focusing on outcome prediction for otitis media patients undergoing canal-wall-down mastoidectomy. Methods: This study proposes a recovery prediction model for chronic otitis media patients undergoing canal-wall-down mastoidectomy, utilizing data from 298 patients treated at Korea University Ansan Hospital between March 2007 and August 2020. Various machine learning techniques, including logistic regression, decision tree, random forest, support vector machine (SVM), extreme gradient boosting (XGBoost), and light gradient boosting machine (light GBM), were employed. Results: The light GBM model achieved a predictive value (PPV) of 0.6945, the decision tree algorithm showed a sensitivity of 0.7574 and an F1 score of 0.6751, and the light GBM algorithm demonstrated the highest AUC-ROC values of 0.7749 for each model. XGBoost had the most efficient PR-AUC curve, with a value of 0.7196. Conclusions: This study presents the first predictive model for chronic otitis media patients undergoing canal-wall-down mastoidectomy. The findings underscore the potential of machine learning techniques in predicting hearing recovery outcomes in this population, offering valuable insights for personalized treatment strategies and improving patient care. © 2024 by the authors.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85188997545
Idushan K.A.S.; Dilshan P.G.T.; Jayasundera P.S.; Madhushan K.L.B.; Krishara J.; Wijendra D.,"Idushan, K.A.S. (58876490600); Dilshan, P.G.T. (58876750400); Jayasundera, P.S. (58876701800); Madhushan, K.L.B. (58876651000); Krishara, Jenny (57353919200); Wijendra, Dinuka (57193736232)",58876490600; 58876750400; 58876701800; 58876651000; 57353919200; 57193736232,Sinhala Sign Language Learning System for Hearing Impaired Community,2023,"4th International Informatics and Software Engineering Conference - Symposium Program, IISEC 2023",,,,,,,0,10.1109/IISEC59749.2023.10391004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184659714&doi=10.1109%2fIISEC59749.2023.10391004&partnerID=40&md5=176ac676534f34c445f0a6f17178e365,"This research aims to develop a comprehensive system for Sinhala Sign Language (SSL) that includes a learning system, dynamic sign detection, audio/video to sign conversion, and vocal training. SSL plays a crucial role in facilitating communication for individuals who are deaf or hard of hearing in Sri Lanka. The learning system provides a platform for learning SSL and includes a text-To-sign language interpreter. The dynamic sign detection system uses computer vision techniques to identify and interpret dynamic signs accurately. The audio/video to sign conversion system bridges the gap between spoken language and SSL by converting auditory information into visual representations. The vocal training system focuses on enhancing the vocal skills of cochlear implanted children. This research contributes to the development of effective communication and language skills for SSL users.  © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85184659714
Amizadeh M.; Farahani S.; Afsharmanesh J.; Sharifi H.; Fani Molky F.,"Amizadeh, Maryam (16174242600); Farahani, Saeid (55103879200); Afsharmanesh, Jila (57429852600); Sharifi, Hamid (58859781700); Fani Molky, Fatemeh (58859781800)",16174242600; 55103879200; 57429852600; 58859781700; 58859781800,"The Prevalence of Central Auditory Processing Disorder in Elementary School Students of Kerman, Iran",2024,Iranian Journal of Child Neurology,18,1,,71,80,9,0,10.22037/ijcn.v17i1.33821,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183915429&doi=10.22037%2fijcn.v17i1.33821&partnerID=40&md5=9d724150c0f10f62189bc8a6fcbbb8d0,"Objectives This study aimed to determine the prevalence of central auditory processing disorder (CAPD) in elementary school students in Kerman, Iran, during 2018-2019. Materials & Methods This cross-sectional study was conducted on 1369 elementary school students in Kerman. These students were selected by cluster sampling from different areas of Kerman and then screened using the Buffalo Model Questionnaire (BMQ). Based on the data obtained from the questionnaire, normal children were excluded from the study. Then, children with suspected central auditory processing disorder (CAPD) underwent ear exams and were excluded from the study in case of abnormal results in the tympanic membrane examination (rapture-effusion). The remaining subjects underwent peripheral audiometry evaluation, and children with abnormal audiometry were excluded from the study. Finally, the remaining children with suspicious screening results, a normal examination, and normal audiometry underwent a specific test to detect Central auditory processing disorder. Data analysis was carried out using SPSS software. Results One thousand three hundred sixty-nine primary school students with a mean age of 9.15 ±2.63 years enrolled in this study. 52%% of students were male. 8.03% of them had CAPD. A statistically significant relationship was found between the prevalence of CAPD and gender (P<0.001), place of residence (P<0.001), history of middle ear inflammation (P<0.001) and history of head injury. Conclusion The quality of life of these students with CAPD can be improved via timely recognition of CAPD and the provision of appropriate preventive and therapeutic facilities. © 2023 The Authors.",,Article,Final,,Scopus,2-s2.0-85183915429
Corona-Rivera J.R.; Zenteno J.C.; López-Pérez L.G.; Yokoyama-Rebollar E.; Villarroel C.E.; Barragán-Arévalo T.; Montes-Almanza L.Á.; Zepeda-Romero L.C.; Morales-Domínguez G.E.; Peña-Padilla C.; Bobadilla-Morales L.; Corona-Rivera A.,"Corona-Rivera, Jorge Román (57226291773); Zenteno, Juan Carlos (7004122469); López-Pérez, Leopoldo Gildardo (57197866079); Yokoyama-Rebollar, Emiy (56991102200); Villarroel, Camilo E. (25643488800); Barragán-Arévalo, Tania (57203659611); Montes-Almanza, Luis Ángel (56574287900); Zepeda-Romero, Luz Consuelo (6506930807); Morales-Domínguez, Guadalupe Elena (57825522000); Peña-Padilla, Christian (55981635100); Bobadilla-Morales, Lucina (6507563128); Corona-Rivera, Alfredo (6602935356)",57226291773; 7004122469; 57197866079; 56991102200; 25643488800; 57203659611; 56574287900; 6506930807; 57825522000; 55981635100; 6507563128; 6602935356,"First Report of Mexican Patients with PACS1 -Related Neurodevelopmental Disorder and Review of the PACS1 -, PACS2 -, and WDR37-Related Ophthalmological Manifestations",2023,Molecular Syndromology,14,2,,143,151,8,0,10.1159/000526975,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145289036&doi=10.1159%2f000526975&partnerID=40&md5=3ac80edb36c4f3605bea6e69492de23b,"Introduction: PACS1-related neurodevelopmental disorder (PACS1-related NDD) is caused by pathogenic variants in the PACS1 gene and is characterized by a distinctive facial appearance, intellectual disability, speech delay, seizures, feeding difficulties, cryptorchidism, hernias, and structural anomalies of the brain, heart, eye, and kidney. There is a marked facial resemblance and a common multisystem affectation with patients carrying pathogenic variants in the WDR37 and PACS2 genes, although they vary in terms of severity and eye involvement. Case Presentation: Here, we describe 4 individuals with PACS1-related NDD from Mexico, all of them carrying a de novo PACS1 variant c.607C>T; p.(Arg203Trp) identified by exome sequencing. In addition to eye colobomata, this report identified corneal leukoma, cataracts, and tortuosity of retinal vessels as ophthalmic manifestations not previously reported in patients with PACS1-related NDD. Discussion: We reviewed the ocular phenotypes reported in 74 individuals with PACS1-related NDD and the overlaps with WDR37- and PACS2-related syndromes. We found that the 3 syndromes have in common the presence of colobomata, ptosis, nystagmus, strabismus, and refractive errors, whereas microphthalmia, microcornea, and Peters anomaly are found only among individuals with PACS1-related NDD and WDR37 syndrome, being more severe in the latter. This supports the previous statement that the so-called WDR37-PACS1-PACS2 axis might have an important role in ocular development and also that the specific ocular findings could be useful in the clinical differentiation between these related syndromes. © 2022 S. Karger AG, Basel. All rights reserved.",,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85145289036
Schilling A.; Schaette R.; Sedley W.; Gerum R.C.; Maier A.; Krauss P.,"Schilling, Achim (57189988281); Schaette, Roland (14014026800); Sedley, William (36085035000); Gerum, Richard Carl (55990645300); Maier, Andreas (23392966100); Krauss, Patrick (55216351100)",57189988281; 14014026800; 36085035000; 55990645300; 23392966100; 55216351100,"Editorial: Auditory perception and phantom perception in brains, minds and machines",2023,Frontiers in Neuroscience,17,,1293552,,,,0,10.3389/fnins.2023.1293552,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174847501&doi=10.3389%2ffnins.2023.1293552&partnerID=40&md5=ea2460e7c682c7b9304605316c4eb339,[No abstract available],,Editorial,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85174847501
Ulrich N.,"Ulrich, Natalja (57259765700)",57259765700,Database description: Russian fricatives recorded in 198 real speech sentences from 59 speakers,2023,Data in Brief,48,,109205,,,,0,10.1016/j.dib.2023.109205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159778829&doi=10.1016%2fj.dib.2023.109205&partnerID=40&md5=23f173a6ecc713658f11edb0eab0ef22,"This speech dataset is primarily designed to investigate linguistic and speaker information in fricative sounds in Russian. Acoustic recordings were obtained from 59 students (30 females and 29 males) between 18 and 30 years. Eighteen participants were recorded in a second session. The participants were born and lived since their early childhood in St. Petersburg. The participants did not report any speech or hearing impairment. The recording sessions were conducted at the phonetic laboratory of the Phonetic Institute in St. Petersburg, in an audiometric booth using the recording program Speech-Recorder version 3.28.0 at a sample rate of 44.1 kHz (16-bit encoding). During the recordings, a clip-on microphone (Sennheiser MKE 2-P) was placed at a distance of 15cm from the speakers’ mouth and connected through an audio interface (Zoom U-22) to a laptop computer. The participants were instructed to read 198 randomized sentences from a computer screen. The fricatives [f], [s], [ʃ], [x], [v], [z], [ʒ], [sʲ], [ɕ], [vʲ], [zʲ] were embedded into those sentences. Two sentence structures were designed to obtain each real-word lexemes produced in three different contexts. The first type of sentence is a so-called carrier sentence with the structure of “She said ”X” and not “Y” ”. Minimal pairs of real words, containing one of the 11 tested fricatives were placed in both “X” and “Y” positions. The second type of pre-designed sentence was a natural language sentence including each of the lexemes. All raw audio files were first automatically pre-processed by applying the online tool Munich Automatic Segmentation system. Then, the files of the first recording session were filtered below 80 and above 20050 Hz, and the boundaries were manually corrected using Praat. The dataset consists of 22,561 fricative tokens. The number of observations per sound differs across categories, because of their natural distribution. The dataset is made available as a collection of audio files in wav format along with companion Praat TextGrid files for each sentence. Target fricatives are furthermore available as individual wav files. The whole dataset can be accessed with the DOI https://doi.org/10.48656/4q9c-gz16. Additionally, the experimental design allows the investigation of other sound categories. The number of speakers recorded gives further possibilities for phonetic-oriented speaker identification studies. © 2023 The Author(s)",,Data paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85159778829
Liu M.; Wang Y.; Jiang L.; Zhang X.; Wang C.; Zhang T.,"Liu, Mengting (57484497100); Wang, Yuyao (57949444900); Jiang, Li (58855141300); Zhang, Xiaopeng (58853833700); Wang, Chunrui (54581848000); Zhang, Tianhong (55729049500)",57484497100; 57949444900; 58855141300; 58853833700; 54581848000; 55729049500,"Research progress of the inferior Colliculus: From Neuron, neural circuit to auditory disease",2024,Brain Research,1828,,148775,,,,0,10.1016/j.brainres.2024.148775,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183633512&doi=10.1016%2fj.brainres.2024.148775&partnerID=40&md5=017565bcc36fd09db4ee7f99498ef7a7,"The auditory midbrain, also known as the inferior colliculus (IC), serves as a crucial hub in the auditory pathway. Comprising diverse cell types, the IC plays a pivotal role in various auditory functions, including sound localization, auditory plasticity, sound detection, and sound-induced behaviors. Notably, the IC is implicated in several auditory central disorders, such as tinnitus, age-related hearing loss, autism and Fragile X syndrome. Accurate classification of IC neurons is vital for comprehending both normal and dysfunctional aspects of IC function. Various parameters, including dendritic morphology, neurotransmitter synthesis, potassium currents, biomarkers, and axonal targets, have been employed to identify distinct neuron types within the IC. However, the challenge persists in effectively classifying IC neurons into functional categories due to the limited clustering capabilities of most parameters. Recent studies utilizing advanced neuroscience technologies have begun to shed light on biomarker-based approaches in the IC, providing insights into specific cellular properties and offering a potential avenue for understanding IC functions. This review focuses on recent advancements in IC research, spanning from neurons and neural circuits to aspects related to auditory diseases. © 2024 Elsevier B.V.",38244755,Article,Final,,Scopus,2-s2.0-85183633512
Mehedi I.M.; Hanif M.S.; Bilal M.; Vellingiri M.T.; Palaniswamy T.,"Mehedi, Ibrahim M. (54407013400); Hanif, Muhammad Shehzad (57213496275); Bilal, Muhammad (58530090600); Vellingiri, Mahendiran T. (57216566103); Palaniswamy, Thangam (57203907867)",54407013400; 57213496275; 58530090600; 57216566103; 57203907867,Artificial Intelligence With Deep Learning Based Automated Ear Infection Detection,2024,IEEE Access,12,,10487914,48335,48348,13,0,10.1109/ACCESS.2024.3383835,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189622111&doi=10.1109%2fACCESS.2024.3383835&partnerID=40&md5=c768d523287e99e3508d7da80b6a6a2c,"Artificial intelligence (AI) related to intelligent control in healthcare denotes using AI techniques to enhance the management and control of healthcare processes and systems. Damage to the inner and middle ear caused by accidents and diseases even causes hearing impairment in the ear that has been harmed or injured. Traditional otoscopy devices were utilized to check the tympanic membrane (TM) to identify OM in medical practice, and a conclusion is drawn depending on the outcomes of the examination. While developing a computer-aided method to support the OM diagnosis, it is possible to focus on methods like feature extraction, image pre-processing, classification, and image segmentation. The existing methodology of detecting the ear infection experiences a reduction of accuracy due to the influence of the noise in the input ear image. This presence of noise affects the feature extraction process, directly influences the accuracy in detection process. To overcome this issue, in this manuscript, a Deep learning (DL) is utilized to find biomedical ear infections by examining images of the eardrum and ear canal. The process includes training a DL method with a large dataset of ear images, where the images were labeled as either not infected or infected. With this motivation, this article emphasizes the design of Bayesian optimization with a deep learning-based automated ear infection detection and classification (BODL-AEIDC) model. The BODL-AEIDC technique exploits the DL model with a metaheuristic optimization algorithm for the ear infection classification process. The BODL-AEIDC technique employs a Wiener filtering (WF) based noise removal process to eliminate the noise data. In addition, the BODL-AEIDC technique exploits W-Net-based segmentation and the EfficientNet model for feature extraction purposes. Moreover, the BODL-AEIDC technique employs a fuzzy Restricted Boltzmann machine (FRBM) model for ear infection detection. Furthermore, the BO algorithm is utilized to adjust the FRBM technique's hyperparameter values effectively. The BODL-AEIDC technique's experimental outcomes occur using the medical dataset. The comprehensive comparative study stated the enhanced performance of the BODL-AEIDC approach over other existing methods.  © 2013 IEEE.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85189622111
Elmer S.; Schmitt R.; Giroud N.; Meyer M.,"Elmer, Stefan (6603796867); Schmitt, Raffael (57565499800); Giroud, Nathalie (57192154805); Meyer, Martin (7403185338)",6603796867; 57565499800; 57192154805; 7403185338,The neuroanatomical hallmarks of chronic tinnitus in comorbidity with pure-tone hearing loss,2023,Brain Structure and Function,228,6,,1511,1534,23,2,10.1007/s00429-023-02669-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162943627&doi=10.1007%2fs00429-023-02669-0&partnerID=40&md5=af455c090932bca3fef864a8eba45ee5,"Tinnitus is one of the main hearing impairments often associated with pure-tone hearing loss, and typically manifested in the perception of phantom sounds. Nevertheless, tinnitus has traditionally been studied in isolation without necessarily considering auditory ghosting and hearing loss as part of the same syndrome. Hence, in the present neuroanatomical study, we attempted to pave the way toward a better understanding of the tinnitus syndrome, and compared two groups of almost perfectly matched individuals with (TIHL) and without (NTHL) pure-tone tinnitus, but both characterized by pure-tone hearing loss. The two groups were homogenized in terms of sample size, age, gender, handedness, education, and hearing loss. Furthermore, since the assessment of pure-tone hearing thresholds alone is not sufficient to describe the full spectrum of hearing abilities, the two groups were also harmonized for supra-threshold hearing estimates which were collected using temporal compression, frequency selectivity und speech-in-noise tasks. Regions-of-interest (ROI) analyses based on key brain structures identified in previous neuroimaging studies showed that the TIHL group exhibited increased cortical volume (CV) and surface area (CSA) of the right supramarginal gyrus and posterior planum temporale (PT) as well as CSA of the left middle-anterior part of the superior temporal sulcus (STS). The TIHL group also demonstrated larger volumes of the left amygdala and of the left head and body of the hippocampus. Notably, vertex-wise multiple linear regression analyses additionally brought to light that CSA of a specific cluster, which was located in the left middle-anterior part of the STS and overlapped with the one found to be significant in the between-group analyses, was positively associated with tinnitus distress level. Furthermore, distress also positively correlated with CSA of gray matter vertices in the right dorsal prefrontal cortex and the right posterior STS, whereas tinnitus duration was positively associated with CSA and CV of the right angular gyrus (AG) and posterior part of the STS. These results provide new insights into the critical gray matter architecture of the tinnitus syndrome matrix responsible for the emergence, maintenance and distress of auditory phantom sensations. © 2023, The Author(s).",37349539,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85162943627
Hamid T.M.T.A.; Sallehuddin R.; Yunos Z.M.; Ali A.,"Hamid, Tengku Mazlin Tengku Ab (57214116896); Sallehuddin, Roselina (23493443900); Yunos, Zuriahati Mohd (57220207360); Ali, Aida (9943308700)",57214116896; 23493443900; 57220207360; 9943308700,Ensemble filters with harmonize PSO–SVM algorithm for optimal hearing disorder prediction,2023,Neural Computing and Applications,35,14,,10473,10496,23,0,10.1007/s00521-023-08244-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147287898&doi=10.1007%2fs00521-023-08244-2&partnerID=40&md5=97c551f11ac1bf8be69fb832f5d5eb4d,"Discovering a hearing disorder at an earlier intervention is critical for reducing the effects of hearing loss and the approaches to increase the remaining hearing ability can be implemented to achieve the successful development of human communication. Recently, the explosive dataset features have increased the complexity for audiologists to decide the proper treatment for the patient. In most cases, data with irrelevant features and improper classifier parameters causes a crucial influence on the audiometry system in terms of accuracy. This is due to the dependent processes of these two, where the classification accuracy performance could be worsened if both processes are conducted independently. Although the filter algorithm is capable of eliminating irrelevant features, it still lacks the ability to consider feature reliance and results in a poor selection of significant features. Improper kernel parameter settings may also contribute to poor accuracy performance. In this paper, an ensemble filters feature selection based on Information Gain (IG), Gain Ratio (GR), Chi-squared (CS), and Relief-F (RF) with harmonize optimization of Particle Swarm Optimization (PSO) and Support Vector Machine (SVM) is presented to mitigate these problems. Ensemble filters are utilized so that the initial top dominant features relevant for classification can be considered. Then, PSO and SVM are optimized simultaneously to achieve the optimal solution. The results on a standard Audiology dataset show that the proposed method produces 96.50% accuracy with optimal solution compared to classical SVM, which signifies the proposed method is effective in handling high dimensional data for hearing disorder prediction. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85147287898
Matusiak M.; Oziębło D.; Ołdak M.; Rejmak E.; Kaczmarek L.; Dobek D.; Skarżyński H.,"Matusiak, Monika (8902822200); Oziębło, Dominika (56880428400); Ołdak, Monika (6602747364); Rejmak, Emilia (55413939900); Kaczmarek, Leszek (7101654245); Dobek, Dominik (57807082200); Skarżyński, Henryk (7006192364)",8902822200; 56880428400; 6602747364; 55413939900; 7101654245; 57807082200; 7006192364,MMP-9 plasma level as biomarker of cochlear implantation outcome in cohort study of deaf children,2023,European Archives of Oto-Rhino-Laryngology,280,10,,4361,4369,8,0,10.1007/s00405-023-07924-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151464085&doi=10.1007%2fs00405-023-07924-y&partnerID=40&md5=8a80a05c27dcc52c31149feca399248f,"Purpose: If before cochlear implantation it was possible to assay biomarkers of neuroplasticity, we might be able to identify those children with congenital deafness who, later on, were at risk of poor speech and language rehabilitation outcomes. Methods: A group of 40 children aged up to 2 years with DFNB1-related congenital deafness was observed in this prospective cohort study over three follow-up intervals (0, 8, and 18 months) after cochlear implant (CI) activation. Children were assessed for auditory development using the LittlEARS Questionnaire (LEAQ) score, and at the same time, measurements were made of matrix metalloproteinase-9 (MMP-9) plasma levels. Results: There were significant negative correlations between plasma levels of MMP-9 at 8-month follow-up and LEAQ score at cochlear implantation (p = 0.04) and LEAQ score at 18-month follow-up (p = 0.02) and between MMP-9 plasma levels at 18-month follow-up and LEAQ score at cochlear implantation (p = 0.04). As already reported, we confirmed a significant negative correlation between MMP-9 plasma level at cochlear implantation and LEAQ score at 18-month follow-up (p = 0.005). Based on this latter correlation, two clusters of good and poor CI performers could be isolated. Conclusions: The study shows that children born deaf who have an MMP-9 plasma level of less than 150 ng/ml at cochlear implantation have a good chance of attaining a high LEAQ score after 18 months of speech and language rehabilitation. This indicates that MMP-9 plasma level at cochlear implantation is a good prognostic marker for CI outcome. © 2023, The Author(s).",37004521,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85151464085
Wu P.-Z.; O’Malley J.T.; Liberman M.C.,"Wu, Pei-zhe (57195631460); O’Malley, Jennifer T. (16550521000); Liberman, M. Charles (7102934682)",57195631460; 16550521000; 7102934682,Neural Degeneration in Normal-Aging Human Cochleas: Machine-Learning Counts and 3D Mapping in Archival Sections,2023,JARO - Journal of the Association for Research in Otolaryngology,24,5,,499,511,12,0,10.1007/s10162-023-00909-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176306603&doi=10.1007%2fs10162-023-00909-y&partnerID=40&md5=8eda35fd6bd1dbe770fc84cf65d4338e,"Quantifying the survival patterns of spiral ganglion cells (SGCs), the cell bodies of auditory-nerve fibers, is critical to studies of sensorineural hearing loss, especially in human temporal bones. The classic method of manual counting is tedious, and, although stereology approaches can be faster, they can only be used to estimate total cell numbers per cochlea. Here, a machine-learning algorithm that automatically identifies, counts, and maps the SGCs in digitized images of semi-serial human temporal-bone sections not only speeds the analysis, with no loss of accuracy, but also allows 3D visualization of the SGCs and fine-grained mapping to cochlear frequency. Applying the algorithm to 62 normal-aging human ears shows significantly faster degeneration of SGCs in the basal than the apical half of the cochlea. Comparison to fiber counts in the same ears shows that the fraction of surviving SGCs lacking a peripheral axon steadily increases with age, reaching more than 50% in the apical cochlea and almost 66% in basal regions. © 2023, The Author(s) under exclusive licence to Association for Research in Otolaryngology.",37957485,Article,Final,,Scopus,2-s2.0-85176306603
Hasnain F.; Herran R.M.; Henning S.C.; Ditmars A.M.; Pisoni D.B.; Sehgal S.T.; Kronenberger W.G.,"Hasnain, Fahad (58140657500); Herran, Reid M. (58183267400); Henning, Shirley C. (25225911300); Ditmars, Allison M. (56623091500); Pisoni, David B. (7005913467); Sehgal, Susan T. (7202688515); Kronenberger, William G. (6701385793)",58140657500; 58183267400; 25225911300; 56623091500; 7005913467; 7202688515; 6701385793,"Verbal Fluency in Prelingually Deaf, Early Implanted Children and Adolescents With Cochlear Implants",2023,"Journal of Speech, Language, and Hearing Research",66,4,,1,16,15,0,10.1044/2022_JSLHR-22-00383,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152488265&doi=10.1044%2f2022_JSLHR-22-00383&partnerID=40&md5=394033d54f5b36141f215771ce3c08ea,"Purpose: Verbal fluency tasks assess the ability to quickly and efficiently retrieve words from the mental lexicon by requiring subjects to rapidly generatwords within a phonological or semantic category. This study investigated differences between cochlear implant users and normal-hearing peers in the clustering and time course of word retrieval during phonological and semantic verbal fluency tasks. Method: Twenty-eight children and adolescents (aged 9–17 years) with cochlear implants and 33 normal-hearing peers completed measures of verbal fluency, nonverbal intelligence, speech perception, and verbal short-term/working memory. Phonological and semantic verbal fluency tests were scored for total wordgenerated, words generated in each 10-s interval of the 1-min task, latency first word generated, number of word clusters, average cluster size, and numbeof word/cluster switches. Results: Children and adolescents with cochlear implants generated fewer words than normal-hearing peers throughout the entire 60-s time interval of thphonological and semantic fluency tasks. Cochlear implant users also had slower start latency times and produced fewer clusters and switches than normal-hearing peers during the phonological fluency task. Speech perception and verbal working memory scores were more strongly associated with verbafluency scores in children and adolescents with cochlear implants than in normal-hearing peers. Conclusions: Cochlear implant users show poorer phonological and semantic verbal fluency than normal-hearing peers, and their verbal fluency is significantly associated with speech perception and verbal working memory. These findings suggest deficits in fluent retrieval of phonological and semantic information from long-term lexical memory in cochlear implant users. © 2023 American Speech-Language-Hearing Association.",36857026,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85152488265
Neuschwander P.; Schmitt R.; Jagoda L.; Kurthen I.; Giroud N.; Meyer M.,"Neuschwander, Pia (57206775028); Schmitt, Raffael (57565499800); Jagoda, Laura (57202954582); Kurthen, Ira (57201395125); Giroud, Nathalie (57192154805); Meyer, Martin (7403185338)",57206775028; 57565499800; 57202954582; 57201395125; 57192154805; 7403185338,Different neuroanatomical correlates for temporal and spectral supra-threshold auditory tasks and speech in noise recognition in older adults with hearing impairment,2023,European Journal of Neuroscience,57,6,,981,1002,21,0,10.1111/ejn.15922,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148530953&doi=10.1111%2fejn.15922&partnerID=40&md5=b5e576f37eaaeb3505544a1f993a1e67,"Varying degrees of pure-tone hearing loss in older adults are differentially associated with cortical volume (CV) and thickness (CT) within and outside of the auditory pathway. This study addressed the question to what degree supra-threshold auditory performance (i.e., temporal compression and frequency selectivity) as well as speech in noise (SiN) recognition are associated with neurostructural correlates in a sample of 59 healthy older adults with mild to moderate pure-tone hearing loss. Using surface-based morphometry on T1-weighted MRI images, CT, CV, and surface area (CSA) of several regions-of-interest were obtained. The results showed distinct neurostructural patterns for the different tasks in terms of involved regions as well as morphometric parameters. While pure-tone averages (PTAs) positively correlated with CT in a right hemisphere superior temporal sulcus and gyrus cluster, supra-threshold auditory perception additionally extended significantly to CV and CT in left and right superior temporal clusters including Heschl's gyrus and sulcus, the planum polare and temporale. For SiN recognition, we found significant correlations with an auditory-related CT cluster and furthermore with language-related areas in the prefrontal cortex. Taken together, our results show that different auditory abilities are differently associated with cortical morphology in older adults with hearing impairment. Still, a common pattern is that greater PTAs and poorer supra-threshold auditory performance as well as poorer SiN recognition are all related to cortical thinning and volume loss but not to changes in CSA. These results support the hypothesis that mostly CT undergoes alterations in the context of auditory decline, while CSA remains stable. © 2023 University of Zurich and The Authors. European Journal of Neuroscience published by Federation of European Neuroscience Societies and John Wiley & Sons Ltd.",36683390,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85148530953
Ma H.-L.; Zeng T.-A.; Jiang L.; Zhang M.; Li H.; Su R.; Wang Z.-X.; Chen D.-M.; Xu M.; Xie W.-T.; Dang P.; Bu X.-O.; Zhang T.; Wang T.-Z.,"Ma, Hai-Lin (56963065600); Zeng, Tong-Ao (57230747200); Jiang, Lin (57213426796); Zhang, Mei (58069478000); Li, Hao (57218101707); Su, Rui (57231142700); Wang, Zhi-Xin (57212649332); Chen, Dong-Mei (57231142800); Xu, Meng (57681421600); Xie, Wen-Ting (57682528900); Dang, Peng (57229964500); Bu, Xiao-Ou (57229775500); Zhang, Tao (57222562787); Wang, Ting-Zhao (57190752067)",56963065600; 57230747200; 57213426796; 58069478000; 57218101707; 57231142700; 57212649332; 57231142800; 57681421600; 57682528900; 57229964500; 57229775500; 57222562787; 57190752067,Altered resting-state network connectivity patterns for predicting attentional function in deaf individuals: An EEG study,2023,Hearing Research,429,,108696,,,,3,10.1016/j.heares.2023.108696,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146478626&doi=10.1016%2fj.heares.2023.108696&partnerID=40&md5=8eeee9cb86e739cce6176e62b88a94bc,"Multiple aspects of brain development are influenced by early sensory loss such as deafness. Despite growing evidence of changes in attentional functions for prelingual profoundly deaf, the brain mechanisms underlying these attentional changes remain unclear. This study investigated the relationships between differential attention and the resting-state brain network difference in deaf individuals from the perspective of brain network connectivity. We recruited 36 deaf individuals and 34 healthy controls (HC). We recorded each participant's resting-state electroencephalogram (EEG) and the event-related potential (ERP) data from the Attention Network Test (ANT). The coherence (COH) method and graph theory were used to build brain networks and analyze network connectivity. First, the ERPs of analysis in task states were investigated. Then, we correlated the topological properties of the network functional connectivity with the ERPs. The results revealed a significant correlation between frontal-occipital connection in the resting state and the amplitude of alert N1 amplitude in the alpha band. Specifically, clustering coefficients and global and local efficiency correlate negatively with alert N1 amplitude, whereas the characteristic path length positively correlates with alert N1 amplitude. In addition, deaf individuals exhibited weaker frontal-occipital connections compared to the HC group. In executive control, the deaf group had longer reaction times and larger P3 amplitudes. However, the orienting function did not significantly differ from the HC group. Finally, the alert N1 amplitude in the ANT task for deaf individuals was predicted using a multiple linear regression model based on resting-state EEG network properties. Our results suggest that deafness affects the performance of alerting and executive control while orienting functions develop similarly to hearing individuals. Furthermore, weakened frontal-occipital connections in the deaf brain are a fundamental cause of altered alerting functions in the deaf. These results reveal important effects of brain networks on attentional function from the perspective of brain connections and provide potential physiological biomarkers to predicting attention. © 2023",36669260,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85146478626
Daikoku T.; Jentschke S.; Tsogli V.; Bergström K.; Lachmann T.; Ahissar M.; Koelsch S.,"Daikoku, Tatsuya (55318391800); Jentschke, Sebastian (14626220800); Tsogli, Vera (57208109499); Bergström, Kirstin (35195352800); Lachmann, Thomas (55971139300); Ahissar, Merav (6701696304); Koelsch, Stefan (7003503324)",55318391800; 14626220800; 57208109499; 35195352800; 55971139300; 6701696304; 7003503324,Neural correlates of statistical learning in developmental dyslexia: An electroencephalography study,2023,Biological Psychology,181,,108592,,,,2,10.1016/j.biopsycho.2023.108592,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161654769&doi=10.1016%2fj.biopsycho.2023.108592&partnerID=40&md5=d1e8574feb12a95fccd230d5576c9618,"The human brain extracts statistical regularities from the surrounding environment in a process called statistical learning. Behavioural evidence suggests that developmental dyslexia affects statistical learning. However, surprisingly few studies have assessed how developmental dyslexia affects the neural processing underlying this type of learning. We used electroencephalography to explore the neural correlates of an important aspect of statistical learning – sensitivity to transitional probabilities – in individuals with developmental dyslexia. Adults diagnosed with developmental dyslexia (n = 17) and controls (n = 19) were exposed to a continuous stream of sound triplets. Every so often, a triplet ending had a low transitional probability given the triplet's first two sounds (“statistical deviants”). Furthermore, every so often a triplet ending was presented from a deviant location (“acoustic deviants”). We examined mismatch negativity elicited by statistical deviants (sMMN), and MMN elicited by location deviants (i.e., acoustic changes). Acoustic deviants elicited a MMN which was larger in the control group than in the developmental dyslexia group. Statistical deviants elicited a small, yet significant, sMMN in the control group, but not in the developmental dyslexia group. However, the difference between the groups was not significant. Our findings indicate that the neural mechanisms underlying pre-attentive acoustic change detection and implicit statistical auditory learning are both affected in developmental dyslexia. © 2023 The Authors",37268263,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85161654769
Wu P.-Z.; Liberman L.D.; Liberman M.C.,"Wu, Pei-zhe (57195631460); Liberman, Leslie D. (37031396300); Liberman, M. Charles (7102934682)",57195631460; 37031396300; 7102934682,Noise-induced synaptic loss and its post-exposure recovery in CBA/CaJ vs. C57BL/6J mice,2024,Hearing Research,445,,108996,,,,0,10.1016/j.heares.2024.108996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189032230&doi=10.1016%2fj.heares.2024.108996&partnerID=40&md5=7fe7a6c113a5ffedfdf82d791da13459,"Acute noise-induced loss of synapses between inner hair cells (IHCs) and auditory nerve fibers (ANFs) has been documented in several strains of mice, but the extent of post-exposure recovery reportedly varies dramatically. If such inter-strain heterogeneity is real, it could be exploited to probe molecular pathways mediating neural remodeling in the adult cochlea. Here, we compared synaptopathy repair in CBA/CaJ vs. C57BL/6J, which are at opposite ends of the reported recovery spectrum. We evaluated C57BL/6J mice 0 h, 24 h, 2 wks or 8 wks after exposure for 2 h to octave-band noise (8–16 kHz) at either 90, 94 or 98 dB SPL, to compare with analogous post-exposure results in CBA/CaJ at 98 or 101 dB. We counted pre- and post-synaptic puncta in immunostained cochleas, using machine learning to classify paired (GluA2 and CtBP2) vs. orphan (CtBP2 only) puncta, and batch-processing to quantify immunostaining intensity. At 98 dB, both strains show ongoing loss of ribbons and synapses between 0 and 24 h, followed by partial recovery, however the extent and degree of these changes were greater in C57BL/6J. Much of the synaptic recovery is due to transient reduction in GluA2 intensity in synaptopathic regions. In contrast, CtBP2 intensity showed only transient increases (at 2 wks). Neurofilament staining revealed transient extension of ANF terminals in C57BL/6J, but not in CBA/CaJ, peaking at 24 h and reverting by 2 wks. Thus, although interstrain differences in synapse recovery are dominated by reversible changes in GluA2 receptor levels, the neurite extension seen in C57BL/6J suggests a qualitative difference in regenerative capacity. © 2024 Elsevier B.V.",38547565,Article,Final,,Scopus,2-s2.0-85189032230
Zeitler D.M.; Buchlak Q.D.; Ramasundara S.; Farrokhi F.; Esmaili N.,"Zeitler, Daniel M (15027983200); Buchlak, Quinlan D (55205971900); Ramasundara, Savindi (58496559700); Farrokhi, Farrokh (8415226600); Esmaili, Nazanin (56507041300)",15027983200; 55205971900; 58496559700; 8415226600; 56507041300,Predicting Acoustic Hearing Preservation Following Cochlear Implant Surgery Using Machine Learning,2024,Laryngoscope,134,2,,926,936,10,1,10.1002/lary.30894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165261527&doi=10.1002%2flary.30894&partnerID=40&md5=3cb7c070182baad6564f7c4f4e862f23,"Objectives: The aim of the study was to train and test supervised machine-learning classifiers to predict acoustic hearing preservation after CI using preoperative clinical data. Study Design: Retrospective predictive modeling study of prospectively collected single-institution CI dataset. Methods: One hundred and seventy-five patients from a REDCap database including 761 patients >18 years who underwent CI and had audiometric testing preoperatively and one month after surgery were included. The primary outcome variable was the lowest quartile change in acoustic hearing at one month after CI using various formulae (standard pure tone average, SPTA; low-frequency PTA, LFPTA). Analysis involved applying multivariate logistic regression to detect statistical associations and training and testing supervised learning classifiers. Classifier performance was assessed with numerous metrics including area under the receiver operating characteristic curve (AUC) and Matthews correlation coefficient (MCC). Results: Lowest quartile change (indicating hearing preservation) in SPTA was positively associated with a history of meningitis, preoperative LFPTA, and preoperative SPTA. Lowest quartile change in SPTA was negatively associated with sudden hearing loss, noise exposure, aural fullness, and abnormal anatomy. Lowest quartile change in LFPTA was positively associated with preoperative LFPTA. Lowest quartile change in LFPTA was negatively associated with tobacco use. Random forest demonstrated the highest mean classification performance on the validation dataset when predicting each of the outcome variables. Conclusions: Machine learning demonstrated utility for predicting preservation of residual acoustic hearing in patients undergoing CI surgery, and the detected associations facilitated the interpretation of our machine-learning models. The models and statistical associations together may be used to facilitate improvements in shared clinical decision-making and patient outcomes. Level of Evidence: 3 Laryngoscope, 134:926–936, 2024. © 2023 The American Laryngological, Rhinological and Otological Society, Inc.",37449725,Article,Final,,Scopus,2-s2.0-85165261527
Wang J.; Song Y.; Mao Z.; Liu J.; Gao Q.,"Wang, Junhui (58108962500); Song, Yu (57191511945); Mao, Zemin (57204600538); Liu, Junjie (57074204900); Gao, Qiang (56486664800)",58108962500; 57191511945; 57204600538; 57074204900; 56486664800,EEG-Based Emotion Identification Using 1-D Deep Residual Shrinkage Network With Microstate Features,2023,IEEE Sensors Journal,23,5,,5165,5174,9,3,10.1109/JSEN.2023.3239507,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148445529&doi=10.1109%2fJSEN.2023.3239507&partnerID=40&md5=c1bd3bd9fd1fc9341761843786648f53,"Previous studies on emotion identification from electroencephalogram (EEG) mostly focused on normal and depressed people. However, hearing-impaired subjects may require emotional identification due to their chronic lack of perception of auditory information. In this article, we designed an experiment to collect EEG signals from 15 hearing-impaired subjects when they are watching the four kinds of emotional movie clips (happiness, calmness, sadness, and fear). The novel K -means method is used to extract the ten kinds of microstates (as A, B, C, D, E, F, G, H, I, and J) from the raw EEG signal, and then the new EEG single will be retrofitted by those ten microstates. For feature extraction, six kinds of microstate features (global explained variance (GEV), GEV total (GEVT), global field power (GFP), coverage, duration, and occurrence) are calculated. To classify the microstate features, a 1-D deep residual shrinkage network (1-D-DRSN) is utilized, which can filter the emotional irrelevant noise information, and capture emotional representational information. Experimental results show that the proposed model can significantly improve performance compared with other machine learning methods, with an average accuracy of 87.48%. Moreover, we explore different combinations of microstate features to reduce redundant information, and the combination of occurrence, GEV, and coverage reaches 90.15%. From the exploration of each microstate, we find that microstate C has the advantage with an average accuracy of 49.07%.  © 2001-2012 IEEE.",,Article,Final,,Scopus,2-s2.0-85148445529
Lai J.; Alain C.; Bidelman G.M.,"Lai, Jesyin (56763272400); Alain, Claude (7006562076); Bidelman, Gavin M. (26325449700)",56763272400; 7006562076; 26325449700,Cortical-brainstem interplay during speech perception in older adults with and without hearing loss,2023,Frontiers in Neuroscience,17,,1075368,,,,1,10.3389/fnins.2023.1075368,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148353574&doi=10.3389%2ffnins.2023.1075368&partnerID=40&md5=4c327e1643791b7ed3e36fe8f0890018,"Introduction: Real time modulation of brainstem frequency-following responses (FFRs) by online changes in cortical arousal state via the corticofugal (top-down) pathway has been demonstrated previously in young adults and is more prominent in the presence of background noise. FFRs during high cortical arousal states also have a stronger relationship with speech perception. Aging is associated with increased auditory brain responses, which might reflect degraded inhibitory processing within the peripheral and ascending pathways, or changes in attentional control regulation via descending auditory pathways. Here, we tested the hypothesis that online corticofugal interplay is impacted by age-related hearing loss. Methods: We measured EEG in older adults with normal-hearing (NH) and mild to moderate hearing-loss (HL) while they performed speech identification tasks in different noise backgrounds. We measured α power to index online cortical arousal states during task engagement. Subsequently, we split brainstem speech-FFRs, on a trial-by-trial basis, according to fluctuations in concomitant cortical α power into low or high α FFRs to index cortical-brainstem modulation. Results: We found cortical α power was smaller in the HL than the NH group. In NH listeners, α-FFRs modulation for clear speech (i.e., without noise) also resembled that previously observed in younger adults for speech in noise. Cortical-brainstem modulation was further diminished in HL older adults in the clear condition and by noise in NH older adults. Machine learning classification showed low α FFR frequency spectra yielded higher accuracy for classifying listeners’ perceptual performance in both NH and HL participants. Moreover, low α FFRs decreased with increased hearing thresholds at 0.5–2 kHz for clear speech but noise generally reduced low α FFRs in the HL group. Discussion: Collectively, our study reveals cortical arousal state actively shapes brainstem speech representations and provides a potential new mechanism for older listeners’ difficulties perceiving speech in cocktail party-like listening situations in the form of a miss-coordination between cortical and subcortical levels of auditory processing. Copyright © 2023 Lai, Alain and Bidelman.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85148353574
Paglialonga A.; Polo E.M.; Lenatti M.; Mollura M.; Barbieri R.,"Paglialonga, Alessia (23668671800); Polo, Edoardo Maria (57213605525); Lenatti, Marta (57222472784); Mollura, Maximiliano (57204651438); Barbieri, Riccardo (35483096800)",23668671800; 57213605525; 57222472784; 57204651438; 35483096800,A Screening Platform for Hearing Loss and Cognitive Decline: WHISPER (Widespread Hearing Impairment Screening and PrEvention of Risk),2023,Studies in health technology and informatics,309,,,170,174,4,0,10.3233/SHTI230768,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175584899&doi=10.3233%2fSHTI230768&partnerID=40&md5=5eca15d33de88f98235dc1ddc89788a2,"The WHISPER (Widespread Hearing Impairment Screening and PrEvention of Risk) platform was recently developed for screening for hearing loss (HL) and cognitive decline in adults. It includes a battery of tests (a risk factors (RF) questionnaire, a language-independent speech-in-noise test, and cognitive tests) and provides a pass/fail outcome based on the analysis of several features. Earlier studies demonstrated high accuracy of the speech-in-noise test for predicting HL in 350 participants. In this study, preliminary results from the RF questionnaire (137 participants) and from the visual digit span test (DST) (78 participants) are presented. Despite the relatively small sample size, these findings indicate that the RF and DST may provide additional features that could be useful to characterize the overall individual profile, providing additional knowledge related to short-term memory performance and overall risk of HL and cognitive decline. Future research is needed to expand number of subjects tested, number of features analyzed, and the range of algorithms (including supervised and unsupervised machine learning) used to identify novel measures able to predict the individual hearing and cognitive abilities, also including components related to the individual risk.",37869833,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85175584899
Ma J.; Seo J.-H.; Moon I.J.; Park M.K.; Lee J.B.; Kim H.; Ahn J.H.; Jang J.H.; Lee J.D.; Choi S.J.; Hong M.,"Ma, Jun (57211282713); Seo, Jae-Hyun (48161796300); Moon, Il Joon (57968977800); Park, Moo Kyun (24559185500); Lee, Jong Bin (36600522600); Kim, Hantai (57192083561); Ahn, Joong Ho (55199119600); Jang, Jeong Hun (26639429600); Lee, Jong Dae (25722773400); Choi, Seong Jun (55502976600); Hong, Min (55431748700)",57211282713; 48161796300; 57968977800; 24559185500; 36600522600; 57192083561; 55199119600; 26639429600; 25722773400; 55502976600; 55431748700,Auditory Brainstem Response Data Preprocessing Method for the Automatic Classification of Hearing Loss Patients,2023,Diagnostics,13,23,3538,,,,0,10.3390/diagnostics13233538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178909011&doi=10.3390%2fdiagnostics13233538&partnerID=40&md5=8677485930e0576a8b29bdb00b0cce1a,"Auditory brainstem response (ABR) is the response of the brain stem through the auditory nerve. The ABR test is a method of testing for loss of hearing through electrical signals. Basically, the test is conducted on patients such as the elderly, the disabled, and infants who have difficulty in communication. This test has the advantage of being able to determine the presence or absence of objective hearing loss by brain stem reactions only, without any communication. This paper proposes the image preprocessing process required to construct an efficient graph image data set for deep learning models using auditory brainstem response data. To improve the performance of the deep learning model, we standardized the ABR image data measured on various devices with different forms. In addition, we applied the VGG16 model, a CNN-based deep learning network model developed by a research team at the University of Oxford, using preprocessed ABR data to classify the presence or absence of hearing loss and analyzed the accuracy of the proposed method. This experimental test was performed using 10,000 preprocessed data, and the model was tested with various weights to verify classification learning. Based on the learning results, we believe it is possible to help set the criteria for preprocessing and the learning process in medical graph data, including ABR graph data. © 2023 by the authors.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85178909011
Anjimoon S.; Swathi B.; Sobti R.; Kumar A.; Chauhan S.; Ali A.-J.A.; Bandhu D.,"Anjimoon, Shaik (58846821900); Swathi, B. (57655874800); Sobti, Rajeev (55561194200); Kumar, Ashwani (58493830200); Chauhan, Shilpi (57189259730); Ali, Abdul-Jabbar A. (58989617200); Bandhu, Din (58989507400)",58846821900; 57655874800; 55561194200; 58493830200; 57189259730; 58989617200; 58989507400,A Review on Enhancing Accessibility Through Image and Video Processing: Solutions for Differently Abled Individuals,2024,E3S Web of Conferences,505,,3007,,,,0,10.1051/e3sconf/202450503007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190614011&doi=10.1051%2fe3sconf%2f202450503007&partnerID=40&md5=38375a828387482680e82dd106b14862,"This paper presents innovative methodologies in image and video processing aimed at augmenting accessibility for differently abled individuals. Central to this research is the development of advanced algorithms that enable enhanced interpretation and interaction with multimedia content, thereby empowering users with sensory impairments. The study introduces a multi-layered framework that integrates adaptive filtering, object recognition, and augmented reality, tailored to the needs of users with visual and auditory challenges. Semantic scene analysis is leveraged to provide descriptive audio annotations for the visually impaired, facilitating a comprehensive understanding of visual data. For individuals with hearing impairments, the system incorporates real-time sign language interpretation within videos, utilizing deep learning techniques. The efficacy of these solutions is measured against conventional accessibility tools, demonstrating significant improvements in user engagement and comprehension. A novel contribution of this research is the application of machine learning to calibrate the system according to individual user profiles, ensuring a personalized and intuitive user experience. The scalability of the proposed system is validated through its implementation across various platforms and content formats. The findings suggest that such technological advancements have the potential to significantly reduce the barriers faced by differently abled individuals in accessing multimedia information. © The Authors, published by EDP Sciences.",,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85190614011
Lansbergen S.E.; Versfeld N.; Dreschler W.A.,"Lansbergen, Simon E. (57204176840); Versfeld, Niek (6602103494); Dreschler, Wouter A. (7003763918)",57204176840; 6602103494; 7003763918,Exploring Factors That Contribute to the Success of Rehabilitation With Hearing Aids,2023,Ear and Hearing,44,6,,1514,1525,11,1,10.1097/AUD.0000000000001393,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171258134&doi=10.1097%2fAUD.0000000000001393&partnerID=40&md5=49e1acbc83bcbb92a49395f4db39b431,"Objectives: Hearing aids are an essential and important part of hearing rehabilitation. The combination of technical data on hearing aids and individual rehabilitation needs can give insight into the factors that contribute to the success of rehabilitation. This study sets out to investigate if different subgroups of (comparable) hearing aids lead to differences in the success of rehabilitation, and whether these differences vary between different domains of auditory functioning. Design: This study explored the advantages of including patient-reported outcome measures (PROMs) in the process of purchasing new hearing aids in a large sample of successful hearing aid users. Subject data were obtained from 64 (commercial) hearing aid dispensers and 10 (noncommercial) audiological centers in the Netherlands. The PROM was a 32-item questionnaire and was used to determine the success of rehabilitation using hearing aids by measuring auditory disability over time. The items were mapped on six domains of auditory functioning: detection, discrimination, localization, speech in quiet, speech in noise, and noise tolerance, encompassing a variety of daily-life listening situations. Hearing aids were grouped by means of cluster analysis, resulting in nine subgroups. In total, 1149 subjects were included in this study. A general linear model was used to model the final PROM results. Model results were analyzed via a multifactor Analysis of Variance. Post hoc analyses provided detailed information on model variables. Results: Results showed a strong statistically significant effect of hearing aids on self-perceived auditory functioning in general. Clinically relevant differences were found for auditory domains including detection, speech in quiet, speech in noise, and localization. There was only a small, but significant, effect of the different subgroups of hearing aids on the final PROM results, where no differences were found between the auditory domains. Minor differences were found between results obtained in commercial and noncommercial settings, or between novice and experienced users. Severity of Hearing loss, age, gender, and hearing aid style (i.e., behind-the-ear versus receiver-in-canal type) did not have a clinically relevant effect on the final PROM results. Conclusions: The use of hearing aids has a large positive effect on self-perceived auditory functioning. There was however no salient effect of the different subgroups of hearing aids on the final PROM results, indicating that technical properties of hearing aids only play a limited role in this respect. This study challenges the belief that premium devices outperform basic ones, highlighting the need for personalized rehabilitation strategies and the importance of evaluating factors contributing to successful rehabilitation for clinical practice.  © 2023 Wolters Kluwer Health, Inc. All rights reserved.",37792897,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85171258134
Niu Y.; Li N.; Wu X.; Chen J.,"Niu, Yadong (57202442347); Li, Nan (58705804200); Wu, Xihong (7407061832); Chen, Jing (56039497900)",57202442347; 58705804200; 7407061832; 56039497900,A Model-Based Hearing Compensation Method Using a Self-Supervised Framework,2023,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",2023-June,,,,,,0,10.1109/ICASSP49357.2023.10095767,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177607364&doi=10.1109%2fICASSP49357.2023.10095767&partnerID=40&md5=f7ee61223c4185bf97b2edf14600e9a3,"Hearing aids can improve auditory perception for hearing-impaired (HI) listeners, but even state-of-art devices provide only limited benefits if not configured correctly for the listeners. The prescriptive fittings of hearing aids ignore the individual difference among HI listeners with identical hearing thresholds. This paper proposes a model-based hearing compensation method using a self-supervised framework with a given auditory model. The influence of outer/inner hair cells dysfunction was simulated in the auditory model. And then, a neural network was trained to compensate for the given hearing impairment. Both objective and subjective experiments were conducted to evaluate the present method, and the results showed that listeners are sensitive to the parameter controlling the contribution of outer hair cells dysfunction. Additionally, the result indicated that listeners significantly preferred the speech processed by the proposed method to the traditional perspective fitting. © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85177607364
Khalil R.M.; Papanicolaou A.; Chou R.T.; Gibbs B.E.; Anderson S.; Gordon-Salant S.; Cummings M.P.; Goupell M.J.,"Khalil, Rana M. (58706528800); Papanicolaou, Alexandra (58706235800); Chou, Renee Ti (57223239665); Gibbs, Bobby E. (57191266034); Anderson, Samira (36097687200); Gordon-Salant, Sandra (7003302144); Cummings, Michael P. (7202375094); Goupell, Matthew J. (6506799965)",58706528800; 58706235800; 57223239665; 57191266034; 36097687200; 7003302144; 7202375094; 6506799965,"Using Machine Learning to Understand the Relationships Between Audiometric Data, Speech Perception, Temporal Processing, And Cognition",2023,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",2023-June,,,,,,0,10.1109/ICASSP49357.2023.10095325,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177565730&doi=10.1109%2fICASSP49357.2023.10095325&partnerID=40&md5=c9606b5b0bba7fc70ac6bfc96227a5b7,"Aging and hearing loss cause communication difficulties, particularly for speech perception in demanding situations, which have been associated with factors including cognitive processing and extended high-frequency (>8 kHz) hearing. Quantifying such associations and finding other (possibly unintuitive) associations is well suited to machine learning. We constructed ensemble models for 443 participants who varied in age and hearing loss. Audiometric, perceptual, electrophysiological, and cognitive data were used to predict speech perception in noise, reverberation, and with time compression. Speech perception was best predicted by variables associated with audiometric thresholds (including new across-frequency composite variables) between 1-4 kHz, followed by basic temporal processing ability. Cognitive factors and extended high-frequency thresholds had little to no predictive ability of speech perception. Future associations or lack thereof will inform the field as we attempt to better understand the intertwined effects of speech perception, aging, hearing loss, and cognition. © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85177565730
Özyurt F.; Majidpour J.; Rashid T.A.; Majidpour A.; Koç C.,"Özyurt, Fatih (56780136900); Majidpour, Jafar (57188679418); Rashid, Tarik A. (57023479100); Majidpour, Amir (57226014739); Koç, Canan (58117537700)",56780136900; 57188679418; 57023479100; 57226014739; 58117537700,Multi-transfer learning techniques for detecting auditory brainstem response,2023,Applied Acoustics,212,,109604,,,,1,10.1016/j.apacoust.2023.109604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169794494&doi=10.1016%2fj.apacoust.2023.109604&partnerID=40&md5=2ce00f2e98518e0f55ff14a228ea252a,"The assessment of the well-being of the peripheral auditory nerve system in individuals experiencing hearing impairment is conducted through auditory brainstem response (ABR) testing. Audiologists assess and document the results of the ABR test. They interpret the findings and assign labels to them using reference-based markers like peak latency, waveform morphology, amplitude, and other relevant factors. Inaccurate assessment of ABR tests may lead to incorrect judgments regarding the integrity of the auditory nerve system; therefore, proper Hearing Loss (HL) diagnosis and analysis are essential. In order to identify and assess ABR automation while decreasing the possibility of human error, machine learning methods, notably deep learning, may be an appropriate option. To address these issues, this study proposed deep-learning models using the transfer-learning (TL) approach to extract features from ABR testing and diagnose HL using support vector machines (SVM). Pre-trained convolutional neural network (CNN) architectures like AlexNet, DenseNet, GoogleNet, InceptionResNetV2, InceptionV3, MobileNetV2, NASNetMobile, ResNet18, ResNet50, ResNet101, ShuffleNet, and SqueezeNet are used to extract features from the collected ABR reported images dataset in the proposed model. It has been decided to use six measures accuracy, precision, recall, geometric mean (GM), standard deviation (SD), and area under the ROC curve to measure the effectiveness of the proposed model. According to experimental findings, the ShuffleNet and ResNet50 models' TL is effective for ABR to diagnosis HL using an SVM classifier, with a high accuracy rate of 95% when using the 5-fold cross-validation method. © 2023 Elsevier Ltd",,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85169794494
Jeyalakshmi M.S.; Robin C.R.R.; Doreen D.,"Jeyalakshmi, M.S. (57193571737); Robin, C. R. Rene (57189274646); Doreen, D. (15837326600)",57193571737; 57189274646; 15837326600,Predicting cochlear implants score with the aid of reconfigured long short-term memory,2023,Multimedia Tools and Applications,82,8,,12537,12556,19,0,10.1007/s11042-022-13812-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138578989&doi=10.1007%2fs11042-022-13812-0&partnerID=40&md5=7c8e54bd88a0deaffb0731ad74322159,"A surgical procedure namely the Cochlear implantation aims in fitting the electronic device the cochlear implant. This electronic device helps person with moderate to severe hearing loss. It becomes very important to treat children with auditory deprivation much earlier, since it prohibits their language development skill too. This research aims to develop a model that can be used to guide Cochlear Implants (CI) programming for new patients in the children of 5 to 10 ages using visual cross modal data obtained from previously programmed patients. The cohort chosen is bilateral congenitally deaf children. This age group is selected since their language development is affected due to their auditory deprivations. The design is based on obtaining the analysis of cross modal plasticity using the visual evoked potential. AI based techniques, which is formed using the patient database. The goal is to use patients, real time database collected from the children and observe if it is likely to discover patterns in the data that can predict something about future patients. The resolution would be a program that can discover factors for the auditory deprived. The objective of this work is to apply Long Short-Term Memory (LSTM) network based Artificial Intelligence (AI) model to discover the unknown pattern. LSTM is suited to classify, process and predict time series given time lags of unknown duration. Relative insensitivity to gap length gives an advantage to LSTM over alternative RNNs. To augment an additional performance, the investigation comprises Enhanced Swarm based Crow Search Optimization (ESCSO) to identify optimal weights. The results exhibit the dominance of suggested ESCSO based LSTM technique over other techniques. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",,Article,Final,,Scopus,2-s2.0-85138578989
Yu T.; Li G.; Wang C.; Li N.; Yao R.; Wang J.,"Yu, Tingting (36437872600); Li, Guoqiang (57193223398); Wang, Chen (58110577600); Li, Niu (57069375900); Yao, Ruen (55428875700); Wang, Jian (57216509379)",36437872600; 57193223398; 58110577600; 57069375900; 55428875700; 57216509379,Defective Joint Development and Maintenance in GDF6-Related Multiple Synostoses Syndrome,2023,Journal of Bone and Mineral Research,38,4,,568,577,9,1,10.1002/jbmr.4785,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148510839&doi=10.1002%2fjbmr.4785&partnerID=40&md5=85323df807238e4cbe1bfaa67bfbda1a,"Multiple synostoses syndromes (SYNS) are a group of rare genetic bone disorders characterized by multiple joint fusions. We previously reported an SYNS4-causing GDF6 c.1330 T > A (p.Tyr444Asn) mutation, which reduced Noggin-induced GDF6 inhibition and enhanced SMAD1/5/8 signaling. However, the mechanisms by which GDF6 gain-of-function mutation alters joint formation and the comprehensive molecular portraits of SYNS4 remain unclear. Herein, we introduce the p.Tyr443Asn (orthologous to the human GDF6 p.Tyr444Asn) mutation into the mouse Gdf6 locus and report the results of extensive phenotype analysis, joint development investigation, and transcriptome profiling of Gdf6 p.Tyr443Asn limb buds. Gdf6 p.Tyr443Asn knock-in mice recapitulated the morphological features of human SYNS4, showing joint fusion in the wrists, ankles, phalanges, and auditory ossicles. Analysis of mouse embryonic forelimbs demonstrated joint interzone formation defects and excess chondrogenesis in Gdf6 p.Tyr443Asn knock-in mice. Further, RNA sequencing of forelimb buds revealed enhanced bone formation and upregulated bone morphogenetic protein (BMP) signaling in mice carrying the Gdf6 p.Tyr443Asn mutation. Because tightly regulated BMP signaling is critical for skeletal development and joint morphogenesis, our study shows that enhancing GDF6 activity has a significant impact on both prenatal joint development and postnatal joint maintenance. © 2023 American Society for Bone and Mineral Research (ASBMR). © 2023 American Society for Bone and Mineral Research (ASBMR).",36744814,Article,Final,,Scopus,2-s2.0-85148510839
Yang T.-H.; Chen Y.-F.; Cheng Y.-F.; Huang J.-N.; Wu C.-S.; Chu Y.-C.,"Yang, Tzong-Hann (37048107700); Chen, Yu-Fu (57197723841); Cheng, Yen-Fu (57202607130); Huang, Jue-Ni (58693264200); Wu, Chuan-Song (55619296714); Chu, Yuan-Chia (57202613011)",37048107700; 57197723841; 57202607130; 58693264200; 55619296714; 57202613011,Optimizing age-related hearing risk predictions: an advanced machine learning integration with HHIE-S,2023,BioData Mining,16,1,35,,,,0,10.1186/s13040-023-00351-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179959771&doi=10.1186%2fs13040-023-00351-z&partnerID=40&md5=5502ffad311c910efc6a24906a4b6fe8,"Objectives: The elderly are disproportionately affected by age-related hearing loss (ARHL). Despite being a well-known tool for ARHL evaluation, the Hearing Handicap Inventory for the Elderly Screening version (HHIE-S) has only traditionally been used for direct screening using self-reported outcomes. This work uses a novel integration of machine learning approaches to improve the predicted accuracy of the HHIE-S tool for ARHL in older adults. Methods: We employed a dataset that was gathered between 2016 and 2018 and included 1,526 senior citizens from several Taipei City Hospital branches. 80% of the data were used for training (n = 1220) and 20% were used for testing (n = 356). XGBoost, Gradient Boosting, and LightGBM were among the machine learning models that were only used and assessed on the training set. In order to prevent data leakage and overfitting, the Light Gradient Boosting Machine (LGBM) model—which had the greatest AUC of 0.83 (95% CI 0.81–0.85)—was then only used on the holdout testing data. Results: On the testing set, the LGBM model showed a strong AUC of 0.82 (95% CI 0.79–0.86), far outperforming conventional techniques. Notably, several HHIE-S items and age were found to be significant characteristics. In contrast to traditional HHIE research, which concentrates on the psychological effects of hearing loss, this study combines cutting-edge machine learning techniques—specifically, the LGBM classifier—with the HHIE-S tool. The incorporation of SHAP values enhances the interpretability of the model's predictions and provides a more comprehensive comprehension of the significance of various aspects. Conclusions: Our methodology highlights the great potential that arises from combining machine learning with validated hearing evaluation instruments such as the HHIE-S. Healthcare practitioners can anticipate ARHL more accurately thanks to this integration, which makes it easier to intervene quickly and precisely. © 2023, The Author(s).",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85179959771
Webster K.E.; George B.; Galbraith K.; Harrington-Benton N.A.; Judd O.; Kaski D.; Maarsingh O.R.; MacKeith S.; Ray J.; Van Vugt V.A.; Burton M.J.,"Webster, Katie E (57216874757); George, Ben (57191633203); Galbraith, Kevin (57194164532); Harrington-Benton, Natasha A (57392914200); Judd, Owen (27168804900); Kaski, Diego (6507711283); Maarsingh, Otto R (26423725400); MacKeith, Samuel (55663453800); Ray, Jaydip (58294704300); Van Vugt, Vincent A (57192376990); Burton, Martin J (35561613100)",57216874757; 57191633203; 57194164532; 57392914200; 27168804900; 6507711283; 26423725400; 55663453800; 58294704300; 57192376990; 35561613100,Positive pressure therapy for Ménière’s disease,2023,Cochrane Database of Systematic Reviews,2023,2,CD015248,,,,1,10.1002/14651858.CD015248.pub2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148772618&doi=10.1002%2f14651858.CD015248.pub2&partnerID=40&md5=0c5290d362b93db83551affaee386a4f,"Background: Ménière's disease is a condition that causes recurrent episodes of vertigo, associated with hearing loss and tinnitus. It is often treated with medication, but different interventions are sometimes used. Positive pressure therapy is a treatment that creates small pressure pulses, generated by a pump that is attached to tubing placed in the ear canal. It is typically used for a few minutes, several times per day. The underlying cause of Ménière's disease is unknown, as is the way in which this treatment may work. The efficacy of this intervention at preventing vertigo attacks, and their associated symptoms, is currently unclear. Objectives: To evaluate the benefits and harms of positive pressure therapy versus placebo or no treatment in people with Ménière's disease. Search methods: The Cochrane ENT Information Specialist searched the Cochrane ENT Register; CENTRAL; Ovid MEDLINE; Ovid Embase; Web of Science; ClinicalTrials.gov; ICTRP and additional sources for published and unpublished trials. The date of the search was 14 September 2022. Selection criteria: We included randomised controlled trials (RCTs) and quasi-RCTs in adults with a diagnosis of Ménière's disease comparing positive pressure therapy with either placebo or no treatment. We excluded studies with follow-up of less than three months. Data collection and analysis: We used standard Cochrane methods. Our primary outcomes were: 1) improvement in vertigo (assessed as a dichotomous outcome - improved or not improved), 2) change in vertigo (assessed as a continuous outcome, with a score on a numerical scale) and 3) serious adverse events. Our secondary outcomes were: 4) disease-specific health-related quality of life, 5) change in hearing, 6) change in tinnitus and 7) other adverse effects. We considered outcomes reported at three time points: 3 to < 6 months, 6 to ≤ 12 months and > 12 months. We used GRADE to assess the certainty of evidence for each outcome. Main results: We included three studies with a total of 238 participants, all of which compared positive pressure using the Meniett device to sham treatment. The duration of follow-up was a maximum of four months. Improvement in vertigo. A single study assessed whether participants had an improvement in the frequency of their vertigo whilst using positive pressure therapy, therefore we are unable to draw meaningful conclusions from the results. Change in vertigo. Only one study reported on the change in vertigo symptoms using a global score (at 3 to < 6 months), so we are again unable to draw meaningful conclusions from the numerical results. All three studies reported on the change in the frequency of vertigo. The summary effect showed that people receiving positive pressure therapy had, on average, 0.84 fewer days per month affected by vertigo (95% confidence interval from 2.12 days fewer to 0.45 days more; 3 studies; 202 participants). However, the evidence on the change in vertigo frequency was of very low certainty, therefore there is great uncertainty in this estimate. Serious adverse events. None of the included studies provided information on the number of people who experienced serious adverse events. It is unclear whether this is because no adverse events occurred, or whether they were not assessed and reported. Authors' conclusions: The evidence for positive pressure therapy for Ménière's disease is very uncertain. There are few RCTs that compare this intervention to placebo or no treatment, and the evidence that is currently available from these studies is of low or very low certainty. This means that we have very low confidence that the effects reported are accurate estimates of the true effect of these interventions. Consensus on the appropriate outcomes to measure in studies of Ménière's disease is needed (i.e. a core outcome set) in order to guide future studies in this area and enable meta-analyses of the results. This must include appropriate consideration of the potential harms of treatment, as well as the benefits. Copyright © 2023 The Authors. Cochrane Database of Systematic Reviews published by John Wiley & Sons, Ltd. on behalf of The Cochrane Collaboration.",36815713,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85148772618
Raji N.R.; Kumar R.M.S.; Biji C.L.,"Raji, N.R. (57227847500); Kumar, R. Mathusoothana S. (55966916700); Biji, C.L. (56584500800)",57227847500; 55966916700; 56584500800,Explainable Machine Learning Prediction for the Academic Performance of Deaf Scholars,2024,IEEE Access,12,,,23595,23612,17,0,10.1109/ACCESS.2024.3363634,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184809702&doi=10.1109%2fACCESS.2024.3363634&partnerID=40&md5=9ea4d201db2c0f31259f9f12e2537ae4,"Deaf and Hard of Hearing (DHH) students encounter obstacles in higher education due to language and communication challenges. Although research aims to improve their academic performance, the potential of Machine Learning (ML) remains underutilized in DHH education. The opacity of ML models further complicates their adoption. This study aims to fill this gap by developing a novel ML-based system with eXplainable AI (XAI), specifically utilizing Local Interpretable Model-Agnostic Explainer (LIME) and Shapley Additive Explainer (SHAP). The objective is twofold: predicting at-risk DHH students and explaining risk factors. Merging ML and XAI, this approach could positively impact DHH students' educational outcomes. A dataset of 454 records detailing DHH students is collected. To address dataset limitations, synthetic data and SMOTE are used. Students are categorized into three performance levels. The data is modeled with different ML models, transfer models, ensemble models, and combination models. Among the models, the stacked model with XGBoost, ExtraTrees, and Random Forest exhibited better performance with an accuracy of 92.99%. Results highlight the model's significance, providing insights through XAI into crucial factors affecting academic performance, including communication mode, early intervention, schooling type, and family deafness history. LIME and SHAP values were found to be effective in deriving insights into DHH student performance prediction framework. Communication mode, notably, strongly influences at-risk students. The major contribution of this study is the development of a novel ML-based system and the XAI interpretations whose value lies in its social relevance, guiding stakeholders to enhance DHH scholars' academic achievements.  © 2013 IEEE.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85184809702
Ni A.; Akbarzadeh S.; Lobarinas E.; Kehtarnavaz N.,"Ni, Aoxin (57223982896); Akbarzadeh, Sara (57188763859); Lobarinas, Edward (6506251900); Kehtarnavaz, Nasser (7006470206)",57223982896; 57188763859; 6506251900; 7006470206,Personalization of Hearing Aid Fitting Based on Adaptive Dynamic Range Optimization,2022,Sensors,22,16,6033,,,,3,10.3390/s22166033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136540750&doi=10.3390%2fs22166033&partnerID=40&md5=5b39022c8609593e534df2e37a2421b5,"Adaptive dynamic range optimization (ADRO) is a hearing aid fitting rationale which involves adjusting the gains in a number of frequency bands by using a series of rules. The rules reflect the comparison of the estimated percentile occurrences of the sound levels with the audibility and comfort hearing levels of a person suffering from hearing loss. In the study reported in this paper, a previously developed machine learning method was utilized to personalize the ADRO fitting in order to provide an improved hearing experience as compared to the standard ADRO hearing aid fitting. The personalization was carried out based on the user preference model within the framework of maximum likelihood inverse reinforcement learning. The testing of ten subjects with hearing loss was conducted, which indicated that the personalized ADRO was preferred over the standard ADRO on average by about 10 times. Furthermore, a word recognition experiment was conducted, which showed that the personalized ADRO had no adverse impact on speech understanding as compared to the standard ADRO. © 2022 by the authors.",36015791,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85136540750
Saak S.; Huelsmeier D.; Kollmeier B.; Buhl M.,"Saak, Samira (57221710992); Huelsmeier, David (57215435605); Kollmeier, Birger (7006746726); Buhl, Mareike (57207939883)",57221710992; 57215435605; 7006746726; 57207939883,A flexible data-driven audiological patient stratification method for deriving auditory profiles,2022,Frontiers in Neurology,13,,959582,,,,2,10.3389/fneur.2022.959582,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139042339&doi=10.3389%2ffneur.2022.959582&partnerID=40&md5=3de33e63527a27437abbaf567acc7165,"For characterizing the complexity of hearing deficits, it is important to consider different aspects of auditory functioning in addition to the audiogram. For this purpose, extensive test batteries have been developed aiming to cover all relevant aspects as defined by experts or model assumptions. However, as the assessment time of physicians is limited, such test batteries are often not used in clinical practice. Instead, fewer measures are used, which vary across clinics. This study aimed at proposing a flexible data-driven approach for characterizing distinct patient groups (patient stratification into auditory profiles) based on one prototypical database (N = 595) containing audiogram data, loudness scaling, speech tests, and anamnesis questions. To further maintain the applicability of the auditory profiles in clinical routine, we built random forest classification models based on a reduced set of audiological measures which are often available in clinics. Different parameterizations regarding binarization strategy, cross-validation procedure, and evaluation metric were compared to determine the optimum classification model. Our data-driven approach, involving model-based clustering, resulted in a set of 13 patient groups, which serve as auditory profiles. The 13 auditory profiles separate patients within certain ranges across audiological measures and are audiologically plausible. Both a normal hearing profile and profiles with varying extents of hearing impairments are defined. Further, a random forest classification model with a combination of a one-vs.-all and one-vs.-one binarization strategy, 10-fold cross-validation, and the kappa evaluation metric was determined as the optimal model. With the selected model, patients can be classified into 12 of the 13 auditory profiles with adequate precision (mean across profiles = 0.9) and sensitivity (mean across profiles = 0.84). The proposed approach, consequently, allows generating of audiologically plausible and interpretable, data-driven clinical auditory profiles, providing an efficient way of characterizing hearing deficits, while maintaining clinical applicability. The method should by design be applicable to all audiological data sets from clinics or research, and in addition be flexible to summarize information across databases by means of profiles, as well as to expand the approach toward aided measurements, fitting parameters, and further information from databases. Copyright © 2022 Saak, Huelsmeier, Kollmeier and Buhl.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85139042339
Chen J.; Gao D.; Sun L.; Yang J.,"Chen, Jianyong (56066229400); Gao, Dekun (57219695060); Sun, Lianhua (55988662400); Yang, Jun (55987387100)",56066229400; 57219695060; 55988662400; 55987387100,Kölliker’s organ-supporting cells and cochlear auditory development,2022,Frontiers in Molecular Neuroscience,15,,1031989,,,,2,10.3389/fnmol.2022.1031989,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140359894&doi=10.3389%2ffnmol.2022.1031989&partnerID=40&md5=b9c3a69fbdee9af39c97a5e1bee07365,"The Kölliker’s organ is a transient cellular cluster structure in the development of the mammalian cochlea. It gradually degenerates from embryonic columnar cells to cuboidal cells in the internal sulcus at postnatal day 12 (P12)–P14, with the cochlea maturing when the degeneration of supporting cells in the Kölliker’s organ is complete, which is distinct from humans because it disappears at birth already. The supporting cells in the Kölliker’s organ play a key role during this critical period of auditory development. Spontaneous release of ATP induces an increase in intracellular Ca2+ levels in inner hair cells in a paracrine form via intercellular gap junction protein hemichannels. The Ca2+ further induces the release of the neurotransmitter glutamate from the synaptic vesicles of the inner hair cells, which subsequently excite afferent nerve fibers. In this way, the supporting cells in the Kölliker’s organ transmit temporal and spatial information relevant to cochlear development to the hair cells, promoting fine-tuned connections at the synapses in the auditory pathway, thus facilitating cochlear maturation and auditory acquisition. The Kölliker’s organ plays a crucial role in such a scenario. In this article, we review the morphological changes, biological functions, degeneration, possible trans-differentiation of cochlear hair cells, and potential molecular mechanisms of supporting cells in the Kölliker’s organ during the auditory development in mammals, as well as future research perspectives. Copyright © 2022 Chen, Gao, Sun and Yang.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85140359894
Meng Q.; Chen J.; Zhang C.; Wasmann J.-W.A.; Barbour D.L.; Zeng F.-G.,"Meng, Qinglin (16064722600); Chen, Jing (56039497900); Zhang, Changxin (56294152300); Wasmann, Jan-Willem A. (57203991961); Barbour, Dennis L. (7003532294); Zeng, Fan-Gang (7202911218)",16064722600; 56039497900; 56294152300; 57203991961; 7003532294; 7202911218,Editorial: Digital hearing healthcare,2022,Frontiers in Digital Health,4,,959761,,,,0,10.3389/fdgth.2022.959761,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134993289&doi=10.3389%2ffdgth.2022.959761&partnerID=40&md5=1abd592681182e523e47fd74c5570265,[No abstract available],,Editorial,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85134993289
Hall D.A.; Talavage T.M.,"Hall, Deborah Ann (35229238900); Talavage, Thomas M. (6701846437)",35229238900; 6701846437,fMRI of the Central Auditory System,2023,"Functional Neuroradiology: Principles and Clinical Applications, Second Edition",,,,745,764,19,0,10.1007/978-3-031-10909-6_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173321668&doi=10.1007%2f978-3-031-10909-6_32&partnerID=40&md5=ac9677b54224cccea40dde7c1b59a32f,"Challenges for auditory fMRI include the intense scanner acoustic sound and the effects of the magnetic field on sound delivery equipment and on the electronic hearing devices critical to the study of individuals with hearing impairment. Despite these difficulties, a body of neuroimaging studies in humans provides evidence for plasticity in the auditory system and is therefore informative in the clinical context. This chapter presents several clinical applications of fMRI that investigate the processing of nonlinguistic and linguistic sound features. These include studies of the functional reorganization of the auditory system as a consequence of adaptation to hearing loss and its remediation through amplification and the assessment of candidature for cochlear implantation. While the chapter illustrates opportunities for auditory fMRI to supplement the clinical decision-making process, it also highlights specific areas where there is a current lack of understanding and makes recommendations for future clinical research. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",,Book chapter,Final,,Scopus,2-s2.0-85173321668
Vanjari H.B.; Kolte M.T.,"Vanjari, Hrishikesh B (57226597420); Kolte, Mahesh T (36107009000)",57226597420; 36107009000,Machine learning improvements to compressive sensing for speech enhancement in hearing aid applications,2022,World Journal of Engineering,19,2,,216,223,7,4,10.1108/WJE-06-2021-0324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112031073&doi=10.1108%2fWJE-06-2021-0324&partnerID=40&md5=0933abe54296b09bba3f39e10c6f93a7,"Purpose: Speech is the primary means of communication for humans. A proper functioning auditory system is needed for accurate cognition of speech. Compressed sensing (CS) is a method for simultaneous compression and sampling of a given signal. It is a novel method increasingly being used in many speech processing applications. The paper aims to use Compressive sensing algorithm for hearing aid applications to reduce surrounding noise. Design/methodology/approach: In this work, the authors propose a machine learning algorithm for improving the performance of compressive sensing using a neural network. Findings: The proposed solution is able to reduce the signal reconstruction time by about 21.62% and root mean square error of 43% compared to default L2 norm minimization used in CS reconstruction. This work proposes an adaptive neural network–based algorithm to enhance the compressive sensing so that it is able to reconstruct the signal in a comparatively lower time and with minimal distortion to the quality. Research limitations/implications: The use of compressive sensing for speech enhancement in a hearing aid is limited due to the delay in the reconstruction of the signal. Practical implications: In many digital applications, the acquired raw signals are compressed to achieve smaller size so that it becomes effective for storage and transmission. In this process, even unnecessary signals are acquired and compressed leading to inefficiency. Social implications: Hearing loss is the most common sensory deficit in humans today. Worldwide, it is the second leading cause for “Years lived with Disability” the first being depression. A recent study by World health organization estimates nearly 450 million people in the world had been disabled by hearing loss, and the prevalence of hearing impairment in India is around 6.3% (63 million people suffering from significant auditory loss). Originality/value: The objective is to reduce the time taken for CS reconstruction with minimal degradation to the reconstructed signal. Also, the solution must be adaptive to different characteristics of the signal and in presence of different types of noises. © 2021, Emerald Publishing Limited.",,Article,Final,,Scopus,2-s2.0-85112031073
Fan B.; Wang G.; Liu G.; Zhang X.; Wu W.,"Fan, Boya (57864673000); Wang, Gang (56063179000); Liu, Gang (58241663400); Zhang, Xiaoli (57221516568); Wu, Wei (56518514200)",57864673000; 56063179000; 58241663400; 57221516568; 56518514200,Whole-exome sequencing for screening noise-induced hearing loss susceptibility genes,2023,Acta Oto-Laryngologica,143,5,,408,415,7,0,10.1080/00016489.2023.2201287,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158821474&doi=10.1080%2f00016489.2023.2201287&partnerID=40&md5=e8c212c40cc027af85cfc02bffb40f0c,"Background: High-throughput sequencing of genes indicating susceptibility to noise-induced hearing loss has not previously been reported. Aims/Objectives: To identify and analyze genes associated with susceptibility to noise-induced hearing loss (NIHL) and characterize differences in susceptibility to hearing loss by genotype. Material and methods: Pure tone audiometry tests were performed on 113 workers exposed to high-intensity noise. Whole-exome sequencing (WES) was conducted and NIHL susceptibility genes screened for training unsupervised and supervised machine learning models. Immunofluorescence staining of mouse cochlea was used to observe patterns of NIHL susceptibility gene expression. Results: Participants were divided into a NIHL and a control group, according to the results of audiometry tests. Seventy-three possible NIHL susceptibility genes were input into the machine learning model. Two subgroups of NIHL could be distinguished by unsupervised machine learning and the classification was evaluated by the supervised machine learning algorithm. The VWF gene had the highest mutation frequency in the NIHL group and was expressed mainly in the spiral ligament. Conclusions and significance: NIHL susceptibility genes were screened and NIHL subgroups could be distinguished. VWF may be a novel NIHL susceptibility gene. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",37129226,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85158821474
Hong L.; Zeng Q.; Li K.; Luo X.; Xu X.; Liu X.; Li Z.; Fu Y.; Wang Y.; Zhang T.; Chen Y.; Liu Z.; Huang P.; Zhang M.,"Hong, Luwei (57450084900); Zeng, Qingze (57201924448); Li, Kaicheng (57194722932); Luo, Xiao (57145421400); Xu, Xiaopei (57196742467); Liu, Xiaocao (57219426997); Li, Zheyu (57218626267); Fu, Yanv (57219426429); Wang, Yanbo (58747706300); Zhang, Tianyi (57219426542); Chen, Yanxing (55455294300); Liu, Zhirong (57219212293); Huang, Peiyu (56067658500); Zhang, Minming (55507042800)",57450084900; 57201924448; 57194722932; 57145421400; 57196742467; 57219426997; 57218626267; 57219426429; 58747706300; 57219426542; 55455294300; 57219212293; 56067658500; 55507042800,Intrinsic Brain Activity of Inferior Temporal Region Increased in Prodromal Alzheimer's Disease With Hearing Loss,2022,Frontiers in Aging Neuroscience,13,,772136,,,,3,10.3389/fnagi.2021.772136,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124543313&doi=10.3389%2ffnagi.2021.772136&partnerID=40&md5=9637f4141117c14e1b63d4e52ebd4fb1,"Background and Objective: Hearing loss (HL) is one of the modifiable risk factors for Alzheimer's disease (AD). However, the underlying mechanism behind HL in AD remains elusive. A possible mechanism is cognitive load hypothesis, which postulates that over-processing of degraded auditory signals in the auditory cortex leads to deficits in other cognitive functions. Given mild cognitive impairment (MCI) is a prodromal stage of AD, untangling the association between HL and MCI might provide insights for potential mechanism behind HL. Methods: We included 85 cognitively normal (CN) subjects with no hearing loss (NHL), 24 CN with HL, 103 mild cognitive impairment (MCI) patients with NHL, and 23 MCI with HL from the ADNI database. All subjects underwent resting-state functional MRI and neuropsychological scale assessments. Fractional amplitude of low-frequency fluctuation (fALFF) was used to reflect spontaneous brain activity. The mixed-effects analysis was applied to explore the interactive effects between HL and cognitive status (GRF corrected, voxel p-value <0.005, cluster p-value < 0.05, two-tailed). Then, the FDG data was included to further reflect the regional neuronal abnormalities. Finally, Pearson correlation analysis was performed between imaging metrics and cognitive scores to explore the clinical significance (Bonferroni corrected, p < 0.05). Results: The interactive effects primarily located in the left superior temporal gyrus (STG) and bilateral inferior temporal gyrus (ITG). Post-hoc analysis showed that NC with HL had lower fALFF in bilateral ITG compared to NC with NHL. NC with HL had higher fALFF in the left STG and decreased fALFF in bilateral ITG compared to MCI with HL. In addition, NC with HL had lower fALFF in the right ITG compared to MCI with NHL. Correlation analysis revealed that fALFF was associated with MMSE and ADNI-VS, while SUVR was associated with MMSE, MoCA, ADNI-EF and ADNI-Lan. Conclusion: HL showed different effects on NC and MCI stages. NC had increased spontaneous brain activity in auditory cortex while decreased activity in the ITG. Such pattern altered with disease stage changing and manifested as decreased activity in auditory cortex along with increased activity in ITG in MCI. This suggested that the cognitive load hypothesis may be the underlying mechanism behind HL. Copyright © 2022 Hong, Zeng, Li, Luo, Xu, Liu, Li, Fu, Wang, Zhang, Chen, Liu, Huang and Zhang.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124543313
Byun H.; Park C.J.; Oh S.J.; Chung M.J.; Cho B.H.; Cho Y.-S.,"Byun, Hayoung (35754265000); Park, Chae Jung (57216547092); Oh, Seong Je (57386426600); Chung, Myung Jin (55728272500); Cho, Baek Hwan (57212056969); Cho, Yang-Sun (23471632700)",35754265000; 57216547092; 57386426600; 55728272500; 57212056969; 23471632700,Automatic Prediction of Conductive Hearing Loss Using Video Pneumatic Otoscopy and Deep Learning Algorithm,2022,Ear and Hearing,43,5,,1563,1573,10,7,10.1097/AUD.0000000000001217,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137124284&doi=10.1097%2fAUD.0000000000001217&partnerID=40&md5=fa2923ab949f14a1aa91f5e40d9a1826,"Objectives: Diseases of the middle ear can interfere with normal sound transmission, which results in conductive hearing loss. Since video pneumatic otoscopy (VPO) findings reveal not only the presence of middle ear effusions but also dynamic movements of the tympanic membrane and part of the ossicles, analyzing VPO images was expected to be useful in predicting the presence of middle ear transmission problems. Using a convolutional neural network (CNN), a deep neural network implementing computer vision, this preliminary study aimed to create a deep learning model that detects the presence of an air-bone gap, conductive component of hearing loss, by analyzing VPO findings. Design: The medical records of adult patients who underwent VPO tests and pure-tone audiometry (PTA) on the same day were reviewed for enrollment. Conductive hearing loss was defined as an average air-bone gap of more than 10 dB at 0.5, 1, 2, and 4 kHz on PTA. Two significant images from the original VPO videos, at the most medial position on positive pressure and the most laterally displaced position on negative pressure, were used for the analysis. Applying multi-column CNN architectures with individual backbones of pretrained CNN versions, the performance of each model was evaluated and compared for Inception-v3, VGG-16 or ResNet-50. The diagnostic accuracy predicting the presence of conductive component of hearing loss of the selected deep learning algorithm used was compared with experienced otologists. Results: The conductive hearing loss group consisted of 57 cases (mean air-bone gap = 25 ± 8 dB): 21 ears with effusion, 14 ears with malleus-incus fixation, 15 ears with stapes fixation including otosclerosis, one ear with a loose incus-stapes joint, 3 cases with adhesive otitis media, and 3 ears with middle ear masses including congenital cholesteatoma. The control group consisted of 76 cases with normal hearing thresholds without air-bone gaps. A total of 1130 original images including repeated measurements were obtained for the analysis. Of the various network architectures designed, the best was to feed each of the images into the individual backbones of Inception-v3 (three-column architecture) and concatenate the feature maps after the last convolutional layer from each column. In the selected model, the average performance of 10-fold cross-validation in predicting conductive hearing loss was 0.972 mean areas under the curve (mAUC), 91.6% sensitivity, 96.0% specificity, 94.4% positive predictive value, 93.9% negative predictive value, and 94.1% accuracy, which was superior to that of experienced otologists, whose performance had 0.773 mAUC and 79.0% accuracy on average. The algorithm detected over 85% of cases with stapes fixations or ossicular chain problems other than malleus-incus fixations. Visualization of the region of interest in the deep learning model revealed that the algorithm made decisions generally based on findings in the malleus and nearby tympanic membrane. Conclusions: In this preliminary study, the deep learning algorithm created to analyze VPO images successfully detected the presence of conductive hearing losses caused by middle ear effusion, ossicular fixation, otosclerosis, and adhesive otitis media. Interpretation of VPO using the deep learning algorithm showed promise as a diagnostic tool to differentiate conductive hearing loss from sensorineural hearing loss, which would be especially useful for patients with poor cooperation. © 2022 Lippincott Williams and Wilkins. All rights reserved.",35344974,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85137124284
Jamwal A.; Vasukidevi G.; Malleswari T.N.; Vijayakumar T.; Chandra Sekhar Reddy L.; Gupta A.S.A.L.G.G.,"Jamwal, Aryan (58068895800); Vasukidevi, G. (57222657121); Malleswari, Tyj Naga (56350010200); Vijayakumar, T. (57612782300); Chandra Sekhar Reddy, L. (57215910731); Gupta, Amara S A L G Gopala (57204590001)",58068895800; 57222657121; 56350010200; 57612782300; 57215910731; 57204590001,Real Time Conversion of American Sign Language to text with Emotion using Machine Learning,2022,"6th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud), I-SMAC 2022 - Proceedings",,,,603,609,6,1,10.1109/I-SMAC55078.2022.9987362,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146433127&doi=10.1109%2fI-SMAC55078.2022.9987362&partnerID=40&md5=d9e6cdc3fdf5121f8853ee57e04fed32,"Auditory impairment or hearing loss is a major problem in today's human population. Sign language helps hearing-impaired people to live their social life without much difficulty. The latest technology used in detecting sign language connects them to the rest of the world. Sign language recognition and conversion to the text based on the movement of hands and the shape formed by the fingers is a complex system. The solutions using machine learning give significant success for this complex system. This paper mainly focuses on developing a system for recognizing the different hand signs in American Sign Language and their emotions simultaneously in real-time and converting them into text. The system resolves the need for a translator to bridge the gap between a sign language based user and a non-sign language-based user. Most state-of-the-art technology involves CNN models with image pixels by identifying specific key point coordinates on the face/hand obtained. Using the latest technologies like MediaPipe, an improved CNN model is developed based on the distances between each unique identified vital point. The customized model able to achieve 80 percentage of accuracy for the live image.  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85146433127
Jiang Y.; Zhang Y.; Ning C.; Ji Q.; Peng X.; Dong K.; Wang Z.L.,"Jiang, Yang (57217676669); Zhang, Yufei (57200566758); Ning, Chuan (57194686732); Ji, Qingqing (57449569300); Peng, Xiao (57210319902); Dong, Kai (22957078900); Wang, Zhong Lin (56430045300)",57217676669; 57200566758; 57194686732; 57449569300; 57210319902; 22957078900; 56430045300,Ultrathin Eardrum-Inspired Self-Powered Acoustic Sensor for Vocal Synchronization Recognition with the Assistance of Machine Learning,2022,Small,18,13,2106960,,,,41,10.1002/smll.202106960,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124489145&doi=10.1002%2fsmll.202106960&partnerID=40&md5=b4fe9e4c6255e68280f9f715dd5d1562,"With the rapid development of human–machine interfaces, artificial acoustic sensors play an important role in the hearing impaired. Here, an ultrathin eardrum-like triboelectric acoustic sensor (ETAS) is presented consisting of silver-coated nanofibers, whose thickness is only 40 µm. The sensitivity and frequency response range of the ETAS are closely related to the geometric parameters. The ETAS endows a high sensitivity of 228.5 mV Pa−1 at 95 dB, and the ETAS has a broad frequency response ranging from 20 to 5000 Hz, which can be tuned by adjusting the thickness, size, or shape of the sensor. Cooperating with artificial intelligence (AI) algorithms, the ETAS can achieve real-time voice conversion with a high identification accuracy of 92.64%. Under good working property and the AI system, the ETAS simplifies signal processing and reduces the power consumption. This work presents a strategy for self-power auditory systems, which can greatly accelerate the miniaturization of self-powered systems used in wearable electronics, augmented reality, virtual reality, and control hubs for automation. © 2022 Wiley-VCH GmbH.",35122473,Article,Final,,Scopus,2-s2.0-85124489145
Manno F.A.M.; Cheung P.; Basnet V.; Khan M.S.; Mao Y.; Pan L.; Ma V.; Cho W.C.; Tian S.; An Z.; Feng Y.; Cai Y.-L.; Pienkowski M.; Lau C.,"Manno, Francis A. M. (57202875443); Cheung, Pikting (58485020700); Basnet, Vardhan (58571090400); Khan, Muhammad Shehzad (57216360160); Mao, Yuqi (57205266400); Pan, Leilei (56647356400); Ma, Victor (6603826421); Cho, William C. (58556411300); Tian, Shile (58571475300); An, Ziqi (57237406500); Feng, Yanqiu (34770789700); Cai, Yi-Ling (36985178400); Pienkowski, Martin (56265406600); Lau, Condon (15073292200)",57202875443; 58485020700; 58571090400; 57216360160; 57205266400; 56647356400; 6603826421; 58556411300; 58571475300; 57237406500; 34770789700; 36985178400; 56265406600; 15073292200,Subtle alterations of vestibulomotor functioning in conductive hearing loss,2023,Frontiers in Neuroscience,17,,1057551,,,,0,10.3389/fnins.2023.1057551,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170576571&doi=10.3389%2ffnins.2023.1057551&partnerID=40&md5=62d2b043c28a375aa6fbcf30189ec156,"Introduction: Conductive hearing loss (CHL) attenuates the ability to transmit air conducted sounds to the ear. In humans, severe hearing loss is often accompanied by alterations to other neural systems, such as the vestibular system; however, the inter-relations are not well understood. The overall goal of this study was to assess vestibular-related functioning proxies in a rat CHL model. Methods: Male Sprague–Dawley rats (N=134, 250g, 2months old) were used in a CHL model which produced a >20dB threshold shift induced by tympanic membrane puncture. Auditory brainstem response (ABRs) recordings were used to determine threshold depth at different times before and after CHL. ABR threshold depths were assessed both manually and by an automated ABR machine learning algorithm. Vestibular-related functioning proxy assessment was performed using the rotarod, balance beam, elevator vertical motion (EVM) and Ferris-wheel rotation (FWR) assays. Results: The Pre-CHL (control) threshold depth was 27.92dB±11.58dB compared to the Post-CHL threshold depth of 50.69dB±13.98dB (mean±SD) across the frequencies tested. The automated ABR machine learning algorithm determined the following threshold depths: Pre-CHL=24.3dB, Post-CHL same day=56dB, Post-CHL 7 days=41.16dB, and Post-CHL 1 month=32.5dB across the frequencies assessed (1, 2, 4, 8, 16, and 32kHz). Rotarod assessment of motor function was not significantly different between pre and post-CHL (~1week) rats for time duration (sec) or speed (RPM), albeit the former had a small effect size difference. Balance beam time to transverse was significantly longer for post-CHL rats, likely indicating a change in motor coordination. Further, failure to cross was only noted for CHL rats. The defection count was significantly reduced for CHL rats compared to control rats following FWR, but not EVM. The total distance traveled during open-field examination after EVM was significantly different between control and CHL rats, but not for FWR. The EVM is associated with linear acceleration (acting in the vertical plane: up-down) stimulating the saccule, while the FWR is associated with angular acceleration (centrifugal rotation about a circular axis) stimulating both otolith organs and semicircular canals; therefore, the difference in results could reflect the specific vestibular-organ functional role. Discussion: Less movement (EVM) and increase time to transverse (balance beam) may be associated with anxiety and alterations to defecation patterns (FWR) may result from autonomic disturbances due to the impact of hearing loss. In this regard, vestibulomotor deficits resulting in changes in balance and motion could be attributed to comodulation of auditory and vestibular functioning. Future studies should manipulate vestibular functioning directly in rats with CHL. Copyright © 2023 Manno, Cheung, Basnet, Khan, Mao, Pan, Ma, Cho, Tian, An, Feng, Cai, Pienkowski and Lau.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85170576571
Jedlicka D.; Zhen L.,"Jedlicka, David (57202414417); Zhen, Leslie (58151482800)",57202414417; 58151482800,PTSD is associated with self-perceived hearing handicap: An evaluation of comorbidities in Veterans with normal audiometric thresholds,2023,Journal of the American Academy of Audiology,,,,,,,0,10.1055/a-2015-8524,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161535553&doi=10.1055%2fa-2015-8524&partnerID=40&md5=2404e5f9c9d7ebe1a63b53e8d8710371,"Background Cases of self-reported hearing difficulty despite normal audiometric results have risen with the return of Veterans from recent conflicts in Operation Enduring Freedom, Operation Iraqi Freedom, and Operation New Dawn. Auditory outcomes improved despite low compliance among those receiving treatment. Medical chart data appeared more comprehensive for Veterans with, rather than without, auditory complaints. One possibility is that self-reported hearing problems are associated with a subset of these comorbidities, the treatment of which improved auditory outcomes. Purpose This study examined the relationships between Veterans' self-reported auditory problems and other diagnosed medical conditions. Research Design A retrospective chart review was used. Study Sample Participants were 286 Veterans, aged 21 - 52 with normal hearing. Veterans were dichotomized into a group with either self-reported hearing complaints (n = 143) or an aged-matched control group with no auditory complaints (n = 143). Data Collection and Analysis A query of the Computerized Patient Record System was performed with the date range restricted to 2009 to 2018. Metrics of self-perceived hearing handicap, APD testing, and hearing aid use were collected. All diagnoses and related symptoms were recorded. A best subsets regression with principled model selection was performed to investigate the role of these comorbidities on self-perceived hearing loss. Results The Self-Report group had 16 comorbidities that were classified as prevalent, having occurred in ≥33.3% of the group, compared to the age-matched control group, which had 2 comorbidities. The number of diagnosed medical conditions was associated with self-perceived hearing impairment. Specifically, posttraumatic stress disorder (PTSD) and related symptom clusters constituted the largest group of comorbidities that were significantly associated with self-reported hearing problems. Conclusions The significant association between PTSD and self-perceived hearing impairment warrants investigations on whether treatment of PTSD would reduce perceived hearing handicap severity. Further, PTSD assessments could be useful for audiologists to identify potential candidates for auditory complaints with normal audiometric thresholds. © 2021 American Academy of Audiology. All rights reserved.",36657469,Article,Article in press,,Scopus,2-s2.0-85161535553
Gopinath A.; Akshitha H.; Loomba A.; Kumar R.; Narayanappa C.K.,"Gopinath, Anagha (58145543700); Akshitha, H. (58145543800); Loomba, Arshya (58144543400); Kumar, Ranveer (58263560600); Narayanappa, C.K. (57201853656)",58145543700; 58145543800; 58144543400; 58263560600; 57201853656,Data Driven Machine Learning Model for Audiometric Threshold classification,2022,"4th International Conference on Circuits, Control, Communication and Computing, I4C 2022",,,,236,239,3,0,10.1109/I4C57141.2022.10057711,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150260862&doi=10.1109%2fI4C57141.2022.10057711&partnerID=40&md5=396b64e3af8cf0a2c580d424af30ed3e,"Hearing loss is defined as the inability to hear partially or completely, in one or both the ears. It is present in people of all age groups. The continuous exposure to noise in today's world, aging and congenital defects are leading causes of hearing loss. Hearing loss can be present in new born as a result of maternal infections during pregnancy, complications after birth and head trauma. This study will develop a model to estimate the degree of Hearing loss of a sample set of people in the 18-22 age group. The hearing loss was calculated based on the intensity threshold values that was generated by the Smartphone mobile application-based hearing test [1] [2]. This threshold value was compared with the standard audiometric table to classify the sample set into two groups. Support Vector Machine (SVM) was used for building the binary classification model. The Support Vector Machine searches for an optimum hyperplane to classify the two groups. It uses the extreme points, termed as support vectors, to create the hyperplane. The hyperplane is created so as to maximize the margin, which is the distance between the hyperplane and the support vectors. The support vector machine algorithm supports different kernels for building a model. Three different kernels - Linear kernel, Polynomial kernel and Radial Basis function were used with three different training set sizes - 80% training size, 75% training size and 70% training size to select a model of high accuracy. The model with the highest accuracy was tested, and the confusion matrix of the test set data is obtained to verify the results. A classification report provides the values of Precision, Recall and F1 score to assess the quality of the model developed.  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85150260862
Munoz Musat E.; Rohaut B.; Sangare A.; Benhaiem J.-M.; Naccache L.,"Munoz Musat, Esteban (57204760868); Rohaut, Benjamin (12647565300); Sangare, Aude (56531643000); Benhaiem, Jean-Marc (6506570573); Naccache, Lionel (6603997168)",57204760868; 12647565300; 56531643000; 6506570573; 6603997168,Hypnotic Induction of Deafness to Elementary Sounds: An Electroencephalography Case-Study and a Proposed Cognitive and Neural Scenario,2022,Frontiers in Neuroscience,16,,756651,,,,1,10.3389/fnins.2022.756651,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127951199&doi=10.3389%2ffnins.2022.756651&partnerID=40&md5=d5bc981cff65c7483603bf2da3fdfb65,"Hypnosis can be conceived as a unique opportunity to explore how top-down effects can influence various conscious and non-conscious processes. In the field of perception, such modulatory effects have been described in distinct sensory modalities. In the present study we focused on the auditory channel and aimed at creating a radical deafness to elementary sounds by a specific hypnotic suggestion. We report here a single case-study in a highly suggestible healthy volunteer who reported a total hypnotically suggested deafness. We recorded high-density scalp EEG during an auditory odd-ball paradigm before and after hypnotic deafness suggestion. While both early auditory event-related potentials to sounds (P1) and mismatch negativity component were not affected by hypnotic deafness, we observed a total disappearance of the late P3 complex component when the subject reported being deaf. Moreover, a centro-mesial positivity was present exclusively during the hypnotic condition prior to the P3 complex. Interestingly, source localization suggested an anterior cingulate cortex (ACC) origin of this neural event. Multivariate decoding analyses confirmed and specified these findings. Resting state analyses confirmed a similar level of conscious state in both conditions, and suggested a functional disconnection between auditory areas and other cortical areas. Taken together these results suggest the following plausible scenario: (i) preserved early processing of auditory information unaffected by hypnotic suggestion, (ii) conscious setting of an inhibitory process (ACC) preventing conscious access to sounds, (iii) functional disconnection between the modular and unconscious representations of sounds and global neuronal workspace. This single subject study presents several limits that are discussed and remains open to alternative interpretations. This original proof-of-concept paves the way to a larger study that will test the predictions stemming from our theoretical model and from this first report. Copyright © 2022 Munoz Musat, Rohaut, Sangare, Benhaiem and Naccache.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85127951199
Yang H.; Liu Z.; Chen D.; Lin W.; Wang L.; Chen T.; Wang R.; Yan X.,"Yang, Hansong (57895023400); Liu, Zhiyong (57316653700); Chen, Dongmei (56906378100); Lin, Weiru (58734402600); Wang, Lin (58457258600); Chen, Tianfeng (57895258900); Wang, Ruiquan (56469951500); Yan, Xialin (57894538300)",57895023400; 57316653700; 56906378100; 58734402600; 58457258600; 57895258900; 56469951500; 57894538300,Detection of a novel SETBP1 variant in a Chinese neonate with Schinzel–Giedion syndrome,2022,Frontiers in Pediatrics,10,,920741,,,,2,10.3389/fped.2022.920741,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138250452&doi=10.3389%2ffped.2022.920741&partnerID=40&md5=ca9cc625daf324befd6a1ccd2524287f,"Schinzel–Giedion syndrome (SGS) is a multiple malformation syndrome characterized by typical facial features, severe neurodevelopmental delay, and multiple congenital abnormalities. SGS is associated with de novo pathogenic variants in the SETBP1 gene. In specific, SETBP1 variants in over 50 patients with classical or non-classical SGS were clustered within exon 4. A male Chinese neonate with dysmorphic facial features, nervous system disorders, and organ malformations at birth was examined in this study and long-term followed-up. Whole-exome sequencing was performed to identify any underlying pathogenic variants in the proband. Additionally, we reviewed the literature that documents the main clinical features and underlying variants of all patients genetically diagnosed with SGS. The neonate had a characteristic midface retraction, abnormal electroencephalogram waveforms, and genital abnormalities. The patient did not initially develop hydronephrosis or undergo a comprehensive skeletal assessment. Six months after birth, the patient had an epileptic seizure and experienced persistent neurodevelopmental delay with auditory and visual abnormalities. Color Doppler ultrasonography at 18 months revealed hydronephrosis and bilateral widening of the lateral ventricles. The patient died suddenly 20.5 months after birth. Whole-exome sequencing revealed a heterozygous de novo variant (c.2605A > G:p.S869G) in exon 4 degradation sequence in SETBP1. The reported de novo heterozygous variant in SETBP1 (c.2605A > G:p.S869G) broadens the knowledge of the scientific community's on the possible SGS genetic alterations. To the best of our knowledge, this is the first report of SETBP1 variant (c.2605A > G:p.S869G) in SGS. The clinical manifestations of neonatal SGS are atypical, and genetic testing is crucial for diagnosis. Long-term follow-up should be conducted after diagnosis to optimize the therapeutic interventions. Copyright © 2022 Yang, Liu, Chen, Lin, Wang, Chen, Wang and Yan.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85138250452
Krey J.F.; Liu C.; Belyantseva I.A.; Bateschell M.; Dumont R.A.; Goldsmith J.; Chatterjee P.; Morrill R.S.; Fedorov L.M.; Foster S.; Kim J.; Nuttall A.; Jones S.M.; Choi D.; Friedman T.; Ricci A.J.; Zhao B.; Barr-Gillespie P.G.,"Krey, Jocelyn F. (55555401100); Liu, Chang (57204292122); Belyantseva, Inna A. (6602138727); Bateschell, Michael (55744450800); Dumont, Rachel A. (7004651592); Goldsmith, Jennifer (57456419100); Chatterjee, Paroma (57213824581); Morrill, Rachel S. (57456591800); Fedorov, Lev M. (7005800968); Foster, Sarah (56372791200); Kim, Jinkyung (57190754141); Nuttall, Alfredl. (7102583079); Jones, Sherri M. (7405937017); Choi, Dongseok (12791685600); Friedman, Thomasb. (34569115500); Ricci, Anthony J. (57202614718); Zhao, Bo (55520451000); Barr-Gillespie, Peter G. (7005143141)",55555401100; 57204292122; 6602138727; 55744450800; 7004651592; 57456419100; 57213824581; 57456591800; 7005800968; 56372791200; 57190754141; 7102583079; 7405937017; 12791685600; 34569115500; 57202614718; 55520451000; 7005143141,ANKRD24 organizes TRIOBP to reinforce stereocilia insertion points,2022,Journal of Cell Biology,221,4,e202109134,,,,5,10.1083/jcb.202109134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124779761&doi=10.1083%2fjcb.202109134&partnerID=40&md5=f92f52a453f55c18b454545ef246ccf8,"The stereocilia rootlet is a key structure in vertebrate hair cells, anchoring stereocilia firmly into the cell’s cuticular plate and protecting them from overstimulation. Using superresolution microscopy, we show that the ankyrin-repeat protein ANKRD24 concentrates at the stereocilia insertion point, forming a ring at the junction between the lower and upper rootlets. Annular ANKRD24 continues into the lower rootlet, where it surrounds and binds TRIOBP-5, which itself bundles rootlet F-actin. TRIOBP-5 is mislocalized in Ankrd24KO/KO hair cells, and ANKRD24 no longer localizes with rootlets in mice lacking TRIOBP-5; exogenous DsRed–TRIOBP-5 restores endogenous ANKRD24 to rootlets in these mice. Ankrd24KO/KO mice show progressive hearing loss and diminished recovery of auditory function after noise damage, as well as increased susceptibility to overstimulation of the hair bundle. We propose that ANKRD24 bridges the apical plasma membrane with the lower rootlet, maintaining a normal distribution of TRIOBP-5. Together with TRIOBP-5, ANKRD24 organizes rootlets to enable hearing with long-term resilience. © 2022 Krey et al. This article is available under a Creative Commons License (Attribution 4.0 International, as described at https://creativecommons.org/licenses/by/4.0/).",35175278,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85124779761
Schilling A.; Gerum R.; Metzner C.; Maier A.; Krauss P.,"Schilling, Achim (57189988281); Gerum, Richard (55990645300); Metzner, Claus (7006045419); Maier, Andreas (23392966100); Krauss, Patrick (55216351100)",57189988281; 55990645300; 7006045419; 23392966100; 55216351100,Intrinsic Noise Improves Speech Recognition in a Computational Model of the Auditory Pathway,2022,Frontiers in Neuroscience,16,,908330,,,,12,10.3389/fnins.2022.908330,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133383904&doi=10.3389%2ffnins.2022.908330&partnerID=40&md5=e75f7b0a3d155d2238aebcec12c39525,"Noise is generally considered to harm information processing performance. However, in the context of stochastic resonance, noise has been shown to improve signal detection of weak sub- threshold signals, and it has been proposed that the brain might actively exploit this phenomenon. Especially within the auditory system, recent studies suggest that intrinsic noise plays a key role in signal processing and might even correspond to increased spontaneous neuronal firing rates observed in early processing stages of the auditory brain stem and cortex after hearing loss. Here we present a computational model of the auditory pathway based on a deep neural network, trained on speech recognition. We simulate different levels of hearing loss and investigate the effect of intrinsic noise. Remarkably, speech recognition after hearing loss actually improves with additional intrinsic noise. This surprising result indicates that intrinsic noise might not only play a crucial role in human auditory processing, but might even be beneficial for contemporary machine learning approaches. Copyright © 2022 Schilling, Gerum, Metzner, Maier and Krauss.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85133383904
Fan Z.; Fan Z.; Qiu T.; Hu L.; Shi Y.; Xia Y.; Sun X.; Liu Y.; Li S.; Xia M.; Zhu W.,"Fan, Zhiyuan (57202302379); Fan, Zhen (57203592877); Qiu, Tianming (26032289800); Hu, Liuxun (57982756400); Shi, Yuan (57200033970); Xia, Yunman (57195149864); Sun, Xiaoyi (57205696374); Liu, Yingjun (57061915900); Li, Sichen (57200800469); Xia, Mingrui (36774094500); Zhu, Wei (57191095662)",57202302379; 57203592877; 26032289800; 57982756400; 57200033970; 57195149864; 57205696374; 57061915900; 57200800469; 36774094500; 57191095662,Altered topological properties of the intrinsic functional brain network in patients with right-sided unilateral hearing loss caused by acoustic neuroma,2022,Brain Imaging and Behavior,16,4,,1873,1883,10,4,10.1007/s11682-022-00658-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127681145&doi=10.1007%2fs11682-022-00658-1&partnerID=40&md5=ade3e050b831f31a658c11f1e09410ff,"Neuroimaging studies have identified alterations in functional connectivity between specific brain regions in patients with unilateral hearing loss (UHL) and different influence of the side of UHL on neural plasticity. However, little is known about changes of whole-brain functional networks in patients with UHL and whether differences exist in topological organization between right-sided UHL (RUHL) and left-sided UHL (LUHL). To address this issue, we employed resting-state fMRI (rs-fMRI) and graph-theoretical approaches to investigate the topological alterations of brain functional connectomes in patients with RUHL and LUHL. Data from 44 patients with UHL (including 22 RUHL patients and 22 LUHL patients) and 37 healthy control subjects (HCs) were collected. Functional brain networks were constructed for each participant, following by graph-theoretical network analyses at connectional and global (e.g., small-worldness) levels. The correlations between brain network topologies and clinical variables were further studied. Using network-based analysis, we found a subnetwork in the visual cortex which had significantly lower connectivity strength in patients with RUHL as compared to HCs. At global level, all participants showed small-world architecture in functional brain networks, however, significantly lower normalized clustering coefficient and small-worldness were observed in patients with RUHL than in HCs. Moreover, these abnormal network metrics were demonstrated to be correlated with the clinical variables and cognitive performance of patients with RUHL. Notably, no significant alterations in the functional brain networks were found in patients with LUHL. Our findings demonstrate that RUHL (rather than LUHL) is accompanied with aberrant topological organization of the functional brain connectome, indicating different pathophysiological mechanisms between RUHL and LUHL from a viewpoint of network topology. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",35397062,Article,Final,,Scopus,2-s2.0-85127681145
Bajwa M.S.; Gandhi G.C.,"Bajwa, Manpreet Singh (57170114600); Gandhi, Geeta Chhabra (57425010000)",57170114600; 57425010000,A Systematic Review of Machine Learning Approaches for Classifying Indian Sign Language Gestures and Facial Expressions,2022,"4th International Conference on Inventive Research in Computing Applications, ICIRCA 2022 - Proceedings",,,,848,853,5,0,10.1109/ICIRCA54612.2022.9985747,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146492330&doi=10.1109%2fICIRCA54612.2022.9985747&partnerID=40&md5=bfdcef79beb58b2515c096a533e83347,"Indian Sign Language is the primary mode of communication known to persons who use Indian Sign Language for people who have hearing or language deficits. Different types of machine learning models are used to broaden the scope of communication for those with impairments and illiteracy. There are numerous machine learning models for analyzing gestures, postures, and facial recognition in Indian Sign Language for single-handed and double-handed signals. The present study on hand gestures, recognition, and translation intends to build an essential foundation for developing a platform to facilitate communication for the s pecially-abled with anyone. Machine learning algorithms generally focus on letter recognition or a few fundamental indicators. Communication is essential for exchanging ideas, thoughts, and feelings. Sign language is a kind of communication that uses hand motions. This is aimed toward those with impairments such as muteness and deafness. Machine learning, a branch of artificial intelligence, will aid in identifying various hand motions and predicting the language created by those inputs based on those inputs[2]. Sign language has a grammar that is unique from and independent of English. When compared to English, SL allows for far more freedom in word order. Tense is marked morphologically on verbs in English, but SL (like many other languages, such as Indian Sign Language) communicates tense lexically using temporal adverbs. The structure of ISL and English differs at the phonological level as well. Signed languages, like spoken languages, include a degree of sublexical structure that includes segments and combinatorial rules; however, phonological elements are manual rather than vocal. The way spatial information is conveyed in English and ISL differs substantially. All Deaf people are illiterate in written English. As an output, the SL text can be produced. SL is just physically executed English, where English and SL share the identical linguistic structure-that one is a straight encoding of the other. Many software designers mistakenly believe that deaf users can always access printed the English language in a user interface. Many designers feel that if auditory information is also supplied as written English, the deaf user's demands will be addressed. Prepositions such as 'in,' 'on,' and 'under' are used to indicate locative information in English, as in many other spoken languages. On the other hand, SL encodes locative and motion information via verbal classifier formulations in which hand shape morphemes define item type, and the location of the hands in signing space schematically depicts the spatial relationship between two things. Thus, English and ASL differ significantly in phonological, morphological, and syntactic areas.  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85146492330
Emmett S.D.; Platt A.; Turner E.L.; Gallo J.J.; Labrique A.B.; Inglis S.M.; Jenson C.D.; Parnell H.E.; Wang N.-Y.; Hicks K.L.; Egger J.R.; Halpin P.F.; Yong M.; Ballreich J.; Robler S.K.,"Emmett, Susan D (36052713800); Platt, Alyssa (23480456100); Turner, Elizabeth L (7202447916); Gallo, Joseph J (7101605709); Labrique, Alain B (6505557971); Inglis, S Meade (57219714989); Jenson, Cole D (57200534638); Parnell, Heather E (36613760200); Wang, Nae-Yuh (7404340658); Hicks, Kelli L (57200938658); Egger, Joseph R (16439174800); Halpin, Peter F (36696137700); Yong, Michael (57109996400); Ballreich, Jeromie (56392949900); Robler, Samantha Kleindienst (57201022586)",36052713800; 23480456100; 7202447916; 7101605709; 6505557971; 57219714989; 57200534638; 36613760200; 7404340658; 57200938658; 16439174800; 36696137700; 57109996400; 56392949900; 57201022586,Mobile health school screening and telemedicine referral to improve access to specialty care in rural Alaska: a cluster- randomised controlled trial,2022,The Lancet Global Health,10,7,,e1023,e1033,10,18,10.1016/S2214-109X(22)00184-X,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131935466&doi=10.1016%2fS2214-109X%2822%2900184-X&partnerID=40&md5=a75f852ef68b9f78950c8c26388c08e2,"Background: School-based programmes, including hearing screening, provide essential preventive services for rural children. However, minimal evidence on screening methodologies, loss to follow-up, and scarcity of specialists for subsequent care compound rural health disparities. We hypothesised telemedicine specialty referral would improve time to follow-up for school hearing screening compared with standard primary care referral. Methods: In this cluster-randomised controlled trial conducted in 15 rural Alaskan communities, USA, we randomised communities to telemedicine specialty referral (intervention) or standard primary care referral (control) for school hearing screening. All children (K–12; aged 4–21 years) enrolled in Bering Straight School District were eligible. Community randomisation occurred within four strata using location and school size. Participants were masked to group allocation until screening day, and assessors were masked throughout data collection. Screening occurred annually, and children who screened positive for possible hearing loss or ear disease were monitored for 9 months from the screening date for follow-up. Primary outcome was the time to follow-up after a positive hearing screen; analysis was by intention to treat. The trial was registered with ClinicalTrials.gov, NCT03309553. Findings: We recruited participants between Oct 10, 2017, and March 28, 2019. 15 communities were randomised: eight (750 children) to telemedicine referral and seven (731 children) to primary care referral. 790 (53·3%) of 1481 children screened positive in at least one study year: 391 (52∤1%) in the telemedicine referral communities and 399 (50∤4%) in the primary care referral communities. Of children referred, 268 (68·5%) in the telemedicine referral communities and 128 (32·1%) in primary care referral communities received follow-up within 9 months. Among children who received follow-up, mean time to follow-up was 41·5 days (SD 55·7) in the telemedicine referral communities and 92·0 days (75·8) in the primary care referral communities (adjusted event-time ratio 17·6 [95% CI 6·8–45·3] for all referred children). There were no adverse events. Interpretation: Telemedicine specialty referral significantly improved the time to follow-up after hearing screening in Alaska. Telemedicine might apply to other preventive school-based services to improve access to specialty care for rural children. Funding: Patient-Centered Outcomes Research Institute. © 2022 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license",35714630,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131935466
Vozzi A.; Ronca V.; Malerba P.; Ghiselli S.; Murri A.; Pizzol E.; Babiloni F.; Cuda D.,"Vozzi, A. (57204212553); Ronca, V. (57216305636); Malerba, P. (54788014300); Ghiselli, S. (37050710000); Murri, A. (16301868500); Pizzol, E. (57454859700); Babiloni, F. (7006787992); Cuda, D. (6602000037)",57204212553; 57216305636; 54788014300; 37050710000; 16301868500; 57454859700; 7006787992; 6602000037,An innovative method for trans-impedance matrix interpretation in hearing pathologies discrimination,2022,Medical Engineering and Physics,102,,103771,,,,1,10.1016/j.medengphy.2022.103771,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124691412&doi=10.1016%2fj.medengphy.2022.103771&partnerID=40&md5=bd129609917e49c856be7eb46c17a74c,"Trans-impedance measurement is a novel methodology for assessing the positioning of a cochlear implant (CI). This study proposes an innovative use of trans-impedance measurements to characterize specific hearing pathologies by means of the trans-impedance matrix (TIM) quantitative analysis. Three indices are used: Shannon Entropy, the Exponential Decay constant and Spatial Correlation. These indices were computed on the TIMs of two groups of patients, clustered in terms of hearing pathology: (i) congenital hearing loss (CONG) and (ii) otosclerosis (OTO). The study aimed to demonstrate the sensitivity of the above synthetic indices in relation to the considered hearing pathologies. Furthermore, the first two indices were employed to explore the influence of the positioning of the electrode, either over (i) the basal or (ii) the apical regions, on the TIMs patterns. The results suggest that the indices were statistically different for the patient groups and the positioning impacted solely on OTO patients. In particular: (i) CONG patients displayed significantly higher Shannon Entropy (p = 0.0002) and (ii) a lower Exponential Decay constant than OTO patients (p = 0.001); (iii) the OTO patients exhibited a lower Shannon Entropy and a higher Exponential Decay constant over the basal regions than the apical regions (p < 0.008); (iv) Spatial Correlation demonstrated that TIMs had specific patterns according to the hearing pathology (p < 0.008). © 2022 IPEM",35346431,Article,Final,,Scopus,2-s2.0-85124691412
Charuthamrong P.; Israsena P.; Hemrungrojn S.; Pan-Ngum S.,"Charuthamrong, Pimwipa (57468890200); Israsena, Pasin (15046655700); Hemrungrojn, Solaphat (56021778200); Pan-Ngum, Setha (25926629900)",57468890200; 15046655700; 56021778200; 25926629900,Automatic Speech Discrimination Assessment Methods Based on Event-Related Potentials (ERP),2022,Sensors,22,7,2702,,,,1,10.3390/s22072702,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127442107&doi=10.3390%2fs22072702&partnerID=40&md5=cceb772354da5706343be958dc553e48,"Speech discrimination is used by audiologists in diagnosing and determining treatment for hearing loss patients. Usually, assessing speech discrimination requires subjective responses. Using electroencephalography (EEG), a method that is based on event-related potentials (ERPs), could provide objective speech discrimination. In this work we proposed a visual-ERP-based method to assess speech discrimination using pictures that represent word meaning. The proposed method was implemented with three strategies, each with different number of pictures and test sequences. Machine learning was adopted to classify between the task conditions based on features that were extracted from EEG signals. The results from the proposed method were compared to that of a similar visual-ERP-based method using letters and a method that is based on the auditory mismatch negativity (MMN) component. The P3 component and the late positive potential (LPP) component were observed in the two visual-ERP-based methods while MMN was observed during the MMN-based method. A total of two out of three strategies of the proposed method, along with the MMN-based method, achieved approximately 80% average classification accuracy by a combination of support vector machine (SVM) and common spatial pattern (CSP). Potentially, these methods could serve as a pre-screening tool to make speech discrimination assessment more accessible, particularly in areas with a shortage of audiologists. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",35408316,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85127442107
Yong W.; Song J.; Xing C.; Xu J.-J.; Xue Y.; Yin X.; Wu Y.; Chen Y.-C.,"Yong, Wei (57209830447); Song, Jiajie (57735911400); Xing, Chunhua (57209828888); Xu, Jin-Jing (57190813264); Xue, Yuan (57225180342); Yin, Xindao (16835369400); Wu, Yuanqing (57209834804); Chen, Yu-Chen (55326731000)",57209830447; 57735911400; 57209828888; 57190813264; 57225180342; 16835369400; 57209834804; 55326731000,Disrupted Topological Organization of Resting-State Functional Brain Networks in Age-Related Hearing Loss,2022,Frontiers in Aging Neuroscience,14,,907070,,,,3,10.3389/fnagi.2022.907070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131718279&doi=10.3389%2ffnagi.2022.907070&partnerID=40&md5=a747a39c0381d07e3bb163fe78c7d929,"Purpose: Age-related hearing loss (ARHL), associated with the function of speech perception decreases characterized by bilateral sensorineural hearing loss at high frequencies, has become an increasingly critical public health problem. This study aimed to investigate the topological features of the brain functional network and structural dysfunction of the central nervous system in ARHL using graph theory. Methods: Forty-six patients with ARHL and forty-five age, sex, and education-matched healthy controls were recruited to undergo a resting-state functional magnetic resonance imaging (fMRI) scan in this study. Graph theory was applied to analyze the topological properties of the functional connectomes by studying the local and global organization of neural networks. Results: Compared with healthy controls, the patient group showed increased local efficiency (Eloc) and clustering coefficient (Cp) of the small-world network. Besides, the degree centrality (Dc) and nodal efficiency (Ne) values of the left inferior occipital gyrus (IOG) in the patient group showed a decrease in contrast with the healthy control group. In addition, the intra-modular interaction of the occipital lobe module and the inter-modular interaction of the parietal occipital module decreased in the patient group, which was positively correlated with Dc and Ne. The intra-modular interaction of the occipital lobe module decreased in the patient group, which was negatively correlated with the Eloc. Conclusion: Based on fMRI and graph theory, we indicate the aberrant small-world network topology in ARHL and dysfunctional interaction of the occipital lobe and parietal lobe, emphasizing the importance of dysfunctional left IOG. These results suggest that early diagnosis and treatment of patients with ARHL is necessary, which can avoid the transformation of brain topology and decreased brain function. Copyright © 2022 Yong, Song, Xing, Xu, Xue, Yin, Wu and Chen.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131718279
Lee J.; Han J.-H.; Lee H.-J.,"Lee, Jihyun (57204279283); Han, Ji-Hye (56493483800); Lee, Hyo-Jeong (54581192700)",57204279283; 56493483800; 54581192700,Development of Novel Musical Stimuli to Investigate the Perception of Musical Emotions in Individuals With Hearing Loss,2023,Journal of Korean Medical Science,38,12,e82,,,,0,10.3346/JKMS.2023.38.E82,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150951067&doi=10.3346%2fJKMS.2023.38.E82&partnerID=40&md5=dda0016f20ad01f124078fbed40fd8a4,"Background: Many studies have examined the perception of musical emotion using excerpts from familiar music that includes highly expressed emotions to classify emotional choices. However, using familiar music to study musical emotions in people with acquired hearing loss could produce ambiguous results as to whether the emotional perception is due to previous experiences or listening to the current musical stimuli. To overcome this limitation, we developed new musical stimuli to study emotional perception without the effects of episodic memory. Methods: A musician was instructed to compose five melodies with evenly distributed pitches around 1 kHz. The melodies were created to express the emotions of happy, sad, angry, tender, and neutral. To evaluate whether these melodies expressed the intended emotions, two methods were applied. First, we classified the expressed emotions of melodies with selected musical features from 60 features using genetic algorithm-based k-nearest neighbors. Second, forty-four people with normal hearing participated in an online survey regarding the emotional perception of music based on dimensional and discrete approaches to evaluate the musical stimuli set. Results: Twenty-four selected musical features produced classification for intended emotions with an accuracy of 76%. The results of the online survey in the normal hearing (NH) group showed that the intended emotions were selected significantly more often than the others. K-means clustering analysis revealed that melodies with arousal and valence ratings corresponded to representative quadrants of interest. Additionally, the applicability of the stimuli was tested in 4 individuals with high-frequency hearing loss. Conclusion: By applying the individuals with NH, the musical stimuli were shown to classify emotions with high accuracy, as expressed. These results confirm that the set of musical stimuli can be used to study the perceived emotion in music, demonstrating the validity of the musical stimuli, independent of innate musical bias such as due to episodic memory. Furthermore, musical stimuli could be helpful for further studying perceived musical emotion in people with hearing loss because of the controlled pitch for each emotion © 2023 The Korean Academy of Medical Sciences",36974396,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85150951067
Chu M.; Wang L.; Ye H.; Li J.; Lu D.; Piao Y.; Wu L.,"Chu, Min (57224101072); Wang, Leiming (7409188491); Ye, Hong (50961893700); Li, Junjie (37031488900); Lu, Dehong (22634901600); Piao, Yueshan (7006148714); Wu, Liyong (8547476300)",57224101072; 7409188491; 50961893700; 37031488900; 22634901600; 7006148714; 8547476300,Meningeal carcinomatosis secondary to neurenteric cysts with malignant transformation: a case report,2022,BMC Neurology,22,1,433,,,,0,10.1186/s12883-022-02978-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142038056&doi=10.1186%2fs12883-022-02978-7&partnerID=40&md5=33d3f4781924ec530ebd9ceb7ce54dab,"Background: Meningeal carcinomatosis is mainly associated with breast cancer, lung cancer, and melanoma. However, meningeal carcinomatosis secondary to a neurenteric cyst with malignant features is extremely rare. Case presentation: We report the case of a 35-year-old woman who was admitted to the hospital with a 10-month history of headache, 6-month history of diplopia, 4-month history of hearing loss, and 1-month history of back pain, suggesting a diagnosis of chronic meningitis. Notably, enhanced brain and spinal cord magnetic resonance imaging (MRI) revealed extensive lesions with enhancement signals in the pia mater of the pons and cervical, thoracic, and lumbar spinal cord. The cerebral spinal fluid profile showed that pressure was significantly elevated, with a slight increase in leukocytes that mostly comprised mononuclear cells and decreased glucose concentration. Cytology evaluation showed a small cluster of atypical nuclei, which were suspected to be tumor cells arising from the epithelium. However, no primary tumor was found through comprehensive body and skin screening. After a histopathological biopsy of subarachnoid meninx of the thoracic spinal canal, the cause of meningeal carcinomatosis of this patient was determined as neurenteric cysts with malignant features, which is extremely rare. Conclusion: This is the first case to ever report neurenteric cysts as a cause of leptomeningeal carcinomatosis and the first ever report of neurenteric cysts presenting as leptomeningeal carcinomatosis without typical cyst visible on brain MRI. This extremely rare case provided a novel view on the pathogenesis of meningeal carcinomatosis and clinical presentation of neurenteric cysts, highlighting the value of meningeal biopsy in chronic meningitis of unknown causes. © 2022, The Author(s).",36384561,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85142038056
Alonso-Valerdi L.M.; Torres-Torres A.S.; Corona-González C.E.; Ibarra-Zárate D.I.,"Alonso-Valerdi, Luz M. (49962954800); Torres-Torres, Alma S. (57614149400); Corona-González, César E. (57359711900); Ibarra-Zárate, David I. (55234023500)",49962954800; 57614149400; 57359711900; 55234023500,Clustering approach based on psychometrics and auditory event-related potentials to evaluate acoustic therapy effects,2022,Biomedical Signal Processing and Control,76,,103719,,,,3,10.1016/j.bspc.2022.103719,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128752875&doi=10.1016%2fj.bspc.2022.103719&partnerID=40&md5=83658670d85ed453366cab7a8a2bf8cc,"Background: Tinnitus is an auditory condition with no effective treatments. Seven of the 25 most widely used treatment are sound based therapies, but no methods to select an appropriate one have been established. Method: Therefore, this investigation aimed to establish a method to select an appropriate acoustic therapy by finding comparable psycho-neurological effects. For that purpose, 71 Mexican volunteers (60 tinnitus sufferers and 11 controls) followed one of five two-month treatments that aimed to (1) diminish the level of attention towards tinnitus via neuro-modulation, (2) habituate to tinnitus by retraining or (3) to relieve distress (binaural beats and music). From the treatment outcomes, six features were defined: (1) hearing loss, (2) anxiety level, (3) stress level, (4) overall amount of neural electrical response to acoustic therapy, (5) EEG channel wherefrom the maximum neural response was obtained, and (6) assigned group. Then, a cluster analysis based on the k-means method was undertaken. Results: As a result, a strong structure (silhouette measure = 0.798) of six clusters showed that tinnitus sufferers who reported diminution of stress and anxiety, and no side effects, mainly proceeded from neuro-modulation treatments. Furthermore, most of tinnitus sufferers who reported increase of anxiety mainly proceeded from tinnitus retraining and binaural beats. Finally, tinnitus sufferers who only reported anxiety diminution mainly proceeded from tinnitus retraining and music therapy. Conclusion: Taken together, these findings are a guideline to select an appropriate therapy according to clinical history and psycho-neurological effects, what has not been proposed until now. © 2022 Elsevier Ltd",,Article,Final,,Scopus,2-s2.0-85128752875
Chiereghin C.; Robusto M.; Massa V.; Castorina P.; Ambrosetti U.; Asselta R.; Soldà G.,"Chiereghin, Chiara (57189051178); Robusto, Michela (54914296100); Massa, Valentina (6701628384); Castorina, Pierangela (6701650403); Ambrosetti, Umberto (6602424619); Asselta, Rosanna (6701592209); Soldà, Giulia (24073776000)",57189051178; 54914296100; 6701628384; 6701650403; 6602424619; 6701592209; 24073776000,Role of Cytoskeletal Diaphanous-Related Formins in Hearing Loss,2022,Cells,11,11,1726,,,,4,10.3390/cells11111726,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130833070&doi=10.3390%2fcells11111726&partnerID=40&md5=1d34ab63728eb5b859a84561dc0f79f3,"Hearing relies on the proper functioning of auditory hair cells and on actin-based cytoskele-tal structures. Diaphanous-related formins (DRFs) are evolutionarily conserved cytoskeletal proteins that regulate the nucleation of linear unbranched actin filaments. They play key roles during meta-zoan development, and they seem particularly pivotal for the correct physiology of the reproductive and auditory systems. Indeed, in Drosophila melanogaster, a single diaphanous (dia) gene is present, and mutants show sterility and impaired response to sound. Vertebrates, instead, have three orthologs of the diaphanous gene: DIAPH1, DIAPH2, and DIAPH3. In humans, defects in DIAPH1 and DIAPH3 have been associated with different types of hearing loss. In particular, heterozygous mutations in DIAPH1 are responsible for autosomal dominant deafness with or without thrombocytopenia (DFNA1, MIM #124900), whereas regulatory mutations inducing the overexpression of DIAPH3 cause autosomal dominant auditory neuropathy 1 (AUNA1, MIM #609129). Here, we provide an overview of the expression and function of DRFs in normal hearing and deafness. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85130833070
Liu T.; Liu J.; Han C.; Liu Y.; Zeng Q.; Gu Q.,"Liu, Tao (58736186200); Liu, Jing (56018334000); Han, Cheng (57735272800); Liu, Yitao (57735215700); Zeng, Qiang (57220898562); Gu, Qing (56392403500)",58736186200; 56018334000; 57735272800; 57735215700; 57220898562; 56392403500,Health hazards and hearing loss risk assessment of workers exposed to noise in an automobile manufacturing enterprise; [某汽车制造业噪声暴露致作业人员健康危害及听力损失风险评估],2022,Chinese Journal of Industrial Hygiene and Occupational Diseases,40,6,,434,438,4,0,10.3760/cma.j.cn121094-20210615-00286,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133283169&doi=10.3760%2fcma.j.cn121094-20210615-00286&partnerID=40&md5=bc4f440078330174604935091a9ef466,"Objective To investigate the current situation of occupational exposure to noise among noise workers in an automobile manufacturing enterprise in Tianjin, understand the impact of noise on workers' nervous system and hearing, and assess the risk of hearing loss among noise workers. Methods In May 2021, 3516 workers in an automobile manufacturing enterprise were investigated by using a self-made questionnaire ""Noise Workers Questionnaire"" and cluster sampling method. The occupational noise hygiene survey and occupational hazards detection were carried out in their workplaces. They were divided into noise exposure group and non-noise exposure group according to whether they were exposed to noise or not. The general characteristics, hearing and nervous system symptoms of the two groups of workers were compared, and the risk of hearing loss was assessed. Results There were 758 workers in the noise exposure group, aged (26±5) years old, with a working age of 3.0(2.0, 6.0) years exposed to noise. 2758 workers in the non-noise exposure group, aged (25 ±6) years old, with a working age of 2.0 (1.0, 4.0) years. There were statistically significant differences in the distribution of workers'education level, working age and memory loss between the two groups (χ2 =37.98, 38.70, 5.20, P <0.05). The workers in the noise exposure group showed a decreasing trend of insomnia, dreaminess, sweating and fatigue with the increase of working age (χ2trend=6.16, 7.99, P<0.05). The risk classification of binaural high-frequency hearing loss for workers in all noise positions until the age of 50 and 60 was negligible, the risk of occupational noise deafness was low for workers in stamping and welding noise positions until the age of 60. Conclusion The occupational noise exposed to automobile manufacturing workers may cause certain harm to their nervous and auditory systems. Noise protection measures should be taken to reduce the risk of hearing loss and occupational noise deafness. © 2022 Chinese Medical Journals Publishing House Co.Ltd. All Rights Reserved.",35785897,Article,Final,,Scopus,2-s2.0-85133283169
Cho Y.S.; Chung W.-H.,"Cho, Young Sang (56975672700); Chung, Won-Ho (7401983065)",56975672700; 7401983065,AIM in Méniè re’s Disease 122,2022,Artificial Intelligence in Medicine,,,,1705,1716,11,0,10.1007/978-3-030-64573-1_271,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159013557&doi=10.1007%2f978-3-030-64573-1_271&partnerID=40&md5=bb7227bbee69dc2a57c52c16f1558b68,"Ménière’s disease (MD) is difficult to diagnose objectively and evaluate the treatment outcomes. Although pure tone audiometry is the only objective test included in the diagnostic criteria, inner ear MRI technique, which was recently developed to visualize endolymphatic hydrops (EH), is useful for the diagnosis of MD. However, analyzing methods are reported to be diverse, and sometimes, they are timeconsuming and complicated. In recent years, the rapidly developing field of artificial intelligence (AI) showed outstanding performance in image recognition. In particular, convolutional neural network (CNN) based on deep learning plays a remarkable role in today’s medical field, where imaging analysis is critical. We developed a CNN-based deep learning model called INHEARIT (INner ear Hydrops Estimation via ARtificial InTelligence) for automatic calculation of EH ratio in a segmented region of the cochlea and vestibule. The model can generate results that are highly consistent with those generated by manual calculation more quickly. This automated analysis of inner ear MRI using deep learning would be useful for diagnosis and follow-up of MD. It is also expected to be widely used in differential diagnosis of various EH-related diseases. © Springer Nature Switzerland AG 2022.",,Book chapter,Final,,Scopus,2-s2.0-85159013557
Mason K.M.; Marsh R.L.; Pelton S.I.; Harvill E.T.,"Mason, Kevin M. (7102198862); Marsh, Robyn L. (16028784700); Pelton, Stephen I. (7007037211); Harvill, Eric T. (6701542885)",7102198862; 16028784700; 7007037211; 6701542885,Editorial: Otitis media,2022,Frontiers in Cellular and Infection Microbiology,12,,1063153,,,,0,10.3389/fcimb.2022.1063153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143825689&doi=10.3389%2ffcimb.2022.1063153&partnerID=40&md5=c413c27575b8a74a0e35e70e1074d6b3,[No abstract available],36506022,Editorial,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85143825689
Shamsul A.; Ramli N.Bt.,"Shamsul, Amir (58659417700); Ramli, Nabilah Bt. (56707625500)",58659417700; 56707625500,Artificial Neural Network (ANN) Prediction For Noise Risk Assessment In Industrial Workplace,2022,IET Conference Proceedings,2022,10,,143,147,4,0,10.1049/icp.2022.2280,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174650568&doi=10.1049%2ficp.2022.2280&partnerID=40&md5=dd49d2bae44e837e3c3806d3f1783596,"Presently, it is estimated that 16 % of the disabling hearing loss in adults is attributed to occupational noise, ranging from 7 to 21 % in the various countries. With the rise of industrialization, sound pollution is set to increase every 10 years. To alleviate this, the Department of Occupational Safety and Health (DOSH) made it mandatory for industrial workers to undergo annual audiometric testing. However, it is still not enough as hearing loss isn't an annual occasion and hearing damage can occur either instantly or it progresses over time. This could lead to workers prolonging and progressing their hearing damage until the next year. Hence, the purpose of this study is to produce a predictive model to assess the risks of hearing loss for workers in the industrial workplace. This study devised artificial neural network prediction models to predict the level of hearing loss in an employee's left and right ears respectively, based on past audiometric data from The National Institute for Occupational Safety and Health (NIOSH). Once the model is complete, variables such as the sample size, batch size and hidden layers were manipulated to view its effect on the accuracy of the model. The prediction model yielded an overall accuracy of 92% with a range of 78% and 98% when predicting the individual classes of hearing loss and found that increasing certain parameters influences the accuracy of the prediction model. This study utilized 5000 data sample to prove that noise risk assessment can be done in a larger scale using artificial intelligence. © 2022 IET Conference Proceedings. All rights reserved.",,Conference paper,Final,,Scopus,2-s2.0-85174650568
Hülsmeier D.; Kollmeier B.,"Hülsmeier, David (56529593800); Kollmeier, Birger (7006746726)",56529593800; 7006746726,How much individualization is required to predict the individual effect of suprathreshold processing deficits? Assessing Plomp's distortion component with psychoacoustic detection thresholds and FADE,2022,Hearing Research,426,,108609,,,,0,10.1016/j.heares.2022.108609,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139372786&doi=10.1016%2fj.heares.2022.108609&partnerID=40&md5=5c0ffbdfbd505fe4fb5e1e508e7fe3d7,"Plomp introduced an empirical separation of the increased speech recognition thresholds (SRT) in listeners with a sensorineural hearing loss into an Attenuation (A) component (which can be compensated by amplification) and a non-compensable Distortion (D) component. Previous own research backed up this notion by speech recognition models that derive their SRT prediction from the individual audiogram with or without a psychoacoustic measure of suprathreshold processing deficits. To determine the precision in separating the A and D component for the individual listener with various individual measures and individualized models, SRTs with 40 listeners with a variation in hearing impairment were obtained in quiet, stationary noise, and fluctuating noise (ICRA 5–250 and babble). Both the clinical audiogram and an adaptive, precise sweep audiogram were obtained as well as tone-in-noise detection thresholds at four frequencies to characterize the individual hearing impairment. For predicting the SRT, the FADE-model (which is based on machine learning) was used with either of the two audiogram procedures and optionally the individual tone-in-noise detection thresholds. The results indicate that the precisely measured swept tone audiogram allows for a more precise prediction of the individual SRT in comparison to the clinical audiogram (RMS error of 4.3 dB vs. 6.4 dB, respectively). While an estimation from the precise audiogram and FADE performed equally well in predicting the individual A and D component, the further refinement of including the tone-in-noise detection threshold with FADE led to a slight improvement of prediction accuracy (RMS error of 3.3 dB, 4.6 dB and 1.4 dB, for SRT, A and D component, respectively). Hence, applying FADE is advantageous for scientific purposes where a consistent modeling of different psychoacoustical effects in the same listener with a minimum amount of assumptions is desirable. For clinical purposes, however, a precisely measured audiogram and an estimation of the expected D component using a linear regression appears to be a satisfactory first step towards precision audiology. © 2022",36209657,Review,Final,,Scopus,2-s2.0-85139372786
Meyer C.; Waite M.; Atkins J.; Ekberg K.; Scarinci N.; Barr C.; Cowan R.; Hickson L.,"Meyer, Carly (26027432100); Waite, Monique (27568161800); Atkins, Jenny (57364826200); Ekberg, Katie (55641225100); Scarinci, Nerina (13608802400); Barr, Caitlin (57222417746); Cowan, Robert (35551636700); Hickson, Louise (7004043266)",26027432100; 27568161800; 57364826200; 55641225100; 13608802400; 57222417746; 35551636700; 7004043266,How Can eHealth Meet the Hearing and Communication Needs of Adults with Hearing Impairment and their Significant Others? A Group Concept Mapping Study,2022,Ear and Hearing,43,2,,335,346,11,4,10.1097/AUD.0000000000001097,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120701675&doi=10.1097%2fAUD.0000000000001097&partnerID=40&md5=e26636d94c6c509ec60dff3785d09eb0,"Objectives: To seek the perspectives of key stakeholders regarding: (1) how eHealth could help meet the hearing and communication needs of adults with hearing impairment and their significant others; and (2) how helpful each aspect of eHealth would be to key stakeholders personally. Design: Group concept mapping, a mixed-methods participatory research method, was used to seek the perspectives of key stakeholders: adults with hearing impairment (n = 39), significant others (n = 28), and hearing care professionals (n = 56). All participants completed a short online survey before completing one or more of the following activities: brainstorming, sorting, and rating. Brainstorming required participants to generate ideas in response to the focus prompt, ""One way I would like to use information and communication technologies to address the hearing and communication needs of adults with hearing loss and their family and friends is to."" The sorting task required participants to sort all statements into groups that made sense to them. Finally, the rating task required participants to rate each of the statements according to ""How helpful would this idea be to you?"" using a 5-point Likert scale. Hierarchical cluster analysis was applied to the ""sorting"" data to develop a cluster map using the Concept Systems software. The ""rating"" data were subsequently analyzed at a cluster level and an individual-item level using descriptive statistics. Differences in cluster ratings between stakeholder groups were examined using Kruskal-Wallis tests. Results: Overall, 123 statements were generated by participants in response to the focus prompt and were included in subsequent analyses. Based on the ""sorting"" data and hierarchical cluster analysis, a seven-cluster map was deemed to be the best representation of the data. Three key themes emerged from the data, including using eHealth to (1) Educate and Involve Others; (2) Support Aural Rehabilitation; and (3) Educate About and Demonstrate the Impacts of Hearing Impairment and Benefits of Hearing Rehabilitation. Overall median rating scores for each cluster ranged from 3.97 (educate and involve significant others) to 3.44 (empower adults with hearing impairment to manage their hearing impairment from home). Conclusions: These research findings demonstrate the broad range of clinical applications of eHealth that have the capacity to support the implementation of patient- and family-centered hearing care, with self-directed educational tools and resources typically being rated as most helpful. Therefore, eHealth appears to be a viable option for enabling a more biopsychosocial approach to hearing healthcare and educating and involving significant others in the hearing rehabilitation process without adding more pressure on clinical time. More research is needed to inform the subsequent development of eHealth interventions, and it is recommended that health behavior change theory be adhered to for such interventions. © 2022 Lippincott Williams and Wilkins. All rights reserved.",34320524,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85120701675
D'Onofrio K.L.; Zeng F.-G.,"D'Onofrio, Kristen L. (57209482074); Zeng, Fan-Gang (7202911218)",57209482074; 7202911218,Tele-Audiology: Current State and Future Directions,2022,Frontiers in Digital Health,3,,788103,,,,24,10.3389/fdgth.2021.788103,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131266969&doi=10.3389%2ffdgth.2021.788103&partnerID=40&md5=1b84818f06199556f865e6f9fa7c05aa,"The importance of tele-audiology has been heightened by the current COVID-19 pandemic. The present article reviews the current state of tele-audiology practice while presenting its limitations and opportunities. Specifically, this review addresses: (1) barriers to hearing healthcare, (2) tele-audiology services, and (3) tele-audiology key issues, challenges, and future directions. Accumulating evidence suggests that tele-audiology is a viable service delivery model, as remote hearing screening, diagnostic testing, intervention, and rehabilitation can each be completed reliably and effectively. The benefits of tele-audiology include improved access to care, increased follow-up rates, and reduced travel time and costs. Still, significant logistical and technical challenges remain from ensuring a secure and robust internet connection to controlling ambient noise and meeting all state and federal licensure and reimbursement regulations. Future research and development, especially advancements in artificial intelligence, will continue to increase tele-audiology acceptance, expand remote care, and ultimately improve patient satisfaction. Copyright © 2022 D'Onofrio and Zeng.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131266969
Na Y.; Joo H.; Trang L.T.; Quan L.D.A.; Woo J.,"Na, Youngmin (57204535040); Joo, Hyosung (56204085100); Trang, Le Thi (57885885100); Quan, Luong Do Anh (57887050900); Woo, Jihwan (56203746000)",57204535040; 56204085100; 57885885100; 57887050900; 56203746000,Objective speech intelligibility prediction using a deep learning model with continuous speech-evoked cortical auditory responses,2022,Frontiers in Neuroscience,16,,906616,,,,0,10.3389/fnins.2022.906616,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137807462&doi=10.3389%2ffnins.2022.906616&partnerID=40&md5=9da1f887d5b086143423240076a5ce89,"Auditory prostheses provide an opportunity for rehabilitation of hearing-impaired patients. Speech intelligibility can be used to estimate the extent to which the auditory prosthesis improves the user’s speech comprehension. Although behavior-based speech intelligibility is the gold standard, precise evaluation is limited due to its subjectiveness. Here, we used a convolutional neural network to predict speech intelligibility from electroencephalography (EEG). Sixty-four–channel EEGs were recorded from 87 adult participants with normal hearing. Sentences spectrally degraded by a 2-, 3-, 4-, 5-, and 8-channel vocoder were used to set relatively low speech intelligibility conditions. A Korean sentence recognition test was used. The speech intelligibility scores were divided into 41 discrete levels ranging from 0 to 100%, with a step of 2.5%. Three scores, namely 30.0, 37.5, and 40.0%, were not collected. The speech features, i.e., the speech temporal envelope (ENV) and phoneme (PH) onset, were used to extract continuous-speech EEGs for speech intelligibility prediction. The deep learning model was trained by a dataset of event-related potentials (ERP), correlation coefficients between the ERPs and ENVs, between the ERPs and PH onset, or between ERPs and the product of the multiplication of PH and ENV (PHENV). The speech intelligibility prediction accuracies were 97.33% (ERP), 99.42% (ENV), 99.55% (PH), and 99.91% (PHENV). The models were interpreted using the occlusion sensitivity approach. While the ENV models’ informative electrodes were located in the occipital area, the informative electrodes of the phoneme models, i.e., PH and PHENV, were based on the occlusion sensitivity map located in the language processing area. Of the models tested, the PHENV model obtained the best speech intelligibility prediction accuracy. This model may promote clinical prediction of speech intelligibility with a comfort speech intelligibility test. Copyright © 2022 Na, Joo, Trang, Quan and Woo.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85137807462
Colquitt B.M.; Li K.; Green F.; Veline R.; Brainard M.S.,"Colquitt, Bradley M. (37123539100); Li, Kelly (58076741800); Green, Foad (57209078567); Veline, Robert (57195717072); Brainard, Michael S. (6603938002)",37123539100; 58076741800; 57209078567; 57195717072; 6603938002,Neural circuit-wide analysis of changes to gene expression during deafening-induced birdsong destabilization,2023,eLife,12,,e85970,,,,1,10.7554/eLife.85970,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163236862&doi=10.7554%2feLife.85970&partnerID=40&md5=10eb01e689acc56067bcef2a4dbf35f0,"Sensory feedback is required for the stable execution of learned motor skills, and its loss can severely disrupt motor performance. The neural mechanisms that mediate sensorimotor stability have been extensively studied at systems and physiological levels, yet relatively little is known about how disruptions to sensory input alter the molecular properties of associated motor systems. Songbird courtship song, a model for skilled behavior, is a learned and highly structured vocalization that is destabilized following deafening. Here, we sought to determine how the loss of auditory feedback modifies gene expression and its coordination across the birdsong senso-rimotor circuit. To facilitate this system-wide analysis of transcriptional responses, we developed a gene expression profiling approach that enables the construction of hundreds of spatially-defined RNA-sequencing libraries. Using this method, we found that deafening preferentially alters gene expression across birdsong neural circuitry relative to surrounding areas, particularly in premotor and striatal regions. Genes with altered expression are associated with synaptic transmission, neuronal spines, and neuromodulation and show a bias toward expression in glutamatergic neurons and Pvalb/Sst-class GABAergic interneurons. We also found that connected song regions exhibit correla-tions in gene expression that were reduced in deafened birds relative to hearing birds, suggesting that song destabilization alters the inter-region coordination of transcriptional states. Finally, lesioning LMAN, a forebrain afferent of RA required for deafening-induced song plasticity, had the largest effect on groups of genes that were also most affected by deafening. Combined, this integrated transcriptomics analysis demonstrates that the loss of peripheral sensory input drives a distributed gene expression response throughout associated sensorimotor neural circuitry and iden-tifies specific candidate molecular and cellular mechanisms that support the stability and plasticity of learned motor skills. © Colquitt et al.",37284822,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85163236862
Tang O.Y.; Bajaj A.I.; Zhao K.; Rivera Perla K.M.; Mary Ying Y.-L.; Jyung R.W.; Liu J.K.,"Tang, Oliver Y. (57209690095); Bajaj, Ankush I. (57208926384); Zhao, Kevin (57214689838); Rivera Perla, Krissia M. (57199648015); Mary Ying, Yu-Lan (55545929700); Jyung, Robert W. (6603139857); Liu, James K. (35187640600)",57209690095; 57208926384; 57214689838; 57199648015; 55545929700; 6603139857; 35187640600,In Reply: Association of Patient Frailty With Vestibular Schwannoma Resection Outcomes and Machine Learning Development of a Vestibular Schwannoma Risk Stratification Score,2022,Neurosurgery,91,5,,E141,E142,1,3,10.1227/neu.0000000000002155,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140143866&doi=10.1227%2fneu.0000000000002155&partnerID=40&md5=2798fefedba57ae94562f55aa52ca114,[No abstract available],36106865,Letter,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85140143866
Soji E.S.; Kamalakannan T.,"Soji, Edwin Shalom (57210703477); Kamalakannan, T. (57194034395)",57210703477; 57194034395,Machine learning approaches to intelligent sign language recognition and classification,2023,International Journal of System of Systems Engineering,13,2,,109,122,13,0,10.1504/IJSSE.2023.131232,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161863224&doi=10.1504%2fIJSSE.2023.131232&partnerID=40&md5=a79df6980d509424c836027946885808,"Sign language is a great visual communication technique for those who have auditory or speech impairments. The deaf and dumb people have long relied on sign language recognition (SLR) to communicate and integrate into society. This research uses Indian Sign Language to identify elementary sign-language gestures in images/videos and compares machine language methods. Images are pre-processed and feature-extracted to improve the performance of deployed models. The goal is to create a system that uses an efficient classifier to deliver reliable hand sign-language gesture recognition. For the recognition of the Indian Sign Language dataset for the Sign Language Translation and Recognition ISL-CSLTR database, the accuracy and precision of classification methods are analysed and compared. When compared to the decision tree and KNN models, the Random Forest model had a greater accuracy of 84% and 83% precision. We also got 77% Recall and a 0.7 F Score according to this study. The tool used for evaluating our work in python.  © 2023 Inderscience Enterprises Ltd.",,Article,Final,,Scopus,2-s2.0-85161863224
Lee M.K.; Jeon E.-T.; Baek N.; Kim J.H.; Rah Y.C.; Choi J.,"Lee, Min Kyu (42961935900); Jeon, Eun-Tae (57195325591); Baek, Namyoung (57485382500); Kim, Jeong Hwan (57486004800); Rah, Yoon Chan (36978238900); Choi, June (36019909600)",42961935900; 57195325591; 57485382500; 57486004800; 36978238900; 36019909600,Prediction of hearing recovery in unilateral sudden sensorineural hearing loss using artificial intelligence,2022,Scientific Reports,12,1,3977,,,,10,10.1038/s41598-022-07881-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126232361&doi=10.1038%2fs41598-022-07881-2&partnerID=40&md5=79a2ee31f05f5f9198257c4443e33237,"Despite the significance of predicting the prognosis of idiopathic sudden sensorineural hearing loss (ISSNHL), no predictive models have been established. This study used artificial intelligence to develop prognosis models to predict recovery from ISSNHL. We retrospectively reviewed the medical data of 453 patients with ISSNHL (men, 220; women, 233; mean age, 50.3 years) who underwent treatment at a tertiary hospital between January 2021 and December 2019 and were followed up after 1 month. According to Siegel’s criteria, 203 patients recovered in 1 month. Demographic characteristics, clinical and laboratory data, and pure-tone audiometry were analyzed. Logistic regression (baseline), a support vector machine, extreme gradient boosting, a light gradient boosting machine, and multilayer perceptron were used. The outcomes were the area under the receiver operating characteristic curve (AUROC) primarily, area under the precision-recall curve, Brier score, balanced accuracy, and F1 score. The light gradient boosting machine model had the best AUROC and balanced accuracy. Together with multilayer perceptron, it was also significantly superior to logistic regression in terms of AUROC. Using the SHapley Additive exPlanation method, we found that the initial audiogram shape is the most important prognostic factor. Machine/deep learning methods were successfully established to predict the prognosis of ISSNHL. © 2022, The Author(s).",35273267,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85126232361
Lenatti M.; Moreno-Sánchez P.A.; Polo E.M.; Mollura M.; Barbieri R.; Paglialonga A.,"Lenatti, Marta (57222472784); Moreno-Sánchez, Pedro A. (57219909354); Polo, Edoardo M. (57213605525); Mollura, Maximiliano (57204651438); Barbieri, Riccardo (35483096800); Paglialonga, Alessia (23668671800)",57222472784; 57219909354; 57213605525; 57204651438; 35483096800; 23668671800,Evaluation of Machine Learning Algorithms and Explainability Techniques to Detect Hearing Loss From a Speech-in-Noise Screening Test,2022,American Journal of Audiology,31,3S,,961,979,18,11,10.1044/2022_AJA-21-00194,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137992021&doi=10.1044%2f2022_AJA-21-00194&partnerID=40&md5=d8d02d0aafe0f14c07c30ebb61bd5499,"Purpose: The aim of this study was to analyze the performance of multivariate machine learning (ML) models applied to a speech-in-noise hearing screening test and investigate the contribution of the measured features toward hearing loss detection using explainability techniques. Method: Seven different ML techniques, including transparent (i.e., decision tree and logistic regression) and opaque (e.g., random forest) models, were trained and evaluated on a data set including 215 tested ears (99 with hearing loss of mild degree or higher and 116 with no hearing loss). Post hoc explainability techniques were applied to highlight the role of each feature in predicting hearing loss. Results: Random forest (accuracy = .85, sensitivity = .86, specificity = .85, precision = .84) performed, on average, better than decision tree (accuracy = .82, sensitivity = .84, specificity = .80, precision = .79). Support vector machine, logistic regression, and gradient boosting had similar performance as random forest. According to post hoc explainability analysis on models generated using random forest, the features with the highest relevance in predicting hearing loss were age, number and percentage of correct responses, and average reaction time, whereas the total test time had the lowest relevance. Conclusions: This study demonstrates that a multivariate approach can help detect hearing loss with satisfactory performance. Further research on a bigger sample and using more complex ML algorithms and explainability techniques is needed to fully investigate the role of input features (including additional features such as risk factors and individual responses to low-/high-frequency stimuli) in predicting hearing loss. © 2022 The Authors.",35877954,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85137992021
Siddiqui H.U.R.; Saleem A.A.; Raza M.A.; Zafar K.; Russo R.; Dudley S.,"Siddiqui, Hafeez Ur Rehman (55613267500); Saleem, Adil Ali (57214224665); Raza, Muhammad Amjad (57918902000); Zafar, Kainat (57903695900); Russo, Riccardo (7201444063); Dudley, Sandra (7006033464)",55613267500; 57214224665; 57918902000; 57903695900; 7201444063; 7006033464,Automatic User Preferences Selection of Smart Hearing Aid Using BioAid,2022,Sensors,22,20,8031,,,,1,10.3390/s22208031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140643255&doi=10.3390%2fs22208031&partnerID=40&md5=6fc20ecfcf95b4d3e604b4fe69095693,"Noisy environments, changes and variations in the volume of speech, and non-face-to-face conversations impair the user experience with hearing aids. Generally, a hearing aid amplifies sounds so that a hearing-impaired person can listen, converse, and actively engage in daily activities. Presently, there are some sophisticated hearing aid algorithms available that operate on numerous frequency bands to not only amplify but also provide tuning and noise filtering to minimize background distractions. One of those is the BioAid assistive hearing system, which is an open-source, freely available downloadable app with twenty-four tuning settings. Critically, with this device, a person suffering with hearing loss must manually alter the settings/tuning of their hearing device when their surroundings and scene changes in order to attain a comfortable level of hearing. However, this manual switching among multiple tuning settings is inconvenient and cumbersome since the user is forced to switch to the state that best matches the scene every time the auditory environment changes. The goal of this study is to eliminate this manual switching and automate the BioAid with a scene classification algorithm so that the system automatically identifies the user-selected preferences based on adequate training. The aim of acoustic scene classification is to recognize the audio signature of one of the predefined scene classes that best represent the environment in which it was recorded. BioAid, an open-source biological inspired hearing aid algorithm, is used after conversion to Python. The proposed method consists of two main parts: classification of auditory scenes and selection of hearing aid tuning settings based on user experiences. The DCASE2017 dataset is utilized for scene classification. Among the many classifiers that were trained and tested, random forests have the highest accuracy of 99.7%. In the second part, clean speech audios from the LJ speech dataset are combined with scenes, and the user is asked to listen to the resulting audios and adjust the presets and subsets. A CSV file stores the selection of presets and subsets at which the user can hear clearly against the scenes. Various classifiers are trained on the dataset of user preferences. After training, clean speech audio was convolved with the scene and fed as input to the scene classifier that predicts the scene. The predicted scene was then fed as input to the preset classifier that predicts the user’s choice for preset and subset. The BioAid is automatically tuned to the predicted selection. The accuracy of random forest in the prediction of presets and subsets was 100%. This proposed approach has great potential to eliminate the tedious manual switching of hearing assistive device parameters by allowing hearing-impaired individuals to actively participate in daily life by automatically adjusting hearing aid settings based on the acoustic scene. © 2022 by the authors.",36298382,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85140643255
Vanjari H.B.; Kolte M.T.; Chopade N.,"Vanjari, Hrishikesh B. (57226597420); Kolte, Mahesh T. (36107009000); Chopade, Nilkanth (25957914200)",57226597420; 36107009000; 25957914200,Hearing Loss Adaptivity of Machine Learning Based Compressive Sensing Speech Enhancement for Hearing Aids,2022,"2022 6th International Conference on Computing, Communication, Control and Automation, ICCUBEA 2022",,,,,,,1,10.1109/ICCUBEA54992.2022.10011011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147436527&doi=10.1109%2fICCUBEA54992.2022.10011011&partnerID=40&md5=d5cf06aa9532ef66b0310d047837ecab,"Hearing aids are needed to compensate for various auditory losses in human speech cognition. Though many techniques have for proposed for speech enhancement for hearing aids, they are tuned for a particular loss and not robust against many losses. Most existing speech enhancement techniques lack adaptivity to various noises. This work proposes a machine learning speech enhancement technique based on compressive sensing. The proposed technique adapts its sensing to obtain noised reduced speech characteristics and then amplifies it for different hearing loss. The effectiveness of proposed solution is tested against different hearing loss and the solution is found to perform well in terms subjective and objective speech quality metrics  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85147436527
Fan X.; Fu Z.; Ma K.; Tao W.; Huang B.; Guo G.; Huang D.; Liu G.; Song W.; Song T.; Xiao L.; Xia L.; Liu Y.,"Fan, Xiaochong (56949509600); Fu, Zhijian (14624855400); Ma, Ke (35765403900); Tao, Wei (57201603790); Huang, Bing (55314541200); Guo, Gang (57869454500); Huang, Dong (41361212900); Liu, Guangzhao (57208668274); Song, Wenge (57869454600); Song, Tao (57201772946); Xiao, Lizu (7202696824); Xia, Lingjie (57192702089); Liu, Yanqing (37013575500)",56949509600; 14624855400; 35765403900; 57201603790; 55314541200; 57869454500; 41361212900; 57208668274; 57869454600; 57201772946; 7202696824; 57192702089; 37013575500,Chinese expert consensus on minimally invasive interventional treatment of trigeminal neuralgia,2022,Frontiers in Molecular Neuroscience,15,,953765,,,,5,10.3389/fnmol.2022.953765,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137104773&doi=10.3389%2ffnmol.2022.953765&partnerID=40&md5=cb2e4c50ac183d2fbd7573fd21220c91,"Background and purpose: Trigeminal neuralgia is a common condition that is associated with severe pain, which seriously affects the quality of life of patients. When the efficacy of drugs is not satisfactory or adverse drug reactions cannot be tolerated, minimally invasive interventional therapy has become an important treatment because of its simple operation, low risk, high repeatability and low cost. In recent years, minimally invasive interventional treatments, such as radiofrequency thermocoagulation (RF) of the trigeminal nerve and percutaneous microcompression (PMC), have been widely used in the clinic to relieve severe pain in many patients, however, some related problems remain to be addressed. The Pain Association of the Chinese Medical Association organizes and compiles the consensus of Chinese experts to standardize the development of minimally invasive interventional treatment of trigeminal neuralgia to provide a basis for its clinical promotion and application. Materials and methods: The Pain Association of the Chinese Medical Association organizes the Chinese experts to compile a consensus. With reference to the evidence-based medicine (OCEBM) system and the actual situation of the profession, the Consensus Development Committee adopts the nominal group method to adjust the recommended level. Results: Precise imaging positioning and guidance are the keys to ensuring the efficacy and safety of the procedures. RF and PMC are the most widely performed and effective treatments among minimally invasive interventional treatments for trigeminal neuralgia. Conclusions: The pain degree of trigeminal neuralgia is severe, and a variety of minimally invasive intervention methods can effectively improve symptoms. Radiofrequency and percutaneous microcompression may be the first choice for minimally invasive interventional therapy. Copyright © 2022 Fan, Fu, Ma, Tao, Huang, Guo, Huang, Liu, Song, Song, Xiao, Xia and Liu.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85137104773
Aslıer M.; Aslıer N.G.Y.; Ercan İ.; Keskin S.,"Aslıer, Mustafa (16038708000); Aslıer, Nesibe Gül Yüksel (56784344300); Ercan, İlker (6603789069); Keskin, Serhan (58388419700)",16038708000; 56784344300; 6603789069; 58388419700,"Clustering upper airway physicals, otitis media with effusion and auditory functions in children",2022,Auris Nasus Larynx,49,2,,195,201,6,0,10.1016/j.anl.2021.07.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111066917&doi=10.1016%2fj.anl.2021.07.001&partnerID=40&md5=a78f9ab3f29a3a68f6f3f61ac0ab6b0c,"Objective: Adenoid hypertrophy (AH) has been identified as a cause of otitis media with effusion (OME), which is the most common cause of childhood hearing loss. Indeed, there may be other upper airway-related predisposing factors such as, location of the adenoid, accompanying tonsillar hypertrophy (TH) and nasal septal deviation (NSD) for the development of OME. In this study, we aimed to evaluate the associations between the upper airway physicals and OME with auditory functions. Methods: Eighty-six ears of 43 children, aged 3–11 years were included in this prospective clinical study. Findings of otolaryngologic examinations were noted. Data of pure tone audiometry (PTA), traditional tympanometry (TT) and wideband tympanometry (WBT) parameters were collected. Cluster analysis was performed to the following variables: age, sex; the adenoid choana percentage (ACP), the presences of adenoid around torus tubarius (AATT), TH, NSD and OME; peak pressure (PP) values on TT, resonance frequencies (RF) on WBT, ambient pressure absorbance ratios (APAR) and PTA hearing thresholds. Results: Two groups of ears revealed by clustering; cluster-1 (n = 46) and cluster-2 (n = 40), at the similarity level of 0.662. The presences of AH, AATT, OME and the medians of ACP, PP, RF, WBT APARs at all frequencies except 5656 Hz and 8000 Hz, all PTA thresholds were significantly different between two clusters (p < 0.05). The lower WBT APARs and higher PTA thresholds were associated with higher levels of ACP and higher frequencies of the presence of AATT and OME in cluster-1. Conclusion: There are associations between AH, AATT and OME together with decline in hearing and SEA. Whereas, TH and NSD are not related to the formation of clusters and they are insignificant factors. © 2021",34304942,Article,Final,,Scopus,2-s2.0-85111066917
Wilson B.S.; Tucci D.L.; Moses D.A.; Chang E.F.; Young N.M.; Zeng F.-G.; Lesica N.A.; Bur A.M.; Kavookjian H.; Mussatto C.; Penn J.; Goodwin S.; Kraft S.; Wang G.; Cohen J.M.; Ginsburg G.S.; Dawson G.; Francis H.W.,"Wilson, Blake S. (7403562464); Tucci, Debara L. (6701321249); Moses, David A. (57191408368); Chang, Edward F. (7401837635); Young, Nancy M. (7402413031); Zeng, Fan-Gang (7202911218); Lesica, Nicholas A. (6505793695); Bur, Andrés M. (57218000877); Kavookjian, Hannah (57202384814); Mussatto, Caroline (57492750400); Penn, Joseph (57211556204); Goodwin, Sara (57207828131); Kraft, Shannon (35956332200); Wang, Guanghui (56276619900); Cohen, Jonathan M. (57208763971); Ginsburg, Geoffrey S. (57213561704); Dawson, Geraldine (7201539036); Francis, Howard W. (35298907500)",7403562464; 6701321249; 57191408368; 7401837635; 7402413031; 7202911218; 6505793695; 57218000877; 57202384814; 57492750400; 57211556204; 57207828131; 35956332200; 56276619900; 57208763971; 57213561704; 7201539036; 35298907500,Harnessing the Power of Artificial Intelligence in Otolaryngology and the Communication Sciences,2022,JARO - Journal of the Association for Research in Otolaryngology,23,3,,319,349,30,5,10.1007/s10162-022-00846-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128460801&doi=10.1007%2fs10162-022-00846-2&partnerID=40&md5=5056f6a03b952a0cfd3b21e60b67c99e,"Use of artificial intelligence (AI) is a burgeoning field in otolaryngology and the communication sciences. A virtual symposium on the topic was convened from Duke University on October 26, 2020, and was attended by more than 170 participants worldwide. This review presents summaries of all but one of the talks presented during the symposium; recordings of all the talks, along with the discussions for the talks, are available at https://www.youtube.com/watch?v=ktfewrXvEFg and https://www.youtube.com/watch?v=-gQ5qX2v3rg. Each of the summaries is about 2500 words in length and each summary includes two figures. This level of detail far exceeds the brief summaries presented in traditional reviews and thus provides a more-informed glimpse into the power and diversity of current AI applications in otolaryngology and the communication sciences and how to harness that power for future applications. © 2022, The Author(s) under exclusive licence to Association for Research in Otolaryngology.",35441936,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85128460801
Abdelfatah N.; Mostafa A.A.; French C.R.; Doucette L.P.; Penney C.; Lucas M.B.; Griffin A.; Booth V.; Rowley C.; Besaw J.E.; Tranebjærg L.; Rendtorff N.D.; Hodgkinson K.A.; Little L.A.; Agrawal S.; Parnes L.; Batten T.; Moore S.; Hu P.; Pater J.A.; Houston J.; Galutira D.; Benteau T.; MacDonald C.; French D.; O’Rielly D.D.; Stanton S.G.; Young T.-L.,"Abdelfatah, Nelly (55382776100); Mostafa, Ahmed A. (56154453400); French, Curtis R. (15834617300); Doucette, Lance P. (26649428600); Penney, Cindy (57191914017); Lucas, Matthew B. (57291846200); Griffin, Anne (7202675933); Booth, Valerie (7003616159); Rowley, Christopher (12787868300); Besaw, Jessica E. (55155465500); Tranebjærg, Lisbeth (35403999800); Rendtorff, Nanna Dahl (6602671285); Hodgkinson, Kathy A. (7003957430); Little, Leichelle A. (57209369411); Agrawal, Sumit (7403054662); Parnes, Lorne (7007064053); Batten, Tony (57291397500); Moore, Susan (7403537154); Hu, Pingzhao (8957120500); Pater, Justin A. (57191912953); Houston, Jim (55382808200); Galutira, Dante (6507923427); Benteau, Tammy (55383181900); MacDonald, Courtney (57292534500); French, Danielle (35195717400); O’Rielly, Darren D. (57212024314); Stanton, Susan G. (35990773400); Young, Terry-Lynn (7403037663)",55382776100; 56154453400; 15834617300; 26649428600; 57191914017; 57291846200; 7202675933; 7003616159; 12787868300; 55155465500; 35403999800; 6602671285; 7003957430; 57209369411; 7403054662; 7007064053; 57291397500; 7403537154; 8957120500; 57191912953; 55382808200; 6507923427; 55383181900; 57292534500; 35195717400; 57212024314; 35990773400; 7403037663,A pathogenic deletion in Forkhead Box L1 (FOXL1) identifies the first otosclerosis (OTSC) gene,2022,Human Genetics,141,03-Apr,,965,979,14,5,10.1007/s00439-021-02381-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116915029&doi=10.1007%2fs00439-021-02381-1&partnerID=40&md5=0f2e9e7d9b0c2eefa0c39c4ea7013f59,"Otosclerosis is a bone disorder of the otic capsule and common form of late-onset hearing impairment. Considered a complex disease, little is known about its pathogenesis. Over the past 20 years, ten autosomal dominant loci (OTSC1-10) have been mapped but no genes identified. Herein, we map a new OTSC locus to a 9.96 Mb region within the FOX gene cluster on 16q24.1 and identify a 15 bp coding deletion in Forkhead Box L1 co-segregating with otosclerosis in a Caucasian family. Pre-operative phenotype ranges from moderate to severe hearing loss to profound sensorineural loss requiring a cochlear implant. Mutant FOXL1 is both transcribed and translated and correctly locates to the cell nucleus. However, the deletion of 5 residues in the C-terminus of mutant FOXL1 causes a complete loss of transcriptional activity due to loss of secondary (alpha helix) structure. FOXL1 (rs764026385) was identified in a second unrelated case on a shared background. We conclude that FOXL1 (rs764026385) is pathogenic and causes autosomal dominant otosclerosis and propose a key inhibitory role for wildtype Foxl1 in bone remodelling in the otic capsule. New insights into the molecular pathology of otosclerosis from this study provide molecular targets for non-invasive therapeutic interventions. © 2021, The Author(s).",34633540,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85116915029
Nie L.; Li C.; Marzani F.; Wang H.; Thibouw F.; Grayeli A.B.,"Nie, Leixin (57222038571); Li, Chao (58604343800); Marzani, Franck (6603361103); Wang, Haibin (36621450200); Thibouw, Francois (57200757594); Grayeli, Alexis Bozorg (56059842200)",57222038571; 58604343800; 6603361103; 36621450200; 57200757594; 56059842200,Classification of Wideband Tympanometry by Deep Transfer Learning with Data Augmentation for Automatic Diagnosis of Otosclerosis,2022,IEEE Journal of Biomedical and Health Informatics,26,2,,888,897,9,8,10.1109/JBHI.2021.3093007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112172026&doi=10.1109%2fJBHI.2021.3093007&partnerID=40&md5=244cae7c6f48fbab2e99e2c192e68d53,"Otosclerosis is a common disease of the middle ear leading to stapedial fixation. Its rapid and non-invasive diagnosis could be achieved through wideband tympanometry (WBT), but the interpretation of the raw data provided by this tool is complex and time-consuming. Convolutional neural networks (CNN) could potentially be applied to this situation to help the clinicians categorize WBT data. A dataset containing 135 samples from 80 patients with otosclerosis and 55 controls was obtained. We designed a lightweight CNN to categorize samples into the otosclerosis and control. Receiver operating characteristic (ROC) analysis showed an area under the curve (AUC) of 0.95 ± 0.011, and the F1-score was 0.89 ± 0.031 (r=10). The performance was further improved by data augmentation schemes and transfer learning strategies (AUC: 0.97 ± 0.010, F1-score: 0.94 ± 0.016, p< 0.05, ANOVA). Finally, the most relevant diagnostic features employed by the CNN were assessed via the activation pattern heatmaps. These results are crucial for the visual interpretation of WBT graphic outputs which clinicians use in routine, and for a better understanding of the WBT signal in relation to the ossicular mechanics.  © 2013 IEEE.",34181561,Article,Final,,Scopus,2-s2.0-85112172026
Wang Q.; Chen A.; Hong M.; Liu X.; Du Y.; Wu Z.; Cheng W.; Ji F.,"Wang, Qian (56042780300); Chen, Aiting (24463460000); Hong, Mengdi (7402688203); Liu, Xingjian (53981504900); Du, Yi (57225888591); Wu, Ziming (9747556700); Cheng, Wenbo (58628558500); Ji, Fei (57202689017)",56042780300; 24463460000; 7402688203; 53981504900; 57225888591; 9747556700; 58628558500; 57202689017,Investigation of hearing loss in elderly vertigo and dizziness patients in the past 10 years,2023,Frontiers in Aging Neuroscience,15,,1225786,,,,0,10.3389/fnagi.2023.1225786,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173047346&doi=10.3389%2ffnagi.2023.1225786&partnerID=40&md5=e44e09f0c1b87b4b4ad376ceda5da3ad,"Background: Vertigo and hearing loss are both prevalent in the elderly. This study retrospectively analyzed hearing test results from elderly patients experiencing vertigo and dizziness at ENT outpatient over a 10-year period, in order to study the patterns of hearing loss in this patient population. Methods: Nine thousand three hundred eighty four patients over 50 years old underwent retrospective collection and screening of outpatient diagnosis, pure tone audiometry, acoustic immittance measurement (tympanogram) and auditory brainstem response (ABR) test. The patient's audiograms are divided into 7 subtypes according to a set of fixed criteria. Meanwhile, K-Means clustering analysis method was used to classify the audiogram. Results: The Jerger classification of tympanogram in elderly patients with vertigo and dizziness showed the majority falling under type A. The leading audiogram shapes were flat (27.81% in right ear and 26.89% in left ear), high-frequency gently sloping (25.97% in right ear and 27.34% in left ear), and high-frequency steeply sloping (21.60% in right ear and 22.53% in left ear). Meniere's disease (MD; 30.87%), benign recurrent vertigo (BRV; 19.07%), and benign paroxysmal positional vertigo (BPPV; 15.66%) were the most common etiologies in elderly vestibular diseases. We observed statistically significant differences in hearing thresholds among these vestibular diseases (P < 0.001). K-Means clustering analysis suggested that the optimal number of clusters was three, with sample sizes for the three clusters being 2,747, 2,413, and 4,139, respectively. The ANOVA statistical results of each characteristic value showed P < 0.001. Conclusion: The elderly patients often have mild to moderate hearing loss as a concomitant symptom with vertigo. Female patients have better hearing thresholds than males. The dominant audiometric shapes in this patient population were flat, high-frequency gently sloping, and high-frequency steeply sloping according to a set of fixed criteria. This study highlights the need for tailored strategies in managing hearing loss in elderly patients with vertigo and dizziness. Copyright © 2023 Wang, Chen, Hong, Liu, Du, Wu, Cheng and Ji.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85173047346
Lin S.-C.; Lin M.-Y.; Kang B.-H.; Lin Y.-S.; Liu Y.-H.; Yin C.-Y.; Lin P.-S.; Lin C.-W.,"Lin, Sheng-Chiao (57189046991); Lin, Ming-Yee (56424449400); Kang, Bor-Hwang (7401684497); Lin, Yaoh-Shiang (7406587817); Liu, Yu-Hsi (57190965057); Yin, Chi-Yuan (58109134000); Lin, Po-Shing (58109897100); Lin, Che-Wei (53986367000)",57189046991; 56424449400; 7401684497; 7406587817; 57190965057; 58109134000; 58109897100; 53986367000,Artificial Neural Network-Assisted Classification of Hearing Prognosis of Sudden Sensorineural Hearing Loss With Vertigo,2023,IEEE Journal of Translational Engineering in Health and Medicine,11,,,170,181,11,1,10.1109/JTEHM.2023.3242339,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148443718&doi=10.1109%2fJTEHM.2023.3242339&partnerID=40&md5=4bfef01a57610c943d2eac6b116b3597,"This study aimed to determine the impact on hearing prognosis of the coherent frequency with high magnitude-squared wavelet coherence (MSWC) in video head impulse test (vHIT) among patients with sudden sensorineural hearing loss with vertigo (SSNHLV) undergoing high-dose steroid treatment. This study was a retrospective cohort study. SSNHLV patients treated at our referral center from December 2016 to December 2020 were examined. The cohort comprised 64 patients with SSNHLV undergoing high-dose steroid treatment. MSWC was measured by calculating the wavelet coherence analysis (WCA) at various frequencies from a vHIT. The hearing prognosis were analyzed using a multivariable Cox regression model and convolution neural network (CNN) of WCA. There were 64 patients with a male-to-female ratio of 1:1.67. The greater highest coherent frequency of the posterior semicircular canal (SCC) was associated with the complete recovery (CR) of hearing. After adjustment for other factors, the result remained robust (hazard ratio [HR] 2.11, 95% confidence interval [CI] 1.86-2.35). In the feature extraction with Resnet-50 and proceeding SVM in the horizontal image cropping style, the classification accuracy [STD] for (CR vs. partial + no recovery [PR + NR]), (over-sampling of CR vs. PR + NR), (extensive data extraction of CR vs. PR + NR), and (interpolation of time series of CR vs. PR + NR) were 83.6% [7.4], 92.1% [6.8], 88.9% [7.5], and 91.6% [6.4], respectively. The high coherent frequency of the posterior SCC was a significantly independent factor that was associated with good hearing prognosis in the patients who have SSNHLV. WCA may be provided with comprehensive ability in vestibulo-ocular reflex (VOR) evaluation. CNN could be utilized to classify WCA, predict treatment outcomes, and facilitate vHIT interpretation. Feature extraction in CNN with proceeding SVM and horizontal cropping style of wavelet coherence plot performed better accuracy and offered more stable model for hearing outcomes in patients with SSNHLV than pure CNN classification. Clinical and Translational Impact Statement - High coherent frequency in vHIT results in good hearing outcomes in SSNHLV and facilitates AI classification. © 2013 IEEE.",36816096,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85148443718
Schuerch K.; Wimmer W.; Dalbert A.; Rummel C.; Caversaccio M.; Mantokoudis G.; Weder S.,"Schuerch, Klaus (57496701800); Wimmer, Wilhelm (55808897400); Dalbert, Adrian (56736869400); Rummel, Christian (36905332200); Caversaccio, Marco (7004135207); Mantokoudis, Georgios (24341994500); Weder, Stefan (54787128200)",57496701800; 55808897400; 56736869400; 36905332200; 7004135207; 24341994500; 54787128200,Objectification of intracochlear electrocochleography using machine learning,2022,Frontiers in Neurology,13,,943816,,,,3,10.3389/fneur.2022.943816,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138304832&doi=10.3389%2ffneur.2022.943816&partnerID=40&md5=9e16cd46a5951c3180530bd2846def74,"Introduction: Electrocochleography (ECochG) measures inner ear potentials in response to acoustic stimulation. In patients with cochlear implant (CI), the technique is increasingly used to monitor residual inner ear function. So far, when analyzing ECochG potentials, the visual assessment has been the gold standard. However, visual assessment requires a high level of experience to interpret the signals. Furthermore, expert-dependent assessment leads to inconsistency and a lack of reproducibility. The aim of this study was to automate and objectify the analysis of cochlear microphonic (CM) signals in ECochG recordings. Methods: Prospective cohort study including 41 implanted ears with residual hearing. We measured ECochG potentials at four different electrodes and only at stable electrode positions (after full insertion or postoperatively). When stimulating acoustically, depending on the individual residual hearing, we used three different intensity levels of pure tones (i.e., supra-, near-, and sub-threshold stimulation; 250–2,000 Hz). Our aim was to obtain ECochG potentials with differing SNRs. To objectify the detection of CM signals, we compared three different methods: correlation analysis, Hotelling's T2 test, and deep learning. We benchmarked these methods against the visual analysis of three ECochG experts. Results: For the visual analysis of ECochG recordings, the Fleiss' kappa value demonstrated a substantial to almost perfect agreement among the three examiners. We used the labels as ground truth to train our objectification methods. Thereby, the deep learning algorithm performed best (area under curve = 0.97, accuracy = 0.92), closely followed by Hotelling's T2 test. The correlation method slightly underperformed due to its susceptibility to noise interference. Conclusions: Objectification of ECochG signals is possible with the presented methods. Deep learning and Hotelling's T2 methods achieved excellent discrimination performance. Objective automatic analysis of CM signals enables standardized, fast, accurate, and examiner-independent evaluation of ECochG measurements. Copyright © 2022 Schuerch, Wimmer, Dalbert, Rummel, Caversaccio, Mantokoudis and Weder.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85138304832
Ray C.; Pisoni D.B.; Lu E.; Kronenberger W.G.; Moberly A.C.,"Ray, Christin (57195295677); Pisoni, David B. (7005913467); Lu, Emily (57581629500); Kronenberger, William G. (6701385793); Moberly, Aaron C. (26030594300)",57195295677; 7005913467; 57581629500; 6701385793; 26030594300,Preoperative Visual Measures of Verbal Learning and Memory and their Relations to Speech Recognition after Cochlear Implantation,2022,Ear and Hearing,43,3,,993,1002,9,1,10.1097/AUD.0000000000001155,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128488596&doi=10.1097%2fAUD.0000000000001155&partnerID=40&md5=720885c2108634a37d6f5c3cc9d68b25,"Objectives: This study examined the performance of a group of adult cochlear implant (CI) candidates (CIC) on visual tasks of verbal learning and memory. Preoperative verbal learning and memory abilities of the CIC group were compared with a group of older normal-hearing (ONH) control participants. Relations between preoperative verbal learning and memory measures and speech recognition outcomes after 6 mo of CI use were also investigated for a subgroup of the CICs. Design: A group of 80 older adult participants completed a visually presented multitrial free recall task. Measures of word recall, repetition learning, and the use of self-generated organizational strategies were collected from a group of 49 CICs, before cochlear implantation, and a group of 31 ONH controls. Speech recognition outcomes were also collected from a subgroup of 32 of the CIC participants who returned for testing 6 mo after CI activation. Results: CICs demonstrated poorer verbal learning performance compared with the group of ONH control participants. Among the preoperative verbal learning and memory measures, repetition learning slope and measures of self-generated organizational clustering strategies were the strongest predictors of post-CI speech recognition outcomes. Conclusions: Older adult CI candidates present with verbal learning and memory deficits compared with older adults without hearing loss, even on visual tasks that are independent from the direct effects of audibility. Preoperative verbal learning and memory processes reflecting repetition learning and self-generated organizational strategies in free recall were associated with speech recognition outcomes 6 months after implantation. The pattern of results suggests that visual measures of verbal learning may be a useful predictor of outcomes in postlingual adult CICs. Copyright © 2022 Wolters Kluwer Health, Inc. All rights reserved",35319518,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85128488596
Xue Y.; Hu X.; Wang D.; Li D.; Li Y.; Wang F.; Huang M.; Gu X.; Xu Z.; Zhou J.; Wang J.; Chai R.; Shen J.; Chen Z.-Y.; Li G.-L.; Yang H.; Li H.; Zuo E.; Shu Y.,"Xue, Yuanyuan (57211317646); Hu, Xinde (57208896237); Wang, Daqi (57194396531); Li, Di (57226801885); Li, Yige (57211131201); Wang, Fang (58601341600); Huang, Mingqian (7404260318); Gu, Xi (57221695770); Xu, Zhijiao (57208878689); Zhou, Jinan (57254667800); Wang, Jinghan (56540076000); Chai, Renjie (37065753300); Shen, Jun (56276570200); Chen, Zheng-Yi (57209865740); Li, Geng-Lin (8595887200); Yang, Hui (57201369054); Li, Huawei (57221546012); Zuo, Erwei (55301265400); Shu, Yilai (56577263700)",57211317646; 57208896237; 57194396531; 57226801885; 57211131201; 58601341600; 7404260318; 57221695770; 57208878689; 57254667800; 56540076000; 37065753300; 56276570200; 57209865740; 8595887200; 57201369054; 57221546012; 55301265400; 56577263700,Gene editing in a Myo6 semi-dominant mouse model rescues auditory function,2022,Molecular Therapy,30,1,,105,118,13,27,10.1016/j.ymthe.2021.06.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114673060&doi=10.1016%2fj.ymthe.2021.06.015&partnerID=40&md5=eedf2529fd6ebc6583bf0a9ea3746204,"Myosin VI（MYO6） is an unconventional myosin that is vital for auditory and vestibular function. Pathogenic variants in the human MYO6 gene cause autosomal-dominant or -recessive forms of hearing loss. Effective treatments for Myo6 mutation causing hearing loss are limited. We studied whether adeno-associated virus (AAV)-PHP.eB vector-mediated in vivo delivery of Staphylococcus aureus Cas9 (SaCas9-KKH)-single-guide RNA (sgRNA) complexes could ameliorate hearing loss in a Myo6WT/C442Y mouse model that recapitulated the phenotypes of human patients. The in vivo editing efficiency of the AAV-SaCas9-KKH-Myo6-g2 system on Myo6C442Y is 4.05% on average in Myo6WT/C442Y mice, which was ∼17-fold greater than editing efficiency of Myo6WT alleles. Rescue of auditory function was observed up to 5 months post AAV-SaCas9-KKH-Myo6-g2 injection in Myo6WT/C442Y mice. Meanwhile, shorter latencies of auditory brainstem response (ABR) wave I, lower distortion product otoacoustic emission (DPOAE) thresholds, increased cell survival rates, more regular hair bundle morphology, and recovery of inward calcium levels were also observed in the AAV-SaCas9-KKH-Myo6-g2-treated ears compared to untreated ears. These findings provide further reference for in vivo genome editing as a therapeutic treatment for various semi-dominant forms of hearing loss and other semi-dominant diseases. © 2021 The American Society of Gene and Cell Therapy",34174443,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85114673060
Guan B.; Xu Y.; Chen Y.-C.; Xing C.; Xu L.; Shang S.; Xu J.-J.; Wu Y.; Yan Q.,"Guan, Bing (9745440000); Xu, Yixi (57747308300); Chen, Yu-Chen (55326731000); Xing, Chunhua (57209828888); Xu, Li (57747308400); Shang, Song'an (55914711000); Xu, Jin-Jing (57190813264); Wu, Yuanqing (57209834804); Yan, Qi (57748276800)",9745440000; 57747308300; 55326731000; 57209828888; 57747308400; 55914711000; 57190813264; 57209834804; 57748276800,Reorganized Brain Functional Network Topology in Presbycusis,2022,Frontiers in Aging Neuroscience,14,,905487,,,,8,10.3389/fnagi.2022.905487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132200152&doi=10.3389%2ffnagi.2022.905487&partnerID=40&md5=9b74fe8c6d86464bd6156e98bd654c77,"Purpose: Presbycusis is characterized by bilateral sensorineural hearing loss at high frequencies and is often accompanied by cognitive decline. This study aimed to identify the topological reorganization of brain functional network in presbycusis with/without cognitive decline by using graph theory analysis approaches based on resting-state functional magnetic resonance imaging (rs-fMRI). Methods: Resting-state fMRI scans were obtained from 30 presbycusis patients with cognitive decline, 30 presbycusis patients without cognitive decline, and 50 age-, sex-, and education-matched healthy controls. Graph theory was applied to analyze the topological properties of brain functional networks including global and nodal metrics, modularity, and rich-club organization. Results: At the global level, the brain functional networks of all participants were found to possess small-world properties. Also, significant group differences in global network metrics were observed among the three groups such as clustering coefficient, characteristic path length, normalized characteristic path length, and small-worldness. At the nodal level, several nodes with abnormal betweenness centrality, degree centrality, nodal efficiency, and nodal local efficiency were detected in presbycusis patients with/without cognitive decline. Changes in intra-modular connections in frontal lobe module and inter-modular connections in prefrontal subcortical lobe module were found in presbycusis patients exposed to modularity analysis. Rich-club nodes were reorganized in presbycusis patients, while the connections among them had no significant group differences. Conclusion: Presbycusis patients exhibited topological reorganization of the whole-brain functional network, and presbycusis patients with cognitive decline showed more obvious changes in these topological properties than those without cognitive decline. Abnormal changes of these properties in presbycusis patients may compensate for cognitive impairment by mobilizing additional neural resources. Copyright © 2022 Guan, Xu, Chen, Xing, Xu, Shang, Xu, Wu and Yan.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85132200152
Ma W.; Tang X.; Xia Q.; Xu Y.; Gao W.; Gu J.,"Ma, Wanly (58178756100); Tang, Xuegang (58178665500); Xia, Qiuqin (58178605400); Xu, Yiwei (58178605500); Gao, Weitong (58178665600); Gu, Jin (58067043000)",58178756100; 58178665500; 58178605400; 58178605500; 58178665600; 58067043000,Decoding of Auditory Imagination Activity Based on Machine Learning Methods,2022,"2022 4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022",,,,133,136,3,1,10.1109/ICFTIC57696.2022.10075201,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152190146&doi=10.1109%2fICFTIC57696.2022.10075201&partnerID=40&md5=a55a509509846edcf9c17bee9ff2942c,"The decoding of brain signals has important research value and is also full of challenges. In recent years, the fMRI technology is more and more widely used in the brain signals decoding because of its high spatial resolution and non-invasive characteristic. The existing brain region template provides a powerful tool for brain region decoding research, and the obtained functional connectivity matrix quantifies the correlation between brain regions. The development of pattern recognition technology has created a favorable technical foundation for the study of fMRI data, including a variety of mature machine learning methods such as support vector machine. In this paper, the fMRI data of 24 healthy subjects was measured when they performed the auditory imagination under different sound and scene conditions, then the functional connectivity matrices of brain regions were obtained and to be classified by several pattern recognition methods, such as optimized support vector machine, naive Bayes, and logistic regression. At last, the classification methods were compared according to the classification accuracy. Compared with related works, Methods of data acquisition and the accuracy of the results are better than previous job. The method can help psychologists and neuroscientists perform the brain signal decoding with high efficiency and quality. At the same time, the research is helpful to reveal the neural mechanism of auditory imagination and auditory perception, deepen our understanding of human brain auditory information processing, help the computer to simulate human hearing, and use the correlation of brain signals to help the deaf and mute people to carry out related activities, which has good social benefits.  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85152190146
Nicoras R.; Gotowiec S.; Hadley L.V.; Smeds K.; Naylor G.,"Nicoras, Raluca (57812038600); Gotowiec, Sarah (57201558993); Hadley, Lauren V (56781223400); Smeds, Karolina (6602812496); Naylor, Graham (12761085700)",57812038600; 57201558993; 56781223400; 6602812496; 12761085700,Conversation success in one-to-one and group conversation: a group concept mapping study of adults with normal and impaired hearing,2023,International Journal of Audiology,62,9,,868,876,8,3,10.1080/14992027.2022.2095538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134601297&doi=10.1080%2f14992027.2022.2095538&partnerID=40&md5=4ca13558c64fb7d66636497712d06d5a,"Objective: The concept of conversation success is undefined, although prior work has variously related it to accurate exchange of information, alignment between interlocutors, and good management of misunderstandings. This study aimed (1) to identify factors of conversation success and (2) to explore the importance of these factors in one-to-one versus group conversations. Design: Group concept mapping method was applied. Participants responded to two brainstorming prompts (“What does ‘successful conversation’ look like?” and “Think about a successful conversation you have taken part in. What aspects of that conversation contributed to its success?”). The resulting statements were sorted into related clusters and rated in importance for one-to-one and group conversation. Study Sample: Thirty-five adults with normal and impaired hearing. Results: Seven clusters were identified: (1) Being able to listen easily; (2) Being spoken to in a helpful way; (3) Being engaged and accepted; (4) Sharing information as desired; (5) Perceiving flowing and balanced interaction; (6) Feeling positive emotions; (7) Not having to engage coping mechanisms. Three clusters (1, 2, and 4) were more important in group than in one-to-one conversation. There were no differences by hearing group. Conclusions: These findings emphasise that conversation success is a multifaceted concept. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group on behalf of British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",35875851,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85134601297
Chen J.; Zhao Y.; Zou T.; Wen X.; Zhou X.; Yu Y.; Liu Z.; Li M.,"Chen, Junming (55938853100); Zhao, Yuanxin (56504286800); Zou, Tuanming (57192909666); Wen, Xiaoling (57581279700); Zhou, Xiaowei (56504078500); Yu, Youjun (35764134200); Liu, Zhen (57191691233); Li, Meige (57581089900)",55938853100; 56504286800; 57192909666; 57581279700; 56504078500; 35764134200; 57191691233; 57581089900,"Sensorineural Hearing Loss Affects Functional Connectivity of the Auditory Cortex, Parahippocampal Gyrus and Inferior Prefrontal Gyrus in Tinnitus Patients",2022,Frontiers in Neuroscience,16,,816712,,,,4,10.3389/fnins.2022.816712,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128453362&doi=10.3389%2ffnins.2022.816712&partnerID=40&md5=5a991014ce102871d13f68358a157da0,"Background: Tinnitus can interfere with a patient’s speech discrimination, but whether tinnitus itself or the accompanying sensorineural hearing loss (SNHL) causes this interference is still unclear. We analyzed event-related electroencephalograms (EEGs) to observe auditory-related brain function and explore the possible effects of SNHL on auditory processing in tinnitus patients. Methods: Speech discrimination scores (SDSs) were recorded in 21 healthy control subjects, 24 tinnitus patients, 24 SNHL patients, and 27 patients with both SNHL and tinnitus. EEGs were collected under an oddball paradigm. Then, the mismatch negativity (MMN) amplitude and latency, the clustering coefficient and average path length of the whole network in the tinnitus and SNHL groups were compared with those in the control group. Additionally, we analyzed the intergroup differences in functional connectivity among the primary auditory cortex (AC), parahippocampal gyrus (PHG), and inferior frontal gyrus (IFG). Results: SNHL patients with or without tinnitus had lower SDSs than the control subjects. Compared with control subjects, tinnitus patients with or without SNHL had decreased MMN amplitudes, and SNHL patients had longer MMN latencies. Tinnitus patients without SNHL had a smaller clustering coefficient and a longer whole-brain average path length than the control subjects. SNHL patients with or without tinnitus had a smaller clustering coefficient and a longer average path length than patients with tinnitus alone. The connectivity strength from the AC to the PHG and IFG was lower on the affected side in tinnitus patients than that in control subjects; the connectivity strength from the PHG to the IFG was also lower on the affected side in tinnitus patients than that in control subjects. However, the connectivity strength from the IFG to the AC was stronger in tinnitus patients than that in the control subjects. In SNHL patients with or without tinnitus, these changes were magnified. Conclusion: Changes in auditory processing in tinnitus patients do not influence SDSs. Instead, SNHL might cause the activity of the AC, PHG and IFG to change, resulting in impaired speech recognition in tinnitus patients with SNHL. Copyright © 2022 Chen, Zhao, Zou, Wen, Zhou, Yu, Liu and Li.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128453362
Hua J.-C.; Xu X.-M.; Xu Z.-G.; Xu J.-J.; Hu J.-H.; Xue Y.; Wu Y.,"Hua, Jin-Chao (57735977100); Xu, Xiao-Min (57204001877); Xu, Zhen-Gui (57225174835); Xu, Jin-Jing (57190813264); Hu, Jing-Hua (57218647233); Xue, Yuan (57225180342); Wu, Yuanqing (57209834804)",57735977100; 57204001877; 57225174835; 57190813264; 57218647233; 57225180342; 57209834804,Aberrant Functional Network of Small-World in Sudden Sensorineural Hearing Loss With Tinnitus,2022,Frontiers in Neuroscience,16,,898902,,,,4,10.3389/fnins.2022.898902,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131714817&doi=10.3389%2ffnins.2022.898902&partnerID=40&md5=06feb1e9c0f90f85d2b9a235e602832c,"Few researchers investigated the topological properties and relationships with cognitive deficits in sudden sensorineural hearing loss (SNHL) with tinnitus. To explore the topological characteristics of the brain connectome following SNHL from the global level and nodal level, we recruited 36 bilateral SNHL patients with tinnitus and 37 well-matched healthy controls. Every subject underwent pure tone audiometry tests, neuropsychological assessments, and MRI scanning. AAL atlas was employed to divide a brain into 90 cortical and subcortical regions of interest, then investigated the global and nodal properties of “small world” network in SNHL and control groups using a graph-theory analysis. The global characteristics include small worldness, cluster coefficient, characteristic path length, local efficiency, and global efficiency. Node properties include degree centrality, betweenness centrality, nodal efficiency, and nodal clustering coefficient. Interregional connectivity analysis was also computed among 90 nodes. We found that the SNHL group had significantly higher hearing thresholds and cognitive impairments, as well as disrupted internal connections among 90 nodes. SNHL group displayed lower AUC of cluster coefficient and path length lambda, but increased global efficiency. The opercular and triangular parts of the inferior frontal gyrus, rectus gyrus, parahippocampal gyrus, precuneus, and amygdala showed abnormal local features. Some of these connectome alterations were correlated with cognitive ability and the duration of SNHL. This study may prove potential imaging biomarkers and treatment targets for future studies. Copyright © 2022 Hua, Xu, Xu, Xu, Hu, Xue and Wu.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131714817
Wouters M.; Drakopoulos F.; Verhulst S.,"Wouters, Marjoleen (58198322700); Drakopoulos, Fotios (57221479037); Verhulst, Sarah (23391322600)",58198322700; 57221479037; 23391322600,Machine-learning-based audio algorithms for cochlear synaptopathy compensation: which speech features are enhanced?,2022,Proceedings of the International Congress on Acoustics,,,,,,,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162295833&partnerID=40&md5=aeaccb1033545419a0c983d7ad2861da,"Auditory models have been used for decades to develop audio signal processing algorithms in hearing aids. Here, we used a biophysically-inspired auditory model, in a differentiable convolutional neural-network (CNN) description (CoNNear), to train different end-to-end machine-learning- (ML) based audio signal processing algorithms that maximally restore cochlear synaptopathy (CS) affected auditory-nerve (AN) responses. Based on the reference normal-hearing (NH) model and a hearing-impaired (HI) model, we used backpropagation to design several ML-based algorithms, using the same CNN encoder-decoder architecture but different loss functions focusing on different aspects of the AN responses. Processing of pure tones and words by the ML-algorithms showed enhanced AN responses to both low- and high-frequency pure tones, and to vowels and consonants in quiet, but responses were usually not restored to the NH-level. The algorithms generally sharpened the onset response to speech and improved the stimulus dynamic range. In an unconstrained operation, the ML-algorithms added more energy to the higher frequencies, degrading speech quality and intelligibility. We will objectively assess the effect of these compensation algorithms on sound quality and speech intelligibility in future clinical experiments. © ICA 2022.All rights reserved",,Conference paper,Final,,Scopus,2-s2.0-85162295833
Henry F.; Glavin M.; Jones E.,"Henry, Fergal (57226774713); Glavin, Martin (6602095350); Jones, Edward (25958101300)",57226774713; 6602095350; 25958101300,Noise Reduction in Cochlear Implant Signal Processing: A Review and Recent Developments,2023,IEEE Reviews in Biomedical Engineering,16,,,319,331,12,8,10.1109/RBME.2021.3095428,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112612437&doi=10.1109%2fRBME.2021.3095428&partnerID=40&md5=e19585d00b74ffec03bb3f2f3ea4bb45,"Cochlear implant technology successfully restores hearing function to patients with sensory impairment. Although cochlear implant users generally hear well in quiet, they still find noisy conditions very challenging, hence the need to employ noise reduction algorithms in these systems to enhance the user experience. This paper reviews noise reduction algorithms in cochlear implants. Traditionally, such algorithms have been classified as either single- or multiple-channel, depending on the number of microphones they use. This review retains this general classification in looking at recent papers and extends it to reflect recent interest in machine learning techniques. The review concludes with consideration of promising future areas of research.  © 2008-2011 IEEE.",34232892,Review,Final,,Scopus,2-s2.0-85112612437
Iliadou E.; Su Q.; Kikidis D.; Bibas T.; Kloukinas C.,"Iliadou, Eleftheria (57219273310); Su, Qiqi (57889791300); Kikidis, Dimitrios (25521861600); Bibas, Thanos (57300524100); Kloukinas, Christos (55913575000)",57219273310; 57889791300; 25521861600; 57300524100; 55913575000,Profiling hearing aid users through big data explainable artificial intelligence techniques,2022,Frontiers in Neurology,13,,933940,,,,5,10.3389/fneur.2022.933940,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137982746&doi=10.3389%2ffneur.2022.933940&partnerID=40&md5=15d5eeef19e6b18e1c63b092f3e0a968,"Debilitating hearing loss (HL) affects ~6% of the human population. Only 20% of the people in need of a hearing assistive device will eventually seek and acquire one. The number of people that are satisfied with their Hearing Aids (HAids) and continue using them in the long term is even lower. Understanding the personal, behavioral, environmental, or other factors that correlate with the optimal HAid fitting and with users' experience of HAids is a significant step in improving patient satisfaction and quality of life, while reducing societal and financial burden. In SMART BEAR we are addressing this need by making use of the capacity of modern HAids to provide dynamic logging of their operation and by combining this information with a big amount of information about the medical, environmental, and social context of each HAid user. We are studying hearing rehabilitation through a 12-month continuous monitoring of HL patients, collecting data, such as participants' demographics, audiometric and medical data, their cognitive and mental status, their habits, and preferences, through a set of medical devices and wearables, as well as through face-to-face and remote clinical assessments and fitting/fine-tuning sessions. Descriptive, AI-based analysis and assessment of the relationships between heterogeneous data and HL-related parameters will help clinical researchers to better understand the overall health profiles of HL patients, and to identify patterns or relations that may be proven essential for future clinical trials. In addition, the future state and behavioral (e.g., HAids Satisfiability and HAids usage) of the patients will be predicted with time-dependent machine learning models to assist the clinical researchers to decide on the nature of the interventions. Explainable Artificial Intelligence (XAI) techniques will be leveraged to better understand the factors that play a significant role in the success of a hearing rehabilitation program, constructing patient profiles. This paper is a conceptual one aiming to describe the upcoming data collection process and proposed framework for providing a comprehensive profile for patients with HL in the context of EU-funded SMART BEAR project. Such patient profiles can be invaluable in HL treatment as they can help to identify the characteristics making patients more prone to drop out and stop using their HAids, using their HAids sufficiently long during the day, and being more satisfied by their HAids experience. They can also help decrease the number of needed remote sessions with their Audiologist for counseling, and/or HAids fine tuning, or the number of manual changes of HAids program (as indication of poor sound quality and bad adaptation of HAids configuration to patients' real needs and daily challenges), leading to reduced healthcare cost. Copyright © 2022 Iliadou, Su, Kikidis, Bibas and Kloukinas.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85137982746
Daneman N.; Lee S.; Bai H.; Bell C.M.; Bronskill S.E.; Campitelli M.A.; Dobell G.; Fu L.; Garber G.; Ivers N.; Kumar M.; Lam J.M.C.; Langford B.; Laur C.; Morris A.M.; Mulhall C.L.; Pinto R.; Saxena F.E.; Schwartz K.L.; Brown K.A.,"Daneman, Nick (6508076243); Lee, Samantha (57226759879); Bai, Heming (57294778000); Bell, Chaim M (7402354998); Bronskill, Susan E (6603032553); Campitelli, Michael A (37051803200); Dobell, Gail (57194490333); Fu, Longdi (47161199700); Garber, Gary (7005418284); Ivers, Noah (57206506806); Kumar, Matthew (56724918300); Lam, Jonathan M. C (35933364600); Langford, Bradley (57190872384); Laur, Celia (55674137200); Morris, Andrew M (56420323200); Mulhall, Cara L (57214316630); Pinto, Ruxandra (16646325300); Saxena, Farah E (57205644327); Schwartz, Kevin L (55629854600); Brown, Kevin A (56954007200)",6508076243; 57226759879; 57294778000; 7402354998; 6603032553; 37051803200; 57194490333; 47161199700; 7005418284; 57206506806; 56724918300; 35933364600; 57190872384; 55674137200; 56420323200; 57214316630; 16646325300; 57205644327; 55629854600; 56954007200,Behavioral Nudges to Improve Audit and Feedback Report Opening among Antibiotic Prescribers: A Randomized Controlled Trial,2022,Open Forum Infectious Diseases,9,5,ofac111,,,,3,10.1093/ofid/ofac111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128466436&doi=10.1093%2fofid%2fofac111&partnerID=40&md5=972578042e73501dad76522185b2bc35,"Background: Peer comparison audit and feedback has demonstrated effectiveness in improving antibiotic prescribing practices, but only a minority of prescribers view their reports. We rigorously tested 3 behavioral nudging techniques delivered by email to improve report opening. Methods: We conducted a pragmatic randomized controlled trial among Ontario long-Term care prescribers enrolled in an ongoing peer comparison audit and feedback program which includes data on their antibiotic prescribing patterns. Physicians were randomized to 1 of 8 possible sequences of intervention/control allocation to 3 different behavioral email nudges: A social peer comparison nudge (January 2020), a maintenance of professional certification incentive nudge (October 2020), and a prior participation nudge (January 2021). The primary outcome was feedback report opening; the primary analysis pooled the effects of all 3 nudging interventions. Results: The trial included 421 physicians caring for >28 000 residents at 450 facilities. In the pooled analysis, physicians opened only 29.6% of intervention and 23.9% of control reports (odds ratio [OR], 1.51 [95% confidence interval {CI}, 1.10-2.07], P=.011); this difference remained significant after accounting for physician characteristics and clustering (adjusted OR [aOR], 1.74 [95% CI, 1.24-2.45], P=.0014). Of individual nudging techniques, the prior participation nudge was associated with a significant increase in report opening (OR, 1.62 [95% CI, 1.06-2.47], P=.026; aOR, 2.16 [95% CI, 1.33-3.50], P=.0018). In the pooled analysis, nudges were also associated with accessing more report pages (aOR, 1.28 [95% CI, 1.14-1.43], P<.001). Conclusions: Enhanced nudging strategies modestly improved report opening, but more work is needed to optimize physician engagement with audit and feedback. Clinical Trials Registration: NCT04187742.  © 2022 The Author(s) 2022. Published by Oxford University Press on behalf of Infectious Diseases Society of America.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85128466436
Hoppe U.; Hocke T.; Iro H.,"Hoppe, Ulrich (7101650824); Hocke, Thomas (6507624477); Iro, Heinrich (55934673000)",7101650824; 6507624477; 55934673000,Age-Related Decline of Speech Perception,2022,Frontiers in Aging Neuroscience,14,,891202,,,,6,10.3389/fnagi.2022.891202,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133756081&doi=10.3389%2ffnagi.2022.891202&partnerID=40&md5=c9831f7c78fc7be1482d90faea13254e,"Hearing loss is one of the most common disorders worldwide. It affects communicative abilities in all age groups. However, it is well known that elderly people suffer more frequently from hearing loss. Two different model approaches were employed: A generalised linear model and a random forest regression model were used to quantify the relationship between pure-tone hearing loss, age, and speech perception. Both models were applied to a large clinical data set of 19,801 ears, covering all degrees of hearing loss. They allow the estimation of age-related decline in speech recognition for different types of audiograms. Our results show that speech scores depend on the specific type of hearing loss and life decade. We found age effects for all degrees of hearing loss. A deterioration in speech recognition of up to 25 percentage points across the whole life span was observed for constant pure-tone thresholds. The largest decrease was 10 percentage points per life decade. This age-related decline in speech recognition cannot be explained by elevated hearing thresholds as measured by pure-tone audiometry. Copyright © 2022 Hoppe, Hocke and Iro.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85133756081
Suresh K.; Franck K.; Arenberg J.G.; Song Y.; Lee D.J.; Crowson M.G.,"Suresh, Krish (57191546303); Franck, Kevin (6603882325); Arenberg, Julie G. (57189058088); Song, Yohan (56136431900); Lee, Daniel J. (55547132033); Crowson, Matthew G. (56631418200)",57191546303; 6603882325; 57189058088; 56136431900; 55547132033; 56631418200,Development of a Predictive Model for Individualized Hearing Aid Benefit,2023,Otology and Neurotology,44,1,,E1,E7,6,1,10.1097/MAO.0000000000003739,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144094074&doi=10.1097%2fMAO.0000000000003739&partnerID=40&md5=7d4464f7cc500aab4cadada000193235,"Objectives To develop a model to predict individualized hearing aid benefit. To provide interpretations of model predictions on global and individual levels. Methods We compiled a data set of patients with hearing loss who trialed hearing aids and completed the Client Oriented Scale of Improvement (COSI) questionnaire, a validated patient-reported outcome measure of hearing aid benefit. Features included demographic, medical, and audiological measures. The outcome was the COSI score for change in listening ability with hearing aids, scaled from 1 to 5. Model development was performed using fivefold cross-validation repeated three times with hyperparameter tuning. Model performance was assessed using the root mean squared error (RMSE) of the COSI scores. Model interpretation was performed using Shapley Additive Explanations. Results The data set comprised 1,286 patients across 3,523 listening situations. The best performing model was random forest with an RMSE of 0.80, found to be significantly better than the next best model (eXtreme gradient boosting with RMSE of 0.85, p < 0.01). The most important features in predicting hearing aid benefit were shorter duration of hearing aid use, higher pure-tone average in the better hearing ear, and younger age. Conclusion We have developed a predictive model for hearing aid benefit that can also provide individualized explanations of model predictions. Predictive modeling could be a useful tool in assessing a patient's candidacy and predicted benefit from hearing aids.  © Wolters Kluwer Health, Inc. All rights reserved.",36413361,Article,Final,,Scopus,2-s2.0-85144094074
Grierson K.E.; Hickman T.T.; Liberman M.C.,"Grierson, Kiera E. (57212485682); Hickman, Tyler T. (57211488161); Liberman, M. Charles (57216596032)",57212485682; 57211488161; 57216596032,Dopaminergic and cholinergic innervation in the mouse cochlea after noise-induced or age-related synaptopathy,2022,Hearing Research,422,,108533,,,,4,10.1016/j.heares.2022.108533,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131384612&doi=10.1016%2fj.heares.2022.108533&partnerID=40&md5=9b62d0b7b729e90e9b20596e0404b253,"Cochlear synaptopathy, the loss of or damage to connections between auditory-nerve fibers (ANFs) and inner hair cells (IHCs), is a prominent pathology in noise-induced and age-related hearing loss. Here, we investigated if degeneration of the olivocochlear (OC) efferent innervation is also a major aspect of the synaptopathic ear, by quantifying the volume and spatial organization of its cholinergic and dopaminergic components, using antibodies to vesicular acetylcholine transporter (VAT) and tyrosine hydroxylase (TH), respectively. CBA/CaJ male mice were examined 1 day to 8 months after a synaptopathic noise exposure, and compared to unexposed age-matched controls and unexposed aged mice at 24-28 months. In normal ears, cholinergic lateral (L)OC terminals were denser in the apical half of the cochlea and on the modiolar side of the inner hair cells (IHCs), where ANFs of low-spontaneous rate are typically found, while dopaminergic terminals were more common in the basal third of the cochlea and, re the IHC axes, were offset towards the habenula with respect to cholinergic terminals. The noise had only small and transient effects on the density of LOC innervation, its spatial organization around the IHC axes, or the extent to which TH and VAT signal were colocalized. The synaptopathic noise also had relatively small and transient effects on cholinergic innervation density in the outer hair cell (OHC) area, which normally peaks in the 16 kHz region and falls monotonically towards higher and lower frequencies. In contrast, in the aged ears, there was massive degeneration of OHC efferents, especially in the apical half of the cochlea, where there was also significant loss of OHCs. In the IHC area, there was significant loss of cholinergic terminals in both apical and basal regions and of dopaminergic innervation in the basal half. Furthermore, the cholinergic terminals in the aged ears spread from their normal clustering near the IHC basolateral pole, where the ANF synapses are found, to positions up and down the IHC somata and regions of the neuropil closer to the habenula. This apparent migration was most striking in the apex, where the hair cell pathology was greatest, and may be a harbinger of impending hair cell death. © 2022",35671600,Article,Final,,Scopus,2-s2.0-85131384612
Shi X.; Wang Z.; Ren W.; Chen L.; Xu C.; Li M.; Fan S.; Xu Y.; Chen M.; Zheng F.; Zhang W.; Zhou X.; Zhang Y.; Qiu S.; Wu L.; Zhou P.; Lv X.; Cui T.; Qiao Y.; Zhao H.; Guo W.; Chen W.; Li S.; Zhong W.; Lin J.; Yang S.,"Shi, Xi (55785325800); Wang, Zihao (57219569188); Ren, Wei (57191057028); Chen, Long (56085101600); Xu, Cong (57746286100); Li, Menghua (57222588027); Fan, Shiyong (36185172800); Xu, Yuru (57218891986); Chen, Mengbing (57820465500); Zheng, Fanjun (57220998967); Zhang, Wenyuan (57220108763); Zhou, Xinbo (36186443700); Zhang, Yue (57735361200); Qiu, Shiwei (57203457907); Wu, Liyuan (57735361300); Zhou, Peng (57735361400); Lv, Xinze (57735390800); Cui, Tianyu (57735246800); Qiao, Yuehua (55992225700); Zhao, Hui (56159359400); Guo, Weiwei (55957341100); Chen, Wei (57087430400); Li, Song (36072901600); Zhong, Wu (35424990900); Lin, Jian (57205479338); Yang, Shiming (8074203500)",55785325800; 57219569188; 57191057028; 56085101600; 57746286100; 57222588027; 36185172800; 57218891986; 57820465500; 57220998967; 57220108763; 36186443700; 57735361200; 57203457907; 57735361300; 57735361400; 57735390800; 57735246800; 55992225700; 56159359400; 55957341100; 57087430400; 36072901600; 35424990900; 57205479338; 8074203500,"LDL receptor-related protein 1 (LRP1), a novel target for opening the blood-labyrinth barrier (BLB)",2022,Signal Transduction and Targeted Therapy,7,1,175,,,,9,10.1038/s41392-022-00995-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131711394&doi=10.1038%2fs41392-022-00995-z&partnerID=40&md5=2cb3a691d9fdd245393f5c6b9f607ef8,"Inner ear disorders are a cluster of diseases that cause hearing loss in more than 1.5 billion people worldwide. However, the presence of the blood-labyrinth barrier (BLB) on the surface of the inner ear capillaries greatly hinders the effectiveness of systemic drugs for prevention and intervention due to the low permeability, which restricts the entry of most drug compounds from the bloodstream into the inner ear tissue. Here, we report the finding of a novel receptor, low-density lipoprotein receptor-related protein 1 (LRP1), that is expressed on the BLB, as a potential target for shuttling therapeutics across this barrier. As a proof-of-concept, we developed an LRP1-binding peptide, IETP2, and covalently conjugated a series of model small-molecule compounds to it, including potential drugs and imaging agents. All compounds were successfully delivered into the inner ear and inner ear lymph, indicating that targeting the receptor LRP1 is a promising strategy to enhance the permeability of the BLB. The discovery of the receptor LRP1 will illuminate developing strategies for crossing the BLB and for improving systemic drug delivery for inner ear disorders. © 2022, The Author(s).",35680846,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131711394
Jin X.; Zhang L.; Wang X.; An L.; Huang S.; Dai P.; Gao H.; Ma X.,"Jin, Xiaohua (24338200500); Zhang, Lu (57850859700); Wang, Xinjie (55935248900); An, Lisha (56701777500); Huang, Shasha (51863809500); Dai, Pu (7006395563); Gao, Huafang (56580843300); Ma, Xu (35196580300)",24338200500; 57850859700; 55935248900; 56701777500; 51863809500; 7006395563; 56580843300; 35196580300,Novel CRISPR/Cas12a-based genetic diagnostic approach for SLC26A4 mutation-related hereditary hearing loss,2022,European Journal of Medical Genetics,65,2,104406,,,,3,10.1016/j.ejmg.2021.104406,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122285620&doi=10.1016%2fj.ejmg.2021.104406&partnerID=40&md5=2722b180d30eaccf8b3c8a719dc4b6c8,"Hereditary hearing loss is a common defect of the auditory nervous system with high-incidence, seriously affecting the quality of life of the patients. The clinical manifestations of SLC26A4 mutation-related hearing loss are congenital sensorineural or mixed deafness. Sensitive and specific SLC26A4 mutation detection in the early clinical stage is key for the early indication of potential hearing loss in the lack of effective treatment. Using clustered regularly interspaced short palindromic repeats (CRISPR)-based nucleic acid detection technology, we designed a fast and sensitive detection system for SLC26A4 pathogenic mutations (c.919-2A > G, c.2168A > G and c.1229C > T). This recombinase-aided amplification-based detection system allows rapid target gene amplification and, in combination with the CRISPR-based nucleic acid testing (NAT) system, mutation site detection. Moreover, mismatches were introduced in CRISPR-derived RNA (crRNA) to increase signal differences between the wild-type genes and mutant genes. A total of 64 samples were examined using this approach and all results were verified using Sanger sequencing. The detection results were consistent with the polymerase chain reaction-Sanger sequencing results. Overall, this CRISPR-based NAT technology provides a sensitive and fast new approach for the detection of hereditary deafness and provides a crRNA optimization strategy for single-nucleotide polymorphism detection, which could be helpful for the clinical diagnosis of SLC26A4 mutation-related hereditary hearing loss. © 2021",34968750,Article,Final,,Scopus,2-s2.0-85122285620
Carey G.E.; Jacobson C.E.; Warburton A.N.; Biddle E.; Mannarelli G.; Wilson M.; Stucken E.Z.,"Carey, Grace E. (56926241800); Jacobson, Clare E. (57192649768); Warburton, Alyssa N. (57712500100); Biddle, Elliot (57212764137); Mannarelli, Greg (54381948700); Wilson, Michael (58273696000); Stucken, Emily Z. (36057570200)",56926241800; 57192649768; 57712500100; 57212764137; 54381948700; 58273696000; 36057570200,Machine Learning for Vestibular Schwannoma Diagnosis Using Audiometrie Data Alone,2022,Otology and Neurotology,43,5,,E530,E534,4,3,10.1097/MAO.0000000000003539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130837320&doi=10.1097%2fMAO.0000000000003539&partnerID=40&md5=2ac51dfc236277d191a4b34bfc3f10af,"Objective: The aim of this study is to compare machine learning algorithms and established rule-based evaluations in screening audiograms for the purpose of diagnosing vestibular schwannomas. A secondary aim is to assess the performance of rule-based evaluations for predicting vestibular schwannomas using the largest dataset in the literature. Study Design: Retrospective case-control study. Setting: Tertiary referral center. Patients: Seven hundred sixty seven adult patients with confirmed vestibular schwannoma and a pretreatment audiogram on file and 2000 randomly selected adult controls with audiograms. Intervention(s): Audiometric data were analyzed using machine learning algorithms and standard rule-based criteria for defining asymmetric hearing loss. Main Outcome Measures: The primary outcome is the ability to identify patients with vestibular schwannomas based on audiometric data alone, using machine learning algorithms and rule-based formulas. The secondary outcome is the application of conventional rule-based formulas to a larger dataset using advanced computational techniques. Results: The machine learning algorithms had mildly improved specificity in some fields compared with rule-based evaluations and had similar sensitivity to previous rule-based evaluations in diagnosis of vestibular schwannomas. Conclusions: Machine learning algorithms perform similarly to rule-based evaluations in identifying patients with vestibular schwannomas based on audiometric data alone. Performance of established rule-based formulas was consistent with earlier performance metrics, when analyzed using a large dataset. © 2022, Otology & Neurotology, Inc.",35617004,Article,Final,,Scopus,2-s2.0-85130837320
Sheng Y.; Yang C.; Curhan S.; Curhan G.; Wang M.,"Sheng, Yanghui (57897120100); Yang, Ce (57783601000); Curhan, Sharon (6506501242); Curhan, Gary (7006279647); Wang, Molin (12774321000)",57897120100; 57783601000; 6506501242; 7006279647; 12774321000,Analytical methods for correlated data arising from multicenter hearing studies,2022,Statistics in Medicine,41,26,,5335,5348,13,9,10.1002/sim.9572,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138388573&doi=10.1002%2fsim.9572&partnerID=40&md5=17595e341c57f39c4b2c40b93a5f7875,"In epidemiological hearing studies, estimating the association between exposures and hearing loss using audiometrically-assessed hearing measurements is challenging due to the complex correlation structure in the clustered data, with clusters formed by the two ears of the same individual and the testing site and audiologist. We propose a linear mixed-effects model to take into account the multilevel correlation structures of the data. Both theoretically and in simulation studies, we compare single-ear linear regression models commonly used in published hearing loss studies with the proposed both-ears linear mixed models properly accounting for the multi-level correlations. Our findings include (1) when there are only participant-level covariates, the worse-ear linear regression models produce unbiased but typically less efficient estimators than the both-ear and average-ear approaches; (2) when there are ear-level confounders, the worse-ear method may lead to biased estimators and the average-ear method produces unbiased but typically less efficient estimators than the both-ear method; (3) the both-ear method may gain efficiency when additionally adjusting for testing sites and audiologists. As an illustrative example, we applied the single-ear and both-ear methods to assess aspirin-hearing association in the Nurses' Health Study II. © 2022 John Wiley & Sons Ltd.",36125070,Article,Final,,Scopus,2-s2.0-85138388573
Wasmann J.-W.; Pragt L.; Eikelboom R.; Swanepoel D.W.,"Wasmann, Jan-Willem (57203991961); Pragt, Leontien (57440381100); Eikelboom, Robert (7006848551); Swanepoel, De Wet (13609471200)",57203991961; 57440381100; 7006848551; 13609471200,Digital Approaches to Automated and Machine Learning Assessments of Hearing: Scoping Review,2022,Journal of Medical Internet Research,24,2,e32581,,,,16,10.2196/32581,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124056113&doi=10.2196%2f32581&partnerID=40&md5=6bb1458585b20492ac26fa319e212ab6,"Background: Hearing loss affects 1 in 5 people worldwide and is estimated to affect 1 in 4 by 2050. Treatment relies on the accurate diagnosis of hearing loss; however, this first step is out of reach for >80% of those affected. Increasingly automated approaches are being developed for self-administered digital hearing assessments without the direct involvement of professionals. Objective: This study aims to provide an overview of digital approaches in automated and machine learning assessments of hearing using pure-tone audiometry and to focus on the aspects related to accuracy, reliability, and time efficiency. This review is an extension of a 2013 systematic review. Methods: A search across the electronic databases of PubMed, IEEE, and Web of Science was conducted to identify relevant reports from the peer-reviewed literature. Key information about each report’s scope and details was collected to assess the commonalities among the approaches. Results: A total of 56 reports from 2012 to June 2021 were included. From this selection, 27 unique automated approaches were identified. Machine learning approaches require fewer trials than conventional threshold-seeking approaches, and personal digital devices make assessments more affordable and accessible. Validity can be enhanced using digital technologies for quality surveillance, including noise monitoring and detecting inconclusive results. Conclusions: In the past 10 years, an increasing number of automated approaches have reported similar accuracy, reliability, and time efficiency as manual hearing assessments. New developments, including machine learning approaches, offer features, versatility, and cost-effectiveness beyond manual audiometry. Used within identified limitations, automated assessments using digital devices can support task-shifting, self-care, telehealth, and clinical care pathways. ©Jan-Willem Wasmann, Leontien Pragt, Robert Eikelboom, De Wet Swanepoel.",34919056,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124056113
Pai K.V.; Thilagam P.S.,"Pai, K Venkataramana (58040197600); Thilagam, P. Santhi (55666234500)",58040197600; 55666234500,"Hearing Loss Prediction using Machine Learning Approaches: Contributions, Limitations and Issues",2022,"2022 IEEE 3rd Global Conference for Advancement in Technology, GCAT 2022",,,,,,,0,10.1109/GCAT55367.2022.9972110,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145441672&doi=10.1109%2fGCAT55367.2022.9972110&partnerID=40&md5=c9528b67fbbcaffc6065652dd06a734e,"Hearing, one of the five basic human senses is the ability to perceive sounds and give meaning to them. Hearing loss is a significant health problem affecting children and adults and is growing exponentially. There is a lack of knowledge regarding hearing loss despite enough awareness, resulting in detection and treatment delays. The need for detection at an early stage is significant so that people can take necessary precautions given the limited options for treatment. This paper aims to survey machine learning-based hearing loss prediction. We investigate datasets, machine learning methods, and their outcomes. We also discuss the constraints, difficulties, and intended future works. Based on the results of this survey, we have a greater understanding of the problem's complexity, the obstacles to developing a better system, and the scope of the research, which has led us to concentrate our efforts in the future on analysing data from newborns, infants, and young children. © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85145441672
Zheng Z.; Li G.; Cui C.; Wang F.; Wang X.; Xu Z.; Guo H.; Chen Y.; Tang H.; Wang D.; Huang M.; Chen Z.-Y.; Huang X.; Li H.; Li G.-L.; Hu X.; Shu Y.,"Zheng, Ziwen (57489533000); Li, Guo (57226451344); Cui, Chong (57216818962); Wang, Fang (58601341600); Wang, Xiaohan (58609812000); Xu, Zhijiao (57208878689); Guo, Huiping (57489360500); Chen, Yuxin (57217034706); Tang, Honghai (57223052015); Wang, Daqi (57194396531); Huang, Mingqian (7404260318); Chen, Zheng-Yi (57209865740); Huang, Xingxu (8688812300); Li, Huawei (57221546012); Li, Geng-Lin (8595887200); Hu, Xiaoxiang (56555429600); Shu, Yilai (56577263700)",57489533000; 57226451344; 57216818962; 58601341600; 58609812000; 57208878689; 57489360500; 57217034706; 57223052015; 57194396531; 7404260318; 57209865740; 8688812300; 57221546012; 8595887200; 56555429600; 56577263700,Preventing autosomal-dominant hearing loss in Bth mice with CRISPR/CasRx-based RNA editing,2022,Signal Transduction and Targeted Therapy,7,1,79,,,,21,10.1038/s41392-022-00893-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126424071&doi=10.1038%2fs41392-022-00893-4&partnerID=40&md5=963509fa717b51e75628bdbd4f2660d1,"CRISPR/RfxCas13d (CasRx) editing system can specifically and precisely cleave single-strand RNAs, which is a promising treatment for various disorders by downregulation of related gene expression. Here, we tested this RNA-editing approach on Beethoven (Bth) mice, an animal model for human DFNA36 due to a point mutation in Tmc1. We first screened 30 sgRNAs in cell cultures and found that CasRx with sgRNA3 reduced the Tmc1Bth transcript by 90.8%, and the Tmc1 wild type transcript (Tmc1+) by 44.3%. We then injected a newly developed AAV vector (AAV-PHP.eB) based CasRx into the inner ears of neonatal Bth mice, and we found that Tmc1Bth was reduced by 70.2% in 2 weeks with few off-target effects in the whole transcriptome. Consistently, we found improved hair cell survival, rescued hair bundle degeneration, and reduced mechanoelectrical transduction current. Importantly, the hearing performance, measured in both ABR and DPOAE thresholds, was improved significantly in all ages over 8 weeks. We, therefore, have validated the CRISPR/CasRx-based RNA editing strategy in treating autosomal-dominant hearing loss, paving way for its further application in many other hereditary diseases in hearing and beyond. © 2022, The Author(s).",35283480,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85126424071
Kodituwakku P.; Kodituwakku E.L.,"Kodituwakku, Piyadasa (6602564908); Kodituwakku, E. Louise (37111138800)",6602564908; 37111138800,Fetal Alcohol Syndrome,2022,Neuroscience in the 21st Century: From Basic to Clinical: Third Edition,,,,3627,3647,20,0,10.1007/978-3-030-88832-9_90,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160128660&doi=10.1007%2f978-3-030-88832-9_90&partnerID=40&md5=c4c7b54d10086b389b6486778ea81ab9,"Maternal alcohol consumption during pregnancy is known to produce a spectrum of morphological and neurocognitive outcomes in the offspring. The most severely affected on the spectrum exhibit a cluster of birth defects called fetal alcohol syndrome, which is characterized by a unique pattern of anomalies on the face, prenatal and/or postnatal growth deficiency, and evidence of central nervous system (CNS) dysfunction (Jones et al, Lancet 1:1267–1271, 1973). The characteristic pattern of malformations on the face includes a smooth philtrum, thin upper lip, and short palpebral fissures (see Fig. 1). Children with FASD are usually small in stature, with their height and weight falling below the 10th percentile. The deleterious effects of alcohol on the central nervous system are evidenced by microcephaly and cognitive and behavioral deficits. Children with prenatal alcohol exposure have also been observed to exhibit birth defects involving other systems such as cardiac (e.g., atrial and ventricular septal defects), skeletal (e.g., clinodactyly and camptodactyly), ocular (e.g., strabismus), and auditory (e.g., conductive hearing loss). However, the majority of children on the spectrum display only some or none of the above physical features but exhibit evidence of CNS dysfunction. The term, “alcohol-related neurodevelopmental disorder” (ARND), is used to label neurodevelopmental difficulties in those alcohol-exposed children without clinically discernable physical anomalies (Stratton et al (eds) Fetal alcohol syndrome: diagnosis, epidemiology, prevention, and treatment. National Academy Press, Washington, DC, 1996). Although not a diagnostic label, the term “fetal alcohol spectrum disorders” (FASDs) has been introduced to denote the full spectrum of morphological and neurocognitive outcomes resulting from prenatal alcohol exposure. While estimated prevalence rates of FAS range from.5 to 2 cases per 1,000 live births, the rate of FASD is estimated at 1 per 100 (Sampson et al, Teratology 56:317–326, 1997). © Springer Science+Business Media New York 2013, 2016 and Springer Nature Switzerland AG 2022.",,Book chapter,Final,,Scopus,2-s2.0-85160128660
Fu Y.-P.; Chen W.-Y.; Guo L.-Q.; Zhu Y.-Q.; Yuan J.-S.; Liu Y.-H.,"Fu, Yan-Peng (57320098100); Chen, Wen-Yu (57223866824); Guo, Li-Qing (57320571900); Zhu, Ya-Qiong (57209344796); Yuan, Jia-Sheng (57344405700); Liu, Yue-Hui (36052017100)",57320098100; 57223866824; 57320571900; 57209344796; 57344405700; 36052017100,The association between hearing threshold and urinary personal care and consumer product metabolites in middle-aged and elderly people from the USA,2022,Environmental Science and Pollution Research,29,53,,81076,81086,10,1,10.1007/s11356-022-21459-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132336859&doi=10.1007%2fs11356-022-21459-5&partnerID=40&md5=067f85dc72b9d556e0b34a13488ec3bf,"Endocrine disruptors have been reported to be associated with hearing ability. However, the association between personal care and consumer product chemicals, known as commonly detected endocrine disruptors, and age-related hearing loss still remains unclear. This study aimed to examine the association between exposure to 7 personal care and consumer product chemicals and hearing thresholds in middle-aged and elderly people. A nationally representative cross-sectional study was performed. Eight hundred forty-five adults aged over 45 from the National Health and Nutrition Examination Survey (NHANES) were included in this study. Bayesian kernel machine regression (BKMR) and the k-medoid cluster analysis were used to evaluate the mixture effect of exposure to 7 chemicals on pure-tone average (PTA). Exposure to these chemicals was negatively associated with PTA. 2,5-Dichlorophenol had the greatest contribution to the mixture effect. The mixture effect was stronger in women, elderly people. Four pooled clusters were identified according to 7 chemicals exposures. Cluster 4 (high TCS exposure) showed a lower HFPTA (P = 0.00258) than cluster 3 (the lowest exposure cluster, as a reference). Our study provides evidence that exposure to personal care and consumer product chemicals might be inversely associated with PTA. More studies are needed to fully understand the association of exposure to these chemicals with hearing threshold. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",35731440,Article,Final,,Scopus,2-s2.0-85132336859
Saremi A.; Stenfelt S.,"Saremi, Amin (57159463300); Stenfelt, Stefan (55879660000)",57159463300; 55879660000,The effects of noise-induced hair cell lesions on cochlear electromechanical responses: A computational approach using a biophysical model,2022,International Journal for Numerical Methods in Biomedical Engineering,38,5,e3582,,,,0,10.1002/cnm.3582,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124885169&doi=10.1002%2fcnm.3582&partnerID=40&md5=c272e443c82cc665954addb6e8d6d2bd,"A biophysically inspired signal processing model of the human cochlea is deployed to simulate the effects of specific noise-induced inner hair cell (IHC) and outer hair cell (OHC) lesions on hearing thresholds, cochlear compression, and the spectral and temporal features of the auditory nerve (AN) coding. The model predictions were evaluated by comparison with corresponding data from animal studies as well as human clinical observations. The hearing thresholds were simulated for specific OHC and IHC damages and the cochlear nonlinearity was assessed at 0.5 and 4 kHz. The tuning curves were estimated at 1 kHz and the contributions of the OHC and IHC pathologies to the tuning curve were distinguished by the model. Furthermore, the phase locking of AN spikes were simulated in quiet and in presence of noise. The model predicts that the phase locking drastically deteriorates in noise indicating the disturbing effect of background noise on the temporal coding in case of hearing impairment. Moreover, the paper presents an example wherein the model is inversely configured for diagnostic purposes using a machine learning optimization technique (Nelder–Mead method). Accordingly, the model finds a specific pattern of OHC lesions that gives the audiometric hearing loss measured in a group of noise-induced hearing impaired humans. © 2022 The Authors. International Journal for Numerical Methods in Biomedical Engineering published by John Wiley & Sons Ltd.",35150464,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85124885169
Jaschke A.C.; Bos A.F.,"Jaschke, Artur C. (55246324300); Bos, Arend F. (36839156800)",55246324300; 36839156800,Concept and considerations of a medical device: the active noise cancelling incubator,2023,Frontiers in Pediatrics,11,,1187815,,,,0,10.3389/fped.2023.1187815,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165135363&doi=10.3389%2ffped.2023.1187815&partnerID=40&md5=72d67461f6b91e30391b0f77e10afdb0,"Background: An increasingly 24/7 connected and urbanised world has created a silent pandemic of noise-induced hearing loss. Ensuring survival to children born (extremely) preterm is crucial. The incubator is a closed medical device, modifying the internal climate, and thus providing an environment for the child, as safe, warm, and comfortable as possible. While sound outside the incubator is managed and has decreased over the years, managing the noise inside the incubator is still a challenge. Method: Using active noise cancelling in an incubator will eliminate unwanted sounds (i.e., from the respirator and heating) inside the incubator, and by adding sophisticated algorithms, normal human speech, neonatal intensive care unit music-based therapeutic interventions, and natural sounds will be sustained for the child in the pod. Applying different methods such as active noise cancelling, motion capture, sonological engineering. and sophisticated machine learning algorithms will be implemented in the development of the incubator. Projected Results: A controlled and active sound environment in and around the incubator can in turn promote the wellbeing, neural development, and speech development of the child and minimise distress caused by unwanted noises. While developing the hardware and software pose individual challenges, it is about the system design and aspects contributing to it. On the one hand, it is crucial to measure the auditory range and frequencies in the incubator, as well as the predictable sounds that will have to be played back into the environment. On the other, there are many technical issues that have to be addressed when it comes to algorithms, datasets, delay, microphone technology, transducers, convergence, tracking, impulse control and noise rejection, noise mitigation stability, detection, polarity, and performance. Conclusion: Solving a complex problem like this, however, requires a de-disciplinary approach, where each discipline will realise its own shortcomings and boundaries, and in turn will allow for innovations and new avenues. Technical developments used for building the active noise cancellation-incubator have the potential to contribute to improved care solutions for patients, both infants and adults. Code available at: 10.3389/fped.2023.1187815. 2023 Jaschke and Bos.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85165135363
Ma X.; Guo J.; Fu Y.; Shen C.; Jiang P.; Zhang Y.; Zhang L.; Yu Y.; Fan J.; Chai R.,"Ma, Xiangyu (57204680709); Guo, Jiamin (57484478600); Fu, Yaoyang (57223848405); Shen, Cangsong (57217030601); Jiang, Pei (57215013788); Zhang, Yuan (57854087100); Zhang, Lei (58607331600); Yu, Yafeng (56143721500); Fan, Jiangang (7402794729); Chai, Renjie (37065753300)",57204680709; 57484478600; 57223848405; 57217030601; 57215013788; 57854087100; 58607331600; 56143721500; 7402794729; 37065753300,G protein-coupled receptors in cochlea: Potential therapeutic targets for hearing loss,2022,Frontiers in Molecular Neuroscience,15,,1028125,,,,1,10.3389/fnmol.2022.1028125,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140626949&doi=10.3389%2ffnmol.2022.1028125&partnerID=40&md5=01f9bfe93a1c68b08f47833185cb8cf6,"The prevalence of hearing loss-related diseases caused by different factors is increasing worldwide year by year. Currently, however, the patient’s hearing loss has not been effectively improved. Therefore, there is an urgent need to adopt new treatment measures and treatment techniques to help improve the therapeutic effect of hearing loss. G protein-coupled receptors (GPCRs), as crucial cell surface receptors, can widely participate in different physiological and pathological processes, particularly play an essential role in many disease occurrences and be served as promising therapeutic targets. However, no specific drugs on the market have been found to target the GPCRs of the cochlea. Interestingly, many recent studies have demonstrated that GPCRs can participate in various pathogenic process related to hearing loss in the cochlea including heredity, noise, ototoxic drugs, cochlear structure, and so on. In this review, we comprehensively summarize the functions of 53 GPCRs known in the cochlea and their relationships with hearing loss, and highlight the recent advances of new techniques used in cochlear study including cryo-EM, AI, GPCR drug screening, gene therapy vectors, and CRISPR editing technology, as well as discuss in depth the future direction of novel GPCR-based drug development and gene therapy for cochlear hearing loss. Collectively, this review is to facilitate basic and (pre-) clinical research in this area, and provide beneficial help for emerging GPCR-based cochlear therapies. Copyright © 2022 Ma, Guo, Fu, Shen, Jiang, Zhang, Zhang, Yu, Fan and Chai.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85140626949
Eichler T.; Rötz W.; Kayser C.; Bröhl F.; Römer M.; Witteborg A.H.; Kummert F.; Sandmeier T.; Schulte C.; Stolz P.; Meyer K.; Sudhoff H.; Todt I.,"Eichler, Theda (57222059796); Rötz, Wiebke (57682256900); Kayser, Christoph (7006326383); Bröhl, Felix (57221343404); Römer, Michael (50861941200); Witteborg, Arne Henning (57681422700); Kummert, Franz (6602460088); Sandmeier, Tobias (57681140500); Schulte, Christoph (57681699300); Stolz, Patricia (57681975800); Meyer, Katharina (58282810100); Sudhoff, Holger (7006806083); Todt, Ingo (8723996000)",57222059796; 57682256900; 7006326383; 57221343404; 50861941200; 57681422700; 6602460088; 57681140500; 57681699300; 57681975800; 58282810100; 7006806083; 8723996000,Algorithm-Based Hearing and Speech Therapy Rehabilitation after Cochlear Implantation,2022,Brain Sciences,12,5,580,,,,0,10.3390/brainsci12050580,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129992444&doi=10.3390%2fbrainsci12050580&partnerID=40&md5=f934a86ecc03640c0f02594652b96e3b,"Introduction: Due to the changes in the indication range for cochlear implants and the demographic development towards an aging society, more and more people are in receipt of cochlear implants. An implantation requires a close-meshed audiological and logopedic aftercare. Hearing therapy rehabilitation currently requires great personnel effort and is time consuming. Hearing and speech therapy rehabilitation can be supported by digital hearing training programs. However, the apps currently on the market are to a limited degree personalized and structured. Increasing digital-ization makes it possible, especially in times of pandemics, to decouple hearing therapy treatment from everyday clinical practice. Material and Methods: For this purpose, an app is in development that provides hearing therapy tailored to the patient. The individual factors that influence hearing outcome are considered. Using intelligent algorithms, the app determines the selection of exercises, the level of difficulty and the speed at which the difficulty is increased. Results: The app works autonomously without being connected to local speech therapists. In addition, the app is able to analyze patient difficulties within the exercises and provides conclusions about the need for technical adjustments. Conclusions: The presented newly developed app represents a possibility to support, replace, expand and improve the classic outpatient hearing and speech therapy after CI implantation. The way the application works allows it to reach more people and provide a time-and cost-saving alternative to traditional therapy. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85129992444
Anderson S.R.; Jocewicz R.; Kan A.; Zhu J.; Tzeng S.; Litovsky R.Y.,"Anderson, Sean R. (57210580670); Jocewicz, Rachael (57218566099); Kan, Alan (55263239700); Zhu, Jun (55694009300); Tzeng, ShengLi (15754686900); Litovsky, Ruth Y. (6701642611)",57210580670; 57218566099; 55263239700; 55694009300; 15754686900; 6701642611,Sound source localization patterns and bilateral cochlear implants: Age at onset of deafness effects,2022,PLoS ONE,17,02-Feb,e0263516,,,,2,10.1371/journal.pone.0263516,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124230327&doi=10.1371%2fjournal.pone.0263516&partnerID=40&md5=b018d3d1b3ceaaa9e9a455ffa72cbda2,"The ability to determine a sound’s location is critical in everyday life. However, sound source localization is severely compromised for patients with hearing loss who receive bilateral cochlear implants (BiCIs). Several patient factors relate to poorer performance in listeners with BiCIs, associated with auditory deprivation, experience, and age. Critically, characteristic errors are made by patients with BiCIs (e.g., medial responses at lateral target locations), and the relationship between patient factors and the type of errors made by patients has seldom been investigated across individuals. In the present study, several different types of analysis were used to understand localization errors and their relationship with patient-dependent factors (selected based on their robustness of prediction). Binaural hearing experience is required for developing accurate localization skills, auditory deprivation is associated with degradation of the auditory periphery, and aging leads to poorer temporal resolution. Therefore, it was hypothesized that earlier onsets of deafness would be associated with poorer localization acuity and longer periods without BiCI stimulation or older age would lead to greater amounts of variability in localization responses. A novel machine learning approach was introduced to characterize the types of errors made by listeners with BiCIs, making them simple to interpret and generalizable to everyday experience. Sound localization performance was measured in 48 listeners with BiCIs using pink noise trains presented in free-field. Our results suggest that older age at testing and earlier onset of deafness are associated with greater average error, particularly for sound sources near the center of the head, consistent with previous research. The machine learning analysis revealed that variability of localization responses tended to be greater for individuals with earlier compared to later onsets of deafness. These results suggest that early bilateral hearing is essential for best sound source localization outcomes in listeners with BiCIs. Copyright: © 2022 Anderson et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",35134072,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124230327
Chen F.; Chen J.; Luo X.,"Chen, Fei (57219004705); Chen, Jing (56039497900); Luo, Xin (55667363000)",57219004705; 56039497900; 55667363000,Editorial: New discoveries in the benefits and outcomes of cochlear implantation,2022,Frontiers in Neuroscience,16,,1062582,,,,0,10.3389/fnins.2022.1062582,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143169777&doi=10.3389%2ffnins.2022.1062582&partnerID=40&md5=0cdb952403e13fdfaabfe5dc8e1cc71d,[No abstract available],,Editorial,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85143169777
Boboshko M.Y.; Garbaruk E.S.; Golovanova L.E.; Maltseva N.V.; Berdnikova I.P.; Markelov O.A.; Shpakovskaya I.I.; Romanov S.A.; Kaplun D.I.,"Boboshko, M.Y. (15218977400); Garbaruk, E.S. (57203240516); Golovanova, L.E. (56568953500); Maltseva, N.V. (7003831223); Berdnikova, I.P. (36764489600); Markelov, O.A. (56512189700); Shpakovskaya, I.I. (57207994178); Romanov, S.A. (57195323899); Kaplun, D.I. (57205093075)",15218977400; 57203240516; 56568953500; 7003831223; 36764489600; 56512189700; 57207994178; 57195323899; 57205093075,Analysis of hearing aids application in elderly patients,2023,Advances in gerontology = Uspekhi gerontologii,36,2,,265,273,8,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162830904&partnerID=40&md5=577e0f900ba7dc4c4b7f343c67addc96,"The aim of the study is to evaluate the possibility to implement machine learning to create a digital auditory profile for elderly patients and to analyze the hearing aid fitting efficacy depending on involvement of the peripheral and central auditory pathways in a pathological process. Data analysis of 375 people aged 60-93 years is presented. 355 patients with chronic bilateral hearing loss (230 of them used hearing aids) were included in the main group, and 20 normal hearing elderly people were included in the control group. Audiological examination consisted of standard tests (pure tone audiometry, impedancemetry, speech audiometry in quiet) and tests to evaluate the central auditory processing (binaural fusion, dichotic digits, speech audiometry in noise, random gap detection). The Montreal Cognitive Assessment was used to detect cognitive impairment. The hearing aid fitting efficiency was evaluated with COSI questionnaire and speech audiometry in free field. Processing of the results was carried out using Pearson's correlation analysis aimed at creating a polynomial model of a patient's hearing on the basis of the limited test battery. There were close correlations between the state of cognitive functions and age, results of tests to evaluate the central auditory processing, as well as patients' satisfaction of hearing aid. The results of the work indicate the possibility of using computer technologies of data analysis to develop rehabilitation programs for elderly hearing impaired patients.; Цель исследования — оценка возможности внедрения методов машинного обучения для создания цифрового слухового профиля у пациентов старших возрастных групп и анализа эффективности слухопротезирования в зависимости от вовлеченности в патологический процесс периферических и центральных отделов слуховой системы. Представлены результаты обследования 375 лиц 60–93 лет, из которых в основную группу вошли 355 пациентов с хронической двусторонней тугоухостью (230 из них использовали слуховые аппараты), а в контрольную — 20 человек пожилого возраста с нормальными порогами слуха. Аудиологическое обследование включало базовые методики (тональная пороговая и надпороговая аудиометрия, импедансометрия, речевая аудиометрия в тишине) и методы оценки состояния центральных отделов слуховой системы (тест чередующейся бинаурально речью, дихотический числовой тест, речевая аудиометрия в шуме, тест обнаружения паузы). Диагностику состояния когнитивных функций осуществляли с использованием Монреальской когнитивной шкалы. Эффективность слухопротезирования оценивали посредством анкетирования и речевой аудиометрии в свободном звуковом поле. Обработку результатов проводили с применением корреляционного анализа Пирсона, направленного на создание полиномиальной модели слуха пациента на основе ограниченного набора тестов. Выявлены корреляции состояния когнитивных функций и возраста, выполнения ряда тестов по оценке центральных отделов слуховой системы, а также успешности применения слуховых аппаратов. Результаты работы свидетельствуют о возможности использования компьютерных технологий анализа данных для разработки программ реабилитации пациентов старших возрастных групп с нарушениями слуха.",37356105,Article,Final,,Scopus,2-s2.0-85162830904
Polo E.M.; Mollura M.; Barbieri R.; Paglialonga A.,"Polo, Edoardo Maria (57213605525); Mollura, Maximiliano (57204651438); Barbieri, Riccardo (35483096800); Paglialonga, Alessia (23668671800)",57213605525; 57204651438; 35483096800; 23668671800,Multivariate Classification of Mild and Moderate Hearing Loss Using a Speech-in-Noise Test for Hearing Screening at a Distance,2023,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",456 LNICST,,,81,92,11,1,10.1007/978-3-031-28663-6_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151054296&doi=10.1007%2f978-3-031-28663-6_7&partnerID=40&md5=54da58135c3e66357c6d30882d27a9cc,"In the area of smartphone-based hearing screening, the number of speech-in-noise tests available is growing rapidly. However, the available tests are typically based on a univariate classification approach, for example using the speech recognition threshold (SRT) or the number of correct responses. There is still lack of multivariate approaches to screen for hearing loss (HL). Moreover, all the screening methods developed so far do not assess the degree of HL, despite the potential importance of this information in terms of patient education and clinical follow-up. The aim of this study was to characterize multivariate approaches to identify mild and moderate HL using a recently developed, validated speech-in-noise test for hearing screening at a distance, namely the WHISPER (Widespread Hearing Impairment Screening and PrEvention of Risk) test. The WHISPER test is automated, minimally dependent on the listeners’ native language, it is based on an optimized, efficient adaptive procedure, and it uses a multivariate approach. The results showed that age and SRT were the features with highest performance in identifying mild and moderate HL, respectively. Multivariate classifiers using all the WHISPER features achieved better performance than univariate classifiers, reaching an accuracy equal to 0.82 and 0.87 for mild and moderate HL, respectively. Overall, this study suggested that mild and moderate HL may be discriminated with high accuracy using a set of features extracted from the WHISPER test, laying the ground for the development of future self-administered speech-in-noise tests able to provide specific recommendations based on the degree of HL. © 2023, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",,Conference paper,Final,,Scopus,2-s2.0-85151054296
Wu H.; Wan W.; Jiang H.; Xiong Y.,"Wu, Huadong (57441219700); Wan, Wei (57288079300); Jiang, Hongqun (36439651500); Xiong, Yuanping (57202586517)",57441219700; 57288079300; 36439651500; 57202586517,Prognosis of Idiopathic Sudden Sensorineural Hearing Loss: The Nomogram Perspective,2023,"Annals of Otology, Rhinology and Laryngology",132,1,,5,12,7,10,10.1177/00034894221075114,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124081061&doi=10.1177%2f00034894221075114&partnerID=40&md5=9f1faa7e77381d1847e9d2c4b88177f3,"Objective: The aim of this study is to create a nomogram for accurately predicting the prognosis of idiopathic sudden sensorineural hearing loss (ISSNHL) and provide a reference for clinical treatment. Methods: Three hundred and twenty-three patients with ISSNHL were admitted from September 2014 to November 2020. The clinical data were retrospectively reviewed. Prognostic factors for ISSNHL were assessed based on univariate and multivariate logistic regression analysis and used to create a nomogram. Nomogram performance in terms of predictive and discriminatory ability was evaluated by calculating the concordance index (C-index) and generating calibration plots. Results: The overall hearing improvement rate was 41.4%, comprising complete recovery (13.3%), marked recovery (17.0%), and slight recovery (11.1%). Multivariate logistic regression analysis showed that age, symptoms of vertigo, interval between onset and treatment, low-density lipoprotein, and type of hearing loss were independent predictors of ISSNHL. A nomogram based on these 5 factors had a C index of 0.798 (95% confidence interval 0.750-0.845). Conclusions: Age, vertigo, interval between onset and treatment, low-density lipoprotein level, and type of hearing loss are closely associated with hearing recovery. The nomogram may enable prediction of the prognosis of ISSNHL and facilitate clinical decision-making. © The Author(s) 2022.",35081764,Article,Final,,Scopus,2-s2.0-85124081061
Oike H.; Tomita S.; Koyano H.; Azami K.,"Oike, Hideaki (35339633700); Tomita, Satoru (26533389100); Koyano, Hitoshi (57818405900); Azami, Kayo (57216817158)",35339633700; 26533389100; 57818405900; 57216817158,Garland chrysanthemum consumption ameliorates age-related hearing loss in C57BL/6 mouse; model system to explore hearing loss prevention foods in a short period,2022,"Bioscience, Biotechnology and Biochemistry",86,8,,1085,1094,9,0,10.1093/bbb/zbac092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134854933&doi=10.1093%2fbbb%2fzbac092&partnerID=40&md5=68f5a1b09d46fb7adee18b043242f937,"Garland chrysanthemum (Glebionis coronaria L.) is an antioxidant-rich leafy vegetable. We found that garland chrysanthemum consumption ameliorated age-related hearing loss (AHL) in C57BL/6J mice, an early onset model. We also found that AHL progression was significantly ameliorated by three of ten products. Metabolome analysis of the 10 products using nuclear magnetic resonance (NMR) spectroscopy indicated that phytosterols may be involved in the amelioration of AHL. However, the direct inhibitory effect of phytosterol mixture on mouse AHL progression was not identified. These results suggest that garland chrysanthemum consumption delays AHL development in mice and its efficiency varies depending on the source of the product. Our findings also suggest that phytosterol content in garland chrysanthemum functions as an evaluation marker for the efficiency. Furthermore, to accelerate the search for foods that prevent AHL, we have used these data to develop an automatic threshold determination method for auditory brainstem response using machine learning.  © 2022 The Author(s). Published by Oxford University Press on behalf of Japan Society for Bioscience, Biotechnology, and Agrochemistry.",35687003,Article,Final,,Scopus,2-s2.0-85134854933
Zeng J.; Kang W.; Chen S.; Lin Y.; Deng W.; Wang Y.; Chen G.; Ma K.; Zhao F.; Zheng Y.; Liang M.; Zeng L.; Ye W.; Li P.; Chen Y.; Chen G.; Gao J.; Wu M.; Su Y.; Zheng Y.; Cai Y.,"Zeng, Junbo (57221754210); Kang, Weibiao (57204272245); Chen, Suijun (12809083300); Lin, Yi (57208593735); Deng, Wenting (57711539600); Wang, Yajing (55934270400); Chen, Guisheng (56888033500); Ma, Kai (57216331738); Zhao, Fei (57213194373); Zheng, Yefeng (8062522600); Liang, Maojin (37051140100); Zeng, Linqi (57710773500); Ye, Weijie (57709757800); Li, Peng (56190912100); Chen, Yubin (52463298900); Chen, Guoping (57190117405); Gao, Jinliang (57711539700); Wu, Minjian (57221740021); Su, Yuejia (57221753079); Zheng, Yiqing (9747500000); Cai, Yuexin (55826218300)",57221754210; 57204272245; 12809083300; 57208593735; 57711539600; 55934270400; 56888033500; 57216331738; 57213194373; 8062522600; 37051140100; 57710773500; 57709757800; 56190912100; 52463298900; 57190117405; 57711539700; 57221740021; 57221753079; 9747500000; 55826218300,A Deep Learning Approach to Predict Conductive Hearing Loss in Patients With Otitis Media With Effusion Using Otoscopic Images,2022,JAMA Otolaryngology - Head and Neck Surgery,148,7,,612,620,8,7,10.1001/jamaoto.2022.0900,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130704347&doi=10.1001%2fjamaoto.2022.0900&partnerID=40&md5=a74add3341284fd2b386f89f7556991c,"Importance: Otitis media with effusion (OME) is one of the most common causes of acquired conductive hearing loss (CHL). Persistent hearing loss is associated with poor childhood speech and language development and other adverse consequence. However, to obtain accurate and reliable hearing thresholds largely requires a high degree of cooperation from the patients. Objective: To predict CHL from otoscopic images using deep learning (DL) techniques and a logistic regression model based on tympanic membrane features. Design, Setting, and Participants: A retrospective diagnostic/prognostic study was conducted using 2790 otoscopic images obtained from multiple centers between January 2015 and November 2020. Participants were aged between 4 and 89 years. Of 1239 participants, there were 209 ears from children and adolescents (aged 4-18 years [16.87%]), 804 ears from adults (aged 18-60 years [64.89%]), and 226 ears from older people (aged >60 years, [18.24%]). Overall, 679 ears (54.8%) were from men. The 2790 otoscopic images were randomly assigned into a training set (2232 [80%]), and validation set (558 [20%]). The DL model was developed to predict an average air-bone gap greater than 10 dB. A logistic regression model was also developed based on otoscopic features. Main Outcomes and Measures: The performance of the DL model in predicting CHL was measured using the area under the receiver operating curve (AUC), accuracy, and F1 score (a measure of the quality of a classifier, which is the harmonic mean of precision and recall; a higher F1 score means better performance). In addition, these evaluation parameters were compared to results obtained from the logistic regression model and predictions made by three otologists. Results: The performance of the DL model in predicting CHL showed the AUC of 0.74, accuracy of 81%, and F1 score of 0.89. This was better than the results from the logistic regression model (ie, AUC of 0.60, accuracy of 76%, and F1 score of 0.82), and much improved on the performance of the 3 otologists; accuracy of 16%, 30%, 39%, and F1 scores of 0.09, 0.18, and 0.25, respectively. Furthermore, the DL model took 2.5 seconds to predict from 205 otoscopic images, whereas the 3 otologists spent 633 seconds, 645 seconds, and 692 seconds, respectively. Conclusions and Relevance: The model in this diagnostic/prognostic study provided greater accuracy in prediction of CHL in ears with OME than those obtained from the logistic regression model and otologists. This indicates great potential for the use of artificial intelligence tools to facilitate CHL evaluation when CHL is unable to be measured.  © 2022 American Medical Association. All rights reserved.",35588049,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85130704347
Seo H.W.; Chung J.H.; Byun H.; Lee S.H.,"Seo, Hee Won (57214077539); Chung, Jae Ho (57192989487); Byun, Hayoung (35754265000); Lee, Seung Hwan (57219406696)",57214077539; 57192989487; 35754265000; 57219406696,Vestibular mapping assessment in idiopathic sudden sensorineural hearing loss,2022,Ear and Hearing,43,1,,242,249,7,11,10.1097/AUD.0000000000001129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122705465&doi=10.1097%2fAUD.0000000000001129&partnerID=40&md5=2ef308756748689343d775a41abddff5,"Objective: The aim of this study was to investigate patterns of semicircular canal (SCC) and otolith organ dysfunction by vestibular mapping, and to determine the clinical implications of treatment outcomes in idiopathic sudden sensorineural hearing loss (ISSNHL). Methods: We retrospectively reviewed 135 consecutive patients diagnosed with ISSNHL from January 2016 to December 2020. Patients underwent video-head impulse tests (vHIT) for each SCC, cervical vestibular- evoked myogenic potential test for the saccules, ocular vestibular- evoked myogenic potential test for the utricles, and hearing tests. Hearing outcomes were evaluated according to the American Academy of Otolaryngology-Head and Neck Surgery criteria and factors associated with prognosis were assessed. We also conducted vestibular mapping assessments and hierarchical cluster analysis. Results: Overall, utricular impairment (76, 56.3%) was the most frequent diagnosis in the 135 ISSNHL patients, followed by saccular impairment (59, 43.7%) and posterior SCC impairment (30, 22.2%). The mean number of affected end organs was 1.37 ± 1.24, with higher numbers in the complete recovery group than in the partial/no recovery groups. In a multivariate analysis, higher initial hearing level and abnormal vHIT results in the posterior SCC were associated with poor prognosis in ISSNHL. In hierarchical cluster analysis, horizontal SCC and anterior SCC showed the highest similarity but were in different clusters than posterior SCC, and the saccule and utricle were in separate clusters from the three SCCs. Conclusions: The vestibular end organ showed various patterns of dysfunction in patients with ISSNHL. Of the five vestibular end organs, only abnormal posterior SCC was associated with poor prognosis for hearing recovery. © 2022 Lippincott Williams and Wilkins. All rights reserved.",34524151,Article,Final,,Scopus,2-s2.0-85122705465
Udbhasa S.; Lelkada P.; Priyanka M.; Senarathna E.; Vidhanaarachchi S.; Wickramarathne J.; Wijekoon J.L.,"Udbhasa, Saluka (58608977700); Lelkada, Parami (58608977800); Priyanka, Modeesha (57517671400); Senarathna, Esala (58608644200); Vidhanaarachchi, Samitha (57480855300); Wickramarathne, Jagath (35147255200); Wijekoon, Janaka L. (53878874200)",58608977700; 58608977800; 57517671400; 58608644200; 57480855300; 35147255200; 53878874200,"Interactive, Visual-Learning based Tool for Hearing Impaired Children to Improve Language and Cognitive Skills",2023,"2023 International Conference on Information Technology: Cybersecurity Challenges for Sustainable Cities, ICIT 2023 - Proceeding",,,,416,421,5,1,10.1109/ICIT58056.2023.10225863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171805246&doi=10.1109%2fICIT58056.2023.10225863&partnerID=40&md5=d4a0f2b7ea6f399e833ec9548e6f66dd,"Hearing impairment is a common condition that affects millions of people worldwide, with approximately 1 in 1000 newborns experiencing some degree of hearing loss. This condition can significantly impact a person's quality of life, causing communication difficulties and social isolation. Early childhood hearing impairment can present significant challenges to a child's cognitive development, making it difficult for them to learn in a traditional educational setting. Consequently, there is an urge for effective learning tools that can assist hearing-impaired children in learning their first language. This paper introduces visual-based and interactive learning tools as a promising approach to enhancing the learning experience and engagement of hearing-impaired children. The proposed system utilizes machine learning to assess a child's initial status and subsequently generates adaptive content while continuously monitoring progress. Moreover, the system incorporates an object exploration feature that enables children to learn from their surroundings. Additionally, it employs natural language learning processes to present contextually similar content, supported by audio and lip movement analysis features that guide correct pronunciation. In response to the ML models utilized, object detection was accomplished through YOLO5, while lip movements were analyzed using LipNet. Regression models were deployed for assessing a child's initial status and subsequent progress. The data collection process involved comprehensive sources that covered a wide array of visual, auditory, and linguistic elements, with the dataset being rigorously tested and verified. Testing implementations were conducted in various real-world settings, encompassing diverse environmental factors and learning conditions. The YOLO model demonstrated an accuracy of 90.3%, LipNet achieved 92.2% accuracy in lip movement analysis, and the multivariate regression models showed a prediction accuracy of 92.8% in evaluating child progress.  © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85171805246
Becker L.; Keck A.; Rohleder N.; Müller-Voggel N.,"Becker, Linda (56747231700); Keck, Antonia (57641540300); Rohleder, Nicolas (6603180791); Müller-Voggel, Nadia (24528753000)",56747231700; 57641540300; 6603180791; 24528753000,Higher Peripheral Inflammation Is Associated With Lower Orbitofrontal Gamma Power in Chronic Tinnitus,2022,Frontiers in Behavioral Neuroscience,16,,883926,,,,4,10.3389/fnbeh.2022.883926,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128817949&doi=10.3389%2ffnbeh.2022.883926&partnerID=40&md5=6640e407f5eac1d38511a9c37911b20a,"Chronic tinnitus, the continuous perception of a phantom sound, is a highly prevalent audiological symptom, for which the underlying pathology has not yet been fully understood. It is associated with neurophysiological alterations in the central nervous system and chronic stress, which can be related with a disinhibition of the inflammatory system. We here investigated the association between resting-state oscillatory activity assessed with Magnetoencephalography (MEG), and peripheral inflammation assessed by C-reactive protein (CRP) in a group of patients with chronic tinnitus (N = 21, nine males, mean age: 40.6 ± 14.6 years). Additionally, CRP was assessed in an age- and sex-matched healthy control group (N = 21, nine males, mean age: 40.9 ± 15.2 years). No MEG data was available for the control group. We found a significant negative correlation between CRP and gamma power in the orbitofrontal cortex in tinnitus patients (p < 0.001), pointing to a deactivation of the orbitofrontal cortex when CRP was high. No significant clusters were found for other frequency bands. Moreover, CRP levels were significantly higher in the tinnitus group than in the healthy controls (p = 0.045). Our results can be interpreted based on findings from previous studies having disclosed the orbitofrontal cortex as part of the tinnitus distress network. We suggest that higher CRP levels and the associated deactivation of the orbitofrontal cortex in chronic tinnitus patients is maintaining the tinnitus percept through disinhibition of the auditory cortex and attentional or emotional top-down processes. Although the direction of the association (i.e., causation) between CRP levels and orbitofrontal gamma power in chronic tinnitus is not yet known, inflammation reducing interventions are promising candidates when developing treatments for tinnitus patients. Overall, our study highlights the importance of considering immune-brain communication in tinnitus research. Copyright © 2022 Becker, Keck, Rohleder and Müller-Voggel.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85128817949
Bao J.; Jegede S.L.; Hawks J.W.; Dade B.; Guan Q.; Middaugh S.; Qiu Z.; Levina A.; Tsai T.-H.,"Bao, Jianxin (8262099000); Jegede, Segun Light (57211603188); Hawks, John W. (7004065813); Dade, Bethany (57216830569); Guan, Qiang (36918359000); Middaugh, Samantha (57557722800); Qiu, Ziyu (55797760600); Levina, Anna (57558496300); Tsai, Tsung-Heng (56328919100)",8262099000; 57211603188; 7004065813; 57216830569; 36918359000; 57557722800; 55797760600; 57558496300; 56328919100,Detecting Cochlear Synaptopathy Through Curvature Quantification of the Auditory Brainstem Response,2022,Frontiers in Cellular Neuroscience,16,,851500,,,,2,10.3389/fncel.2022.851500,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127391194&doi=10.3389%2ffncel.2022.851500&partnerID=40&md5=392d42ae4aca165bd5524eaa5bf5a9c2,"The sound-evoked electrical compound potential known as auditory brainstem response (ABR) represents the firing of a heterogenous population of auditory neurons in response to sound stimuli, and is often used for clinical diagnosis based on wave amplitude and latency. However, recent ABR applications to detect human cochlear synaptopathy have led to inconsistent results, mainly due to the high variability of ABR wave-1 amplitude. Here, rather than focusing on the amplitude of ABR wave 1, we evaluated the use of ABR wave curvature to detect cochlear synaptic loss. We first compared four curvature quantification methods using simulated ABR waves, and identified that the cubic spline method using five data points produced the most accurate quantification. We next evaluated this quantification method with ABR data from an established mouse model with cochlear synaptopathy. The data clearly demonstrated that curvature measurement is more sensitive and consistent in identifying cochlear synaptic loss in mice compared to the amplitude and latency measurements. We further tested this curvature method in a different mouse model presenting with otitis media. The change in curvature profile due to middle ear infection in otitis media is different from the profile of mice with cochlear synaptopathy. Thus, our study suggests that curvature quantification can be used to address the current ABR variability issue, and may lead to additional applications in the clinic diagnosis of hearing disorders. Copyright © 2022 Bao, Jegede, Hawks, Dade, Guan, Middaugh, Qiu, Levina and Tsai.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85127391194
Hicks K.L.; Robler S.K.; Platt A.; Morton S.N.; Egger J.R.; Emmett S.D.,"Hicks, Kelli L. (57200938658); Robler, Samantha Kleindienst (57201022586); Platt, Alyssa (23480456100); Morton, Sarah N. (57219840416); Egger, Joseph R. (16439174800); Emmett, Susan D. (36052713800)",57200938658; 57201022586; 23480456100; 57219840416; 16439174800; 36052713800,Environmental Factors for Hearing Loss and Middle Ear Disease in Alaska Native Children and Adolescents: A Cross-Sectional Analysis from a Cluster Randomized Trial,2023,Ear and Hearing,44,1,,2,9,7,0,10.1097/AUD.0000000000001265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144594641&doi=10.1097%2fAUD.0000000000001265&partnerID=40&md5=5dfd0002e61d3ce78119018d1bce5a83,"Objectives: Infection-related childhood hearing loss is one of the few preventable chronic health conditions that can affect a child's lifelong trajectory. This study sought to quantify relationships between infection-mediated hearing loss and middle ear disease and environmental factors, such as exposure to wood smoke, cigarette smoke, household crowding, and lack of access to plumbed (running) water, in a northwest region of rural Alaska. Design: This study is a cross-sectional analysis to estimate environmental factors of infection-related hearing loss in children aged 3 to 21 years. School hearing screenings were performed as part of two cluster randomized trials in rural Alaska over two academic years (2017-2018 and 2018-2019). The first available screening for each child was used for this analysis. Sociodemographic questionnaires were completed by parents/guardians upon entry into the study. Multivariable regression was performed to estimate prevalence differences and prevalence ratios (PR). A priori knowledge about the prevalence of middle ear disease and the difficulty inherent in obtaining objective hearing loss data in younger children led to analysis of children by age (3 to 6 years versus 7 years and older) and a separate multiple imputation sensitivity analysis for pure-tone average (PTA)-based infection-related hearing loss measures. Results: A total of 1634 children participated. Hearing loss was present in 11.1% of children sampled based on otoacoustic emission as the primary indicator of hearing loss and was not associated with exposure to cigarette smoke (PR = 1.07; 95% confidence interval [CI], 0.48 to 2.38), use of a wood-burning stove (PR = 0.85; 95% CI, 0.55 to 1.32), number of persons living in the household (PR = 1.06; 95% CI, 0.97 to 1.16), or lack of access to running water (PR = 1.38; 95% CI, 0.80 to 2.39). Using PTA as a secondary indicator of hearing loss also showed no association with environmental factors. Middle ear disease was present in 17.4% of children. There was a higher prevalence of middle ear disease in homes without running water versus those with access to running water (PR = 1.53; 95% CI, 1.03 to 2.27). There was little evidence to support any cumulative effects of environmental factors. Heterogeneity of effect models by age found sample prevalence of hearing loss higher for children aged 3 to 6 years (12.2%; 95% CI, 9.3 to 15.7) compared to children 7 years and older (10.6%; 95% CI, 8.9 to 2.6), as well as for sample prevalence of middle ear disease (22.7%; 95% CI, 18.9 to 26.9 and 15.3%; 95% CI, 13.3 to 17.5, respectively). Conclusions: Lack of access to running water in the home was associated with increased prevalence of middle ear disease in this rural, Alaska Native population, particularly among younger children (aged 3 to 6 years). There was little evidence in this study that cigarette smoke, wood-burning stoves, and greater numbers of persons in the household were associated with infection-mediated hearing loss or middle ear disease. Future research with larger sample sizes and more sensitive measures of environmental exposure is necessary to further evaluate these relationships. Children who live in homes without access to running water may benefit from earlier and more frequent hearing health visits. © 2023 Lippincott Williams and Wilkins. All rights reserved.",35998103,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85144594641
Van Opstal A.J.; Noordanus E.,"Van Opstal, A. John (7003413417); Noordanus, Elisabeth (57221737309)",7003413417; 57221737309,Towards personalized and optimized fitting of cochlear implants,2023,Frontiers in Neuroscience,17,,1183126,,,,0,10.3389/fnins.2023.1183126,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166007622&doi=10.3389%2ffnins.2023.1183126&partnerID=40&md5=be9ddaa60c76eb941e092c86298d2df4,"A cochlear implant (CI) is a neurotechnological device that restores total sensorineural hearing loss. It contains a sophisticated speech processor that analyzes and transforms the acoustic input. It distributes its time-enveloped spectral content to the auditory nerve as electrical pulsed stimulation trains of selected frequency channels on a multi-contact electrode that is surgically inserted in the cochlear duct. This remarkable brain interface enables the deaf to regain hearing and understand speech. However, tuning of the large (>50) number of parameters of the speech processor, so-called “device fitting,” is a tedious and complex process, which is mainly carried out in the clinic through ‘one-size-fits-all’ procedures. Current fitting typically relies on limited and often subjective data that must be collected in limited time. Despite the success of the CI as a hearing-restoration device, variability in speech-recognition scores among users is still very large, and mostly unexplained. The major factors that underly this variability incorporate three levels: (i) variability in auditory-system malfunction of CI-users, (ii) variability in the selectivity of electrode-to-auditory nerve (EL-AN) activation, and (iii) lack of objective perceptual measures to optimize the fitting. We argue that variability in speech recognition can only be alleviated by using objective patient-specific data for an individualized fitting procedure, which incorporates knowledge from all three levels. In this paper, we propose a series of experiments, aimed at collecting a large amount of objective (i.e., quantitative, reproducible, and reliable) data that characterize the three processing levels of the user’s auditory system. Machine-learning algorithms that process these data will eventually enable the clinician to derive reliable and personalized characteristics of the user’s auditory system, the quality of EL-AN signal transfer, and predictions of the perceptual effects of changes in the current fitting. Copyright © 2023 Van Opstal and Noordanus.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85166007622
Pinzas L.; Glaun M.; Liu Y.-C.C.,"Pinzas, Lauren (57357508700); Glaun, Mica (57221405216); Liu, Yi-Chun Carol (55841031100)",57357508700; 57221405216; 55841031100,Congenital cholesteatoma in identical twins,2022,International Journal of Pediatric Otorhinolaryngology,162,,111330,,,,0,10.1016/j.ijporl.2022.111330,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139721952&doi=10.1016%2fj.ijporl.2022.111330&partnerID=40&md5=a44a8fcef8ad534fa323f3d795565464,"Congenital cholesteatoma in identical twins has only been described once in Otolaryngology literature thus far. This report describes a case of monozygotic twins with a history of recurrent acute otitis media and bilateral middle ear effusions without tympanic membrane perforation. Upon myringotomy with pressure equalization tube insertion, both were found to have right-sided cholesteatoma with nearly identical location and pattern of progression. In the context of previous case series demonstrating familial clustering and reports of possible genetic associations of this condition, the authors present an important addition to the current understanding of congenital cholesteatoma disorder. © 2022 Elsevier B.V.",36228387,Article,Final,,Scopus,2-s2.0-85139721952
Ponticorvo S.; Manara R.; Cassandro E.; Canna A.; Scarpa A.; Troisi D.; Cassandro C.; Cuoco S.; Cappiello A.; Pellecchia M.T.; Salle F.D.; Esposito F.,"Ponticorvo, Sara (57201745187); Manara, Renzo (6603641806); Cassandro, Ettore (6603123006); Canna, Antonietta (57193434142); Scarpa, Alfonso (56844779000); Troisi, Donato (57192163462); Cassandro, Claudia (22633886000); Cuoco, Sofia (56388633500); Cappiello, Arianna (57205670768); Pellecchia, Maria Teresa (7007039088); Salle, Francesco Di (23036454500); Esposito, Fabrizio (7102220908)",57201745187; 6603641806; 6603123006; 57193434142; 56844779000; 57192163462; 22633886000; 56388633500; 57205670768; 7007039088; 23036454500; 7102220908,Cross-modal connectivity effects in age-related hearing loss,2022,Neurobiology of Aging,111,,,1,13,12,3,10.1016/j.neurobiolaging.2021.09.024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121267725&doi=10.1016%2fj.neurobiolaging.2021.09.024&partnerID=40&md5=40959c78f552df28e13e634d3431e1b2,"Age-related sensorineural hearing loss (HL) leads to localized brain changes in the primary auditory cortex, long-range functional alterations, and is considered a risk factor for dementia. Nonhuman studies have repeatedly highlighted cross-modal brain plasticity in sensorial brain networks other than those primarily involved in the peripheral damage, thus in this study, the possible cortical alterations associated with HL have been analyzed using a whole-brain multimodal connectomic approach. Fifty-two HL and 30 normal hearing participants were examined in a 3T MRI study along with audiological and neurological assessments. Between-regions functional connectivity and whole-brain probabilistic tractography were calculated in a connectome-based manner and graph theory was used to obtain low-dimensional features for the analysis of brain connectivity at global and local levels. The HL condition was associated with a different functional organization of the visual subnetwork as revealed by a significant increase in global efficiency, density, and clustering coefficient. These functional effects were mirrored by similar (but more subtle) structural effects suggesting that a functional repurposing of visual cortical centers occurs to compensate for age-related loss of hearing abilities. © 2021 Elsevier Inc.",34915240,Article,Final,,Scopus,2-s2.0-85121267725
Sihvonen A.J.; Sammler D.; Ripollés P.; Leo V.; Rodríguez-Fornells A.; Soinila S.; Särkämö T.,"Sihvonen, Aleksi J. (56566645500); Sammler, Daniela (6508123104); Ripollés, Pablo (6504219503); Leo, Vera (56566441100); Rodríguez-Fornells, Antoni (35234806900); Soinila, Seppo (7006286238); Särkämö, Teppo (22136497700)",56566645500; 6508123104; 6504219503; 56566441100; 35234806900; 7006286238; 22136497700,Right ventral stream damage underlies both poststroke aprosodia and amusia,2022,European Journal of Neurology,29,3,,873,882,9,5,10.1111/ene.15148,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117880997&doi=10.1111%2fene.15148&partnerID=40&md5=2da6613ecd84a7cb4b73bebd0e288d72,"Background and purpose: This study was undertaken to determine and compare lesion patterns and structural dysconnectivity underlying poststroke aprosodia and amusia, using a data-driven multimodal neuroimaging approach. Methods: Thirty-nine patients with right or left hemisphere stroke were enrolled in a cohort study and tested for linguistic and affective prosody perception and musical pitch and rhythm perception at subacute and 3-month poststroke stages. Participants listened to words spoken with different prosodic stress that changed their meaning, and to words spoken with six different emotions, and chose which meaning or emotion was expressed. In the music tasks, participants judged pairs of short melodies as the same or different in terms of pitch or rhythm. Structural magnetic resonance imaging data were acquired at both stages, and machine learning-based lesion–symptom mapping and deterministic tractography were used to identify lesion patterns and damaged white matter pathways giving rise to aprosodia and amusia. Results: Both aprosodia and amusia were behaviorally strongly correlated and associated with similar lesion patterns in right frontoinsular and striatal areas. In multiple regression models, reduced fractional anisotropy and lower tract volume of the right inferior fronto-occipital fasciculus were the strongest predictors for both disorders, over time. Conclusions: These results highlight a common origin of aprosodia and amusia, both arising from damage and disconnection of the right ventral auditory stream integrating rhythmic–melodic acoustic information in prosody and music. Comorbidity of these disabilities may worsen the prognosis and affect rehabilitation success. © 2021 European Academy of Neurology",34661326,Article,Final,,Scopus,2-s2.0-85117880997
Wu Y.; Langworthy B.; Wang M.,"Wu, Yujie (57219527510); Langworthy, Benjamin (57201032609); Wang, Molin (12774321000)",57219527510; 57201032609; 12774321000,Marginal structural models for multilevel clustered data,2022,Biostatistics,23,4,,1056,1073,17,0,10.1093/biostatistics/kxac027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140144468&doi=10.1093%2fbiostatistics%2fkxac027&partnerID=40&md5=9c236c4bcdd67dc677bc402303f8e3ea,"Marginal structural models (MSMs), which adopt inverse probability treatment weighting in the estimating equations, are powerful tools to estimate the causal effects of time-varying exposures in the presence of time-dependent confounders. Motivated by the Conservation of Hearing Study (CHEARS) Audiology Assessment Arm (AAA) where repeated hearing measurements were clustered by study participants, time, and testing sites, we propose two methods to account for the multilevel correlation structure when fitting the MSMs. The first method directly models the covariance of the repeated outcomes when solving the weighted generalized estimating equations for MSMs, while the second two-stage analysis approach fits cluster-specific MSMs first and then combines the estimated parameters using mixed-effects meta-analysis. Finite sample simulation results suggest that our methods can obtain less biased and more efficient estimates of the parameters by accounting for the multilevel correlation. Moreover, we explore the effects of using fixed- or mixed-effects model to estimate the treatment probability on the parameter estimates of the MSMs in the presence of unmeasured cluster-level confounders. Lastly, we apply our methods to the CHEARS AAA data set, to estimate the causal effects of aspirin use on hearing loss.  © 2022 The Author. Published by Oxford University Press. All rights reserved.",35904119,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85140144468
Grégoire A.; Deggouj N.; Dricot L.; Decat M.; Kupers R.,"Grégoire, Anaïs (57193529142); Deggouj, Naïma (7003305164); Dricot, Laurence (18134948800); Decat, Monique (6701559662); Kupers, Ron (7003484370)",57193529142; 7003305164; 18134948800; 6701559662; 7003484370,Brain Morphological Modifications in Congenital and Acquired Auditory Deprivation: A Systematic Review and Coordinate-Based Meta-Analysis,2022,Frontiers in Neuroscience,16,,850245,,,,7,10.3389/fnins.2022.850245,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128436354&doi=10.3389%2ffnins.2022.850245&partnerID=40&md5=8167ca5b41acbf9a807f64fe6d2ef69f,"Neuroplasticity following deafness has been widely demonstrated in both humans and animals, but the anatomical substrate of these changes is not yet clear in human brain. However, it is of high importance since hearing loss is a growing problem due to aging population. Moreover, knowing these brain changes could help to understand some disappointing results with cochlear implant, and therefore could improve hearing rehabilitation. A systematic review and a coordinate-based meta-analysis were realized about the morphological brain changes highlighted by MRI in severe to profound hearing loss, congenital and acquired before or after language onset. 25 papers were included in our review, concerning more than 400 deaf subjects, most of them presenting prelingual deafness. The most consistent finding is a volumetric decrease in gray matter around bilateral auditory cortex. This change was confirmed by the coordinate-based meta-analysis which shows three converging clusters in this region. The visual areas of deaf children is also significantly impacted, with a decrease of the volume of both gray and white matters. Finally, deafness is responsible of a gray matter increase within the cerebellum, especially at the right side. These results are largely discussed and compared with those from deaf animal models and blind humans, which demonstrate for example a much more consistent gray matter decrease along their respective primary sensory pathway. In human deafness, a lot of other factors than deafness could interact on the brain plasticity. One of the most important is the use of sign language and its age of acquisition, which induce among others changes within the hand motor region and the visual cortex. But other confounding factors exist which have been too little considered in the current literature, such as the etiology of the hearing impairment, the speech-reading ability, the hearing aid use, the frequent associated vestibular dysfunction or neurocognitive impairment. Another important weakness highlighted by this review concern the lack of papers about postlingual deafness, whereas it represents most of the deaf population. Further studies are needed to better understand these issues, and finally try to improve deafness rehabilitation. Copyright © 2022 Grégoire, Deggouj, Dricot, Decat and Kupers.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128436354
Akeroyd M.A.; Bailey W.; Barker J.; Cox T.J.; Culling J.F.; Graetzer S.; Naylor G.; Podwińska Z.; Tu Z.,"Akeroyd, Michael A. (7003932221); Bailey, Will (58830878800); Barker, Jon (7401680706); Cox, Trevor J. (7203000240); Culling, John F. (7004194328); Graetzer, Simone (56166652200); Naylor, Graham (12761085700); Podwińska, Zuzanna (57209878100); Tu, Zehai (57204144418)",7003932221; 58830878800; 7401680706; 7203000240; 7004194328; 56166652200; 12761085700; 57209878100; 57204144418,The 2nd Clarity Enhancement Challenge for Hearing Aid Speech Intelligibility Enhancement: Overview and Outcomes,2023,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",2023-June,,,,,,5,10.1109/ICASSP49357.2023.10094918,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166052077&doi=10.1109%2fICASSP49357.2023.10094918&partnerID=40&md5=aa612b35c1aad111540dc3cbb911133f,"This paper reports on the design and outcomes of the 2nd Clarity Enhancement Challenge (CEC2), a challenge for stimulating novel approaches to hearing-aid speech intelligibility enhancement. The challenge was for a listener attending to a target speaker in a noisy, domestic environment. The challenge extends the previous edition, CEC1, in a number of key respects: scenes have multiple interferers including speech, noise and music; ambisonics are used to model listener head movement; target speaker identity is provided to encourage speaker extraction approaches. Systems are evaluated both via the HASPI intelligibility metric and with listening tests using a panel of hearing-impaired listeners. The paper reviews the 18 systems that were submitted describing them in terms of their enhancement and amplification stages. HASPI is seen to be a good predictor of listener performance. The top system, using carefully engineered neural approaches, produces highly intelligible signals for complex scenes with SNRs down to -12 dB while obeying the challenges 5 ms latency constraint. © 2023 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85166052077
Song Q.; Qi S.; Jin C.; Yang L.; Qian W.; Yin Y.; Zhao H.; Yu H.,"Song, Qiyuan (57580663300); Qi, Shouliang (36572483500); Jin, Chaoyang (57223124687); Yang, Lei (57580955900); Qian, Wei (36842193500); Yin, Yi (57218212538); Zhao, Houyu (24068244900); Yu, Hui (57195980184)",57580663300; 36572483500; 57223124687; 57580955900; 36842193500; 57218212538; 24068244900; 57195980184,Functional Brain Connections Identify Sensorineural Hearing Loss and Predict the Outcome of Cochlear Implantation,2022,Frontiers in Computational Neuroscience,16,,825160,,,,4,10.3389/fncom.2022.825160,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128469014&doi=10.3389%2ffncom.2022.825160&partnerID=40&md5=101195ad7672558afb4119b99355f37b,"Identification of congenital sensorineural hearing loss (SNHL) and early intervention, especially by cochlear implantation (CI), are crucial for restoring hearing in patients. However, high accuracy diagnostics of SNHL and prognostic prediction of CI are lacking to date. To diagnose SNHL and predict the outcome of CI, we propose a method combining functional connections (FCs) measured by functional magnetic resonance imaging (fMRI) and machine learning. A total of 68 children with SNHL and 34 healthy controls (HC) of matched age and gender were recruited to construct classification models for SNHL and HC. A total of 52 children with SNHL that underwent CI were selected to establish a predictive model of the outcome measured by the category of auditory performance (CAP), and their resting-state fMRI images were acquired. After the dimensional reduction of FCs by kernel principal component analysis, three machine learning methods including the support vector machine, logistic regression, and k-nearest neighbor and their voting were used as the classifiers. A multiple logistic regression method was performed to predict the CAP of CI. The classification model of voting achieves an area under the curve of 0.84, which is higher than that of three single classifiers. The multiple logistic regression model predicts CAP after CI in SNHL with an average accuracy of 82.7%. These models may improve the identification of SNHL through fMRI images and prognosis prediction of CI in SNHL. Copyright © 2022 Song, Qi, Jin, Yang, Qian, Yin, Zhao and Yu.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128469014
Raja Sankari V.M.; Snekhalatha U.; Rajalakshmi T.,"Raja Sankari, V.M. (57758805500); Snekhalatha, U. (57803525200); Rajalakshmi, T. (58632986600)",57758805500; 57803525200; 58632986600,Design And Implementation Of A Portable Automated Audiometer For Hearing Classification Using Machine Learning Approaches,2022,"Biomedical Engineering - Applications, Basis and Communications",34,5,2250035,,,,2,10.4015/S1016237222500351,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132537674&doi=10.4015%2fS1016237222500351&partnerID=40&md5=52d3d84e2e695566db84f07ef822276f,"Audiometric tests can identify the hearing loss at specific frequencies using the audiogram. The aim and objectives of the study were (i) to develop an automated audiometer for self-diagnosing the hearing ability of the patient; (ii) to extract the features from the acoustic signals and to classify the normal and profound hearing loss patients using different machine learning algorithms; (iii) to validate the hearing loss classification using six-frequency average (6-FA) method based on simple linear regression analysis and machine learning algorithms. The study is conducted among 150 patients, including 75 patients with normal hearing ability and 75 patients with profound hearing loss. The total population of 150 underwent audiometric test both in the soundproof audiometric room and in the normal field environment. Based on the patient response, the intensity and frequency are changed automatically, and the audiogram is plotted by the principle of Artificial Neural Network learning procedures. The overall accuracy produced by classification of normal and profound hearing loss patients using Support Vector Machine (SVM), k-Nearest Neighbor classifier, and Naïve Bayes classifier is 97%, 96%, and 95%, respectively. The results indicated that the SVM classifier outperforms the other two classifiers well. The preliminary audiometric test can be performed remotely and then consulted with an audiologist. Thus, the patient could operate the developed prototype independently and get a consultation from trained medical personnel.  © 2022 National Taiwan University.",,Article,Final,,Scopus,2-s2.0-85132537674
Roßbach J.; Kollmeier B.; Meyer B.T.,"Roßbach, Jana (57263541300); Kollmeier, Birger (7006746726); Meyer, Bernd T. (57214341543)",57263541300; 7006746726; 57214341543,A model of speech recognition for hearing-impaired listeners based on deep learning,2022,Journal of the Acoustical Society of America,151,3,,1417,1427,10,4,10.1121/10.0009411,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126462649&doi=10.1121%2f10.0009411&partnerID=40&md5=23aee09193f7a5fb7e7f6bdb7870b0ec,"Automatic speech recognition (ASR) has made major progress based on deep machine learning, which motivated the use of deep neural networks (DNNs) as perception models and specifically to predict human speech recognition (HSR). This study investigates if a modeling approach based on a DNN that serves as phoneme classifier [Spille, Ewert, Kollmeier, and Meyer (2018). Comput. Speech Lang. 48, 51-66] can predict HSR for subjects with different degrees of hearing loss when listening to speech embedded in different complex noises. The eight noise signals range from simple stationary noise to a single competing talker and are added to matrix sentences, which are presented to 20 hearing-impaired (HI) listeners (categorized into three groups with different types of age-related hearing loss) to measure their speech recognition threshold (SRT), i.e., the signal-to-noise ratio with 50% word recognition rate. These are compared to responses obtained from the ASR-based model using degraded feature representations that take into account the individual hearing loss of the participants captured by a pure-tone audiogram. Additionally, SRTs obtained from eight normal-hearing (NH) listeners are analyzed. For NH subjects and three groups of HI listeners, the average SRT prediction error is below 2 dB, which is lower than the errors of the baseline models.  © 2022 Author(s).",35364918,Article,Final,,Scopus,2-s2.0-85126462649
Hu S.; Hu W.; Yang S.; Zhu X.; Sun K.; Jiang S.; Qiu Y.; Li X.,"Hu, Shuangqiu (57216520567); Hu, Weijiang (57210845671); Yang, Shu (57821960300); Zhu, Xinhe (57216520180); Sun, Kang (57190382843); Jiang, Shaobo (58797365700); Qiu, Yanxia (57237767400); Li, Xiaodong (57775674000)",57216520567; 57210845671; 57821960300; 57216520180; 57190382843; 58797365700; 57237767400; 57775674000,Investigation on noise exposure level and health status of workers in transportation equipment manufacturing industry; [交通运输设备制造行业工人噪声接触水平及健康状况调查],2021,Chinese Journal of Industrial Hygiene and Occupational Diseases,39,7,,498,502,4,5,10.3760/cma.j.cn121094-20200513-00258,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113729857&doi=10.3760%2fcma.j.cn121094-20200513-00258&partnerID=40&md5=eaba45f7229689952a447e1032df4216,"Objective To explore the noise exposure level and the health status of workers in transportation equipment manufacturing industry, and provide a scientific basis for guidance and implementation of intervention measures. Methods From January to December in 2019, a total of 2088 noise workers from a large enterprise were selected by cluster sampling method in railway transportation equipment manufacturing, automobile manufacturing and aerospace aircraft manufacturing enterprises. The worker's noise exposure level was detected. Occupatio nal health checkups were performed on the noise workers including electrical audiometry, blood pressure and electrocardiogram. χ2 test and trend χ2 test were used to analyze the data. Results The noise exposure level of 66.9%(1396/2088) workers exceeded 85 dB(A), and the median noise level was 87.9(84.3-90.3) dB(A). Among them, workers of railway transportation equipment manufacturing enterprises had the highest noise exposure level[89.9(87.8-91.6) dB(A)]. The detection rate of high鄄frequency hearing loss, abnormal blood pressure and abnormal electrocardiogram of noise workers were 15.7% (327/ 2088),18.1% (378/2088) and 6.1% (128/2088), respectively. The differences in the detection rates of high鄄frequency hearing loss, abnormal blood pressure, and abnormal electrocardiogram in workers of railway transportation equipment manufacturing enterprises, automobile manufacturing enterprises, and aerospace manufacturing enterprises were statistically significant (P<0.05). Workers of railway transportation equipment manufacturing enterprises had higher detection rates of high鄄frequency hearing loss(17.6%, 186/1056). Workers of aerospace manufacturing enterprises had higher detection rates of abnormal blood pressure and abnormal electrocardiogram (26.3%, 169/642;10.0%, 64/642). The differences in the detection rates of high鄄frequency hearing loss, abnormal blood pressure and abnormal electrocardiogram of noise workers were statistically significant in different age and working age groups, and gradually increased with age and working age (P< 0.05). The difference in the detection rate of high鄄frequency hearing loss of noise workers was statistically significant in different noise intensity groups, and the overall trend was increasing(P<0.05). Conclusion The transportation equipment manufacturing industry has serious noise hazards, especially the railway transportation equipment manufacturing industry. Long鄄term occupational noise exposure can adversely affect workers' hearing and cardiovascular system. Enterprises should strengthen occupational health inspections, and at the same time, take personal protective measures to protect the health of workers. © 2019 Zhonghua er ke za zhi / Chinese Journal of Pediatrics.",34365758,Article,Final,,Scopus,2-s2.0-85113729857
Zainul Abidin F.N.; Scelsi M.A.; Dawson S.J.; Altmann A.,"Zainul Abidin, Fatin N. (57194187102); Scelsi, Marzia A. (57202741862); Dawson, Sally J. (7202902185); Altmann, Andre (24448145000)",57194187102; 57202741862; 7202902185; 24448145000,Glucose hypometabolism in the Auditory Pathway in Age Related Hearing Loss in the ADNI cohort,2021,NeuroImage: Clinical,32,,102823,,,,3,10.1016/j.nicl.2021.102823,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118721190&doi=10.1016%2fj.nicl.2021.102823&partnerID=40&md5=e5adc54229b8140b394842c3abde8d2d,"Purpose: Hearing loss (HL) is one of the most common age-related diseases. Here, we investigate the central auditory correlates of HL in people with normal cognition and mild cognitive impairment (MCI) and test their association with genetic markers with the aim of revealing pathogenic mechanisms. Methods: Brain glucose metabolism based on FDG-PET, self-reported HL status, and genetic data were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort. FDG-PET data was analysed from 742 control subjects (non-HL with normal cognition or MCI) and 162 cases (HL with normal cognition or MCI) with age ranges of 72.2 ± 7.1 and 77.4 ± 6.4, respectively. Voxel-wise statistics of FDG uptake differences between cases and controls were computed using the generalised linear model in SPM12. An additional 1515 FDG-PET scans of 618 participants were analysed using linear mixed effect models to assess longitudinal HL effects. Furthermore, a quantitative trait genome-wide association study (GWAS) was conducted on the glucose uptake within regions of interest (ROIs), which were defined by the voxel-wise comparison, using genotyping data with 5,082,878 variants available for HL cases and HL controls (N = 817). Results: The HL group exhibited hypometabolism in the bilateral Heschl's gyrus (kleft = 323; kright = 151; Tleft = 4.55; Tright = 4.14; peak Puncorr < 0.001), the inferior colliculus (k = 219;T = 3.53; peak Puncorr < 0.001) and cochlear nucleus (k = 18;T = 3.55; peak Puncorr < 0.001) after age correction and using a cluster forming height threshold P < 0.005 (FWE-uncorrected). Moreover, in an age-matched subset, the cluster comprising the left Heschl's gyrus survived the FWE-correction (kleft = 1903; Tleft = 4.39; cluster PFWE-corr = 0.001). The quantitative trait GWAS identified no genome-wide significant locus in the three HL ROIs. However, various loci were associated at the suggestive threshold (p < 1e-05). Conclusion: Compared to the non-HL group, glucose metabolism in the HL group was lower in the auditory cortex, the inferior colliculus, and the cochlear nucleus although the effect sizes were small. The GWAS identified candidate genes that might influence FDG uptake in these regions. However, the specific biological pathway(s) underlying the role of these genes in FDG-hypometabolism in the auditory pathway requires further investigation. © 2021 The Author(s)",34624637,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85118721190
Hu C.-J.; Lu Y.-C.; Yang T.-H.; Chan Y.-H.; Tsai C.-Y.; Yu I.-S.; Lin S.-W.; Liu T.-C.; Cheng Y.-F.; Wu C.-C.; Hsu C.-J.,"Hu, Chin-Ju (57204090868); Lu, Ying-Chang (35174929400); Yang, Ting-Hua (24473916900); Chan, Yen-Hui (57204089885); Tsai, Cheng-Yu (57205177467); Yu, I-Shing (7102120396); Lin, Shu-Wha (16201167800); Liu, Tien-Chen (7405914488); Cheng, Yen-Fu (57202607130); Wu, Chen-Chi (8451843700); Hsu, Chuan-Jen (7404946816)",57204090868; 35174929400; 24473916900; 57204089885; 57205177467; 7102120396; 16201167800; 7405914488; 57202607130; 8451843700; 7404946816,Toward the pathogenicity of the slc26a4 p.C565y variant using a genetically driven mouse model,2021,International Journal of Molecular Sciences,22,6,2789,1,14,13,5,10.3390/ijms22062789,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102113936&doi=10.3390%2fijms22062789&partnerID=40&md5=9517d0e302bce9053ce4c83ae3d29960,"Recessive variants of the SLC26A4 gene are globally a common cause of hearing impair-ment. In the past, cell lines and transgenic mice were widely used to investigate the pathogenicity associated with SLC26A4 variants. However, discrepancies in pathogenicity between humans and cell lines or transgenic mice were documented for some SLC26A4 variants. For instance, the p.C565Y variant, which was reported to be pathogenic in humans, did not exhibit functional pathogenic con-sequences in cell lines. To address the pathogenicity of p.C565Y, we used a genotype-based approach in which we generated knock-in mice that were heterozygous (Slc26a4+/C565Y), homozygous (Slc26a4C565Y/C565Y), and compound heterozygous (Slc26a4919-2A>G/C565Y) for this variant. Subsequent phenotypic characterization revealed that mice with these genotypes demonstrated normal auditory and vestibular functions, and normal inner-ear morphology and pendrin expression. These findings indicate that the p.C565Y variant is nonpathogenic for mice, and that a single p.C565Y allele is sufficient to maintain normal inner-ear physiology in mice. Our results highlight the differences in pathogenicity associated with certain SLC26A4 variants between transgenic mice and hu-mans, which should be considered when interpreting the results of animal studies for SLC26A4-related deafness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",33801843,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102113936
Wimalarathna H.; Ankmnal-Veeranna S.; Allan C.; Agrawal S.K.; Allen P.; Samarabandu J.; Ladak H.M.,"Wimalarathna, Hasitha (57221683588); Ankmnal-Veeranna, Sangamanatha (57209368725); Allan, Chris (35979021200); Agrawal, Sumit K. (7403054662); Allen, Prudence (7403502061); Samarabandu, Jagath (6603705056); Ladak, Hanif M. (57207541892)",57221683588; 57209368725; 35979021200; 7403054662; 7403502061; 6603705056; 57207541892,Comparison of machine learning models to classify Auditory Brainstem Responses recorded from children with Auditory Processing Disorder,2021,Computer Methods and Programs in Biomedicine,200,,105942,,,,12,10.1016/j.cmpb.2021.105942,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099787713&doi=10.1016%2fj.cmpb.2021.105942&partnerID=40&md5=c92c7fd67d496aafa68f2f765c677073,"Introduction: Auditory brainstem responses (ABRs) offer a unique opportunity to assess the neural integrity of the peripheral auditory nervous system in individuals presenting with listening difficulties. ABRs are typically recorded and analyzed by an audiologist who manually measures the timing and quality of the waveforms. The interpretation of ABRs requires considerable experience and training, and inappropriate interpretation can lead to incorrect judgments about the integrity of the system. Machine learning (ML) techniques may be a suitable approach to automate ABR interpretation and reduce human error. Objectives: The main objective of this paper was to identify a suitable ML technique to automate the analysis of ABR responses recorded as a part of the electrophysiological testing in the Auditory Processing Disorder clinical test battery. Methods: ABR responses recorded during routine clinical assessment from 136 children being evaluated for auditory processing difficulties were analyzed using several common ML algorithms: Support Vector Machines (SVM), Random Forests (RF), Decision Trees (DT), Gradient Boosting (GB), Extreme Gradient Boosting (Xgboost), and Neural Networks (NN). A variety of signal feature extraction techniques were used to extract features from the ABR waveforms as inputs to the ML algorithms. Statistical significance testing and confusion matrices were used to identify the most robust model capable of accurately identifying neurological abnormalities present in ABRs. Results: Clinically significant features in the time-frequency representation of the signal were identified. The ML model trained using the Xgboost algorithm was identified as the most robust model with an accuracy of 92% compared to other models. Conclusion: The findings of the present study demonstrate that it is possible to develop accurate ML models to automate the process of analyzing ABR waveforms recorded at suprathreshold levels. There is currently no ML-based application to screen children with listening difficulties. Therefore, it is expected that this work will be translated into an evaluation tool that can be used by audiologists in the clinic. Furthermore, this work may aid future researchers in exploring ML paradigms to improve clinical test batteries used by audiologists in achieving accurate diagnoses. © 2021 Elsevier B.V.",33515845,Article,Final,,Scopus,2-s2.0-85099787713
Kim H.; Park J.; Choung Y.-H.; Jang J.H.; Ko J.,"Kim, Hantai (57221994950); Park, JaeYeon (57191892662); Choung, Yun-Hoon (7004685469); Jang, Jeong Hun (26639429600); Ko, JeongGil (24822444000)",57221994950; 57191892662; 7004685469; 26639429600; 24822444000,"Predicting speech discrimination scores from pure-tone thresholds—A machine learning-based approach using data from 12,697 subjects",2021,PLoS ONE,16,12-Dec,e0261433,,,,4,10.1371/journal.pone.0261433,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122019990&doi=10.1371%2fjournal.pone.0261433&partnerID=40&md5=8fbe4d67167f6ab29318d9e461665dd4,"Diagnostic tests for hearing impairment not only determines the presence (or absence) of hearing loss, but also evaluates its degree and type, and provides physicians with essential data for future treatment and rehabilitation. Therefore, accurately measuring hearing loss conditions is very important for proper patient understanding and treatment. In current-day practice, to quantify the level of hearing loss, physicians exploit specialized test scores such as the pure-tone audiometry (PTA) thresholds and speech discrimination scores (SDS) as quantitative metrics in examining a patient’s auditory function. However, given that these metrics can be easily affected by various human factors, which includes intentional (or accidental) patient intervention, there are needs to cross validate the accuracy of each metric. By understanding a “normal” relationship between the SDS and PTA, physicians can reveal the need for re-testing, additional testing in different dimensions, and also potential malingering cases. For this purpose, in this work, we propose a prediction model for estimating the SDS of a patient by using PTA thresholds via a Random Forest-based machine learning approach to overcome the limitations of the conventional statistical (or even manual) methods. For designing and evaluating the Random Forest-based prediction model, we collected a large-scale dataset from 12,697 subjects, and report a SDS level prediction accuracy of 95.05% and 96.64% for the left and right ears, respectively. We also present comparisons with other widely-used machine learning algorithms (e.g., Support Vector Machine, Multilayer Perceptron) to show the effectiveness of our proposed Random Forest-based approach. Results obtained from this study provides implications and potential feasibility in providing a practically-applicable screening tool for identifying patient-intended malingering in hearing loss-related tests. © 2021 Kim et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",34972151,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85122019990
Shafieibavani E.; Goudey B.; Kiral I.; Zhong P.; Jimeno-Yepes A.; Swan A.; Gambhir M.; Buechner A.; Kludt E.; Eikelboom R.H.; Sucher C.; Gifford R.H.; Rottier R.; Plant K.; Anjomshoa H.,"Shafieibavani, Elaheh (57041343400); Goudey, Benjamin (54393054300); Kiral, Isabell (57214683799); Zhong, Peter (57222049082); Jimeno-Yepes, Antonio (24398815300); Swan, Annalisa (57262204500); Gambhir, Manoj (57262060500); Buechner, Andreas (35361395500); Kludt, Eugen (36554442900); Eikelboom, Robert H. (7006848551); Sucher, Cathy (6505828279); Gifford, Rene H. (7102275184); Rottier, Riaan (57262485500); Plant, Kerrie (6603695085); Anjomshoa, Hamideh (36135245000)",57041343400; 54393054300; 57214683799; 57222049082; 24398815300; 57262204500; 57262060500; 35361395500; 36554442900; 7006848551; 6505828279; 7102275184; 57262485500; 6603695085; 36135245000,"Predictive models for cochlear implant outcomes: Performance, generalizability, and the impact of cohort size",2021,Trends in Hearing,25,,,,,,13,10.1177/23312165211066174,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121377960&doi=10.1177%2f23312165211066174&partnerID=40&md5=e4d7dd33c29775b363e6194bd569e3dc,"While cochlear implants have helped hundreds of thousands of individuals, it remains difficult to predict the extent to which an individual’s hearing will benefit from implantation. Several publications indicate that machine learning may improve predictive accuracy of cochlear implant outcomes compared to classical statistical methods. However, existing studies are limited in terms of model validation and evaluating factors like sample size on predictive performance. We conduct a thorough examination of machine learning approaches to predict word recognition scores (WRS) measured approximately 12 months after implantation in adults with post-lingual hearing loss. This is the largest retrospective study of cochlear implant outcomes to date, evaluating 2,489 cochlear implant recipients from three clinics. We demonstrate that while machine learning models significantly outperform linear models in prediction of WRS, their overall accuracy remains limited (mean absolute error: 17.9-21.8). The models are robust across clinical cohorts, with predictive error increasing by at most 16% when evaluated on a clinic excluded from the training set. We show that predictive improvement is unlikely to be improved by increasing sample size alone, with doubling of sample size estimated to only increasing performance by 3% on the combined dataset. Finally, we demonstrate how the current models could support clinical decision making, highlighting that subsets of individuals can be identified that have a 94% chance of improving WRS by at least 10% points after implantation, which is likely to be clinically meaningful. We discuss several implications of this analysis, focusing on the need to improve and standardize data collection. © The Author(s) 2021.",34903103,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85121377960
Krohs C.; Körber C.; Ebbers L.; Altaf F.; Hollje G.; Hoppe S.; Dörflinger Y.; Prosser H.M.; Nothwang H.G.,"Krohs, Constanze (57201120065); Körber, Christoph (36869954900); Ebbers, Lena (56060168600); Altaf, Faiza (57226744440); Hollje, Giulia (57226748794); Hoppe, Simone (55548183400); Dörflinger, Yvette (55165382400); Prosser, Haydn M. (7004899713); Nothwang, Hans Gerd (7003310160)",57201120065; 36869954900; 56060168600; 57226744440; 57226748794; 55548183400; 55165382400; 7004899713; 7003310160,Loss of miR-183/96 alters synaptic strength via presynaptic and postsynaptic mechanisms at a central synapse,2021,Journal of Neuroscience,41,32,,6796,6811,15,9,10.1523/JNEUROSCI.0139-20.2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112508657&doi=10.1523%2fJNEUROSCI.0139-20.2021&partnerID=40&md5=aaa3dd754c20a408737a055cce84b06d,"A point mutation in miR-96 causes non-syndromic progressive peripheral hearing loss and alters structure and physiology of the central auditory system. To gain further insight into the functions of microRNAs (miRNAs) within the central auditory system, we investigated constitutive Mir-183/96dko mice of both sexes. In this mouse model, the genomically clustered miR-183 and miR-96 are constitutively deleted. It shows significantly and specifically reduced volumes of auditory hindbrain nuclei, because of decreases in cell number and soma size. Electrophysiological analysis of the calyx of Held synapse in the medial nucleus of the trapezoid body (MNTB) demonstrated strongly altered synaptic transmission in young-adult mice. We observed an increase in quantal content and readily releasable vesicle pool size in the presynapse while the overall morphology of the calyx was unchanged. Detailed analysis of the active zones (AZs) revealed differences in its molecular composition and synaptic vesicle (SV) distribution. Postsynaptically, altered clustering and increased synaptic abundancy of the AMPA receptor subunit GluA1 was observed resulting in an increase in quantal amplitude. Together, these presynaptic and postsynaptic alterations led to a 2-fold increase of the evoked excitatory postsynaptic currents in MNTB neurons. None of these changes were observed in deaf Cldn14ko mice, confirming an on-site role of miR-183 and miR-96 in the auditory hindbrain. Our data suggest that the Mir-183/96 cluster plays a key role for proper synaptic transmission at the calyx of Held and for the development of the auditory hindbrain. Copyright © 2021 the authors",34193555,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85112508657
Graetzer S.; Barker J.; Cox T.J.; Akeroyd M.; Culling J.F.; Naylor G.; Porter E.; Muñoz R.V.,"Graetzer, Simone (56166652200); Barker, Jon (7401680706); Cox, Trevor J. (7203000240); Akeroyd, Michael (7003932221); Culling, John F. (7004194328); Naylor, Graham (12761085700); Porter, Eszter (57219741883); Muñoz, Rhoddy Viveros (57211064463)",56166652200; 7401680706; 7203000240; 7003932221; 7004194328; 12761085700; 57219741883; 57211064463,Clarity-2021 challenges: Machine learning challenges for advancing hearing aid processing,2021,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2,,,1181,1185,4,29,10.21437/Interspeech.2021-1574,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119182231&doi=10.21437%2fInterspeech.2021-1574&partnerID=40&md5=df20bf858c0c0797e89ca476b7a01a97,"In recent years, rapid advances in speech technology have been made possible by machine learning challenges such as CHiME, REVERB, Blizzard, and Hurricane. In the Clarity project, the machine learning approach is applied to the problem of hearing aid processing of speech-in-noise, where current technology in enhancing the speech signal for the hearing aid wearer is often ineffective. The scenario is a (simulated) cuboid-shaped living room in which there is a single listener, a single target speaker and a single interferer, which is either a competing talker or domestic noise. All sources are static, the target is always within ±30° azimuth of the listener and at the same elevation, and the interferer is an omnidirectional point source at the same elevation. The target speech comes from an open source 40-speaker British English speech database collected for this purpose. This paper provides a baseline description of the round one Clarity challenges for both enhancement (CEC1) and prediction (CPC1). To the authors' knowledge, these are the first machine learning challenges to consider the problem of hearing aid speech signal processing.  Copyright © 2021 ISCA.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119182231
Elkhouly A.; Andrew A.M.; Rahim H.A.; Abdulaziz N.; Abdulmalek M.; Yasin M.N.M.; Jusoh M.; Sabapathy T.; Siddique S.,"Elkhouly, Abeer (57206896443); Andrew, Allan Melvin (36469871200); Rahim, Hasliza A. (57202496362); Abdulaziz, Nidhal (6602928578); Abdulmalek, Mohamedfareq (23098429000); Yasin, Mohd Najib Mohd (57210314287); Jusoh, Muzammil (24483755700); Sabapathy, Thennarasan (35424377200); Siddique, Shafiquzzaman (22635895700)",57206896443; 36469871200; 57202496362; 6602928578; 23098429000; 57210314287; 24483755700; 35424377200; 22635895700,A novel unsupervised spectral clustering for pure-tone audiograms towards hearing aid filter bank design and initial configurations,2022,Applied Sciences (Switzerland),12,1,298,,,,3,10.3390/app12010298,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122034103&doi=10.3390%2fapp12010298&partnerID=40&md5=bddbd1789b7eb4af3a9d88b6cc5acae0,"The current practice of adjusting hearing aids (HA) is tiring and time-consuming for both patients and audiologists. Of hearing-impaired people, 40–50% are not satisfied with their HAs. In addition, good designs of HAs are often avoided since the process of fitting them is exhausting. To improve the fitting process, a machine learning (ML) unsupervised approach is proposed to cluster the pure-tone audiograms (PTA). This work applies the spectral clustering (SP) approach to group audiograms according to their similarity in shape. Different SP approaches are tested for best results and these approaches were evaluated by Silhouette, Calinski-Harabasz, and Davies-Bouldin criteria values. Kutools for Excel add-in is used to generate audiograms’ population, annotated using the results from SP, and different criteria values are used to evaluate population clusters. Finally, these clusters are mapped to a standard set of audiograms used in HA characterization. The results indicated that grouping the data in 8 groups or 10 results in ones with high evaluation criteria. The evaluation for population audiograms clusters shows good performance, as it resulted in a Silhouette coefficient >0.5. This work introduces a new concept to classify audiograms using an ML algorithm according to the audiograms’ similarity in shape. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85122034103
Yousheng C.; Jian W.,"Yousheng, Chen (57222131685); Jian, Wang (57222130412)",57222131685; 57222130412,Simulation System of Cochlear Implant,2021,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",342,,,278,284,6,0,10.1007/978-3-030-66785-6_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101524891&doi=10.1007%2f978-3-030-66785-6_32&partnerID=40&md5=22a55072881c1188d7e77eac02fead04,"Different types of hearing loss can be treated according to the etiology and degree. Commonly used methods include drug therapy, surgical treatment, wearing hearing aids and implanting electrical stimulation equipment. Among them, cochlear implant is an effective way to restore the hearing perception ability of patients with very severe deafness and total deafness, and it is the most commonly used electrical stimulation implant device. Cochlear implant is still not widely used in China because of its high price and long training period. In order to facilitate speech training and improve speech perception ability of cochlear implant, this paper designs a speech training and speech simulation system of cochlear implant. The designed software and hardware system is a simulation test platform, with low price, simple test mode, and potential huge market value and application value. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",,Conference paper,Final,,Scopus,2-s2.0-85101524891
Smith P.F.; Zheng Y.,"Smith, Paul F. (7408329494); Zheng, Yiwen (7404837924)",7408329494; 7404837924,"Applications of Multivariate Statistical and Data Mining Analyses to the Search for Biomarkers of Sensorineural Hearing Loss, Tinnitus, and Vestibular Dysfunction",2021,Frontiers in Neurology,12,,627294,,,,5,10.3389/fneur.2021.627294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102872674&doi=10.3389%2ffneur.2021.627294&partnerID=40&md5=b36bdd694065adee5b874ac9cb003796,"Disorders of sensory systems, as with most disorders of the nervous system, usually involve the interaction of multiple variables to cause some change, and yet often basic sensory neuroscience data are analyzed using univariate statistical analyses only. The exclusive use of univariate statistical procedures, analyzing one variable at a time, may limit the potential of studies to determine how interactions between variables may, as a network, determine a particular result. The use of multivariate statistical and data mining methods provides the opportunity to analyse many variables together, in order to appreciate how they may function as a system of interacting variables, and how this system or network may change as a result of sensory disorders such as sensorineural hearing loss, tinnitus or different types of vestibular dysfunction. Here we provide an overview of the potential applications of multivariate statistical and data mining techniques, such as principal component and factor analysis, cluster analysis, multiple linear regression, random forest regression, linear discriminant analysis, support vector machines, random forest classification, Bayesian classification, and orthogonal partial least squares discriminant analysis, to the study of auditory and vestibular dysfunction, with an emphasis on classification analytic methods that may be used in the search for biomarkers of disease. © Copyright © 2021 Smith and Zheng.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102872674
Ellis G.M.; Souza P.E.,"Ellis, Gregory M. (57191381427); Souza, Pamela E. (35577095800)",57191381427; 35577095800,Using Machine Learning and the National Health and Nutrition Examination Survey to Classify Individuals With Hearing Loss,2021,Frontiers in Digital Health,3,,723533,,,,3,10.3389/fdgth.2021.723533,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131256575&doi=10.3389%2ffdgth.2021.723533&partnerID=40&md5=444aa2c9edd004b25231ade25a8924a5,"Even before the COVID-19 pandemic, there was mounting interest in remote testing solutions for audiology. The ultimate goal of such work was to improve access to hearing healthcare for individuals that might be unable or reluctant to seek audiological help in a clinic. In 2015, Diane Van Tasell patented a method for measuring an audiogram when the precise signal level was unknown (patent US 8,968,209 B2). In this method, the slope between pure-tone thresholds measured at 2 and 4 kHz is calculated and combined with questionnaire information in order to reconstruct the most likely audiograms from a database of options. An approach like the Van Tasell method is desirable because it is quick and feasible to do in a patient's home where exact stimulus levels are unknown. The goal of the present study was to use machine learning to assess the effectiveness of such audiogram-estimation methods. The National Health and Nutrition Examination Survey (NHANES), a database of audiologic and demographic information, was used to train and test several machine learning algorithms. Overall, 9,256 cases were analyzed. Audiometric data were classified using the Wisconsin Age-Related Hearing Impairment Classification Scale (WARHICS), a method that places hearing loss into one of eight categories. Of the algorithms tested, a random forest machine learning algorithm provided the best fit with only a few variables: the slope between 2 and 4 kHz; gender; age; military experience; and self-reported hearing ability. Using this method, 54.79% of the individuals were correctly classified, 34.40% were predicted to have a milder loss than measured, and 10.82% were predicted to have a more severe loss than measured. Although accuracy was low, it is unlikely audibility would be severely affected if classifications were used to apply gains. Based on audibility calculations, underamplification still provided sufficient gain to achieve ~95% correct (Speech Intelligibility Index ≥ 0.45) for sentence materials for 88% of individuals. Fewer than 1% of individuals were overamplified by 10 dB for any audiometric frequency. Given these results, this method presents a promising direction toward remote assessment; however, further refinement is needed before use in clinical fittings. © Copyright © 2021 Ellis and Souza.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131256575
Pitathawatchai P.; Chaichulee S.; Kirtsreesakul V.,"Pitathawatchai, Pittayapon (56184866200); Chaichulee, Sitthichok (57195217853); Kirtsreesakul, Virat (6507434853)",56184866200; 57195217853; 6507434853,Robust machine learning method for imputing missing values in audiograms collected in children,2022,International Journal of Audiology,61,1,,66,77,11,3,10.1080/14992027.2021.1884909,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101839235&doi=10.1080%2f14992027.2021.1884909&partnerID=40&md5=2ec5d72a19d4958b0924fad282ec388c,"Objective: To assess the accuracy and reliability of a machine learning (ML) algorithm for predicting the full audiograms of hearing-impaired children relative to the common approach (CA). Design: Retrospective study Study sample: There were 206 audiograms included from 206 children with sensorineural hearing loss. Nested cross-validation was used for evaluating the performance of the CA and ML. Six audiogram prediction simulations were performed in which either one or two thresholds across 0.5–4 kHz from complete audiograms in the dataset were labelled. Missing thresholds at the remaining frequencies were then predicted using the CA and ML in each simulation. The accuracy of the ML algorithm was determined by comparing the median average absolute threshold differences between the CA and ML using Wilcoxon signed-rank test. The reliability between runs of the ML was also assessed with Cronbach’s alphas. Results: The median average absolute threshold differences in ML (5–8 dBHL) were statistically significantly lower than those in CA (6.25–10 dBHL) in all six simulations (p value < 0.05). The ML algorithm was also found to be reliable to predict the audiograms in all six simulations (α > 0.9). Conclusion: Using the ML to predict the children’s audiograms was reliable and more accurate than using the CA. © 2021 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",33641573,Article,Final,,Scopus,2-s2.0-85101839235
Islam M.N.; Sulaiman N.; Rashid M.; Mustafa M.; Hasan M.J.,"Islam, Md Nahidul (57221115971); Sulaiman, Norizam (24734168300); Rashid, Mamunur (57217706501); Mustafa, Mahfuzah (36069366700); Hasan, Md Jahid (57216313085)",57221115971; 24734168300; 57217706501; 36069366700; 57216313085,Auditory Evoked Potentials (AEPs) Response Classification: A Fast Fourier Transform (FFT) and Support Vector Machine (SVM) Approach,2022,Lecture Notes in Electrical Engineering,770,,,539,549,10,0,10.1007/978-981-16-2406-3_41,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116505518&doi=10.1007%2f978-981-16-2406-3_41&partnerID=40&md5=2b2f72fc280c1db4682d1bfa8123cedd,"Hearing loss has become the world's most widespread sensory impairment. The applicability of a traditional hearing test is limited as it allows the subject to provide a direct response. The main aim of this study is to build an intelligent hearing level evaluation method using possible auditory evoked signals (AEPs). AEP responses are subjected to fixed acoustic stimulation strength for usual auditory and abnormal ear subjects to detect the hearing disorder. In this paper, the AEP responses have been captured from the sixteen subjects when the subject hears the auditory stimulus in the left or right ear. Then, the features have extracted with the help of Fast Fourier Transform (FFT), Power Spectral Density (PSD), Spectral Centroids, Standard Deviation algorithms. To classify the extracted features, the Support Vector Machine (SVM) approach using Radial Basis Kernel Function (RBF) has been used. Finally, the performance of the classifier in terms of accuracy, confusion matrix, true positive and false negative rate, precision, recall, and Cohen-Kappa-Score have been evaluated. The maximum classification accuracy of the developed SVM model with FFT feature was observed 95.29% (10 s time windows) which clearly indicates that the method provides a very encouraging performance for detecting the AEPs responses. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",,Conference paper,Final,,Scopus,2-s2.0-85116505518
Deutsch B.C.; Piccirillo J.F.,"Deutsch, Brian C. (57204153498); Piccirillo, Jay F. (7005075436)",57204153498; 7005075436,Momentary Analysis of Tinnitus: Considering the Patient,2021,Current Topics in Behavioral Neurosciences,51,,,383,401,18,2,10.1007/7854_2020_176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114369803&doi=10.1007%2f7854_2020_176&partnerID=40&md5=608d82831572ba16ed0c32682b01d499,"Ecological momentary assessment is a valuable research technique meant to capture real-time data and contextualize disease. While more common in neuropsychiatric research, this methodology is exceptionally fit for tinnitus. Tinnitus has been shown to be affected by many patient-level and environment-specific factors. From an individual’s baseline anxiety to the level of ambient noise in their environment, the level of bother experienced by those with tinnitus can vary widely. Only assessing tinnitus within a clinical environment can distort the true impact of the disease. Ecological data can minimize bias while generating an individualistic picture of the burden being experienced by the patient. Individual data can also compliment new research methods rooted in precision medicine, providing clearer, better-suited treatments for each patient on the tinnitus spectrum. © 2020, Springer Nature Switzerland AG.",32808091,Book chapter,Final,,Scopus,2-s2.0-85114369803
Bhutta M.F.; Swanepoel D.W.; Fagan J.,"Bhutta, Mahmood F. (35236121400); Swanepoel, De Wet (13609471200); Fagan, Johan (7102065187)",35236121400; 13609471200; 7102065187,"ENT from afar: Opportunities for remote patient assessment, clinical management, teaching and learning",2021,Clinical Otolaryngology,46,4,,689,691,2,6,10.1111/coa.13784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105045625&doi=10.1111%2fcoa.13784&partnerID=40&md5=192a904dff32efcef2a0538de8043f41,"Remote communication in ENT has been expanding, spurred by the COVID-19 pandemic. Conferences and teaching have moved online, enabling easier participation and reducing financial and environmental costs. Online multi-disciplinary meetings have recently been instigated in Africa to discuss management of cases in head and neck cancer, or cochlear implantation, expanding access and enhancing patient care. Remote patient consultation has also seen an explosion, but existing literature suggests some caution, particularly because many patients in ENT need an examination to enable definitive diagnosis. Ongoing experience will help us to better understand how remote communication will fit into our future working lives, and also where face-to-face interaction may still be preferable. © 2021 John Wiley & Sons Ltd",33872469,Editorial,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85105045625
Alexander J.M.,"Alexander, Joshua M. (8638486700)",8638486700,Hearing Aid Technology to Improve Speech Intelligibility in Noise,2021,Seminars in Hearing,42,3,,175,185,10,1,10.1055/s-0041-1735174,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116230139&doi=10.1055%2fs-0041-1735174&partnerID=40&md5=a9d580d60d2abf19630b7f6d9cbada6b,"Understanding speech in noise is difficult for individuals with normal hearing and is even more so for individuals with hearing loss. Difficulty understanding speech in noise is one of the primary reasons people seek hearing assistance. Despite amplification, many hearing aid users still struggle to understand speech in noise. In response to this persistent problem, hearing aid manufacturers have invested significantly in developing new solutions. Any solution is not without its tradeoffs, and decisions must be made when optimizing and implementing them. Much of this happens behind the scenes, and casual observers fail to appreciate the nuances of developing new hearing aid technologies. The difficulty of communicating this information to clinicians may hinder the use or the fine-tuning of the various technologies available today. The purpose of this issue of Seminars in Hearing is to educate professionals and students in audiology, hearing science, and engineering about different approaches to combat problems related to environmental and wind noise using technologies that include classification, directional microphones, binaural signal processing, beamformers, motion sensors, and machine learning. To accomplish this purpose, some of the top researchers and engineers from the world's largest hearing aid manufacturers agreed to share their unique insights. © 2021 American Medical Association. All rights reserved.",,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85116230139
Crispo M.; Chenouard V.; dos Santos-Neto P.; Tesson L.; Souza-Neves M.; Heslan J.-M.; Cuadro F.; Anegón I.; Menchaca A.,"Crispo, Martina (15032583900); Chenouard, Vanessa (56373016100); dos Santos-Neto, Pedro (56276450800); Tesson, Laurent (6701460138); Souza-Neves, Marcela (57206848584); Heslan, Jean-Marie (6604007474); Cuadro, Federico (55555840700); Anegón, Ignacio (57207558963); Menchaca, Alejo (6603616921)",15032583900; 56373016100; 56276450800; 6701460138; 57206848584; 6604007474; 55555840700; 57207558963; 6603616921,Generation of a Human Deafness Sheep Model Using the CRISPR/Cas System,2022,Methods in Molecular Biology,2495,,,233,244,11,3,10.1007/978-1-0716-2301-5_12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132827224&doi=10.1007%2f978-1-0716-2301-5_12&partnerID=40&md5=313650744a09d77719528413df6c2163,"CRISPR/Cas9 system is a promising method for the generation of human disease models by genome editing in non-conventional experimental animals. Medium/large-sized animals like sheep have several advantages to study human diseases and medicine. Here, we present a protocol that describes the generation of an otoferlin edited sheep model via CRISPR-assisted single-stranded oligodinucleotide-mediated Homology-Directed Repair (HDR), through direct cytoplasmic microinjection in in vitro produced zygotes. Otoferlin is a protein expressed in the cochlear inner hair cells, with different mutations at the OTOF gene being the major cause of nonsyndromic recessive auditory neuropathy spectrum disorder in humans. By using this protocol, we reported for the first time an OTOF KI model in sheep with 17.8% edited lambs showing indel mutations, and 61.5% of them bearing knock-in mutations by HDR. The reported method establishes the bases to produce a deafness model to test novel therapies in human disorders related to OTOF mutations. © 2022, The Author(s), under exclusive license to Springer Science+Business Media, LLC, part of Springer Nature.",35696036,Book chapter,Final,,Scopus,2-s2.0-85132827224
He J.; Aa J.-Y.; Sun J.-G.; Smith P.F.; De Ridder D.; Wang G.-J.; Zheng Y.,"He, Jun (57190609093); Aa, Ji-Ye (36337632600); Sun, Jian-Guo (55539665500); Smith, Paul F. (7408329494); De Ridder, Dirk (7006928697); Wang, Guang-Ji (10639401500); Zheng, Yiwen (7404837924)",57190609093; 36337632600; 55539665500; 7408329494; 7006928697; 10639401500; 7404837924,"Metabolic changes in the brain and blood of rats following acoustic trauma, tinnitus and hyperacusis",2021,Progress in Brain Research,262,,,399,430,31,4,10.1016/bs.pbr.2020.09.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099623576&doi=10.1016%2fbs.pbr.2020.09.002&partnerID=40&md5=e4ad1e6d01c02c95de59666a19ceb595,"It has been increasingly recognized that tinnitus is likely to be generated by complex network changes. Acoustic trauma that causes tinnitus induces significant changes in multiple metabolic pathways in the brain. However, it is not clear whether those metabolic changes in the brain could also be reflected in blood samples and whether metabolic changes could discriminate acoustic trauma, hyperacusis and tinnitus. We analyzed brain and serum metabolic changes in rats following acoustic trauma or a sham procedure using metabolomics. Hearing levels were recorded before and after acoustic trauma and behavioral measures to quantify tinnitus and hyperacusis were conducted at 4 weeks following acoustic trauma. Tissues from 11 different brain regions and serum samples were collected at about 3 months following acoustic trauma. Among the acoustic trauma animals, eight exhibited hyperacusis-like behavior and three exhibited tinnitus-like behavior. Using Gas chromatography–mass spectrometry and multivariate statistical analysis, significant metabolic changes were found in acoustic trauma animals in both the brain and serum samples with a number of metabolic pathways significantly perturbated. Furthermore, metabolic changes in the serum were able to differentiate sham from acoustic trauma animals, as well as sham from hyperacusis animals, with high accuracy. Our results suggest that serum metabolic profiling in combination with machine learning analysis may be a promising approach for identifying biomarkers for acoustic trauma, hyperacusis and potentially, tinnitus. © 2021 Elsevier B.V.",33931189,Book chapter,Final,,Scopus,2-s2.0-85099623576
Yang C.; Zhang Y.; Li J.; Song Z.; Yi Z.; Li F.; Xue J.; Zhang W.; Wang C.,"Yang, Chengqing (57193264033); Zhang, Ying (55280080600); Li, Jiuwei (23489448800); Song, Zhenfeng (57217996900); Yi, Zhi (57210796674); Li, Fei (56510536700); Xue, Jiao (56985016800); Zhang, Wei (57222554097); Wang, Chunli (57222561755)",57193264033; 55280080600; 23489448800; 57217996900; 57210796674; 56510536700; 56985016800; 57222554097; 57222561755,"Report of a case with ferredoxin reductase (FDXR) gene variants in a Chinese boy exhibiting hearing loss, visual impairment, and motor retardation",2021,International Journal of Developmental Neuroscience,81,4,,364,369,5,4,10.1002/jdn.10104,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103156585&doi=10.1002%2fjdn.10104&partnerID=40&md5=1f8640b7c27819aefec0518fe4ec642d,"Ferredoxin reductase (FDXR), located in 17q25.1, encodes for a mitochondrial NADPH: adrenodoxin oxidoreductase or ferredoxin reductase, the sole human ferredoxin reductase involved in the biosynthesis of iron-sulfur (Fe-S) clusters and heme formation. Iron-sulfur (Fe-S) clusters are involved in enzymatic catalysis, gene expression, and DNA replication and repair. Variants in FDXR lead to sensorial neuropathies, damage optic, and auditory neurons. Here, we report a Chinese boy with hearing loss, visual impairment, and motor retardation, with two novel compound heterozygous variants in FDXR (NM_004110), namely, c.250C > T (p.P84S) and c.634G > C (p.D212H), identified by whole-exome sequencing. Compared with the reported cases, except hearing loss and visual impairment, the clinical manifestations of this boy were more serious, who also had motor retardation and died in infancy after infection. The present study expands our knowledge of FDXR variants and related phenotypes, and provides new information on the genetic defects associated with this disease for clinical diagnosis. © 2021 International Society for Developmental Neuroscience",33742450,Article,Final,,Scopus,2-s2.0-85103156585
Colón-Cruz L.; Rodriguez-Morales R.; Santana-Cruz A.; Cantres-Velez J.; Torrado-Tapias A.; Lin S.-J.; Yudowski G.; Kensler R.; Marie B.; Burgess S.M.; Renaud O.; Varshney G.K.; Behra M.,"Colón-Cruz, Luis (56656628000); Rodriguez-Morales, Roberto (47661653400); Santana-Cruz, Alexis (57219791611); Cantres-Velez, Juan (57210237926); Torrado-Tapias, Aranza (57218114036); Lin, Sheng-Jia (55376715300); Yudowski, Guillermo (6506457518); Kensler, Robert (6603702235); Marie, Bruno (7003267152); Burgess, Shawn M. (7101644458); Renaud, Olivier (57221347621); Varshney, Gaurav K. (6701397694); Behra, Martine (15734566200)",56656628000; 47661653400; 57219791611; 57210237926; 57218114036; 55376715300; 6506457518; 6603702235; 7003267152; 7101644458; 57221347621; 6701397694; 15734566200,Cnr2 Is Important for Ribbon Synapse Maturation and Function in Hair Cells and Photoreceptors,2021,Frontiers in Molecular Neuroscience,14,,624265,,,,1,10.3389/fnmol.2021.624265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105357639&doi=10.3389%2ffnmol.2021.624265&partnerID=40&md5=ea9343d9b40ce98f1932804bf58fcae9,"The role of the cannabinoid receptor 2 (CNR2) is still poorly described in sensory epithelia. We found strong cnr2 expression in hair cells (HCs) of the inner ear and the lateral line (LL), a superficial sensory structure in fish. Next, we demonstrated that sensory synapses in HCs were severely perturbed in larvae lacking cnr2. Appearance and distribution of presynaptic ribbons and calcium channels (Cav1.3) were profoundly altered in mutant animals. Clustering of membrane-associated guanylate kinase (MAGUK) in post-synaptic densities (PSDs) was also heavily affected, suggesting a role for cnr2 for maintaining the sensory synapse. Furthermore, vesicular trafficking in HCs was strongly perturbed suggesting a retrograde action of the endocannabinoid system (ECs) via cnr2 that was modulating HC mechanotransduction. We found similar perturbations in retinal ribbon synapses. Finally, we showed that larval swimming behaviors after sound and light stimulations were significantly different in mutant animals. Thus, we propose that cnr2 is critical for the processing of sensory information in the developing larva. © Copyright © 2021 Colón-Cruz, Rodriguez-Morales, Santana-Cruz, Cantres-Velez, Torrado-Tapias, Lin, Yudowski, Kensler, Marie, Burgess, Renaud, Varshney and Behra.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85105357639
Carvalho L.R.R.D.A.; Pinto L.S.S.; de Sousa G.P.; Correia J.P.D.P.; de Moura M.S.,"Carvalho, Lúcia Rosa Reis de Araújo (57218920735); Pinto, Lucielma Salmito Soares (24830911800); de Sousa, Geovanna Peres (57216592215); Correia, José Pascoal Duarte Pinheiro (57218917795); de Moura, Marcoeli Silva (16309139600)",57218920735; 24830911800; 57216592215; 57218917795; 16309139600,Oromandibular Limb Hypogenesis Syndrome: Overlap of Moebius and Ankyloglossia Superior With Severe Limb Defects,2021,Cleft Palate-Craniofacial Journal,58,4,,518,524,6,2,10.1177/1055665620954736,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090774243&doi=10.1177%2f1055665620954736&partnerID=40&md5=8a8f711543b0eb0e72926a22469cbc3c,"The oromandibular limb hypogenesis syndromes (OLHS) represent a group of rare conditions characterized by congenital malformations involving the tongue, mandible, and limbs. In this report, we describe a newborn girl with paralysis of abducens and facial nerves, transverse agenesis of the distal segments of the limbs, micrognathia, cleft lip and palate, and ankyloglossia superior. This observation confirms an overlap between Moebius syndrome and ankyloglossia superior syndrome with severe limb defects. The etiology of the OLHS is not clearly understood. The intriguing link between facial and limb anomalies can result from their simultaneous development from the fourth to eighth week of gestation, making both areas susceptible to the same teratogenic stimuli. There is an overlap between OLHS conditions, supporting a clustering, rather than a divided nosology and requiring an appropriate classification of these conditions. Patients with OLHS can be successfully managed using a multidisciplinary approach. © 2020, American Cleft Palate-Craniofacial Association.",32909817,Article,Final,,Scopus,2-s2.0-85090774243
Carlton A.J.; Halford J.; Underhill A.; Jeng J.-Y.; Avenarius M.R.; Gilbert M.L.; Ceriani F.; Ebisine K.; Brown S.D.M.; Bowl M.R.; Barr-Gillespie P.G.; Marcotti W.,"Carlton, Adam J. (57218213480); Halford, Julia (57220073095); Underhill, Anna (57220069967); Jeng, Jing-Yi (57196222089); Avenarius, Matthew R. (8515347300); Gilbert, Merle L. (9237677000); Ceriani, Federico (55330877600); Ebisine, Kimimuepigha (57193811750); Brown, Steve D. M. (57206961339); Bowl, Michael R. (6506874735); Barr-Gillespie, Peter G. (7005143141); Marcotti, Walter (6602070670)",57218213480; 57220073095; 57220069967; 57196222089; 8515347300; 9237677000; 55330877600; 57193811750; 57206961339; 6506874735; 7005143141; 6602070670,Loss of Baiap2l2 destabilizes the transducing stereocilia of cochlear hair cells and leads to deafness,2021,Journal of Physiology,599,4,,1173,1198,25,26,10.1113/JP280670,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096764698&doi=10.1113%2fJP280670&partnerID=40&md5=6ee591153dbce99a83452efc78bb18e4,"Key points: Mechanoelectrical transduction at auditory hair cells requires highly specialized stereociliary bundles that project from their apical surface, forming a characteristic graded ‘staircase’ structure. The morphogenesis and maintenance of these stereociliary bundles is a tightly regulated process requiring the involvement of several actin-binding proteins, many of which are still unidentified. We identify a new stereociliary protein, the I-BAR protein BAIAP2L2, which localizes to the tips of the shorter transducing stereocilia in both inner and outer hair cells (IHCs and OHCs). We find that Baiap2l2 deficient mice lose their second and third rows of stereocilia, their mechanoelectrical transducer current, and develop progressive hearing loss, becoming deaf by 8 months of age. We demonstrate that BAIAP2L2 localization to stereocilia tips is dependent on the motor protein MYO15A and its cargo EPS8. We propose that BAIAP2L2 is a new key protein required for the maintenance of the transducing stereocilia in mature cochlear hair cells. Abstract: The transduction of sound waves into electrical signals depends upon mechanosensitive stereociliary bundles that project from the apical surface of hair cells within the cochlea. The height and width of these actin-based stereocilia is tightly regulated throughout life to establish and maintain their characteristic staircase-like structure, which is essential for normal mechanoelectrical transduction. Here, we show that BAIAP2L2, a member of the I-BAR protein family, is a newly identified hair bundle protein that is localized to the tips of the shorter rows of transducing stereocilia in mouse cochlear hair cells. BAIAP2L2 was detected by immunohistochemistry from postnatal day 2.5 (P2.5) throughout adulthood. In Baiap2l2 deficient mice, outer hair cells (OHCs), but not inner hair cells (IHCs), began to lose their third row of stereocilia and showed a reduction in the size of the mechanoelectrical transducer current from just after P9. Over the following post-hearing weeks, the ordered staircase structure of the bundle progressively deteriorates, such that, by 8 months of age, both OHCs and IHCs of Baiap2l2 deficient mice have lost most of the second and third rows of stereocilia and become deaf. We also found that BAIAP2L2 interacts with other key stereociliary proteins involved in normal hair bundle morphogenesis, such as CDC42, RAC1, EPS8 and ESPNL. Furthermore, we show that BAIAP2L2 localization to the stereocilia tips depends on the motor protein MYO15A and its cargo EPS8. We propose that BAIAP2L2 is key to maintenance of the normal actin structure of the transducing stereocilia in mature mouse cochlear hair cells. © 2020 The Authors. The Journal of Physiology published by John Wiley & Sons Ltd on behalf of The Physiological Society.",33151556,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85096764698
Basso L.; Boecking B.; Brueggemann P.; Pedersen N.L.; Canlon B.; Cederroth C.R.; Mazurek B.,"Basso, Laura (57205740946); Boecking, Benjamin (57205672666); Brueggemann, Petra (57193442082); Pedersen, Nancy L. (7202300001); Canlon, Barbara (7005948234); Cederroth, Christopher R. (9242388300); Mazurek, Birgit (8675295000)",57205740946; 57205672666; 57193442082; 7202300001; 7005948234; 9242388300; 8675295000,"Subjective hearing ability, physical and mental comorbidities in individuals with bothersome tinnitus in a Swedish population sample",2021,Progress in Brain Research,260,,,51,78,27,16,10.1016/bs.pbr.2020.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100389983&doi=10.1016%2fbs.pbr.2020.10.001&partnerID=40&md5=7fa25d6dd43679b22e99b7d63dad189a,"Objective: This study investigates associations of subjective hearing ability, physical comorbidities, and mental comorbidities with bothersome (vs. non-bothersome) tinnitus and mediating effects between these influences. Methods: The Swedish LifeGene cohort was used to sample cross-sectional survey data (collected 2009–2016) of 7615 participants with tinnitus, 697 (9.2%) of whom rated their tinnitus as bothersome. Associations between bothersome tinnitus and subjective hearing ability, physical and mental comorbidities were investigated by separate age- and gender-adjusted multiple logistic regression models. Interrelationships between these associations were investigated by logistic mediation models. Results: Compared to non-bothersome tinnitus, bothersome tinnitus was associated with higher age, reduced subjective hearing ability, hearing-related difficulties in social situations, cardiovascular disease, chronic shoulder pain, thyroid disease, Ménière's disease, depression, anxiety syndrome, and social anxiety. Subjective hearing impairment or hearing-related difficulties mediated 13–36% of the effects of mental comorbidities on bothersome tinnitus. Depression or anxiety syndrome mediated 5–8% of most relationships between physical comorbidities and bothersome tinnitus. Depression, anxiety syndrome, or social anxiety mediated 2–4% of the effects of subjective hearing impairment or hearing-related difficulties on bothersome tinnitus. Conclusion: Psychological factors, subjective hearing impairment, and hearing-related difficulties in social situations play key roles in predicting bothersome (vs. non-bothersome) tinnitus in a large population sample. Psychological factors contribute to explaining the impact of physical comorbidities and hearing-related effects on bothersome tinnitus. This highlights their transdiagnostic importance for aggravating varied physical symptom clusters. Interventions to improve or prevent high tinnitus burden should be interdisciplinary/multimodal and target auditory, physical, and psychological factors. © 2021 Elsevier B.V.",33637232,Book chapter,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85100389983
Fischer T.; Caversaccio M.; Wimmer W.,"Fischer, Tim (57189588178); Caversaccio, Marco (7004135207); Wimmer, Wilhelm (55808897400)",57189588178; 7004135207; 55808897400,Speech signal enhancement in cocktail party scenarios by deep learning based virtual sensing of head-mounted microphones,2021,Hearing Research,408,,108294,,,,9,10.1016/j.heares.2021.108294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108596446&doi=10.1016%2fj.heares.2021.108294&partnerID=40&md5=9c2db32e8316f3e4cdd62d74a9860280,"The cocktail party effect refers to the human sense of hearing's ability to pay attention to a single conversation while filtering out all other background noise. To mimic this human hearing ability for people with hearing loss, scientists integrate beamforming algorithms into the signal processing path of hearing aids or implants’ audio processors. Although these algorithms’ performance strongly depends on the number and spatial arrangement of the microphones, most devices are equipped with a small number of microphones mounted close to each other on the audio processor housing. We measured and evaluated the impact of the number and spatial arrangement of hearing aid or head-mounted microphones on the performance of the established Minimum Variance Distortionless Response beamformer in cocktail party scenarios. The measurements revealed that the optimal microphone placement exploits monaural cues (pinna-effect), is close to the target signal, and creates a large distance spread due to its spatial arrangement. However, this microphone placement is impractical for hearing aid or implant users, as it includes microphone positions such as on the forehead. To overcome microphones’ placement at impractical positions, we propose a deep virtual sensing estimation of the corresponding audio signals. The results of objective measures and a subjective listening test with 20 participants showed that the virtually sensed microphone signals significantly improved the speech quality, especially in cocktail party scenarios with low signal-to-noise ratios. Subjective speech quality was assessed using a 3-alternative forced choice procedure to determine which of the presented speech mixtures was most pleasant to understand. Hearing aid and cochlear implant (CI) users might benefit from the presented approach using virtually sensed microphone signals, especially in noisy environments. © 2021 The Author(s)",34182232,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85108596446
Huda M.M.; Hadisaputro S.; Suprihati S.; Suwondo A.,"Huda, Moch Maftuchul (57762516100); Hadisaputro, Soeharyo (6506011180); Suprihati, Suprihati (57209398076); Suwondo, Ari (57189325555)",57762516100; 6506011180; 57209398076; 57189325555,Combination of Egg Tray Silencer and Progressive Relaxation to Overcome Community Auditory Disorders in Indonesian Noise Train Environments; [Combinación de silenciador de bandeja de huevos y relajación progresiva para superar los trastornos auditivos comunitarios en ambientes de ruido de tren en Indonesia],2022,Gaceta Medica de Caracas,130,,,S257,S264,7,0,10.47307/GMC.2022.130.S1.42,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132739062&doi=10.47307%2fGMC.2022.130.S1.42&partnerID=40&md5=620175b6c3654bf3c47f42de5522c734,"Introduction: People who live near the edge of the railroad tracks cannot avoid environmental noise. Various efforts have been made to build a barrier between railroad crossings and residential areas and install silencers on locomotives. However. the environmental noise intensity is still above the normal threshold value (NAV 55dB). Therefore, the combination of egg tray damper and progressive relaxation (KODAMSI) is expected to be an alternative solution. This study aimed to prove the effect of KODAMSI on temporary hearing loss in respondents who are exposed to train noise intensity. M ethods: This study used a randomized control trial (RCT). Research subjects were screened and determined by two-stage cluster random sampling. Three hundred people (35 %) from 3 villages living on the edge of the railway were screened using the KODAMSI, and 30 research subjects were obtained according to inclusion and exclusion criteria. An amount of 30 respondents were randomly assigned to cluster stage II. The statistical analysis used Mann-Whitney and Willcoxon test. Results: The mean difference in reduction (delta) of noise intensity before and after the intervention of the egg tray silencer in the treatment group was 33.87dB. KODAMSI proved effective in improving hearing loss (p=0.0001) from moderate (41.33dB) to mild (32.15dB) with an average delta threshold of 9.2dB. Conclusion: KODAMSI has effectively reduced the intensity of environmental noise in noise pollution from train tracks and can significantly improve temporary hearing loss. KODAMSI might become an alternative to diminish hearing loss and prevent noise in the community. © 2022 Academia Nacional de Medicina. All rights reserved.",,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85132739062
Schlee W.; Langguth B.; Kleinjung T.; Vanneste S.; De Ridder D.,"Schlee, Winfried (22836015100); Langguth, Berthold (6602352583); Kleinjung, Tobias (6602406673); Vanneste, Sven (35225555700); De Ridder, Dirk (57221973477)",22836015100; 6602352583; 6602406673; 35225555700; 57221973477,Preface,2021,Progress in Brain Research,260,,,xxxv,xlii,,0,10.1016/S0079-6123(21)00069-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101360730&doi=10.1016%2fS0079-6123%2821%2900069-8&partnerID=40&md5=3b2b27b70fb02d4ef219eec56c9fd380,[No abstract available],33637234,Editorial,Final,,Scopus,2-s2.0-85101360730
Crowson M.G.; Franck K.H.; Rosella L.C.; Chan T.C.Y.,"Crowson, Matthew G. (56631418200); Franck, Kevin H. (6603882325); Rosella, Laura C. (23489789700); Chan, Timothy C. Y. (26667472500)",56631418200; 6603882325; 23489789700; 26667472500,Predicting Depression from Hearing Loss Using Machine Learning,2021,Ear and Hearing,42,4,,982,989,7,4,10.1097/AUD.0000000000000993,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108972337&doi=10.1097%2fAUD.0000000000000993&partnerID=40&md5=ebd4e70b91b9cee87270b17be0ef08d8,"Objectives: Hearing loss is the most common sensory loss in humans and carries an enhanced risk of depression. No prior studies have attempted a contemporary machine learning approach to predict depression using subjective and objective hearing loss predictors. The objective was to deploy supervised machine learning to predict scores on a validated depression scale using subjective and objective audiometric variables and other health determinant predictors. Design: A large predictor set of health determinants from the National Health and Nutrition Examination Survey 2015-2016 database was used to predict adults' scores on a validated instrument to screen for the presence and severity of depression (Patient Health Questionnaire-9 [PHQ-9]). After model training, the relative influence of individual predictors on depression scores was stratified and analyzed. Model prediction performance was determined by prediction error metrics. Results: The test set mean absolute error was 3.03 (95% confidence interval: 2.91 to 3.14) and 2.55 (95% confidence interval: 2.48 to 2.62) on datasets with audiology-only predictors and all predictors, respectively, on the PHQ-9's 27-point scale. Participants' self-reported frustration when talking to members of family or friends due to hearing loss was the fifth-most influential of all predictors. Of the top 10 most influential audiometric predictors, five were related to social contexts, two for significant noise exposure, two objective audiometric parameters, and one presence of bothersome tinnitus. Conclusions: Machine learning algorithms can accurately predict PHQ-9 depression scale scores from National Health and Nutrition Examination Survey data. The most influential audiometric predictors of higher scores on a validated depression scale were social dynamics of hearing loss and not objective audiometric testing. Such models could be useful in predicting depression scale scores at the point-of-care in conjunction with a standard audiologic assessment. © 2021 Lippincott Williams and Wilkins. All rights reserved.",33577219,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85108972337
Saleh H.K.; Folkeard P.; Van Eeckhoutte M.; Scollie S.,"Saleh, Hasan K. (57213175524); Folkeard, Paula (55503455900); Van Eeckhoutte, Maaike (57192011266); Scollie, Susan (6602453065)",57213175524; 55503455900; 57192011266; 6602453065,Premium versus entry-level hearing aids: using group concept mapping to investigate the drivers of preference,2022,International Journal of Audiology,61,12,,1003,1017,14,3,10.1080/14992027.2021.2009923,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122264238&doi=10.1080%2f14992027.2021.2009923&partnerID=40&md5=d3db49c5ada72555a6dc9c766b5294ee,"Objectives: To investigate the difference in outcome measures and drivers of user preference between premium and entry-level hearing aids using group concept mapping. Design: A single-blind crossover trial was conducted. Aided behavioural outcomes measured were loudness rating, speech/consonant recognition, and speech quality. Preference between hearing aids was measured with a 7-point Likert scale. Group concept mapping was utilised to investigate preference results. Participants generated statements based on what influenced their preferences. These were sorted into categories with underlying themes. Participants rated each statement on a 5-point Likert scale of importance. Study sample: Twenty-three adult participants (mean: 62.4 years; range: 24–78) with mild to moderately severe bilateral SNHL (PTA500–4000 Hz > 20 dB HL). Results: A total of 83 unique statements and nine distinct clusters, with underlying themes driving preference, were generated. Clusters that differed significantly in importance between entry-level and premium hearing aid choosers were: Having access to smartphone application-based user-controlled settings, the ability to stream calls and music, and convenience features such as accessory compatibility. Conclusion: This study has identified non-signal-processing factors which significantly influenced preference for a premium hearing aid over an entry-level hearing aid, indicating the importance of these features as drivers of user preference. © 2021 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",34883040,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85122264238
Manara R.; Ponticorvo S.; Perrotta S.; Barillari M.R.; Costa G.; Brotto D.; Di Concilio R.; Ciancio A.; De Michele E.; Carafa P.A.; Canna A.; Russo A.G.; Troisi D.; Caiazza M.; Ammendola F.; Roberti D.; Santoro C.; Picariello S.; Valentino M.S.; Inserra E.; Carfora R.; Cirillo M.; Raimo S.; Santangelo G.; di Salle F.; Esposito F.; Tartaglione I.,"Manara, Renzo (6603641806); Ponticorvo, Sara (57201745187); Perrotta, Silverio (7006513384); Barillari, Maria Rosaria (6508022061); Costa, Giuseppe (55706635000); Brotto, Davide (56422384100); Di Concilio, Rosanna (6508010119); Ciancio, Angela (7003591915); De Michele, Elisa (56508474400); Carafa, Pasquale Alessandro (57207457995); Canna, Antonietta (57193434142); Russo, Andrea Gerardo (57201747386); Troisi, Donato (57192163462); Caiazza, Martina (7801532501); Ammendola, Federica (57216251793); Roberti, Domenico (36549067400); Santoro, Claudia (25926052100); Picariello, Stefania (55637476500); Valentino, Maria Sole (57212682905); Inserra, Emanuela (57214679095); Carfora, Roberta (57226571742); Cirillo, Mario (7006376762); Raimo, Simona (56388629400); Santangelo, Gabriella (7006968775); di Salle, Francesco (7004206559); Esposito, Fabrizio (7102220908); Tartaglione, Immacolata (56508449200)",6603641806; 57201745187; 7006513384; 6508022061; 55706635000; 56422384100; 6508010119; 7003591915; 56508474400; 57207457995; 57193434142; 57201747386; 57192163462; 7801532501; 57216251793; 36549067400; 25926052100; 55637476500; 57212682905; 57214679095; 57226571742; 7006376762; 56388629400; 7006968775; 7004206559; 7102220908; 56508449200,Auditory cortex hypoperfusion: a metabolic hallmark in Beta Thalassemia,2021,Orphanet Journal of Rare Diseases,16,1,349,,,,7,10.1186/s13023-021-01969-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111993036&doi=10.1186%2fs13023-021-01969-0&partnerID=40&md5=612a3e8d1c64ade3e39750406937467d,"Background: Sensorineural hearing loss in beta-thalassemia is common and it is generally associated with iron chelation therapy. However, data are scarce, especially on adult populations, and a possible involvement of the central auditory areas has not been investigated yet. We performed a multicenter cross-sectional audiological and single-center 3Tesla brain perfusion MRI study enrolling 77 transfusion-dependent/non transfusion-dependent adult patients and 56 healthy controls. Pure tone audiometry, demographics, clinical/laboratory and cognitive functioning data were recorded. Results: Half of patients (52%) presented with high-frequency hearing deficit, with overt hypoacusia (Pure Tone Average (PTA) > 25 dB) in 35%, irrespective of iron chelation or clinical phenotype. Bilateral voxel clusters of significant relative hypoperfusion were found in the auditory cortex of beta-thalassemia patients, regardless of clinical phenotype. In controls and transfusion-dependent (but not in non-transfusion-dependent) patients, the relative auditory cortex perfusion values increased linearly with age (p < 0.04). Relative auditory cortex perfusion values showed a significant U-shaped correlation with PTA values among hearing loss patients, and a linear correlation with the full scale intelligence quotient (right side p = 0.01, left side p = 0.02) with its domain related to communication skills (right side p = 0.04, left side p = 0.07) in controls but not in beta-thalassemia patients. Audiometric test results did not correlate to cognitive test scores in any subgroup. Conclusions: In conclusion, primary auditory cortex perfusion changes are a metabolic hallmark of adult beta-thalassemia, thus suggesting complex remodeling of the hearing function, that occurs regardless of chelation therapy and before clinically manifest hearing loss. The cognitive impact of perfusion changes is intriguing but requires further investigations. © 2021, The Author(s).",34353346,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85111993036
Liu Z.; Yao L.; Wang X.; Monaghan J.J.M.; Schaette R.; He Z.; McAlpine D.,"Liu, Zhe (57218846134); Yao, Lina (54406102800); Wang, Xianzhi (36189130500); Monaghan, Jessica J. M. (26434339400); Schaette, Roland (14014026800); He, Zihuai (56019976400); McAlpine, David (7005917811)",57218846134; 54406102800; 36189130500; 26434339400; 14014026800; 56019976400; 7005917811,Generalizable Sample-Efficient Siamese Autoencoder for Tinnitus Diagnosis in Listeners with Subjective Tinnitus,2021,IEEE Transactions on Neural Systems and Rehabilitation Engineering,29,,9475971,1452,1461,9,7,10.1109/TNSRE.2021.3095298,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111742420&doi=10.1109%2fTNSRE.2021.3095298&partnerID=40&md5=5087a8e0617f85aa94b69360e4fb1626,"Electroencephalogram (EEG)-based neurofeedback has been widely studied for tinnitus therapy in recent years. Most existing research relies on experts' cognitive prediction, and studies based on machine learning and deep learning are either data-hungry or not well generalizable to new subjects. In this paper, we propose a robust, data-efficient model for distinguishing tinnitus from the healthy state based on EEG-based tinnitus neurofeedback. We propose trend descriptor, a feature extractor with lower fineness, to reduce the effect of electrode noises on EEG signals, and a siamese encoder-decoder network boosted in a supervised manner to learn accurate alignment and to acquire high-quality transferable mappings across subjects and EEG signal channels. Our experiments show the proposed method significantly outperforms state-of-the-art algorithms when analyzing subjects' EEG neurofeedback to 90dB and 100dB sound, achieving an accuracy of 91.67%-94.44% in predicting tinnitus and control subjects in a subject-independent setting. Our ablation studies on mixed subjects and parameters show the method's stability in performance. © 2001-2011 IEEE.",34232883,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85111742420
Wang Q.; Shen Y.; Pan Y.; Chen K.; Ding R.; Zou T.; Zhang A.; Guo D.; Ji P.; Fan C.; Mei L.; Hu H.; Ye B.; Xiang M.,"Wang, Quan (57192193179); Shen, Yilin (57202417554); Pan, Yi (57216340022); Chen, Kaili (57222761906); Ding, Rui (57216351054); Zou, Tianyuan (57222271096); Zhang, Andi (57218923776); Guo, Dongye (57222273547); Ji, Peilin (57327096700); Fan, Cui (57202419868); Mei, Ling (57204251594); Hu, Haixia (55891322000); Ye, Bin (57214103175); Xiang, Mingliang (7004985186)",57192193179; 57202417554; 57216340022; 57222761906; 57216351054; 57222271096; 57218923776; 57222273547; 57327096700; 57202419868; 57204251594; 55891322000; 57214103175; 7004985186,Tlr2/4 Double Knockout Attenuates the Degeneration of Primary Auditory Neurons: Potential Mechanisms From Transcriptomic Perspectives,2021,Frontiers in Cell and Developmental Biology,9,,750271,,,,2,10.3389/fcell.2021.750271,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118690829&doi=10.3389%2ffcell.2021.750271&partnerID=40&md5=109fbca744c2207b784a0e85c1765e8f,"The transcriptomic landscape of mice with primary auditory neurons degeneration (PAND) indicates key pathways in its pathogenesis, including complement cascades, immune responses, tumor necrosis factor (TNF) signaling pathway, and cytokine-cytokine receptor interaction. Toll-like receptors (TLRs) are important immune and inflammatory molecules that have been shown to disrupt the disease network of PAND. In a PAND model involving administration of kanamycin combined with furosemide to destroy cochlear hair cells, Tlr 2/4 double knockout (DKO) mice had auditory preservation advantages, which were mainly manifested at 4–16 kHz. DKO mice and wild type (WT) mice had completely damaged cochlear hair cells on the 30th day, but the density of spiral ganglion neurons (SGN) in the Rosenthal canal was significantly higher in the DKO group than in the WT group. The results of immunohistochemistry for p38 and p65 showed that the attenuation of SGN degeneration in DKO mice may not be mediated by canonical Tlr signaling pathways. The SGN transcriptome of DKO and WT mice indicated that there was an inverted gene set enrichment relationship between their different transcriptomes and the SGN degeneration transcriptome, which is consistent with the morphology results. Core module analysis suggested that DKO mice may modulate SGN degeneration by activating two clusters, and the involved molecules include EGF, STAT3, CALB2, LOX, SNAP25, CAV2, SDC4, MYL1, NCS1, PVALB, TPM4, and TMOD4. Copyright © 2021 Wang, Shen, Pan, Chen, Ding, Zou, Zhang, Guo, Ji, Fan, Mei, Hu, Ye and Xiang.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85118690829
Liu Y.; Xu R.; Gong Q.,"Liu, Yin (57192571399); Xu, Runyi (57219111960); Gong, Qin (7201440945)",57192571399; 57219111960; 7201440945,Maximising the ability of stimulus-frequency otoacoustic emissions to predict hearing status and thresholds using machine-learning models,2021,International Journal of Audiology,60,4,,263,273,10,4,10.1080/14992027.2020.1821252,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091308879&doi=10.1080%2f14992027.2020.1821252&partnerID=40&md5=0523d0148a1d3c566f9d203c561ff605,"Objective: This study aimed to maximise the ability of stimulus-frequency otoacoustic emissions (SFOAEs) to predict hearing status and thresholds based on machine-learning models. Design: SFOAE data and audiometric thresholds were collected at octave frequencies from 0.5 to 8 kHz. Support vector machine, k-nearest neighbour, back propagation neural network, decision tree, and random forest algorithms were used to build classification models for status identification and to develop regression models for threshold prediction. Study sample: About 230 ears with normal hearing and 737 ears with sensorineural hearing loss. Results: All classification models yielded areas under the receiver operating characteristic curve of 0.926–0.994 at 0.5–8 kHz, superior to the previous SFOAE study. The regression models produced lower standard errors (8.1–12.2 dB, mean absolute errors: 5.53–8.97 dB) as compared to those for distortion-product and transient-evoked otoacoustic emissions previously reported (8.6–19.2 dB). Conclusions: SFOAEs using machine-learning approaches offer promising tools for the prediction of hearing capabilities, at least at 0.5–4 kHz. Future research may focus on further improvements in accuracy and reductions in test time to improve clinical utility. © 2020 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",32959697,Article,Final,,Scopus,2-s2.0-85091308879
Skidmore J.; Xu L.; Chao X.; Riggs W.J.; Pellittieri A.; Vaughan C.; Ning X.; Wang R.; Luo J.; He S.,"Skidmore, Jeffrey (56377180900); Xu, Lei (56895370600); Chao, Xiuhua (56769189600); Riggs, William J. (57193009058); Pellittieri, Angela (57215347307); Vaughan, Chloe (58351513600); Ning, Xia (14016229200); Wang, Ruijie (57189321101); Luo, Jianfen (55482634200); He, Shuman (15839465400)",56377180900; 56895370600; 56769189600; 57193009058; 57215347307; 58351513600; 14016229200; 57189321101; 55482634200; 15839465400,Prediction of the Functional Status of the Cochlear Nerve in Individual Cochlear Implant Users Using Machine Learning and Electrophysiological Measures,2021,Ear and Hearing,42,1,,180,192,12,17,10.1097/AUD.0000000000000916,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099072589&doi=10.1097%2fAUD.0000000000000916&partnerID=40&md5=ec63de7d58cd21cf424c5efcf2079cad,"Objectives: This study aimed to create an objective predictive model for assessing the functional status of the cochlear nerve (CN) in individual cochlear implant (CI) users. Design: Study participants included 23 children with cochlear nerve deficiency (CND), 29 children with normal-sized CNs (NSCNs), and 20 adults with various etiologies of hearing loss. Eight participants were bilateral CI users and were tested in both ears. As a result, a total of 80 ears were tested in this study. All participants used Cochlear Nucleus CIs in their test ears. For each participant, the CN refractory recovery function and input/output (I/O) function were measured using electrophysiological measures of the electrically evoked compound action potential (eCAP) at three electrode sites across the electrode array. Refractory recovery time constants were estimated using statistical modeling with an exponential decay function. Slopes of I/O functions were estimated using linear regression. The eCAP parameters used as input variables in the predictive model were absolute refractory recovery time estimated based on the refractory recovery function, eCAP threshold, slope of the eCAP I/O function, and negative-peak (i.e., N1) latency. The output variable of the predictive model was CN index, an indicator for the functional status of the CN. Predictive models were created by performing linear regression, support vector machine regression, and logistic regression with eCAP parameters from children with CND and the children with NSCNs. One-way analysis of variance with post hoc analysis with Tukey's honest significant difference criterion was used to compare study variables among study groups. Results: All three machine learning algorithms created two distinct distributions of CN indices for children with CND and children with NSCNs. Variations in CN index when calculated using different machine learning techniques were observed for adult CI users. Regardless of these variations, CN indices calculated using all three techniques in adult CI users were significantly correlated with Consonant-Nucleus-Consonant word and AzBio sentence scores measured in quiet. The five oldest CI users had smaller CN indices than the five youngest CI users in this study. Conclusions: The functional status of the CN for individual CI users was estimated by our newly developed analytical models. Model predictions of CN function for individual adult CI users were positively and significantly correlated with speech perception performance. The models presented in this study may be useful for understanding and/or predicting CI outcomes for individual patients. © 2021 Lippincott Williams and Wilkins. All rights reserved.",32826505,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85099072589
Shew M.; Wichova H.; Bur A.; Koestler D.C.; St Peter M.; Warnecke A.; Staecker H.,"Shew, Matthew (57188966373); Wichova, Helena (57194501938); Bur, Andres (57218000877); Koestler, Devin C. (36548210200); St Peter, Madeleine (57205691198); Warnecke, Athanasia (22636241700); Staecker, Hinrich (7003979770)",57188966373; 57194501938; 57218000877; 36548210200; 57205691198; 22636241700; 7003979770,MicroRNA Profiling as a Methodology to Diagnose Ménière’s Disease: Potential Application of Machine Learning,2021,Otolaryngology - Head and Neck Surgery (United States),164,2,,399,406,7,7,10.1177/0194599820940649,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087982820&doi=10.1177%2f0194599820940649&partnerID=40&md5=aa3fc9f20da4cf06dd6588bd7d0edb2f,"Objective: Diagnosis and treatment of Ménière’s disease remains a significant challenge because of our inability to understand what is occurring on a molecular level. MicroRNA (miRNA) perilymph profiling is a safe methodology and may serve as a “liquid biopsy” equivalent. We used machine learning (ML) to evaluate miRNA expression profiles of various inner ear pathologies to predict diagnosis of Ménière’s disease. Study Design: Prospective cohort study. Setting: Tertiary academic hospital. Subjects and Methods: Perilymph was collected during labyrinthectomy (Ménière’s disease, n = 5), stapedotomy (otosclerosis, n = 5), and cochlear implantation (sensorineural hearing loss [SNHL], n = 9). miRNA was isolated and analyzed with the Affymetrix miRNA 4.0 array. Various ML classification models were evaluated with an 80/20 train/test split and cross-validation. Permutation feature importance was performed to understand miRNAs that were critical to the classification models. Results: In terms of miRNA profiles for conductive hearing loss versus Ménière’s, 4 models were able to differentiate and identify the 2 disease classes with 100% accuracy. The top-performing models used the same miRNAs in their decision classification model but with different weighted values. All candidate models for SNHL versus Ménière’s performed significantly worse, with the best models achieving 66% accuracy. Ménière’s models showed unique features distinct from SNHL. Conclusions: We can use ML to build Ménière’s-specific prediction models using miRNA profile alone. However, ML models were less accurate in predicting SNHL from Ménière’s, likely from overlap of miRNA biomarkers. The power of this technique is that it identifies biomarkers without knowledge of the pathophysiology, potentially leading to identification of novel biomarkers and diagnostic tests. © American Academy of Otolaryngology–Head and Neck Surgery Foundation 2020.",32663060,Article,Final,,Scopus,2-s2.0-85087982820
Zhao X.; Henderson H.J.; Wang T.; Liu B.; Li Y.,"Zhao, Xiaochang (57220962981); Henderson, Heidi J. (57224518400); Wang, Tianying (57224529346); Liu, Bo (7408693325); Li, Yi (57214958913)",57220962981; 57224518400; 57224529346; 7408693325; 57214958913,Deletion of Clusterin Protects Cochlear Hair Cells against Hair Cell Aging and Ototoxicity,2021,Neural Plasticity,2021,,9979157,,,,6,10.1155/2021/9979157,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107755664&doi=10.1155%2f2021%2f9979157&partnerID=40&md5=d02fd687540645e234edb04afad0576f,"Hearing loss is a debilitating disease that affects 10% of adults worldwide. Most sensorineural hearing loss is caused by the loss of mechanosensitive hair cells in the cochlea, often due to aging, noise, and ototoxic drugs. The identification of genes that can be targeted to slow aging and reduce the vulnerability of hair cells to insults is critical for the prevention of sensorineural hearing loss. Our previous cell-specific transcriptome analysis of adult cochlear hair cells and supporting cells showed that Clu, encoding a secreted chaperone that is involved in several basic biological events, such as cell death, tumor progression, and neurodegenerative disorders, is expressed in hair cells and supporting cells. We generated Clu-null mice (C57BL/6) to investigate its role in the organ of Corti, the sensory epithelium responsible for hearing in the mammalian cochlea. We showed that the deletion of Clu did not affect the development of hair cells and supporting cells; hair cells and supporting cells appeared normal at 1 month of age. Auditory function tests showed that Clu-null mice had hearing thresholds comparable to those of wild-type littermates before 3 months of age. Interestingly, Clu-null mice displayed less hair cell and hearing loss compared to their wildtype littermates after 3 months. Furthermore, the deletion of Clu is protected against aminoglycoside-induced hair cell loss in both in vivo and in vitro models. Our findings suggested that the inhibition of Clu expression could represent a potential therapeutic strategy for the alleviation of age-related and ototoxic drug-induced hearing loss.  © 2021 Xiaochang Zhao et al.",34194490,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85107755664
Barker J.; Akeroyd M.A.; Cox T.J.; Culling J.F.; Firth J.; Graetzer S.; Griffiths H.; Harris L.; Viveros-Munoz R.; Naylor G.; Podwinska Z.; Porter E.,"Barker, Jon (7401680706); Akeroyd, Michael A. (7003932221); Cox, Trevor J. (7203000240); Culling, John F. (7004194328); Firth, Jennifer (57931671600); Graetzer, Simone (56166652200); Griffiths, Holly (57211188356); Harris, Lara (55534607600); Viveros-Munoz, Rhoddy (57464390300); Naylor, Graham (12761085700); Podwinska, Zuzanna (57209878100); Porter, Eszter (57219741883)",7401680706; 7003932221; 7203000240; 7004194328; 57931671600; 56166652200; 57211188356; 55534607600; 57464390300; 12761085700; 57209878100; 57219741883,The 1st Clarity Prediction Challenge: A machine learning challenge for hearing aid intelligibility prediction,2022,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2022-September,,,3508,3512,4,13,10.21437/Interspeech.2022-10821,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128551580&doi=10.21437%2fInterspeech.2022-10821&partnerID=40&md5=e2dbea477b2b4d4a3809c19d562dea7b,"This paper reports on the design and outcomes of the 1st Clarity Prediction Challenge (CPC1) for predicting the intelligibility of hearing aid processed signals heard by individuals with a hearing impairment. The challenge was designed to promote the development of new intelligibility measures suitable for use in developing hearing aid algorithms. Participants were supplied with listening test data compromising 7233 responses from 27 individuals. Data was split between training and test sets in a manner that fostered a machine learning approach and allowed both closed-set (known listeners) and open-set (unseen listener/unseen system) evaluation. The paper provides a description of the challenge design including the datasets, the hearing aid algorithms applied, the listeners and the perceptual tests. The challenge attracted submissions from 15 systems. The results are reviewed and the paper summarises, compares and contrasts approaches. Copyright © 2022 ISCA.",,Conference paper,Final,,Scopus,2-s2.0-85128551580
Opoku-Baah C.; Schoenhaut A.M.; Vassall S.G.; Tovar D.A.; Ramachandran R.; Wallace M.T.,"Opoku-Baah, Collins (57188873291); Schoenhaut, Adriana M. (57222523161); Vassall, Sarah G. (57223864816); Tovar, David A. (55831795600); Ramachandran, Ramnarayan (7101619578); Wallace, Mark T. (7401942866)",57188873291; 57222523161; 57223864816; 55831795600; 7101619578; 7401942866,"Visual Influences on Auditory Behavioral, Neural, and Perceptual Processes: A Review",2021,JARO - Journal of the Association for Research in Otolaryngology,22,4,,365,386,21,9,10.1007/s10162-021-00789-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106210947&doi=10.1007%2fs10162-021-00789-0&partnerID=40&md5=a6d9590b614a2a79931cb3f8431e7fc9,"In a naturalistic environment, auditory cues are often accompanied by information from other senses, which can be redundant with or complementary to the auditory information. Although the multisensory interactions derived from this combination of information and that shape auditory function are seen across all sensory modalities, our greatest body of knowledge to date centers on how vision influences audition. In this review, we attempt to capture the state of our understanding at this point in time regarding this topic. Following a general introduction, the review is divided into 5 sections. In the first section, we review the psychophysical evidence in humans regarding vision’s influence in audition, making the distinction between vision’s ability to enhance versus alter auditory performance and perception. Three examples are then described that serve to highlight vision’s ability to modulate auditory processes: spatial ventriloquism, cross-modal dynamic capture, and the McGurk effect. The final part of this section discusses models that have been built based on available psychophysical data and that seek to provide greater mechanistic insights into how vision can impact audition. The second section reviews the extant neuroimaging and far-field imaging work on this topic, with a strong emphasis on the roles of feedforward and feedback processes, on imaging insights into the causal nature of audiovisual interactions, and on the limitations of current imaging-based approaches. These limitations point to a greater need for machine-learning-based decoding approaches toward understanding how auditory representations are shaped by vision. The third section reviews the wealth of neuroanatomical and neurophysiological data from animal models that highlights audiovisual interactions at the neuronal and circuit level in both subcortical and cortical structures. It also speaks to the functional significance of audiovisual interactions for two critically important facets of auditory perception—scene analysis and communication. The fourth section presents current evidence for alterations in audiovisual processes in three clinical conditions: autism, schizophrenia, and sensorineural hearing loss. These changes in audiovisual interactions are postulated to have cascading effects on higher-order domains of dysfunction in these conditions. The final section highlights ongoing work seeking to leverage our knowledge of audiovisual interactions to develop better remediation approaches to these sensory-based disorders, founded in concepts of perceptual plasticity in which vision has been shown to have the capacity to facilitate auditory learning. © 2021, The Author(s).",34014416,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85106210947
Uhler K.; Hunter S.; Gilley P.M.,"Uhler, Kristin (37119580400); Hunter, Sharon (7201434918); Gilley, Phillip M. (6506605176)",37119580400; 7201434918; 6506605176,Mismatched response predicts behavioral speech discrimination outcomes in infants with hearing loss and normal hearing,2021,Infancy,26,2,,327,348,21,5,10.1111/infa.12386,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099969901&doi=10.1111%2finfa.12386&partnerID=40&md5=83b7c57a9e017b6083ba5fe6bbd4ffc1,"Children with hearing loss (HL) remain at risk for poorer language abilities than normal hearing (NH) children despite targeted interventions; reasons for these differences remain unclear. In NH children, research suggests speech discrimination is related to language outcomes, yet we know little about it in children with HL under the age of 2 years. We utilized a vowel contrast, /a-i/, and a consonant-vowel contrast, /ba-da/, to examine speech discrimination in 47 NH infants and 40 infants with HL. At Mean age =3 months, EEG recorded from 11 scalp electrodes was used to compute the time-frequency mismatched response (TF-MMRSE) to the contrasts; at Mean age =9 months, behavioral discrimination was assessed using a head turn task. A machine learning (ML) classifier was used to predict behavioral discrimination when given an arbitrary TF-MMRSE as input, achieving accuracies of 73% for exact classification and 92% for classification within a distance of one class. Linear fits revealed a robust relationship regardless of hearing status or speech contrast. TF-MMRSE responses in the delta (1–3.5 Hz), theta (3.5–8 Hz), and alpha (8–12 Hz) bands explained the most variance in behavioral task performance. Our findings demonstrate the feasibility of using TF-MMRSE to predict later behavioral speech discrimination. © 2021 The Authors. Infancy published by Wiley Periodicals LLC on behalf of International Congress of Infant Studies.",33481354,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85099969901
Cassandro E.; Manara R.; Ponticorvo S.; Brotto D.; Cappiello A.; Cuoco S.; Pellecchia M.T.; Cassandro C.; Cantone E.; Scarpa A.; Pfeuffer J.; Di Salle F.; Esposito F.,"Cassandro, Ettore (6603123006); Manara, Renzo (6603641806); Ponticorvo, Sara (57201745187); Brotto, Davide (56422384100); Cappiello, Arianna (57205670768); Cuoco, Sofia (56388633500); Pellecchia, Maria T. (7007039088); Cassandro, Claudia (22633886000); Cantone, Elena (26027709000); Scarpa, Alfonso (56844779000); Pfeuffer, Josef (57204984474); Di Salle, Francesco (7004206559); Esposito, Fabrizio (7102220908)",6603123006; 6603641806; 57201745187; 56422384100; 57205670768; 56388633500; 7007039088; 22633886000; 26027709000; 56844779000; 57204984474; 7004206559; 7102220908,Metabolic and functional correlates of age-related hearing loss: Advanced MRI findings and rehabilitation perspectives of the central auditory pathways,2021,Otorhinolaryngology(Italy),71,3,,125,133,8,0,10.23736/S2724-6302.21.02375-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117308051&doi=10.23736%2fS2724-6302.21.02375-6&partnerID=40&md5=43f798ea2ee85531e3ea469b6945a9d8,"BACKGROUND: Presbycusis is the hearing loss (HL) determined by aging mechanisms affecting the inner ear. Auditory cortical hypoperfusion has been shown in the early phases of presbycusis, suggesting a regionally selective metabolic vulnerability secondary to peripheral loss of function. In this study, HL patients were stratified according to the audiogram profiles to possibly enable a finer regional characterization of cortical perfusion changes within the primary auditory cortex. METHODS: Sixty-two HL patients (age range: 47-78 years, PTA <50dB) and thirty-two normal hearing (NH) subjects (age-range 48-78 years) were enrolled in a 3 Tesla MRI study. Two clusters of HL patients were identified, and labeled as low-loss-high-slope (LLHS) and high-losslow-slope (HLLS), according to the audiogram centro-types from an independent data set of fifty-five HL patients (age range: 45-80 years, PTA<50dB). Pseudo-continuous arterial spin labeling (ASL) and T1-weighted MRI were performed to derive cerebral blood flow (CBF) maps and to assess group-level perfusion changes within the primary auditory cortex. RESULT S: The comparison of CBF maps of all HL patients vs. NH controls confirmed a statistically significant CBF reduction in a compact region encompassing the right transverse temporal gyrus. The separate comparisons of LLHS and HLLS patients vs. NH subjects resulted in different localizations of the hypoperfusion region along the transverse temporal gyrus. CONCLUSIONS: Presbycusis is associated with perfusion reductions in the right primary auditory cortex with a different spatial pattern according to the audiogram profile. The observed heterogeneity of central auditory perfusion patterns may underlie different pathogenetic aspects and clinical forms of presbycusis.  © 2021 EDIZIONI MINERVA MEDICA.",,Article,Final,,Scopus,2-s2.0-85117308051
Rosengarth K.; Kleinjung T.; Langguth B.; Landgrebe M.; Lohaus F.; Greenlee M.W.; Hajak G.; Schmidt N.O.; Schecklmann M.,"Rosengarth, Katharina (24280085300); Kleinjung, Tobias (6602406673); Langguth, Berthold (6602352583); Landgrebe, Michael (23004653800); Lohaus, Fabian (57331278400); Greenlee, Mark W. (7004294169); Hajak, Göran (19835322300); Schmidt, Nils Ole (7101859771); Schecklmann, Martin (22935795700)",24280085300; 6602406673; 6602352583; 23004653800; 57331278400; 7004294169; 19835322300; 7101859771; 22935795700,Altered brain responses to emotional facial expressions in tinnitus patients,2021,Progress in Brain Research,262,,,189,207,18,2,10.1016/bs.pbr.2021.01.026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103377035&doi=10.1016%2fbs.pbr.2021.01.026&partnerID=40&md5=5f9fc835b752f23233631d01115e25d0,"Tinnitus, the phantom perception of sound, is a frequent disorder that can lead to severe distress and stress-related comorbidity. The pathophysiological mechanisms involved in the etiology of tinnitus are still under exploration. Electrophysiological and functional neuroimaging studies provide increasing evidence for abnormal functioning in auditory but also in non-auditory, e.g., emotional, brain areas. In order to elucidate alterations of affective processing in patients with chronic tinnitus, we used functional magnetic resonance imaging (fMRI) to measure neural responses to emotionally expressive and neutral faces. Twelve patients with chronic tinnitus and a group of 11 healthy controls, matched for age, sex, hearing loss and depressive symptoms were investigated. While viewing emotionally expressive faces compared to neutral faces brain activations in the tinnitus patients differed from those of the controls in a cluster that encompasses the amygdala, the hippocampus and the parahippocampal gyrus bilaterally. Whereas in controls affective faces induced higher brain activation in these regions than neutral faces, these regions in tinnitus patients were deactivated. Our results (1) provide evidence for alterations of affective processing of facial expressions in tinnitus patients indicating general domain-unspecific dysfunctions in emotion processing and (2) indicate the involvement of medial temporal areas in the pathophysiology of tinnitus. © 2021 Elsevier B.V.",33931179,Book chapter,Final,,Scopus,2-s2.0-85103377035
Mason H.G.; Noble J.H.,"Mason, Hannah G. (57740554900); Noble, Jack H. (22635393500)",57740554900; 22635393500,Automatic Internal Auditory Canal Segmentation Using a Weakly Supervised 3D U-Net,2022,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,12034,,120341X,,,,1,10.1117/12.2611897,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131959117&doi=10.1117%2f12.2611897&partnerID=40&md5=b944f5e56d4b53222db8e9af17180b2e,"Cochlear implants (CIs) are neural prosthetics used to improve hearing in patients with severe-to-profound hearing loss. After implantation, the process of fine-tuning the implant for a specific patient is expedited if the audiologist has tools to approximate which auditory nerve fiber regions are being stimulated by the implant's electrode array. Auditory nerves travel from the cochlea where the prosthetic is implanted to the brain via the internal auditory canal (IAC). In this paper, we present a method for segmenting the IAC in a CT image using weakly supervised 3D UNets. Our approach is to train a U-Net with a custom loss function to refine a localization provided by a previously proposed active-shape-model-based IAC segmentation method. Preliminary results indicate that our proposed approach is successful in refining IAC localization, which is an important step towards accurate auditory nerve fiber localization for neural activation modeling.  © 2022 SPIE.",,Conference paper,Final,,Scopus,2-s2.0-85131959117
McSweeny C.; Cushing S.L.; Campos J.L.; Papsin B.C.; Gordon K.A.,"McSweeny, Claire (57298135000); Cushing, Sharon L. (6603902938); Campos, Jennifer L. (7201617496); Papsin, Blake C. (7007086575); Gordon, Karen A. (56262823700)",57298135000; 6603902938; 7201617496; 7007086575; 56262823700,Functional Consequences of Poor Binaural Hearing in Development: Evidence From Children With Unilateral Hearing Loss and Children Receiving Bilateral Cochlear Implants,2021,Trends in Hearing,25,,,,,,13,10.1177/23312165211051215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117181433&doi=10.1177%2f23312165211051215&partnerID=40&md5=58134abac4baea4dd54bd27fd7ede213,"Poor binaural hearing in children was hypothesized to contribute to related cognitive and academic deficits. Children with unilateral hearing have normal hearing in one ear but no access to binaural cues. Their cognitive and academic deficits could be unique from children receiving bilateral cochlear implants (CIs) at young ages who have poor access to spectral cues and impaired binaural sensitivity. Both groups are at risk for vestibular/balance deficits which could further contribute to memory and learning challenges. Eighty-eight children (43 male:45 female, aged 9.89 ± 3.40 years), grouped by unilateral hearing loss (n = 20), bilateral CI (n = 32), and typically developing (n = 36), completed a battery of sensory, cognitive, and academic tests. Analyses revealed that children in both hearing loss groups had significantly poorer skills (accounting for age) on most tests than their normal hearing peers. Children with unilateral hearing loss had more asymmetric speech perception than children with bilateral CIs (p <.0001) but balance and language deficits (p =.0004, p <.0001, respectively) were similar in the two hearing loss groups (p >.05). Visuospatial memory deficits occurred in both hearing loss groups (p =.02) but more consistently across tests in children with unilateral hearing loss. Verbal memory was not significantly different than normal (p >.05). Principal component analyses revealed deficits in a main cluster of visuospatial memory, oral language, mathematics, and reading measures (explaining 46.8% data variability). The remaining components revealed clusters of self-reported hearing, balance and vestibular function, and speech perception deficits. The findings indicate significant developmental impacts of poor binaural hearing in children. © The Author(s) 2021.",34661482,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85117181433
Uhm T.; Lee J.E.; Yi S.; Choi S.W.; Oh S.J.; Kong S.K.; Lee I.W.; Lee H.M.,"Uhm, Taewoong (57205093500); Lee, Jae Eun (57221384379); Yi, Seongbaek (8160499000); Choi, Sung Won (55736595700); Oh, Se Joon (55948875500); Kong, Soo Keun (24831909300); Lee, Il Woo (56390540500); Lee, Hyun Min (57192204715)",57205093500; 57221384379; 8160499000; 55736595700; 55948875500; 24831909300; 56390540500; 57192204715,Predicting hearing recovery following treatment of idiopathic sudden sensorineural hearing loss with machine learning models,2021,American Journal of Otolaryngology - Head and Neck Medicine and Surgery,42,2,102858,,,,18,10.1016/j.amjoto.2020.102858,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098985673&doi=10.1016%2fj.amjoto.2020.102858&partnerID=40&md5=5da9bba2c21a53321bd05d6e274116e3,"Purpose: Idiopathic sudden sensorineural hearing loss (ISSHL) is an emergency otological disease, and its definite prognostic factors remain unclear. This study applied machine learning methods to develop a new ISSHL prognosis prediction model. Materials and methods: This retrospective study reviewed the medical data of 244 patients who underwent combined intratympanic and systemic steroid treatment for ISSHL at a tertiary referral center between January 2015 and October 2019. We used 35 variables to predict hearing recovery based on Siegel's criteria. In addition to performing an analysis based on the conventional logistic regression model, we developed prediction models with five machine learning methods: least absolute shrinkage and selection operator, decision tree, random forest (RF), support vector machine, and boosting. To compare the predictive ability of each model, the accuracy, precision, recall, F-score, and the area under the receiver operator characteristic curves (ROC-AUC) were calculated. Results: Former otological history, ear fullness, delay between symptom onset and treatment, delay between symptom onset and intratympanic steroid injection (ITSI), and initial hearing thresholds of the affected and unaffected ears differed significantly between the recovery and non-recovery groups. While the RF method (accuracy: 72.22%, ROC-AUC: 0.7445) achieved the highest predictive power, the other methods also featured relatively good predictive power. In the RF model, the following variables were identified to be important for hearing-recovery prediction: delay between symptom onset and ITSI or the initial treatment, initial hearing levels of the affected and non-affected ears, body mass index, and a previous history of hearing loss. Conclusions: The machine learning models predictive of hearing recovery following treatment for ISSHL showed superior predictive power relative to the conventional logistic regression method, potentially allowing for better patient treatment outcomes. © 2020 Elsevier Inc.",33445040,Article,Final,,Scopus,2-s2.0-85098985673
Ntlhakana L.; Nelson G.; Khoza-Shangase K.; Dorkin E.,"Ntlhakana, Liepollo (57200618674); Nelson, Gill (9332733600); Khoza-Shangase, Katijah (36005211600); Dorkin, Elton (57323672300)",57200618674; 9332733600; 36005211600; 57323672300,Occupational hearing loss for platinum miners in South Africa: A case study of data sharing practices and ethical challenges in the mining industry,2022,International Journal of Environmental Research and Public Health,19,1,1,,,,1,10.3390/ijerph19010001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121377009&doi=10.3390%2fijerph19010001&partnerID=40&md5=953515520fa7bf8cc3fbde9cdf88bddc,"Background: The relevant legislation ensures confidentiality and has paved the way for data handling and sharing. However, the industry remains uncertain regarding big data handling and sharing practices for improved healthcare delivery and medical research. Methods: A semi-qualitative cross-sectional study was used which entailed analysing miners’ personal health records from 2014 to 2018. Data were accessed from the audiometry medical surveillance database (n = 480), the hearing screening database (n = 24,321), and the occupational hygiene database (n = 15,769). Ethical principles were applied to demonstrate big data protection and sharing. Results: Some audiometry screening and occupational hygiene records were incomplete and/or inaccurate (N = 4675). The database containing medical disease and treatment records could not be accessed. Ethical challenges included a lack of clarity regarding permission rights when sharing big data, and no policy governing the divulgence of miners’ personal and medical records for research. Conclusion: This case study illustrates how research can be effectively, although not maliciously, obstructed by the strict protection of employee medical data. Clearly communicated company policies should be developed for the sharing of workers’ records in the mining industry to improve HCPs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",35010261,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85121377009
Wu Y.,"Wu, Yougui (7406895582)",7406895582,Nonparametric inference of the area under ROC curve under two-phase cluster sampling,2022,Journal of Biopharmaceutical Statistics,32,2,,346,355,9,2,10.1080/10543406.2021.2009501,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121697554&doi=10.1080%2f10543406.2021.2009501&partnerID=40&md5=01f31a9ab8a8530839ff254a18b242c8,"Nonparametric inference of the area under ROC curve (AUC) has been well developed either in the presence of verification bias or clustering. However, current nonparametric methods are not able to handle cases where both verification bias and clustering are present. Such a case arises when a two-phase study design is applied to a cohort of subjects (verification bias) where each subject might have multiple test results (clustering). In such cases, the inference of AUC must account for both verification bias and intra-cluster correlation. In the present paper, we propose an IPW AUC estimator that corrects for verification bias and derive a variance formula to account for intra-cluster correlations between disease status and test results. Results of a simulation study indicate that the method that assumes independence underestimates the true variance of the IPW AUC estimator in the presence of intra-cluster correlations. The proposed method, on the other hand, provides a consistent variance estimate for the IPW AUC estimator by appropriately accounting for correlations between true disease statuses and between test results. © 2021 Taylor & Francis Group, LLC.",34932424,Article,Final,,Scopus,2-s2.0-85121697554
Buck A.N.; Rosskothen-Kuhl N.; Schnupp J.W.,"Buck, Alexa N (57205646823); Rosskothen-Kuhl, Nicole (36125408700); Schnupp, Jan WH (14325987100)",57205646823; 36125408700; 14325987100,Sensitivity to interaural time differences in the inferior colliculus of cochlear implanted rats with or without hearing experience,2021,Hearing Research,408,,108305,,,,5,10.1016/j.heares.2021.108305,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111024498&doi=10.1016%2fj.heares.2021.108305&partnerID=40&md5=8bb1248b9406ae7093dc546f5c15f18b,"For deaf patients cochlear implants (CIs) can restore substantial amounts of functional hearing. However, binaural hearing, and in particular, the perception of interaural time differences (ITDs) with current CIs has been found to be notoriously poor, especially in the event of early hearing loss. One popular hypothesis for these deficits posits that a lack of early binaural experience may be a principal cause of poor ITD perception in pre-lingually deaf CI patients. This is supported by previous electrophysiological studies done in neonatally deafened, bilateral CI-stimulated animals showing reduced ITD sensitivity. However, we have recently demonstrated that neonatally deafened CI rats can quickly learn to discriminate microsecond ITDs under optimized stimulation conditions which suggests that the inability of human CI users to make use of ITDs is not due to lack of binaural hearing experience during development. In the study presented here, we characterized ITD sensitivity and tuning of inferior colliculus neurons under bilateral CI stimulation of neonatally deafened and hearing experienced rats. The hearing experienced rats were not deafened prior to implantation. Both cohorts were implanted bilaterally between postnatal days 64-77 and recorded immediately following surgery. Both groups showed comparably large proportions of ITD sensitive multi-units in the inferior colliculus (Deaf: 84.8%, Hearing: 82.5%), and the strength of ITD tuning, quantified as mutual information between response and stimulus ITD, was independent of hearing experience. However, the shapes of tuning curves differed substantially between both groups. We observed four main clusters of tuning curves – trough, contralateral, central, and ipsilateral tuning. Interestingly, over 90% of multi-units for hearing experienced rats showed predominantly contralateral tuning, whereas as many as 50% of multi-units in neonatally deafened rats were centrally tuned. However, when we computed neural d’ scores to predict likely limits on performance in sound lateralization tasks, we did not find that these differences in tuning shapes predicted worse psychoacoustic performance for the neonatally deafened animals. We conclude that, at least in rats, substantial amounts of highly precise, “innate” ITD sensitivity can be found even after profound hearing loss throughout infancy. However, ITD tuning curve shapes appear to be strongly influenced by auditory experience although substantial lateralization encoding is present even in its absence. © 2021",34315027,Article,Final,,Scopus,2-s2.0-85111024498
Wang Z.-T.; Supin A.Y.; Akamatsu T.; Duan P.-X.; Yang Y.-N.; Wang K.-X.; Wang D.,"Wang, Zhi-Tao (55340884900); Supin, Alexander Ya (35613914900); Akamatsu, Tomonari (7101930604); Duan, Peng-Xiang (57205722739); Yang, Yi-Ning (57215506116); Wang, Ke-Xiong (7501397792); Wang, Ding (54991518300)",55340884900; 35613914900; 7101930604; 57205722739; 57215506116; 7501397792; 54991518300,Auditory evoked potential in stranded melon-headed whales (Peponocephala electra): With severe hearing loss and possibly caused by anthropogenic noise pollution,2021,Ecotoxicology and Environmental Safety,228,,113047,,,,7,10.1016/j.ecoenv.2021.113047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120313565&doi=10.1016%2fj.ecoenv.2021.113047&partnerID=40&md5=62136fda75a4bd3394597a80cac464fa,"Highly concentrated live mass stranding events of dolphins and whales happened in the eastern coast of China between June and October 2021. The current study adopted the non-invasive auditory evoked-potential technique to investigate the hearing threshold of a stranded melon headed whale (Peponocephala electra) at a frequency range of between 9.5 and 181 kHz. It was found that, at the frequency range of from 10 to 100 kHz, hearing thresholds for the animal were between 20 and 65 dB higher than those of its phylogenetically closest species (Pygmy killer whale). The severe hearing loss in the melon headed whale was probably caused by transient intense anthropogenic sonar or chronic shipping noise exposures. The hearing loss could have been the cause for the observed temporal and spatial clustered stranding events. Therefore, there is need for noise mitigation strategies to reduce noise exposure levels for marine mammals in the coastal areas of China. © 2021 The Authors",34861441,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85120313565
Bussé A.M.L.; Mackey A.R.; Hoeve H.L.J.; Goedegebure A.; Carr G.; Uhlén I.M.; Simonsz H.J.,"Bussé, Andrea M. L. (57214685149); Mackey, Allison R. (25926602800); Hoeve, Hans L. J. (7003546700); Goedegebure, André (6507548477); Carr, Gwen (7101982382); Uhlén, Inger M. (22956690800); Simonsz, Huibert J. (35513772000)",57214685149; 25926602800; 7003546700; 6507548477; 7101982382; 22956690800; 35513772000,Assessment of hearing screening programmes across 47 countries or regions I: provision of newborn hearing screening,2021,International Journal of Audiology,60,11,,821,830,9,12,10.1080/14992027.2021.1886350,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102521420&doi=10.1080%2f14992027.2021.1886350&partnerID=40&md5=da2d7a8c24a14ce31bdaed0730e81983,"Objectives: Newborn hearing screening (NHS) varies regarding number and type of tests, location, age, professionals and funding. We compared the provision of existing screening programmes. Design: A questionnaire containing nine domains: demography, administration, existing screening, coverage, tests, diagnosis, treatment, cost and adverse effects, was presented to hearing screening experts. Responses were verified. Clusters were identified based on number of screening steps and use of OAE or aABR, either for all infants or for well and high-risk infants (dual-protocol). Study sample: Fifty-two experts completed the questionnaire sufficiently: 40 European countries, Russia, Malawi, Rwanda, India and China. Results: It took considerable effort to find experts for all countries with sufficient time and knowledge. Data essential for evaluation are often not collected. Infants are first screened in maternity wards in most countries. Human development index and health expenditure were high among countries with dual protocols, three screening steps, including aABR, and low among countries without NHS and countries using OAE for all infants. Nationwide implementation of NHS took 6 years, on average. Conclusion: The extent and complexity of NHS programmes are primarily related to health expenditure and HDI. Data collection should be improved to facilitate comparison of NHS programmes across borders. © 2021 The Authors. Published by Informa UK Limited, trading as Taylor & Francis Group on behalf of British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",33688794,Article,Final,,Scopus,2-s2.0-85102521420
Lei I.M.; Jiang C.; Lei C.L.; de Rijk S.R.; Tam Y.C.; Swords C.; Sutcliffe M.P.F.; Malliaras G.G.; Bance M.; Huang Y.Y.S.,"Lei, Iek Man (57203536143); Jiang, Chen (57217192164); Lei, Chon Lok (57199325592); de Rijk, Simone Rosalie (57190574810); Tam, Yu Chuen (55216032800); Swords, Chloe (55963863100); Sutcliffe, Michael P. F. (57224805292); Malliaras, George G. (57191283469); Bance, Manohar (7003525806); Huang, Yan Yan Shery (41461132500)",57203536143; 57217192164; 57199325592; 57190574810; 55216032800; 55963863100; 57224805292; 57191283469; 7003525806; 41461132500,3D printed biomimetic cochleae and machine learning co-modelling provides clinical informatics for cochlear implant patients,2021,Nature Communications,12,1,6260,,,,17,10.1038/s41467-021-26491-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118472042&doi=10.1038%2fs41467-021-26491-6&partnerID=40&md5=f39256e40c4579300452fcc23ee9eb0c,"Cochlear implants restore hearing in patients with severe to profound deafness by delivering electrical stimuli inside the cochlea. Understanding stimulus current spread, and how it correlates to patient-dependent factors, is hampered by the poor accessibility of the inner ear and by the lack of clinically-relevant in vitro, in vivo or in silico models. Here, we present 3D printing-neural network co-modelling for interpreting electric field imaging profiles of cochlear implant patients. With tuneable electro-anatomy, the 3D printed cochleae can replicate clinical scenarios of electric field imaging profiles at the off-stimuli positions. The co-modelling framework demonstrated autonomous and robust predictions of patient profiles or cochlear geometry, unfolded the electro-anatomical factors causing current spread, assisted on-demand printing for implant testing, and inferred patients’ in vivo cochlear tissue resistivity (estimated mean = 6.6 kΩcm). We anticipate our framework will facilitate physical modelling and digital twin innovations for neuromodulation implants. © 2021, The Author(s).",34716306,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85118472042
Kyong J.-S.; Suh M.-W.; Han J.J.; Park M.K.; Noh T.S.; Oh S.H.; Lee J.H.,"Kyong, Jeong-Sug (8645186900); Suh, Myung-Whan (7103253889); Han, Jae Joon (57190294778); Park, Moo Kyun (24559185500); Noh, Tae Soo (56801415400); Oh, Seung Ha (56582818600); Lee, Jun Ho (55882259900)",8645186900; 7103253889; 57190294778; 24559185500; 56801415400; 56582818600; 55882259900,Cross-modal cortical activity in the brain can predict cochlear implantation outcome in adults: A machine learning study,2021,Journal of International Advanced Otology,17,5,,380,386,6,1,10.5152/iao.2021.9337,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117218934&doi=10.5152%2fiao.2021.9337&partnerID=40&md5=80015d06eaa0b3140efbfebdf8c1c12e,"OBJECTIVES: Prediction of cochlear implantation (CI) outcome is often difficult because outcomes vary among patients. Though the brain plasticity across modalities during deafness is associated with individual CI outcomes, longitudinal observations in multiple patients are scarce. Therefore, we sought a prediction system based on cross-modal plasticity in a longitudinal study with multiple patients. METHODS: Classification of CI outcomes between excellent or poor was tested based on the features of brain cross-modal plasticity, measured using event-related responses and their corresponding electromagnetic sources. A machine learning estimation model was applied to 13 datas-ets from 3 patients based on linear supervised training. Classification efficiency was evaluated comparing prediction accuracy, sensitivity/speci-ficity, total mis-classification cost, and training time among feature set conditions. RESULTS: Combined feature sets with the sensor and source levels dramatically improved classification accuracy between excellent and poor outcomes. Specifically, the tactile feature set best explained CI outcome (accuracy, 98.83 ± 2.57%; sensitivity, 98.00 ± 0.01%; specificity, 98.15 ± 4.26%; total misclassification cost, 0.17 ± 0.38; training time, 0.51 ± 0.09 sec), followed by the visual feature (accuracy, 93.50 ± 4.89%; sensitivity, 89.17 ± 8.16%; specificity, 98.00 ± 0.01%; total misclassification cost, 0.65 ± 0.49; training time, 0.38 ± 0.50 sec). CONCLUSION: Individual tactile and visual processing in the brain best classified the current status when classified by combined sensor–source level features. Our results suggest that cross-modal brain plasticity due to deafness may provide a basis for classifying the status. We expect this novel method to contribute to the evaluation and prediction of CI outcomes. © 2021, AVES. All rights reserved.",34617886,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85117218934
Song P.; Guan Y.; Chen X.; Wu C.; Qiao A.; Jiang H.; Li Q.; Huang Y.; Huang W.; Xu M.; Niemtiah O.; Yuan C.; Li W.; Zhou L.; Xiao Z.; Pan S.; Hu Y.,"Song, Pingping (57195289047); Guan, Yuqing (35975913000); Chen, Xia (57219725839); Wu, Chaochen (57222227656); Qiao, An (57209105789); Jiang, Haishan (27172065800); Li, Qi (56155695400); Huang, Yingwei (57210207483); Huang, Wei (57195295168); Xu, Miaojing (57190584246); Niemtiah, Ouattara (57219722692); Yuan, Chao (57139345200); Li, Wei (58798896400); Zhou, Liang (57304775600); Xiao, Zhongju (7402447280); Pan, Suyue (55855560900); Hu, Yafang (9736556900)",57195289047; 35975913000; 57219725839; 57222227656; 57209105789; 27172065800; 56155695400; 57210207483; 57195295168; 57190584246; 57219722692; 57139345200; 58798896400; 57304775600; 7402447280; 55855560900; 9736556900,"Frameshift mutation of Timm8a1 gene in mouse leads to an abnormal mitochondrial structure in the brain, correlating with hearing and memory impairment",2021,Journal of Medical Genetics,58,9,e106925,619,627,8,10,10.1136/jmedgenet-2020-106925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094946649&doi=10.1136%2fjmedgenet-2020-106925&partnerID=40&md5=2b56a1b8a91069aa8426c05f40f0e58d,"Background Deafness-dystonia-optic neuronopathy (DDON) syndrome is a progressive X-linked recessive disorder characterised by deafness, dystonia, ataxia and reduced visual acuity. The causative gene deafness/dystonia protein 1 (DDP1)/translocase of the inner membrane 8A (TIMM8A) encodes a mitochondrial intermembrane space chaperon. The molecular mechanism of DDON remains unclear, and detailed information on animal models has not been reported yet. Methods and results We characterized a family with DDON syndrome, in which the affected members carried a novel hemizygous variation in the DDP1 gene (NM_004085.3, c.82C>T, p.Q28X). We then generated a mouse line with the hemizygous mutation (p.I23fs49X) in the Timm8a1 gene using the clustered regularly interspaced short palindromic repeats /Cas9 technology. The deficient DDP1 protein was confirmed by western blot assay. Electron microscopic analysis of brain samples from the mutant mice indicated abnormal mitochondrial structure in several brain areas. However, Timm8a1 I23fs49X/y mutation did not affect the import of mitochondria inner member protein Tim23 and outer member protein Tom40 as well as the biogenesis of the proteins in the mitochondrial oxidative phosphorylation system and the manganese superoxide dismutase (MnSOD / SOD-2). The male mice with Timm8a1 I23fs49X/y mutant exhibited less weight gain, hearing impairment and cognitive deficit. Conclusion Our study suggests that frameshift mutation of the Timm8a1 gene in mice leads to an abnormal mitochondrial structure in the brain, correlating with hearing and memory impairment. Taken together, we have successfully generated a mouse model bearing loss-of-function mutation in Timm8a1. © 2021 BMJ Publishing Group. All rights reserved.",32820032,Article,Final,,Scopus,2-s2.0-85094946649
Shekar R.C.M.C.; Belitz C.; Hansen J.H.L.,"Shekar, Ram C.M.C (57221520194); Belitz, Chelzy (57211639140); Hansen, John H.L. (7404334144)",57221520194; 57211639140; 7404334144,Development of CNN-Based Cochlear Implant and Normal Hearing Sound Recognition Models Using Natural and Auralized Environmental Audio,2021,"2021 IEEE Spoken Language Technology Workshop, SLT 2021 - Proceedings",,,9383550,728,733,5,3,10.1109/SLT48900.2021.9383550,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103952046&doi=10.1109%2fSLT48900.2021.9383550&partnerID=40&md5=1fe503c9b036557581e60d64a19d63da,"Restoration of auditory function among hearing impaired individuals using Cochlear Implant (CI) technology has contributed significantly towards an improved quality of life. CI users experience greater challenges in recognizing speech effectively in noisy, reverberant, or time-varying diverse environments. Most CI research efforts focus on enhancing speech perception and environmental sound awareness has received little or no attention. This study focuses on a comparative analysis of normal hearing (NH) vs. CI environmental sound recognition using classifiers trained on learned sound representations using a CNN-based sound event model. Sounds experienced by CI listeners are recreated by auralizing electrical stimuli. CCi-MOBILE is used to generate electrical stimuli and Braecker Vocoder is used for auralization. Natural and auralized sound representations are then applied in order to develop NH and CI sound recognition models. Comparative assessment of environmental sound recognition is carried out by analyzing f1-scores and other performance characteristics. Benefits stemming from this research can help CI researchers improve sound recognition performance, develop novel sound processing algorithms, exclusively for environmental sounds, and identify optimal CI electrical stimulation characteristics to enhance sound perception. Among CI users, improvement in environmental sound awareness contributes to improved quality of life. © 2021 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85103952046
Rim H.-S.; Kim M.-G.; Park D.-C.; Kim S.-S.; Kang D.-W.; Kim S.-H.; Yeo S.-G.,"Rim, Hwa-Sung (57302251700); Kim, Myung-Gu (7406090034); Park, Dong-Choon (56603513700); Kim, Sung-Soo (57206875837); Kang, Dae-Woong (57207742088); Kim, Sang-Hoon (57761664600); Yeo, Seung-Geun (55572248100)",57302251700; 7406090034; 56603513700; 57206875837; 57207742088; 57761664600; 55572248100,Association of metabolic syndrome with sensorineural hearing loss,2021,Journal of Clinical Medicine,10,21,4866,,,,10,10.3390/jcm10214866,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117464041&doi=10.3390%2fjcm10214866&partnerID=40&md5=6d17c28e93b8341d11ac5a60844e696c,"The prevalence of sensorineural hearing loss has increased along with increases in life expectancy and exposure to noisy environments. Metabolic syndrome (MetS) is a cluster of co-occurring conditions that increase the risk of heart disease, stroke and type 2 diabetes, along with other conditions that affect the blood vessels. Components of MetS include insulin resistance, body weight, lipid concentration, blood pressure, and blood glucose concentration, as well as other features of insulin resistance such as microalbuminuria. MetS has become a major public health problem affecting 20–30% of the global population. This study utilized health examination to investigate whether metabolic syndrome was related to hearing loss. Methods: A total of 94,223 people who underwent health check-ups, including hearing tests, from January 2010 to December 2020 were evaluated. Subjects were divided into two groups, with and without metabolic syndrome. In addition, Scopus, Embase, PubMed, and Cochrane libraries were systematically searched, using keywords such as “hearing loss” and “metabolic syndrome”, for studies that evaluated the relationship between the two. Results: Of the 94,223 subjects, 11,414 (12.1%) had metabolic syndrome and 82,809 did not. The mean ages of subjects in the two groups were 46.1 and 43.9 years, respectively. A comparison of hearing thresholds by age in subjects with and without metabolic syndrome showed that the average pure tone hearing thresholds were significantly higher in subjects with metabolic syndrome than in subjects without it in all age groups. (p < 0.001) Rates of hearing loss in subjects with 0, 1, 2, 3, 4, and 5 of the components of metabolic syndrome were 7.9%, 12.1%, 13.8%, 13.8%, 15.5% and 16.3%, respectively, indicating a significant association between the number of components of metabolic syndrome and the rate of hearing loss (p < 0.0001). The odds ratio of hearing loss was significantly higher in subjects with four components of metabolic syndrome: waist circumference, blood pressure, and triglyceride and fasting blood sugar concentrations (p < 0.0001). (4) Conclusions: The number of components of the metabolic syndrome is positively correlated with the rate of sensorineural hearing loss. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85117464041
Santacruz J.L.; de Kleine E.; van Dijk P.,"Santacruz, Jose L. (57207573014); de Kleine, Emile (6602869559); van Dijk, Pim (57206129856)",57207573014; 6602869559; 57206129856,Investigating the relation between minimum masking levels and hearing thresholds for tinnitus subtyping,2021,Progress in Brain Research,263,,,81,94,13,3,10.1016/bs.pbr.2021.04.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106621473&doi=10.1016%2fbs.pbr.2021.04.011&partnerID=40&md5=3b467acbf02163a6b490b5f4f4d15067,"Heterogeneity of tinnitus imposes a challenge for its treatment. Identifying tinnitus subtypes might help to establish individualized diagnosis and therapies. The minimum masking level (MML) is a clinical tool defined as the minimum intensity of a masking sound required to cover tinnitus. Understanding the differences among masking patterns in patients could facilitate the task of subtyping tinnitus. Here, we studied the variability of hearing thresholds and MMLs among patients with tinnitus to identify tinnitus subgroups. A population of 366 consecutive patients from a specialized tinnitus clinic were included in the analysis. Hearing thresholds and MMLs were determined for octave frequencies from 0.25 to 8 kHz, as well as for 3 and 6 kHz. Subjects were divided into two groups according to whether their tinnitus was maskable (M, 329 subjects) or non-maskable (NM, 37 subjects). Hearing thresholds and tinnitus loudness did not differ significantly between both groups. The dimensionality of the data was reduced by means of principal component analysis (PCA), and the largest resulting components were used for clustering the data. The cluster analysis resulted in five clusters with differences in tinnitus pitch, lateralization, hearing thresholds and MML, as well as on age and gender. Clusters differed in contours of hearing thresholds and MML, describing patterns of low or high thresholds in combination with low or high MML. The clustering solution presented a low silhouette value (0.45), implying that the clustering is weak and could be artificial. The analysis pointed out the diversity across tinnitus patients. Our results suggest that there might be a continuum of patients' characteristics rather than discrete subgroups. © 2021 Elsevier B.V.",34243892,Book chapter,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85106621473
Cox M.; de Vries B.,"Cox, Marco (56028823900); de Vries, Bert (57211989726)",56028823900; 57211989726,Bayesian Pure-Tone Audiometry Through Active Learning Under Informed Priors,2021,Frontiers in Digital Health,3,,723348,,,,3,10.3389/fdgth.2021.723348,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131255202&doi=10.3389%2ffdgth.2021.723348&partnerID=40&md5=ec945bb57d6cae8129a072301dc2956f,"Pure-tone audiometry—the process of estimating a person's hearing threshold from “audible” and “inaudible” responses to tones of varying frequency and intensity—is the basis for diagnosing and quantifying hearing loss. By taking a probabilistic modeling approach, both optimal tone selection (in terms of expected information gain) and hearing threshold estimation can be derived through Bayesian inference methods. The performance of probabilistic model-based audiometry methods is directly linked to the quality of the underlying model. In recent years, Gaussian process (GP) models have been shown to provide good results in this context. We present methods to improve the efficiency of GP-based audiometry procedures by improving the underlying model. Instead of a single GP, we propose to use a GP mixture model that can be conditioned on side-information about the subject. The underlying idea is that one can typically distinguish between different types of hearing thresholds, enabling a mixture model to better capture the statistical properties of hearing thresholds among a population. Instead of modeling all hearing thresholds by a single GP, a mixture model allows specific types of hearing thresholds to be modeled by independent GP models. Moreover, the mixing coefficients can be conditioned on side-information such as age and gender, capturing the correlations between age, gender, and hearing threshold. We show how a GP mixture model can be optimized for a specific target population by learning the parameters from a data set containing annotated audiograms. We also derive an optimal tone selection method based on greedy information gain maximization, as well as hearing threshold estimation through Bayesian inference. The proposed models are fitted to a data set containing roughly 176 thousand annotated audiograms collected in the Nordic countries. We compare the predictive accuracies of optimized mixture models of varying sizes with that of an optimized single-GP model. The usefulness of the optimized models is tested in audiometry simulations. Simulation results indicate that an optimized GP mixture model can significantly outperform an optimized single-GP model in terms of predictive accuracy, and leads to significant increases the efficiency of the resulting Bayesian audiometry procedure. © Copyright © 2021 Cox and de Vries.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85131255202
Huckvale M.; Hilkhuysen G.,"Huckvale, Mark (6603430483); Hilkhuysen, Gaston (6508182495)",6603430483; 6508182495,ELO-SPHERES intelligibility prediction model for the Clarity Prediction Challenge 2022,2022,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2022-September,,,3934,3938,4,1,10.21437/Interspeech.2022-10521,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140088307&doi=10.21437%2fInterspeech.2022-10521&partnerID=40&md5=21afcab694acf35b2eef048513910865,"This paper describes and evaluates the ELO-SPHERES project sentence intelligibility model for the Clarity Prediction Challenge 2022. The aim of the model is to make predictions of the intelligibility of enhanced speech to hearing impaired listeners. Input to the model are binaural processed audio of short sentences generated in a simulated noisy and reverberant environment together with the original source audio. Output of the model is a prediction of the intelligibility of each sentence in terms of percentage words correct for a known hearing-impaired listener characterized by a pure-tone audiogram. Models are evaluated in terms of the root mean squared error of prediction. We approached this problem in three stages: (i) evaluation of the influences of the scene metadata on scores, (ii) construction of classifiers for estimation of scene metadata from audio, and (iii) training a non-linear regression model on the challenge data and evaluation using 5-fold cross validation. On the test data, a baseline system using only the standard short-time objective intelligibility metric on the better ear achieved a RMS prediction error of 27%, while our model that also took into account given and estimated scene data achieved an RMS error of 22%. Copyright © 2022 ISCA.",,Conference paper,Final,,Scopus,2-s2.0-85140088307
Jiang Z.; Fa B.; Zhang X.; Wang J.; Feng Y.; Shi H.; Zhang Y.; Sun D.; Wang H.; Yin S.,"Jiang, Zhuang (57219895699); Fa, Botao (56574329400); Zhang, Xunmiao (57225187957); Wang, Jiping (56464659400); Feng, Yanmei (15924998600); Shi, Haibo (55448175000); Zhang, Yue (57201032367); Sun, Daoyuan (48862045000); Wang, Hui (55361359300); Yin, Shankai (57203371062)",57219895699; 56574329400; 57225187957; 56464659400; 15924998600; 55448175000; 57201032367; 48862045000; 55361359300; 57203371062,Identifying genetic risk variants associated with noise-induced hearing loss based on a novel strategy for evaluating individual susceptibility,2021,Hearing Research,407,,108281,,,,5,10.1016/j.heares.2021.108281,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109364112&doi=10.1016%2fj.heares.2021.108281&partnerID=40&md5=6d7af3585b1846a8925f6848db3039a5,"Background: The overall genetic profile for noise-induced hearing loss (NIHL) remains elusive. Herein we proposed a novel machine learning (ML) based strategy to evaluate individual susceptibility to NIHL and identify the underlying genetic risk variants based on a subsample of participants with extreme phenotypes. Methods: Five features (age, sex, cumulative noise exposure [CNE], smoking, and alcohol drinking status) of 5,539 shipbuilding workers from large cross-sectional surveys were included in four ML classification models to predict their hearing levels. The area under the curve (AUC) and prediction accuracy were exploited to evaluate the performance of the models. Based on the prediction error of the ML models, the NIHL-susceptible group (n=150) and NIHL-resistant group (n=150) with a paradoxical relationship between hearing levels and features were separately screened, to identify the underlying variants associated with NIHL risk using whole-exome sequencing (WES). Subsequently, candidate risk variants were validated in an additional replication cohort (n=2108), followed by a meta-analysis. Results: With 10-fold cross-validation, the performances of the four ML models were robust and similar, with average AUCs and accuracies ranging from 0.783 to 0.798 and 73.7% to 73.8%, respectively. The phenotypes of the NIHL-susceptible and NIHL-resistant groups were significantly different (all p<0.001). After WES analysis and filtering, 12 risk variants contributing to NIHL susceptibility were identified and replicated. The meta-analyses showed that the A allele of CDH23 rs41281334 (odds ratio [OR]=1.506, 95% confidence interval [CI]=1.106-2.051) and the C allele of WHRN rs12339210 (OR=3.06, 95% CI=1.398-6.700) were significantly associated with increased risk of NIHL after adjustment for confounding factors. Conclusions: This study revealed two genetic variants in CDH23 rs41281334 and WHRN rs12339210 that associated with NIHL risk, based on a promising approach for evaluating individual susceptibility using ML models. © 2021",34157653,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85109364112
Correia F.; Medeiros A.B.; Castelhano L.; Cavilhas P.; Escada P.,"Correia, Filipe (57209248043); Medeiros, Ana Beatriz (57219380793); Castelhano, Luís (57202010930); Cavilhas, Pedro (57189489584); Escada, Pedro (6602601084)",57209248043; 57219380793; 57202010930; 57189489584; 6602601084,Personality and psychopathology in Ménière's disease; [Personalidad y psicopatología en la enfermedad de Ménière],2021,Acta Otorrinolaringologica Espanola,72,6,,344,351,7,3,10.1016/j.otorri.2020.06.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092542100&doi=10.1016%2fj.otorri.2020.06.007&partnerID=40&md5=b07fc2b5e712c2c0298595f19a75f4fe,"Introduction and Objectives: Psychological factors in vertigo patients have been extensively studied but the role of anxiety and personality traits in the clinical course of Ménière's disease (MD) is unknown. The objectives of this study are to identify and characterize psychopathology in MD and to find risk factors for an increased rate and intensity of crisis and chronic symptoms. Materials and Methods: We performed a transversal study in all patients diagnosed with definite MD in our department during a 5-year period. Sample subjects were interviewed in 3 steps: first, an otorhinolaryngologist collected information about clinical and pharmacological background of MD; second, a psychiatrist screened for mood, anxiety and personality disorders; in a third stage, the patient completed the DHI (Dizziness Handicap Inventory), STAI-Y (State Trait Anxiety Inventory), NEO-PI-R (Neo Personality Inventory Reviewed) and VAS (Visual Analogue Scale) for vertigo and dizziness. Statistical analysis was performed to search for risk factors for multiple and intense crisis and chronic symptoms. Results: Thirty-four patients completed all 3 phases of the study. A predominant dysfunctional personality trait was identified in 80% of patients (predominantly cluster C type), 35% were being treated with psychiatric medication and 34.4% had a considerable mood or anxiety disorder. All patients scored high (>7) in VAS during crisis. There was a statistically significant positive correlation between crisis rate and STAI, anxiety-subscale (N1) in NEO-PI-R, VAS and DHI scores (p<.044). Crises were more common in bilateral MD (p=.041). DHI scores were higher with higher STAI and N1 (p=.001). Disease duration and pure tone average were found to have a positive moderate correlation (p=.017). Conclusions: The positive correlations between crisis rate, chronic dizziness and anxiety-related personality traits reveal a bidirectional and intimate relationship between personality, anxiety and MD, affecting these patients’ quality of life. These results support the relevance of prospecting adjuvant psychological and psychiatric approaches to these patients. © 2020 Sociedad Española de Otorrinolaringología y Cirugía de Cabeza y Cuello",33059851,Article,Final,,Scopus,2-s2.0-85092542100
Marsh O.; Freeman J.; Pollard D.; De Risio L.,"Marsh, O. (57217658897); Freeman, J. (55472396800); Pollard, D. (57194702949); De Risio, L. (57154430100)",57217658897; 55472396800; 57194702949; 57154430100,Congenital sensorineural deafness in Australian Cattle dogs in the UK: Prevalence and association with phenotype,2021,Veterinary Journal,274,,105711,,,,3,10.1016/j.tvjl.2021.105711,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110241528&doi=10.1016%2fj.tvjl.2021.105711&partnerID=40&md5=c0016b25e4a9cd1c983ba1181791f958,"The Australian Cattle dog (ACD) is one of many breeds predisposed to congenital sensorineural deafness (CSD). The objective of this study was to estimate CSD prevalence and investigate any association with phenotype in the ACD in the UK. The database of the authors’ institution was searched for ACD puppies undergoing brainstem auditory evoked response (BAER) testing for CSD screening (1999–2019). Inclusion criteria were BAER performed at 4–10 weeks of age, testing of complete litters and available phenotypic data. The age, sex, coat and iris colour, presence and location of face and body patches, hearing status and BAER- determined parental hearing status of each puppy were recorded. A multivariable mixed-effects logistic regression model was used to calculate odds ratios and 95% confidence intervals to determine whether any of these variables were significantly associated with CSD, while adjusting for clustering at litter level. Inclusion criteria were met for 524 puppies. Hearing was bilaterally normal in 464 puppies (88.6%). The prevalence of unilateral and bilateral CSD was 9.7% and 1.7%, respectively. On the basis of multivariable analysis, the presence of a pigmented face patch was the only phenotypic variable significantly associated with CSD, and was linked to a reduced risk of the condition. The prevalence was similar to that reported in an Australian population of ACDs. The key findings from this study were that overall CSD prevalence in the ACD population in the UK was 11.4%, and puppies with a face patch were at reduced risk of the condition. © 2021 Elsevier Ltd",34182072,Article,Final,,Scopus,2-s2.0-85110241528
Waoo A.A.; Soni B.K.,"Waoo, Akhilesh A. (55220071000); Soni, Brijesh K. (57984092200)",55220071000; 57984092200,Recurrent neural network model for identifying neurological auditory disorder,2022,Artificial Intelligence for Neurological Disorders,,,,77,89,12,1,10.1016/B978-0-323-90277-9.00103-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142820773&doi=10.1016%2fB978-0-323-90277-9.00103-6&partnerID=40&md5=f2c8eae2d7d2241a5721af8c24a95e80,"This chapter discusses neurological disorders related to the auditory cortex of the human brain. For example, cortical deafness might be considered a neurological disorder. Sometimes cortical deafness occurs due to a major stroke or injury in the cortical tissues around the temporal lobe. Patients with these types of cortical disorders may not be able to perceive or understand acoustic stimuli. Speech recognition is a sub-domain of natural language processing and machine learning (ML) that enables recognition and understanding of acoustic information in machines parallel to the human auditory cortex. This type of artificial acoustic information processing is possible with the help of a recurrent neural network (RNN), which is one of the main pillars of deep learning (DL). An RNN predicts the frequency and pattern of sound waves by the technique of backpropagation, which is a fundamental phenomenon of recurrences in the detailed architecture of a well-defined RNN. In this chapter, we identify cortical processing ambiguities due to neurological disorders. An RNN can efficiently learn various temporal as well as spatial relationships of speech by using mechanisms such as gated recurrent units (GRUs) and long short-term memory (LSTM) with sequence controlling. This is only possible by using the advanced techniques of sound and speech recognition that are fully adopted by RNNs in the broad domain of cognitive auditory information processing and natural language processing such as audio segmentation, phonetic recognition, attention mechanism, and so on. © 2023 Elsevier Inc. All rights reserved.",,Book chapter,Final,,Scopus,2-s2.0-85142820773
Polo E.M.; Zanet M.; Lenatti M.; van Waterschoot T.; Barbieri R.; Paglialonga A.,"Polo, Edoardo Maria (57213605525); Zanet, Marco (57213610020); Lenatti, Marta (57222472784); van Waterschoot, Toon (16040861800); Barbieri, Riccardo (35483096800); Paglialonga, Alessia (23668671800)",57213605525; 57213610020; 57222472784; 16040861800; 35483096800; 23668671800,Development and Evaluation of a Novel Method for Adult Hearing Screening: Towards a Dedicated Smartphone App,2021,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",360,,,3,19,16,3,10.1007/978-3-030-69963-5_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102772915&doi=10.1007%2f978-3-030-69963-5_1&partnerID=40&md5=95aa5d1b442ded396fb506f47c5575e1,"Towards implementation of adult hearing screening tests that can be delivered via a mobile app, we have recently designed a novel speech-in-noise test based on the following requirements: user-operated, fast, reliable, accurate, viable for use by listeners of unknown native language and viable for testing at a distance. This study addresses specific models to (i) investigate the ability of the test to identify ears with mild hearing loss using machine learning; and (ii) address the range of the output levels generated using different transducers. Our results demonstrate that the test classification performance using decision tree models is in line with the performance of validated, language-dependent speech-in-noise tests. We observed, on average, 0.75 accuracy, 0.64 sensitivity and 0.81 specificity. Regarding the analysis of output levels, we demonstrated substantial variability of transducers’ characteristics and dynamic range, with headphones yielding higher output levels compared to earphones. These findings confirm the importance of a self-adjusted volume option. These results also suggest that earphones may not be suitable for test execution as the output levels may be relatively low, particularly for subjects with hearing loss or for those who skip the volume adjustment step. Further research is needed to fully address test performance, e.g. testing a larger sample of subjects, addressing different classification approaches, and characterizing test reliability in varying conditions using different devices and transducers. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85102772915
Liu Q.; Li N.; Yang Y.; Yan X.; Dong Y.; Peng Y.; Shi J.,"Liu, Qing (57282896100); Li, Ning (58622679700); Yang, Yifang (57367317900); Yan, Xirui (57367942200); Dong, Yang (36652655900); Peng, Yinting (15045248700); Shi, Jianrong (55337135800)",57282896100; 58622679700; 57367317900; 57367942200; 36652655900; 15045248700; 55337135800,Prediction of the Molecular Mechanisms Underlying Erlong Zuoci Treatment of Age-Related Hearing Loss via Network Pharmacology-Based Analyses Combined with Experimental Validation,2021,Frontiers in Pharmacology,12,,719267,,,,4,10.3389/fphar.2021.719267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120854221&doi=10.3389%2ffphar.2021.719267&partnerID=40&md5=9e400a8ba94e43e7cd31295f69d63240,"Background: The traditional Chinese medicine formula ErLong ZuoCi (ELZC) has been extensively used to treat age-related hearing loss (ARHL) in clinical practice in China for centuries. However, the underlying molecular mechanisms are still poorly understood. Objective: Combine network pharmacology with experimental validation to explore the potential molecular mechanisms underlying ELZC with a systematic viewpoint. Methods: The chemical components of ELZC were collected from the Traditional Chinese Medicine System Pharmacology database, and their possible target proteins were predicted using the SwissTargetPrediction database. The putative ARHL-related target proteins were identified from the database: GeneCards and OMIM. We constructed the drug-target network as well as drug-disease specific protein-protein interaction networks and performed clustering and topological property analyses. Functional annotation and signaling pathways were performed by gene ontology and Kyoto Encyclopedia of Genes and Genomes enrichment analysis. Finally, in vitro experiments were also performed to validate ELZC’s key target proteins and treatment effects on ARHL. Results: In total, 63 chemical compounds from ELZC and 365 putative ARHL-related targets were identified, and 1860 ARHL-related targets were collected from the OMIM and GeneCards. A total of 145 shared targets of ELZC and ARHL were acquired by Venn diagram analysis. Functional enrichment analysis suggested that ELZC might exert its pharmacological effects in multiple biological processes, such as cell proliferation, apoptosis, inflammatory response, and synaptic connections, and the potential targets might be associated with AKT, ERK, and STAT3, as well as other proteins. In vitro experiments revealed that ELZC pretreatment could decrease senescence-associated β-galactosidase activity in hydrogen peroxide-induced auditory hair cells, eliminate DNA damage, and reduce cellular senescence protein p21 and p53. Finally, Western blot analysis confirmed that ELZC could upregulate the predicted target ERK phosphorylation. Conclusion: We provide an integrative network pharmacology approach, in combination with in vitro experiments to explore the underlying molecular mechanisms governing ELZC treatment of ARHL. The protective effects of ELZC against ARHL were predicted to be associated with cellular senescence, inflammatory response, and synaptic connections which might be linked to various pathways such as JNK/STAT3 and ERK cascade signaling pathways. As a prosperous possibility, our experimental data suggest phosphorylation ERK is essential for ELZC to prevent degeneration of cochlear. Copyright © 2021 Liu, Li, Yang, Yan, Dong, Peng and Shi.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85120854221
Pollastri F.; Pecci R.; Pellegrini E.; Vannucchi P.; Taverna C.; Giannoni B.,"Pollastri, Federica (57219223243); Pecci, Rudi (37665711100); Pellegrini, Elisa (57213711091); Vannucchi, Paolo (8416371500); Taverna, Cecilia (57193259907); Giannoni, Beatrice (6506636759)",57219223243; 37665711100; 57213711091; 8416371500; 57193259907; 6506636759,Late onset middle ear neuroendocrine tumor presenting with distant metastasis,2021,Otolaryngology Case Reports,19,,100289,,,,0,10.1016/j.xocr.2021.100289,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103139942&doi=10.1016%2fj.xocr.2021.100289&partnerID=40&md5=cff95ab60e63bda994f70041642d3c5f,"Tumors of the ear with neuroendocrine features are a very rare group of neoplasms, with neuroendocrine adenoma representing the more frequent entity found; the prevalence of middle ear neuroendocrine tumors is so low that it has never been determined exactly. Herein we describe the case of a 74 years old woman who presented a pure moderately differentiated middle ear neuroendocrine tumor after a long history of adhesive otitis media. Patient abruptly developed otalgia and a sense of plugged ear. Otomicroscopy revealed a polypoid mass of the external auditory canal. On histopathologic exam a neoplastic proliferation of monomorphous epithelioid cells arranged in small nests and clusters was present, being positive to cytokeratins, chromogranin, synaptophysin and CD56, and negative to S100. Ki-67 proliferation index was 20%. The lesion was diagnosed as a moderately differentiated neuroendocrine tumor (NET grade 2). CT and PET scans highlighted the concurrent presence of locoregional lymph nodes involvement but also at distance liver metastases. The patient underwent chemotherapy and liver repetitions were treated locally. At the time of the writing the patient is in good general condition. We describe an exceeding rare case of a moderately differentiated neuroendocrine tumor with primitivity in the middle ear and concurrent distant metastasis at the time of the diagnosis. This case represents a clinical and histological challenge, for the rarity of the lesion and the aspecific symptoms of the patient. © 2021",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85103139942
Li J.; Liu C.; Zhao B.,"Li, Jinan (56380663800); Liu, Chang (57204292122); Zhao, Bo (55520451000)",56380663800; 57204292122; 55520451000,N-Terminus of GRXCR2 Interacts With CLIC5 and Is Essential for Auditory Perception,2021,Frontiers in Cell and Developmental Biology,9,,671364,,,,9,10.3389/fcell.2021.671364,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105991281&doi=10.3389%2ffcell.2021.671364&partnerID=40&md5=f632fe175218c6156a70221ecb366502,"Stereocilia of cochlear hair cells are specialized mechanosensing organelles that convert sound-induced vibration to electrical signals. Glutaredoxin domain-containing cysteine-rich protein 2 (GRXCR2) is localized at the base of stereocilia and is necessary for stereocilia morphogenesis and auditory perception. However, the detailed functions of GRXCR2 in hair cells are still largely unknown. Here, we report that GRXCR2 interacts with chloride intracellular channel protein 5 (CLIC5) which is also localized at the base of stereocilia and required for normal hearing in human and mouse. Immunolocalization analyses suggest that GRXCR2 is not required for the localization of CLIC5 to the stereociliary base during development, or vice versa. Using clustered regularly interspaced short palindromic repeats (CRISPR)/Cas9 system, we deleted 60 amino acids near the N-terminus of GRXCR2 essential for its interaction with CLIC5. Interestingly, mice harboring this in-frame deletion in Grxcr2 exhibit moderate hearing loss at lower frequencies and severe hearing loss at higher frequencies although the morphogenesis of stereocilia is minimally affected. Thus, our findings reveal that the interaction between GRXCR2 and CLIC5 is crucial for normal hearing. © Copyright © 2021 Li, Liu and Zhao.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85105991281
Abu Bakar A.R.; Lai K.W.; Hamzaid N.A.,"Abu Bakar, Abdul Rauf (57270787800); Lai, Khin Wee (57194066657); Hamzaid, Nur Azah (9243249400)",57270787800; 57194066657; 9243249400,The emergence of machine learning in auditory neural impairment: A systematic review,2021,Neuroscience Letters,765,,136250,,,,3,10.1016/j.neulet.2021.136250,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115615660&doi=10.1016%2fj.neulet.2021.136250&partnerID=40&md5=44cc76ea8f7ec4ea05058ccc2788b92a,"Hearing loss is a common neurodegenerative disease that can start at any stage of life. Misalignment of the auditory neural impairment may impose challenges in processing incoming auditory stimulus that can be measured using electroencephalography (EEG). The electrophysiological behaviour response emanated from EEG auditory evoked potential (AEP) requires highly trained professionals for analysis and interpretation. Reliable automated methods using techniques of machine learning would assist the auditory assessment process for informed treatment and practice. It is thus highly required to develop models that are more efficient and precise by considering the characteristics of brain signals. This study aims to provide a comprehensive review of several state-of-the-art techniques of machine learning that adopt EEG evoked response for the auditory assessment within the last 13 years. Out of 161 initially screened articles, 11 were retained for synthesis. The outcome of the review presented that the Support Vector Machine (SVM) classifier outperformed with over 80% accuracy metric and was recognized as the best suited model within the field of auditory research. This paper discussed the comprehensive iterative properties of the proposed computed algorithms and the feasible future direction in hearing impaired rehabilitation. © 2021 Elsevier B.V.",34536511,Review,Final,,Scopus,2-s2.0-85115615660
Peineau T.; Belleudy S.; Pietropaolo S.; Bouleau Y.; Dulon D.,"Peineau, Thibault (57210906228); Belleudy, Séverin (57208685066); Pietropaolo, Susanna (36898132300); Bouleau, Yohan (7801686785); Dulon, Didier (7003805088)",57210906228; 57208685066; 36898132300; 7801686785; 7003805088,Synaptic Release Potentiation at Aging Auditory Ribbon Synapses,2021,Frontiers in Aging Neuroscience,13,,756449,,,,18,10.3389/fnagi.2021.756449,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118337551&doi=10.3389%2ffnagi.2021.756449&partnerID=40&md5=ff46774dd4f1077b0cfaa86951ea0d1b,"Age-related hidden hearing loss is often described as a cochlear synaptopathy that results from a progressive degeneration of the inner hair cell (IHC) ribbon synapses. The functional changes occurring at these synapses during aging are not fully understood. Here, we characterized this aging process in IHCs of C57BL/6J mice, a strain which is known to carry a cadherin-23 mutation and experiences early hearing loss with age. These mice, while displaying a large increase in auditory brainstem thresholds due to 50% loss of IHC synaptic ribbons at middle age (postnatal day 365), paradoxically showed enhanced acoustic startle reflex suggesting a hyperacusis-like response. The auditory defect was associated with a large shrinkage of the IHCs' cell body and a drastic enlargement of their remaining presynaptic ribbons which were facing enlarged postsynaptic AMPAR clusters. Presynaptic Ca2+ microdomains and the capacity of IHCs to sustain high rates of exocytosis were largely increased, while on the contrary the expression of the fast-repolarizing BK channels, known to negatively control transmitter release, was decreased. This age-related synaptic plasticity in IHCs suggested a functional potentiation of synaptic transmission at the surviving synapses, a process that could partially compensate the decrease in synapse number and underlie hyperacusis. © Copyright © 2021 Peineau, Belleudy, Pietropaolo, Bouleau and Dulon.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85118337551
Neff P.; Simões J.; Psatha S.; Nyamaa A.; Boecking B.; Rausch L.; Dettling-Papargyris J.; Funk C.; Brueggemann P.; Mazurek B.,"Neff, P. (57215041697); Simões, J. (57210094225); Psatha, S. (57221686869); Nyamaa, A. (12645192500); Boecking, B. (57205672666); Rausch, L. (57221695845); Dettling-Papargyris, J. (57221697666); Funk, C. (57221689212); Brueggemann, P. (57193442082); Mazurek, B. (8675295000)",57215041697; 57210094225; 57221686869; 12645192500; 57205672666; 57221695845; 57221697666; 57221689212; 57193442082; 8675295000,The impact of tinnitus distress on cognition,2021,Scientific Reports,11,1,2243,,,,28,10.1038/s41598-021-81728-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099846818&doi=10.1038%2fs41598-021-81728-0&partnerID=40&md5=8fda31d0a0a71e46e616b04906332f6d,"Tinnitus is the chronic perception of a phantom sound with different levels of related distress. Past research has elucidated interactions of tinnitus distress with audiological, affective and further clinical variables. The influence of tinnitus distress on cognition is underinvestigated. Our study aims at investigating specific influences of tinnitus distress and further associated predictors on cognition in a cohort of n = 146 out-ward clinical tinnitus patients. Age, educational level, hearing loss, Tinnitus Questionnaire (TQ) score, tinnitus duration, speech in noise (SIN), stress, anxiety and depression, and psychological well-being were included as predictors of a machine learning regression approach (elastic net) in three models with scores of a multiple choice vocabulary test (MWT-B), or two trail-making tests (TMT-A and TMT-B), as dependent variables. TQ scores predicted lower MWT-B scores and higher TMT-B test completion time. Stress, emotional, and psychological variables were not found to be relevant predictors in all models with the exception of small positive influences of SIN and depression on TMT-B. Effect sizes were small to medium for all models and predictors. Results are indicative of specific influence of tinnitus distress on cognitive performance, especially on general or crystallized intelligence and executive functions. More research is needed at the delicate intersection of tinnitus distress and cognitive skills needed in daily functioning. © 2021, The Author(s).",33500489,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85099846818
Jeyalakshmi M.S.; Robin C.R.R.,"Jeyalakshmi, M.S. (57193571737); Robin, C. R. Rene (57189274646)",57193571737; 57189274646,Ontology-based prediction of cochlear implantation outcome using cross-modal plasticity analysis,2021,Journal of Ambient Intelligence and Humanized Computing,12,5,,5337,5347,10,0,10.1007/s12652-020-02011-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083982542&doi=10.1007%2fs12652-020-02011-0&partnerID=40&md5=c4467e68926b70894fbcf02aaa423504,"Cochlear implantation is a surgical procedure by which an electronic medical device, namely a cochlear implant, is fitted to the individual who has the challenge of hearing. It takes the function of the damaged inner ear, the cochlea. The hearing impaired may not benefit from this procedure because of cross-modal plasticity. This work aims to study the implantee’s visual modal adaptation by analyzing the visual evoked potential. The proposed methodology analyses the existence of cross-modal reorganization in the auditory cortex of bilateral prelingually deaf children after cochlear implantation using visual evoked potential. Fifty healthy, 50 prelingually, deaf children 50 cochlear implanted were considered as a cohort of the Visual evoked potential. The evoked potential recorded using pattern reversal stimulation. The amplitude and latency of N75, P100, and N145 components show a significant difference in normal, cochlear, and deaf. The early diagnosis of hearing impairment demands the patients and doctors to make a series of decisions for the betterment of the implantee in an accelerated manner through traditional database methodology implemented for making decisions, analyzing, interpreting, processing of data is so difficult in the conventional system. Medical knowledge represented for the computers to analyze the inferred data and to make the decisions. Ontology is the most potent tool to encode medical data semantically. A fuzzy ontology-based decision support system built to predict the cochlear implantation outcome. The ontology created using Protégé software tool and the decision taken using Jena and pellet reasoner. A fuzzy-based prediction model designed using a fuzzy interface system to estimate the categories of auditory performance (CAP) test reliable indicators of cochlear implantation success. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",,Retracted,Final,,Scopus,2-s2.0-85083982542
Salah M.; De Varebeke S.J.; Fransen E.; Topsakal V.; Van Camp G.; Van Rompaey V.,"Salah, Mahadi (57219020621); De Varebeke, Sebastien Janssens (6507536359); Fransen, Erik (7004158064); Topsakal, Vedat (22137091700); Van Camp, Guy (34573802800); Van Rompaey, Vincent (16417918400)",57219020621; 6507536359; 7004158064; 22137091700; 34573802800; 16417918400,Predictive Sensitivity and Concordance of Machine-learning Tools for Diagnosing DFNA9 in a Large Series of p.Pro51Ser Variant Carriers in the COCH-gene,2021,Otology and Neurotology,42,5,,671,677,6,0,10.1097/MAO.0000000000003028,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106538359&doi=10.1097%2fMAO.0000000000003028&partnerID=40&md5=fc64e8bc3f75b26ecfe99d78a235dff3,"Objective:In this study we aimed to evaluate the predictive cross-sectional sensitivity and longitudinal concordance of a machine-learning algorithm in a series of genetically confirmed p.(Pro51Ser) variant carriers (DFNA9).Study Design:Cross-sectional study.Setting:Tertiary and secondary referral center.Patients:Audiograms of 111 subjects with the p.(Pro51Ser) mutation in the COCH-gene were analyzed cross-sectionally. A subset of 17 subjects with repeated audiograms were used for longitudinal analysis.Intervention(s):All audiological thresholds were run through the web-based AudioGene v4.0 software.Main Outcome Measure(s):Sensitivity for accurate prediction of DFNA9 for cross-sectional data and concordance of correct prediction for longitudinal auditory data.Results:DFNA9 was predicted with a sensitivity of 93.7% in a series of 222 cross-sectionally collected audiological thresholds (76.1% as first gene locus). When using the hearing thresholds of the best ear, the sensitivity was 94.6%. The sensitivity was significantly higher in DFNA9 patients aged younger than 40 and aged 60 years or older, compared to the age group of 40 to 59 years, with resp. 97.6% (p<0.0001) and 98.8% (p<0.0001) accurate predictions. An average concordance of 91.6% was found to show the same response in all successive longitudinal audiometric data per patient.Conclusions:Audioprofiling software can accurately predict DFNA9 in an area with a high prevalence of confirmed carriers of the p.(Pro51Ser) variant in the COCH-gene. This algorithm yields high promises for helping clinicians in directing genetic testing in case of a strong family history of progressive hearing loss, especially for very young and old carriers. © 2021 Lippincott Williams and Wilkins. All rights reserved.",33492061,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85106538359
Wang Q.; Qian M.; Yang L.; Shi J.; Hong Y.; Han K.; Li C.; Lin J.; Huang Z.; Wu H.,"Wang, Qixuan (57205263260); Qian, Minfei (57220651642); Yang, Lu (57213836823); Shi, Junbo (57222723405); Hong, Yingying (57222720955); Han, Kun (57200820644); Li, Chen (58740723600); Lin, James (57222723021); Huang, Zhiwu (9336671200); Wu, Hao (55762405900)",57205263260; 57220651642; 57213836823; 57222723405; 57222720955; 57200820644; 58740723600; 57222723021; 9336671200; 55762405900,Audiometric Phenotypes of Noise-Induced Hearing Loss by Data-Driven Cluster Analysis and Their Relevant Characteristics,2021,Frontiers in Medicine,8,,662045,,,,8,10.3389/fmed.2021.662045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103859477&doi=10.3389%2ffmed.2021.662045&partnerID=40&md5=417eac5e8fd44f124b2289c1ff374f85,"Background: The definition of notched audiogram for noise-induced hearing loss (NIHL) is presently based on clinical experience, but audiometric phenotypes of NIHL are highly heterogeneous. The data-driven clustering of subtypes could provide refined characteristics of NIHL, and help identify individuals with typical NIHL at diagnosis. Methods: This cross-sectional study initially recruited 12,218 occupational noise-exposed employees aged 18–60 years from two factories of a shipyard in Eastern China. Of these, 10,307 subjects with no history of otological injurie or disease, family history of hearing loss, or history of ototoxic drug use were eventually enrolled. All these subjects completed health behavior questionnaires, cumulative noise exposure (CNE) measurement, and pure-tone audiometry. We did data-driven cluster analysis (k-means clustering) in subjects with hearing loss audiograms (n = 6,599) consist of two independent datasets (n = 4,461 and n = 2,138). Multinomial logistic regression was performed to analyze the relevant characteristics of subjects with different audiometric phenotypes compared to those subjects with normal hearing audiograms (n = 3,708). Results: A total of 10,307 subjects (9,165 males [88.9%], mean age 34.5 [8.8] years, mean CNE 91.2 [22.7] dB[A]) were included, 3,708 (36.0%) of them had completely normal hearing, the other 6,599 (64.0%) with hearing loss audiograms were clustered into four audiometric phenotypes, which were replicable in two distinct datasets. We named the four clusters as the 4–6 kHz sharp-notched, 4–6 kHz flat-notched, 3–8 kHz notched, and 1–8 kHz notched audiogram. Among them, except for the 4–6 kHz flat-notched audiogram which was not significantly related to NIHL, the other three phenotypes with different relevant characteristics were strongly associated with noise exposure. In particular, the 4–6 kHz sharp-notched audiogram might be a typical subtype of NIHL. Conclusions: By data-driven cluster analysis of the large-scale noise-exposed population, we identified three audiometric phenotypes associated with distinct NIHL subtypes. Data-driven sub-stratification of audiograms might eventually contribute to the precise diagnosis and treatment of NIHL. © Copyright © 2021 Wang, Qian, Yang, Shi, Hong, Han, Li, Lin, Huang and Wu.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85103859477
Rumschlag J.A.; Razak K.A.,"Rumschlag, Jeffrey A. (57196118257); Razak, Khaleel A. (6602399214)",57196118257; 6602399214,"Age-related changes in event related potentials, steady state responses and temporal processing in the auditory cortex of mice with severe or mild hearing loss",2021,Hearing Research,412,,108380,,,,4,10.1016/j.heares.2021.108380,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118580053&doi=10.1016%2fj.heares.2021.108380&partnerID=40&md5=f0bc14c1b978feae52d091c79aa34d91,"Age-related changes in auditory processing affect the quality of life of older adults with and without hearing loss. To distinguish between the effects of sensorineural hearing loss and aging on cortical processing, the main goal of the present study was to compare cortical responses using the same stimulus paradigms and recording conditions in two strains of mice (C57BL/6J and FVB) that differ in the degree of age-related hearing loss. Electroencephalogram (EEG) recordings were obtained from freely moving young and old mice using epidural screw electrodes. We measured event related potentials (ERP) and 40 Hz auditory steady-state responses (ASSR). We used a novel stimulus, termed the gap-ASSR stimulus, which elicits an ASSR by rapidly presenting short gaps in continuous noise. By varying the gap widths and modulation depths, we probed the limits of temporal processing in young and old mice. Temporal fidelity of ASSR and gap-ASSR responses were measured as phase consistency across trials (inter-trial phase clustering; ITPC). The old C57 mice, which show severe hearing loss, produced larger ERP amplitudes compared to young mice. Despite robust ERPs, the old C57 mice showed significantly diminished ITPC in the ASSR and gap-ASSR responses, even with 100% modulation depth. The FVB mice, which show mild hearing loss with age, generated similar ERP amplitudes and ASSR ITPC across the age groups tested. However, the old FVB mice showed decreased gap-ASSR responses compared to young mice, particularly for modulation depths <100%. The C57 mice data suggest that severe presbycusis leads to increased gain in the auditory cortex, but with reduced temporal fidelity. The FVB mice data suggest that with mild hearing loss, age-related changes in temporal processing become apparent only when tested with more challenging sounds (shorter gaps and shallower modulation). © 2021",34758398,Article,Final,,Scopus,2-s2.0-85118580053
Belitz C.; Ali H.; Hansen J.H.L.,"Belitz, Chelzy (57211639140); Ali, Hussnain (35408639900); Hansen, John H. L. (7404334144)",57211639140; 35408639900; 7404334144,Estimating hearing aid fitting presets with machine learning-based clustering strategies,2021,JASA Express Letters,1,11,115204,,,,0,10.1121/10.0007149,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177490362&doi=10.1121%2f10.0007149&partnerID=40&md5=247c444f6b6a03074b86a599eb385668,"Although there exist nearly 35 × 106 hearing impaired people in the U.S., only an estimated 25% use hearing aids (HA), while others elect not to use prescribed HAs. Lack of HA acceptance can be attributed to several factors including (i) performance variability in diverse environments, (ii) time-to-convergence for best HA operating configuration, (iii) unrealistic expectations, and (iv) cost/insurance. This study examines a nationwide dataset of pure-tone audiograms and HA fitting configurations. An overview of data characteristics is presented, followed by use of machine learning clustering to suggest ways of obtaining effective starting configurations, thereby reducing time-to-convergence to improve HA retention. © 2021 Author(s).",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85177490362
Bennett R.J.; Swanepoel D.W.; Ratinaud P.; Bailey A.; Pennebaker J.W.; Manchaiah V.,"Bennett, Rebecca J. (57222869276); Swanepoel, De Wet (13609471200); Ratinaud, Pierre (55576099800); Bailey, Abram (57209745309); Pennebaker, James W. (7005677125); Manchaiah, Vinaya (35330310500)",57222869276; 13609471200; 55576099800; 57209745309; 7005677125; 35330310500,Hearing aid acquisition and ownership: what can we learn from online consumer reviews?,2021,International Journal of Audiology,60,11,,917,926,9,7,10.1080/14992027.2021.1931487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107747909&doi=10.1080%2f14992027.2021.1931487&partnerID=40&md5=1f07d4d52e84c4ac37c0e0250d607d99,"Objective: To explore the publicised opinions of consumers actively participating in online hearing aid reviews. Design: A retrospective design examining data generated from an online consumer review website (www.HearingTracker.com). Qualitative data (open text responses) were analysed using the open source automated topic modelling software IRaMuTeQ (http://www.iramuteq.org/) to identify themes. Outputs were compared with quantitative data from the consumer reviews (short response questions exploring hearing aid performance and benefit, and some meta-data such as hearing aid brand and years of hearing aid ownership). Study sample: 1378 online consumer hearing aid reviews. Results: Six clusters within two domains were identified. The domain Device Acquisition included three clusters: Finding the right provider, device and price-point; Selecting a hearing aid to suit the hearing loss; Attaining physical fit and device management skills. The domain Device Use included three clusters: Smartphone streaming to hearing aids; Hearing aid adjustment using smartphone; and Hearing in noise. Conclusions: Although online hearing aid consumers indicate positive performance on multiple-choice questions relating to hearing aid performance and benefit, their online reviews describe a number of barriers limiting their success. Hearing healthcare clinicians must employ a personalised approach to audiological rehabilitation to ensure individual clients’ needs are met. © 2021 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",34120557,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85107747909
Guo J.; Dong G.; Rong X.; Luo H.; Liu Y.,"Guo, Jingyi (55990929300); Dong, Guanghui (22233889400); Rong, Xing (57190409370); Luo, Hancheng (57714022400); Liu, Yimin (57192560973)",55990929300; 22233889400; 57190409370; 57714022400; 57192560973,Relationship between binaural high-frequency mean hearing threshold and hypertension in female worker exposed to noise; [噪声作业女工双耳高频平均听阈与高血压的关系],2021,Chinese Journal of Industrial Hygiene and Occupational Diseases,39,5,,354,358,4,0,10.3760/cma.j.cn121094-20200413-00185,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107456689&doi=10.3760%2fcma.j.cn121094-20200413-00185&partnerID=40&md5=c3b704537fb26c1a40ffb65d1600b1e0,"Objective To explore the relationship between the binaural high-frequency mean hearing threshold and the hypertension of female workers exposed to noise, and to understand the application significance of the binaural high-frequency mean hearing threshold as an internal effect indicator of the risk of hypertension in female workers exposed to noise. Ｍｅｔｈｏｄｓ From January to December 2018, a total of 20882 female workers exposed to noise in Guangzhou were selected by cluster sampling. Pure tone audiometry, blood pressure, age and length of service were collected. Trend test was used to evaluate the effects of exposure to noise and binaural high-frequency mean hearing threshold on blood pressure. Binary logistic regression model was used to evaluate the risk of hypertension associated with exposure to noise and binaural high-frequency mean hearing threshold. Ｒｅｓｕｌｔｓ The detection rate of normal hearing threshold, mild hearing loss and severe hearing loss was 80.73% (16858/20882), 16.21% (3384/20882) and 3.06% (640/20882) respectively. The prevalence of hypertension was 6.04%(1018/16858) in normal hearing group, 10.28%(348/3384) in patients with high frequency mild hearing loss, and 11.25% (72/640) in patients with high frequency severe hearing loss. There was a linear relationship between the increase of working age and high-frequency mean hearing threshold and the increase of systolic and diastolic blood pressure (P< 0.05). Compared with those exposed to noise for less than 1 year, the risk of hypertension in female workers with 7-9 years and more than 9 years was decreased (OR= 0.79, 0.75, P<0.05). Compared with normal hearing group, the risk of hypertension in high frequency mild hearing loss group was increased (OR =1.31, P <0.05). Ｃｏｎｃｌｕｓｉｏｎ The increase in the binaural high-frequency mean hearing threshold of female workers exposed to noise can increase the blood pressure level and the risk of hypertension, and attention should be paid to female workers with high-frequency mild hearing loss. © 2021 Chinese Medical Journals Publishing House Co.Ltd. All Rights Reserved.",34074080,Article,Final,,Scopus,2-s2.0-85107456689
Zhao C.; Liu C.,"Zhao, Chaoyang (57457068000); Liu, Chun (57223108520)",57457068000; 57223108520,An Artificial Intelligence Hearing Aid Based on Two-level Neural Network,2021,"Proceedings of the 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2021",2,,,1045,1050,5,1,10.1109/IDAACS53288.2021.9660975,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124792281&doi=10.1109%2fIDAACS53288.2021.9660975&partnerID=40&md5=a3e07f138cc38f8d7317865cfb5aa491,"Hearing aids have become an indispensable part of the lives of some hearing-impaired people. Traditional hearing aids will be adjusted according to the personal hearing curve and allowing patients to avoid noise-induced harm. However, there is no sound classification or intelligent noise reduction, which cannot meet the higher demand for hearing aids. This paper designed a hearing aid based on a two-level neural network, and the Urbansound8K data set was used to train the neural network. It can simulate the human auditory attention mechanism and intelligently control the output volume. At the same time, the noise reduction model is used to perform corresponding noise reduction processing on different speech streams. Experimental results show that the hearing aid can differentially amplify various sounds in different scenes. The noise part of the sound heard by the user will be suppressed to a certain extent, which can improve the comfort of long-term wearing.  © 2021 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85124792281
Potnis M.; Raul D.; Inamdar M.,"Potnis, Mitali (57486392900); Raul, Divya (57485981400); Inamdar, Madhura (57221251742)",57486392900; 57485981400; 57221251742,Recognition of Indian Sign Language using Machine Learning Algorithms,2021,"Proceedings of the 8th International Conference on Signal Processing and Integrated Networks, SPIN 2021",,,,579,584,5,0,10.1109/SPIN52536.2021.9566141,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126197310&doi=10.1109%2fSPIN52536.2021.9566141&partnerID=40&md5=04f1d74faa9b3912ab2552a34b7da9ab,"Auditory perception enables an individual to sense sound vibrations caused due to the variations in pressure present. In accordance with WHO, 6.3% of the Indian population suffers from hearing disability. People that suffer from hearing impairment communicate using hand gestures. Unfortunately, the vast majority of the people in India are not aware of the semantics of these gestures. To bridge the gap between the people suffering from hearing disabilities and those who are not, we have proposed an Indian sign language Recognition system using machine learning algorithm techniques. Our method utilizes several images of people demonstrating the alphabets in Indian Sign Language. These images are pre-processed, and further, we utilize these obtained images for training and testing our Machine Learning Algorithms. Out of all the six machine learning algorithms that we used, Random Forest Machine Learning Algorithm gave the highest accuracy of 98.44%. © 2021 IEEE",,Conference paper,Final,,Scopus,2-s2.0-85126197310
Luque M.; Schrott-Fischer A.; Dudas J.; Pechriggl E.; Brenner E.; Rask-Andersen H.; Liu W.; Glueckert R.,"Luque, Maria (57210729786); Schrott-Fischer, Anneliese (55403356500); Dudas, Jozsef (35493771100); Pechriggl, Elisabeth (55588855300); Brenner, Erich (7102996757); Rask-Andersen, Helge (7006223005); Liu, Wei (56108887200); Glueckert, Rudolf (55923185200)",57210729786; 55403356500; 35493771100; 55588855300; 7102996757; 7006223005; 56108887200; 55923185200,"HCN channels in the mammalian cochlea: Expression pattern, subcellular location, and age-dependent changes",2021,Journal of Neuroscience Research,99,2,,699,728,29,8,10.1002/jnr.24754,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096768978&doi=10.1002%2fjnr.24754&partnerID=40&md5=4e9fc5ef1a62876b44f6c5e627312c36,"Neuronal diversity in the cochlea is largely determined by ion channels. Among voltage-gated channels, hyperpolarization-activated cyclic nucleotide-gated (HCN) channels open with hyperpolarization and depolarize the cell until the resting membrane potential. The functions for hearing are not well elucidated and knowledge about localization is controversial. We created a detailed map of subcellular location and co-expression of all four HCN subunits across different mammalian species including CBA/J, C57Bl/6N, Ly5.1 mice, guinea pigs, cats, and human subjects. We correlated age-related hearing deterioration in CBA/J and C57Bl/6N with expression levels of HCN1, −2, and −4 in individual auditory neurons from the same cohort. Spatiotemporal expression during murine postnatal development exposed HCN2 and HCN4 involvement in a critical phase of hair cell innervation. The huge diversity of subunit composition, but lack of relevant heteromeric pairing along the perisomatic membrane and axon initial segments, highlighted an active role for auditory neurons. Neuron clusters were found to be the hot spots of HCN1, −2, and −4 immunostaining. HCN channels were also located in afferent and efferent fibers of the sensory epithelium. Age-related changes on HCN subtype expression were not uniform among mice and could not be directly correlated with audiometric data. The oldest mice groups revealed HCN channel up- or downregulation, depending on the mouse strain. The unexpected involvement of HCN channels in outer hair cell function where HCN3 overlaps prestin location emphasized the importance for auditory function. A better understanding may open up new possibilities to tune neuronal responses evoked through electrical stimulation by cochlear implants. © 2020 The Authors. Journal of Neuroscience Research published by Wiley Periodicals LLC",33181864,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85096768978
Enomoto Y.; Tsurusaki Y.; Tominaga M.; Kobayashi S.; Inoue M.; Fujita K.; Kumaki T.; Murakami H.; Kurosawa K.,"Enomoto, Yumi (56599907400); Tsurusaki, Yoshinori (6603057042); Tominaga, Makiko (55235448000); Kobayashi, Shinji (57205399909); Inoue, Maki (55580936400); Fujita, Kazutoshi (57206922163); Kumaki, Tatsuro (57206275520); Murakami, Hiroaki (57206248013); Kurosawa, Kenji (7203077687)",56599907400; 6603057042; 55235448000; 57205399909; 55580936400; 57206922163; 57206275520; 57206248013; 7203077687,"A Recurrent Variant in POLR1B, c.3007C>T; P.Arg1003Cys, Associated with Atresia of the External Canal and Microtia in Treacher Collins Syndrome Type 4",2021,Molecular Syndromology,12,2,,127,132,5,4,10.1159/000513224,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105669421&doi=10.1159%2f000513224&partnerID=40&md5=01d86fcf89621bdaf051d313a45596e0,"Treacher Collins syndrome (TCS) is a heterogenous malformation syndrome characterized by a distinct facial appearance including downslanting palpebral fissures, malar hypoplasia, conductive hearing loss, and mandibular hypoplasia. Recently, a new causative gene, POLR1B, encoding DNA-directed RNA polymerase I subunit RPA2, was identified as a fourth type of TCS (TCS4). We describe another patient with TCS4 caused by a recurrent POLR1B variant, c.3007C>T; p.Arg1003Cys. Including our patient, all 4 patients with p.(Arg1003Cys) had atresia of the external auditory canal and microtia. All of the reported pathogenic variants in POLR1B were clustered at only 2 residues. Our patient highlights the genotype-phenotype correlation in TCS4 associated with POLR1B. © 2021 S. Karger AG, Basel. Copyright: All rights reserved.",,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85105669421
Vasudevan S.K.; Raguraman T.B.; Pulari S.R.,"Vasudevan, Shriram K. (55793633700); Raguraman, T.B. (57979285600); Pulari, Sini Raj (57939225700)",55793633700; 57979285600; 57939225700,Curtailing insomnia in a non-intrusive hardware less approach with machine learning,2022,International Journal of Medical Engineering and Informatics,14,6,,537,549,12,0,10.1504/ijmei.2022.126524,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142481025&doi=10.1504%2fijmei.2022.126524&partnerID=40&md5=136bfbcd1f0075f8d00922d534be60f2,"The significant challenges nowadays with the expanded utilisation of cell phones are restlessness and a risk to mental health. Rest time is implied for the cerebrum to revive. If the rest time is disturbed because of a non-stop outer aggravation, it upsets the profound rest. Most of us prefer music as the option to induce sleep and relax. Headphones or earphones are used for the same. It is shrewd to turn off the music after an individual rests, which the majority of us do not do, as we by at that point, are rested. This causes damage. Excessive usage of earphones or headphones is one part of it and unnecessary feed to the ears while sleeping shall trigger noise-induced hearing loss. Here, we propose a framework built with machine learning as the key. This will guarantee that the music player stops once the individual using it has dozed off. This ensures proper rest and forestalls sleep deprivation/NIHL. Copyright © 2022 Inderscience Enterprises Ltd.",,Article,Final,,Scopus,2-s2.0-85142481025
Duan B.; Xu Z.; Pan L.; Chen W.; Qiao Z.,"Duan, Bo (57057096600); Xu, Zhengmin (7405425109); Pan, Lili (57637695200); Chen, Wenxia (57056652300); Qiao, Zhongwei (16444536400)",57057096600; 7405425109; 57637695200; 57056652300; 16444536400,Prediction of Hearing Prognosis of Large Vestibular Aqueduct Syndrome Based on the PyTorch Deep Learning Model,2022,Journal of Healthcare Engineering,2022,,4814577,,,,3,10.1155/2022/4814577,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128802331&doi=10.1155%2f2022%2f4814577&partnerID=40&md5=9de4da677cf87636c440ed3bd7b02a3b,"In order to compare magnetic resonance imaging (MRI) findings of patients with large vestibular aqueduct syndrome (LVAS) in the stable hearing loss (HL) group and the fluctuating HL group, this paper provides reference for clinicians' early intervention. From January 2001 to January 2016, patients with hearing impairment diagnosed as LVAS in infancy in the Department of Otorhinolaryngology, Head and Neck Surgery, Children's Hospital of Fudan University were collected and divided into the stable HL group (n = 29) and the fluctuating HL group (n = 30). MRI images at initial diagnosis were collected, and various deep learning neural network training models were established based on PyTorch to classify and predict the two series. Vgg16_bn, vgg19_bn, and ResNet18, convolutional neural networks (CNNs) with fewer layers, had favorable effects for model building, with accs of 0.9, 0.8, and 0.85, respectively. ResNet50, a CNN with multiple layers and an acc of 0.54, had relatively poor effects. The GoogLeNet-trained model performed best, with an acc of 0.98. We conclude that deep learning-based radiomics can assist doctors in accurately predicting LVAS patients to classify them into either fluctuating or stable HL types and adopt differentiated treatment methods.  © 2022 Bo Duan et al.",35463685,Retracted,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128802331
Islam M.N.; Sulaiman N.; Mustafa M.,"Islam, Md. Nahidul (57221115971); Sulaiman, Norizam (24734168300); Mustafa, Mahfuzah (36069366700)",57221115971; 24734168300; 36069366700,Diagnosis of Hearing Impairment Based on Wavelet Transformation and Machine Learning Approach,2022,Lecture Notes in Electrical Engineering,842,,,705,715,10,0,10.1007/978-981-16-8690-0_62,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126937271&doi=10.1007%2f978-981-16-8690-0_62&partnerID=40&md5=694d99d7336aec9719419497426b3f63,"Hearing impairment has become the most widespread sensory disorder in the world, obstructing human-to-human communication and comprehension. The EEG-based brain-computer interface (BCI) technology may be an important solution to rehabilitating their hearing capacity for people who are unable to sustain verbal contact and behavioral response by sound stimulation. Auditory evoked potentials (AEPs) are a kind of EEG signal produced by an acoustic stimulus from the brain scalp. This study aims to develop an intelligent hearing level assessment technique using AEP signals to address these concerns. First, we convert the raw AEP signals into the time–frequency image using the continuous wavelet transform (CWT). Then, the Support vector machine (SVM) approach is used for classifying the time–frequency images. This study uses the reputed publicly available dataset to check the validation of the proposed approach. This approach achieves a maximum of 95.21% classification accuracy, which clearly indicates that the approach provides a very encouraging performance for detecting the AEPs responses in determining human auditory level. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",,Conference paper,Final,,Scopus,2-s2.0-85126937271
Yoo H.B.; Mohan A.; De Ridder D.; Vanneste S.,"Yoo, Hye Bin (57190565225); Mohan, Anusha (57089879900); De Ridder, Dirk (7006928697); Vanneste, Sven (35225555700)",57190565225; 57089879900; 7006928697; 35225555700,Paradoxical relationship between distress and functional network topology in phantom sound perception,2021,Progress in Brain Research,260,,,367,395,28,4,10.1016/bs.pbr.2020.08.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094155479&doi=10.1016%2fbs.pbr.2020.08.007&partnerID=40&md5=53d0b547d79c388ac90f0115d24b1872,"Distress is a domain-general symptom that accompanies several disorders, including tinnitus. Based on previous studies, we know that distress is encoded by changes in functional connectivity between cortical and subcortical regions. However, how distress relates to large-scale brain networks is not yet clear. In the current study, we investigate the relationship between distress and the efficiency of a network by examining its topological properties using resting state fMRI collected from 90 chronic tinnitus patients. The present results indicate that distress negatively correlates with path length and positively correlates with clustering coefficient, small-worldness, and efficiency of information transfer. Specifically, path analysis showed that the relationship between distress and efficiency is significantly mediated by the resilience of the feeder connections and the centrality of the rich-club connections. In other words, the higher the network efficiency, the lower the resilience of the feeder connections and the centrality of the rich-club connections, which in turn reflects in higher distress in tinnitus patients. This indicates a reorganization of the network towards a paradoxically more efficient topology in patients with high distress, potentially explaining their increased rumination on the tinnitus percept itself. © 2021 Elsevier B.V.",33637228,Book chapter,Final,,Scopus,2-s2.0-85094155479
Zahid H.; Rashid M.; Hussain S.; Azim F.; Syed S.A.; Saad A.,"Zahid, Hira (57217597979); Rashid, Munaf (57220177714); Hussain, Samreen (57220181392); Azim, Fahad (24723808800); Syed, Sidra Abid (57207914833); Saad, Afshan (57215294695)",57217597979; 57220177714; 57220181392; 24723808800; 57207914833; 57215294695,Recognition of Urdu sign language: a systematic review of the machine learning classification,2022,PeerJ Computer Science,8,,e883,,,,4,10.7717/PEERJ-CS.883,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125842251&doi=10.7717%2fPEERJ-CS.883&partnerID=40&md5=56eee893d858293ddfc29ca2f1a1a7ec,"Background and Objective. Humans communicate with one another using language systems such as written words or body language (movements), hand motions, head gestures, facial expressions, lip motion, and many more. Comprehending sign language is just as crucial as learning a natural language. Sign language is the primary mode of communication for those who have a deaf or mute impairment or are disabled. Without a translator, people with auditory difficulties have difficulty speaking with other individuals. Studies in automatic recognition of sign language identification utilizing machine learning techniques have recently shown exceptional success and made significant progress. The primary objective of this research is to conduct a literature review on all the work completed on the recognition of Urdu Sign Language through machine learning classifiers to date. Materials and methods. All the studies have been extracted from databases, i.e., PubMed, IEEE, Science Direct, and Google Scholar, using a structured set of keywords. Each study has gone through proper screening criteria, i.e., exclusion and inclusion cri- teria. PRISMA guidelines have been followed and implemented adequately throughout this literature review. Results. This literature review comprised 20 research articles that fulfilled the eligibility requirements. Only those articles were chosen for additional full-text screening that follows eligibility requirements for peer-reviewed and research articles and studies issued in credible journals and conference proceedings until July 2021. After other screenings, only studies based on Urdu Sign language were included. The results of this screening are divided into two parts; (1) a summary of all the datasets available on Urdu Sign Language. (2) a summary of all the machine learning techniques for recognizing Urdu Sign Language. Conclusion. Our research found that there is only one publicly-available USL sign- based dataset with pictures versus many character-, number-, or sentence-based publicly available datasets. It was also concluded that besides SVM and Neural Network, no unique classifier is used more than once. Additionally, no researcher opted for an unsupervised machine learning classifier for detection. To the best of our knowledge, this is the first literature review conducted on machine learning approaches applied to Urdu sign language. © 2022 Zahid et al",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85125842251
Goderie T.; Van Wier M.F.; Stam M.; Lissenberg-Witte B.I.; Merkus P.; Smits C.; Kramer S.E.,"Goderie, Thadé (26639312500); Van Wier, Marieke F. (14046367200); Stam, Mariska (56032139200); Lissenberg-Witte, Birgit I. (57204744042); Merkus, Paul (7004836512); Smits, Cas (56240310400); Kramer, Sophia E. (7401609154)",26639312500; 14046367200; 56032139200; 57204744042; 7004836512; 56240310400; 7401609154,Association between Speech Recognition in Noise and Risk Factors of Cardiovascular Disease,2021,Audiology and Neurotology,26,5,,368,377,9,7,10.1159/000513551,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106226115&doi=10.1159%2f000513551&partnerID=40&md5=13538085c0d56c25909614b3a81b3575,"Introduction: Risk factors for cardiovascular disease (CVD) are associated with sensorineural hearing loss. CVD risk factors are known to cluster and interact, thereby increasing the cumulative risk for CVD. Previously, using the database of the Netherlands Longitudinal Study on Hearing (NL-SH), an association was found between a history of smoking and an increased decline in speech recognition in noise over 10 years of follow-up. Prospectively limited data are available on the association between CVD risk factors, interactions of these risk factors, and hearing loss. In this study, data from the NL-SH were used to study the association between CVD risk factors and speech recognition in noise longitudinally. Methods: Baseline, 5-year, and 10-year follow-up data of the NL-SH were included. The NL-SH is a web-based prospective cohort study which started in 2006. Participants were aged 18-70 years at baseline. Speech recognition in noise was determined with an online digit-triplet speech-in-noise test. In addition, participants completed online questionnaires on demographic, lifestyle, and health-related characteristics. The association of the ability to recognize speech in noise with CVD risk factors (i.e., obesity, rheumatoid arthritis [RA], hypertension, diabetes mellitus, and dyslipidemia) was analyzed longitudinally. We also analyzed the interaction between these risk factors (including age, sex, and history of smoking) and speech recognition in noise. Results: None of the CVD risk factors or interactions of 2 CVD risk factors was significantly associated with a decline in SRT over time. Obesity (p = 0.016), RA (p = 0.027), and hypertension (p = 0.044) were associated with overall higher (more unfavorable) SRTs. No overall interactions between CVD risk factors were found. Conclusion: Obesity, RA, and hypertension were overall associated with a higher SRT, but no longitudinal associations between these or other CVD factors with SRTs were found. Also, no interactions between 2 CVD risk factors and SRTs were found. Although no longitudinal associations between CVD risk factors and decline in SRTs were found, clinicians should be alert about the concurrent association between CVD risk factors and hearing loss.  © 2021 The Author(s) Published by S. Karger AG, Basel.",33652431,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85106226115
Keshavarzi M.; Reichenbach T.; Moore B.C.J.,"Keshavarzi, Mahmoud (55657249300); Reichenbach, Tobias (14060798600); Moore, Brian C. J. (57211731030)",55657249300; 14060798600; 57211731030,Transient Noise Reduction Using a Deep Recurrent Neural Network: Effects on Subjective Speech Intelligibility and Listening Comfort,2021,Trends in Hearing,25,,,,,,5,10.1177/23312165211041475,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116463552&doi=10.1177%2f23312165211041475&partnerID=40&md5=256d385510e7fcfa4483f56a22cb441e,"A deep recurrent neural network (RNN) for reducing transient sounds was developed and its effects on subjective speech intelligibility and listening comfort were investigated. The RNN was trained using sentences spoken with different accents and corrupted by transient sounds, using the clean speech as the target. It was tested using sentences spoken by unseen talkers and corrupted by unseen transient sounds. A paired-comparison procedure was used to compare all possible combinations of three conditions for subjective speech intelligibility and listening comfort for two relative levels of the transients. The conditions were: no processing (NP); processing using the RNN; and processing using a multi-channel transient reduction method (MCTR). Ten participants with normal hearing and ten with mild-to-moderate hearing loss participated. For the latter, frequency-dependent linear amplification was applied to all stimuli to compensate for individual audibility losses. For the normal-hearing participants, processing using the RNN was significantly preferred over that for NP for subjective intelligibility and comfort, processing using the RNN was significantly preferred over that for MCTR for subjective intelligibility, and processing using the MCTR was significantly preferred over that for NP for comfort for the higher transient level only. For the hearing-impaired participants, processing using the RNN was significantly preferred over that for NP for both subjective intelligibility and comfort, processing using the RNN was significantly preferred over that for MCTR for comfort, and processing using the MCTR was significantly preferred over that for NP for comfort. © The Author(s) 2021.",34606381,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85116463552
Gupta M.; Thakur N.; Bansal D.; Chaudhary G.; Davaasambuu B.; Hua Q.,"Gupta, Meenu (55255409400); Thakur, Narina (36988312600); Bansal, Dhruvi (57473762600); Chaudhary, Gopal (57189576936); Davaasambuu, Battulga (56454448000); Hua, Qiaozhi (57201726103)",55255409400; 36988312600; 57473762600; 57189576936; 56454448000; 57201726103,CNN-LSTM Hybrid Real-Time IoT-Based Cognitive Approaches for ISLR with WebRTC: Auditory Impaired Assistive Technology,2022,Journal of Healthcare Engineering,2022,,3978627,,,,10,10.1155/2022/3978627,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125572029&doi=10.1155%2f2022%2f3978627&partnerID=40&md5=b6bb976442f2dd863dbb7c97fa567122,"In the era of modern technology, people may readily communicate through facial expressions, body language, and other means. As the use of the Internet evolves, it may be a boon to the medical fields. Recently, the Internet of Medical Things (IoMT) has provided a broader platform to handle difficulties linked to healthcare, including people's listening and hearing impairment. Although there are many translators that exist to help people of various linguistic backgrounds communicate more effectively. Using kinesics linguistics, one may assess or comprehend the communications of auditory and hearing-impaired persons who are standing next to each other. When looking at the present COVID-19 scenario, individuals are still linked in some way via online platforms; however, persons with disabilities have communication challenges with online platforms. The work provided in this research serves as a communication bridge inside the challenged community and the rest of the globe. The proposed work for Indian Sign Linguistic Recognition (ISLR) uses three-dimensional convolutional neural networks (3D-CNNs) and long short-term memory (LSTM) technique for analysis. A conventional hand gesture recognition system involves identifying the hand and its location or orientation, extracting certain essential features and applying an appropriate machine learning algorithm to recognise the completed action. In the calling interface of the web application, WebRTC has been implemented. A teleprompting technology is also used in the web app, which transforms sign language into audible sound. The proposed web app's average recognition rate is 97.21%. Copyright © 2022 Meenu Gupta et al.",35237390,Retracted,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85125572029
Cassandro C.; Manassero A.; Landi V.; Aschero G.; Lovallo S.; Albera A.; Genovese E.; Canale A.,"Cassandro, Claudia (22633886000); Manassero, Alessandra (57299791500); Landi, Valeria (57300161000); Aschero, Giulia (57299976300); Lovallo, Silvano (57299608600); Albera, Andrea (55777543500); Genovese, Elisabetta (7006425005); Canale, Andrea (6701710329)",22633886000; 57299791500; 57300161000; 57299976300; 57299608600; 55777543500; 7006425005; 6701710329,Auditory processing disorders: Diagnostic and therapeutic challenge,2021,Otorhinolaryngology(Italy),71,3,,120,124,4,0,10.23736/S2724-6302.21.02387-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117306101&doi=10.23736%2fS2724-6302.21.02387-2&partnerID=40&md5=9235c0b2676067841ae782b460bc209f,"BACKGROUND: The auditory processing disorders (APD) are characterized by normal peripheral hearing, but abnormal processing of auditory information within the central auditory nervous system and the neurobiological activity that underlies that processing and gives rise to the electrophysiological auditory potentials. Learning disorders (LD) are diagnosed when a subject's achievement on individually administered standardized tests in reading, mathematics or written expression is substantially below (defined as a discrepancy of more than two standard deviations from the mean) that expected for age, schooling and level of intelligence. Prevalence of APD in students diagnosed with LD is estimated to be as high but is still unclear the overlap between the APD and other developmental disorders. This lack of clarity is probably due to the use of multiple diagnostic criteria and different tests proposed that evaluate the same cognitive domains as memory, attention, speech production etc. METHODS: The aim of our study was to present a cluster analysis to determine the overall profile of students that are tested for dyslexia with the co-occurrence of poor performance on auditory skills. In absence of any audiometric hearing loss, they have been addressed for auditory processing assessment according to diagnostic criteria. We evaluated 70 patients (30 males and 40 females) aged between 17 and 55 years. The students were tested on cognitive, auditory, reading and language skills with an IQ assessment, dyslexia assessment, phonological awareness screening, instrumental evaluation for hearing threshold. Exclusion criteria: IQ below the norm (<70 points) and the presence of neurological and sensory deficits. RESULT S: Among 70 patients examined, 33% have poor SRT -PTA agreement because ITA Matrix test showed a SRT average of -3.8 dB SNR; of these 33%, 56% also showed a low score in repeating non-words with shielded mouth, 61% a speed less than 4th percentage in spelling and 39% less than the 5th percentage in the fusion test. Analyzing the profiles of the group with poor SRT-PTA agreement, we focused on four cases that are suspected for APD and we tested them. Only one subjects had a poor performance below two standard deviation on two tests according to diagnostic criteria, so we confirm an APD. CONCLUSIONS: The clinical presentation of APD has much in common especially with specific language impairment (SLI) and dyslexia and this occurrence suggests that may be a symptom of a more varied neurodevelopmental disorder. We conclude that all the patients with difficult on auditory skills with normal hearing threshold should be assess for an APD. The diagnosis of APD is still today a challenge that require a larger sample for further investigation. © 2021 EDIZIONI MINERVA MEDICA.",,Article,Final,,Scopus,2-s2.0-85117306101
Mayer C.; Trezek B.J.; Hancock G.R.,"Mayer, Connie (7202232503); Trezek, Beverly J. (8945169800); Hancock, Gregory R. (7102177068)",7202232503; 8945169800; 7102177068,Reading Achievement of Deaf Students: Challenging the Fourth Grade Ceiling,2021,Journal of Deaf Studies and Deaf Education,26,3,,427,437,10,11,10.1093/deafed/enab013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108386991&doi=10.1093%2fdeafed%2fenab013&partnerID=40&md5=fc765c6fb28b2a71e3e882b688f03b68,"Historically it has been reported that deaf students do not achieve age-appropriate outcomes in reading, with this performance often being characterized in terms of a fourth grade ceiling. However, given the shifts in the field during the past 20 years (e.g., widespread implementation of newborn hearing screening, advances in hearing technologies), it would be timely to question whether this continues to serve as a meaningful benchmark. To this end, the purpose of this study was to investigate reading outcomes of a Canadian cohort of school-aged deaf learners (N=70) who all used listening and spoken language as the primary mode of communication. Specifically, the goal was to establish whether their achievement approached that of their hearing age peers and to identify demographic factors influencing performance (i.e., gender, unilateral/bilateral hearing loss, personal amplification, level of auditory functioning, grade placement, additional disabilities, home language). Results indicate that participants obtained standard scores in the average range on both the Basic Reading and Reading Comprehension clusters of the Woodcock Johnson III-Diagnostic Reading Battery (Woodcock et al., 2004), surpassing the fourth grade reading achievement ceiling often reported for this population. © 2021 Oxford University Press. All rights reserved.",34060625,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85108386991
Sanchez-Lopez R.; Dau T.; Whitmer W.M.,"Sanchez-Lopez, Raul (57204522385); Dau, Torsten (56368948300); Whitmer, William M. (9244546900)",57204522385; 56368948300; 9244546900,Audiometric profiles and patterns of benefit: a data-driven analysis of subjective hearing difficulties and handicaps,2022,International Journal of Audiology,61,4,,301,310,9,4,10.1080/14992027.2021.1905890,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103901527&doi=10.1080%2f14992027.2021.1905890&partnerID=40&md5=04692bb9e84a0456e60314bb6a5d48d2,"Objective: Hearing rehabilitation attempts to compensate for auditory dysfunction, reduce hearing difficulties and minimise participation restrictions that can lead to social isolation. However, there is no systematic approach to assess the quality of the intervention at an individual level that might help to evaluate the need of further hearing rehabilitation in the hearing care clinic. Design: A data-driven analysis on subjective data reflecting hearing disabilities and handicap was chosen to explore “benefit patterns” as a result of rehabilitation in different audiometric groups. The method was based on (1) dimensionality reduction; (2) stratification; (3) archetypal analysis; (4) clustering; (5) item importance estimation. Study sample: 572 hearing-aid users completed questionnaires of hearing difficulties (speech, spatial and qualities hearing scale; SSQ) and hearing handicap (HHQ). Results: The data-driven approach revealed four benefit profiles that were different for each audiometric group. The groups with low degree of high-frequency hearing loss (HLHF) showed a priority for rehabilitating hearing handicaps, whereas the groups with HLHF > 50 dB HL showed a priority for improvements in speech understanding. Conclusions: The patterns of benefit and the stratification approach might guide the clinical intervention strategy and improve the efficacy and quality of service in the hearing care clinic. © 2021 The Authors. Published by Informa UK Limited, trading as Taylor & Francis Group on behalf of British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",33825590,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85103901527
Beukes E.W.; Baguley D.M.; Manchaiah V.; Andersson G.; Allen P.M.; Kaldo V.; Jacquemin L.; Lourenco M.P.C.G.; Onozuka J.; Stockdale D.; Maidment D.W.,"Beukes, Eldré W. (57189571719); Baguley, David M. (7006369497); Manchaiah, Vinaya (35330310500); Andersson, Gerhard (7202645907); Allen, Peter M. (55421603100); Kaldo, Viktor (6506425962); Jacquemin, Laure (57203021883); Lourenco, Matheus P. C. G. (57207580299); Onozuka, Joy (57219977625); Stockdale, David (57195419055); Maidment, David W. (57142070800)",57189571719; 7006369497; 35330310500; 7202645907; 55421603100; 6506425962; 57203021883; 57207580299; 57219977625; 57195419055; 57142070800,Investigating tinnitus subgroups based on hearing-related difficulties,2021,International Journal of Clinical Practice,75,10,e14684,,,,4,10.1111/ijcp.14684,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112653087&doi=10.1111%2fijcp.14684&partnerID=40&md5=ba5e0151806c3b655f0b3e3a6911ff1d,"Purpose: Meaningfully grouping individuals with tinnitus who share a common characteristics (ie, subgrouping, phenotyping) may help tailor interventions to certain tinnitus subgroups and hence reduce outcome variability. The purpose of this study was to test if the presence of tinnitus subgroups are discernible based on hearing-related comorbidities, and to identify predictors of tinnitus severity for each subgroup identified. Methods: An exploratory cross-sectional study was used. The study was nested within an online survey distributed worldwide to investigate tinnitus experiences during the COVID-19 pandemic. The main outcome measure was the tinnitus Handicap Inventory- Screening Version. Results: From the 3400 respondents, 2980 were eligible adults with tinnitus with an average age of 58 years (SD = 14.7) and 49% (n = 1457) being female. A three-cluster solution identified distinct subgroups, namely, those with tinnitus-only (n = 1306; 44%), those presenting with tinnitus, hyperacusis, hearing loss and/or misophonia (n = 795; 27%), and those with tinnitus and hearing loss (n = 879; 29%). Those with tinnitus and hyperacusis reported the highest tinnitus severity (M = 20.3; SD = 10.5) and those with tinnitus and no hearing loss had the lowest tinnitus severity (M = 15.7; SD = 10.4). Younger age and the presence of mental health problems predicted greater tinnitus severity for all groups (β ≤ −0.1, P ≤.016). Conclusion: Further exploration of these potential subtypes are needed in both further research and clinical practice by initially triaging tinnitus patients prior to their clinical appointments based on the presence of hearing-related comorbidities. Unique management pathways and interventions could be tailored for each tinnitus subgroup. © 2021 John Wiley & Sons Ltd",34331723,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85112653087
Dondzillo A.; Takeda H.; Gubbels S.P.,"Dondzillo, Anna (6503924463); Takeda, Hiroki (56417036400); Gubbels, Samuel P. (12769819500)",6503924463; 56417036400; 12769819500,Sex difference in the efferent inner hair cell synapses of the aging murine cochlea,2021,Hearing Research,404,,108215,,,,2,10.1016/j.heares.2021.108215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101906282&doi=10.1016%2fj.heares.2021.108215&partnerID=40&md5=61da96c4ad9a76850214dd5fcbb3e1dc,"Efferent innervation of the inner hair cells changes over time. At an early age in mice, inner hair cells receive efferent feedback, which helps fine-tune tonotopic maps in the brainstem. In adulthood, inner hair cell efferent innervation wanes but increases again in older animals. It is not clear, however, whether age-related inner hair cell efferents increase along the entire range of the cochlear frequencies, or if this increase is restricted to a particular frequency-region, and whether this phenomenon occurs in both sexes. Age-related hearing loss, presbycusis, affects men and women differently. In mice, this difference is also strain specific. In aging black six mice, the auditory brainstem response thresholds increase in females earlier than in males. Here, we study age-related increase of the inner hair cell efferent innervation throughout the cochlea before hearing onset, in one month old and in ten months old and older male and female black six mice. We collected confocal images of immunostained inner hair cell efferents and quantified the labeled terminals in the entire cochlea using a machine learning algorithm. The overall number of the inner hair cell efferents in both sexes did not change significantly between age-groups. The distribution of the inner hair cell efferent innervation did not differ across frequencies in the cochlea. However, in females, inner hair cells received on average up to four times more efferent innervation than in males per each of the frequency regions tested. Sex differences were also found in the oldest age-group tested (≥ 10 months) where on average inner hair cells received six times more efferents in females than in males of matching age. Our findings emphasize the importance of including both sexes in sensorineural hearing loss research. © 2021 Elsevier B.V.",33677192,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85101906282
Bourqui M.; Pernon M.; Fougeron C.; Laganaro M.,"Bourqui, Marion (57223936604); Pernon, Michaela (54389869600); Fougeron, Cécile (6603139291); Laganaro, Marina (6506057139)",57223936604; 54389869600; 6603139291; 6506057139,Contribution of acoustic analysis to the detection of vocoid epenthesis in apraxia of speech and other motor speech disorders,2022,Aphasiology,36,7,,854,867,13,0,10.1080/02687038.2021.1914815,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106455126&doi=10.1080%2f02687038.2021.1914815&partnerID=40&md5=28a27b9117e86cfa04c5b5fee8eb3e19,"Background: Vocoid epenthesis within consonant clusters has been claimed to contribute to the diagnosis of apraxia of speech. In clinical practice, the clinicians often doubt about the correct production of clusters as the C-C transition may be minimally disrupted. Aims: To demonstrate the value of acoustic analysis in clinical practice as a reliable complement to perceptive judgment. Methods & Procedures: We compared the acoustic signature and the perceptive detection of vocoid epentheses in unvoiced consonant clusters within pseudo-words produced by 40 participants presenting different subtypes of motor speech disorders (including apraxia of speech (AoS) and dysarthria) and matched neurotypical controls. Outcomes & Results: The results indicate that vocoid epenthesis was acoustically visible in 3 out of 10 participants with AoS, and in one out of 30 participants with dysarthria. One-quarter of these vocoid epentheses was not detected via auditory perception by expert listeners (speech and language therapists) who also made false detections. Conclusions: The current results indicate that vocoid epenthesis is not systematic at least in mild AoS. Moreover, an important proportion is misdetected by ear, even by expert clinicians, meaning that visualisation of the acoustic signal can be of precious help. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85106455126
Zanet M.; Polo E.M.; Lenatti M.; Van Waterschoot T.; Mongelli M.; Barbieri R.; Paglialonga A.,"Zanet, Marco (57213610020); Polo, Edoardo M. (57213605525); Lenatti, Marta (57222472784); Van Waterschoot, Toon (16040861800); Mongelli, Maurizio (7005882346); Barbieri, Riccardo (35483096800); Paglialonga, Alessia (23668671800)",57213610020; 57213605525; 57222472784; 16040861800; 7005882346; 35483096800; 23668671800,Evaluation of a Novel Speech-in-Noise Test for Hearing Screening: Classification Performance and Transducers' Characteristics,2021,IEEE Journal of Biomedical and Health Informatics,25,12,,4300,4307,7,7,10.1109/JBHI.2021.3100368,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112658406&doi=10.1109%2fJBHI.2021.3100368&partnerID=40&md5=9dffed0cc558bbd6c54ea1a1bdce8957,"One of the current gaps in teleaudiology is the lack of methods for adult hearing screening viable for use in individuals of unknown language and in varying environments. We have developed a novel automated speech-in-noise test that uses stimuli viable for use in non-native listeners. The test reliability has been demonstrated in laboratory settings and in uncontrolled environmental noise settings in previous studies. The aim of this study was: (i) to evaluate the ability of the test to identify hearing loss using multivariate logistic regression classifiers in a population of 148 unscreened adults and (ii) to evaluate the ear-level sound pressure levels generated by different earphones and headphones as a function of the test volume. The multivariate classifiers had sensitivity equal to 0.79 and specificity equal to 0.79 using both the full set of features extracted from the test as well as a subset of three features (speech recognition threshold, age, and number of correct responses). The analysis of the ear-level sound pressure levels showed substantial variability across transducer types and models, with earphones levels being up to 22 dB lower than those of headphones. Overall, these results suggest that the proposed approach might be viable for hearing screening in varying environments if an option to self-adjust the test volume is included and if headphones are used. Future research is needed to assess the viability of the test for screening at a distance, for example by addressing the influence of user interface, device, and settings, on a large sample of subjects with varying hearing loss.  © 2013 IEEE.",34314365,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85112658406
Osman R.A.; Osman H.A.,"Osman, Rida Al (57201476167); Osman, Hussein Al (24586737500)",57201476167; 24586737500,On the use of machine learning for classifying auditory brainstem responses: A scoping review,2021,IEEE Access,9,,9504576,110592,110600,8,3,10.1109/ACCESS.2021.3102096,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112635028&doi=10.1109%2fACCESS.2021.3102096&partnerID=40&md5=db40f99121eb02c41ca7726faf72f5bd,"Recent advances in machine learning have led to a surge of interest in classification of the auditory brainstem response. In this work, we conducted a search in the PubMed, Google Scholar, SpringerLink, ScienceDirect, and Scopus databases, and identified twelve studies that explored the use of machine learning to classify the auditory brainstem response as a complementary and objective method to (a) help clinicians better diagnose hearing impairment by discerning between healthy and pathological auditory brainstem response waveforms, (b) present a neural marker for potential applications in hearing aid tuning, and (c) provide a biometric marker for discriminating between subjects. A comparison between the studies presented in this review is not possible as they used different test subjects, group sizes, and stimuli, and evaluated auditory brainstem response differently. Instead, the result of these studies will be presented and their limitations as well as their potential applications will be discussed. Overall, the findings of these studies suggest that ABR classification using machine learning is a promising tool for assessing patients with hearing loss, optimizing technologies for tuning hearing aids, and discriminating between subjects.  © 2013 IEEE.",,Review,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85112635028
Fletcher M.D.,"Fletcher, Mark D. (57204176402)",57204176402,Can Haptic Stimulation Enhance Music Perception in Hearing-Impaired Listeners?,2021,Frontiers in Neuroscience,15,,723877,,,,10,10.3389/fnins.2021.723877,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114985260&doi=10.3389%2ffnins.2021.723877&partnerID=40&md5=ae663555880cddcd261ae550ec265364,"Cochlear implants (CIs) have been remarkably successful at restoring hearing in severely-to-profoundly hearing-impaired individuals. However, users often struggle to deconstruct complex auditory scenes with multiple simultaneous sounds, which can result in reduced music enjoyment and impaired speech understanding in background noise. Hearing aid users often have similar issues, though these are typically less acute. Several recent studies have shown that haptic stimulation can enhance CI listening by giving access to sound features that are poorly transmitted through the electrical CI signal. This “electro-haptic stimulation” improves melody recognition and pitch discrimination, as well as speech-in-noise performance and sound localization. The success of this approach suggests it could also enhance auditory perception in hearing-aid users and other hearing-impaired listeners. This review focuses on the use of haptic stimulation to enhance music perception in hearing-impaired listeners. Music is prevalent throughout everyday life, being critical to media such as film and video games, and often being central to events such as weddings and funerals. It represents the biggest challenge for signal processing, as it is typically an extremely complex acoustic signal, containing multiple simultaneous harmonic and inharmonic sounds. Signal-processing approaches developed for enhancing music perception could therefore have significant utility for other key issues faced by hearing-impaired listeners, such as understanding speech in noisy environments. This review first discusses the limits of music perception in hearing-impaired listeners and the limits of the tactile system. It then discusses the evidence around integration of audio and haptic stimulation in the brain. Next, the features, suitability, and success of current haptic devices for enhancing music perception are reviewed, as well as the signal-processing approaches that could be deployed in future haptic devices. Finally, the cutting-edge technologies that could be exploited for enhancing music perception with haptics are discussed. These include the latest micro motor and driver technology, low-power wireless technology, machine learning, big data, and cloud computing. New approaches for enhancing music perception in hearing-impaired listeners could substantially improve quality of life. Furthermore, effective haptic techniques for providing complex sound information could offer a non-invasive, affordable means for enhancing listening more broadly in hearing-impaired individuals. © Copyright © 2021 Fletcher.",,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85114985260
Liu W.; Luque M.; Li H.; Schrott-Fischer A.; Glueckert R.; Tylstedt S.; Rajan G.; Ladak H.; Agrawal S.; Rask-Andersen H.,"Liu, Wei (56108887200); Luque, Maria (57210729786); Li, Hao (56988820800); Schrott-Fischer, Anneliese (55403356500); Glueckert, Rudolf (55923185200); Tylstedt, Sven (6506993306); Rajan, Gunesh (7003625401); Ladak, Hanif (57207541892); Agrawal, Sumit (7403054662); Rask-Andersen, Helge (7006223005)",56108887200; 57210729786; 56988820800; 55403356500; 55923185200; 6506993306; 7003625401; 57207541892; 7403054662; 7006223005,"Spike Generators and Cell Signaling in the Human Auditory Nerve: An Ultrastructural, Super-Resolution, and Gene Hybridization Study",2021,Frontiers in Cellular Neuroscience,15,,642211,,,,4,10.3389/fncel.2021.642211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103408379&doi=10.3389%2ffncel.2021.642211&partnerID=40&md5=1f908c1ab57458174acdc7cd2ac6580b,"Background: The human auditory nerve contains 30,000 nerve fibers (NFs) that relay complex speech information to the brain with spectacular acuity. How speech is coded and influenced by various conditions is not known. It is also uncertain whether human nerve signaling involves exclusive proteins and gene manifestations compared with that of other species. Such information is difficult to determine due to the vulnerable, “esoteric,” and encapsulated human ear surrounded by the hardest bone in the body. We collected human inner ear material for nanoscale visualization combining transmission electron microscopy (TEM), super-resolution structured illumination microscopy (SR-SIM), and RNA-scope analysis for the first time. Our aim was to gain information about the molecular instruments in human auditory nerve processing and deviations, and ways to perform electric modeling of prosthetic devices. Material and Methods: Human tissue was collected during trans-cochlear procedures to remove petro-clival meningioma after ethical permission. Cochlear neurons were processed for electron microscopy, confocal microscopy (CM), SR-SIM, and high-sensitive in situ hybridization for labeling single mRNA transcripts to detect ion channel and transporter proteins associated with nerve signal initiation and conductance. Results: Transport proteins and RNA transcripts were localized at the subcellular level. Hemi-nodal proteins were identified beneath the inner hair cells (IHCs). Voltage-gated ion channels (VGICs) were expressed in the spiral ganglion (SG) and axonal initial segments (AISs). Nodes of Ranvier (NR) expressed Nav1.6 proteins, and encoding genes critical for inter-cellular coupling were disclosed. Discussion: Our results suggest that initial spike generators are located beneath the IHCs in humans. The first NRs appear at different places. Additional spike generators and transcellular communication may boost, sharpen, and synchronize afferent signals by cell clusters at different frequency bands. These instruments may be essential for the filtering of complex sounds and may be challenged by various pathological conditions. © Copyright © 2021 Liu, Luque, Li, Schrott-Fischer, Glueckert, Tylstedt, Rajan, Ladak, Agrawal and Rask-Andersen.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85103408379
Tu Z.; Ma N.; Barker J.,"Tu, Zehai (57204144418); Ma, Ning (57190190446); Barker, Jon (7401680706)",57204144418; 57190190446; 7401680706,Optimising hearing aid fittings for speech in noise with a differentiable hearing loss model,2021,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2,,,1201,1205,4,3,10.21437/Interspeech.2021-1613,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119175694&doi=10.21437%2fInterspeech.2021-1613&partnerID=40&md5=9be6998e1da6137562611452a4a3c3cc,"Current hearing aids normally provide amplification based on a general prescriptive fitting, and the benefits provided by the hearing aids vary among different listening environments despite the inclusion of noise suppression feature. Motivated by this fact, this paper proposes a data-driven machine learning technique to develop hearing aid fittings that are customised to speech in different noisy environments. A differentiable hearing loss model is proposed and used to optimise fittings with back-propagation. The customisation is reflected on the data of speech in different noise with also the consideration of noise suppression. The objective evaluation shows the advantages of optimised custom fittings over general prescriptive fittings.  Copyright © 2021 ISCA.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119175694
Taylor K.; Sheikh W.,"Taylor, Kyra (57796504600); Sheikh, Waseem (22836360100)",57796504600; 22836360100,Automated Hearing Impairment Diagnosis Using Machine Learning,2022,"2022 Intermountain Engineering, Technology and Computing, IETC 2022",,,,,,,2,10.1109/IETC54973.2022.9796707,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133968110&doi=10.1109%2fIETC54973.2022.9796707&partnerID=40&md5=7d9e0980c87068dcf0e47f8938c6e4b2,"Approximately 700 million people will suffer from disabling hearing loss by 2050. Underdeveloped and developing countries, which encompass a considerable proportion of people with incapacitating hearing impairment, have a sparse number of audiologists and otolaryngologists. The lack of specialists leaves most hearing impairments undiagnosed for a long time. In this paper, we propose an automated hearing impairment diagnosis software - based on machine learning - to support audiologists and otolaryngologists in accurately and efficiently diagnosing and classifying hearing loss. We present the design, implementation, and performance analysis of the automated hearing impairment diagnosis software, which consists of two modules: a hearing test Data Generation Module and a Machine Learning Model. The Data Generation Module produces a diverse and exhaustive dataset for training and evaluating the Machine Learning Model. By employing multiclass and multi-label classification techniques to learn from the hearing test data, the model can instantaneously predict the type, degree, and configuration of hearing loss with high accuracy. Our proposed Machine Learning Model demonstrates propitious results with a prediction time of 634 ms, a log-loss reduction rate of 98.48%, and macro and micro precisions of 100% - showing the model's applicability to assist audiologists and otolaryngologists in rapidly and accurately classifying the type, degree, and configuration of hearing loss.  © 2022 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85133968110
Zou Y.; Ma H.; Liu B.; Li D.; Liu D.; Wang X.; Wang S.; Fan W.; Han P.,"Zou, Yan (57195721876); Ma, Hui (55723486100); Liu, Bo (57200554550); Li, Dan (57205885840); Liu, Dingxi (8285623100); Wang, Xinrong (57219034386); Wang, Siqi (56495813200); Fan, Wenliang (55624403100); Han, Ping (35726604400)",57195721876; 55723486100; 57200554550; 57205885840; 8285623100; 57219034386; 56495813200; 55624403100; 35726604400,Disrupted Topological Organization in White Matter Networks in Unilateral Sudden Sensorineural Hearing Loss,2021,Frontiers in Neuroscience,15,,666651,,,,6,10.3389/fnins.2021.666651,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111384644&doi=10.3389%2ffnins.2021.666651&partnerID=40&md5=e2a037528c5df3498849e4f774064b42,"Sudden sensorineural hearing loss (SSNHL) is a sudden-onset hearing impairment that rapidly develops within 72 h and is mostly unilateral. Only a few patients can be identified with a defined cause by routine clinical examinations. Recently, some studies have shown that unilateral SSNHL is associated with alterations in the central nervous system. However, little is known about the topological organization of white matter (WM) networks in unilateral SSNHL patients in the acute phase. In this study, 145 patients with SSNHL and 91 age-, gender-, and education-matched healthy controls were evaluated using diffusion tensor imaging (DTI) and graph theoretical approaches. The topological properties of WM networks, including global and nodal parameters, were investigated. At the global level, SSNHL patients displayed decreased clustering coefficient, local efficiency, global efficiency, normalized clustering coefficient, normalized characteristic path length, and small-worldness and increased characteristic path length (p < 0.05) compared with healthy controls. At the nodal level, altered nodal centralities in brain regions involved the auditory network, visual network, attention network, default mode network (DMN), sensorimotor network, and subcortical network (p < 0.05, Bonferroni corrected). These findings indicate a shift of the WM network topology in SSNHL patients toward randomization, which is characterized by decreased global network integration and segregation and is reflected by decreased global connectivity and altered nodal centralities. This study could help us understand the potential pathophysiology of unilateral SSNHL. © Copyright © 2021 Zou, Ma, Liu, Li, Liu, Wang, Wang, Fan and Han.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85111384644
Pickett S.B.; Raible D.W.,"Pickett, Sarah B. (57200541904); Raible, David W. (7004125277)",57200541904; 7004125277,Water Waves to Sound Waves: Using Zebrafish to Explore Hair Cell Biology,2019,JARO - Journal of the Association for Research in Otolaryngology,20,1,,,,,33,10.1007/s10162-018-00711-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059916767&doi=10.1007%2fs10162-018-00711-1&partnerID=40&md5=0be0fae3da39cfee461660345b6046d9,"Although perhaps best known for their use in developmental studies, over the last couple of decades, zebrafish have become increasingly popular model organisms for investigating auditory system function and disease. Like mammals, zebrafish possess inner ear mechanosensory hair cells required for hearing, as well as superficial hair cells of the lateral line sensory system, which mediate detection of directional water flow. Complementing mammalian studies, zebrafish have been used to gain significant insights into many facets of hair cell biology, including mechanotransduction and synaptic physiology as well as mechanisms of both hereditary and acquired hair cell dysfunction. Here, we provide an overview of this literature, highlighting some of the particular advantages of using zebrafish to investigate hearing and hearing loss. © 2019, Association for Research in Otolaryngology.",30635804,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85059916767
Parthasarathy A.; Romero Pinto S.; Lewis R.M.; Goedicke W.; Polley D.B.,"Parthasarathy, Aravindakshan (55213012500); Romero Pinto, Sandra (57216523452); Lewis, Rebecca M. (57201456258); Goedicke, William (57214075305); Polley, Daniel B. (6701823573)",55213012500; 57216523452; 57201456258; 57214075305; 6701823573,Data-driven segmentation of audiometric phenotypes across a large clinical cohort,2020,Scientific Reports,10,1,6704,,,,23,10.1038/s41598-020-63515-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083804700&doi=10.1038%2fs41598-020-63515-5&partnerID=40&md5=8d45393201a862d132786d340181e253,"Pure tone audiograms are used to assess the degree and underlying source of hearing loss. Audiograms are typically categorized into a few canonical types, each thought to reflect distinct pathologies of the ear. Here, we analyzed 116,400 patient records from our clinic collected over a 24-year period and found that standard categorization left 46% of patient records unclassified. To better account for the full spectrum of hearing loss profiles, we used a Gaussian Mixture Model (GMM) to segment audiograms without any assumptions about frequency relationships, interaural symmetry or etiology. The GMM converged on ten types, featuring varying degrees of high-frequency hearing loss, flat loss, mixed loss, and notched profiles, with predictable relationships to patient age and sex. A separate GMM clustering of 15,380 audiograms from the National Health and Nutrition Examination Survey (NHANES) identified six similar types, that only lacked the more extreme hearing loss configurations observed in our patient cohort. Whereas traditional approaches distill hearing loss configurations down to a few canonical types by disregarding much of the underlying variability, an objective probabilistic model that accounted for all of the data identified an organized, but more heterogenous set of audiogram types that was consistent across two large clinical databases. © 2020, The Author(s).",32317648,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85083804700
Shoushtarian M.; Alizadehsani R.; Khosravi A.; Acevedo N.; McKay C.M.; Nahavandi S.; Fallon J.B.,"Shoushtarian, Mehrnaz (57201491759); Alizadehsani, Roohallah (55328861400); Khosravi, Abbas (56234594800); Acevedo, Nicola (57200082414); McKay, Colette M. (7101952184); Nahavandi, Saeid (55992860000); Fallon, James B. (9435651900)",57201491759; 55328861400; 56234594800; 57200082414; 7101952184; 55992860000; 9435651900,Objective measurement of tinnitus using functional near-infrared spectroscopy and machine learning,2020,PLoS ONE,15,11-Nov,e0241695,,,,26,10.1371/journal.pone.0241695,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096407620&doi=10.1371%2fjournal.pone.0241695&partnerID=40&md5=af155a6a66795729a65f6f93250bd219,"Chronic tinnitus is a debilitating condition which affects 10–20% of adults and can severely impact their quality of life. Currently there is no objective measure of tinnitus that can be used clinically. Clinical assessment of the condition uses subjective feedback from individuals which is not always reliable. We investigated the sensitivity of functional near-infrared spectroscopy (fNIRS) to differentiate individuals with and without tinnitus and to identify fNIRS features associated with subjective ratings of tinnitus severity. We recorded fNIRS signals in the resting state and in response to auditory or visual stimuli from 25 individuals with chronic tinnitus and 21 controls matched for age and hearing loss. Severity of tinnitus was rated using the Tinnitus Handicap Inventory and subjective ratings of tinnitus loudness and annoyance were measured on a visual analogue scale. Following statistical group comparisons, machine learning methods including feature extraction and classification were applied to the fNIRS features to classify patients with tinnitus and controls and differentiate tinnitus at different severity levels. Resting state measures of connectivity between temporal regions and frontal and occipital regions were significantly higher in patients with tinnitus compared to controls. In the tinnitus group, temporal-occipital connectivity showed a significant increase with subject ratings of loudness. Also in this group, both visual and auditory evoked responses were significantly reduced in the visual and auditory regions of interest respectively. Naïve Bayes classifiers were able to classify patients with tinnitus from controls with an accuracy of 78.3%. An accuracy of 87.32% was achieved using Neural Networks to differentiate patients with slight/ mild versus moderate/ severe tinnitus. Our findings show the feasibility of using fNIRS and machine learning to develop an objective measure of tinnitus. Such a measure would greatly benefit clinicians and patients by providing a tool to objectively assess new treatments and patients’ treatment progress. © 2020 Shoushtarian et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",33206675,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096407620
Mosqueda Cárdenas E.; de la Rosa Gutiérrez J.P.; Aguilar Lobo L.M.; Ochoa Ruiz G.,"Mosqueda Cárdenas, Edgar (57209639080); de la Rosa Gutiérrez, José P. (57209642006); Aguilar Lobo, Lina María (35331718100); Ochoa Ruiz, Gilberto (55388097000)",57209639080; 57209642006; 35331718100; 55388097000,Automatic Detection and Classification of Hearing Loss Conditions Using an Artificial Neural Network Approach,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11524 LNCS,,,227,237,10,4,10.1007/978-3-030-21077-9_21,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068345233&doi=10.1007%2f978-3-030-21077-9_21&partnerID=40&md5=fe3962219465311e9402549cde38e189,"The auditory dysfunction is one of the most frequent disabilities, this condition can be diagnosed with an electroencephalogram modality called auditory evoked potentials (AEP). In this paper, we present a machine learning implementation to automatically detect and classify hearing loss conditions based on features extracted from synthetically generated brainstem auditory evoked potentials, a necessity given the scarcity of full-fledged datasets. The approach is based on a multi-player perceptron, which has demonstrated to be a useful and powerful tool in this domain. Preliminary results show very encouraging results, with accuracy results above 90% for a variety of hearing loss conditions; this system is to be deployed as hardware implementation for creating an affordable and portable medical device, as reported in previous work. © 2019, Springer Nature Switzerland AG.",,Conference paper,Final,,Scopus,2-s2.0-85068345233
Menchaca A.; dos Santos-Neto P.C.; Souza-Neves M.; Cuadro F.; Mulet A.P.; Tesson L.; Chenouard V.; Guiffès A.; Heslan J.M.; Gantier M.; Anegón I.; Crispo M.,"Menchaca, A. (6603616921); dos Santos-Neto, P.C. (56276450800); Souza-Neves, M. (57206848584); Cuadro, F. (55555840700); Mulet, A.P. (56276409900); Tesson, L. (6701460138); Chenouard, V. (56373016100); Guiffès, A. (57216091309); Heslan, J.M. (6604007474); Gantier, M. (57191844865); Anegón, I. (57207558963); Crispo, M. (15032583900)",6603616921; 56276450800; 57206848584; 55555840700; 56276409900; 6701460138; 56373016100; 57216091309; 6604007474; 57191844865; 57207558963; 15032583900,Otoferlin gene editing in sheep via CRISPR-assisted ssODN-mediated Homology Directed Repair,2020,Scientific Reports,10,1,5995,,,,19,10.1038/s41598-020-62879-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083278939&doi=10.1038%2fs41598-020-62879-y&partnerID=40&md5=13f3c0b9b39b7df09c14d8473e8b6fa1,"Different mutations of the OTOF gene, encoding for otoferlin protein expressed in the cochlear inner hair cells, induces a form of deafness that is the major cause of nonsyndromic recessive auditory neuropathy spectrum disorder in humans. We report the generation of the first large animal model of OTOF mutations using the CRISPR system associated with different Cas9 components (mRNA or protein) assisted by single strand oligodeoxynucleotides (ssODN) to induce homology-directed repair (HDR). Zygote microinjection was performed with two sgRNA targeting exon 5 and 6 associated to Cas9 mRNA or protein (RNP) at different concentrations in a mix with an ssODN template targeting HDR in exon 5 containing two STOP sequences. A total of 73 lambs were born, 13 showing indel mutations (17.8%), 8 of which (61.5%) had knock-in mutations by HDR. Higher concentrations of Cas9-RNP induced targeted mutations more effectively, but negatively affected embryo survival and pregnancy rate. This study reports by the first time the generation of OTOF disrupted sheep, which may allow better understanding and development of new therapies for human deafness related to genetic disorders. These results support the use of CRISPR/Cas system assisted by ssODN as an effective tool for gene editing in livestock. © 2020, The Author(s).",32265471,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85083278939
Danga K.; Leb T.,"Danga, Khang (57225186236); Leb, Tuyen (57187647600)",57225186236; 57187647600,A novel audio-based machine learning model for automated detection of collision hazards at construction sites,2020,"Proceedings of the 37th International Symposium on Automation and Robotics in Construction, ISARC 2020: From Demonstration to Practical Use - To New Stage of Construction Robot",,,,829,835,6,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109376926&partnerID=40&md5=6801602426138ce5a5832efb8248435a,"Collisions between workers and operating vehicles are the leading source of fatal incidents in the construction industry. One of the most prevalent factors causing contact hazards is the decline in construction workers' auditory situational awareness due to the hearing loss and the complicated nature of construction noises. Thus, a computational technique that can augment the audible sense of a worker can significantly improve safety performance. Since construction machines often generate distinct sound patterns while operating at the construction sites, audio signal processing could be an innovative solution to achieve the goal. Unfortunately, the current body of knowledge regarding automated surveillance in construction still lacks such advanced methods. This paper presents a newly developed auditory surveillance framework using convolutional neural networks (CNNs) that can detect collision hazards by processing acoustic signals in construction sites. The study specifically has two primary contributions: (1) a new labeled dataset of normal and abnormal sound events relating to collision hazards in the construction site, and (2) a novel audio-based machine learning model for automated detection of collision hazards. The model was trained with different network architectures, and its performance was evaluated using various measures, including accuracy, recall, precision, and combined F-measure. The research is expected to help increase the auditory situational awareness of construction workers and consequently enhance construction safety. © 2020 Proceedings of the 37th International Symposium on Automation and Robotics in Construction, ISARC 2020: From Demonstration to Practical Use - To New Stage of Construction Robot. All rights reserved.",,Conference paper,Final,,Scopus,2-s2.0-85109376926
Fidan V.,"Fidan, Vural (30767467000)",30767467000,New type of corona virus induced acute otitis media in adult,2020,American Journal of Otolaryngology - Head and Neck Medicine and Surgery,41,3,102487,,,,69,10.1016/j.amjoto.2020.102487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083583354&doi=10.1016%2fj.amjoto.2020.102487&partnerID=40&md5=ae315706446588ab5e3a22cccb55cfe5,"Since late December 2019, a new type of coronavirus (CIVID-19) causing a cluster of respiratory infections was first identified in Wuhan-China. And it disseminated to all countries. Generally, COVID-19 cases have fever, cough, respiratory distress findings (dyspnoea, intercostal retraction, cyanosis etc.). In this paper, we have presented an adult otitis media case whom infected with COVID-19, but she have not any classical COVID-19 symptoms. © 2020 Elsevier Inc.",32336572,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85083583354
Duan D.; Dal L.; Qiu C.; Iiuung T.; Tang S.; Liu Y.,"Duan, Danping (58436529300); Dal, Luxi (58763556100); Qiu, Congxi (57217850469); Iiuung, Tingyuan (58762739800); Tang, Shijuio (57217856985); Liu, Yimin (57192560973)",58436529300; 58763556100; 57217850469; 58762739800; 57217856985; 57192560973,Combined effect of noise and hand-transmitted vibration on noise-induced hearing loss in the automobile manufacturing industry; [噪声与手传振动联合作用对噪声性听力损失的影响],2020,Chinese Journal of Industrial Hygiene and Occupational Diseases,38,6,,420,423,3,2,10.3760/cma.j.cn121094-20191009-00470,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087737955&doi=10.3760%2fcma.j.cn121094-20191009-00470&partnerID=40&md5=a2434deab473310bfd924081e4fa06b0,"ObjectiveTo investigate the combined effect of noise and hand-transmitted vibration on noise-induced hearing loss (NIHL) in the automobile manufacturing industry. MethodsFrom September 2018 to January 2019, cluster sampling was used to select 998 workers in an automobile factory as study subjects, among whom 352 workers exposed to noise alone were enrolled as noise group, 342 workers exposed to noise and hand-transmitted vibration were enrolled as combined effect group, and 304 workers without exposure to occupational hazardous factors were enrolled as control group. A questionnaire survey and pure tone audiometry were performed for all study subjects. An analysis of variance was used for comparison of continuous data between groups, and the chi-square test was used for comparison of categorical data between groups; a ordinal polytomous logistic regression analysis was used to investigate the influencing factors for NIHL (with 0.05 as the inclusion criteria and 0.10 as the exclusion criteria for independent variables) . ResultsThere was a significant difference in LAeq, 8 h between groups (P<0.05) ; the noise group and the combined effect group had a significantly higher LAeq, 8 h than the control group (P<0.05) , while there was no significant difference in LAeq, 8 h between the noise group and the combined effect group (P>0.05) . The control group had a significantly lower detection rate of hearing loss than the noise group and the combined effect group (P<0.0125) , and the combined effect group had a significantly higher detection rate of hearing loss than the noise group (P<0.0125) . The ordinal polytomous logistic regression analysis showed that after adjustment for confounding factors such as age, working years, sex, smoking, and drinking, both noise exposure and exposure to both noise and hand-transmitted vibration had an influence on workers' hearing (P<0.05) , and the workers exposed to both noise and hand-transmitted vibration had a higher risk of hearing loss than those exposed to noise alone. ConclusionThere may be a combined effect of noise and hand-transmitted vibration in the automobile manufacturing industry, which can increase the risk of NIHL in workers. © 2020 Chinese Medical Journals Publishing House Co.Ltd",32629569,Article,Final,,Scopus,2-s2.0-85087737955
Macnamara E.F.; Koehler A.E.; D'Souza P.; Estwick T.; Lee P.; Vezina G.; Fauni H.; Braddock S.R.; Torti E.; Holt J.M.; Sharma P.; Malicdan M.C.V.; Tifft C.J.,"Macnamara, Ellen F. (57191572448); Koehler, Alanna E. (57191581749); D'Souza, Precilla (57197886675); Estwick, Tyra (26633742800); Lee, Paul (56117198300); Vezina, Gilbert (6701753304); Fauni, Harper (57201446826); Braddock, Stephen R. (6604049752); Torti, Erin (56008508900); Holt, James Matthew (14622686500); Sharma, Prashant (57191569566); Malicdan, May Christine V. (58414270700); Tifft, Cynthia J. (7003867536)",57191572448; 57191581749; 57197886675; 26633742800; 56117198300; 6701753304; 57201446826; 6604049752; 56008508900; 14622686500; 57191569566; 58414270700; 7003867536,Kilquist syndrome: A novel syndromic hearing loss disorder caused by homozygous deletion of SLC12A2,2019,Human Mutation,40,5,,532,538,6,31,10.1002/humu.23722,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062797843&doi=10.1002%2fhumu.23722&partnerID=40&md5=e73b40ecad3f4f496ef66a9223887bfc,"Syndromic sensorineural hearing loss is multigenic and associated with malformations of the ear and other organ systems. Herein we describe a child admitted to the NIH Undiagnosed Diseases Program with global developmental delay, sensorineural hearing loss, gastrointestinal abnormalities, and absent salivation. Next-generation sequencing revealed a uniparental isodisomy in chromosome 5, and a 22 kb homozygous deletion in SLC12A2, which encodes for sodium, potassium, and chloride transporter in the basolateral membrane of secretory epithelia. Functional studies using patient-derived fibroblasts showed truncated SLC12A2 transcripts and markedly reduced protein abundance when compared with control. Loss of Slc12a2 in mice has been shown to lead to deafness, abnormal neuronal growth and migration, severe gastrointestinal abnormalities, and absent salivation. Together with the described phenotype of the Slc12a2-knockout mouse model, our results suggest that the absence of functional SLC12A2 causes a new genetic syndrome and is crucial for the development of auditory, neurologic, and gastrointestinal tissues. © 2019 Wiley Periodicals, Inc.",30740830,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85062797843
Keshavarzi M.; Reichenbach T.,"Keshavarzi, Mahmoud (55657249300); Reichenbach, Tobias (14060798600)",55657249300; 14060798600,Transcranial Alternating Current Stimulation With the Theta-Band Portion of the Temporally-Aligned Speech Envelope Improves Speech-in-Noise Comprehension,2020,Frontiers in Human Neuroscience,14,,187,,,,8,10.3389/fnhum.2020.00187,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086433988&doi=10.3389%2ffnhum.2020.00187&partnerID=40&md5=895fb2a2ba26fd59a9330f27d2da8e5d,"Transcranial alternating current stimulation with the speech envelope can modulate the comprehension of speech in noise. The modulation stems from the theta- but not the delta-band portion of the speech envelope, and likely reflects the entrainment of neural activity in the theta frequency band, which may aid the parsing of the speech stream. The influence of the current stimulation on speech comprehension can vary with the time delay between the current waveform and the audio signal. While this effect has been investigated for current stimulation based on the entire speech envelope, it has not yet been measured when the current waveform follows the theta-band portion of the speech envelope. Here, we show that transcranial current stimulation with the speech envelope filtered in the theta frequency band improves speech comprehension as compared to a sham stimulus. The improvement occurs when there is no time delay between the current and the speech stimulus, as well as when the temporal delay is comparatively short, 90 ms. In contrast, longer delays, as well as negative delays, do not impact speech-in-noise comprehension. Moreover, we find that the improvement of speech comprehension at no or small delays of the current stimulation is consistent across participants. Our findings suggest that cortical entrainment to speech is most influenced through current stimulation that follows the speech envelope with at most a small delay. They also open a path to enhancing the perception of speech in noise, an issue that is particularly important for people with hearing impairment. © Copyright © 2020 Keshavarzi and Reichenbach.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85086433988
Incerti P.V.; Ching T.Y.C.; Cowan R.,"Incerti, Paola V (6603614560); Ching, Teresa YC (35423324600); Cowan, Robert (35551636700)",6603614560; 35423324600; 35551636700,The effect of cross-over frequency on binaural hearing performance of adults using electric-acoustic stimulation,2019,Cochlear Implants International,,,,,,,2,10.1080/14670100.2019.1590499,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063037782&doi=10.1080%2f14670100.2019.1590499&partnerID=40&md5=b35b1fae86a60409925f799f886a33ae,"Objective: To investigate the effect of varying cross-over frequency (CF) settings for electric-acoustic (EA) stimulation in one ear combined with acoustic (A) hearing in the opposite ear on binaural speech perception, localization and functional performance in real life. Methods: Performance with three different CF settings set according to audiometric-based criterion were compared, following a four week familiarisation period with each, in ten adult cochlear implant recipients with residual hearing in both ears. On completion of all trials participants selected their preferred CF setting. Results: On average, CF settings did not have a significant effect on performance scores. However, higher ratings on device usage were associated with the preferred CF settings. Conclusion: Individuals who use EA + A stimulation may benefit from access to different CF settings to achieve maximal device usage. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",30880646,Article,Article in press,,Scopus,2-s2.0-85063037782
"James L.S.; Davies R., Jr.; Mori C.; Wada K.; Sakata J.T.","James, Logan S. (56400189000); Davies, Ronald (57216966960); Mori, Chihiro (55744638600); Wada, Kazuhiro (7401668299); Sakata, Jon T. (7006577724)",56400189000; 57216966960; 55744638600; 7401668299; 7006577724,Manipulations of sensory experiences during development reveal mechanisms underlying vocal learning biases in zebra finches,2020,Developmental Neurobiology,80,03-Apr,,132,146,14,8,10.1002/dneu.22754,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085557410&doi=10.1002%2fdneu.22754&partnerID=40&md5=f3e6c5336c58126791071a47c033b853,"Biological predispositions in learning can bias and constrain the cultural evolution of social and communicative behaviors (e.g., speech and birdsong), and lead to the emergence of behavioral and cultural “universals.” For example, surveys of laboratory and wild populations of zebra finches (Taeniopygia guttata) document consistent patterning of vocal elements (“syllables”) with respect to their acoustic properties (e.g., duration, mean frequency). Furthermore, such universal patterns are also produced by birds that are experimentally tutored with songs containing randomly sequenced syllables (“tutored birds”). Despite extensive demonstrations of learning biases, much remains to be uncovered about the nature of biological predispositions that bias song learning and production in songbirds. Here, we examined the degree to which “innate” auditory templates and/or biases in vocal motor production contribute to vocal learning biases and production in zebra finches. Such contributions can be revealed by examining acoustic patterns in the songs of birds raised without sensory exposure to song (“untutored birds”) or of birds that are unable to hear from early in development (“early-deafened birds”). We observed that untutored zebra finches and early-deafened zebra finches produce songs with positional variation in some acoustic features (e.g., mean frequency) that resemble universal patterns observed in tutored birds. Similar to tutored birds, early-deafened birds also produced song motifs with alternation in acoustic features across adjacent syllables. That universal acoustic patterns are observed in the songs of both untutored and early-deafened birds highlights the contribution motor production biases to the emergence of universals in culturally transmitted behaviors. © 2020 Wiley Periodicals, LLC",32330360,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85085557410
Sun Z.; Seo J.W.; Lee J.Y.; Kwak M.Y.; Kim Y.; Lee J.Y.; Toga A.W.; Park H.J.; Kim H.,"Sun, Zhe (57211431742); Seo, Ji Won (57205162191); Lee, Jee Yeon (57206734003); Kwak, Min Young (57205166252); Kim, Yehree (57195399872); Lee, Je Yeon (57202608969); Toga, Arthur W. (35412870200); Park, Hong Ju (57213039619); Kim, Hosung (56245794300)",57211431742; 57205162191; 57206734003; 57205166252; 57195399872; 57202608969; 35412870200; 57213039619; 56245794300,Random forest regression combined with MRI brain morphometry predicts surgical outcome of cochlear implantation,2019,Proceedings - International Symposium on Biomedical Imaging,2019-April,,8759541,360,363,3,1,10.1109/ISBI.2019.8759541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073902005&doi=10.1109%2fISBI.2019.8759541&partnerID=40&md5=620b67893a5f20ca69caaba8f3549067,"Long-term hearing loss in post-lingually deaf adults may lead to progressive structural changes in the cerebral cortices where auditory and language functions are processed. These alterations may affect the outcome of the cochlear implant (CI) surgery. In our study, we aim to predict the surgery outcome using imaging features that characterize such cortical structural changes. We used voxel-based morphometry approach to calculate the brain GM density. To reconstruct a smaller feature-set while collapsing the number of voxel-wise GM density values, we applied an anatomically hypothesized ROI-based method and a data-driven cluster-based method. We fed the reconstructed features to a Random-Forest Regression model combined with clinical features. We observed that the cluster-based method outperformed the ROI-based method and proved the competence of the image features in CI outcome prediction. Our data-driven approach found that the most accurate prediction was made with the clusters of GM density changes in the middle temporal cortex, a critical network node of language processing, and in the thalamus, a structure (dis-)engaging and (de-)coupling cortical language operations. © 2019 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85073902005
Loughrey D.G.; Pakhomov S.V.S.; Lawlor B.A.,"Loughrey, David G. (57194744008); Pakhomov, Serguei V.S. (55655567400); Lawlor, Brian A. (57214358440)",57194744008; 55655567400; 57214358440,Altered verbal fluency processes in older adults with age-related hearing loss,2020,Experimental Gerontology,130,,110794,,,,11,10.1016/j.exger.2019.110794,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075794693&doi=10.1016%2fj.exger.2019.110794&partnerID=40&md5=4729dc6d18cbc262e4ac312385a3778c,"Epidemiological studies have linked age-related hearing loss (ARHL) with an increased risk of neurocognitive decline. Difficulties in speech perception with subsequent changes in brain morphometry, including regions important for lexical-semantic memory, are thought to be a possible mechanism for this relationship. This study investigated differences in automatic and executive lexical-semantic processes on verbal fluency tasks in individuals with acquired hearing loss. The primary outcomes were indices of automatic (clustering/word retrieval at start of task) and executive (switching/word retrieval after start of the task) processes from semantic and phonemic fluency tasks. To extract indices of clustering and switching, we used both manual and computerised methods. There were no differences between groups on indices of executive fluency processes or on any indices from the semantic fluency task. The hearing loss group demonstrated weaker automatic processes on the phonemic fluency task. Further research into differences in lexical-semantic processes with ARHL is warranted. © 2019 Elsevier Inc.",31790801,Article,Final,,Scopus,2-s2.0-85075794693
Buhl M.; Warzybok A.; Schädler M.R.; Lenarz T.; Majdani O.; Kollmeier B.,"Buhl, Mareike (57207939883); Warzybok, Anna (36081535600); Schädler, Marc René (55312455700); Lenarz, Thomas (35227565300); Majdani, Omid (23479973000); Kollmeier, Birger (7006746726)",57207939883; 36081535600; 55312455700; 35227565300; 23479973000; 7006746726,Common Audiological Functional Parameters (CAFPAs): statistical and compact representation of rehabilitative audiological classification based on expert knowledge,2019,International Journal of Audiology,58,4,,231,245,14,8,10.1080/14992027.2018.1554912,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063273539&doi=10.1080%2f14992027.2018.1554912&partnerID=40&md5=b152403011ccf0970c527e704a1eb7d5,"Objective: As a step towards objectifying audiological rehabilitation and providing comparability between different test batteries and clinics, the Common Audiological Functional Parameters (CAFPAs) were introduced as a common and abstract representation of audiological knowledge obtained from diagnostic tests. Design: Relationships between CAFPAs as an intermediate representation between diagnostic tests and audiological findings, diagnoses and treatment recommendations (summarised as “diagnostic cases”) were established by means of an expert survey. Expert knowledge was collected for 14 given categories covering different diagnostic cases. For each case, the experts were asked to indicate expected ranges of diagnostic test outcomes, as well as traffic light-encoded CAFPAs. Study sample: Eleven German experts in the field of audiological rehabilitation from Hanover and Oldenburg participated in the survey. Results: Audiological findings or treatment recommendations could be distinguished by a statistical model derived from the experts' answers for CAFPAs as well as audiological tests. Conclusions: The CAFPAs serve as an abstract, comprehensive representation of audiological knowledge. If more detailed information on certain functional aspects of the auditory system is required, the CAFPAs indicate which information is missing. The statistical graphical representations for CAFPAs and audiological tests are suitable for audiological teaching material; they are universally applicable for real clinical databases. © 2019, © 2019 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",30900518,Article,Final,,Scopus,2-s2.0-85063273539
Mahmud M.S.; Ahmed F.; Yeasin M.; Alain C.; Bidelman G.M.,"Mahmud, Md Sultan (57195770993); Ahmed, Faruk (57196026885); Yeasin, Mohammed (18039042000); Alain, Claude (7006562076); Bidelman, Gavin M. (26325449700)",57195770993; 57196026885; 18039042000; 7006562076; 26325449700,Multivariate Models for Decoding Hearing Impairment using EEG Gamma-Band Power Spectral Density,2020,Proceedings of the International Joint Conference on Neural Networks,,,9206731,,,,12,10.1109/IJCNN48605.2020.9206731,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093868427&doi=10.1109%2fIJCNN48605.2020.9206731&partnerID=40&md5=9fb26d57fd972d0d3b40757afc3c5e51,"Speech-in-noise (SIN) comprehension decreases with age, and these declines have been related to social isolation, depression, and dementia in the elderly. In this work, we build models to distinguish the normal hearing (NH) or mild hearing impairment (HI) using the different genres of machine learning. We compute band wise power spectral density (PSD) of source- derived EEGs as features in building models using support vector machine (SVM), k-nearest neighbors (KNN), and AdaBoost classifiers and compare their performance while listeners perceived clear or noise-degraded sounds. Combining all frequency bands features obtained from the whole-brain, the SVM registered the best performance. The group classification accuracy was found to be 94.90% [area under the curve (AUC) 94.75%; F1-score 95.00%] perceived the clear speech, and for noise- degraded speech perception, accuracy was found to be 92.52% (AUC 91.12%, and F1-score 93.00%). Remarkably, individual frequency band analysis on whole-brain data showed that γ frequency band segregated groups with a best accuracy of 96.78%, AUC 96.79% for clear speech data and noise-degraded speech data yielded slightly less accuracy of 93.62% with AUC 93.17% by using SVM. A separate analysis using the left hemisphere (LH) and right hemisphere (RH) data showed that the LH activity is a better predictor of groups compared to RH. These results are consistent with the dominance of LH in auditory-linguistic processing. Our results demonstrate that spectral features of the γ-band frequency could be used to differentiate NH and HI older adults in terms of their ability to process speech sounds. These findings would be useful to model attentional and listening assistive devices to amplify a more specific pitch than others. © 2020 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85093868427
Diener M.L.; Shi K.; Park A.H.,"Diener, Marissa L. (7005745954); Shi, Kevin (57213621593); Park, Albert H. (7201557009)",7005745954; 57213621593; 7201557009,A Cross-Sectional Study of Caregiver Perceptions of Congenital Cytomegalovirus Infection: Knowledge and Attitudes about Screening,2020,Journal of Pediatrics,218,,,151,1.56E+04,,5,10.1016/j.jpeds.2019.12.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077932658&doi=10.1016%2fj.jpeds.2019.12.005&partnerID=40&md5=b675fdc1bde3849d532f7fc1e9b342cd,"Objectives: To understand caregiver knowledge of and attitudes toward congenital cytomegalovirus (cCMV) testing in Utah. Study design: We surveyed 365 caregivers whose children were being seen in an otolaryngology clinic at a tertiary pediatric hospital about their knowledge of and attitudes toward cCMV and cCMV screening. Descriptive statistics and cluster analysis were used to examine their responses. Results: The majority of caregivers were unsure how cCMV was spread, the symptoms of cCMV, and why cCMV screening of infants was important. Most caregivers did not know that cCMV screening was required by law in Utah if an infant is referred after newborn hearing screening. A majority wanted to know if their child had cCMV even if asymptomatic and were willing to pay $20 for cCMV screening. Caregivers of children who had been tested for cCMV were significantly more likely to be strongly in favor of cCMV screening than expected by chance. Caregivers in the highly knowledgeable cluster were more likely to be strongly in favor of cCMV screening. Conclusions: Caregivers frequently were unaware of cCMV and its implications. Attitudes toward cCMV screening generally were positive. Education on epidemiology and impact of cCMV may benefit both prevention of infection and attitudes toward screening. © 2019 Elsevier Inc.",31952844,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85077932658
Neuschwander P.; Hänggi J.; Zekveld A.A.; Meyer M.,"Neuschwander, Pia (57206775028); Hänggi, Jürgen (12243647500); Zekveld, Adriana A. (8641362500); Meyer, Martin (7403185338)",57206775028; 12243647500; 8641362500; 7403185338,Cortical thickness of left Heschl's gyrus correlates with hearing acuity in adults – A surface-based morphometry study,2019,Hearing Research,384,,107823,,,,17,10.1016/j.heares.2019.107823,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074128016&doi=10.1016%2fj.heares.2019.107823&partnerID=40&md5=70e7b419fa8be314cdb5f903c9f3ca37,"To date, research examining the relationship between brain structure and hearing acuity is sparse, especially given the context of a broad age range. To investigate this relationship, we applied an automated surface-based morphometry (SBM) approach (FreeSurfer) in this study to re-examine a sample of normal-hearing (n = 17) and hearing-impaired (n = 17) age- and education-matched adults, aged between 20 and 63 years (Alfandari et al., 2018). The SBM approach allows the disentanglement of cortical surface area (CSA) from cortical thickness (CT), the 2 independent constituents of cortical volume (CV). We extend the findings of Alfandari and colleagues by showing several clusters in auditory-related areas as well as in the left and right angular gyrus that showed reduced CT, CSA and CV in hearing-impaired compared to normal-hearing listeners. Nevertheless, none of the clusters found correlated significantly with hearing acuity, measured by pure-tone thresholds, in the 2 groups. An additional vertex-wise correlation analysis between hearing acuity and morphometric parameters over all participants revealed a single significant cluster encompassing the left Heschl's gyrus. Higher hearing thresholds were associated with a thinner cortex within this cluster. Our results imply that hearing impairment is associated with reduced thickness in primary and secondary auditory cortex regions, those regions especially involved in perceiving and processing relevant speech cues. This decrease was observed not only in older but also in younger and middle-aged adults, independent of age-related decline in the cognitive domain and age-dependent whole-brain atrophy. Further, the results show the value added when considering CV, CT and CSA separately, relative to previous studies which have solely relied on voxel-based morphometry to investigate brain structure and hearing acuity across the lifespan. © 2019 Elsevier B.V.",31678891,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074128016
Germundsson P.; Manchaiah V.; Ratinaud P.; Tympas A.; Danermark B.,"Germundsson, Per (49963580200); Manchaiah, Vinaya (35330310500); Ratinaud, Pierre (55576099800); Tympas, Aristotle (6505849765); Danermark, Berth (57205891374)",49963580200; 35330310500; 55576099800; 6505849765; 57205891374,Patterns in the social representation of “hearing loss” across countries: how do demographic factors influence this representation?,2018,International Journal of Audiology,57,12,,925,932,7,6,10.1080/14992027.2018.1516894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057085145&doi=10.1080%2f14992027.2018.1516894&partnerID=40&md5=d1c79c8ab68343d9126249f556179cfd,"This study aims to understand patterns in the social representation of hearing loss reported by adults across different countries and explore the impact of different demographic factors on response patterns. The study used a cross-sectional survey design. Data were collected using a free association task and analysed using qualitative content analysis, cluster analysis and chi-square analysis. The study sample included 404 adults (18 years and over) in the general population from four countries (India, Iran, Portugal and UK). The cluster analysis included 380 responses out of 404 (94.06%) and resulted in five clusters. The clusters were named: (1) individual aspects; (2) aetiology; (3) the surrounding society; (4) limitations and (5) exposed. Various demographic factors (age, occupation type, education and country) showed an association with different clusters, although country of origin seemed to be associated with most clusters. The study results suggest that how hearing loss is represented in adults in general population varies and is mainly related to country of origin. These findings strengthen the argument about cross-cultural differences in perception of hearing loss, which calls for a need to make necessary accommodations while developing public health strategies about hearing loss. © 2018, © 2018 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society. Published by Informa UK Limited, trading as Taylor & Francis Group.",30468404,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85057085145
Saini S.; Kaur C.; Pal I.; Kumar P.; Jacob T.G.; Thakar A.; Roy K.K.; Roy T.S.,"Saini, Shubhi (57200734349); Kaur, Charanjeet (57212012157); Pal, Indra (57194719791); Kumar, Punit (57204239602); Jacob, Tony George (55431765800); Thakar, Alok (7004120426); Roy, Kallol Kumar (55963149000); Roy, Tara Sankar (7202953212)",57200734349; 57212012157; 57194719791; 57204239602; 55431765800; 7004120426; 55963149000; 7202953212,Morphological development of the human cochlear nucleus,2019,Hearing Research,382,,107784,,,,2,10.1016/j.heares.2019.107784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072018907&doi=10.1016%2fj.heares.2019.107784&partnerID=40&md5=a603b5ec56ec770fed9c8f5d9534fa92,"Morphological studies in developing brain determine critical periods of proliferation, neurogenesis, gliogenesis, and apoptosis. During these periods both intrinsic and extrinsic pathological factors can hamper development. These time points are not available for the human cochlear nucleus (CN). We have used design-based stereology and determined that 18–22 weeks of gestation (WG) are critical in the development of the human CN. Twenty-three fetuses and seven postnatal brainstems were processed for cresyl violet (CV) staining and immunoexpression of NeuN (neurons), GFAP (astrocytes), Ki-67 (proliferation) and TUNEL (apoptosis) and 3-D reconstruction. The volume of CN, total number of neurons selected profiles and the volume of neurons and their nuclei were estimated. Data were grouped (G) into: G1:18-20 WG, G2: 21–24 WG, G3: 25–28 WG and G4 >29 WG. The dimensions of morphologically identified neurons were also measured. The CN primordium was first identifiable at 10WG. Definitive DCN (Dorsal cochlear nucleus) and VCN (ventral cochlear nucleus) were identifiable at 16 WG. There was a sudden growth spurt in total volume of CN, number of neurons and astrocytes from 18 WG. We also observed an increase in proliferation and apoptosis after 22 WG. The number of neurons identifiable by CV was significantly lower than that by NeuN-immunostaining till 25 WG (p = 0.020), after which, both methods were equivalent. Eight morphological types of neurons were identifiable by 26 WG and could be resolved into four clusters by volume and diameter. The CN changed orientation from small, flat and horizontal at 10–16 WG to larger and oblique from 18WG onwards. Prevention of exposure to noxious factors at 18–22 WG may be important in preventing congenital deafness. © 2019 Elsevier B.V.",31522073,Article,Final,,Scopus,2-s2.0-85072018907
Albouy P.; Caclin A.; Norman-Haignere S.V.; Lévêque Y.; Peretz I.; Tillmann B.; Zatorre R.J.,"Albouy, Philippe (55682546200); Caclin, Anne (15519602000); Norman-Haignere, Sam V. (37051186800); Lévêque, Yohana (26642092800); Peretz, Isabelle (7006137534); Tillmann, Barbara (7005560313); Zatorre, Robert J. (7006534581)",55682546200; 15519602000; 37051186800; 26642092800; 7006137534; 7005560313; 7006534581,Decoding task-related functional brain imaging data to identify developmental disorders: The case of congenital amusia,2019,Frontiers in Neuroscience,13,OCT,1165,,,,11,10.3389/fnins.2019.01165,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074979629&doi=10.3389%2ffnins.2019.01165&partnerID=40&md5=4db64aa28257e570b46f25916de45a5e,"Machine learning classification techniques are frequently applied to structural and resting-state fMRI data to identify brain-based biomarkers for developmental disorders. However, task-related fMRI has rarely been used as a diagnostic tool. Here, we used structural MRI, resting-state connectivity and task-based fMRI data to detect congenital amusia, a pitch-specific developmental disorder. All approaches discriminated amusics from controls in meaningful brain networks at similar levels of accuracy. Interestingly, the classifier outcome was specific to deficit-related neural circuits, as the group classification failed for fMRI data acquired during a verbal task for which amusics were unimpaired. Most importantly, classifier outputs of task-related fMRI data predicted individual behavioral performance on an independent pitch-based task, while this relationship was not observed for structural or resting-state data. These results suggest that task-related imaging data can potentially be used as a powerful diagnostic tool to identify developmental disorders as they allow for the prediction of symptom severity. © 2019 Albouy, Caclin, Norman-Haignere, Lévêque, Peretz, Tillmann and Zatorre.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85074979629
Søgaard Jensen N.; Hau O.; Bagger Nielsen J.B.; Bundgaard Nielsen T.; Vase Legarth S.,"Søgaard Jensen, Niels (35169618000); Hau, Ole (57209208695); Bagger Nielsen, Jens Brehm (57209213162); Bundgaard Nielsen, Thor (57209215264); Vase Legarth, Søren (25422690800)",35169618000; 57209208695; 57209213162; 57209215264; 25422690800,Perceptual Effects of Adjusting Hearing-Aid Gain by Means of a Machine-Learning Approach Based on Individual User Preference,2019,Trends in Hearing,23,,,,,,23,10.1177/2331216519847413,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066867158&doi=10.1177%2f2331216519847413&partnerID=40&md5=660ef80e95ffbff9539b4769ba2bf775,"This study investigated a method to adjust hearing-aid gain by use of a machine-learning algorithm that estimates the optimal setting of gain parameters based on user preference indicated in an iterative paired-comparison procedure. Twenty hearing-impaired participants completed this procedure for 12 different sound scenarios. During the adjustment procedure, their task was to indicate a preference based on one of three sound attributes: Basic Audio Quality, Listening Comfort, or Speech Clarity. In a double-blind comparison of recordings of the processed scenarios, and using the same attributes as criteria, the adjusted gain settings were subsequently compared with two prescribed settings of the same hearing aid (with and without activation of an automatic sound-classification system). The results showed that the adjustment method provided a general improvement of Basic Audio Quality, an improvement of Listening Comfort in a traffic-noise scenario but not in three scenarios with speech babble, and no significant improvement of Speech Clarity. A large variation in gain adjustments was observed across participants, both among those who did benefit and among those who did not benefit from the adjustment. There was no clear connection between the gain adjustments and the perceived benefit, which indicates that the preferred gain settings for a given sound scenario and a given listening intention are highly individual and difficult to predict. © The Author(s) 2019.",31104581,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85066867158
Kim H.; Kang W.S.; Park H.J.; Lee J.Y.; Park J.W.; Kim Y.; Seo J.W.; Kwak M.Y.; Kang B.C.; Yang C.J.; Duffy B.A.; Cho Y.S.; Lee S.-Y.; Suh M.W.; Moon I.J.; Ahn J.H.; Cho Y.-S.; Oh S.H.; Chung J.W.,"Kim, Hosung (56245794300); Kang, Woo Seok (36165604500); Park, Hong Ju (57213039619); Lee, Jee Yeon (57206734003); Park, Jun Woo (57040126000); Kim, Yehree (57195399872); Seo, Ji Won (57205162191); Kwak, Min Young (57205166252); Kang, Byung Chul (57199669090); Yang, Chan Joo (56019649500); Duffy, Ben A. (44760948800); Cho, Young Sang (56975672700); Lee, Sang-Youp (57195594079); Suh, Myung Whan (7103253889); Moon, Il Joon (13606798300); Ahn, Joong Ho (55199119600); Cho, Yang-Sun (23471632700); Oh, Seung Ha (56582818600); Chung, Jong Woo (7404003342)",56245794300; 36165604500; 57213039619; 57206734003; 57040126000; 57195399872; 57205162191; 57205166252; 57199669090; 56019649500; 44760948800; 56975672700; 57195594079; 7103253889; 13606798300; 55199119600; 23471632700; 56582818600; 7404003342,Cochlear Implantation in Postlingually Deaf Adults is Time-sensitive Towards Positive Outcome: Prediction using Advanced Machine Learning Techniques,2018,Scientific Reports,8,1,18004,,,,33,10.1038/s41598-018-36404-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058875127&doi=10.1038%2fs41598-018-36404-1&partnerID=40&md5=b3259389831cd5fdc44ee42f53e1774f,"Given our aging society and the prevalence of age-related hearing loss that often develops during adulthood, hearing loss is a common public health issue affecting almost all older adults. Moderate-to-moderately severe hearing loss can usually be corrected with hearing aids; however, severe-to-profound hearing loss often requires a cochlear implant (CI). However, post-operative CI results vary, and the performance of the previous prediction models is limited, indicating that a new approach is needed. For postlingually deaf adults (n de120) who received CI with full insertion, we predicted CI outcomes using a Random-Forest Regression (RFR) model and investigated the effect of preoperative factors on CI outcomes. Postoperative word recognition scores (WRS) served as the dependent variable to predict. Predictors included duration of deafness (DoD), age at CI operation (ageCI), duration of hearing-aid use (DoHA), preoperative hearing threshold and sentence recognition score. Prediction accuracy was evaluated using mean absolute error (MAE) and Pearson’s correlation coefficient r between the true WRS and predicted WRS. The fitting using a linear model resulted in prediction of WRS with r = 0.7 and MAE = 15.6 ± 9. RFR outperformed the linear model (r = 0.96, MAE = 6.1 ± 4.7, p < 0.00001). Cross-hospital data validation showed reliable performance using RFR (r = 0.91, MAE = 9.6 ± 5.2). The contribution of DoD to prediction was the highest (MAE increase when omitted: 14.8), followed by ageCI (8.9) and DoHA (7.5). After CI, patients with DoD < 10 years presented better WRSs and smaller variations (p < 0.01) than those with longer DoD. Better WRS was also explained by younger age at CI and longer-term DoHA. Machine learning demonstrated a robust prediction performance for CI outcomes in postlingually deaf adults across different institutes, providing a reference value for counseling patients considering CI. Health care providers should be aware that the patients with severe-to-profound hearing loss who cannot have benefit from hearing aids need to proceed with CI as soon as possible and should continue using hearing aids until after CI operation. © 2018, The Author(s).",30573747,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85058875127
Heidari S.; Mohsenipour R.; Abbasi F.; Rabbani A.; Sayarifard F.; Enayati S.; Borhan-Dayani S.; Saadati B.; Setoodeh A.; Yaghootkar H.; Amoli M.M.,"Heidari, Solmaz (56971007100); Mohsenipour, Reihaneh (55534750000); Abbasi, Farzaneh (36668310100); Rabbani, Ali (13806862200); Sayarifard, Fatemeh (35796088700); Enayati, Samaneh (56966532300); Borhan-Dayani, Sepideh (57209687661); Saadati, B. (57208454108); Setoodeh, Aria (50562003600); Yaghootkar, Hanieh (57223117018); Amoli, Mahsa M. (6603909279)",56971007100; 55534750000; 36668310100; 13806862200; 35796088700; 56966532300; 57209687661; 57208454108; 50562003600; 57223117018; 6603909279,A case of H syndrome with a novel mutation in SLC29A3,2019,Meta Gene,21,,100599,,,,1,10.1016/j.mgene.2019.100599,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068449069&doi=10.1016%2fj.mgene.2019.100599&partnerID=40&md5=4abc6173b4ccd61217454260e070358e,"H syndrome is a hereditary disease transmitted in an autosomal recessive pattern.It consists of two major clusters of cutaneous and systemic manifestations [1,2].The symptoms include short stature, hyperpigmentation of skin, hypertrichosis, deafness, hypogonadism, anomalies of heart, hyperglycemia(insulin dependent diabetes mellitus) and hepatosplenomegaly [1]. H syndrome is the result of mutations in theSLC29A3 gene that can be homozygous or compound heterozygous. The SLC29A3 gene is located on chromosome 10q22 and encodes a transporter protein that causes passive transportation of nucleosides which is critical for several functions such as DNA and RNA repair [3–5]. Several different mutations withinSLC29A3 can cause H syndrome. In this report, we present a 4.5 year old girl diagnosed with H syndrome based on genetic investigation. © 2019",,Article,Final,,Scopus,2-s2.0-85068449069
Newall J.P.; Martinez N.; Swanepoel D.W.; McMahon C.M.,"Newall, John P. (56528072000); Martinez, Norberto (15925738500); Swanepoel, De Wet (13609471200); McMahon, Catherine M. (7202819523)",56528072000; 15925738500; 13609471200; 7202819523,A National Survey of Hearing Loss in the Philippines,2020,Asia-Pacific Journal of Public Health,32,5,,235,241,6,4,10.1177/1010539520937086,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087286944&doi=10.1177%2f1010539520937086&partnerID=40&md5=cf03ccff010deafe833e4757a7e647d4,"This study aimed to estimate the prevalence of hearing loss in the Philippines using a nationally representative sample. A cross-sectional national survey was undertaken utilizing a 3-stage stratified cluster design. Participants in the present study comprised 2275 adults and children with pure tone hearing assessment results. Prevalence of moderate or worse hearing loss, defined as 4FA ≥41 dBHL, was 7.5% in children <18 years, 14.7% in adults between 18 and 65 years, and 49.1% in adults >65 years. Factors associated with greater risk of moderate hearing loss in the better ear were presence of a middle ear condition (adjusted odds ratio = 2.39, 95% confidence interval = 1.49-3.85) and socioeconomic status (household income; adjusted odds ratio = 1.64, 95% confidence interval = 1.23-2.19). Age was also associated with increased risk, with adjusted odds ratios varying with age category. Prevalence of wax occlusion and outer and middle ear disease was 12.2% and 14.2%, respectively. Prevalence of hearing loss, outer, and middle ear disease appear comparatively high in the Philippines when compared with rates reported in high-income countries. Higher proportions of severe to profound hearing loss were also identified, indicating that there is both an increased prevalence and severity of hearing loss in this population. © 2020 APJPH.",32608243,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85087286944
Nisar S.; Tariq M.; Adeel A.; Gogate M.; Hussain A.,"Nisar, Shibli (57190176448); Tariq, Muhammad (57188704876); Adeel, Ahsan (55050917800); Gogate, Mandar (57200280664); Hussain, Amir (19734290900)",57190176448; 57188704876; 55050917800; 57200280664; 19734290900,Cognitively Inspired Feature Extraction and Speech Recognition for Automated Hearing Loss Testing,2019,Cognitive Computation,11,4,,489,502,13,18,10.1007/s12559-018-9607-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061590715&doi=10.1007%2fs12559-018-9607-4&partnerID=40&md5=42a03886f658aa336376be033d49964f,"Hearing loss, a partial or total inability to hear, is one of the most commonly reported disabilities. A hearing test can be carried out by an audiologist to assess a patient’s auditory system. However, the procedure requires an appointment, which can result in delays and practitioner fees. In addition, there are often challenges associated with the unavailability of equipment and qualified practitioners, particularly in remote areas. This paper presents a novel idea that automatically identifies any hearing impairment based on a cognitively inspired feature extraction and speech recognition approach. The proposed system uses an adaptive filter bank with weighted Mel-frequency cepstral coefficients for feature extraction. The adaptive filter bank implementation is inspired by the principle of spectrum sensing in cognitive radio that is aware of its environment and adapts to statistical variations in the input stimuli by learning from the environment. Comparative performance evaluation demonstrates the potential of our automated hearing test method to achieve comparable results to the clinical ground truth, established by the expert audiologist’s tests. The overall absolute error of the proposed model when compared with the expert audiologist test is less than 4.9 dB and 4.4 dB for the pure tone and speech audiometry tests, respectively. The overall accuracy achieved is 96.67% with a hidden Markov model (HMM). The proposed method potentially offers a second opinion to audiologists, and serves as a cost-effective pre-screening test to predict hearing loss at an early stage. In future work, authors intend to explore the application of advanced deep learning and optimization approaches to further enhance the performance of the automated testing prototype considering imperfect datasets with real-world background noise. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85061590715
van Vugt F.T.; Near J.; Hennessy T.; Doyon J.; Ostry D.J.,"van Vugt, F.T. (55035786400); Near, J. (37026802100); Hennessy, T. (57033758400); Doyon, J. (7005584295); Ostry, D.J. (7003953201)",55035786400; 37026802100; 57033758400; 7005584295; 7003953201,Early stages of sensorimotor map acquisition: Neurochemical signature in primary motor cortex and its relation to functional connectivity,2020,Journal of Neurophysiology,124,6,,1615,1624,9,7,10.1152/jn.00285.2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097749357&doi=10.1152%2fjn.00285.2020&partnerID=40&md5=5755f5b9e871384eb139b4937699b7dd,"The earliest stages of sensorimotor learning involve learning the correspondence between movements and sensory results-a sensorimotor map. The present exploratory study investigated the neurochemical underpinnings of map acquisition by monitoring 25 participants as they acquired a new association between movements and sounds. Functional magnetic resonance spectroscopy was used to measure neurochemical concentrations in the left primary motor cortex during learning. Resting-state functional magnetic resonance imaging data were also collected before and after training to assess learning-related changes in functional connectivity. There were monotonic increases in c-aminobutyric acid (GABA) and decreases in glucose during training, which extended into the subsequent rest period and, importantly, in the case of GABA correlated with the amount of learning: participants who showed greater behavioral learning showed greater GABA increase. The GABA change was furthermore correlated with changes in functional connectivity between the primary motor cortex and a cluster of voxels in the right intraparietal sulcus: greater increases in GABA were associated with greater strengthening of connectivity. Transiently, there were increases in lactate and reductions in aspartate, which returned to baseline at the end of training, but only lactate showed a statistical trend to correlate with the amount of learning. In summary, during the earliest stages of sensorimotor learning, GABA levels are linked on a subject-level basis to both behavioral learning and a strengthening of functional connections that persists beyond the training period. The findings are consistent with the idea that GABA-mediated inhibition is linked to maintenance of newly learned information. Copyright © 2020 the American Physiological Society",32997558,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85097749357
Ilyas M.; Nait-Ali A.,"Ilyas, Muhammad (57200275342); Nait-Ali, Amine (57698810500)",57200275342; 57698810500,Machine learning based detection of hearing loss using auditory perception responses,2019,"Proceedings - 15th International Conference on Signal Image Technology and Internet Based Systems, SISITS 2019",,,9067911,146,150,4,5,10.1109/SITIS.2019.00034,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084794921&doi=10.1109%2fSITIS.2019.00034&partnerID=40&md5=f8b44838523e81b33cff5eb0f777d9fe,"Hearing loss or hearing impairment is the primary reason of deafness throughout the world. Hearing impairment can occur to one or both the ears. If hearing loss is identified in time, it can be minimized by practicing specific precautions. In this paper, we investigate the likelihood of detection of hearing loss through auditory system responses. Auditory perception and human age are highly interrelated. Likewise, detecting a significant gap within the real age and the estimated age, the hearing loss can easily be identified. Our proposed system for human age estimation has promising results with a Root Mean Square Error (RMSE) value of 4.1 years, and classification performance efficiency for hearing loss is 94%, showing the applicability of our approach for detection of hearing loss. © 2019 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85084794921
Losorelli S.; Kaneshiro B.; Musacchia G.A.; Blevins N.H.; Fitzgerald M.B.,"Losorelli, Steven (56790026500); Kaneshiro, Blair (56884405500); Musacchia, Gabriella A. (9743555800); Blevins, Nikolas H. (6603760259); Fitzgerald, Matthew B. (16175153000)",56790026500; 56884405500; 9743555800; 6603760259; 16175153000,Factors influencing classification of frequency following responses to speech and music stimuli,2020,Hearing Research,398,,108101,,,,5,10.1016/j.heares.2020.108101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094821273&doi=10.1016%2fj.heares.2020.108101&partnerID=40&md5=79fa14f85a9f533adb6181d36afa1b50,"Successful mapping of meaningful labels to sound input requires accurate representation of that sound's acoustic variances in time and spectrum. For some individuals, such as children or those with hearing loss, having an objective measure of the integrity of this representation could be useful. Classification is a promising machine learning approach which can be used to objectively predict a stimulus label from the brain response. This approach has been previously used with auditory evoked potentials (AEP) such as the frequency following response (FFR), but a number of key issues remain unresolved before classification can be translated into clinical practice. Specifically, past efforts at FFR classification have used data from a given subject for both training and testing the classifier. It is also unclear which components of the FFR elicit optimal classification accuracy. To address these issues, we recorded FFRs from 13 adults with normal hearing in response to speech and music stimuli. We compared labeling accuracy of two cross-validation classification approaches using FFR data: (1) a more traditional method combining subject data in both the training and testing set, and (2) a “leave-one-out” approach, in which subject data is classified based on a model built exclusively from the data of other individuals. We also examined classification accuracy on decomposed and time-segmented FFRs. Our results indicate that the accuracy of leave-one-subject-out cross validation approaches that obtained in the more conventional cross-validation classifications while allowing a subject's results to be analysed with respect to normative data pooled from a separate population. In addition, we demonstrate that classification accuracy is highest when the entire FFR is used to train the classifier. Taken together, these efforts contribute key steps toward translation of classification-based machine learning approaches into clinical practice. © 2020",33142106,Article,Final,,Scopus,2-s2.0-85094821273
DeMarco A.T.; Turkeltaub P.E.,"DeMarco, Andrew T. (55934853500); Turkeltaub, Peter E. (7004120324)",55934853500; 7004120324,Functional anomaly mapping reveals local and distant dysfunction caused by brain lesions,2020,NeuroImage,215,,116806,,,,8,10.1016/j.neuroimage.2020.116806,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083393483&doi=10.1016%2fj.neuroimage.2020.116806&partnerID=40&md5=c4497947800296edeb82fce92f47bbad,"The lesion method has been important for understanding brain-behavior relationships in humans, but has previously used maps based on structural damage. Lesion measurement based on structural damage may label partly damaged but functional tissue as abnormal, and moreover, ignores distant dysfunction in structurally intact tissue caused by deafferentation, diaschisis, and other processes. A reliable method to map functional integrity of tissue throughout the brain would provide a valuable new approach to measuring lesions. Here, we use machine learning on four dimensional resting state fMRI data obtained from left-hemisphere stroke survivors in the chronic period of recovery and control subjects to generate graded maps of functional anomaly throughout the brain in individual patients. These functional anomaly maps identify areas of obvious structural lesions and are stable across multiple measurements taken months and even years apart. Moreover, the maps identify functionally anomalous regions in structurally intact tissue, providing a direct measure of remote effects of lesions on the function of distant brain structures. Multivariate lesion-behavior mapping using functional anomaly maps replicates classic behavioral localization, identifying inferior frontal regions related to speech fluency, lateral temporal regions related to auditory comprehension, parietal regions related to phonology, and the hand area of motor cortex and descending corticospinal pathways for hand motor function. Further, this approach identifies relationships between tissue function and behavior distant from the structural lesions, including right premotor dysfunction related to ipsilateral hand movement, and right cerebellar regions known to contribute to speech fluency. Brain-wide maps of the functional effects of focal lesions could have wide implications for lesion-behavior association studies and studies of recovery after brain injury. © 2020 The Author(s)",32278896,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85083393483
Belitz C.; Ali H.; Hansen J.H.L.,"Belitz, Chelzy (57211639140); Ali, Hussnain (35408639900); Hansen, John H.L. (7404334144)",57211639140; 35408639900; 7404334144,A machine learning based clustering protocol for determining hearing aid initial configurations from pure-tone audiograms,2019,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2019-September,,,2325,2329,4,2,10.21437/Interspeech.2019-3091,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074718098&doi=10.21437%2fInterspeech.2019-3091&partnerID=40&md5=bd98e20c30aaa728330b7b68012491d3,"Of the nearly 35 million people in the USA who are hearing impaired, only an estimated 25% use hearing aids (HA). A good number of HAs are prescribed but not used partially because of the time to convergence for best operation between the audiologist and user. To improve HA retention, it is suggested that a machine learning (ML) protocol could be established which improves initial HA configurations given a user's pure-tone audiogram. This study examines a ML clustering method to predict the best initial HA fitting from a corpus of over 90,000 audiogram-fitting pairs collected from hearing centers throughout the USA. We first examine the final HA comfort targets to determine a limited number of preset configurations using several multi-dimensional clustering methods (Birch, Ward, and k-means). The goal is to reduce the amount of adjustments between the centroid, selected as a fitting configuration to represent the cluster, and the final HA configurations. This may be used to reduce the adjustment cycles for HAs or as preset starting configurations for personal sound amplification products (PSAPs). Using various classification methods, audiograms are mapped to a limited number of potential preset configurations. Finally, the average adjustment between the preset fitting targets and the final fitting targets is examined. Copyright © 2019 ISCA",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074718098
Meijerink J.F.J.; Pronk M.; Lissenberg-Witte B.I.; Jansen V.; Kramer S.E.,"Meijerink, Janine F.J. (57216450809); Pronk, Marieke (36939723800); Lissenberg-Witte, Birgit I. (57204744042); Jansen, Vera (57194588888); Kramer, Sophia E. (7401609154)",57216450809; 36939723800; 57204744042; 57194588888; 7401609154,"Effectiveness of a web-based support program (SUPR) for hearing aid users aged 50+: Two-arm, cluster randomized controlled trial",2020,Journal of Medical Internet Research,22,9,e17927,,,,12,10.2196/17927,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091488635&doi=10.2196%2f17927&partnerID=40&md5=10a39707e161a873df63c5049ae2f0b0,"Background: Hearing aid (HA) use is known to improve health outcomes for people with hearing loss. Despite that, HA use is suboptimal, and communication issues and hearing-related activity limitations and participation restrictions often remain. Web-based self-management communication programs may support people with hearing loss to effectively self-manage the impact of hearing loss in their daily lives. Objective: The goal of the research is to examine the short- and long-term effects of a web-based self-management SUpport PRogram (SUPR) on communication strategy use (primary outcome) and a range of secondary outcomes for HA users aged 50 years and older. Methods: Clients of 36 HA dispensing practices were randomized to SUPR (SUPR recipients; n=180 HA users) and 34 to care as usual (controls; n=163 HA users). SUPR recipients received a practical support booklet and online materials delivered via email over the course of their 6-month HA rehabilitation trajectory. They were encouraged to appoint a communication partner and were offered optional email contact with the HA dispensing practice. The online materials included 3 instruction videos on HA handling, 5 videos on communication strategies, and 3 testimonial videos. Care as usual included a HA fitting rehabilitation trajectory only. Measurements were carried out at baseline, immediately postintervention, 6 months postintervention, and 12 months postintervention. The primary outcome measure was self-reported use of communication strategies (3 subscales of the Communication Profile for the Hearing Impaired [CPHI]). Secondary outcome measures included self-reported personal adjustment to hearing loss (CPHI); use, satisfaction and benefit of HAs and SUPR (use questionnaire; International Outcome Inventory for Hearing Aids [IOI-HA], Alternative Interventions [IOI-AI]); recommendation of HA dispensing services; self-efficacy for HA handling (Measure of Audiologic Rehabilitation Self-Efficacy for Hearing Aids [MARS-HA]); readiness to act on hearing loss (University of Rhode Island Change Assessment adapted for hearing loss [URICA-HL]); and hearing disability (Amsterdam Inventory for Auditory Disability and Handicap [AIADH]). Results: Linear mixed model analyses (intention to treat) showed no significant differences between the SUPR and control group in the course of communication strategy use (CPHI). Immediately postintervention, SUPR recipients showed significantly higher self-efficacy for advanced HA handling than the controls, which was sustained at 12 months (MARS-HA; mean difference immediately postintervention: 5.3, 95% CI 0.3 to 10.4; P=.04). Also, SUPR recipients showed significantly greater HA satisfaction than controls immediately postintervention (IOI-HA; 0.3, 95% CI 0.09 to 0.5; P=.006), which was sustained at 12 months, and significantly greater HA use than the controls immediately postintervention (IOI-HA; 0.3, 95% CI 0.02 to 0.5; P=.03), which was not sustained at 12 months. Conclusions: This study provides ground to recommend adding SUPR to standard HA dispensing care, as long-term, modest improvements in HA outcomes were observed. Further research is needed to evaluate what adjustments to SUPR are needed to establish long-term effectiveness on outcomes in the psychosocial domain. © Janine FJ Meijerink, Marieke Pronk, Birgit I Lissenberg-Witte, Vera Jansen, Sophia E Kramer. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 22.09.2020. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.",32960175,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091488635
Lansbergen S.; Dreschler W.A.,"Lansbergen, Simon (57204176840); Dreschler, Wouter A. (7003763918)",57204176840; 7003763918,Classification of Hearing Aids Into Feature Profiles Using Hierarchical Latent Class Analysis Applied to a Large Dataset of Hearing Aids,2020,Ear and hearing,41,6,,1619,1634,15,5,10.1097/AUD.0000000000000410,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095390429&doi=10.1097%2fAUD.0000000000000410&partnerID=40&md5=4839d39e42fbe3946f10a93fb49fb306,"OBJECTIVES: We developed a framework for objectively comparing hearing aids, independent of brand, type, or product family. This was done using a large dataset of commercially available hearing aids. To achieve this, we investigated which hearing aid features are suitable for comparison, and are also relevant for the rehabilitation of hearing impairment. To compare hearing aids objectively, we distinguished populations of hearing aids based on a set of key hearing aid features. Finally, we describe these hearing aid subpopulations so that these could potentially be used as a supporting tool for the selection of an appropriate hearing aid. DESIGN: In this study, we used technical (meta-)data from 3911 hearing aids (available on the Dutch market in March 2018). The dataset contained about 50 of the most important characteristics of a hearing aid. After cleaning and handling the data via a well-defined knowledge discovery in database procedure, a total 3083 hearing aids were included. Subsequently, a set of well-defined key hearing aid features were used as input for further analysis. The data were split into an in-the-ear style hearing aid subset and a behind-the-ear style subset, for separate analyses. The knowledge discovery in databases procedure was also used as an objective guiding tool for applying an exploratory cluster analysis to expose subpopulations of hearing aids within the dataset. The latter was done using Latent Class Tree Analysis, which is an extension to the better-known Latent Class Analysis clustering method: with the important addition of a hierarchical structure. RESULTS: A total of 10 hearing aid features were identified as relevant for audiological rehabilitation: compression, sound processing, noise reduction (NR), expansion, wind NR, impulse (noise) reduction, active feedback management, directionality, NR environments, and ear-to-ear communication. These features had the greatest impact on results yielded by the Latent Class Tree cluster analysis. At the first level in the hierarchical cluster model, the two subpopulations of hearing aids could be divided into 3 main branches, mainly distinguishable by the overall availability or technology level of hearing aid features. Higher-level results of the cluster analysis yielded a set of mutually exclusive hearing aid populations, called modalities. In total, nine behind-the-ear and seven in-the-ear modalities were found. These modalities were characterized by particular profiles of (complex) interplay between the selected key features. A technical comparison of features (e.g., implementation) is beyond the scope of this research. CONCLUSIONS: Combining a large dataset of hearing aids with a probabilistic hierarchical clustering method enables analysis of hearing aid characteristics which extends beyond product families and manufacturers. Furthermore, this study found that the resulting hearing aid modalities can be thought of as a generic alternative to the manufacturer-dependent proprietary ""concepts,"" and could potentially aid the selection of an appropriate hearing aid for technical rehabilitation. This study is in line with a growing need for justification of hearing aid selection and the increasing demand for evidence-based practice.",33136637,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095390429
Jensen J.; Vyas D.; Urbanski D.; Garudadri H.; Chipara O.; Wu Y.-H.,"Jensen, Justin (57218826939); Vyas, Dhruv (56206479800); Urbanski, Dana (57218829299); Garudadri, Harinath (6602304452); Chipara, Octav (9334529600); Wu, Yu-Hsiang (18038757800)",57218826939; 56206479800; 57218829299; 6602304452; 9334529600; 18038757800,Common configurations of real-ear aided response targets prescribed by NAL-NL2 for older adults with mild-to-moderate hearing loss,2020,American Journal of Audiology,29,3,,460,475,15,3,10.1044/2020_AJA-20-00025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090357313&doi=10.1044%2f2020_AJA-20-00025&partnerID=40&md5=6df78c00fc38d09e154f1ed742773309,"Purpose: This study investigates common real-ear aided response (REAR) configurations prescribed by the NAL-NL2 algorithm for older adults with hearing loss. Method: A data set that is representative of the older adult U.S. population with mild-to-moderate sensorineural hearing loss was constructed from the audiometric data of 934 adults (aged 55–85 years) from the National Health and Nutrition Examination Survey years 1999–2012. Two clustering approaches were implemented to generate common REAR configurations for eight frequencies (0.25, 0.5, 1, 2, 3, 4, 6, and 8 kHz) at three input levels (55, 65, and 75 dB SPL). (a) In the REAR-based clustering approach, the National Health and Nutrition Examination Survey audiograms were first converted to REAR targets and then clustered to generate common REAR configurations. (b) In the audiogram-based clustering approach, the audiograms were first clustered into common hearing loss profiles and then converted to REAR configurations. The trade-off between the number of available REAR configurations and the percentage of the U.S. population whose hearing loss could be fit by at least one of them (i.e., percent coverage) was evaluated. Hearing loss fit was defined as less than ± 5-dB difference between an individual’s REAR targets and those of the clustered REAR configuration. Results: Percent coverage increases with the number of available REAR configurations, with four configurations resulting in 75% population coverage. Overall, REAR-based clustering yielded 5 percentage points better coverage on average compared to audiogram-based clustering. Conclusions: The common REAR configurations can be used for programming the gain frequency responses in preconfigured over-the-counter hearing aids and provide clinically appropriate amplification settings for older adults with mild-to-moderate hearing loss. © 2020 American Speech-Language-Hearing Association.",32693613,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85090357313
Bhat G.S.; Shankar N.; Panahi I.M.S.,"Bhat, Gautam Shreedhar (57202500800); Shankar, Nikhil (57196017115); Panahi, Issa M.S (6603262686)",57202500800; 57196017115; 6603262686,Automated machine learning based speech classification for hearing aid applications and its real-time implementation on smartphone,2020,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2020-July,,9175693,956,959,3,13,10.1109/EMBC44109.2020.9175693,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091043304&doi=10.1109%2fEMBC44109.2020.9175693&partnerID=40&md5=1078aa3960342990a166acfeedb04452,"Deep neural networks (DNNs) have been useful in solving benchmark problems in various domains including audio. DNNs have been used to improve several speech processing algorithms that improve speech perception for hearing impaired listeners. To make use of DNNs to their full potential and to configure models easily, automated machine learning (AutoML) systems are developed, focusing on model optimization. As an application of AutoML to audio and hearing aids, this work presents an AutoML based voice activity detector (VAD) that is implemented on a smartphone as a real-time application. The developed VAD can be used to elevate the performance of speech processing applications like speech enhancement that are widely used in hearing aid devices. The classification model generated by AutoML is computationally fast and has minimal processing delay, which enables an efficient, real-time operation on a smartphone. The steps involved in real-time implementation are discussed in detail. The key contribution of this work include the utilization of AutoML platform for hearing aid applications and the realization of AutoML model on smartphone. The experimental analysis and results demonstrate the significance and importance of using the AutoML for the current approach. The evaluations also show improvements over the state of art techniques and reflect the practical usability of the developed smartphone app in different noisy environments. © 2020 IEEE.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85091043304
Yang H.; Lin H.; Lin X.; Zhang X.; Xiong H.; Zheng Y.,"Yang, Haidi (37051569400); Lin, Haiyan (57889226200); Lin, Xiaofeng (57215886497); Zhang, Xueyuan (57207317212); Xiong, Hao (36438003100); Zheng, Yiqing (9747500000)",37051569400; 57889226200; 57215886497; 57207317212; 36438003100; 9747500000,Regional homogeneity and functional connectivity in resting-state brain activity in tinnitus patients,2020,Journal of Bio-X Research,3,2,,45,53,8,1,10.1097/JBR.0000000000000047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137970014&doi=10.1097%2fJBR.0000000000000047&partnerID=40&md5=03f0d2dccea3ef8e825822ff6076537e,"Objective: Subjective tinnitus is characterized by the perception of sound in the absence of any external auditory stimuli. This perceived sound may be related to altered intrinsic neural activity generated along the central auditory pathway. This retrospective study was designed to investigate regional homogeneity and functional connectivity in the resting-state brain activity of patients with tinnitus. Methods: We recruited tinnitus patients with normal hearing or mild hearing loss (n = 17) and age-matched healthy controls (n = 20), and examined regional homogeneity and functional connectivity in resting-state brain activity using resting-state functional magnetic resonance imaging data. The present study protocol was approved by the Institutional Review Board on Experimental Ethics at Sun Yat-sen University, China (approval No. SYSEC-KY-KS-2019-083). Results: Compared with normal controls, patients with tinnitus had significantly decreased regional homogeneity in the anterior lobe of the cerebellum and increased homogeneity in the inferior frontal gyrus (P < 0.05 corrected at a cluster-level). In addition, tinnitus patients showed enhanced functional connectivity between the inferior frontal gyrus and the ventral striatum and midbrain, as well as increased connectivity between the cerebellum and ventromedial prefrontal cortex (P < 0.05 corrected at a cluster-level). We also found decreased connectivity between the cerebellum and the anterior insula compared with controls (P < 0.05 corrected at a cluster-level). Conclusion: Abnormal connectivity in non-auditory brain structures, particularly those related to emotion processing, may be associated with tinnitus persistence. Copyright © 2020 The Chinese Medical Association, Published by Wolters Kluwer Health, Inc",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85137970014
Oike H.; Ogawa Y.; Azami K.,"Oike, Hideaki (35339633700); Ogawa, Yukino (57217780186); Azami, Kayo (57216817158)",35339633700; 57217780186; 57216817158,Long-term feeding of a high-fat diet ameliorated age-related phenotypes in SAMP8 mice,2020,Nutrients,12,5,1416,,,,13,10.3390/nu12051416,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084787725&doi=10.3390%2fnu12051416&partnerID=40&md5=7e0e6d7ae8973d874704ef2e04b6636f,"High-fat diets (HFD) have been thought to increase the risk of obesity and metabolic syndrome, as well as shorten lifespan. On the other hand, chrono-nutritional studies have shown that time-restricted feeding during active phase significantly suppresses the induction of HFDinduced obesity in mouse model. However, the long-term effects of time-restricted HFD feeding on aging are unknown. Therefore, in this study, we set up a total of four groups: mutual combination of ad libitum feeding or night-time-restricted feeding (NtRF) and an HFD or a control diet. We examined their long-term effects in a senescence-accelerated mouse strain, SAMP8, for over a year. Hearing ability, cognitive function, and other behavioral and physiological indexes were evaluated during the study. Unexpectedly, SAMP8 mice did not show early onset of death caused by the prolonged HFD intake, and both HFD and NtRF retarded age-related hearing loss (AHL). NtRF improved grip strength and cognitive memory scores, while HFD weakly suppressed age-related worsening of the appearance scores associated with the eyes. Notably, the HFD also retarded the progression of AHL in both DBA/2J and C57BL/6J mice. These results suggest that HFD prevents aging unless metabolic disorders occur and that HFD and NtRF are independently effective in retarding aging; thus, the combination of HFD and chrono-nutritional feeding may be an effective anti-aging strategy. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",32423039,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85084787725
Genitsaridi E.; Hoare D.J.; Kypraios T.; Hall D.A.,"Genitsaridi, Eleni (57204612058); Hoare, Derek J. (36184054900); Kypraios, Theodore (35622076800); Hall, Deborah A. (35229238900)",57204612058; 36184054900; 35622076800; 35229238900,A review and a framework of variables for defining and characterizing tinnitus subphenotypes,2020,Brain Sciences,10,12,938,1,21,20,16,10.3390/brainsci10120938,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097165031&doi=10.3390%2fbrainsci10120938&partnerID=40&md5=85ac1b6c86b1f74b6ca3267f076f929b,"Tinnitus patients can present with various characteristics, such as those related to the tinnitus perception, symptom severity, and pattern of comorbidities. It is speculated that this phenotypic heterogeneity is associated with differences in the underlying pathophysiology and personal reaction to the condition. However, there is as yet no established protocol for tinnitus profiling or subtyping, hindering progress in treatment development. This review summarizes data on variables that have been used in studies investigating phenotypic differences in subgroups of tinnitus, including variables used to both define and compare subgroups. A PubMed search led to the identification of 64 eligible articles. In most studies, variables for subgrouping were chosen by the researchers (hypothesis-driven approach). Other approaches included application of unsupervised machine-learning techniques for the definition of subgroups (data-driven), and subgroup definition based on the response to a tinnitus treatment (treatment response). A framework of 94 variable concepts was created to summarize variables used across all studies. Frequency statistics for the use of each variable concept are presented, demonstrating those most and least commonly assessed. This review highlights the high dimensionality of tinnitus heterogeneity. The framework of variables can contribute to the design of future studies, helping to decide on tinnitus assessment and subgrouping. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85097165031
Kim K.X.; Payne S.; Yang-Hood A.; Li S.-Z.; Davis B.; Carlquist J.; Ghaffari B.V.; Gantz J.A.; Kallogjeri D.; Fitzpatrick J.A.J.; Ohlemiller K.K.; Hirose K.; Rutherford M.A.,"Kim, Kyunghee X. (35210602100); Payne, Shelby (57209324837); Yang-Hood, Aizhen (57209325376); Li, Song-Zhe (56182577300); Davis, Bethany (57209324391); Carlquist, Jason (57209323891); Ghaffari, Babak V. (57210110707); Gantz, Jay A. (23972262700); Kallogjeri, Dorina (23492735800); Fitzpatrick, James A. J. (57202411825); Ohlemiller, Kevin K. (7004359121); Hirose, Keiko (35568451500); Rutherford, Mark A. (12752186900)",35210602100; 57209324837; 57209325376; 56182577300; 57209324391; 57209323891; 57210110707; 23972262700; 23492735800; 57202411825; 7004359121; 35568451500; 12752186900,Vesicular glutamatergic transmission in noise-induced loss and repair of cochlear ribbon synapses,2019,Journal of Neuroscience,39,23,,4434,4447,13,71,10.1523/JNEUROSCI.2228-18.2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067371982&doi=10.1523%2fJNEUROSCI.2228-18.2019&partnerID=40&md5=ddbfee0f3b40eb2777512f4c18dccf78,"Noise-induced excitotoxicity is thought to depend on glutamate. However, the excitotoxic mechanisms are unknown, and the necessity of glutamate for synapse loss or regeneration is unclear. Despite absence of glutamatergic transmission from cochlear inner hair cells in mice lacking the vesicular glutamate transporter-3 (Vglut3KO), at 9-11 weeks, approximately half the number of synapses found in Vglut3WT were maintained as postsynaptic AMPA receptors juxtaposed with presynaptic ribbons and voltage-gated calcium channels (CaV1.3). Synapses were larger in Vglut3KO than Vglut3WT. In Vglut3WT and Vglut3+/− mice, 8-16 kHz octave-band noise exposure at 100 dB sound pressure level caused a threshold shift (~40 dB) and a loss of synapses (>50%) at 24 h after exposure. Hearing threshold and synapse number partially recovered by 2 weeks after exposure as ribbons became larger, whereas recovery was significantly better in Vglut3WT. Noise exposure at 94 dB sound pressure level caused auditory threshold shifts that fully recovered in 2 weeks, whereas suprathreshold hearing recovered faster in Vglut3WT than Vglut3+/−. These results, from mice of both sexes, suggest that spontaneous repair of synapses after noise depends on the level of Vglut3 protein or the level of glutamate release during the recovery period. Noise-induced loss of presynaptic ribbons or postsynaptic AMPA receptors was not observed in Vglut3KO, demonstrating its dependence on vesicular glutamate release. In Vglut3WT and Vglut3+/−, noise exposure caused unpairing of presynaptic ribbons and presynaptic CaV1.3, but not in Vglut3KO where CaV1.3 remained clustered with ribbons at presynaptic active zones. These results suggest that, without glutamate release, noise-induced presynaptic Ca2+ influx was insufficient to disassemble the active zone. However, synapse volume increased by 2 weeks after exposure in Vglut3KO, suggesting glutamate-independent mechanisms. SIGNIFICANCE STATEMENT Hearing depends on glutamatergic transmission mediated by Vglut3, but the role of glutamate in synapse loss and repair is unclear. Here, using mice of both sexes, we show that one copy of the Vglut3 gene is sufficient for noise-induced threshold shift and loss of ribbon synapses, but both copies are required for normal recovery of hearing function and ribbon synapse number. Impairment of the recovery process in mice having only one functional copy suggests that glutamate release may promote synapse regeneration. At least one copy of the Vglut3 gene is necessary for noise-induced synapse loss. Although the excitotoxic mechanism remains unknown, these findings are consistent with the presumption that glutamate is the key mediator of noise-induced synaptopathy. © 2019 the authors.",30926748,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85067371982
Bramhall N.F.; McMillan G.P.; Kujawa S.G.; Konrad-Martin D.,"Bramhall, Naomi F. (24398417500); McMillan, Garnett P. (7006767888); Kujawa, Sharon G. (7003709164); Konrad-Martin, Dawn (6603455821)",24398417500; 7006767888; 7003709164; 6603455821,Use of non-invasive measures to predict cochlear synapse counts,2018,Hearing Research,370,,,113,119,6,11,10.1016/j.heares.2018.10.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055267292&doi=10.1016%2fj.heares.2018.10.006&partnerID=40&md5=d30329a2b2585db505bb6466013a31f6,"Cochlear synaptopathy, the loss of synaptic connections between inner hair cells (IHCs) and auditory nerve fibers, has been documented in animal models of aging, noise, and ototoxic drug exposure, three common causes of acquired sensorineural hearing loss in humans. In each of these models, synaptopathy begins prior to changes in threshold sensitivity or loss of hair cells; thus, this underlying injury can be hidden behind a normal threshold audiogram. Since cochlear synaptic loss cannot be directly confirmed in living humans, non-invasive assays will be required for diagnosis. In animals with normal auditory thresholds, the amplitude of wave 1 of the auditory brainstem response (ABR) is highly correlated with synapse counts. However, synaptopathy can also co-occur with threshold elevation, complicating the use of the ABR alone as a diagnostic measure. Using an age-graded series of mice and a partial least squares regression approach to model structure-function relationships, this study shows that the combination of a small number of ABR and distortion product otoacoustic emission (DPOAE) measurements can predict synaptic ribbon counts at various cochlear frequencies to within 1–2 synapses per IHC of their true value. In contrast, the model, trained using the age-graded series of mice, overpredicted synapse counts in a small sample of young noise-exposed mice, perhaps due to differences in the underlying pattern of damage between aging and noise-exposed mice. These results provide partial validation of a noninvasive approach to identify synaptic/neuronal loss in humans using ABRs and DPOAEs. © 2018",30366194,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85055267292
Stroh A.-L.; Rösler F.; Dormal G.; Salden U.; Skotara N.; Hänel-Faulhaber B.; Röder B.,"Stroh, Anna-Lena (57522187600); Rösler, Frank (7004908915); Dormal, Giulia (36999202900); Salden, Uta (49964399000); Skotara, Nils (20436807100); Hänel-Faulhaber, Barbara (51261271800); Röder, Brigitte (7005308612)",57522187600; 7004908915; 36999202900; 49964399000; 20436807100; 51261271800; 7005308612,Neural correlates of semantic and syntactic processing in German Sign Language,2019,NeuroImage,200,,,231,241,10,7,10.1016/j.neuroimage.2019.06.025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068088395&doi=10.1016%2fj.neuroimage.2019.06.025&partnerID=40&md5=53c7ec91274044d284f3c3aed0287fd6,"The study of deaf and hearing native users of signed languages can offer unique insights into how biological constraints and environmental input interact to shape the neural bases of language processing. Here, we use functional magnetic resonance imaging (fMRI) to address two questions: (1) Do semantic and syntactic processing in a signed language rely on anatomically and functionally distinct neural substrates as it has been shown for spoken languages? and (2) Does hearing status affect the neural correlates of these two types of linguistic processing? Deaf and hearing native signers performed a sentence judgement task on German Sign Language (Deutsche Gebärdensprache: DGS) sentences which were correct or contained either syntactic or semantic violations. We hypothesized that processing of semantic and syntactic violations in DGS relies on distinct neural substrates as it has been shown for spoken languages. Moreover, we hypothesized that effects of hearing status are observed within auditory regions, as deaf native signers have been shown to activate auditory areas to a greater extent than hearing native signers when processing a signed language. Semantic processing activated low-level visual areas and the left inferior frontal gyrus (IFG), suggesting both modality-dependent and independent processing mechanisms. Syntactic processing elicited increased activation in the right supramarginal gyrus (SMG). Moreover, psychophysiological interaction (PPI) analyses revealed a cluster in left middle occipital regions showing increased functional coupling with the right SMG during syntactic relative to semantic processing, possibly indicating spatial processing mechanisms that are specific to signed syntax. Effects of hearing status were observed in the right superior temporal cortex (STC): deaf but not hearing native signers showed greater activation for semantic violations than for syntactic violations in this region. Taken together, the present findings suggest that the neural correlates of language processing are partly determined by biological constraints, but that they may additionally be influenced by the unique processing demands of the language modality and different sensory experiences. © 2019 Elsevier Inc.",31220577,Article,Final,,Scopus,2-s2.0-85068088395
Villanueva R.; Hoang B.; Shah U.; Martinez Y.; George K.,"Villanueva, Ryan (57215577913); Hoang, Brandon (57215577266); Shah, Urmil (57205689758); Martinez, Yazmin (57215579772); George, Kiran (57190838101)",57215577913; 57215577266; 57205689758; 57215579772; 57190838101,Sensory audio focusing detection using brain-computer interface archetype,2019,"Proceedings - 2019 IEEE 1st International Conference on Cognitive Machine Intelligence, CogMI 2019",,,8999001,97,101,4,2,10.1109/CogMI48466.2019.00022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081274441&doi=10.1109%2fCogMI48466.2019.00022&partnerID=40&md5=325d66a3ca4ee49df6a33e713325bb6d,"Everyday people are placed in environments where countless conversations simultaneously take place within earshot. Speech intelligibility in the presence of multiple speakers, commonly known as the 'Cocktail Party Phenomenon', is significantly reduced for most hearing-impaired listeners who use hearing assistive devices [1]. Prior research addressing this issue include noise filtering based on trajectories of multiple moving speakers and locations of talking targets based on face detection [2][3]. This study focuses on the practicality of audio filtering through measuring electroencephalogram (EEG) signals using a Brain-Computer Interfaces (BCI) system. The study explores the use of machine learning algorithms to classify which speaker the listener is focusing on. In this study, training data is obtained of a listener focusing on one auditory stimulus (audiobook) while other auditory stimuli are presented at the same time. A g.Nautilus BCI headset was used to obtain EEG data. After collecting trial data for each audio source, a machine learning algorithm trains a classifier to distinguish one audiobook between another. Data was collected from five subjects in each trial. Results yielded an accuracy of above 90% from all three experiments. © 2019 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85081274441
Moulin A.; Vergne J.; Gallego S.; Micheyl C.,"Moulin, Annie (57193911866); Vergne, Judith (57192704829); Gallego, Stéphane (55418515700); Micheyl, Christophe (7003276084)",57193911866; 57192704829; 55418515700; 7003276084,"A new speech, spatial, and qualities of hearing scale short-form: Factor, cluster, and comparative analyses",2019,Ear and Hearing,40,4,,938,950,12,20,10.1097/AUD.0000000000000675,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068822200&doi=10.1097%2fAUD.0000000000000675&partnerID=40&md5=f7d0574ce53c2cf32f63bbd89462e109,"Objectives: The objective of this work was to build a 15-item short-form of the Speech Spatial and Qualities of Hearing Scale (SSQ) that maintains the three-factor structure of the full form, using a data-driven approach consistent with internationally recognized procedures for short-form building. This included the validation of the new short-form on an independent sample and an in-depth, comparative analysis of all existing, full and short SSQ forms. Design: Data from a previous study involving 98 normal-hearing (NH) individuals and 196 people with hearing impairments (HI), non hearing aid wearers, along with results from several other published SSQ studies, were used for developing the short-form. Data from a new and independent sample of 35 NH and 88 HI hearing aid wearers were used to validate the new short-form. Factor and hierarchical cluster analyses were used to check the factor structure and internal consistency of the new short-form. In addition, the new short-form was compared with all other SSQ forms, including the full SSQ, the German SSQ15, the SSQ12, and the SSQ5. Construct validity was further assessed by testing statistical relationships between scores and audiometric factors, including pure-tone threshold averages (PTAs) and left/right PTA asymmetry. Receiver-operating characteristic analyses were used to compare the ability of different SSQ forms to discriminate between NH and HI (HI non hearing aid wearers and HI hearing aid wearers) individuals. Results: Compared all other SSQ forms, including the full SSQ, the new short-form showed negligible cross-loading across the three main subscales and greater discriminatory power between NH and HI subjects (as indicated by a larger area under the receiver-operating characteristic curve), as well as between the main subscales (especially Speech and Qualities). Moreover, the new, 5-item Spatial subscale showed increased sensitivity to left/right PTA asymmetry. Very good internal consistency and homogeneity and high correlations with the SSQ were obtained for all short-forms. Conclusions: While maintaining the three-factor structure of the full SSQ, and exceeding the latter in terms of construct validity and sensitivity to audiometric variables, the new 15-item SSQ affords a substantial reduction in the number of items and, thus, in test time. Based on overall scores, Speech subscores, or Spatial subscores, but not Qualities subscores, the 15-item SSQ appears to be more sensitive to differences in self-evaluated hearing abilities between NH and HI subjects than the full SSQ. Copyright © 2018 Wolters Kluwer Health, Inc. All rights reserved",30461444,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85068822200
Meng L.; Wang K.; Lv H.; Wang Z.; Zhang W.; Yuan Y.,"Meng, Lingchao (56161768700); Wang, Kang (57210556142); Lv, He (36939519600); Wang, Zhaoxia (57192246565); Zhang, Wei (57310476600); Yuan, Yun (7402708960)",56161768700; 57210556142; 36939519600; 57192246565; 57310476600; 7402708960,A novel mutation in PRPS1 causes X-linked Charcot-Marie-Tooth disease-5,2019,Neuropathology,39,5,,342,347,5,7,10.1111/neup.12589,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070859618&doi=10.1111%2fneup.12589&partnerID=40&md5=2a66bb4b8d6b7ae80426d91ed9d34882,"X-linked Charcot-Marie-Tooth disease-5 (CMTX5) is a rare hereditary disorder caused by mutations in the gene for phosphoribosyl pyrophosphate synthetase-1 (PRPS1). We investigated a boy with a novel PRPS1 mutation (c.334G>C, p.V112L) via genetic, neuropathological and enzymatic tests. The proband was a 13-year-old boy with congenital non-syndromic sensorineural deafness. At 3 year old, he developed progressive distal weakness of all limbs with muscle atrophy of both hands and shanks. Nerve conduction study revealed the loss of sensory nerve action potentials, and slowing down of motor nerve conduction velocities with a decrease of amplitudes of compound motor action potentials. Visual evoked potentials and brainstem auditory evoked potentials were not bilaterally evocable. Sural biopsy proved the loss of myelinated nerve fibers, with axonal degeneration, regenerating clusters and onion bulbs. Enzymatically, PRPS1 activity was close to zero in the proband and mildly reduced in his mother, compared with controls. To our knowledge, this is the first report of CMTX5 in a Chinese population. The genetic finding has expanded the genotypic spectrum of PRPS1 mutations. © 2019 Japanese Society of Neuropathology",31434166,Article,Final,,Scopus,2-s2.0-85070859618
Raghavan A.M.; Lipschitz N.; Breen J.T.; Samy R.N.; Kohlberg G.D.,"Raghavan, Arun M. (57202206225); Lipschitz, Noga (34875279400); Breen, Joseph T. (36611216300); Samy, Ravi N. (7004366896); Kohlberg, Gavriel D. (12788784700)",57202206225; 34875279400; 36611216300; 7004366896; 12788784700,Visual Speech Recognition: Improving Speech Perception in Noise through Artificial Intelligence,2020,Otolaryngology - Head and Neck Surgery (United States),163,4,,771,777,6,1,10.1177/0194599820924331,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085362741&doi=10.1177%2f0194599820924331&partnerID=40&md5=440b493e4d6a2097ed9f914646fa980c,"Objectives: To compare speech perception (SP) in noise for normal-hearing (NH) individuals and individuals with hearing loss (IWHL) and to demonstrate improvements in SP with use of a visual speech recognition program (VSRP). Study Design: Single-institution prospective study. Setting: Tertiary referral center. Subjects and Methods: Eleven NH and 9 IWHL participants in a sound-isolated booth facing a speaker through a window. In non-VSRP conditions, SP was evaluated on 40 Bamford-Kowal-Bench speech-in-noise test (BKB-SIN) sentences presented by the speaker at 50 A-weighted decibels (dBA) with multiperson babble noise presented from 50 to 75 dBA. SP was defined as the percentage of words correctly identified. In VSRP conditions, an infrared camera was used to track 35 points around the speaker’s lips during speech in real time. Lip movement data were translated into speech-text via an in-house developed neural network–based VSRP. SP was evaluated similarly in the non-VSRP condition on 42 BKB-SIN sentences, with the addition of the VSRP output presented on a screen to the listener. Results: In high-noise conditions (70-75 dBA) without VSRP, NH listeners achieved significantly higher speech perception than IWHL listeners (38.7% vs 25.0%, P =.02). NH listeners were significantly more accurate with VSRP than without VSRP (75.5% vs 38.7%, P <.0001), as were IWHL listeners (70.4% vs 25.0% P <.0001). With VSRP, no significant difference in SP was observed between NH and IWHL listeners (75.5% vs 70.4%, P =.15). Conclusions: The VSRP significantly increased speech perception in high-noise conditions for NH and IWHL participants and eliminated the difference in SP accuracy between NH and IWHL listeners. © American Academy of Otolaryngology–Head and Neck Surgery Foundation 2020.",32453650,Article,Final,,Scopus,2-s2.0-85085362741
Shen C.-L.; Chou T.-L.; Lai W.-S.; Hsieh M.H.; Liu C.-C.; Liu C.-M.; Hwu H.-G.,"Shen, Chen-Lan (58829509800); Chou, Tai-Li (12140823400); Lai, Wen-Sung (8849529000); Hsieh, Ming H. (13605989800); Liu, Chen-Chung (23566858300); Liu, Chih-Min (7409794479); Hwu, Hai-Gwo (7006444908)",58829509800; 12140823400; 8849529000; 13605989800; 23566858300; 7409794479; 7006444908,"P50, N100, and P200 Auditory Sensory Gating Deficits in Schizophrenia Patients",2020,Frontiers in Psychiatry,11,,868,,,,34,10.3389/fpsyt.2020.00868,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091371162&doi=10.3389%2ffpsyt.2020.00868&partnerID=40&md5=9dc043a82d18f51e55cf95fd11c793f3,"Background: Sensory gating describes neurological processes of filtering out redundant or unnecessary stimuli during information processing, and sensory gating deficits may contribute to the symptoms of schizophrenia. Among the three components of auditory event-related potentials reflecting sensory gating, P50 implies pre-attentional filtering of sensory information and N100/P200 reflects attention triggering and allocation processes. Although diminished P50 gating has been extensively documented in patients with schizophrenia, previous studies on N100 were inconclusive, and P200 has been rarely examined. This study aimed to investigate whether patients with schizophrenia have P50, N100, and P200 gating deficits compared with control subjects. Methods: Control subjects and clinically stable schizophrenia patients were recruited. The mid-latency auditory evoked responses, comprising P50, N100, and P200, were measured using the auditory-paired click paradigm without manipulation of attention. Sensory gating parameters included S1 amplitude, S2 amplitude, amplitude difference (S1-S2), and gating ratio (S2/S1). We also evaluated schizophrenia patients with PANSS to be correlated with sensory gating indices. Results: One hundred four patients and 102 control subjects were examined. Compared to the control group, schizophrenia patients had significant sensory gating deficits in P50, N100, and P200, reflected by larger gating ratios and smaller amplitude differences. Further analysis revealed that the S2 amplitude of P50 was larger, while the S1 amplitude of N100/P200 was smaller, in schizophrenia patients than in the controls. We found no correlations between sensory gating indices and schizophrenia positive or negative symptom clusters. However, we found a negative correlation between the P200 S2 amplitude and Bell’s emotional discomfort factor/Wallwork’s depressed factor. Conclusion: Till date, this study has the largest sample size to analyze P50, N100, and P200 collectively by adopting the passive auditory paired-click paradigm without distractors. With covariates controlled for possible confounds, such as age, education, smoking amount and retained pairs, we found that schizophrenia patients had significant sensory gating deficits in P50-N100-P200. The schizophrenia patients had demonstrated a unique pattern of sensory gating deficits, including repetition suppression deficits in P50 and stimulus registration deficits in N100/200. These results suggest that sensory gating is a pervasive cognitive abnormality in schizophrenia patients that is not limited to the pre-attentive phase of information processing. Since P200 exhibited a large effect size and did not require additional time during recruitment, future studies of P50-N100-P200 collectively are highly recommended. © Copyright © 2020 Shen, Chou, Lai, Hsieh, Liu, Liu and Hwu.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091371162
Madrid R.; Guariglia S.R.; Haworth A.; Korosh W.; Gavin M.; Lyon G.J.,"Madrid, Ricardo (7005516533); Guariglia, Sara R. (37109633700); Haworth, Andrea (23134548500); Korosh, William (6507566862); Gavin, Maureen (28267635800); Lyon, Gholson J. (57196750882)",7005516533; 37109633700; 23134548500; 6507566862; 28267635800; 57196750882,Early-onset cerebellar ataxia in a patient with CMT2A2,2020,Cold Spring Harbor Molecular Case Studies,6,3,a005108,,,,2,10.1101/MCS.A005108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086605750&doi=10.1101%2fMCS.A005108&partnerID=40&md5=4093e63866bddb4f23923a77c0369cbd,"A 9-yr 8-mo-old right-handed female presented with a history of gait difficulties, which first became apparent at age 9 mo of age, along with slurred speech and hand tremors while holding a tray. Her past medical history was significant for global developmental delay, and she was attending fourth grade special education classes. On examination, she had an ataxic gait, dysarthria, absent deep tendon reflexes, and flexor plantar responses. There were no signs of optic atrophy or hearing loss. Nerve conduction studies were consistent with an axonal neuropathy. A fascicular sural nerve biopsy showed a marked decrease of myelinated fibers larger than 6 µm in diameter as compared with an age-matched control. By electron microscopy, clusters of degenerating axonal mitochondria in both myelinated and unmyelinated fibers were frequently found. Whole-exome sequencing revealed a heterozygous c.314C > T (p.Thr105Met) missense variant in MFN2 in the patient but not in her mother. The father was unavailable for testing. The phenotypes with MFN2 variants can be quite variable, including intellectual disability, optic atrophy, auditory impairment, spinal atrophy with or without hydromyelia, and hydrocephalus. We report here that early onset ataxia with intellectual disability can also be associated with MFN2-related Charcot–Marie–Tooth, Type 2A2A diagnosis, the most common type of autosomal dominant axonal neuropathy. © 2020 Madrid et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse and redistribution provided that the original author and source are credited.",32532879,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85086605750
Gisselsson-Solén M.; Tähtinen P.A.; Ryan A.F.; Mulay A.; Kariya S.; Schilder A.G.M.; Valdez T.A.; Brown S.; Nolan R.M.; Hermansson A.; van Ingen G.; Marom T.,"Gisselsson-Solén, Marie (21740575900); Tähtinen, Paula A. (35180564400); Ryan, Allen F. (35601525500); Mulay, Apoorva (55357814300); Kariya, Shin (7005491565); Schilder, Anne G.M. (7007062761); Valdez, Tulio A. (6602161115); Brown, Steve (57206961339); Nolan, Ryan M. (56086162800); Hermansson, Ann (7006216064); van Ingen, Gijs (56576331700); Marom, Tal (24338789300)",21740575900; 35180564400; 35601525500; 55357814300; 7005491565; 7007062761; 6602161115; 57206961339; 56086162800; 7006216064; 56576331700; 24338789300,"Panel 1: Biotechnology, biomedical engineering and new models of otitis media",2020,International Journal of Pediatric Otorhinolaryngology,130,,109833,,,,2,10.1016/j.ijporl.2019.109833,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077165747&doi=10.1016%2fj.ijporl.2019.109833&partnerID=40&md5=ed5ef9c9c68695a9000859d79565df1f,"Objective: To summarize recently published key articles on the topics of biomedical engineering, biotechnology and new models in relation to otitis media (OM). Data sources: Electronic databases: PubMed, Ovid Medline, Cochrane Library and Clinical Evidence (BMJ Publishing). Review methods: Articles on biomedical engineering, biotechnology, material science, mechanical and animal models in OM published between May 2015 and May 2019 were identified and subjected to review. A total of 132 articles were ultimately included. Results: New imaging technologies for the tympanic membrane (TM) and the middle ear cavity are being developed to assess TM thickness, identify biofilms and differentiate types of middle ear effusions. Artificial intelligence (AI) has been applied to train software programs to diagnose OM with a high degree of certainty. Genetically modified mice models for OM have further investigated what predisposes some individuals to OM and consequent hearing loss. New vaccine candidates protecting against major otopathogens are being explored and developed, especially combined vaccines, targeting more than one pathogen. Transcutaneous vaccination against non-typeable Haemophilus influenzae has been successfully tried in a chinchilla model. In terms of treatment, novel technologies for trans-tympanic drug delivery are entering the clinical domain. Various growth factors and grafting materials aimed at improving healing of TM perforations show promising results in animal models. Conclusion: New technologies and AI applications to improve the diagnosis of OM have shown promise in pre-clinical models and are gradually entering the clinical domain. So are novel vaccines and drug delivery approaches that may allow local treatment of OM. IMPLICATIONS FOR PRACTICE: New diagnostic methods, potential vaccine candidates and the novel trans-tympanic drug delivery show promising results, but are not yet adapted to clinical use. © 2019 Elsevier B.V.",31901291,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85077165747
Lin X.; Chen Y.; Wang M.; Song C.; Lin B.; Yuan X.; Liu Q.; Yang H.; Jiang N.,"Lin, Xiaofeng (57215886497); Chen, Yueyao (55966648600); Wang, Mingxia (57216438168); Song, Chao (57195715260); Lin, Bingling (57191867939); Yuan, Xiaoping (55352414000); Liu, Qingyu (57219040878); Yang, Haidi (37051569400); Jiang, Ningyi (7201943724)",57215886497; 55966648600; 57216438168; 57195715260; 57191867939; 55352414000; 57219040878; 37051569400; 7201943724,Altered Topological Patterns of Gray Matter Networks in Tinnitus: A Graph-Theoretical-Based Study,2020,Frontiers in Neuroscience,14,,541,,,,14,10.3389/fnins.2020.00541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086641018&doi=10.3389%2ffnins.2020.00541&partnerID=40&md5=b8b40c27fe8f5590ee75195c17d11937,"Objective: Tinnitus is a prevalent hearing disorder, which could have a devastating impact on a patient’s life. Functional studies have revealed connectivity pattern changes in the tinnitus brains that suggested a change of network dynamics as well as topological organization. However, no studies have yet provided evidence for the topological network changes in the gray matter. In this research, we aim to use the graph-theoretical approach to investigate the changes of topology in the tinnitus brain using structural MRI data, which could provide insights into the underlying anatomical basis for the neural mechanism in generating phantom sounds. Methods: We collected 3D MRI images on 46 bilateral tinnitus patients and 46 age and gender-matched healthy controls. Brain networks were constructed with correlation matrices of the cortical thickness and subcortical volumes of 80 cortical/subcortical regions of interests. Global network properties were analyzed using local and global efficiency, clustering coefficient, and small-world coefficient, and regional network properties were evaluated using the betweenness coefficient for hub connectivity, and interregional correlations for edge properties. Between-group differences in cortical thickness and subcortical volumes were assessed using independent sample t-tests, and local efficiency, global efficiency, clustering coefficient, sigma, and interregional correlation were compared using non-parametric permutation tests. Results: Tinnitus was found to have increased global efficiency, local efficiency, and cluster coefficient, indicating generally heightened connectivity of the network. The small-world coefficient remained normal for tinnitus, indicating intact small-worldness. Betweenness centrality analysis showed that hubs in the amygdala and parahippocampus were only found for tinnitus but not controls. In contrast, hubs in the auditory cortex, insula, and thalamus were only found for controls but not tinnitus. Interregional correlation analysis further found in tinnitus enhanced connectivity between the auditory cortex and prefrontal lobe, and decreased connectivity of the insula with anterior cingulate gyrus and parahippocampus. Conclusion: These findings provided the first morphological evidence of altered topological organization of the brain networks in tinnitus. These alterations suggest that heightened efficiency of the brain network and altered auditory-limbic connection for tinnitus, which could be developed in compensation for the auditory deafferentation, leading to overcompensation and, ultimately, an emotional and cognitive burden. © Copyright © 2020 Lin, Chen, Wang, Song, Lin, Yuan, Liu, Yang and Jiang.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85086641018
Cai Y.; Chen S.; Chen Y.; Li J.; Wang C.-D.; Zhao F.; Dang C.-P.; Liang J.; He N.; Liang M.; Zheng Y.,"Cai, Yuexin (55826218300); Chen, Suijun (12809083300); Chen, Yanhong (57202833364); Li, Jiahong (57209740379); Wang, Chang-Dong (55157826700); Zhao, Fei (57213194373); Dang, Cai-Ping (55237740000); Liang, Jianheng (57209731233); He, Nannan (57209737413); Liang, Maojin (37051140100); Zheng, Yiqing (56607507700)",55826218300; 12809083300; 57202833364; 57209740379; 55157826700; 57213194373; 55237740000; 57209731233; 57209737413; 37051140100; 56607507700,Altered Resting-State EEG microstate in idiopathic sudden sensorineural hearing loss patients with tinnitus,2019,Frontiers in Neuroscience,13,MAY,443,,,,21,10.3389/fnins.2019.00443,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068576258&doi=10.3389%2ffnins.2019.00443&partnerID=40&md5=e8e6d14b9215e8fb82fef70d2f11ff8b,"In order to clarify the central reorganization in acute period of hearing loss, this study explored the aberrant dynamics of electroencephalogram (EEG) microstates and the correlations with the features of idiopathic sudden sensorineural hearing loss (ISSNHL) and tinnitus. We used high-density EEG with 128 channels to investigate alterations in microstate parameters between 25 ISSNHL patients with tinnitus and 27 healthy subjects. This study also explored the associations between microstate characteristics and tinnitus features. Microstates were clustered into four categories. There was a reduced presence of microstate A in amplitude, coverage, lifespan, frequency and an increased presence of microstate B in frequency in ISSNHL patients with tinnitus. According to the syntax analysis, a reduced transition from microstate C to microstate A and an increased transition from microstate C to microstate B were found in ISSNHL subjects. In addition, the significant negative correlations were found between Tinnitus Handicap Inventory (THI) scores and frequency of microstate A as well as between THI scores and the probability of transition from microstate D to microstate A. While THI was positively correlated with the transition probability from microstate D to microstate B. To sum up, the significant differences in the characteristics of resting-state EEG microstates were found between ISSNHL subjects with tinnitus and healthy controls. This study suggests that the alterations of central neural networks occur in acute stage of hearing loss and tinnitus. And EEG microstate may be considered as a useful tool to study the whole brain network in ISSNHL patients. © 2019 Cai, Chen, Chen, Li, Wang, Zhao, Dang, Liang, He, Liang and Zheng.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85068576258
Tomiazzi J.S.; Pereira D.R.; Judai M.A.; Antunes P.A.; Favareto A.P.A.,"Tomiazzi, Jamile Silveira (57196346403); Pereira, Danillo Roberto (37041692000); Judai, Meire Aparecida (57196343207); Antunes, Patrícia Alexandra (57196347982); Favareto, Ana Paula Alves (36193754200)",57196346403; 37041692000; 57196343207; 57196347982; 36193754200,Performance of machine-learning algorithms to pattern recognition and classification of hearing impairment in Brazilian farmers exposed to pesticide and/or cigarette smoke,2019,Environmental Science and Pollution Research,26,7,,6481,6491,10,16,10.1007/s11356-018-04106-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059861138&doi=10.1007%2fs11356-018-04106-w&partnerID=40&md5=7776f79a7da7b347f354d9037125d474,"The use of pesticides has been increasing in agriculture, leading to a public health problem. The aim of this study was to evaluate ototoxic effects in farmers who were exposed to cigarette smoke and/or pesticides and to identify possible classification patterns in the exposure groups. The sample included 127 participants of both sexes aged between 18 and 39, who were divided into the following four groups: control group (CG), smoking group (SG), pesticide group (PG), and smoking + pesticide group (SPG). Meatoscopy, pure tone audiometry, logoaudiometry, high-frequency thresholds, and immittance testing were performed. Data were evaluated by artificial neural network (ANN), K-nearest neighbors (K-NN), and support vector machine (SVM). There was symmetry between the right and left ears, an increase in the incidence of hearing loss at high frequency and of downward sloping audiometric curve configuration, and alteration of stapedial reflex in the three exposed groups. The machine-learning classifiers achieved good classification performance (control and exposed). The best classification results occur in high type (I and II) datasets (about 90% accuracy) in k-NN test. It is concluded that both xenobiotic substances have ototoxic potential; however, their combined use does not present additive or potentiating effects recognizable by the algorithms. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",30623325,Article,Final,,Scopus,2-s2.0-85059861138
Zhao Y.; Li J.; Zhang M.; Lu Y.; Xie H.; Tian Y.; Qiu W.,"Zhao, Yanxia (57195396885); Li, Jingsong (35766898100); Zhang, Meibian (8649190800); Lu, Yao (57195395861); Xie, Hongwei (56997943800); Tian, Yu (56461757000); Qiu, Wei (56924417000)",57195396885; 35766898100; 8649190800; 57195395861; 56997943800; 56461757000; 56924417000,Machine Learning Models for the Hearing Impairment Prediction in Workers Exposed to Complex Industrial Noise: A Pilot Study,2019,Ear and Hearing,40,3,,690,699,9,36,10.1097/AUD.0000000000000649,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065335190&doi=10.1097%2fAUD.0000000000000649&partnerID=40&md5=d168248309cf431a18a36f678cf0575c,"Objectives: To demonstrate the feasibility of developing machine learning models for the prediction of hearing impairment in humans exposed to complex non-Gaussian industrial noise. Design: Audiometric and noise exposure data were collected on a population of screened workers (N = 1,113) from 17 factories located in Zhejiang province, China. All the subjects were exposed to complex noise. Each subject was given an otologic examination to determine their pure-tone hearing threshold levels and had their personal full-shift noise recorded. For each subject, the hearing loss was evaluated according to the hearing impairment definition of the National Institute for Occupational Safety and Health. Age, exposure duration, equivalent A-weighted SPL (LAeq), and median kurtosis were used as the input for four machine learning algorithms, that is, support vector machine, neural network multilayer perceptron, random forest, and adaptive boosting. Both classification and regression models were developed to predict noise-induced hearing loss applying these four machine learning algorithms. Two indexes, area under the curve and prediction accuracy, were used to assess the performances of the classification models for predicting hearing impairment of workers. Root mean square error was used to quantify the prediction performance of the regression models. Results: A prediction accuracy between 78.6 and 80.1% indicated that the four classification models could be useful tools to assess noise-induced hearing impairment of workers exposed to various complex occupational noises. A comprehensive evaluation using both the area under the curve and prediction accuracy showed that the support vector machine model achieved the best score and thus should be selected as the tool with the highest potential for predicting hearing impairment from the occupational noise exposures in this study. The root mean square error performance indicated that the four regression models could be used to predict noise-induced hearing loss quantitatively and the multilayer perceptron regression model had the best performance. Conclusions: This pilot study demonstrated that machine learning algorithms are potential tools for the evaluation and prediction of noise-induced hearing impairment in workers exposed to diverse complex industrial noises. © 2018 Wolters Kluwer Health, Inc.",30142102,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85065335190
Chang Y.-S.; Park H.; Hong S.H.; Chung W.-H.; Cho Y.-S.; Joon Moon I.I.,"Chang, Young-Soo (56193558800); Park, Heesung (56215993500); Hong, Sung Hwa (21934425200); Chung, Won-Ho (7401983065); Cho, Yang-Sun (23471632700); Joon Moon, I.I. (57209139593)",56193558800; 56215993500; 21934425200; 7401983065; 23471632700; 57209139593,Predicting cochlear dead regions in patients with hearing loss through a machine learning-based approach: A preliminary study,2019,PLoS ONE,14,6,e0217790,,,,11,10.1371/journal.pone.0217790,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066622673&doi=10.1371%2fjournal.pone.0217790&partnerID=40&md5=947982a6f6e9fed6ddf81e368fab8beb,"We propose a machine learning (ML)-based model for predicting cochlear dead regions (DRs) in patients with hearing loss of various etiologies. Five hundred and fifty-five ears from 380 patients (3,770 test samples) diagnosed with sensorineural hearing loss (SNHL) were analyzed. A threshold-equalizing noise (TEN) test was applied to detect the presence of DRs. Data were collected on sex, age, side of the affected ear, hearing loss etiology, word recognition scores (WRS), and pure-tone thresholds at each frequency. According to the cause of hearing loss as diagnosed by the physician, we categorized the patients into six groups: 1) SNHL with unknown etiology; 2) sudden sensorineural hearing loss (SSNHL); 3) vestibular schwannoma (VS); 4) Meniere’s disease (MD); 5) noise-induced hearing loss (NIHL); or 6) presbycusis or age-related hearing loss (ARHL). To develop a predictive model, we performed recursive partitioning and regression for classification, logistic regression, and random forest. The overall prevalence of one or more DRs in test ears was 20.36% (113 ears). Among the 3,770 test samples, the overall frequency-specific prevalence of DR was 6.7%. WRS, pure-tone thresholds at each frequency, disease type (VS or MD), and frequency information were useful for predicting DRs. Sex and age were not associated with detecting DRs. Based on these results, we suggest possible predictive factors for determining the presence of DRs. To improve the predictive power of the model, a more flexible model or more clinical features, such as the duration of hearing loss or risk factors for developing DRs, may be needed. © 2019 Chang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",31158267,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85066622673
You E.; Lin V.; Mijovic T.; Eskander A.; Crowson M.G.,"You, Eunice (57206171244); Lin, Vincent (7005816469); Mijovic, Tamara (26434782600); Eskander, Antoine (35848359800); Crowson, Matthew G. (56631418200)",57206171244; 7005816469; 26434782600; 35848359800; 56631418200,Artificial Intelligence Applications in Otology: A State of the Art Review,2020,Otolaryngology - Head and Neck Surgery (United States),163,6,,1123,1133,10,21,10.1177/0194599820931804,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086237068&doi=10.1177%2f0194599820931804&partnerID=40&md5=1c647c6cbe1273d08601e7fe109f3603,"Objective: Recent advances in artificial intelligence (AI) are driving innovative new health care solutions. We aim to review the state of the art of AI in otology and provide a discussion of work underway, current limitations, and future directions. Data Sources: Two comprehensive databases, MEDLINE and EMBASE, were mined using a directed search strategy to identify all articles that applied AI to otology. Review Methods: An initial abstract and title screening was completed. Exclusion criteria included nonavailable abstract and full text, language, and nonrelevance. References of included studies and relevant review articles were cross-checked to identify additional studies. Conclusion: The database search identified 1374 articles. Abstract and title screening resulted in full-text retrieval of 96 articles. A total of N = 38 articles were retained. Applications of AI technologies involved the optimization of hearing aid technology (n = 5; 13% of all articles), speech enhancement technologies (n = 4; 11%), diagnosis and management of vestibular disorders (n = 11; 29%), prediction of sensorineural hearing loss outcomes (n = 9; 24%), interpretation of automatic brainstem responses (n = 5; 13%), and imaging modalities and image-processing techniques (n = 4; 10%). Publication counts of the included articles from each decade demonstrated a marked increase in interest in AI in recent years. Implications for Practice: This review highlights several applications of AI that otologists and otolaryngologists alike should be aware of given the possibility of implementation in mainstream clinical practice. Although there remain significant ethical and regulatory challenges, AI powered systems offer great potential to shape how healthcare systems of the future operate and clinicians are key stakeholders in this process. © American Academy of Otolaryngology–Head and Neck Surgery Foundation 2020.",32513061,Review,Final,,Scopus,2-s2.0-85086237068
Jackler R.K.; Jan T.A.,"Jackler, R.K. (7005247400); Jan, T.A. (54083171700)",7005247400; 54083171700,The future of otology,2019,Journal of Laryngology and Otology,133,9,,747,758,11,8,10.1017/S0022215119001531,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072230467&doi=10.1017%2fS0022215119001531&partnerID=40&md5=1b5b290b0cdc0139431f65f8ad99bb09,"Background The field of otology is increasingly at the forefront of innovation in science and medicine. The inner ear, one of the most challenging systems to study, has been rendered much more open to inquiry by recent developments in research methodology. Promising advances of potential clinical impact have occurred in recent years in biological fields such as auditory genetics, ototoxic chemoprevention and organ of Corti regeneration. The interface of the ear with digital technology to remediate hearing loss, or as a consumer device within an intelligent ecosystem of connected devices, is receiving enormous creative energy. Automation and artificial intelligence can enhance otological medical and surgical practice. Otology is poised to enter a new renaissance period, in which many previously untreatable ear diseases will yield to newly introduced therapies.Objective This paper speculates on the direction otology will take in the coming decades.Conclusion Making predictions about the future of otology is a risky endeavour. If the predictions are found wanting, it will likely be because of unforeseen revolutionary methods. © 2019 JLO (1984) Limited.",31462337,Article,Final,,Scopus,2-s2.0-85072230467
Hong H.; Dowdy D.W.; Dooley K.E.; Francis H.W.; Budhathoki C.; Han H.-R.; Farley J.E.,"Hong, H. (57200142157); Dowdy, D.W. (6603069678); Dooley, K.E. (35616578800); Francis, H.W. (35298907500); Budhathoki, C. (23988531200); Han, H.-R. (7401969194); Farley, J.E. (8879472600)",57200142157; 6603069678; 35616578800; 35298907500; 23988531200; 7401969194; 8879472600,Risk of hearing loss among multidrug-resistant tuberculosis patients according to cumulative aminoglycoside dose,2020,International Journal of Tuberculosis and Lung Disease,24,1,,65,72,7,12,10.5588/ijtld.19.0062,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078858828&doi=10.5588%2fijtld.19.0062&partnerID=40&md5=fc8fdd82d1be0c4464928d9d6845c865,"SETTING: The ototoxic effects of aminoglycosides (AGs) lead to permanent hearing loss, which is one of the devastating consequences of multidrug-resistant tuberculosis (MDR-TB) treatment. As AG ototoxicity is dose-dependent, the impact of a surrogate measure of AG exposure on AG-induced hearing loss warrants close attention for settings with limited therapeutic drug monitoring. O B J E C T I V E: To explore the prognostic impact of cumulative AG dose on AG ototoxicity in patients following initiation of AG-containing treatment for MDR-TB. DESIGN: This prospective cohort study was nested within an ongoing cluster-randomized trial of nurse case management intervention across 10 MDR-TB hospitals in South Africa. RESULTS: The adjusted hazard of AG regimen modification due to ototoxicity in the high-dose group (≥75 mg/kg/week) was 1.33 times higher than in the low-dose group (,75 mg/kg/week, 95%CI 1.09-1.64). The adjusted hazard of developing audiometric hearing loss was 1.34 times higher than in the low-dose group (95%CI 1.01-1.77). Pre-existing hearing loss (adjusted hazard ratio [aHR] 1.71, 95%CI 1.29-2.26) and age (aHR 1.16 per 10 years of age, 95%CI 1.01-1.33) were also associated with an increased risk of hearing loss. CONCLUSION: MDR-TB patients with high AG dose, advanced age and pre-existing hearing loss have a significantly higher risk of AG-induced hearing loss. Those at high risk may be candidates for more frequent monitoring or AG-sparing regimens. © 2020 The Union",32005308,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85078858828
Berland A.; Collett E.; Gaillard P.; Guidetti M.; Strelnikov K.; Cochard N.; Barone P.; Deguine O.,"Berland, Aurore (56505312900); Collett, Edward (57188739369); Gaillard, Pascal (56622475100); Guidetti, Michèle (6701496065); Strelnikov, Kuzma (55967530400); Cochard, Nadine (6603031128); Barone, Pascal (7102266372); Deguine, Olivier (7003638549)",56505312900; 57188739369; 56622475100; 6701496065; 55967530400; 6603031128; 7102266372; 7003638549,Categorization of everyday sounds by cochlear implanted children,2019,Scientific Reports,9,1,3532,,,,3,10.1038/s41598-019-39991-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062584949&doi=10.1038%2fs41598-019-39991-9&partnerID=40&md5=4d2017413758c3025617b6f3af8ba60a,"Auditory categorization is an important process in the perception and understanding of everyday sounds. The use of cochlear implants (CIs) may affect auditory categorization and result in poor abilities. The current study was designed to compare how children with normal hearing (NH) and children with CIs categorize a set of everyday sounds. We tested 24 NH children and 24 children with CI on a free-sorting task of 18 everyday sounds corresponding to four a priori categories: nonlinguistic human vocalizations, environmental sounds, musical sounds, and animal vocalizations. Multiple correspondence analysis revealed considerable variation within both groups of child listeners, although the human vocalizations and musical sounds were similarly categorized. In contrast to NH children, children with CIs categorized some sounds according to their acoustic content rather than their associated semantic information. These results show that despite identification deficits, children with CIs are able to categorize environmental and vocal sounds in a similar way to NH children, and are able to use categorization as an adaptive process when dealing with everyday sounds. © 2019, The Author(s).",30837546,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85062584949
Moatti A.; Cai Y.; Li C.; Sattler T.; Edwards L.; Piedrahita J.; Ligler F.S.; Greenbaum A.,"Moatti, Adele (56066482500); Cai, Yuheng (57219625527); Li, Chen (57219625408); Sattler, Tyler (57205462804); Edwards, Laura (57219625979); Piedrahita, Jorge (7005030948); Ligler, Frances S. (57209036471); Greenbaum, Alon (55740693400)",56066482500; 57219625527; 57219625408; 57205462804; 57219625979; 7005030948; 57209036471; 55740693400,Three-dimensional imaging of intact porcine cochlea using tissue clearing and custom-built light-sheet microscopy,2020,Biomedical Optics Express,11,11,,6181,6196,15,18,10.1364/BOE.402991,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094324251&doi=10.1364%2fBOE.402991&partnerID=40&md5=e1239c284244e30446b25ce40eea461a,"Hearing loss is a prevalent disorder that affects people of all ages. On top of the existing hearing aids and cochlear implants, there is a growing effort to regenerate functional tissues and restore hearing. However, studying and evaluating these regenerative medicine approaches in a big animal model (e.g. pigs) whose anatomy, physiology, and organ size are similar to a human is challenging. In big animal models, the cochlea is bulky, intricate, and veiled in a dense and craggy otic capsule. These facts complicate 3D microscopic analysis that is vital in the cochlea, where structure-function relation is time and again manifested. To allow 3D imaging of an intact cochlea of newborn and juvenile pigs with a volume up to ∼ 250 mm3, we adapted the BoneClear tissue clearing technique, which renders the bone transparent. The transparent cochleae were then imaged with cellular resolution and in a timely fashion, which prevented bubble formation and tissue degradation, using an adaptive custom-built light-sheet fluorescence microscope. The adaptive light-sheet microscope compensated for deflections of the illumination beam by changing the angles of the beam and translating the detection objective while acquiring images. Using this combination of techniques, macroscopic and microscopic properties of the cochlea were extracted, including the density of hair cells, frequency maps, and lower frequency limits. Consequently, the proposed platform could support the growing effort to regenerate cochlear tissues and assist with basic research to advance cures for hearing impairments. © 2020 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85094324251
Yu P.; Fan W.; Kong X.; Lei Z.; Yu J.,"Yu, Peilin (57212305296); Fan, Wenliang (55624403100); Kong, Xiangchuang (56310389300); Lei, Ziqiao (8570447200); Yu, Jianming (56420663100)",57212305296; 55624403100; 56310389300; 8570447200; 56420663100,Feasibility of constructing a unilateral sudden sensorineural hearing loss machine learning classification model based on diffusion tensor imaging; [基于扩散张量成像构建单侧突发感音神经性耳聋机器学习分类模型的可行性],2019,Chinese Journal of Radiology (China),53,9,,767,771,4,0,10.3760/cma.j.issn.1005-1201.2019.09.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076413394&doi=10.3760%2fcma.j.issn.1005-1201.2019.09.010&partnerID=40&md5=e378aea3401f5676052631346d3f3e45,"Objective: To explore the feasibility of constructing a machine learning classification model for unilateral sudden sensorineural hearing loss (SSHL) patients and normal controls based on diffusion tensor imaging. Methods: Prospective collection of 84 patients with untreated SSHL were recruited from the otolaryngology department of the Union Hospital of Tongji Medical College of Huazhong University of Science and Technology between June 2013 to May 2015 as the SSHL group. Meanwhile, a total of 63 healthy volunteers who were no any ear disease history, and the hearing function were confirmed with pure tone audiometry, were collected as the control group. All subjects underwent a brain DTI scan. The data were divided into the training set and validation set according to the ratio of 7 to 3, that was, the training set contained 58 cases of SSHL patients and 44 control groups, and the validation set included 26 cases of SSHL patients and 19 control groups. A vector which included the DTI parameters such as fractional anisotropy, mean diffusivity, axial diffusivity and radial diffusivity was constructed with the software R. The LASSO regression of machine learning method was used to perform feature dimensionality reduction and construct a classification model. The training set samples were used to map the nomogram based on the multivariate logistic analysis method, the validation set and the AUC were used to evaluate the prediction ability of the nomogram, and the calibration curve was used to evaluate the model. Results: From the 200 feature vectors including the fractional anisotropy (FA), mean diffusivity (MD), axial diffusivity (AD), and radial diffusivity (RD) values of each brain region, after each dimension reduction process, a total of six features were retained, which were the MD of left superior corona radiate and right superior fronto-occipital fasciculus, the AD of the body of corpus callosum, and the RD of left inferior cerebellar peduncle, left superior corona radiate and right posterior limb of internal capsule. The six features of patients with unilateral SSHL were higher than the control group, and the difference was statistically significant (P<0.05). Based on this, a two-class model is constructed and a nomogram is drawn. The sensitivity, specificity, accuracy and AUC of the training set were 93.1% (54/58), 72.7% (32/44), 84.3% (86/102) and 0.854, respectively; the sensitivity, specificity, accuracy and AUC of validation set were 80.8% (21/26), 84.2% (16/19), 82.2% (37/45), 0.870, respectively. Nomogram could significantly improve the classification efficiency of the control group and patients, and the model with the LASSO method showed a higher prediction curve than other models. Conclusions: The machine learning classification model based on DTI metrics can effectively distinguish patients with unilateral sudden sensorineural deafness from healthy control people. Copyright © 2019 by the Chinese Medical Association.",,Article,Final,,Scopus,2-s2.0-85076413394
Dixon P.R.; Shipp D.; Smilsky K.; Lin V.Y.; Le T.; Chen J.M.,"Dixon, Peter R. (55429000200); Shipp, David (7006177253); Smilsky, Kari (26654465200); Lin, Vincent Y. (58769161600); Le, Trung (56086297300); Chen, Joseph M. (7501883246)",55429000200; 7006177253; 26654465200; 58769161600; 56086297300; 7501883246,Association of Speech Processor Technology and Speech Recognition Outcomes in Adult Cochlear Implant Users,2019,Otology and Neurotology,40,5,,595,601,6,6,10.1097/MAO.0000000000002172,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066061553&doi=10.1097%2fMAO.0000000000002172&partnerID=40&md5=d028f64825d5bcc275ae009da7b0e1c9,"Objective: Determine association of advancements in speech processor technology with improvements in speech recognition outcomes. Study Design: Retrospective cohort. Setting: Tertiary referral center. Patients: Adult unilateral cochlear implant (CI) recipients. Intervention: Increasing novelty of speech processor defined by year of market availability. Main Outcome Measures: Consonant-Nucleus-Consonant (CNC) and Hearing in Noise Test (HINT) in quiet. Results: From 1991 to 2016, 1,111 CNC scores and 1,121 HINT scores were collected from 351 patients who had complete data. Mean post-implantation CNC score was 53.8% and increased with more recent era of implantation ( p<0.001, analysis of variance [ANOVA]). Median HINT score was 87.0% and did not significantly vary with implantation era ( p=0.06, ANOVA). Multivariable generalized linear models were fitted to estimate the effect of speech processor novelty on CNC and HINT scores, each accounting for clustering of scores within patients and characteristics known to influence speech recognition outcomes. Each 5-year increment in speech processor novelty was independently associated with an increase in CNC score by 2.85% (95% confidence limits [CL] 0.26, 5.44%) and was not associated with change in HINT scores ( p=0.30). Conclusion: Newer speech processors are associated with improved CNC scores independent of the year of device implantation and expanding candidacy criteria. The lack of association with HINT scores can be attributed to a ceiling effect, suggesting that HINT in quiet may not be an informative test of speech recognition in the modern CI recipient. The implications of these findings with respect to appropriate interval of speech processor upgrades are discussed.  © 2019, Otology & Neurotology, Inc.",31083080,Article,Final,,Scopus,2-s2.0-85066061553
Bennett R.J.; Meyer C.J.; Eikelboom R.H.,"Bennett, Rebecca J. (57222869276); Meyer, Carly J. (26027432100); Eikelboom, Robert H. (7006848551)",57222869276; 26027432100; 7006848551,How do hearing aid owners acquire hearing aid management skills?,2019,Journal of the American Academy of Audiology,30,6,,516,532,16,4,10.3766/jaaa.17129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068809094&doi=10.3766%2fjaaa.17129&partnerID=40&md5=99a80aa43b985a27ee4ddc1a0c88bc08,"Background: Clinical studies have found up to 90% of hearing aid owners demonstrate difficulty with basic hearing aid management tasks and almost 50% of hearing aid owners self-report not receiving enough practical help from their clinician regarding how to use their hearing aid. Although studies have highlighted the overwhelming amount of information and training required to learn how to use a hearing aid appropriately, a gap remains in the literature regarding the range of methods by which hearing aid owners acquire the knowledge and skills for hearing aid use, and whether these approaches are considered beneficial. Purpose: To gain insight into how both hearing aid owners and hearing health clinicians view the acquisition of hearing aid management skills and the efficacy of currently used methods of hearing aid training. Research Design: Concept mapping techniques were used to identify key themes, wherein participants generated, sorted, and rated the importance of statements in response to the question ''How do hearing aid owners learn the skills required to use, handle, manage, maintain, and care for their hearing aids?'' Study Sample: Twenty-four hearing aid owners (aged 56-91 years; 54.2% male) and 22 clinicians (aged 32-69 years; 9.1% male). Data collection and Analysis: Participant perspectives were collected via group concept mapping sessions in October 2015. Hierarchical cluster analysis was used to identify themes and develop a framework for understanding how skill acquisition occurs. Participants rated each method of hearing aid skill acquisition as to how beneficial it was and how often it was used. Results: Participants identified 75 unique items describing how hearing aid management skills are acquired within six concepts: (1) Relationship with the clinician, (2) clinician as a source of knowledge and support, (3) hands-on experience, (4) seeking additional information, (5) asking support people for help, and (6) external resources. Conclusions: The results of this study highlight the diverse methods and sources by which hearing aid owners learn the skills necessary to use, manage, and maintain their hearing aids. Significant emphasis was placed on the role of the hearing health clinician to provide training, support, and an ongoing professional relationship, with lesser roles played by family, friends, and other health professionals. © 2019 American Academy of Audiology. All rights reserved.",30969909,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85068809094
Charih F.; Steeves A.; Bromwich M.; Mark A.E.; Lefrancois R.; Green J.R.,"Charih, Francois (57202033563); Steeves, Ashlynn (57205491890); Bromwich, Matthew (57192121176); Mark, Amy E. (57203838568); Lefrancois, Renee (57203844950); Green, James R. (57190496220)",57202033563; 57205491890; 57192121176; 57203838568; 57203844950; 57190496220,Applications of Machine Learning Methods in Retrospective Studies on Hearing,2018,"2018 IEEE Life Sciences Conference, LSC 2018",,,8572268,126,129,3,3,10.1109/LSC.2018.8572268,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060239928&doi=10.1109%2fLSC.2018.8572268&partnerID=40&md5=144c570358636184f81d1fff77d0566f,"Hearing healthcare professionals rely on the audiograms produced through pure tone audiometry, among other tests, to diagnose and treat hearing loss. Researchers also rely on audiograms to study the prevalence of hearing loss in various populations. Notably, due to the available test time, intraoctave frequencies are not often recorded, even though they can contribute to certain diagnoses. Previous work has proposed the imputation of these thresholds using a simple average of neighboring thresholds. In this work, we present an alternative approach for addressing missing intra-octave thresholds that relies on a $\pmb{k}$ -nearest neighbors algorithm and show that accuracy can be slightly improved using a data-driven approach to imputation. We also present a Gaussian mixture model-based approach to flagging atypical or potentially unreliable audiograms to produce high quality datasets. Our method allows the imputation of intra-octave thresholds with an accuracy no worse than simple averaging. For the more challenging 6000 Hz threshold, our method appears to be particularly effective. Overall, our method allows for improved presentation of complete audiogram datasets. © 2018 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85060239928
Bright T.; Mactaggart I.; Kuper H.; Murthy G.V.; Polack S.,"Bright, Tess (57193859076); Mactaggart, Islay (56255420000); Kuper, Hannah (7004023998); Murthy, G.V. (56654874600); Polack, Sarah (6602403285)",57193859076; 56255420000; 7004023998; 56654874600; 6602403285,"Prevalence of Hearing Impairment in Mahabubnagar District, Telangana State, India",2019,Ear and Hearing,40,1,,204,212,8,13,10.1097/AUD.0000000000000599,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059113075&doi=10.1097%2fAUD.0000000000000599&partnerID=40&md5=3b13721a4a8cd61d59372d7300246d59,"Objectives: To estimate the prevalence of hearing impairment in Mahabubnagar district, Telangana state, India. Methods: A population-based prevalence survey of hearing impairment was undertaken in 2014. Fifty-one clusters of 80 people aged 6 months and older were selected using probability-proportionate-to-size sampling. A two-stage hearing screening was conducted using otoacoustic emissions on all participants followed by pure-tone audiometry on those aged 4 years and older who failed otoacoustic emissions. Cases of hearing impairment were defined using the World Health Organization definition of disabling hearing impairment: a pure-tone average of thresholds at 500, 1000, 2000, and 4000 Hz of ≥41 dB HL for adults and ≥31 dB HL for children based on the better ear. Possible causes of hearing impairment were ascertained by a certified audiologist. Reported hearing difficulties were also measured in this survey and compared with audiometry results. Results: Three thousand five hundred seventy-three people were examined (response rate 87%), of whom 52% were female. The prevalence of disabling hearing impairment was 4.5% [95% confidence interval (CI) = 3.8 to 5.3). Disabling hearing impairment prevalence increased with age from 0.4% in those aged 4 to 17 years (95% CI = 0.2 to 1.1) to 34.7% (95% CI = 28.7 to 41.1) in those aged older than 65 years. No difference in prevalence was seen by sex. Ear examination suggested that the possible cause of disabling hearing impairment was chronic suppurative otitis media for 6.9% of cases and dry perforation for 5.6% cases. For the vast majority of people with disabling hearing impairment, a possible cause could not be established. The overall prevalence of reported or proxy reported hearing impairment was 2.6% (95% CI = 2.0 to 3.4), and this ranged from 0.6% (95% CI = 0.08 to 4.4) in those aged 0 to 3 years to 14.4% (95% CI = 9.8 to 20.7) in those aged older than 65 years. Conclusions: Disabling hearing impairment in Telangana State is common, affecting approximately 1 in 23 people overall and a third of people aged older than 65 years. These findings suggest that there are a substantial number of individuals with hearing impairment who could potentially benefit from improved access to low-cost interventions. Copyright © 2018 American Auditory Society . Printed in the U.S.A.",29782444,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85059113075
Liu Y.-W.; Kao S.-L.; Wu H.-T.; Liu T.-C.; Fang T.-Y.; Wang P.-C.,"Liu, Yi-Wen (55581071600); Kao, Sheng-Lun (57214590365); Wu, Hau-Tieng (36451741900); Liu, Tzu-Chi (57192298455); Fang, Te-Yung (54784197600); Wang, Pa-Chun (7405458813)",55581071600; 57214590365; 36451741900; 57192298455; 54784197600; 7405458813,Transient-evoked otoacoustic emission signals predicting outcomes of acute sensorineural hearing loss in patients with Ménière’s disease,2020,Acta Oto-Laryngologica,140,3,,230,235,5,10,10.1080/00016489.2019.1704865,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078837574&doi=10.1080%2f00016489.2019.1704865&partnerID=40&md5=f1b28f81fc935c3d1274851023f37e2d,"Background: Fluctuating hearing loss is characteristic of Ménière’s disease (MD) during acute episodes. However, no reliable audiometric hallmarks are available for counselling the hearing recovery possibility. Aims/objectives: To find parameters for predicting MD hearing outcomes. Material and methods: We applied machine learning techniques to analyse transient-evoked otoacoustic emission (TEOAE) signals recorded from patients with MD. Thirty unilateral MD patients were recruited prospectively after onset of acute cochleo-vestibular symptoms. Serial TEOAE and pure-tone audiogram (PTA) data were recorded longitudinally. Denoised TEOAE signals were projected onto the three most prominent principal directions through a linear transformation. Binary classification was performed using a support vector machine (SVM). TEOAE signal parameters, including signal energy and group delay, were compared between improved (PTA improvement: ≥15 dB) and nonimproved groups using Welch’s t-test. Results: Signal energy did not differ (p =.64) but a significant difference in 1-kHz (p =.045) group delay was recorded between improved and nonimproved groups. The SVM achieved a cross-validated accuracy of >80% in predicting hearing outcomes. Conclusions and significance: This study revealed that baseline TEOAE parameters obtained during acute MD episodes, when processed through machine learning technology, may provide information on outer hair cell function to predict hearing recovery. © 2020, © 2020 Acta Oto-Laryngologica AB (Ltd).",32003266,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85078837574
Baldridge D.; Spillmann R.C.; Wegner D.J.; Wambach J.A.; White F.V.; Sisco K.; Toler T.L.; Dickson P.I.; Cole F.S.; Shashi V.; Grange D.K.,"Baldridge, Dustin (6602512817); Spillmann, Rebecca C. (56891574800); Wegner, Daniel J. (7006783758); Wambach, Jennifer A. (24175276900); White, Frances V. (7202578909); Sisco, Kathleen (57209074712); Toler, Tomi L. (55519839200); Dickson, Patricia I. (7005285218); Cole, F. Sessions (7102534359); Shashi, Vandana (57197505862); Grange, Dorothy K. (56622571200)",6602512817; 56891574800; 7006783758; 24175276900; 7202578909; 57209074712; 55519839200; 7005285218; 7102534359; 57197505862; 56622571200,Phenotypic expansion of KMT2D-related disorder: Beyond Kabuki syndrome,2020,"American Journal of Medical Genetics, Part A",182,5,,1053,1065,12,21,10.1002/ajmg.a.61518,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083907753&doi=10.1002%2fajmg.a.61518&partnerID=40&md5=25df507b6fd9038773656da014bfdda0,"Pathogenic variants in KMT2D, which encodes lysine specific methyltransferase 2D, cause autosomal dominant Kabuki syndrome, associated with distinctive dysmorphic features including arched eyebrows, long palpebral fissures with eversion of the lower lid, large protuberant ears, and fetal finger pads. Most disease-causing variants identified to date are putative loss-of-function alleles, although 15–20% of cases are attributed to missense variants. We describe here four patients (including one previously published patient) with de novo KMT2D missense variants and with shared but unusual clinical findings not typically seen in Kabuki syndrome, including athelia (absent nipples), choanal atresia, hypoparathyroidism, delayed or absent pubertal development, and extreme short stature. These individuals also lack the typical dysmorphic facial features found in Kabuki syndrome. Two of the four patients had severe interstitial lung disease. All of these variants cluster within a 40-amino-acid region of the protein that is located just N-terminal of an annotated coiled coil domain. These findings significantly expand the phenotypic spectrum of features associated with variants in KMT2D beyond those seen in Kabuki syndrome and suggest a possible new underlying disease mechanism for these patients. © 2020 Wiley Periodicals, Inc.",32083401,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85083907753
Zhang H.; Wang D.; Ma H.; Ren Y.; Li C.; Zheng Y.; Dai X.; Yang L.; Xu L.,"Zhang, Huai (57222507391); Wang, Dahui (57197844654); Ma, Haiyan (55723503600); Ren, Ying (57211903368); Li, Chenhui (57215336739); Zheng, Yihua (57216891682); Dai, Xiaoming (57219878594); Yang, Lei (56401965900); Xu, Liangwen (56142265600)",57222507391; 57197844654; 55723503600; 57211903368; 57215336739; 57216891682; 57219878594; 56401965900; 56142265600,Increased atherogenic index in the general hearing loss population,2020,Open Medicine (Poland),15,1,,349,357,8,6,10.1515/med-2020-0003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095881563&doi=10.1515%2fmed-2020-0003&partnerID=40&md5=d771d517fe9a94cb37e6dd33a7850018,"Purpose. The purpose of this study was to evaluate the association of hearing loss with atherogenic index (AI) in the general population. Methods. A multistage study using cluster random sampling method was conducted in the Zhejiang province from 2016 to 2018. Pure-tone air-conduction hearing thresholds were measured at frequencies of 0.125.8kHz for each subject. After obtaining their consent, all participants were asked to provide their own plasma lipid data. Results. A total of 3,414 eligible participants were included, 1,765 (51.7%) were men and 1,649 (48.3%) were women and 1,113 (32.6%) had hearing loss. Ridge regression showed increased AI in subjects with hearing loss. The subgroup with the highest quartile of AI, presenting the highest risk of hearing loss as compared to the lowest quartile, comprised young and middle-aged women. Further analysis revealed that the AI in people with different categories of hearing loss was higher than that in the normal population, except for those with (extremely) severe hearing loss. Moreover, the young and middle-aged women exhibited the most significant correlations between AI and hearing loss. © 2020 Huai Zhang et al.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85095881563
Hong H.; Dowdy D.W.; Dooley K.E.; Francis H.W.; Budhathoki C.; Han H.-R.; Farley J.E.,"Hong, Hyejeong (57200142157); Dowdy, David W. (6603069678); Dooley, Kelly E. (35616578800); Francis, Howard W. (35298907500); Budhathoki, Chakra (23988531200); Han, Hae-Ra (7401969194); Farley, Jason E. (8879472600)",57200142157; 6603069678; 35616578800; 35298907500; 23988531200; 7401969194; 8879472600,Prevalence of pre-existing hearing loss among patients with drug-resistant tuberculosis in South Africa,2020,American Journal of Audiology,29,2,,199,205,6,6,10.1044/2020_AJA-19-00103,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086052797&doi=10.1044%2f2020_AJA-19-00103&partnerID=40&md5=11e42a9af384402bcba66a0b84c4e036,"Purpose: Hearing loss, resulting from aminoglycoside ototoxicity, is common among patients with drug-resistant tuberculosis (DR-TB). Those with pre-existing hearing loss are at particular risk of clinically important hearing loss with aminoglycoside-containing treatment than those with normal hearing at baseline. This study aimed to identify factors associated with pre-existing hearing loss among patients being treated for DR-TB in South Africa. Method: Cross-sectional analysis nested within a cluster-randomized trial data across 10 South African TB hospitals. Patients ≥ 13 years old received clinical and audiological evaluations before DR-TB treatment initiation. Results: Of 936 patients, average age was 35 years. One hundred forty-two (15%) reported pre-existing auditory symptoms. Of 482 patients tested by audiometry, 290 (60%) had pre-existing hearing loss. The prevalence of pre-existing hearing loss was highest among patients ≥ 50 years (adjusted prevalence ratio [aPrR] for symptoms 5.53, 95% confidence interval (CI) [3.63, 8.42]; aPrR for audiometric hearing loss 1.63, 95% CI [1.31, 2.03] compared to age 13–18 years) and among those with a prior history of second-line TB treatment (aPrR for symptoms 1.73, 95% CI [1.66, 1.80]; PrR for audiometric hearing loss 1.33, 95% CI [1.03, 1.73]). Having HIV with cluster of differentiation 4 cell count < 200 cells/mm3 and malnutrition were risk factors but did not reach statistical significance in adjusted analyses. Conclusion: Pre-existing hearing loss is common among patients presenting for DR-TB treatment in South Africa, and those older than the age of 50 years or who had prior second-line TB treatment history were at highest risk. © 2020 American Speech-Language-Hearing Association.",32320639,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85086052797
Ajduk J.; Košec A.; Kelava I.; Ries M.; Gregurić T.; Kalogjera L.,"Ajduk, Jakov (24068676200); Košec, Andro (37002895900); Kelava, Iva (57193930965); Ries, Mihael (24072079800); Gregurić, Tomislav (55982484100); Kalogjera, Livije (6603361937)",24068676200; 37002895900; 57193930965; 24072079800; 55982484100; 6603361937,Recovery from sudden sensorineural hearing loss may be linked to chronic stress levels and steroid treatment resistance,2019,American Journal of Audiology,28,2,,315,321,6,5,10.1044/2019_AJA-18-0127,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067906848&doi=10.1044%2f2019_AJA-18-0127&partnerID=40&md5=76b45fa5503895723776c8d68ff8ebad,"Purpose: This article investigates the possible connections between the level of chronic stress and success of steroid therapy in patients with sudden sensorineural hearing loss (SSNHL). Method: A single-center, retrospective, longitudinal cohort studyon55patientsinatertiary referral otology center was examined. Patients diagnosed with SSNHL between 2014 and 2017 were asked to complete a Measure of Perceived Stress (Brajac, Tkalcic, Dragojević, &Gruber, 2003) questionnaire. Inclusion criteria were patients > 18 years of age, SSNHL diagnosed within 4 previous weeks, completed steroid treatment, and complete documentation. Results: There were 30 patients (55%) that showed significant improvement in their pure-tone audiogram (PTA) hearing threshold average (≥ 15 dB) after steroid treatment. Two-step cluster analysis identified 3 clusters based on average PTA hearing threshold recovery and average Measure of Perceived Stress scores. The difference between pretreatment and posttreatment hearing levels was significantly higher in the cluster with moderate stress compared to clusters with mild and high stress levels (Kruskal–Wallis test, Friedman test, p < .001). There were no significant differences in average PTA hearing threshold recovery after steroid therapy between groups of patients with mild and severe stress. Conclusion: Patients with moderate stress levels show significantly better results after steroid treatment for SSNHL than patients with low or high stress levels. © 2019 American Speech-Language-Hearing Association.",31084569,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85067906848
GUAN G.; HE X.; CHEN J.; BIN L.; TANG X.,"GUAN, GUOFANG (7004891158); HE, XIAO (57219843239); CHEN, JINGJING (57219842707); BIN, LI (57219837083); TANG, XUXIA (57188853785)",7004891158; 57219843239; 57219842707; 57219837083; 57188853785,Identifying the mechanisms underlying the protective effect of tetramethylpyrazine against cisplatin-induced in vitro ototoxicity in HEI-OC1 auditory cells using gene expression profiling,2020,Molecular Medicine Reports,22,6,,5053,5068,15,7,10.3892/mmr.2020.11631,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095686460&doi=10.3892%2fmmr.2020.11631&partnerID=40&md5=3ab5aea12ad92ffba118c00f07a2064a,"Sensorineural hearing loss is prevalent in patients receiving cisplatin therapy. Tetramethylpyrazine (Tet) and tanshinone IIA (Tan IIA ) have protective roles against hearing impairment or ototoxicity. The present study aimed to investigate the molecular mechanisms underlying cisplatin-induced ototoxicity and the protective effect of Tet and Tan IIA against it. House Ear Institute-O rgan of Corti 1 auditory cells were treated with titrating doses of Tan IIA , Tet, and cisplatin. In a cell viability assay, cisplatin, Tan IIA and Tet had IC 50 values of 42.89 μM, 151.80 and 1.04x103 mg/l, respectively. Tan IIA augmented cisplatin-induced cytotoxicity. However, Tet concentrations <75 mg/l attenuated cisplatin-induced cytotoxicity and apoptosis. Moreover, RNA sequencing analysis was carried out on auditory cells treated for 30 h with 30 μM cisplatin alone for 48 h or combined with 37.5 mg/l Tet for 30 h. Differentially expressed genes (DE Gs) induced in these conditions were identified and examined using Gene Ontology and Kyoto Encyclopedia of Genes and Genomes pathway analysis. Cisplatin increased the expression of genes related to the p53 and FoxO pathways, such as Fas, p21/CD KN1A, and Bcl-2 binding component 3, but decreased the expression of insulin-like growth factor 1 (IGF1), as well as genes in the histone (Hist)1 and Hist2 clusters. Treatment with Tet downregulated FOXO3 and Bcl-2 binding component 3, and increased the expression of IGF1. Moreover, Tet upregulated genes associated with Wnt signaling, but not p53-related genes. Thus, the otoprotective properties of Tet might be mediated by activation of Wnt and IGF1 signaling, and inhibition of FoxO signaling. © 2020 Spandidos Publications. All rights reserved.",33174043,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85095686460
Heisey K.L.; Walker A.M.; Xie K.; Abrams J.M.; Barbour D.L.,"Heisey, Katherine L. (56741202000); Walker, Alexandra M. (57219771149); Xie, Kevin (57219770867); Abrams, Jenna M. (57219769006); Barbour, Dennis L. (7003532294)",56741202000; 57219771149; 57219770867; 57219769006; 7003532294,Dynamically Masked Audiograms with Machine Learning Audiometry,2020,Ear and Hearing,41,6,,1692,1702,10,4,10.1097/AUD.0000000000000891,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095406197&doi=10.1097%2fAUD.0000000000000891&partnerID=40&md5=b482f800844331fac17ba1ac8ef52635,"Objectives: When one ear of an individual can hear significantly better than the other ear, evaluating the worse ear with loud probe tones may require delivering masking noise to the better ear to prevent the probe tones from inadvertently being heard by the better ear. Current masking protocols are confusing, laborious, and time consuming. Adding a standardized masking protocol to an active machine learning audiogram procedure could potentially alleviate all of these drawbacks by dynamically adapting the masking as needed for each individual. The goal of this study is to determine the accuracy and efficiency of automated machine learning masking for obtaining true hearing thresholds. Design: Dynamically masked automated audiograms were collected for 29 participants between the ages of 21 and 83 (mean 43, SD 20) with a wide range of hearing abilities. Normal-hearing listeners were given unmasked and masked machine learning audiogram tests. Listeners with hearing loss were given a standard audiogram test by an audiologist, with masking stimuli added as clinically determined, followed by a masked machine learning audiogram test. The hearing thresholds estimated for each pair of techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). Results: Masked and unmasked machine learning audiogram threshold estimates matched each other well in normal-hearing listeners, with a mean absolute difference between threshold estimates of 3.4 dB. Masked machine learning audiogram thresholds also matched well the thresholds determined by a conventional masking procedure, with a mean absolute difference between threshold estimates for listeners with low asymmetry and high asymmetry between the ears, respectively, of 4.9 and 2.6 dB. Notably, out of 6200 masked machine learning audiogram tone deliveries for this study, no instances of tones detected by the nontest ear were documented. The machine learning methods were also generally faster than the manual methods, and for some listeners, substantially so. Conclusions: Dynamically masked audiograms achieve accurate true threshold estimates and reduce test time compared with current clinical masking procedures. Dynamic masking is a compelling alternative to the methods currently used to evaluate individuals with highly asymmetric hearing, yet can also be used effectively and efficiently for anyone.  © Copyright 2020 Wolters Kluwer Health, Inc. All rights reserved.",33136643,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095406197
Buhl M.; Warzybok A.; Schädler M.R.; Majdani O.; Kollmeier B.,"Buhl, Mareike (57207939883); Warzybok, Anna (36081535600); Schädler, Marc René (55312455700); Majdani, Omid (23479973000); Kollmeier, Birger (7006746726)",57207939883; 36081535600; 55312455700; 23479973000; 7006746726,Common Audiological Functional Parameters (CAFPAs) for single patient cases: deriving statistical models from an expert-labelled data set,2020,International Journal of Audiology,59,7,,534,547,13,7,10.1080/14992027.2020.1728401,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087528613&doi=10.1080%2f14992027.2020.1728401&partnerID=40&md5=164b8d167872bdc71c2d526db07745eb,"Objective: Statistical knowledge about many patients could be exploited using machine learning to provide supporting information to otolaryngologists and other hearing health care professionals, but needs to be made accessible. The Common Audiological Functional Parameters (CAFPAs) were recently introduced for the purpose of integrating data from different databases by providing an abstract representation of audiological measurements. This paper aims at collecting expert labels for a sample database and to determine statistical models from the labelled data set. Design: By an expert survey, CAFPAs as well as labels for audiological findings and treatment recommendations were collected for patients from the database of Hörzentrum Oldenburg. Study sample: A total of 287 single patient cases were assessed by twelve highly experienced audiological experts. Results: The labelled data set was used to derive probability density functions for categories given by the expert labels. The collected data set is suitable for estimating training distributions due to realistic variability contained in data for different, distinct categories. Suitable distribution functions were determined. The derived training distributions were compared regarding different audiological questions. Conclusions: The method-expert survey, sorting data into categories, and determining training distributions–could be extended to other data sets, which could then be integrated via the CAFPAs and used in a classification task. © 2020, © 2020 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",32091289,Article,Final,,Scopus,2-s2.0-85087528613
Kearney P.; Li W.-C.; Yu C.-S.; Braithwaite G.,"Kearney, Peter (56963530000); Li, Wen-Chin (36064620900); Yu, Chung-San (56241985400); Braithwaite, Graham (7004369056)",56963530000; 36064620900; 56241985400; 7004369056,The impact of alerting designs on air traffic controller’s eye movement patterns and situation awareness,2019,Ergonomics,62,2,,305,318,13,22,10.1080/00140139.2018.1493151,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053067654&doi=10.1080%2f00140139.2018.1493151&partnerID=40&md5=bb7f92eeebf6e9d2e11f223deb0d689c,"This research investigated controller’ situation awareness by comparing COOPANS’s acoustic alerts with newly designed semantic alerts. The results demonstrate that ATCOs’ visual scan patterns had significant differences between acoustic and semantic designs. ATCOs established different eye movement patterns on fixations number, fixation duration and saccade velocity. Effective decision support systems require human-centered design with effective stimuli to direct ATCO’s attention to critical events. It is necessary to provide ATCOs with specific alerting information to reflect the nature of the critical situation in order to minimise the side effects of startle and inattentional deafness. Consequently, the design of a semantic alert can significantly reduce ATCOs’ response time, therefore providing valuable extra time in a time-limited situation to formulate and execute resolution strategies in critical air safety events. The findings of this research indicate that the context-specified design of semantic alerts could improve ATCO’s situational awareness and significantly reduce response time in the event of Short Term Conflict Alert (STCA) activation which alerts to two aircraft having less than the required lateral or vertical separation. Practitioner Summary: Eye movements are closely linked with visual attention and can be analysed to explore shifting attention whilst performing monitoring tasks. This research has found that context-specific designed semantic alerts facilitated improved ATCO cognitive processing by integrating visual and auditory resources. Semantic designs have been demonstrated to be superior to acoustic design by directing the operator’s attention more quickly to critical situations.Abbreviations: APW: area proximity warning; ASRS: aviation safety reporting system; ATC: air traffic control; ATCO: air traffic controller; ATM: air traffic management; COOPANS: cooperation between air navigation service providers; HCI: human-computer interaction; IAA: irish aviation authority; MSAW: minimum safe altitude warning; MTCD: medium-term conflict detection; SA: situation awareness; STCA: short term conflict alert; TP: trajectory prediction. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.",29943681,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85053067654
Barbour D.L.; Howard R.T.; Song X.D.; Metzger N.; Sukesan K.A.; DiLorenzo J.C.; Snyder B.R.D.; Chen J.Y.; Degen E.A.; Buchbinder J.M.; Heisey K.L.,"Barbour, Dennis L. (7003532294); Howard, Rebecca T. (57209844960); Song, Xinyu D. (56956060700); Metzger, Nikki (57209842321); Sukesan, Kiron A. (57199732113); DiLorenzo, James C. (57202442868); Snyder, Braham R.D. (57209842055); Chen, Jeff Y. (57202442710); Degen, Eleanor A. (57202440522); Buchbinder, Jenna M. (57204512351); Heisey, Katherine L. (56741202000)",7003532294; 57209844960; 56956060700; 57209842321; 57199732113; 57202442868; 57209842055; 57202442710; 57202440522; 57204512351; 56741202000,Online machine learning audiometry,2019,Ear and Hearing,40,4,,918,926,8,29,10.1097/AUD.0000000000000669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068886590&doi=10.1097%2fAUD.0000000000000669&partnerID=40&md5=e94f2a5493abf3eed184b7743bcbc13a,"Objectives: A confluence of recent developments in cloud computing, real-time web audio and machine learning psychometric function estimation has made wide dissemination of sophisticated turn-key audiometric assessments possible. The authors have combined these capabilities into an online (i.e., web-based) pure-tone audiogram estimator intended to empower researchers and clinicians with advanced hearing tests without the need for custom programming or special hardware. The objective of this study was to assess the accuracy and reliability of this new online machine learning audiogram method relative to a commonly used hearing threshold estimation technique also implemented online for the first time in the same platform. Design: The authors performed air conduction pure-tone audiometry on 21 participants between the ages of 19 and 79 years (mean 41, SD 21) exhibiting a wide range of hearing abilities. For each ear, two repetitions of online machine learning audiogram estimation and two repetitions of online modified Hughson-Westlake ascending-descending audiogram estimation were acquired by an audiologist using the online software tools. The estimated hearing thresholds of these two techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). Results: The two threshold estimation methods delivered very similar threshold estimates at standard audiogram frequencies. Specifically, the mean absolute difference between threshold estimates was 3.24 ± 5.15 dB. The mean absolute differences between repeated measurements of the online machine learning procedure and between repeated measurements of the Hughson-Westlake procedure were 2.85 ± 6.57 dB and 1.88 ± 3.56 dB, respectively. The machine learning method generated estimates of both threshold and spread (i.e., the inverse of psychometric slope) continuously across the entire frequency range tested from fewer samples on average than the modified Hughson-Westlake procedure required to estimate six discrete thresholds. Conclusions: Online machine learning audiogram estimation in its current form provides all the information of conventional threshold audiometry with similar accuracy and reliability in less time. More importantly, however, this method provides additional audiogram details not provided by other methods. This standardized platform can be readily extended to bone conduction, masking, spectrotemporal modulation, speech perception, etc., unifying audiometric testing into a single comprehensive procedure efficient enough to become part of the standard audiologic workup. Copyright © 2018 Wolters Kluwer Health, Inc. All rights reserved",30358656,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85068886590
Glista D.; O’Hagan R.; Moodie S.; Scollie S.,"Glista, Danielle (26324903700); O’Hagan, Robin (57218372641); Moodie, Sheila (11839456100); Scollie, Susan (6602453065)",26324903700; 57218372641; 11839456100; 6602453065,An examination of clinical uptake factors for remote hearing aid support: a concept mapping study with audiologists,2020,International Journal of Audiology,60,S1,,S13,S22,9,14,10.1080/14992027.2020.1795281,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088999828&doi=10.1080%2f14992027.2020.1795281&partnerID=40&md5=e54181070891bc155b6478fa56c32a6c,"Objective: To develop a conceptual framework around the factors that influence audiologists in the clinical uptake of remote follow-up hearing aid support services. Design: A purposive sample of 42 audiologists, stratified according to client-focus of either paediatric or adult, were recruited from professional associations in Ontario, Canada, as members of the six-step, participatory-based concept mapping process. Analyses included multidimensional scaling and hierarchical cluster analysis. Results: Six main themes emerged from this research according to overall level of importance: (1) technology and infrastructure; (2) audiologist-centred considerations; (3) hearing healthcare regulations; (4) client-centred considerations; (5) clinical implementation considerations; and (6) financial considerations. Subthemes were identified at the group-level and by subgroup. These highlight the importance of TECH factors (accessible Technology, Easy to use, robust Connection, and Help available), as well as the multi-faceted nature of the perceived attitudes/aptitudes across stakeholders. Conclusion: Findings can be utilised in tailored planning and development efforts to support future research, knowledge dissemination, best-practice protocol/guideline development, and related training to assist in the clinical uptake of remote follow-up hearing aid support services, across variable practice contexts. © 2020 The Authors. Published by Informa UK Limited, trading as Taylor & Francis Group on behalf of British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",32749182,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85088999828
Cruickshanks K.J.; Nondahl D.M.; Fischer M.E.; Schubert C.R.; Tweed T.S.,"Cruickshanks, Karen J. (7006073825); Nondahl, David M. (6701732527); Fischer, Mary E. (55640343300); Schubert, Carla R. (7103270553); Tweed, Ted S. (6603596278)",7006073825; 6701732527; 55640343300; 7103270553; 6603596278,A novel method for classifying hearing impairment in epidemiological studies of aging: The wisconsin age-related hearing impairment classification scale,2020,American Journal of Audiology,29,1,,59,67,8,12,10.1044/2019_AJA-19-00021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081946193&doi=10.1044%2f2019_AJA-19-00021&partnerID=40&md5=3582b8ff5ce3c297b5282e03055057f3,"Purpose: Longitudinal population-based cohort data were used to develop a standardized classification system for age-related hearing impairment using thresholds for frequencies (0.5–8 kHz) typically measured in cohort studies. Method: Audiometric testing data collected in the Epidemiology of Hearing Loss Study from participants (n = 1,369) with four visits (1993–1995, 1998–2000, 2003– 2005, and 2009–2010) were included (10,952 audiograms). Cluster analyses (Wald’s method) were used to identify audiometric patterns. Maximum allowable threshold values were defined for each cluster to create an ordered scale. Progression was defined as a two-step change. Results: An eight-step scale was developed to capture audiogram shape and severity of hearing impairment. Of the 1,094 participants classified as having normal hearing based on a pure-tone average, only 25% (n = 277) were classified as Level 1 (all thresholds ≤ 20 dB HL) on the new scale, whereas 17% (n = 182) were Levels 4–6. During the 16-year follow-up, 64.9% of those at Level 1 progressed. There was little regression using this scale. Conclusions: This is the first scale developed from population-based longitudinal cohort data to capture audiogram shape across time. This simple, standardized scale is easy to apply, reduces misclassification of normal hearing, and may be a useful method for identifying risk factors for early, preclinical, age-related changes in hearing. © 2020 American Speech-Language-Hearing Association.",32011900,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85081946193
Zhang B.; Wang D.; Chen M.; Ma H.; Zhou C.; Chen Y.; Wang D.; Chen Y.; Ren Y.; Zhu Y.; Xu L.,"Zhang, Baodan (57195505551); Wang, Dahui (57197844654); Chen, Minyan (57211911218); Ma, Haiyan (55723503600); Zhou, Chi (37094393100); Chen, Yijia (57211909762); Wang, Danni (57211910516); Chen, Yuan (57211909862); Ren, Ying (57211903368); Zhu, Yajun (57211906156); Xu, Liangwen (56142265600)",57195505551; 57197844654; 57211911218; 55723503600; 37094393100; 57211909762; 57211910516; 57211909862; 57211903368; 57211906156; 56142265600,Influencing Factors of Hearing Habits on Hearing Loss and Related Symptoms among Medical Students; [医学生用耳习惯对听力损失及相关症状的影响因素分析研究],2019,Chinese General Practice,22,29,,3602,3608,6,2,10.12114/j.issn.1007-9572.2019.00.102,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075317542&doi=10.12114%2fj.issn.1007-9572.2019.00.102&partnerID=40&md5=92173eef09a18f60ccc38dd323b1186f,"Background: Recently,many studies have assessed the hearing loss (HL) of elderly people,people across occupational groups,and infants,but few have assessed this issue among medical students in China.Objective: To investigate the status of HL and hearing related symptoms among medical students,and to explore the effect of hearing habits on them.Methods: A total of 1 882 students of four-year (freshman-junior students) and five-year (freshman-senior students) graduation systems were selected by cluster sampling in Medical School,Hangzhou Normal University from March to May 2017.The questionnaire survey and pure-tone hearing tests(PTT)were conducted.The questionnaire comprised three parts:demographic characteristics (age,sex,major,grade),the hearing related symptoms(the occurrence of tinnitus,earache and aural fullness in the last year),and hearing habits(whether to use headphones,type of headphones,frequency of headphone usage,time of headphone usage,time of playing games with headphones,maximum volume of headphone,mode of cell phone conversation,noise environment to improve headphone volume,sleeping with headphones listening to music/radio,frequency of going entertainment places).The sound-pressure levels of background noise measured at a dedicated sound-isolating room in the university laboratory building were below 30 dB.PTT were measured using a calibrated audiometer (AT235) with standard headphones (TDH-39P).The speech-frequency HL (>25 dB)and high-frequency HL (>25 dB) were assessed.Factors influencing HL and hearing related symptoms were analyzed by multivariate Logistic regression models.Results: A total of 1 882 questionnaires were sent out,1 882 questionnaires were recovered,1 882 questionnaires were valid,with an effective recovery rate of 100.0%.Pure-tone averages of the right ear were higher than those of the left ear at hearing frequency of 0.125,0.250,0.500,1.000,2.000,4.000,6.000 kHz(P<0.05).The number of students with speech frequency hearing loss (> 25 dB) was 32 (1.7%),high frequency hearing loss (> 25 dB) was 62 (3.3%),tinnitus was 913 (48.5%),earache was 533 (28.3%) and aural fullness was 502 (26.7%).Among 1 664 medical students(88.4%)who used headphones,there were 963 (57.9%),610 (36.6%) and 91(5.5%) medical students used earplug,in-ear headphones or headset,respectively.The number of students with frequency of using earphones > 2 times/d was 513(27.3%).Duration of using earphones was >1.0 h/d among 289 medical students(15.4%).Duration of playing games with using earphones was ≥1 h/d among 547 medical students(29.1%).Maximum volume of using earphones was ≥60% among 70 medical students(3.7%).The number of students making phone calls by earphones was 521(27.6%).Probability to increase earphone volume in a noisy environment was ≥50% among 1 142 medical students(60.7%).Frequency of sleeping with earphones while listening to music or broadcast was ≥2 times/week among 158 medical students(8.4%).Frequency of attending entertainment venues was >3 times/month among 36 medical students(1.9%).The speech-frequency HL and high-frequency HL rates of the tinnitus group were higher than those in the non-tinnitus group(P<0.05).The speech-frequency HL and high-frequency HL rates did not show any significant difference among ear pain,and aural fullness(P>0.05).Sex〔female:OR=0.467,95%CI(0.267,0.816)〕was a factor affecting speech-frequency HL among medical students(P<0.05).Probability to increase earphone volume in a noisy environment〔≥50%:OR=1.567,95%CI(1.282,1.915)〕 was a factor influencing tinnitus among medical students(P<0.05).Frequency of using earphones〔>2 times/d:OR=1.443,95%CI(1.151,1.810)〕,and duration of using earphones 〔0.5-1.0 h/time:OR=1.447,95%CI(1.151,1.818);>1.0 h/times:OR=1.648,95%CI(1.214,2.237)〕were factors of ear pain among medical students(P<0.05).Sex 〔female:OR=1.338,95%CI(1.061,1.686)〕,duration of playing games with earphones〔≥1 h/d:OR=1.315,95%CI(1.053,1.642)〕,probability to increase earphone volume in a noisy environment〔≥50%:OR=1.398,95%CI(1.126,1.735)〕,and frequency of attending entertainment venues 〔>3 times/month:OR=3.324,95%CI(1.686,6.554)〕were factors for aural fullness among medical students(P<0.05).Conclusion: The hearing status is not optimistic among medical students.The hearing status of the right ear is worse than that of the left ear.Improper usage of earphones and exposure to damaging sound levels at noisy entertainment venue can cause hearing damage.Bad hearing habits have long-term influence on the hearing of medical students.We suggest that qualified schools add PTT to the entrance examination,and strengthen the health education related to hearing. Copyright © 2019 by the Chinese General Practice.",,Article,Final,,Scopus,2-s2.0-85075317542
Geng R.; Furness D.N.; Muraleedharan C.K.; Zhang J.; Dabdoub A.; Lin V.; Xu S.,"Geng, Ruishuang (27567635000); Furness, David N (7003958281); Muraleedharan, Chithra K (56193982200); Zhang, Jinsheng (35309071800); Dabdoub, Alain (6507497803); Lin, Vincent (58769161600); Xu, Shunbin (8772616500)",27567635000; 7003958281; 56193982200; 35309071800; 6507497803; 58769161600; 8772616500,The microRNA-183/96/182 Cluster is Essential for Stereociliary Bundle Formation and Function of Cochlear Sensory Hair Cells,2018,Scientific Reports,8,1,18022,,,,23,10.1038/s41598-018-36894-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058924434&doi=10.1038%2fs41598-018-36894-z&partnerID=40&md5=03b619313f38a8b34af33f081b7b1b7e,"The microRNA (miR)-183/96/182 cluster plays important roles in the development and functions of sensory organs, including the inner ear. Point-mutations in the seed sequence of miR-96 result in non-syndromic hearing loss in both mice and humans. However, the lack of a functionally null mutant has hampered the evaluation of the cluster’s physiological functions. Here we have characterized a loss-of-function mutant mouse model (miR-183CGT/GT), in which the miR-183/96/182 cluster gene is inactivated by a gene-trap (GT) construct. The homozygous mutant mice show profound congenital hearing loss with severe defects in cochlear hair cell (HC) maturation, alignment, hair bundle formation and the checkboard-like pattern of the cochlear sensory epithelia. The stereociliary bundles retain an immature appearance throughout the cochlea at postnatal day (P) 3 and degenerate soon after. The organ of Corti of mutant newborn mice has no functional mechanoelectrical transduction. Several predicted target genes of the miR-183/96/182 cluster that are known to play important roles in HC development and function, including Clic5, Rdx, Ezr, Rac1, Myo1c, Pvrl3 and Sox2, are upregulated in the cochlea. These results suggest that the miR-183/96/182 cluster is essential for stereociliary bundle formation, morphogenesis and function of the cochlear HCs. © 2018, The Author(s).",30575790,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85058924434
Tzounopoulos T.; Balaban C.; Zitelli L.; Palmer C.,"Tzounopoulos, Thanos (6603084470); Balaban, Carey (7005544876); Zitelli, Lori (57194236641); Palmer, Catherine (7403081086)",6603084470; 7005544876; 57194236641; 7403081086,Towards a Mechanistic-Driven Precision Medicine Approach for Tinnitus,2019,JARO - Journal of the Association for Research in Otolaryngology,20,2,,115,131,16,18,10.1007/s10162-018-00709-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062707419&doi=10.1007%2fs10162-018-00709-9&partnerID=40&md5=da9849323ea5c511c13e078f35980142,"In this position review, we propose to establish a path for replacing the empirical classification of tinnitus with a taxonomy from precision medicine. The goal of a classification system is to understand the inherent heterogeneity of individuals experiencing and suffering from tinnitus and to identify what differentiates potential subgroups. Identification of different patient subgroups with distinct audiological, psychophysical, and neurophysiological characteristics will facilitate the management of patients with tinnitus as well as the design and execution of drug development and clinical trials, which, for the most part, have not yielded conclusive results. An alternative outcome of a precision medicine approach in tinnitus would be that additional mechanistic phenotyping might not lead to the identification of distinct drivers in each individual, but instead, it might reveal that each individual may display a quantitative blend of causal factors. Therefore, a precision medicine approach towards identifying these causal factors might not lead to subtyping these patients but may instead highlight causal pathways that can be manipulated for therapeutic gain. These two outcomes are not mutually exclusive, and no matter what the final outcome is, a mechanistic-driven precision medicine approach is a win-win approach for advancing tinnitus research and treatment. Although there are several controversies and inconsistencies in the tinnitus field, which will not be discussed here, we will give a few examples, as to how the field can move forward by exploring the major neurophysiological tinnitus models, mostly by taking advantage of the common features supported by all of the models. Our position stems from the central concept that, as a field, we can and must do more to bring studies of mechanisms into the realm of neuroscience. © 2019, Association for Research in Otolaryngology.",30825037,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85062707419
Ashrafi M.R.; Amanat M.; Garshasbi M.; Kameli R.; Nilipour Y.; Heidari M.; Rezaei Z.; Tavasoli A.R.,"Ashrafi, Mahmoud Reza (12141682400); Amanat, Man (57200646152); Garshasbi, Masoud (56015559700); Kameli, Reyhaneh (57205888608); Nilipour, Yalda (57211450454); Heidari, Morteza (57209591899); Rezaei, Zahra (36061461000); Tavasoli, Ali Reza (16246450200)",12141682400; 57200646152; 56015559700; 57205888608; 57211450454; 57209591899; 36061461000; 16246450200,"An update on clinical, pathological, diagnostic, and therapeutic perspectives of childhood leukodystrophies",2020,Expert Review of Neurotherapeutics,20,1,,65,84,19,49,10.1080/14737175.2020.1699060,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076367424&doi=10.1080%2f14737175.2020.1699060&partnerID=40&md5=a71c133961818d85b9f54db3caef2944,"Introduction: Leukodystrophies constitute heterogenous group of rare heritable disorders primarily affecting the white matter of central nervous system. These conditions are often under-appreciated among physicians. The first clinical manifestations of leukodystrophies are often nonspecific and can occur in different ages from neonatal to late adulthood periods. The diagnosis is, therefore, challenging in most cases. Area covered: Herein, the authors discuss different aspects of leukodystrophies. The authors used MEDLINE, EMBASE, and GOOGLE SCHOLAR to provide an extensive update about epidemiology, classifications, pathology, clinical findings, diagnostic tools, and treatments of leukodystrophies. Comprehensive evaluation of clinical findings, brain magnetic resonance imaging, and genetic studies play the key roles in the early diagnosis of individuals with leukodystrophies. No cure is available for most heritable white matter disorders but symptomatic treatments can significantly decrease the burden of events. New genetic methods and stem cell transplantation are also under investigation to further increase the quality and duration of life in affected population. Expert opinion: The improvements in molecular diagnostic tools allow us to identify the meticulous underlying etiology of leukodystrophies and result in higher diagnostic rates, new classifications of leukodystrophies based on genetic information, and replacement of symptomatic managements with more specific targeted therapies. Abbreviations: 4H: Hypomyelination, hypogonadotropic hypogonadism and hypodontia; AAV: Adeno-associated virus; AD: autosomal dominant; AGS: Aicardi-Goutieres syndrome; ALSP: Axonal spheroids and pigmented glia; APGBD: Adult polyglucosan body disease; AR: autosomal recessive; ASO: Antisense oligonucleotide therapy; AxD: Alexander disease; BAEP: Brainstem auditory evoked potentials; CAA: Cerebral amyloid angiopathy; CADASIL: Cerebral autosomal dominant arteriopathy with subcortical infarcts and leukoencephalopathy; CARASAL: Cathepsin A–related arteriopathy with strokes and leukoencephalopathy; CARASIL: Cerebral autosomal recessive arteriopathy with subcortical infarcts and leukoencephalopathy; CGH: Comparative genomic hybridization; ClC2: Chloride Ion Channel 2; CMTX: Charcot-Marie-Tooth disease, X-linked; CMV: Cytomegalovirus; CNS: central nervous system; CRISP/Cas9: Clustered regularly interspaced short palindromic repeat/CRISPR-associated 9; gRNA: Guide RNA; CTX: Cerebrotendinous xanthomatosis; DNA: Deoxyribonucleic acid; DSB: Double strand breaks; DTI: Diffusion tensor imaging; FLAIR: Fluid attenuated inversion recovery; GAN: Giant axonal neuropathy; H-ABC: Hypomyelination with atrophy of basal ganglia and cerebellum; HBSL: Hypomyelination with brainstem and spinal cord involvement and leg spasticity; HCC: Hypomyelination with congenital cataracts; HEMS: Hypomyelination of early myelinated structures; HMG CoA: Hydroxy methylglutaryl CoA; HSCT: Hematopoietic stem cell transplant; iPSC: Induced pluripotent stem cells; KSS: Kearns-Sayre syndrome; L-2-HGA: L-2-hydroxy glutaric aciduria; LBSL: Leukoencephalopathy with brainstem and spinal cord involvement and elevated lactate; LCC: Leukoencephalopathy with calcifications and cysts; LTBL: Leukoencephalopathy with thalamus and brainstem involvement and high lactate; MELAS: Mitochondrial myopathy, encephalopathy, lactic acidosis, and stroke; MERRF: Myoclonic epilepsy with ragged red fibers; MLC: Megalencephalic leukoencephalopathy with subcortical cysts; MLD: metachromatic leukodystrophy; MRI: magnetic resonance imaging; NCL: Neuronal ceroid lipofuscinosis; NGS: Next generation sequencing; ODDD: Oculodentodigital dysplasia; PCWH: Peripheral demyelinating neuropathy-central-dysmyelinating leukodystrophy-Waardenburg syndrome-Hirschprung disease; PMD: Pelizaeus‐Merzbacher disease; PMDL: Pelizaeus-Merzbacher-like disease; RNA: Ribonucleic acid; TW: T-weighted; VWM: Vanishing white matter; WES: whole exome sequencing; WGS: whole genome sequencing; X-ALD: X-linked adrenoleukodystrophy; XLD: X-linked dominant; XLR: X-linked recessive. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",31829048,Review,Final,,Scopus,2-s2.0-85076367424
Yamazaki Y.; Urrutia R.; Franco L.M.; Giliani S.; Zhang K.; Alazami A.M.; Dobbs A.K.; Masneri S.; Joshi A.; Otaizo-Carrasquero F.; Myers T.G.; Ganesan S.; Bondioni M.P.; Ho M.L.; Marks C.; Alajlan H.; Mohammed R.W.; Zou F.; Valencia C.A.; Filipovich A.H.; Facchetti F.; Boisson B.; Azzari C.; Al-Saud B.K.; Al-Mousa H.; Casanova J.L.; Abraham R.S.; Notarangelo L.D.,"Yamazaki, Yasuhiro (55319485100); Urrutia, Raul (7005900108); Franco, Luis M. (56745594700); Giliani, Silvia (35309934800); Zhang, Kejian (55445465000); Alazami, Anas M. (24469997800); Dobbs, A. Kerry (55778402700); Masneri, Stefania (54976948200); Joshi, Avni (24766060000); Otaizo-Carrasquero, Francisco (55748834700); Myers, Timothy G. (56686026500); Ganesan, Sundar (21742639000); Bondioni, Maria Pia (6507618240); Ho, Mai Lan (56970415200); Marks, Catherine (7102306524); Alajlan, Huda (57200599296); Mohammed, Reem W. (57196119212); Zou, Fanggeng (57193118984); Valencia, C. Alexander (8592159000); Filipovich, Alexandra H. (7005882582); Facchetti, Fabio (7006730085); Boisson, Bertrand (23484212500); Azzari, Chiara (7004089795); Al-Saud, Bander K. (31168259000); Al-Mousa, Hamoud (35267859500); Casanova, Jean Laurent (7201863327); Abraham, Roshini S. (7202079890); Notarangelo, Luigi D. (34768650200)",55319485100; 7005900108; 56745594700; 35309934800; 55445465000; 24469997800; 55778402700; 54976948200; 24766060000; 55748834700; 56686026500; 21742639000; 6507618240; 56970415200; 7102306524; 57200599296; 57196119212; 57193118984; 8592159000; 7005882582; 7006730085; 23484212500; 7004089795; 31168259000; 35267859500; 7201863327; 7202079890; 34768650200,PAX1 is essential for development and function of the human thymus,2020,Science Immunology,5,44,aax1036,,,,54,10.1126/sciimmunol.aax1036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081071846&doi=10.1126%2fsciimmunol.aax1036&partnerID=40&md5=053133194a5bef973c144ec11bad10d0,"We investigated the molecular and cellular basis of severe combined immunodeficiency (SCID) in six patients with otofaciocervical syndrome type 2 who failed to attain T cell reconstitution after allogeneic hematopoietic stem cell transplantation, despite successful engraftment in three of them. We identified rare biallelic PAX1 rare variants in all patients. We demonstrated that these mutant PAX1 proteins have an altered conformation and flexibility of the paired box domain and reduced transcriptional activity. We generated patient-derived induced pluripotent stem cells and differentiated them into thymic epithelial progenitor cells and found that they have an altered transcriptional profile, including for genes involved in the development of the thymus and other tissues derived from pharyngeal pouches. These results identify biallelic, loss-of-function PAX1 mutations as the cause of a syndromic form of SCID due to altered thymus development.  © 2020 The Authors.",32111619,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85081071846
Ayyappa Swamy K.; Prathima S.; Padmaja N.,"Ayyappa Swamy, K. (57193502177); Prathima, Samuda (57210571736); Padmaja, N. (55339735000)",57193502177; 57210571736; 55339735000,Study of Presbycusis and Single Microphone Noise Reduction Techniques for Hearing AIDS,2018,"2018 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2018",,,8782402,,,,4,10.1109/ICCIC.2018.8782402,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071021820&doi=10.1109%2fICCIC.2018.8782402&partnerID=40&md5=8fd1d4fef38d8da00d84e033903afcb0,"Age-Related hearing loss or Presbycusis is a slow, progressive hearing loss and affects both ears equally. First signs of hearing loss are inability to understand speech in noisy environments. This study includes the changes in the response of auditory filter and the hearing thresholds due to the masking sounds for elderly with hearing impaired. The hearing aid designer should come across this study before designing a suitable device not just only amplifying the sounds. The dynamic range of hearing thresholds especially for hearing impaired changes due to Masking. Therefore, to understand the speech for hearing impaired requires high SNRs due to broadening of auditory filter compared to normal hearing. To improve the SNR, it is challenging to select best noise reduction technique among plenty. This study presents number of SMNR methods to get clean speech by estimating noise from noisy speech. It is also discusses the combination of the techniques and the idea behind the techniques. © 2018 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85071021820
Mabenda S.B.; Bunabe G.; Gilyoma J.M.; Chalya P.L.; Mahalu W.,"Mabenda, Shija B. (57218278644); Bunabe, Gustave (57218283086); Gilyoma, Japhet M. (6503903865); Chalya, Phillipo L. (36930124200); Mahalu, William (36802241100)",57218278644; 57218283086; 6503903865; 36930124200; 36802241100,"Prevalence of cerumen impaction and associated factors among primary school children in Mwanza City, Tanzania",2019,Tanzania Journal of Health Research,21,1,,1,9,8,4,10.4314/thrb.v21i1.6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088555279&doi=10.4314%2fthrb.v21i1.6&partnerID=40&md5=77ed5cd3221438226856d31e0d8ee871,"Background: Cerumen impaction is a worldwide problem constituting a significant proportion of health problems in many settings and its prevalence varies. There is a paucity of published data regarding this condition in Tanzania with none from Mwanza region. The aim of this study was to determine the prevalence of cerumen impaction and associated factors among primary school children in Mwanza City and to assess the effect of cerumen impaction and its removal on hearing ability Methods and Patients: This was a cross-sectional, community based study of primary school children with cerumen impaction that was carried out in randomly selected primary schools in Mwanza City between December 2016 and May 2017. Multistage cluster sampling technique was employed to obtain a required number of the study population. Results: Out of the 406 participants, ninety-five (23.4%) had cerumen impacted in their ears. Of these, 56 (58.9%) were males and 39(41.1%) were females. The mean age at presentation was 11.24±8.86 years. Ear bud abuse (83.7%) was the most common predisposing factor for cerumen impaction. Cerumen impaction was found in the right ear of 9 (9.5%) patients and in the left ear in 31 (32.6%) patients and bilateral in 55 (57.9%) of patients. The major presenting symptoms were ear itching, otalgia, hearing loss and tinnitus. Ear syringing was used to remove cerumen impaction and caused significant improvement in hearing thresholds. There were no recorded complications. Conclusion: Cerumen impaction is a common otologic presentation in our sub-region. Ignorance with the profound abuse of cotton buds is the major predisposing factor. Health education is of the essence as treatment is simple and effective. © 2019, National Institute for Medical Research. All rights reserved.",,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85088555279
Mehra R.; Brimijoin O.; Robinson P.; Lunner T.,"Mehra, Ravish (35790270300); Brimijoin, Owen (57219707832); Robinson, Philip (57198535715); Lunner, Thomas (6602520682)",35790270300; 57219707832; 57198535715; 6602520682,Potential of Augmented Reality Platforms to Improve Individual Hearing Aids and to Support More Ecologically Valid Research,2020,Ear and Hearing,41,,,140S,146S,6,17,10.1097/AUD.0000000000000961,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094816725&doi=10.1097%2fAUD.0000000000000961&partnerID=40&md5=0e6247e0b2861f6e18b0dae72b16bfe4,"An augmented reality (AR) platform combines several technologies in a system that can render individual ""digital objects"" that can be manipulated for a given purpose. In the audio domain, these may, for example, be generated by speaker separation, noise suppression, and signal enhancement. Access to the ""digital objects"" could be used to augment auditory objects that the user wants to hear better. Such AR platforms in conjunction with traditional hearing aids may contribute to closing the gap for people with hearing loss through multimodal sensor integration, leveraging extensive current artificial intelligence research, and machine-learning frameworks. This could take the form of an attention-driven signal enhancement and noise suppression platform, together with context awareness, which would improve the interpersonal communication experience in complex real-life situations. In that sense, an AR platform could serve as a frontend to current and future hearing solutions. The AR device would enhance the signals to be attended, but the hearing amplification would still be handled by hearing aids. In this article, suggestions are made about why AR platforms may offer ideal affordances to compensate for hearing loss, and how research-focused AR platforms could help toward better understanding of the role of hearing in everyday life. © 2020 Lippincott Williams and Wilkins. All rights reserved.",33105268,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85094816725
Bayat A.; Saki N.; Nikakhlagh S.; Mirmomeni G.; Raji H.; Soleimani H.; Rahim F.,"Bayat, Arash (55504934600); Saki, Nader (16403314600); Nikakhlagh, Soheila (16402645400); Mirmomeni, Golshan (55504103800); Raji, Hanieh (54913346300); Soleimani, Hossein (23029054700); Rahim, Fakher (23052247800)",55504934600; 16403314600; 16402645400; 55504103800; 54913346300; 23029054700; 23052247800,Is COPD associated with alterations in hearing? A systematic review and meta-analysis,2019,International Journal of COPD,14,,,149,162,13,13,10.2147/COPD.S182730,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060036904&doi=10.2147%2fCOPD.S182730&partnerID=40&md5=307625f84fe80bb713686ba1966184de,"Background and aims: COPD is an irreversible or persistent airflow obstruction, which affects up to 600 million people globally. The primary purpose of this systematic review was to explore the COPD-based alteration in the auditory system function by conducting a quantitative analysis of presently published data. Materials and methods: We systematically searched seven diverse electronic databases and manual searching of references to identify relevant studies. Data from the selected studies were rated by two investigators independently in a blinded fashion. Meta-analysis was done on pooled data using Cochrane’s Review Manager 5.3. Results: Sixteen articles received suitable scores and were thus included for further processes. Hearing loss (HL) was defined as a change in pure tone audiometry (PTA) thresholds, auditory brainstem response (ABR), and auditory P300 parameters. ABR wave was significantly elongated in patients with COPD than in controls (standardized mean difference [SMD]=0.27, 95% CI: 0.05–0.48, P=0.02). PTA was significantly higher in patients with COPD when compared with controls (SMD=1.76, 95% CI: 0.43–3.08, P=0.0004). We found that patients with COPD had a significantly higher latency than controls (SMD=1.30, 95% CI: 0.79–1.80, P=0.0001). Conclusion: COPD patients had considerably greater incidence of HL when compared with controls. Interestingly, although the mean PTA thresholds at every frequency for COPD patients were higher than those for controls, these values were still in the slight to mild HL ranges. Prolonged ABR wave latencies in the COPD patients suggest retro-cochlear involvement. Thus, COPD most frequently clusters with HL, but it is worth noting that alteration in hearing is not always recognized by medical experts as a frequent comorbidity associated with COPD. © 2019 Bayat et al.",30643401,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85060036904
Quriba A.S.; Hassan E.M.,"Quriba, A.S. (54894555700); Hassan, E.M. (57196010409)",54894555700; 57196010409,Analysis of phonological criteria in Egyptian Arabic speaking children using cochlear implant,2019,International Journal of Pediatric Otorhinolaryngology,127,,109637,,,,0,10.1016/j.ijporl.2019.109637,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072172835&doi=10.1016%2fj.ijporl.2019.109637&partnerID=40&md5=e369c74521353ef449a231abc8ca4852,"Objectives: The purpose of this study is to assess the most common segmental and supra-segmental phonological criteria of the Egyptian Arabic speaking children using CI. This may lead to; better understanding of speech progress and planning individualized therapy programs for these children. Methods: This study included 43 children using cochlear implant (23 males and 20 females), from the clients of the phoniatric unit of ORL Department Zagazig University, at the period from September 2017 to April 2019. The age ranged between 4 to 10 years old. All children had assessments of their language and speech features (phonological patterns, segmental and supra-segmental) and speech intelligibility, then the results were collected and statistically analyzed. Results: The participants of the study exhibited many types of developmental patterns; e.g., Cluster reduction, final consonant deletions, assimilation and substitutions. There were also fewer incidences of non-developmental phonological patterns. The sequence of acquisition of segmental phonological development revealed the following sequence: Bilabial sounds acquired first (oral /b/ before nasal /m/), then lingu-alveolar, then fricatives, then velar and back sounds and lastly laterals and glides. All studied segmental, supra-segmental features and speech intelligibility were correlated with the CI usage period. Conclusion: The speech of the Egyptian CI children shows many developmental phonological patterns as well as non-developmental ones. The sequence of phonemic development revealed that anterior sounds precede posterior ones, oral sounds precede nasal ones and stops precede fricatives. Glides and laterals showed very late acquisition. All segmental and supra-segmental disturbances improved gradually with regular use of CI and attending speech therapy plans. © 2019 Elsevier B.V.",31526935,Article,Final,,Scopus,2-s2.0-85072172835
Ge F.,"Ge, Fei (57221326115)",57221326115,Brief review of recent researches in speech enhancement from filters to neural networks,2020,"Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020",,,9276003,260,264,4,2,10.1109/CDS49703.2020.00059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098843429&doi=10.1109%2fCDS49703.2020.00059&partnerID=40&md5=ad7c1a87e2ed0e221aa7c2f82e7ca857,"According to the World Health Organization, more and more people will suffer from hearing loss in the future. Therefore, there will be greater demand for the output and technology of hearing aids. Under the help of artificial intelligence, the technology of smart hearing aids will also become more intelligent, so that the wearer can get a better experience. This paper mainly studies the related problems of speech signal processing in intelligent digital hearing aids. This article focuses on the speech enhancement in digital hearing aids. First, this work studies the application of filter in speech enhancement technology, mainly introduces the Wiener filter algorithm using the minimum mean square error criterion; the Kalman filter algorithm that can solve discrete signals; spectral subtraction based on multi-window spectrum estimation. Secondly, this paper studies some specific methods of deep learning technology in speech enhancement, mainly introduces DNN-based speech enhancement method, deep learning-based auditory cepstrum coefficient speech enhancement algorithm, and AE-CGAN-based speech enhancement algorithm. Finally, this paper studies the related problems of acoustic scene classification, divides the listening environment into Gaussian white noise, impact noise, and music noise, and explains the solutions for each listening environment. © 2020 IEEE",,Conference paper,Final,,Scopus,2-s2.0-85098843429
Emmett S.D.; Robler S.K.; Wang N.-Y.; Labrique A.; Gallo J.J.; Hofstetter P.,"Emmett, Susan D. (36052713800); Robler, Samantha Kleindienst (57201022586); Wang, Nae-Yuh (7404340658); Labrique, Alain (6505557971); Gallo, Joseph J. (7101605709); Hofstetter, Philip (57205441590)",36052713800; 57201022586; 7404340658; 6505557971; 7101605709; 57205441590,Hearing Norton Sound: A community randomised trial protocol to address childhood hearing loss in rural Alaska,2019,BMJ Open,9,1,e023078,,,,20,10.1136/bmjopen-2018-023078,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060061863&doi=10.1136%2fbmjopen-2018-023078&partnerID=40&md5=031c4527da525b436423ddacac6e474a,"Introduction: The population in rural Alaska experiences a disproprionately high burden of infection-mediated hearing loss. While the state mandates school hearing screening, many children with hearing loss are not identified or are lost to follow-up before ever receiving treatment. A robust, tribally owned healthcare system exists in Alaska, but children with hearing loss must first be identified and referred for existing infrastructure to be used. This trial will evaluate a new school hearing screening and referral process in rural Alaska, with the goal of improving timely identification and treatment of childhood hearing loss. Methods and analysis: Comparative effectiveness community randomised trial testing digital innovations to improve school hearing screening and referral in 15 communities in the Norton Sound region of northwest Alaska, with data collection from October 2017 to February 2020. All children (K-12) attending school in Bering Strait School District with parental informed consent and child assent will be eligible (target recruitment n=1500). Participating children will undergo both the current school hearing screen and new mobile health (mHealth) screen, with screening test validity evaluated against an audiometric assessment. Communities will be cluster randomised to continue the current primary care referral process or receive telemedicine referral for follow-up diagnosis and treatment. The primary outcome will be time to International Statistical Classification of Diseases, 10th Revision, ear/hearing diagnosis from screening date, measured in days. Secondary outcomes will include: sensitivity and specificity of current school and mHealth screening protocols measured against a benchmark audiometric assessment (air and bone conduction audiometry, tympanometry and digital otoscopy); hearing loss prevalence; hearing-related quality of life; and school performance (AIMSweb). Intention-to-treat analysis will be used. Ethics and: dissemination This study has been approved by the Institutional Review Boards of Alaska Area, Norton Sound and Duke University and is registered on clinicaltrials.gov. Results will be distributed with equal emphasis on scientific and community dissemination. © Author(s) (or their employer(s)) 2019.",30782695,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85060061863
Bidelman G.M.; Mahmud M.S.; Yeasin M.; Shen D.; Arnott S.R.; Alain C.,"Bidelman, Gavin M. (26325449700); Mahmud, Md Sultan (57195770993); Yeasin, Mohammed (18039042000); Shen, Dawei (14034704300); Arnott, Stephen R. (7005583955); Alain, Claude (7006562076)",26325449700; 57195770993; 18039042000; 14034704300; 7005583955; 7006562076,Age-related hearing loss increases full-brain connectivity while reversing directed signaling within the dorsal–ventral pathway for speech,2019,Brain Structure and Function,224,8,,2661,2676,15,34,10.1007/s00429-019-01922-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069674129&doi=10.1007%2fs00429-019-01922-9&partnerID=40&md5=3a0c33604c6a8ed5db503009da3b82a4,"Speech comprehension difficulties are ubiquitous to aging and hearing loss, particularly in noisy environments. Older adults’ poorer speech-in-noise (SIN) comprehension has been related to abnormal neural representations within various nodes (regions) of the speech network, but how senescent changes in hearing alter the transmission of brain signals remains unspecified. We measured electroencephalograms in older adults with and without mild hearing loss during a SIN identification task. Using functional connectivity and graph-theoretic analyses, we show that hearing-impaired (HI) listeners have more extended (less integrated) communication pathways and less efficient information exchange among widespread brain regions (larger network eccentricity) than their normal-hearing (NH) peers. Parameter optimized support vector machine classifiers applied to EEG connectivity data showed hearing status could be decoded (> 85% accuracy) solely using network-level descriptions of brain activity, but classification was particularly robust using left hemisphere connections. Notably, we found a reversal in directed neural signaling in left hemisphere dependent on hearing status among specific connections within the dorsal–ventral speech pathways. NH listeners showed an overall net “bottom-up” signaling directed from auditory cortex (A1) to inferior frontal gyrus (IFG; Broca’s area), whereas the HI group showed the reverse signal (i.e., “top-down” Broca’s → A1). A similar flow reversal was noted between left IFG and motor cortex. Our full-brain connectivity results demonstrate that even mild forms of hearing loss alter how the brain routes information within the auditory–linguistic–motor loop. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",31346715,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85069674129
Feng Y.; Yu P.; Li J.; Cao Y.; Zhang J.,"Feng, Yufei (57221196172); Yu, Ping (57221266858); Li, Jingyu (57205675773); Cao, Ying (55470329400); Zhang, Jingjing (56662280700)",57221196172; 57221266858; 57205675773; 55470329400; 56662280700,Phosphatidylinositol 4-kinase β is required for the ciliogenesis of zebrafish otic vesicle,2020,Journal of Genetics and Genomics,47,10,,627,636,9,8,10.1016/j.jgg.2020.07.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098501647&doi=10.1016%2fj.jgg.2020.07.007&partnerID=40&md5=526602c747f0c14d07e4c3839af813c9,"The primary cilium, an important microtubule-based organelle, protrudes from nearly all the vertebrate cells. The motility of cilia is necessary for various developmental and physiological processes. Phosphoinositides (PIs) and its metabolite, PtdIns(4,5)P2, have been revealed to contribute to cilia assembly and disassembly. As an important kinase of the PI pathway and signaling, phosphatidylinositol 4-kinase β (PI4KB) is the one of the most extensively studied phosphatidylinositol 4-kinase isoform. However, its potential roles in organ development remain to be characterized. To investigate the developmental role of Pi4kb, especially its function on zebrafish ciliogenesis, we generated pi4kb deletion mutants using clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated protein 9 technique. The homozygous pi4kb mutants exhibit an absence of primary cilia in the inner ear, neuromasts, and pronephric ducts accompanied by severe edema in the eyes and other organs. Moreover, smaller otic vesicle, malformed semicircular canals, and the insensitivity on sound stimulation were characteristics of pi4kb mutants. At the protein level, both in vivo and in vitro analyses revealed that synthesis of Pi4p was greatly reduced owing to the loss of Pi4kb. In addition, the expression of the Pi4kb-binding partner of neuronal calcium sensor-1, as well as the phosphorylation of phosphatidylinositol-4-phosphate downstream effecter of Akt, was significantly inhibited in pi4kb mutants. Taken together, our work uncovers a novel role of Pi4kb in zebrafish inner ear development and the functional formation of hearing ability by determining hair cell ciliogenesis. © 2020 Institute of Genetics and Developmental Biology, Chinese Academy of Sciences, and Genetics Society of China",33358778,Article,Final,,Scopus,2-s2.0-85098501647
Eckrich S.; Hecker D.; Sorg K.; Blum K.; Fischer K.; Münkner S.; Wenzel G.; Schick B.; Engel J.,"Eckrich, Stephanie (56823496600); Hecker, Dietmar (16175097900); Sorg, Katharina (57207758729); Blum, Kerstin (57191752391); Fischer, Kerstin (57209686272); Münkner, Stefan (6507140530); Wenzel, Gentiana (35254391500); Schick, Bernhard (7006075517); Engel, Jutta (35298876800)",56823496600; 16175097900; 57207758729; 57191752391; 57209686272; 6507140530; 35254391500; 7006075517; 35298876800,Cochlea-Specific deletion of Cav1.3 calcium channels arrests inner hair cell differentiation and unravels pitfalls of conditional mouse models,2019,Frontiers in Cellular Neuroscience,13,,225,,,,12,10.3389/fncel.2019.00225,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068484668&doi=10.3389%2ffncel.2019.00225&partnerID=40&md5=050505b47c37d13db9f35e5ead0c7c01,"Inner hair cell (IHC) Cav1.3 Ca2+ channels are multifunctional channels mediating Ca2+ influx for exocytosis at ribbon synapses, the generation of Ca2+ action potentials in pre-hearing IHCs and gene expression. IHCs of deaf systemic Cav1.3-deficient (Cav1.3-/-) mice stay immature because they fail to up-regulate voltage- and Ca2+-activated K+ (BK) channels but persistently express small conductance Ca2+-activated K+ (SK2) channels. In pre-hearing wildtype mice, cholinergic neurons from the superior olivary complex (SOC) exert efferent inhibition onto spontaneously active immature IHCs by activating their SK2 channels. Because Cav1.3 plays an important role for survival, health and function of SOC neurons, SK2 channel persistence and lack of BK channels in systemic Cav1.3-/- IHCs may result from malfunctioning neurons of the SOC. Here we analyze cochlea-specific Cav1.3 knockout mice with green fluorescent protein (GFP) switch reporter function, Pax2::cre;Cacna1d-eGFPflex/flex and Pax2::cre;Cacna1d-eGFPflex/-. Profound hearing loss, lack of BK channels and persistence of SK2 channels in Pax2::cre;Cacna1d-eGFPflex/- mice recapitulated the phenotype of systemic Cav1.3-/- mice, indicating that in wildtype mice, regulation of SK2 and BK channel expression is independent of Cav1.3 expression in SOC neurons. In addition, we noticed dose-dependent GFP toxicity leading to death of basal coil IHCs of Pax2::cre;Cacna1d-eGFPflex/flex mice, likely because of high GFP concentration and small repair capacity. This and the slower time course of Pax2-driven Cre recombinase in switching two rather than one Cacna1d-eGFPflex allele lead us to study Pax2::cre;Cacna1d-eGFPflex/- mice. Notably, control Cacna1d-eGFPflex/- IHCs showed a significant reduction in Cav1.3 channel cluster sizes and currents, suggesting that the intronic construct interfered with gene translation or splicing. These pitfalls are likely to be a frequent problem of many genetically modified mice with complex or multiple gene-targeting constructs or fluorescent proteins. Great caution and appropriate controls are therefore required. © 2019 Eckrich, Hecker, Sorg, Blum, Fischer, Münkner, Wenzel, Schick and Engel.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85068484668
Men Y.; Li X.; Tu H.; Zhang A.; Fu X.; Wang Z.; Jin Y.; Hou C.; Zhang T.; Zhang S.; Zhou Y.; Li B.; Li J.; Sun X.; Wang H.; Gao J.,"Men, Yuqin (56888477100); Li, Xiujuan (57203718293); Tu, Hailong (57203711069); Zhang, Aizhen (56321935400); Fu, Xiaolong (57189600139); Wang, Zhishuo (57192118805); Jin, Yecheng (55605114200); Hou, Congzhe (55981883200); Zhang, Tingting (57208071086); Zhang, Sen (57207330983); Zhou, Yichen (57192907407); Li, Boqin (56424198700); Li, Jianfeng (57115579800); Sun, Xiaoyang (56373124300); Wang, Haibo (57221608959); Gao, Jiangang (56555482400)",56888477100; 57203718293; 57203711069; 56321935400; 57189600139; 57192118805; 55605114200; 55981883200; 57208071086; 57207330983; 57192907407; 56424198700; 57115579800; 56373124300; 57221608959; 56555482400,Tprn is essential for the integrity of stereociliary rootlet in cochlear hair cells in mice,2019,Frontiers of Medicine,13,6,,690,704,14,7,10.1007/s11684-018-0638-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052706719&doi=10.1007%2fs11684-018-0638-8&partnerID=40&md5=e2ac440c25839bdcda8489365c768085,"Tprn encodes the taperin protein, which is concentrated in the tapered region of hair cell stereocilia in the inner ear. In humans, TPRN mutations cause autosomal recessive nonsyndromic deafness (DFNB79) by an unknown mechanism. To determine the role of Tprn in hearing, we generated Tprn-null mice by clustered regularly interspaced short palindromic repeat/Cas9 genome-editing technology from a CBA/CaJ background. We observed significant hearing loss and progressive degeneration of stereocilia in the outer hair cells of Tprn-null mice starting from postnatal day 30. Transmission electron microscopy images of stereociliary bundles in the mutant mice showed some stereociliary rootlets with curved shafts. The central cores of the stereociliary rootlets possessed hollow structures with surrounding loose peripheral dense rings. Radixin, a protein expressed at stereocilia tapering, was abnormally dispersed along the stereocilia shafts in Tprn-null mice. The expression levels of radixin and β-actin significantly decreased.We propose that Tprn is critical to the retention of the integrity of the stereociliary rootlet. Loss of Tprn in Tprn-null mice caused the disruption of the stereociliary rootlet, which resulted in damage to stereociliary bundles and hearing impairments. The generated Tprn-null mice are ideal models of human hereditary deafness DFNB79. © 2018, Higher Education Press and Springer-Verlag GmbH Germany, part of Springer Nature.",30159668,Article,Final,,Scopus,2-s2.0-85052706719
Chang Y.-S.; Yoon S.H.; Kim J.R.; Baek S.-Y.; Cho Y.S.; Hong S.H.; Kim S.; Moon I.J.,"Chang, Young-Soo (56193558800); Yoon, Sung Hoon (57206933352); Kim, Jin Ryoul (56490415100); Baek, Sun-Young (57203575696); Cho, Young Sang (56975672700); Hong, Sung Hwa (21934425200); Kim, Seonwoo (8961850200); Moon, Il Joon (13606798300)",56193558800; 57206933352; 56490415100; 57203575696; 56975672700; 21934425200; 8961850200; 13606798300,Standard Audiograms for Koreans Derived through Hierarchical Clustering Using Data from the Korean National Health and Nutrition Examination Survey 2009–2012,2019,Scientific Reports,9,1,3675,,,,6,10.1038/s41598-019-40300-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062585306&doi=10.1038%2fs41598-019-40300-7&partnerID=40&md5=8847e2f0c2bcb0505903de98b8432f11,"Assessments of standardized region/population-specific audiological characteristics are needed for provision of effective rehabilitative services through reducing costs associated with hearing aids. This study aims to propose a set of standard audiograms representing the Korean population that were derived by analyzing data from the 2009–2012 Korea National Health and Nutrition Examination Survey (KNHANES), a nationwide epidemiologic study conducted by Korean government organizations. Standard audiograms were derived by applying a hierarchical clustering method from recorded audiologic data that were obtained independently at 6 frequencies for each ear: 0.5, 1.0, 2.0, 3.0, 4.0, and 6.0 kHz (in dB HL). To derive the optimal number of clusters of the desired standard audiograms, cubic clustering criterion, pseudo-F-, and pseudo-t2-statistics were calculated. These analyses resulted in 29 clusters representing a standard audiogram of the South Korean population. Eighteen of the clusters represented normal hearing audiograms (73.11%), while 11 represented hearing-impaired (HI) standard audiograms (27.89%). Of the 11 HI audiograms, 7 were defined as flat-type (17.81%), while the remaining 4 were defined as sloping-type (9.08%). In conclusion, 29 audiograms representing standard audiograms for the Korean population have been derived using KNHANES data. Improved understanding of the characteristics of each cluster may be helpful for development of more personalized, fixed-setting hearing aids. © 2019, The Author(s).",30842521,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85062585306
Wathour J.; Govaerts P.J.; Deggouj N.,"Wathour, Justine (57041226200); Govaerts, Paul J. (7005148990); Deggouj, Naïma (7003305164)",57041226200; 7005148990; 7003305164,From manual to artificial intelligence fitting: Two cochlear implant case studies,2020,Cochlear Implants International,21,5,,299,305,6,6,10.1080/14670100.2019.1667574,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073995334&doi=10.1080%2f14670100.2019.1667574&partnerID=40&md5=7bb353ebc27f19e261a0e972ece98c1f,"Objective: To assess whether CI programming by means of a software application using artificial intelligence (AI), FOX®, may improve cochlear implant (CI) performance. Patients: Two adult CI recipients who had mixed auditory results with their manual fitting were selected for an AI-assisted fitting. Even after 17 months CI experience and 19 manual fitting sessions, the first subject hadn’t developed open set word recognition. The second subject, after 9 months of manual fitting, had developed good open set word recognition, but his scores remained poor at soft and loud presentation levels. Main outcome measure(s): Cochlear implant fitting parameters, pure tone thresholds, bisyllabic word recognition, phonemic discrimination scores and loudness scaling curves. Results: For subject 1, a first approach trying to optimize the home maps by means of AI-proposed adaptations was not successful whereas a second approach based on the use of Automaps (an AI approach based on universal, i.e. population based group statistics) during 3 months allowed the development of open set word recognition. For subject 2, the word recognition scores improved at soft and loud intensities with the AI suggestions. The AI-suggested modifications seem to be atypical. Conclusions: The two case studies illustrate that adults implanted with manual CI fitting may experience an improvement in their auditory results with AI-assisted fitting. © 2019 Informa UK Limited, trading as Taylor & Francis Group.",31530099,Article,Final,,Scopus,2-s2.0-85073995334
Kelly-Smith M.; Strain G.M.,"Kelly-Smith, Maria (57216815920); Strain, George M. (7006446955)",57216815920; 7006446955,STRING data mining of GWAS data in canine hereditary pigment-associated deafness,2020,Veterinary and Animal Science,9,,100118,,,,5,10.1016/j.vas.2020.100118,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085036200&doi=10.1016%2fj.vas.2020.100118&partnerID=40&md5=eb4bdb2e1af8182516af74d5ccf9dc0d,"Most canine deafness is linked to white pigmentation caused by the piebald locus, shown to be the gene MITF (melanocyte inducing transcription factor), but studies have failed to identify a deafness cause. The coding regions of MITF have not been shown to be mutated in deaf dogs, leading us to pursue genes acting on or controlled by MITF. We have genotyped DNA from 502 deaf and hearing Australian cattle dogs, Dalmatians, and English setters, breeds with a high deafness prevalence. Genome-wide significance was not attained in any of our analyses, but we did identify several suggestive associations. Genome-wide association studies (GWAS) in complex hereditary disorders frequently fail to identify causative gene variants, so advanced bioinformatics data mining techniques are needed to extract information to guide future studies. STRING diagrams are graphical representations of known and predicted networks of protein-protein interactions, identifying documented relationships between gene proteins based on the scientific literature, to identify functional gene groupings to pursue for further scrutiny. The STRING program predicts associations at a preset confidence level and suggests biological functions based on the identified genes. Starting with (1) genes within 500 kb of GWAS-suggested SNPs, (2) known pigmentation genes, (3) known human deafness genes, and (4) genes identified from proteomic analysis of the cochlea, we generated STRING diagrams that included these genes. We then reduced the number of genes by excluding genes with no relationship to auditory function, pigmentation, or relevant structures, and identified clusters of genes that warrant further investigation. © 2020 The Authors",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85085036200
Bright T.; Mulwafu W.; Phiri M.; Jiang F.; Swanepoel D.W.; Kuper H.; Mactaggart I.; Yip J.L.Y.; Polack S.,"Bright, Tess (57193859076); Mulwafu, Wakisa (16316845600); Phiri, Mwanaisha (57208742300); Jiang, Fan (56496138100); Swanepoel, De Wet (13609471200); Kuper, Hannah (7004023998); Mactaggart, Islay (56255420000); Yip, Jennifer L. Y. (8561665000); Polack, Sarah (6602403285)",57193859076; 16316845600; 57208742300; 56496138100; 13609471200; 7004023998; 56255420000; 8561665000; 6602403285,"Field test of the Rapid Assessment of Hearing Loss survey protocol in Ntcheu district, Malawi",2020,International Journal of Audiology,59,8,,574,582,8,4,10.1080/14992027.2020.1739764,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081755244&doi=10.1080%2f14992027.2020.1739764&partnerID=40&md5=ccf841687b397ff2b94337293241703d,"Objective: (1) To test the feasibility of the Rapid Assessment of Hearing Loss (RAHL) survey protocol in Malawi (Ntcheu); (2) To estimate the prevalence and probable causes of hearing loss (adults 50+). Design: Cross-sectional population-based survey. Study sample: Clusters (n = 38) were selected using probability-proportionate-to-size-sampling. Within each cluster, 30 people aged 50+ were selected using compact-segment-sampling. All participants completed smartphone-based audiometry (hearTest). Prevalence was estimated using WHO definitions (PTA of thresholds 0.5, 1, 2, 4 kHz in the better ear of >25 dB HL (any) and >40 dB HL (≥moderate)). Otoscopy and questionnaire were used to assess probable causes. Participants with hearing loss and/or ear disease were asked about care-seeking and barriers. Results: Four teams completed the survey in 24 days. 1080 of 1153 (93.7%) participants were examined. The median time to complete the protocol was 24 min/participant. Prevalence of hearing loss was 35.9% (95% CI = 31.6–40.2) (any level); and 10.0% (95% CI = 7.9–12.5) (≥moderate). The majority was classified as probable sensorineural. Nearly one third of people (30.9%) needed diagnostic audiology services and possible hearing aid fitting. Hearing aid coverage was <1%. Lack of perceived need was a key barrier. Conclusion: The RAHL is simple, fast and provides information about the magnitude and probable causes of hearing loss to plan services. © 2020 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",32180476,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85081755244
Mahmud M.S.; Ahmed F.; Al-Fahad R.; Moinuddin K.A.; Yeasin M.; Alain C.; Bidelman G.M.,"Mahmud, Md Sultan (57195770993); Ahmed, Faruk (57196026885); Al-Fahad, Rakib (57193643596); Moinuddin, Kazi Ashraf (57218322163); Yeasin, Mohammed (18039042000); Alain, Claude (7006562076); Bidelman, Gavin M. (26325449700)",57195770993; 57196026885; 57193643596; 57218322163; 18039042000; 7006562076; 26325449700,Decoding Hearing-Related Changes in Older Adults’ Spatiotemporal Neural Processing of Speech Using Machine Learning,2020,Frontiers in Neuroscience,14,,748,,,,12,10.3389/fnins.2020.00748,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088798297&doi=10.3389%2ffnins.2020.00748&partnerID=40&md5=0d9fee52c4a7af7d4549cf539317ae95,"Speech perception in noisy environments depends on complex interactions between sensory and cognitive systems. In older adults, such interactions may be affected, especially in those individuals who have more severe age-related hearing loss. Using a data-driven approach, we assessed the temporal (when in time) and spatial (where in the brain) characteristics of cortical speech-evoked responses that distinguish older adults with or without mild hearing loss. We performed source analyses to estimate cortical surface signals from the EEG recordings during a phoneme discrimination task conducted under clear and noise-degraded conditions. We computed source-level ERPs (i.e., mean activation within each ROI) from each of the 68 ROIs of the Desikan-Killiany (DK) atlas, averaged over a randomly chosen 100 trials without replacement to form feature vectors. We adopted a multivariate feature selection method called stability selection and control to choose features that are consistent over a range of model parameters. We use parameter optimized support vector machine (SVM) as a classifiers to investigate the time course and brain regions that segregate groups and speech clarity. For clear speech perception, whole-brain data revealed a classification accuracy of 81.50% [area under the curve (AUC) 80.73%; F1-score 82.00%], distinguishing groups within ∼60 ms after speech onset (i.e., as early as the P1 wave). We observed lower accuracy of 78.12% [AUC 77.64%; F1-score 78.00%] and delayed classification performance when speech was embedded in noise, with group segregation at 80 ms. Separate analysis using left (LH) and right hemisphere (RH) regions showed that LH speech activity was better at distinguishing hearing groups than activity measured in the RH. Moreover, stability selection analysis identified 12 brain regions (among 1428 total spatiotemporal features from 68 regions) where source activity segregated groups with >80% accuracy (clear speech); whereas 16 regions were critical for noise-degraded speech to achieve a comparable level of group segregation (78.7% accuracy). Our results identify critical time-courses and brain regions that distinguish mild hearing loss from normal hearing in older adults and confirm a larger number of active areas, particularly in RH, when processing noise-degraded speech information. © Copyright © 2020 Mahmud, Ahmed, Al-Fahad, Moinuddin, Yeasin, Alain and Bidelman.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85088798297
Zou B.; Desmidt A.A.; Mittal R.; Yan D.; Richmond M.; Tekin M.; Liu X.Z.; Lu Z.,"Zou, Bing (56673554700); Desmidt, Alexandra A. (55795561400); Mittal, Rahul (7202560100); Yan, Denise (7401863128); Richmond, Micheal (57208163300); Tekin, Mustafa (7005614191); Liu, Xue Zhong (26642875300); Lu, Zhongmin (7404769187)",56673554700; 55795561400; 7202560100; 7401863128; 57208163300; 7005614191; 26642875300; 7404769187,The Generation of Zebrafish Mariner Model Using the CRISPR/Cas9 System,2020,Anatomical Record,303,3,,556,562,6,1,10.1002/ar.24221,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069924617&doi=10.1002%2far.24221&partnerID=40&md5=4359d936d9841fcc4750fe29871da653,"Targeted genome editing mediated by clustered, regularly interspaced, short palindromic repeat (CRISPR)/CRISPR-associated nuclease 9 (Cas9) technology has emerged as a powerful tool for gene function studies and has great potential for gene therapy. Although CRISPR/Cas9 has been widely used in many research fields, only a few successful zebrafish models have been established using this technology in hearing research. In this study, we successfully created zebrafish mariner mutants by targeting the motor head domain of Myo7aa using CRISPR/Cas9. The CRISPR/Cas9-generated mutants showed unbalanced swimming behavior and disorganized sterocilia of inner ear hair cells, which resemble the phenotype of the zebrafish mariner mutants. In addition, we found that CRISPR/Cas9-generated mutants have reduced number of stereociliary bundles of inner ear hair cells and have significant hearing loss. Furthermore, phenotypic analysis was performed on F0 larvae within the first week post fertilization, which dramatically shortens data collection period. Therefore, results of this study showed that CRISPR/Cas9 is a quick and effective method to generate zebrafish mutants as a model for studying human genetic deafness. Anat Rec, 303:556–562, 2020. © 2019 American Association for Anatomy. © 2019 Wiley Periodicals, Inc.",31260171,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85069924617
Bright T.; Shan X.; Xu J.; Liang J.; Xiao B.; Ensink R.; Mactaggart I.; Polack S.; Yip J.L.Y.,"Bright, Tess (57193859076); Shan, Xin (57215576004); Xu, Jinling (57215575128); Liang, Jianguo (57215593822); Xiao, Baixiang (36474151700); Ensink, Robbert (6701485385); Mactaggart, Islay (56255420000); Polack, Sarah (6602403285); Yip, Jennifer L. Y. (8561665000)",57193859076; 57215576004; 57215575128; 57215593822; 36474151700; 6701485385; 56255420000; 6602403285; 8561665000,"Field-testing of a rapid survey method to assess the prevalence and causes of hearing loss in Gao'an, Jiangxi province, China",2020,Archives of Public Health,78,1,16,,,,6,10.1186/s13690-020-0398-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081197802&doi=10.1186%2fs13690-020-0398-1&partnerID=40&md5=9ac3270ad093865e4312580b1c0bcbd1,"Background: The Rapid Assessment of Hearing Loss (RAHL) survey protocol aims to measure the prevalence and causes of hearing loss in a low cost and rapid manner, to inform planning of ear and hearing services. This paper reports on the first field-test of the RAHL in Gao'an County, Jiangxi Province, China. This study aimed to 1) To report on the feasibility of RAHL; 2) report on the estimated prevalence and causes of hearing loss in Gao'an. Methods: A cross-sectional population-based survey was conducted in September-October 2018. Forty-seven clusters in Gao'an County were selected using probability-proportionate-to-size sampling. Within clusters, compact segment sampling was conducted to select 30 people aged 50+. A questionnaire was completed covering sociodemographics, hearing health, and risk factors. Automated pure-tone audiometry was completed for all participants, using smartphone-based audiometry (hearTest), at 0.5, 1, 2, 4 kHz (kHz). All participants had their ears examined by an Ear Nose and Throat (ENT) doctor, using otoscopy, and probable causes of hearing loss assigned. Prevalence estimates were age and sex standardised to the Jiangxi population. Feasibility of a cluster size of 30 was examined by assessing the response rate, and the proportion of clusters completed in 1 day. Results: 1344 of 1421 eligible participants completed the survey (94.6%). 100% of clusters were completed in 1 day. The survey was completed in 4.5 weeks. The prevalence of moderate or greater hearing loss (pure-tone average of 0.5, 1, 2, 4 kHz of > = 41dBHL in the better ear) was 16.3% (95% CI = 14.3, 18.5) and for any level of hearing loss (pure-tone average of > = 26dBHL in the better ear) the prevalence was 53.2% (95% CI = 49.2, 57.1). The majority of hearing loss was due to acquired sensorineural causes (91.7% left; 92.1% right). Overall 54.0% of the population aged 50+ (108,000 people) are in need of diagnostic audiology services, 3.4% were in need of wax removal (7000 people), and 4.8% were in need of surgical services (9500 people). Hearing aid coverage was 0.4%. Conclusion: The RAHL survey protocol is feasible, demonstrated through the number of people examined per day, and the high response rate. The survey was completed in a much shorter period than previous all-age surveys in China. Some remaining challenges included assignment of causes of probable sensorineural loss. The data obtained from this survey can be used to scale-up hearing services in Gao'an. © 2020 The Author(s).",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85081197802
Jensen N.S.; Balling L.W.; Nielsen J.B.B.,"Jensen, Niels Søgaard (35169618000); Balling, Laura Winther (55318852900); Nielsen, Jens Brehm Bagger (57200656087)",35169618000; 55318852900; 57200656087,Effects of personalizing hearing-aid parameter settings using a real-time machine-learning approach,2019,Proceedings of the International Congress on Acoustics,2019-September,,,3858,3865,7,2,10.18154/RWTH-CONV-239132,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099331086&doi=10.18154%2fRWTH-CONV-239132&partnerID=40&md5=86ecf050e83e40a1eee0097de121f9a9,"In most hearing-aid fittings, amplification is prescribed by a fitting rationale that uses the audiogram as the main input. This approach may fail in situations where the user's listening intention deviates from that assumed by the rationale. This shortcoming motivated a new commercially available method to self-adjust hearing-aid parameters while in a specific situation. The method is based on machine-learning algorithms that estimate the setting that optimizes user satisfaction based on user preferences in paired comparisons of parameter settings. We present results from a lab study where 20 participants with hearing loss used the method to adjust hearing-aid gain in 12 different sound scenarios with respect to three different sound attributes, and subsequently, in a double-blind assessment, compared the adjusted settings with the prescribed settings. The results showed a benefit of the method on basic audio quality. A large spread in the gain adjustments was observed, suggesting the need for more personalized settings of hearing aids. We also present anonymous user data gathered during real-life use of the method, which indicate when and why the method is used. We compare these data to general investigations of listeners' auditory reality and suggest clinical and rehabilitative implications of using the method. © 2019 Proceedings of the International Congress on Acoustics. All rights reserved.",,Conference paper,Final,,Scopus,2-s2.0-85099331086
Li H.; Lv J.; Zhou Q.; Jin L.; Kang Z.; Huang Y.,"Li, He (57193550600); Lv, Jun (58278134100); Zhou, Qinshuang (57212682172); Jin, Lanlan (57212684109); Kang, Zonghui (57212672694); Huang, Yideng (57194284796)",57193550600; 58278134100; 57212682172; 57212684109; 57212672694; 57194284796,The role of sperm associated antigen 6 gene in morphological changes of inner ear development and signal regulation of auditory organs in mice,2020,Journal of King Saud University - Science,32,2,,1586,1591,5,0,10.1016/j.jksus.2019.12.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077337605&doi=10.1016%2fj.jksus.2019.12.015&partnerID=40&md5=851dd5dd52efb775290ded22a36927d0,"Aim: In order to analyze the effects of the deletion of the Sperm Associated Antigen 6 (Spag6) gene on the inner ear and the auditory system of mice. Method: Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)/Cas9 technology was utilized, and the Spag6 gene knockout mouse model was constructed. Self-breeding was carried out to obtain the F1 generation Spag6 homozygous mouse (Spag−/−), the Spag6 heterozygous mouse (Spag+/−) and the Spag6 wild mouse (Spag+/+) were obtained. Polymerase Chain Reaction (PCR) technology was used to verify the three genotypes of mice. The mean hearing threshold of Spag−/− mice, Spag+/− mice and Spag+/+ mice after different intensity of sound stimulation was detected. The inner ear cochlea tissues of Spag−/− mice and Spag+/+ mice were collected and paraffin sections were made. Morphological differences of inner ear tissues in mice were analyzed by hematoxylin – eosin (HE) staining. Immunofluorescence staining was used to analyze the number of hair cells in the inner ear of mice. Apoptosis of mouse inner ear hair cells was analyzed by TdT-mediated dUTP Nick-End Labeling (TUNEL) staining Result: It was found that the hearing of Spag−/− mice decreased significantly compared with that of Spag+/+ mice (P < 0.01), and the hearing of Spag+/− mice decreased significantly compared with that of Spag+/− mice (P < 0.05). After HE staining and immunofluorescence staining, hair cells in the inner ear cochlea of Spag−/− mice were found to be defective. The apoptosis detection results of TUNEL staining indicated that the number of apoptosis of hair cells in inner ear cochlea of Spag−/− mice was significantly higher than that of Spag+/+ mice, and the average optical density of Corti apparatus of Spag−/− mice was significantly higher than that of Spag+/+ mice (P < 0.01). Conclusion: The results showed that the loss of the Spag6 gene accelerated the apoptosis of hair cells in the cochlear tissue of the inner ear of mice, thereby affecting the auditory system of mice. The significance of this study is to lay the foundation for future studies on the effects of Spag6 on deafness. © 2019 The Authors",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85077337605
Molina M.E.; Perez A.; Valente J.P.,"Molina, Marco E. (57189582006); Perez, Aurora (18038093100); Valente, Juan P. (18039004500)",57189582006; 18038093100; 18039004500,Classification of auditory brainstem responses through symbolic pattern discovery,2016,Artificial Intelligence in Medicine,70,,,12,30,18,14,10.1016/j.artmed.2016.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973144098&doi=10.1016%2fj.artmed.2016.05.001&partnerID=40&md5=1d9c0fad5fb8c76807ace91a7b4aeaa3,"Introduction: Numeric time series are present in a very wide range of domains, including many branches of medicine. Data mining techniques have proved to be useful for knowledge discovery in this type of data and for supporting decision-making processes. Objectives: The overall objective is to classify time series based on the discovery of frequent patterns. These patterns will be discovered in symbolic sequences obtained from the time series data by means of a temporal abstraction process. Methods: Firstly, we transform numeric time series into symbolic time sequences, where the symbols aim to represent the relevant domain concepts. These symbols can be defined using either public or expert domain knowledge. Then we apply a symbolic pattern discovery technique to the output symbolic sequences. This technique identifies the subsequences frequently found in a population group. These subsequences (patterns) are representative of population groups. Finally, we employ a classification technique based on the identified patterns in order to classify new individuals. Thanks to the inclusion of domain knowledge, the classification results can be explained using domain terminology. This makes the results easier to interpret for the domain specialist (physician). Results: This method has been applied to brainstem auditory evoked potentials (BAEPs) time series. Preliminary experiments were carried out to analyse several aspects of the method including the best configuration of the pattern discovery technique parameters. We then applied the method to the BAEPs of 83 individuals belonging to four classes (healthy, conductive hearing loss, vestibular schwannoma-brainstem involvement and vestibular schwannoma-8th-nerve involvement). According to the results of the cross-validation, overall accuracy was 99.4%, sensitivity (recall) was 97.6% and specificity was 100% (no false positives). Conclusion: The proposed method effectively reduces dimensionality. Additionally, if the symbolic transformation includes the right domain knowledge, the method arguably outputs a data representation that denotes the relevant domain concepts more clearly. The method is capable of finding patterns in BAEPs time series and is very accurate at correctly predicting whether or not new patients have an auditory-related disorder. © 2016 Elsevier B.V..",27431034,Article,Final,,Scopus,2-s2.0-84973144098
Sun S.; Babola T.; Pregernig G.; So K.S.; Nguyen M.; Su S.-S.M.; Palermo A.T.; Bergles D.E.; Burns J.C.; Müller U.,"Sun, Shuohao (57729170300); Babola, Travis (57195967579); Pregernig, Gabriela (57148437700); So, Kathy S. (55228647800); Nguyen, Matthew (57193324214); Su, Shin-San M. (57190445278); Palermo, Adam T. (8283352500); Bergles, Dwight E. (6603360426); Burns, Joseph C. (57203057585); Müller, Ulrich (35230323400)",57729170300; 57195967579; 57148437700; 55228647800; 57193324214; 57190445278; 8283352500; 6603360426; 57203057585; 35230323400,Hair Cell Mechanotransduction Regulates Spontaneous Activity and Spiral Ganglion Subtype Specification in the Auditory System,2018,Cell,174,5,,1247,1.26E+18,,185,10.1016/j.cell.2018.07.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050998358&doi=10.1016%2fj.cell.2018.07.008&partnerID=40&md5=4e8f8e7e07fc0d0e01a76351a0e927fd,"Type I spiral ganglion neurons (SGNs) transmit sound information from cochlear hair cells to the CNS. Using transcriptome analysis of thousands of single neurons, we demonstrate that murine type I SGNs consist of subclasses that are defined by the expression of subsets of transcription factors, cell adhesion molecules, ion channels, and neurotransmitter receptors. Subtype specification is initiated prior to the onset of hearing during the time period when auditory circuits mature. Gene mutations linked to deafness that disrupt hair cell mechanotransduction or glutamatergic signaling perturb the firing behavior of SGNs prior to hearing onset and disrupt SGN subtype specification. We thus conclude that an intact hair cell mechanotransduction machinery is critical during the pre-hearing period to regulate the firing behavior of SGNs and their segregation into subtypes. Because deafness is frequently caused by defects in hair cells, our findings have significant ramifications for the etiology of hearing loss and its treatment. Single-cell analyses of mouse type I spiral ganglion neurons characterize three functionally distinct subtypes, revealing insights into auditory processing with implications for treating congenital deafness. © 2018 Elsevier Inc.",30078710,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85050998358
Ramos-Miguel A.; Perez-Zaballos T.; Perez D.; Falconb J.C.; Ramosb A.,"Ramos-Miguel, Angel (56866155200); Perez-Zaballos, Teresa (56866365200); Perez, Daniel (12765592500); Falconb, Juan Carlos (56866325600); Ramosb, Angel (56866342300)",56866155200; 56866365200; 12765592500; 56866325600; 56866342300,Use of data mining to predict significant factors and benefits of bilateral cochlear implantation,2015,European Archives of Oto-Rhino-Laryngology,272,11,,3157,3162,5,16,10.1007/s00405-014-3337-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942154640&doi=10.1007%2fs00405-014-3337-3&partnerID=40&md5=8de2051506130574e5bc5e89451967bb,"Data mining (DM) is a technique used to discover pattern and knowledge from a big amount of data. It uses artificial intelligence, automatic learning, statistics, databases, etc. In this study, DM was successfully used as a predictive tool to assess disyllabic speech test performance in bilateral implanted patients with a success rate above 90 %. 60 bilateral sequentially implanted adult patients were included in the study. The DM algorithms developed found correlations between unilateral medical records and Audiological test results and bilateral performance by establishing relevant variables based on two DM techniques: the classifier and the estimation. The nearest neighbor algorithm was implemented in the first case, and the linear regression in the second. The results showed that patients with unilateral disyllabic test results below 70 % benefited the most from a bilateral implantation. Finally, it was observed that its benefits decrease as the inter-implant time increases. © 2014, Springer-Verlag Berlin Heidelberg.",25323153,Article,Final,,Scopus,2-s2.0-84942154640
Cai T.; McPherson B.; Li C.; Yang F.,"Cai, Ting (57191921127); McPherson, Bradley (7006800770); Li, Caiwei (57193417851); Yang, Feng (57191867132)",57191921127; 7006800770; 57193417851; 57191867132,Pure tone hearing profiles in children with otitis media with effusion,2018,Disability and Rehabilitation,40,10,,1166,1175,9,22,10.1080/09638288.2017.1290698,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013820466&doi=10.1080%2f09638288.2017.1290698&partnerID=40&md5=4117dc6a7da16868fbec0370606fc3d1,"Introduction: Otitis media with effusion (OME) is a common middle ear disease in children. The associated conductive hearing loss is a major concern for hearing health professionals. The aim of the present study was to describe the configuration of pure tone audiograms of children with OME and to design a statistical stratification algorithm to facilitate hearing loss profiling in children with OME. Methods: School age children with OME were recruited. Bone and air conduction thresholds were obtained using standard procedures. Hierarchical cluster analysis was employed to determine audiometric profile groups. The Mandarin Hearing in Noise Test was used to measure sentence perception in children for cluster analysis validity assessment. Results: Ninety-seven children (164 ears) aged between 72 months and 153 months were examined. Air conduction thresholds averaged for 500 Hz, 1000 Hz and 2000 Hz were in the range of 8.3–53.3 dB HL with a mean of 26.8 dB HL. Bone conduction thresholds were found to be influenced by middle ear pathology with a maximal elevation at 2000 Hz of 25 dB HL. Four audiometric profiles were identified. Cluster 1 contained 54 ears (32.9%) with normal or near normal hearing, Clusters 2 contained 37 ears (22.6%) with mild hearing loss, Cluster 3 included 48 ears (29.3%) and Cluster 4 included 25 ears (15.2%) with moderate hearing loss. Stability and validity of the four-cluster profiling procedure was examined and established with satisfactory results. Conclusions: OME in children is associated with pure tone hearing thresholds ranging from normal to moderate hearing loss. The hierarchical clustering algorithm proved useful as a novel means of profiling hearing loss in children with OME and may assist in identifying affected children at greater risk of auditory disadvantage. Implications for rehabilitation A hierarchical cluster analysis method can be used to determine audiometric profiles in children with OME. This algorithm assists to identify children at greater risk of auditory disadvantage. Cluster groups with more elevated pure tone thresholds may be targeted for priority in clinical surveillance and medical/surgical intervention. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",28637148,Article,Final,,Scopus,2-s2.0-85013820466
Ehlert K.,"Ehlert, Katerina (57193556143)",57193556143,Perceptions of public primary school teachers regarding noise-induced hearing loss in South Africa,2017,The South African journal of communication disorders = Die Suid-Afrikaanse tydskrif vir Kommunikasieafwykings,64,1,,e1,e12,11,6,10.4102/sajcd.v64i1.185,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040017528&doi=10.4102%2fsajcd.v64i1.185&partnerID=40&md5=aa67f67e8c05ff7d03731f089e3addf4,"BACKGROUND: Noise-induced hearing loss (NIHL) is an increasingly growing problem in young children. This is attributed to recreational noise being the most common cause of this problem. In young children, hearing problems can delay language development and reduce academic achievements. South Africa, in particular, has limited information and protective measures regarding the conservation of hearing in school-aged children.; OBJECTIVES: The main aim of the study was to determine the perception of primary school teachers regarding NIHL. The study also aimed to determine if any hearing conservation programmes are being implemented in schools and the need for training of primary school teachers regarding NIHL.; METHOD: A survey was conducted. In order to cover the population of interest, the sampled schools in Pretoria were clustered into urban, semi-urban and rural areas.; RESULTS: The majority of the teachers included in this study are aware of NIHL and its effects. They, however, lack the necessary resources and knowledge to effectively use this information. Most (67.5%) of the teachers indicated that they have never been exposed to children with NIHL in a school setting. It was also found that the majority (84%) of the schools included in the study do not implement hearing screening and conservation programmes.; CONCLUSION: Although the sample size was limited, the results correlate with other research in this field indicating a need for planning and implementation of hearing conservation programmes in schools, including training of teachers in order for these programmes to be effective.",28397520,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85040017528
Monaghan J.J.; Goehring T.; Yang X.; Bolner F.; Wang S.; Wright M.C.; Bleeck S.,"Monaghan, Jessica J M (26434339400); Goehring, Tobias (57189595633); Yang, Xin (57192379699); Bolner, Federico (57189588142); Wang, Shangqiguo (57207691210); Wright, Matthew C M (56375767400); Bleeck, Stefan (23011378000)",26434339400; 57189595633; 57192379699; 57189588142; 57207691210; 56375767400; 23011378000,Auditory inspired machine learning techniques can improve speech intelligibility and quality for hearing-impaired listeners,2017,The Journal of the Acoustical Society of America,141,3,,1985,,,21,10.1121/1.4977197,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041191034&doi=10.1121%2f1.4977197&partnerID=40&md5=10bea5a942d4463a939fe0347452fe7e,"Machine-learning based approaches to speech enhancement have recently shown great promise for improving speech intelligibility for hearing-impaired listeners. Here, the performance of three machine-learning algorithms and one classical algorithm, Wiener filtering, was compared. Two algorithms based on neural networks were examined, one using a previously reported feature set and one using a feature set derived from an auditory model. The third machine-learning approach was a dictionary-based sparse-coding algorithm. Speech intelligibility and quality scores were obtained for participants with mild-to-moderate hearing impairments listening to sentences in speech-shaped noise and multi-talker babble following processing with the algorithms. Intelligibility and quality scores were significantly improved by each of the three machine-learning approaches, but not by the classical approach. The largest improvements for both speech intelligibility and quality were found by implementing a neural network using the feature set based on auditory modeling. Furthermore, neural network based techniques appeared more promising than dictionary-based, sparse coding in terms of performance and ease of implementation.",28372043,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85041191034
Zhao Y.; Chen X.; Zhong S.; Cui Z.; Gong G.; Dong Q.; Nan Y.,"Zhao, Yanxin (57189471856); Chen, Xizhuo (57189461634); Zhong, Suyu (55587322700); Cui, Zaixu (55588486800); Gong, Gaolang (10241805200); Dong, Qi (25623088100); Nan, Yun (13103429100)",57189471856; 57189461634; 55587322700; 55588486800; 10241805200; 25623088100; 13103429100,Abnormal topological organization of the white matter network in Mandarin speakers with congenital Amusia,2016,Scientific Reports,6,,26505,,,,12,10.1038/srep26505,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971280732&doi=10.1038%2fsrep26505&partnerID=40&md5=62b683b3eff2ec1f36af337739d1f371,"Congenital amusia is a neurogenetic disorder that mainly affects the processing of musical pitch. Brain imaging evidence indicates that it is associated with abnormal structural and functional connections in the fronto-temporal region. However, a holistic understanding of the anatomical topology underlying amusia is still lacking. Here, we used probabilistic diffusion tensor imaging tractography and graph theory to examine whole brain white matter structural connectivity in 31 Mandarin-speaking amusics and 24 age- and IQ-matched controls. Amusics showed significantly reduced global connectivity, as indicated by the abnormally decreased clustering coefficient (C p) and increased normalized shortest path length (λ) compared to the controls. Moreover, amusics exhibited enhanced nodal strength in the right inferior parietal lobule relative to controls. The co-existence of the lexical tone deficits was associated with even more deteriorated global network efficiency in amusics, as suggested by the significant correlation between the increments in normalized shortest path length (λ) and the insensitivity in lexical tone perception. Our study is the first to reveal reduced global connectivity efficiency in amusics as well as an increase in the global connectivity cost due to the co-existed lexical tone deficits. Taken together these results provide a holistic perspective on the anatomical substrates underlying congenital amusia.",27211239,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84971280732
Cano S.; Collazos C.; Fardoun H.M.; Alghazzawi D.M.; Albarakati A.,"Cano, Sandra (56670957000); Collazos, César (8568805300); Fardoun, Habib M. (26435262800); Alghazzawi, Daniyal M. (42861060100); Albarakati, Abdullah (57465144700)",56670957000; 8568805300; 26435262800; 42861060100; 57465144700,Model based on learning needs of children with auditory impairment,2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),9742,,,324,334,10,9,10.1007/978-3-319-39910-2_30,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978878009&doi=10.1007%2f978-3-319-39910-2_30&partnerID=40&md5=b3829ff994af52225bf1a64b12283b9c,"This paper presents a model based on the needs of children with an auditory impairment, in which the dual research lines of Human Computer Interaction and Artificial Intelligence are employed in the design of intelligent interactive systems able to meet the requirements of the user. In following a philosophy of user-centered design, different characteristics of children with hearing disabilities are identified, along with AI techniques that could be applied in the model. The main issues involved in designing a user profile and the techniques used in order to create the process of adapting the system to the user are also discussed. © Springer International Publishing Switzerland 2016.",,Conference paper,Final,,Scopus,2-s2.0-84978878009
Sanchez Lopez R.; Bianchi F.; Fereczkowski M.; Santurette S.; Dau T.,"Sanchez Lopez, Raul (57204522385); Bianchi, Federica (26767554600); Fereczkowski, Michal (55354474800); Santurette, Sébastien (15751771600); Dau, Torsten (56368948300)",57204522385; 26767554600; 55354474800; 15751771600; 56368948300,Data-Driven Approach for Auditory Profiling and Characterization of Individual Hearing Loss,2018,Trends in Hearing,22,,,,,,27,10.1177/2331216518807400,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055915910&doi=10.1177%2f2331216518807400&partnerID=40&md5=38c3678a5690aa54e844c63c14129e91,"Pure-tone audiometry still represents the main measure to characterize individual hearing loss and the basis for hearing-aid fitting. However, the perceptual consequences of hearing loss are typically associated not only with a loss of sensitivity but also with a loss of clarity that is not captured by the audiogram. A detailed characterization of a hearing loss may be complex and needs to be simplified to efficiently explore the specific compensation needs of the individual listener. Here, it is hypothesized that any listener's hearing profile can be characterized along two dimensions of distortion: Type I and Type II. While Type I can be linked to factors affecting audibility, Type II reflects non-audibility-related distortions. To test this hypothesis, the individual performance data from two previous studies were reanalyzed using an unsupervised-learning technique to identify extreme patterns in the data, thus forming the basis for different auditory profiles. Next, a decision tree was determined to classify the listeners into one of the profiles. The analysis provides evidence for the existence of four profiles in the data. The most significant predictors for profile identification were related to binaural processing, auditory nonlinearity, and speech-in-noise perception. This approach could be valuable for analyzing other data sets to select the most relevant tests for auditory profiling and propose more efficient hearing-deficit compensation strategies. © The Author(s) 2018.",30384803,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85055915910
Warlaumont A.S.; Finnegan M.K.,"Warlaumont, Anne S. (23096778100); Finnegan, Megan K. (57201436791)",23096778100; 57201436791,Learning to produce syllabic speech sounds via reward-modulated neural plasticity,2016,PLoS ONE,11,1,e0145096,,,,28,10.1371/journal.pone.0145096,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994213168&doi=10.1371%2fjournal.pone.0145096&partnerID=40&md5=1f78be03850d62f1ee69fd55d00104d3,"At around 7 months of age, human infants begin to reliably produce well-formed syllables containing both consonants and vowels, a behavior called canonical babbling. Over subsequent months, the frequency of canonical babbling continues to increase. How the infant's nervous system supports the acquisition of this ability is unknown. Here we present a computational model that combines a spiking neural network, reinforcement-modulated spike-timing-dependent plasticity, and a human-like vocal tract to simulate the acquisition of canonical babbling. Like human infants, the model's frequency of canonical babbling gradually increases. The model is rewarded when it produces a sound that is more auditorily salient than sounds it has previously produced. This is consistent with data from human infants indicating that contingent adult responses shape infant behavior and with data from deaf and tracheostomized infants indicating that hearing, including hearing one's own vocalizations, is critical for canonical babbling development. Reward receipt increases the level of dopamine in the neural network. The neural network contains a reservoir with recurrent connections and two motor neuron groups, one agonist and one antagonist, which control the masseter and orbicularis oris muscles, promoting or inhibiting mouth closure. The model learns to increase the number of salient, syllabic sounds it produces by adjusting the base level of muscle activation and increasing their range of activity. Our results support the possibility that through dopamine-modulated spike-timing-dependent plasticity, the motor cortex learns to harness its natural oscillations in activity in order to produce syllabic sounds. It thus suggests that learning to produce rhythmic mouth movements for speech production may be supported by general cortical learning mechanisms. The model makes several testable predictions and has implications for our understanding not only of how syllabic vocalizations develop in infancy but also for our understanding of how they may have evolved. Copyright: © 2016 Warlaumont, Finnegan. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",26808148,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84994213168
Schädler M.R.; Warzybok A.; Kollmeier B.,"Schädler, Marc R. (55312455700); Warzybok, Anna (36081535600); Kollmeier, Birger (7006746726)",55312455700; 36081535600; 7006746726,Objective Prediction of Hearing Aid Benefit Across Listener Groups Using Machine Learning: Speech Recognition Performance With Binaural Noise-Reduction Algorithms,2018,Trends in Hearing,22,,,,,,24,10.1177/2331216518768954,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054655928&doi=10.1177%2f2331216518768954&partnerID=40&md5=9ef79f8abf37c60390adbeb42920bc39,"The simulation framework for auditory discrimination experiments (FADE) was adopted and validated to predict the individual speech-in-noise recognition performance of listeners with normal and impaired hearing with and without a given hearing-aid algorithm. FADE uses a simple automatic speech recognizer (ASR) to estimate the lowest achievable speech reception thresholds (SRTs) from simulated speech recognition experiments in an objective way, independent from any empirical reference data. Empirical data from the literature were used to evaluate the model in terms of predicted SRTs and benefits in SRT with the German matrix sentence recognition test when using eight single- and multichannel binaural noise-reduction algorithms. To allow individual predictions of SRTs in binaural conditions, the model was extended with a simple better ear approach and individualized by taking audiograms into account. In a realistic binaural cafeteria condition, FADE explained about 90% of the variance of the empirical SRTs for a group of normal-hearing listeners and predicted the corresponding benefits with a root-mean-square prediction error of 0.6 dB. This highlights the potential of the approach for the objective assessment of benefits in SRT without prior knowledge about the empirical data. The predictions for the group of listeners with impaired hearing explained 75% of the empirical variance, while the individual predictions explained less than 25%. Possibly, additional individual factors should be considered for more accurate predictions with impaired hearing. A competing talker condition clearly showed one limitation of current ASR technology, as the empirical performance with SRTs lower than −20 dB could not be predicted. © The Author(s) 2018.",29692200,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85054655928
Guan Q.; Balciuniene J.; Cao K.; Fan Z.; Biswas S.; Wilkens A.; Gallo D.J.; Bedoukian E.; Tarpinian J.; Jayaraman P.; Sarmady M.; Dulik M.; Santani A.; Spinner N.; Abou Tayoun A.N.; Krantz I.D.; Conlin L.K.; Luo M.,"Guan, Qiaoning (57194453173); Balciuniene, Jorune (6603229120); Cao, Kajia (56291780400); Fan, Zhiqian (57205191913); Biswas, Sawona (55855602200); Wilkens, Alisha (55485952200); Gallo, Daniel J (57205189011); Bedoukian, Emma (57188982520); Tarpinian, Jennifer (57193111509); Jayaraman, Pushkala (55697896200); Sarmady, Mahdi (43261767400); Dulik, Matthew (24437462400); Santani, Avni (6507529708); Spinner, Nancy (7004714485); Abou Tayoun, Ahmad N (35298507700); Krantz, Ian D (7004409233); Conlin, Laura K (6507716966); Luo, Minjie (56729756600)",57194453173; 6603229120; 56291780400; 57205191913; 55855602200; 55485952200; 57205189011; 57188982520; 57193111509; 55697896200; 43261767400; 24437462400; 6507529708; 7004714485; 35298507700; 7004409233; 6507716966; 56729756600,AUDIOME: a tiered exome sequencing–based comprehensive gene panel for the diagnosis of heterogeneous nonsyndromic sensorineural hearing loss,2018,Genetics in Medicine,20,12,,1600,1608,8,24,10.1038/gim.2018.48,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052461338&doi=10.1038%2fgim.2018.48&partnerID=40&md5=bc854eb9c68c892a8e1c604ab98f7b0f,"Purpose: Hereditary hearing loss is highly heterogeneous. To keep up with rapidly emerging disease-causing genes, we developed the AUDIOME test for nonsyndromic hearing loss (NSHL) using an exome sequencing (ES) platform and targeted analysis for the curated genes. Methods: A tiered strategy was implemented for this test. Tier 1 includes combined Sanger and targeted deletion analyses of the two most common NSHL genes and two mitochondrial genes. Nondiagnostic tier 1 cases are subjected to ES and array followed by targeted analysis of the remaining AUDIOME genes. Results: ES resulted in good coverage of the selected genes with 98.24% of targeted bases at >15 ×. A fill-in strategy was developed for the poorly covered regions, which generally fell within GC-rich or highly homologous regions. Prospective testing of 33 patients with NSHL revealed a diagnosis in 11 (33%) and a possible diagnosis in 8 cases (24.2%). Among those, 10 individuals had variants in tier 1 genes. The ES data in the remaining nondiagnostic cases are readily available for further analysis. Conclusion: The tiered and ES-based test provides an efficient and cost-effective diagnostic strategy for NSHL, with the potential to reflex to full exome to identify causal changes outside of the AUDIOME test. © 2018, American College of Medical Genetics and Genomics.",29595809,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85052461338
Mulwafu W.; Kuper H.; Viste A.; Goplen F.K.,"Mulwafu, Wakisa (16316845600); Kuper, Hannah (7004023998); Viste, Asgaut (7005164464); Goplen, Frederik K (6507230869)",16316845600; 7004023998; 7005164464; 6507230869,Feasibility and acceptability of training community health workers in ear and hearing care in Malawi: A cluster randomised controlled trial,2017,BMJ Open,7,10,e016457,,,,22,10.1136/bmjopen-2017-016457,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031330069&doi=10.1136%2fbmjopen-2017-016457&partnerID=40&md5=eb395b3c0c2fd4233f7a38d1865e34f8,"Objective To assess the feasibility and acceptability of training community health workers (CHWs) in ear and hearing care, and their ability to identify patients with ear and hearing disorders. Design Cluster randomised controlled trial (RCT). Setting Health centres in Thyolo district, Malawi. Participants Ten health centres participated, 5 intervention (29 CHWs) and 5 control (28 CHWs). Intervention Intervention CHWs received 3 days of training in primary ear and hearing care, while among control CHWs, training was delayed for 6 months. Both groups were given a pretest that assessed knowledge about ear and hearing care, only the intervention group was given the posttest on the third day of training. The intervention group was given 1 month to identify patients with ear and hearing disorders in their communities, and these people were screened for hearing disorders by ear, nose and throat clinical specialists. Outcome measures Primary outcome measure was improvement in knowledge of ear and hearing care among CHWs after the training. Secondary outcome measures were number of patients with ear or hearing disorders identified by CHWs and number recorded at health centres during routine activities, and the perceived feasibility and acceptability of the intervention. Results The average overall correct answers increased from 55% to 68% (95% CI 65 to 71) in the intervention group (p<0.001). A total of 1739 patients with potential ear and hearing disorders were identified by CHWs and 860 patients attended the screening camps, of whom 400 had hearing loss (73 patients determined through bilateral fail on otoacoustic emissions, 327 patients through audiometry). Where cause could be determined, the most common cause of ear and hearing disorders was chronic suppurative otitis media followed by impacted wax. The intervention was perceived as feasible and acceptable to implement. Conclusions Training was effective in improving the knowledge of CHW in ear and hearing care in Malawi and allowing them to identify patients with ear and hearing disorders. This intervention could be scaled up to other CHWs in low-income and middle-income countries. Trial registration number Pan African Clinical Trial Registry (201705002285194); Results. © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved.",29025832,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85031330069
Kocian A.; Ienco C.; Chessa S.; Grolman W.,"Kocian, Alexander (6507638256); Ienco, Carmelo (57194681495); Chessa, Stefano (6701590804); Grolman, Wilko (6602611503)",6507638256; 57194681495; 6701590804; 6602611503,Intelligent smartphone audiometry,2017,Advances in Intelligent Systems and Computing,615,,,112,120,8,0,10.1007/978-3-319-61118-1_15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021684392&doi=10.1007%2f978-3-319-61118-1_15&partnerID=40&md5=cc3319da33a72b473079c1c6792ebceb,"The continuously aging population in the majority of industrialized nations challenges the healthcare providers to maintain quality of healthcare services at status quo. To make health care sustainable, the paradigm Ambient Intelligence can be used to exploit information and telecommunication technology for the development of autonomous healthcare services. Following this approach, we design and implement a virtual audiologist dubbed ViA, performing air-conduction and bone-conduction hearing tests based on a standard in contrast to existing solutions. The software platform is Android. In this paper, we present the system architecture of ViA with focus on the Android platform and discuss calibration issues. First test results in office environment indicate that a large range of hearing thresholds can be reproduced on different smartphones within a band of 9 dB. ViA has the potential to identify individuals with correctable hearing loss without putting extra load on the healthcare providers. © Springer International Publishing AG 2017.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85021684392
Petrova I.P.; Balashova E.A.; Goikhburg M.V.; Mashchenko A.I.; Markova T.G.; Bakhshinyan V.V.; Tavartkiladze G.A.,"Petrova, I.P. (56332715100); Balashova, E.A. (57194742097); Goikhburg, M.V. (56332758300); Mashchenko, A.I. (37004660200); Markova, T.G. (7007100117); Bakhshinyan, V.V. (56600712600); Tavartkiladze, G.A. (6701603360)",56332715100; 57194742097; 56332758300; 37004660200; 7007100117; 56600712600; 6701603360,Application of the mathematical model for prognosis in the rehabilitation of children after cochlear implantation; [Ispol'zovanie matematicheskoi modeli dlya opredeleniya prognoza reabilitatsii u detei posle kokhlearnoi implantatsii],2016,Vestnik otorinolaringologii,81,6,,47,50,3,1,10.17116/otorino201681647-50,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021851753&doi=10.17116%2fotorino201681647-50&partnerID=40&md5=b832735bdcc4431331a1b576c104c934,"Despite the variety of etiological factors, cochlear implantation (CI) remains the only effective method for the rehabilitation of the patients presenting with total deafness. The aim of this study was the enhancement of the efficiency of selection of the candidates for CI, the improvement of the quality of rehabilitation of the patients with cochlear implants, and the determination of the prognostic criteria for clinical trials.; PATIENTS AND METHODS: (CI). The decision-making support system (DMSS) based on the artificial neural networks (ANNs) has been created to enhance the efficiency of rehabilitation of the patients with cochlear implants and increase the effectiveness of the selection of candidates for cochlear implantation. The results of the children's rehabilitation after CI have been analyzed by using a mathematical model of artificial neural networks (Kohonen layer). The basis for the assessment of ANNs was formed by the results of the observations of audioverbal perception in 110 patients aged from 6 months to 17 years. The initial data were the average values obtained with the use of the Russian-language version of the Nottingham children's implant profile's test T1 - T3. The testing was performed before CI and 3, 6, 12, 18, and 24 months after it.; MAIN RESULTS: The work yielded the four-cluster data structure. It made it possible to estimate the effectiveness of the clinical trials in selected classes depending on the etiology of the disease, the age of the patients, and their experience with the application of hearing aids. The reliable estimation of the dynamics of auditory perception at the stage of rehabilitation and prognosis of the outcomes of CI made it possible to take additional preventive and therapeutic measures in the combination with complementary psychological and educational procedures.; Цель исследования - повышение эффективности отбора кандидатов на кохлеарную имплантацию (КИ), улучшение качества реабилитации пациентов с имплантами, определение прогностических критериев КИ. Проведен анализ результатов реабилитации детей после КИ с использованием математической модели ИНС (слоя Кохонена). В основу построения ИНС легли результаты оценки развития слухоречевого восприятия у 110 пациентов в возрасте от 6 мес до 17 лет. Тестирование пациентов проводилось до КИ и через 3, 6, 12, 18 и 24 мес после проведенной КИ с помощью русскоязычной версии батареи тестов EARS. Проведенная работа позволила получить четырехкластерную структуру данных, оценить эффективность КИ в выделенных классах в зависимости от этиологии заболевания, возраста, наличия опыта слухопротезирования. На этапе реабилитации произведены достоверная оценка динамики развития слухового восприятия и прогноз результатов КИ, что дало возможность своевременно применить дополнительные методы лечения в сложных случаях.",28091476,Article,Final,,Scopus,2-s2.0-85021851753
Kronenberger W.G.; Henning S.C.; Ditmars A.M.; Roman A.S.; Pisoni D.B.,"Kronenberger, William G. (6701385793); Henning, Shirley C. (25225911300); Ditmars, Allison M. (56623091500); Roman, Adrienne S. (41562087300); Pisoni, David B. (7005913467)",6701385793; 25225911300; 56623091500; 41562087300; 7005913467,Verbal learning and memory in prelingually deaf children with cochlear implants,2018,International Journal of Audiology,57,10,,746,754,8,4,10.1080/14992027.2018.1481538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048889657&doi=10.1080%2f14992027.2018.1481538&partnerID=40&md5=00f835ea08fb359576557e143c2ec6f9,"Objective: Deaf children with cochlear implants (CIs) show poorer verbal working memory compared to normal-hearing (NH) peers, but little is known about their verbal learning and memory (VLM) processes involving multi-trial free recall. Design: Children with CIs were compared to NH peers using the California Verbal Learning Test for Children (CVLT-C). Study sample: Participants were 21 deaf (before age 6 months) children (6–16 years old) implanted prior to age 3 years, and 21 age-IQ matched NH peers. Results: Results revealed no differences between groups in number of words recalled. However, CI users showed a pattern of increasing use of serial clustering strategies across learning trials, whereas NH peers decreased their use of serial clustering strategies. In the CI sample (but not in the NH sample), verbal working memory test scores were related to resistance to the build-up of proactive interference, and sentence recognition was associated with performance on the first exposure to the word list and to the use of recency recall strategies. Conclusions: Children with CIs showed robust evidence of VLM comparable to NH peers. However, their VLM processing (especially recency and proactive interference) was related to speech perception outcomes and verbal WM in different ways from NH peers. © 2018, © 2018 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",29933710,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85048889657
Lu X.; Wang Q.; Gu H.; Zhang X.; Qi Y.; Liu Y.,"Lu, X. (57205176637); Wang, Q. (57191968329); Gu, H. (57193011027); Zhang, X. (57203326581); Qi, Y. (7401900655); Liu, Y. (8872222000)",57205176637; 57191968329; 57193011027; 57203326581; 7401900655; 8872222000,Whole exome sequencing identified a second pathogenic variant in HOMER2 for autosomal dominant non-syndromic deafness,2018,Clinical Genetics,94,5,,419,428,9,9,10.1111/cge.13422,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054431014&doi=10.1111%2fcge.13422&partnerID=40&md5=0df775865278bda2bcc282540936e8ef,"Hearing loss is one of the most common sensory disorders worldwide, and about half of all occurrences are attributable to genetic factors. Here, we have identified a novel pathogenic variant in HOMER2 in a Chinese family with autosomal dominant, non-syndromic hearing loss. This is the second family reported globally with hearing loss caused by a variant in HOMER2. The pathogenic variant c.840_841insC in HOMER2 (NM_199330), segregating with the hearing-loss phenotype in the family, leads to a premature stop codon producing a truncated protein. The coiled-coil domain in the C-terminal of HOMER2 protein is essential for protein multimerization and HOMER2-CDC42 interaction. We compared the phenotypes in the two families and found that hearing impairment in this Chinese family was more severe. Furthermore, we found that the ability of this insertion mutant type HOMER2 (HOMER2MU) to multimerize decreased more significantly than wild-type HOMER2 (HOMER2WT) and the reported c.554G>C (NM_004839) mutant HOMER2. HOMER2MU protein tended to be distributed in a diffuse manner, whereas HOMER2WT and the reported mutant HOMER2 tended to cluster together. Our research provides a validating second family for variants in HOMER2 causing non-syndromic sensorineural hearing loss. HOMER2 homo−/hetero-multimerization might be the first step in exerting its normal function. © 2018 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd",30047143,Article,Final,,Scopus,2-s2.0-85054431014
Xue L.; Le Bot G.; Van Petegem W.; van Wieringen A.,"Xue, Lina (57189308043); Le Bot, Gaëlle (57204503617); Van Petegem, Wim (6602438147); van Wieringen, Astrid (22942685800)",57189308043; 57204503617; 6602438147; 22942685800,Defining interdisciplinary competencies for audiological rehabilitation: findings from a modified Delphi study,2018,International Journal of Audiology,57,2,,81,90,9,5,10.1080/14992027.2017.1406156,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035758909&doi=10.1080%2f14992027.2017.1406156&partnerID=40&md5=8f927ddc75e86eaae9250731bc41cf74,"Objectives: The aim of this study is to derive a consensus on an interdisciplinary competency framework regarding a holistic approach for audiological rehabilitation (AR), which includes disciplines from medicine, engineering, social sciences and humanities. Design: We employed a modified Delphi method. In the first round survey, experts were asked to rate an initial list of 28 generic interdisciplinary competencies and to propose specific knowledge areas for AR. In the second round, experts were asked to reconsider their answers in light of the group answers of the first round. Study sample: An international panel of 27 experts from different disciplines in AR completed the first round. Twenty-two of them completed the second round. Results: We developed a competency framework consisting of 21 generic interdisciplinary competencies grouped in five domains and nine specific competencies (knowledge areas) in three clusters. Suggestions for the implementation of the generic competencies in interdisciplinary programmes were identified. Conclusions: This study reveals insights into the interdisciplinary competencies that are unique for AR. The framework will be useful for educators in developing interdisciplinary programmes as well as for professionals in considering their lifelong training needs in AR. © 2017 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",29192519,Article,Final,,Scopus,2-s2.0-85035758909
Liu H.; Luo H.; Yang T.; Wu H.; Chen D.,"Liu, Han (36118803200); Luo, Huajie (37004518000); Yang, Tao (56431700100); Wu, Hao (55762405900); Chen, Dan (56316051300)",36118803200; 37004518000; 56431700100; 55762405900; 56316051300,Association of leukocyte telomere length and the risk of age-related hearing impairment in Chinese Hans,2017,Scientific Reports,7,1,10106,,,,11,10.1038/s41598-017-10680-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028652217&doi=10.1038%2fs41598-017-10680-9&partnerID=40&md5=4721005f17e626030e12d62ec0624488,"Age-related hearing loss (ARHI) is the most common sensory disorder in the elderly. Although telomere attrition has been shown as a determinant in the pathobiology of various age-related diseases, it remains unknown whether telomere length is associated with ARHI. We hypothesized that decreased leukocyte telomere length (LTL) increased the risk of ARHI. Thus, we measured LTL of 666 ARHI and 43 controls by an established quantitative PCR technique. Four audiogram shape subtypes of ARHI, including ""flat shape (FL)"", ""2-4 kHz abrupt loss (AL) shape"", ""8 kHz dip (8D) shape"" and ""sloping shape (SL)"" could be identified among the cases using K-means cluster analysis. Longer LTL was associated with the reduced incidence of ARHI (adjusted OR = 0.550, 95% CI: 0.420-0.721, P < 0.0001 for all the ARHI; 0.498, 0.318-0.780, P = 0.0023 for FL subgroup; 0.428, 0.292-0.628, P < 0.0001 for AL subgroup; 0.552, 0.399-0.764, P = 0.0003 for mSL subgroup). Subjects in the highest tertile of LTL were at less risk for ARHI than those in the lowest and middle tertiles (OR for ARHI: 0.327, 95% CI 0.170-0.629, P = 0.0008). There was a descending trend of LTL as the degree of pure tone threshold average (PTA) aggravated. These results suggest that telomere attrition may be involved in the progression of ARHI. © 2017 The Author(s).",28860610,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85028652217
Alfandari D.; Vriend C.; Heslenfeld D.J.; Versfeld N.J.; Kramer S.E.; Zekveld A.A.,"Alfandari, Defne (57204146040); Vriend, Chris (55568315600); Heslenfeld, Dirk J. (6602304972); Versfeld, Niek J. (6602103494); Kramer, Sophia E. (7401609154); Zekveld, Adriana A. (8641362500)",57204146040; 55568315600; 6602304972; 6602103494; 7401609154; 8641362500,Brain Volume Differences Associated With Hearing Impairment in Adults,2018,Trends in Hearing,22,,,,,,23,10.1177/2331216518763689,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054612228&doi=10.1177%2f2331216518763689&partnerID=40&md5=4f2751f7c55453d3901db1a6e658966a,"Speech comprehension depends on the successful operation of a network of brain regions. Processing of degraded speech is associated with different patterns of brain activity in comparison with that of high-quality speech. In this exploratory study, we studied whether processing degraded auditory input in daily life because of hearing impairment is associated with differences in brain volume. We compared T1-weighted structural magnetic resonance images of 17 hearing-impaired (HI) adults with those of 17 normal-hearing (NH) controls using a voxel-based morphometry analysis. HI adults were individually matched with NH adults based on age and educational level. Gray and white matter brain volumes were compared between the groups by region-of-interest analyses in structures associated with speech processing, and by whole-brain analyses. The results suggest increased gray matter volume in the right angular gyrus and decreased white matter volume in the left fusiform gyrus in HI listeners as compared with NH ones. In the HI group, there was a significant correlation between hearing acuity and cluster volume of the gray matter cluster in the right angular gyrus. This correlation supports the link between partial hearing loss and altered brain volume. The alterations in volume may reflect the operation of compensatory mechanisms that are related to decoding meaning from degraded auditory input. © The Author(s) 2018.",29557274,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85054612228
Langguth B.; Landgrebe M.; Schlee W.; Schecklmann M.; Vielsmeier V.; Steffens T.; Staudinger S.; Frick H.; Frick U.,"Langguth, Berthold (6602352583); Landgrebe, Michael (23004653800); Schlee, Winfried (22836015100); Schecklmann, Martin (22935795700); Vielsmeier, Veronika (23390721300); Steffens, Thomas (7004624896); Staudinger, Susanne (36345027100); Frick, Hannah (55279650900); Frick, Ulrich (7006253859)",6602352583; 23004653800; 22836015100; 22935795700; 23390721300; 7004624896; 36345027100; 55279650900; 7006253859,Different patterns of hearing loss among tinnitus patients: A latent class analysis of a large sample,2017,Frontiers in Neurology,8,FEB,46,,,,39,10.3389/fneur.2017.00046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014257025&doi=10.3389%2ffneur.2017.00046&partnerID=40&md5=0230c8f6476594a194fa534dde0a430b,"Background: The heterogeneity of tinnitus is a major challenge for tinnitus research. Even if a complex interaction of many factors is involved in the etiology of tinnitus, hearing loss (HL) has been identified as the most relevant etiologic factor. Here, we used a data-driven approach to identify patterns of hearing function in a large sample of tinnitus patients presenting in a tinnitus clinic. Methods: Data from 2,838 patients presenting at the Tinnitus Center of the University Regensburg between 2007 and 2014 have been analyzed. Standard audiometric data were frequency-wise categorized in four categories [a: normal hearing (0-20 dB HL); b: moderate HL (25-50 dB HL; representing outer hair cell loss); c: severe HL (> 50 dB HL; representing outer and inner hair cell loss); d: no data available] and entered in a latent class analysis, a statistical method to find subtypes of cases in multivariate categorical data. To validate the clinical relevance of the identified latent classes, they were compared with respect to clinical and demographic characteristics of their members. Results: The classification algorithm identified eight distinct latent classes with an excellent separation. Patient classes differed with respect to demographic (e.g., age, gender) and clinical characteristics (e.g., tinnitus location, tinnitus severity, gradual, or abrupt onset, etc.). Discussion: Our results demonstrate that data-driven categorization of hearing function seems to be a promising approach for profiling tinnitus patients, as it revealed distinct subtypes that reflect prototypic forms of HL and that differ in several relevant clinical characteristics. © 2017 Langguth, Landgrebe, Schlee, Schecklmann, Vielsmeier, Steffens, Staudinger, Frick and Frick.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85014257025
Luo H.; Wu H.; Shen H.; Chen H.; Yang T.; Huang Z.; Jin X.; Pang X.; Li L.; Hu X.; Jiang X.; Fan Z.; Li J.,"Luo, Huajie (37004518000); Wu, Hao (55762405900); Shen, Hailian (57704525400); Chen, Haifeng (57192534806); Yang, Tao (56431700100); Huang, Zhiwu (9336671200); Jin, Xiaojie (7402589120); Pang, Xiuhong (55879489200); Li, Lei (56867926700); Hu, Xianting (58353534600); Jiang, Xuemei (55880158900); Fan, Zhuping (7402099487); Li, Jiping (9240181500)",37004518000; 55762405900; 57704525400; 57192534806; 56431700100; 9336671200; 7402589120; 55879489200; 56867926700; 58353534600; 55880158900; 7402099487; 9240181500,The European GWAS-identified risk SNP rs457717 within IQGAP2 is not associated with age-related hearing impairment in Han male Chinese population,2016,European Archives of Oto-Rhino-Laryngology,273,7,,1677,1687,10,3,10.1007/s00405-015-3711-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937119357&doi=10.1007%2fs00405-015-3711-9&partnerID=40&md5=1fd193a9d3dca2d06489efababb26e34,"This study aimed to test the association between the European GWAS-identified risk IQGAP2 SNP rs457717 (A>G) and age-related hearing impairment (ARHI) in a Han male Chinese (HMC) population. A total of 2420 HMC subjects were divided into two groups [group 70+: >70 years (n = 1306), and group 70−: ≤70 years (n = 1114)]. The participants were categorised into case and control groups according to Z high scores for group 70− and the severity of hearing loss and different audiogram shapes identified by K-means cluster analysis for group 70+. The IQGAP2 tagSNP rs457717 was genotyped in accordance with the different ARHI phenotypes. The genotype distributions of IQGAP2 (AA/AG/GG) were not significantly different between the case and control groups (P = 0.613 for group 70−; P = 0.602 for group 70+). Compared with genotype AA, the ORs of genotypes AG and GG for ARHI were not significantly different following adjustment for other environmental risk factors. We demonstrated that the IQGAP2 TagSNP rs457717 (A/G) was not associated with ARHI in HMC individuals. © 2015, Springer-Verlag Berlin Heidelberg.",26187738,Article,Final,,Scopus,2-s2.0-84937119357
Zaar J.; Dau T.,"Zaar, Johannes (56816877000); Dau, Torsten (56368948300)",56816877000; 56368948300,Predicting consonant recognition and confusions in normal-hearing listeners,2017,Journal of the Acoustical Society of America,141,2,,1051,1064,13,6,10.1121/1.4976054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013948825&doi=10.1121%2f1.4976054&partnerID=40&md5=d46f5e3c1696740cec38a6de73f97919,"The perception of consonants in background noise has been investigated in various studies and was shown to critically depend on fine details in the stimuli. In this study, a microscopic speech perception model is proposed that represents an extension of the auditory signal processing model by Dau, Kollmeier, and Kohlrausch [(1997). J. Acoust. Soc. Am. 102, 2892-2905]. The model was evaluated based on the extensive consonant perception data set provided by Zaar and Dau [(2015). J. Acoust. Soc. Am. 138, 1253-1267], which was obtained with normal-hearing listeners using 15 consonant-vowel combinations mixed with white noise. Accurate predictions of the consonant recognition scores were obtained across a large range of signal-to-noise ratios. Furthermore, the model yielded convincing predictions of the consonant confusion scores, such that the predicted errors were clustered in perceptually plausible confusion groups. The large predictive power of the proposed model suggests that adaptive processes in the auditory preprocessing in combination with a cross-correlation based template-matching back end can account for some of the processes underlying consonant perception in normal-hearing listeners. The proposed model may provide a valuable framework, e.g., for investigating the effects of hearing impairment and hearing-aid signal processing on phoneme recognition. © 2017 Acoustical Society of America.",28253684,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85013948825
Hay-McCutcheon M.J.; Hyams A.; Yang X.; Parton J.; Panasiuk B.; Ondocsin S.; James M.M.; Scogin F.,"Hay-McCutcheon, Marcia J. (6506903505); Hyams, Adriana (35315780700); Yang, Xin (57193392659); Parton, Jason (40462254800); Panasiuk, Brianna (57195392519); Ondocsin, Sarah (57195399354); James, Mary Margaret (57195394390); Scogin, Forrest (7004678901)",6506903505; 35315780700; 57193392659; 40462254800; 57195392519; 57195399354; 57195394390; 7004678901,"An exploration of the associations among hearing loss, physical health, and visual memory in adults from west central alabama",2017,"Journal of Speech, Language, and Hearing Research",60,8,,2346,2359,13,7,10.1044/2017_JSLHR-H-16-0369,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027694150&doi=10.1044%2f2017_JSLHR-H-16-0369&partnerID=40&md5=e5a336b2bdd65e48599e641fe715765f,"Purpose: The purpose of this preliminary study was to physical health issues who lived in an urban city. Poorer explore the associations among hearing loss, physical hearing sensitivity resulted in poorer outcomes on the health, and visual memory in adults living in rural areas, Emotional and Social subscales of the Hearing Handicap urban clusters, and an urban city in west Central Alabama. Inventory for Adults. And last, visual memory, a working-memory Method: Two hundred ninety-seven adults (182 women, task, was not associated with hearing loss but 115 men) from rural areas, urban clusters, and an urban city was associated with educational level. of west Central Alabama completed a hearing assessment, Conclusions: The outcomes suggest that hearing loss is a physical health questionnaire, a hearing handicap associated with poor physical and emotional health but not measure, and a visual memory test. with visual-memory skills. A greater number of adults living Results: A greater number of adults with hearing loss lived in rural areas experienced hearing loss compared with in rural areas and urban clusters than in an urban area. In adults living in an urban city, and consequently, further addition, poorer physical health was significantly associated research will be necessary to confirm this relationship and with hearing loss. A greater number of individuals with poor to explore the reasons behind it. Also, further exploration physical health who lived in rural towns and urban clusters of the relationship between cognition and hearing loss in had hearing loss compared with the adults with other adults living in rural and urban areas will be needed. © 2017 American Speech-Language-Hearing Association.",28793136,Article,Final,,Scopus,2-s2.0-85027694150
Deshpande A.K.; Tan L.; Lu L.J.; Altaye M.; Holland S.K.,"Deshpande, Aniruddha K. (56591639700); Tan, Lirong (55878582500); Lu, Long J. (54403388300); Altaye, Mekibib (6603241667); Holland, Scott K. (8144410100)",56591639700; 55878582500; 54403388300; 6603241667; 8144410100,FMRI as a Preimplant Objective Tool to Predict Postimplant Oral Language Outcomes in Children with Cochlear Implants,2016,Ear and Hearing,37,4,,e263,e272,9,15,10.1097/AUD.0000000000000259,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951299166&doi=10.1097%2fAUD.0000000000000259&partnerID=40&md5=1b6ea29da1b285fdab19855e99928980,"Objectives: Despite the positive effects of cochlear implantation, postimplant variability in speech perception and oral language outcomes is still difficult to predict. The aim of this study was to identify neuroimaging biomarkers of postimplant speech perception and oral language performance in children with hearing loss who receive a cochlear implant. The authors hypothesized positive correlations between blood oxygen level-dependent functional magnetic resonance imaging (fMRI) activation in brain regions related to auditory language processing and attention and scores on the Clinical Evaluation of Language Fundamentals-Preschool, Second Edition (CELF-P2) and the Early Speech Perception Test for Profoundly Hearing-Impaired Children (ESP), in children with congenital hearing loss. Design: Eleven children with congenital hearing loss were recruited for the present study based on referral for clinical MRI and other inclusion criteria. All participants were <24 months at fMRI scanning and <36 months at first implantation. A silent background fMRI acquisition method was performed to acquire fMRI during auditory stimulation. A voxel-based analysis technique was utilized to generate z maps showing significant contrast in brain activation between auditory stimulation conditions (spoken narratives and narrow band noise). CELF-P2 and ESP were administered 2 years after implantation. Because most participants reached a ceiling on ESP, a voxel-wise regression analysis was performed between preimplant fMRI activation and postimplant CELF-P2 scores alone. Age at implantation and preimplant hearing thresholds were controlled in this regression analysis. Results: Four brain regions were found to be significantly correlated with CELF-P2 scores. These clusters of positive correlation encompassed the temporo-parieto-occipital junction, areas in the prefrontal cortex and the cingulate gyrus. For the story versus silence contrast, CELF-P2 core language score demonstrated significant positive correlation with activation in the right angular gyrus (r = 0.95), left medial frontal gyrus (r = 0.94), and left cingulate gyrus (r = 0.96). For the narrow band noise versus silence contrast, the CELF-P2 core language score exhibited significant positive correlation with activation in the left angular gyrus (r = 0.89; for all clusters, corrected p < 0.05). Conclusions: Four brain regions related to language function and attention were identified that correlated with CELF-P2. Children with better oral language performance postimplant displayed greater activation in these regions preimplant. The results suggest that despite auditory deprivation, these regions are more receptive to gains in oral language development performance of children with hearing loss who receive early intervention via cochlear implantation. The present study suggests that oral language outcome following cochlear implant may be predicted by preimplant fMRI with auditory stimulation using natural speech. © Copyright 2016 Wolters Kluwer Health, Inc. All rights reserved.",26689275,Conference paper,Final,,Scopus,2-s2.0-84951299166
Wu Y.-H.; Stangl E.; Chipara O.; Hasan S.S.; Welhaven A.; Oleson J.,"Wu, Yu-Hsiang (18038757800); Stangl, Elizabeth (55552817500); Chipara, Octav (9334529600); Hasan, Syed Shabih (35220015800); Welhaven, Anne (56095551200); Oleson, Jacob (14040397100)",18038757800; 55552817500; 9334529600; 35220015800; 56095551200; 14040397100,Characteristics of real-world signal to noise ratios and speech listening situations of older adults with mild to moderate hearing loss,2018,Ear and Hearing,39,2,,293,304,11,106,10.1097/AUD.0000000000000486,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044299749&doi=10.1097%2fAUD.0000000000000486&partnerID=40&md5=3a7bb3004bc905276bfef5da867e1ea7,"Objectives: The first objective was to determine the relationship between speech level, noise level, and signal to noise ratio (SNR), as well as the distribution of SNR, in real-world situations wherein older adults with hearing loss are listening to speech. The second objective was to develop a set of prototype listening situations (PLSs) that describe the speech level, noise level, SNR, availability of visual cues, and locations of speech and noise sources of typical speech listening situations experienced by these individuals. Design: Twenty older adults with mild to moderate hearing loss carried digital recorders for 5 to 6 weeks to record sounds for 10 hours per day. They also repeatedly completed in situ surveys on smartphones several times per day to report the characteristics of their current environments, including the locations of the primary talker (if they were listening to speech) and noise source (if it was noisy) and the availability of visual cues. For surveys where speech listening was indicated, the corresponding audio recording was examined. Speech-plus-noise and noise-only segments were extracted, and the SNR was estimated using a power subtraction technique. SNRs and the associated survey data were subjected to cluster analysis to develop PLSs. Results: The speech level, noise level, and SNR of 894 listening situations were analyzed to address the first objective. Results suggested that as noise levels increased from 40 to 74 dBA, speech levels systematically increased from 60 to 74 dBA, and SNR decreased from 20 to 0 dB. Most SNRs (62.9%) of the collected recordings were between 2 and 14 dB. Very noisy situations that had SNRs below 0 dB comprised 7.5% of the listening situations. To address the second objective, recordings and survey data from 718 observations were analyzed. Cluster analysis suggested that the participants' daily listening situations could be grouped into 12 clusters (i.e., 12 PLSs). The most frequently occurring PLSs were characterized as having the talker in front of the listener with visual cues available, either in quiet or in diffuse noise. The mean speech level of the PLSs that described quiet situations was 62.8 dBA, and the mean SNR of the PLSs that represented noisy environments was 7.4 dB (speech = 67.9 dBA). A subset of observations (n = 280), which was obtained by excluding the data collected from quiet environments, was further used to develop PLSs that represent noisier situations. From this subset, two PLSs were identified. These two PLSs had lower SNRs (mean = 4.2 dB), but the most frequent situations still involved speech from in front of the listener in diffuse noise with visual cues available. Conclusions: The present study indicated that visual cues and diffuse noise were exceedingly common in real-world speech listening situations, while environments with negative SNRs were relatively rare. The characteristics of speech level, noise level, and SNR, together with the PLS information reported by the present study, can be useful for researchers aiming to design ecologically valid assessment procedures to estimate real-world speech communicative functions for older adults with hearing loss. Copyright © 2017 Wolters Kluwer Health, Inc. All rights reserved.",29466265,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85044299749
Keshavarzi M.; Goehring T.; Zakis J.; Turner R.E.; Moore B.C.J.,"Keshavarzi, Mahmoud (55657249300); Goehring, Tobias (57189595633); Zakis, Justin (15844607200); Turner, Richard E. (57214257840); Moore, Brian C. J. (57203291320)",55657249300; 57189595633; 15844607200; 57214257840; 57203291320,Use of a Deep Recurrent Neural Network to Reduce Wind Noise: Effects on Judged Speech Intelligibility and Sound Quality,2018,Trends in Hearing,22,,,,,,15,10.1177/2331216518770964,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054646886&doi=10.1177%2f2331216518770964&partnerID=40&md5=cadb25a68d3b22c215f4292f3d6ed940,"Despite great advances in hearing-aid technology, users still experience problems with noise in windy environments. The potential benefits of using a deep recurrent neural network (RNN) for reducing wind noise were assessed. The RNN was trained using recordings of the output of the two microphones of a behind-the-ear hearing aid in response to male and female speech at various azimuths in the presence of noise produced by wind from various azimuths with a velocity of 3 m/s, using the “clean” speech as a reference. A paired-comparison procedure was used to compare all possible combinations of three conditions for subjective intelligibility and for sound quality or comfort. The conditions were unprocessed noisy speech, noisy speech processed using the RNN, and noisy speech that was high-pass filtered (which also reduced wind noise). Eighteen native English-speaking participants were tested, nine with normal hearing and nine with mild-to-moderate hearing impairment. Frequency-dependent linear amplification was provided for the latter. Processing using the RNN was significantly preferred over no processing by both subject groups for both subjective intelligibility and sound quality, although the magnitude of the preferences was small. High-pass filtering (HPF) was not significantly preferred over no processing. Although RNN was significantly preferred over HPF only for sound quality for the hearing-impaired participants, for the results as a whole, there was a preference for RNN over HPF. Overall, the results suggest that reduction of wind noise using an RNN is possible and might have beneficial effects when used in hearing aids. © The Author(s) 2018.",29708061,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85054646886
Zhu Q.R.; Shao Y.X.; Cao C.J.; Wu X.; Xie W.Q.; Xu M.; Yang L.; Xu L.W.,"Zhu, Q.R. (57193841515); Shao, Y.X. (57193838599); Cao, C.J. (57193838895); Wu, X. (57193842365); Xie, W.Q. (57193840094); Xu, M. (57193840099); Yang, L. (58603844900); Xu, L.W. (56142265600)",57193841515; 57193838599; 57193838895; 57193842365; 57193840094; 57193840099; 58603844900; 56142265600,Influencing factors for the use of earplugs in workers exposed to noise in a city,2016,Zhonghua lao dong wei sheng zhi ye bing za zhi = Zhonghua laodong weisheng zhiyebing zazhi = Chinese journal of industrial hygiene and occupational diseases,34,4,,271,274,3,0,10.3760/cma.j.issn.1001-9391.2016.04.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017066831&doi=10.3760%2fcma.j.issn.1001-9391.2016.04.008&partnerID=40&md5=2d4a046b45a6b04328dea98467052feb,"OBJECTIVE: To investigate the current status of hearing loss and the use of earplugs in workers exposed to noise who have been provided earplugs in a city, as well as major influencing factors for the use of earplugs.; METHODS: Cluster random sampling was used to conduct a questionnaire survey in workers exposed to noise who had been provided earplugs in 15 enterprises with noise exposure in a city from June to December, 2014.; RESULTS: In the workers exposed to noise who had been provided earplugs, the rate of high-frequency anomaly in both ears was 57.8%, and the workers who kept wearing earplugs only accounted for 55.4%. The results of binary logistic regression analysis showed that the protective factors for the use of earplugs included workers' own feeling of hearing condition (OR=1.704), comfort of earplugs (OR= 1.892), enterprise's inspection of the use of earplugs (OR=1.461), workers' knowledge of the function and usage of earplugs (OR=1.581), workers' understanding of the necessity of earplugs (OR=4.482), workers' initiative to search for related data (OR=4.029), the use of earplugs by colleagues (OR=5.071), and reminders from family members or friends (OR=2.678) (all P<0.05).; CONCLUSION: The workers exposed to noise in this city have a high rate of abnormal hearing, and only half of the workers keep wearing earplugs during work. The use of earplugs is related to the factors including workers' own feeling of hearing condition, comfort of earplugs, workers' knowledge of protection, the enterprise' s management of hearing protection, and environmental support.",27514260,Article,Final,,Scopus,2-s2.0-85017066831
Moulin A.; Richard C.,"Moulin, Annie (57193911866); Richard, Celine (35094322300)",57193911866; 35094322300,"Validation of a French-Language Version of the Spatial Hearing Questionnaire, Cluster Analysis and Comparison with the Speech, Spatial, and Qualities of Hearing Scale",2016,Ear and Hearing,37,4,,412,423,11,10,10.1097/AUD.0000000000000269,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955566062&doi=10.1097%2fAUD.0000000000000269&partnerID=40&md5=fd4a1e1b2b33733e95c1b13e258d9ffe,"Objectives: To validate a French-language version of the spatial hearing questionnaire (SHQ), including investigating its internal structure using cluster analysis and exploring its construct validity on a large population of hearing-impaired (HI) and normal-hearing (NH) subjects, and to compare the SHQ with the speech, spatial, and qualities of hearing scale (SSQ) in the same population. Design: The SHQ was translated in accordance with the principles of the Universalist Model of cross-cultural adaptation of patient-reported outcome instruments. The SSQ and SHQ were then presented in a counterbalanced order, in a self-report mode, in a population of 230 HI subjects (mean age = 54 years and pure-tone audiometry [PTA] on the better ear = 28 dB HL) and 100 NH subjects (mean age = 21 years). The SHQ feasibility, readability, and psychometric properties were systematically investigated using reliability indices, cluster, and factor analyses and multiregression analyses. SHQ characteristics were compared both to different literature data obtained with different language versions and to the SSQ scores obtained in the same population. Results: Internal validity was high and very good reproducibility of scores and intersubject variability were obtained across the 24 items between the English and French SHQ for NH subjects. Factor and cluster analyses concurred in identifying five correlated factors, corresponding to several SHQ subscales: (1) speech in noise (corresponding to SHQ subscales 7 and 8), (2) localization of voice sounds from behind, (3) speech in quiet (corresponding to SHQ subscale 1), (4) localization of everyday sounds, and (5) localization of voices and music (corresponding to parts of the SHQ localization subscale). Correlations between SSQ subscales and SHQ factors identified the greatest correlations between SHQ factors 2, 4, and 5 and SSQ spatial subscales, whereas SHQ factor 1 had the greatest correlation with SSQ-speech. SHQ and SSQ scores were similar, whether in NH subjects (8.5 versus 8.4) or in HI subjects (6.6 for both), sharing more than 80% of variance. The SHQ localization subscale gave similar scores as the SSQ spatial subscale, sharing more than 75% of variance. Construct validity identified better ear PTA and PTA asymmetry as the two main predictors of SHQ scores, to a degree similar to that seen for the SSQ. The SHQ was shorter, easier to read and less sensitive to the number of years of formal education than the SSQ, but this came at a cost of ecological validity, which was rated higher for the SSQ than for the SHQ. Conclusions: A comparison of factor analysis outcomes among the English, Dutch, and French versions of the SHQ confirmed good conceptual equivalence across languages and robustness of the SHQ for use in international settings. In addition, SHQ and SSQ scores showed remarkable similarities, suggesting the possibility of extrapolating the results from one questionnaire to the other. Although the SHQ was originally designed in a population of cochlear implant patients, the present results show that its usefulness could easily be extended to noncochlear-implanted, HI subjects. © Copyright 2016 Wolters Kluwer Health, Inc. All rights reserved.",26808287,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84955566062
Claeys K.G.; Abicht A.; Häusler M.; Kleinle S.; Wiesmann M.; Schulz J.B.; Horvath R.; Weis J.,"Claeys, Kristl G. (6602174457); Abicht, Angela (6601976501); Häusler, Martin (24576600200); Kleinle, Stephanie (56241927000); Wiesmann, Martin (7003887908); Schulz, Jörg B. (7201479829); Horvath, Rita (55937735100); Weis, Joachim (7202856417)",6602174457; 6601976501; 24576600200; 56241927000; 7003887908; 7201479829; 55937735100; 7202856417,"Novel genetic and neuropathological insights in neurogenic muscle weakness, ataxia, and retinitis pigmentosa (NARP)",2016,Muscle and Nerve,54,2,,328,333,5,22,10.1002/mus.25125,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978863817&doi=10.1002%2fmus.25125&partnerID=40&md5=34abf03908e08e834476d3ea16dbc013,"Introduction: Neurogenic muscle weakness, ataxia, and retinitis pigmentosa (NARP) is caused by m.8993T>G/C mutations in the mitochondrial adenosine triphosphate synthase subunit 6 gene (MT-ATP6). Traditionally, heteroplasmy levels between 70% and 90% lead to NARP, and >90% result in Leigh syndrome. Methods: In this study we report a 30-year-old man with NARP and m.8993T>G in MT-ATP6. Results: Although the patient carried the mutation in homoplasmic state in blood with similarly high levels in urine (94%) and buccal swab (92%), he presented with NARP and not the expected, more severe Leigh phenotype. The mutation could not be detected in any of the 3 analyzed tissues of the mother, indicating a large genetic shift between mother and offspring. Nerve biopsy revealed peculiar endoneurial Schwann cell nuclear accumulations, clusters of concentrically arranged Schwann cells devoid of myelinated axons, and degenerated mitochondria. Conclusions: We emphasize the phenotypic variability of the m.8993T>G MT-ATP6 mutation and the need for caution in predictive counseling in such patients. Muscle Nerve 54: 328–333, 2016. © 2016 Wiley Periodicals, Inc.",27015314,Article,Final,,Scopus,2-s2.0-84978863817
Watanabe T.; Suzuki M.,"Watanabe, Tetsuo (7501474882); Suzuki, Masashi (56361150800)",7501474882; 56361150800,Analysis of the audiogram shape in patients with idiopathic sudden sensorineural hearing loss using a cluster analysis,2018,"Ear, Nose and Throat Journal",97,7,E36,,,,11,10.1177/014556131809700706,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050241284&doi=10.1177%2f014556131809700706&partnerID=40&md5=d210256a128ebfdc512987d14be30883,"We performed a cluster analysis to classify the audiogram shape in patients with idiopathic sudden sensorineural hearing loss (ISSNHL). We also investigated whether the audiogram shape is a prognostic indicator in the management of ISSNHL. A total of 115 inpatients with ISSNHL treated between 2001 and 2010 were analyzed. The data collected included age, sex, duration of hearing loss at the time of treatment, and the presence or absence of tinnitus, vertigo, diabetes, nystagmus, and canal paresis. A hierarchical cluster analysis was performed using the hearing threshold for each frequency on audiograms as variables. A logistic regression model was used for the prognostic analysis. The audiogram shape was classified into four clusters: (1) crossing horizontally pattern of all tones; (2) up-sloping pattern of low-tone loss; (3) deaf pattern; and (4) down-sloping pattern of high-tone loss. The age of the patient, presence of canal paresis, and audiogram shape showed statistically significant relationships with hearing improvement. The audiogram shape based on the cluster analysis demonstrated a significant relationship with hearing improvement in patients with ISSNHL. Further studies are needed to elucidate the underlying etiology of each audiogram shape. © 2018 Vendome Group.",30036445,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85050241284
Feng G.; Ingvalson E.M.; Grieco-Calub T.M.; Roberts M.Y.; Ryan M.E.; Birmingham P.; Burrowes D.; Young N.M.; Wong P.C.M.,"Feng, Gangyi (55260997700); Ingvalson, Erin M. (56307824300); Grieco-Calub, Tina M. (23479856300); Roberts, Megan Y. (46161518000); Ryan, Maura E. (55439041200); Birmingham, Patrick (6603710729); Burrowes, Delilah (6507323294); Young, Nancy M. (7402413031); Wong, Patrick C. M. (14018817600)",55260997700; 56307824300; 23479856300; 46161518000; 55439041200; 6603710729; 6507323294; 7402413031; 14018817600,Neural preservation underlies speech improvement from auditory deprivation in young cochlear implant recipients,2018,Proceedings of the National Academy of Sciences of the United States of America,115,5,,E1022,E1031,9,51,10.1073/pnas.1717603115,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041235393&doi=10.1073%2fpnas.1717603115&partnerID=40&md5=e3736c9a6013ce6f02b147d4c33c9216,"Although cochlear implantation enables some children to attain age-appropriate speech and language development, communicative delays persist in others, and outcomes are quite variable and difficult to predict, even for children implanted early in life. To understand the neurobiological basis of this variability, we used presurgical neural morphological data obtained from MRI of individual pediatric cochlear implant (CI) candidates implanted younger than 3.5 years to predict variability of their speech-perception improvement after surgery. We first compared neuroanatomical density and spatial pattern similarity of CI candidates to that of age-matched children with normal hearing, which allowed us to detail neuroanatomical networks that were either affected or unaffected by auditory deprivation. This information enables us to build machine-learning models to predict the individual children’s speech development following CI. We found that regions of the brain that were unaffected by auditory deprivation, in particular the auditory association and cognitive brain regions, produced the highest accuracy, specificity, and sensitivity in patient classification and the most precise prediction results. These findings suggest that brain areas unaffected by auditory deprivation are critical to developing closer to typical speech outcomes. Moreover, the findings suggest that determination of the type of neural reorganization caused by auditory deprivation before implantation is valuable for predicting post-CI language outcomes for young children.",29339512,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85041235393
Healy E.W.; Yoho S.E.,"Healy, Eric W. (7005887267); Yoho, Sarah E. (55550257500)",7005887267; 55550257500,Difficulty understanding speech in noise by the hearing impaired: Underlying causes and technological solutions,2016,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2016-October,,7590647,89,92,3,7,10.1109/EMBC.2016.7590647,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009074999&doi=10.1109%2fEMBC.2016.7590647&partnerID=40&md5=b83ec350bb5aa93782e34128e81a43ee,"A primary complaint of hearing-impaired individuals involves poor speech understanding when background noise is present. Hearing aids and cochlear implants often allow good speech understanding in quiet backgrounds. But hearing-impaired individuals are highly noise intolerant, and existing devices are not very effective at combating background noise. As a result, speech understanding in noise is often quite poor. In accord with the significance of the problem, considerable effort has been expended toward understanding and remedying this issue. Fortunately, our understanding of the underlying issues is reasonably good. In sharp contrast, effective solutions have remained elusive. One solution that seems promising involves a single-microphone machine-learning algorithm to extract speech from background noise. Data from our group indicate that the algorithm is capable of producing vast increases in speech understanding by hearing-impaired individuals. This paper will first provide an overview of the speech-in-noise problem and outline why hearing-impaired individuals are so noise intolerant. An overview of our approach to solving this problem will follow. © 2016 IEEE.",28268288,Conference paper,Final,,Scopus,2-s2.0-85009074999
Collett E.; Marx M.; Gaillard P.; Roby B.; Fraysse B.; Deguine O.; Barone P.,"Collett, E. (57188739369); Marx, M. (16310043700); Gaillard, P. (56622475100); Roby, B. (57188737695); Fraysse, B. (7007176703); Deguine, O. (7003638549); Barone, P. (7102266372)",57188739369; 16310043700; 56622475100; 57188737695; 7007176703; 7003638549; 7102266372,Categorization of common sounds by cochlear implanted and normal hearing adults,2016,Hearing Research,335,,,207,219,12,7,10.1016/j.heares.2016.03.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962749760&doi=10.1016%2fj.heares.2016.03.007&partnerID=40&md5=c44925235efff51224bd9c422beca1d4,"Auditory categorization involves grouping of acoustic events along one or more shared perceptual dimensions which can relate to both semantic and physical attributes. This process involves both high level cognitive processes (categorization) and low-level perceptual encoding of the acoustic signal, both of which are affected by the use of a cochlear implant (CI) device. The goal of this study was twofold: I) compare the categorization strategies of CI users and normal hearing listeners (NHL) II) investigate if any characteristics of the raw acoustic signal could explain the results. 16 experienced CI users and 20 NHL were tested using a Free-Sorting Task of 16 common sounds divided into 3 predefined categories of environmental, musical and vocal sounds. Multiple Correspondence Analysis (MCA) and Hierarchical Clustering based on Principal Components (HCPC) show that CI users followed a similar categorization strategy to that of NHL and were able to discriminate between the three different types of sounds. However results for CI users were more varied and showed less inter-participant agreement. Acoustic analysis also highlighted the average pitch salience and average autocorrelation peak as being important for the perception and categorization of the sounds. The results therefore show that on a broad level of categorization CI users may not have as many difficulties as previously thought in discriminating certain kinds of sound; however the perception of individual sounds remains challenging. © 2016 Elsevier B.V.",27050944,Article,Final,,Scopus,2-s2.0-84962749760
Xu J.; Berret E.; Kim J.H.,"Xu, Jie (57193166500); Berret, Emmanuelle (41861019200); Kim, Jun Hee (12242670300)",57193166500; 41861019200; 12242670300,Activity-dependent formation and location of voltage-gated sodium channel clusters at a CNS nerve terminal during postnatal development,2017,Journal of Neurophysiology,117,2,,582,593,11,16,10.1152/jn.00617.2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011321151&doi=10.1152%2fjn.00617.2016&partnerID=40&md5=10f22c3dc4d5c4c4ec1ff33123a6f7ad,"In auditory pathways, the precision of action potential (AP) propagation depends on axon myelination and high densities of voltage-gated Na (Nav) channels clustered at nodes of Ranvier. Changes in Nav channel expression at the heminode, the final node before the nerve terminal, can alter AP invasion into the presynaptic terminal. We studied the activity-dependent formation of Nav channel clusters before and after hearing onset at postnatal day 12 in the rat and mouse auditory brain stem. In rats, the Nav channel cluster at the heminode formed progressively during the second postnatal week, around hearing onset, whereas the Nav channel cluster at the nodes was present before hearing onset. Initiation of heminodal Nav channel clustering was correlated with the expression of scaffolding protein ankyrinG and paranodal protein Caspr. However, in whirler mice with congenital deafness, heminodal Nav channels did not form clusters and maintained broad expression, but Nav channel clustering was normal at the nodes. In addition, a clear difference in the distance from the heminodal Nav channel to the calyx across the mediolateral axis of the medial nucleus of the trapezoid body (MNTB) developed after hearing onset. In the medial MNTB, where neurons respond best to high-frequency sounds, the heminodal Nav channel cluster was located closer to the terminal than in the lateral MNTB, where neurons respond best to low-frequency sounds. Thus sound-mediated neuronal activities are potentially associated with the refinement of the heminode adjacent to the presynaptic terminal in the auditory brain stem. NEW & NOTEWORTHY Clustering of voltage-gated sodium (Nav) channels and their distribution along the axon, specifically at the unmyelinated axon segment next to the nerve terminal, are essential for tuning propagated action potentials. Nav channel clusters near the nerve terminal and their location as a function of neuronal position along the mediolateral axis are controlled by auditory inputs after hearing onset. Thus sound-mediated neuronal activity influences the tonotopic organization of Nav channels at the nerve terminal in the auditory brain stem. © 2017 the American Physiological Society.",27832602,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85011321151
Asghari A.; Farhadi M.; Daneshi A.; Khabazkhoob M.; Mohazzab-Torabi S.; Jalessi M.; Emamjomeh H.,"Asghari, Alimohamad (6602528657); Farhadi, Mohammad (6602260143); Daneshi, Ahmad (6603071062); Khabazkhoob, Mehdi (16067093200); Mohazzab-Torabi, Saman (55618119300); Jalessi, Maryam (6507417275); Emamjomeh, Hesamedin (6506845848)",6602528657; 6602260143; 6603071062; 16067093200; 55618119300; 6507417275; 6506845848,The prevalence of hearing impairment by age and gender in a population-based study,2017,Iranian Journal of Public Health,46,9,,1237,1246,9,18,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028932292&partnerID=40&md5=0b399bb4ee4edb01cd793729bd155d54,"Background: This study aimed to determine the prevalence of hearing impairment (HI) by age and gender in a population aged 5 yr and older residing in Tehran, Iran. Methods: In this cross-sectional study, 140 clusters each including 10 households from Tehran, Iran were sampled between 2012 and 2013 using cluster random sampling. Trained audiologists examined the participants during face-to-face interviews. The hearing of the participants was evaluated before the removal of wax or other foreign bodies. In this study, HI was categorized as mild (grade 1, 26-40 db), moderate (grade 2, 41-60 db), severe (grade 3, 61-80 db), and deaf (grade 5, 81 db or more). All participants signed informed consent forms. The SATA software was used for data analysis. Results: Of 6521 individuals, 4370 (67%) were interviewed. The prevalence of HI (auditory threshold of 0.5, 1, 2, 4 KHz and more than 25 db in the better ear) was 14.27 (11.53-17.91) of whom 9.52 (7.07-11.98) had grade 1, 4.04 (3.02-5.06) had grade 2, 0.67 (0.33-1.02) had grade 3 HI and 0.48 (0.16-0.8) were deaf. About 5.19% of the participants had disabling hearing impairment. All HI grades increased significantly with age but no significant difference was observed between men and women. Conclusion: The considerable prevalence of HI in Iran in comparison with other developing countries, with regards to the trend of aging in the population, seems concerning. The results of the study could be used as a treatment and research guideline for future works in the area of policymaking and plan to decrease these disorders. © 2017, Iranian Journal of Public Health. All rights reserved.",,Article,Final,,Scopus,2-s2.0-85028932292
Lesica N.A.,"Lesica, Nicholas A. (6505793695)",6505793695,Why Do Hearing Aids Fail to Restore Normal Auditory Perception?,2018,Trends in Neurosciences,41,4,,174,185,11,73,10.1016/j.tins.2018.01.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044530331&doi=10.1016%2fj.tins.2018.01.008&partnerID=40&md5=972c1758f1672dd8287aae4a6e9ce90d,"Hearing loss is a widespread condition that is linked to declines in quality of life and mental health. Hearing aids remain the treatment of choice, but, unfortunately, even state-of-the-art devices provide only limited benefit for the perception of speech in noisy environments. While traditionally viewed primarily as a loss of sensitivity, hearing loss is also known to cause complex distortions of sound-evoked neural activity that cannot be corrected by amplification alone. This Opinion article describes the effects of hearing loss on neural activity to illustrate the reasons why current hearing aids are insufficient and to motivate the use of new technologies to explore directions for improving the next generation of devices. © 2018 Elsevier Ltd",29449017,Review,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85044530331
de Hoog B.E.; Langereis M.C.; van Weerdenburg M.; Knoors H.E.; Verhoeven L.,"de Hoog, Brigitte E. (56426438900); Langereis, Margreet C. (6701770777); van Weerdenburg, Marjolijn (13003016800); Knoors, Harry E T (23397042600); Verhoeven, Ludo (6603731251)",56426438900; 6701770777; 13003016800; 23397042600; 6603731251,Linguistic profiles of children with CI as compared with children with hearing or specific language impairment,2016,International journal of language & communication disorders,51,5,,518,530,12,21,10.1111/1460-6984.12228,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027958941&doi=10.1111%2f1460-6984.12228&partnerID=40&md5=038fe2b315c22fde84fd4d8a0f3fc202,"BACKGROUND: The spoken language difficulties of children with moderate or severe to profound hearing loss are mainly related to limited auditory speech perception. However, degraded or filtered auditory input as evidenced in children with cochlear implants (CIs) may result in less efficient or slower language processing as well. To provide insight into the underlying nature of the spoken language difficulties in children with CIs, linguistic profiles of children with CIs are compared with those of hard-of-hearing (HoH) children with conventional hearing aids and children with specific language impairment (SLI).; AIMS: To examine differences in linguistic abilities and profiles of children with CIs as compared with HoH children and children with SLI, and whether the spoken language difficulties of children with CIs mainly lie in limited auditory perception or in language processing problems.; METHODS & PROCEDURE: Differences in linguistic abilities and differential linguistic profiles of 47 children with CI, 66 HoH children with moderate to severe hearing loss, and 127 children with SLI are compared, divided into two age cohorts. Standardized Dutch tests were administered. Factor analyses and cluster analyses were conducted to find homogeneous linguistic profiles of the children.; OUTCOMES & RESULTS: The children with CIs were outperformed by their HoH peers and peers with SLI on most linguistic abilities. Concerning the linguistic profiles, the largest group of children with CIs and HoH children shared similar profiles. The profiles observed for most of the children with SLI were different from those of their peers with hearing loss in both age cohorts.; CONCLUSIONS & IMPLICATIONS: Results suggest that the underlying nature of spoken language problems in most children with CIs manifests in limited auditory perception instead of language processing difficulties. However, there appears to be a subgroup of children with CIs whose linguistic profiles resemble those of children with SLI. © 2016 Royal College of Speech and Language Therapists.",26864995,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85027958941
Shehieb W.; Nasri M.O.; Mohammed N.; Debsi O.; Arshad K.,"Shehieb, Wessam (57194971956); Nasri, Mohammed Osama (57206902634); Mohammed, Noureldin (57206900935); Debsi, Omar (57206893028); Arshad, Kamran (8727581900)",57194971956; 57206902634; 57206900935; 57206893028; 8727581900,Intelligent Hearing System using Assistive Technology for Hearing-Impaired Patients,2018,"2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference, IEMCON 2018",,,8615021,725,729,4,3,10.1109/IEMCON.2018.8615021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062082218&doi=10.1109%2fIEMCON.2018.8615021&partnerID=40&md5=b4d16bcd7a7f85259f8b4e803591b454,"Hearing is an important sense of coexistence, but majority of people taken it for granted unless it is weakened or lost. In this paper, an Assistive Intelligent Hearing Aid System (AIHAS) is proposed that supports hearing impaired patients and allow them to live a normal life. The patients will be required to wear smart glasses equipped with bone conduction technology and wirelessly connected with an application running on patient's smartphone. The AIHAS is designed to: (1) detect multiple ear damages, (2) evaluates the degree of patient's hearing loss, (3) having smart filters with two different modes based on surrounding environment, and (4) assist children with articulation development. The patients will be able to choose between two types of filters i.e. Quiet Room (QR) and Noisy Room (NR) filter depending on the surrounding environment. Additionally, an Auditory Assistive mode is also added to AIHAS to train and assist children with speech disorders caused by hearing impairment at a younger age. The AIHAS also allows interfacing with a smartwatch for easier system access. The system prototype has been developed and tested with multiple patients. The proposed AIHAS is an intelligent, low cost, reliable and a portable solution. © 2018 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85062082218
Ding J.; Tang Z.; Chen J.; Shi H.; Chen J.; Wang C.; Zhang C.; Li L.; Chen P.; Wang J.,"Ding, Jie (56995465000); Tang, Zihua (38663278700); Chen, Jiarong (39160927200); Shi, Haosong (56995455800); Chen, Jianling (56482932500); Wang, Cuicui (56995404100); Zhang, Cui (55662059500); Li, Liang (12803244900); Chen, Ping (56999395100); Wang, Jinfu (35119898500)",56995465000; 38663278700; 39160927200; 56995455800; 56482932500; 56995404100; 55662059500; 12803244900; 56999395100; 35119898500,Induction of differentiation of human embryonic stem cells into functional hair-cell-like cells in the absence of stromal cells,2016,International Journal of Biochemistry and Cell Biology,81,,,208,222,14,21,10.1016/j.biocel.2015.11.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949422129&doi=10.1016%2fj.biocel.2015.11.012&partnerID=40&md5=d6c9951665fdb0e6357854c6522e3263,"Sensorineural hearing loss and vestibular dysfunction have become the most common forms of sensory defects. Stem cell-based therapeutic strategies for curing hearing loss are being developed. Several attempts to develop hair cells by using chicken utricle stromal cells as feeder cells have resulted in phenotypic conversion of stem cells into inner ear hair-cell-like cells. Here, we induced the differentiation of human embryonic stem cells (hESCs) into otic epithelial progenitors (OEPs), and further induced the differentiation of OEPs into hair-cell-like cells using different substrates. Our results showed that OEPs cultured on the chicken utricle stromal cells with the induction medium could differentiate into hair-cell-like cells with stereociliary bundles. Co-culture with stromal cells, however, may be problematic for subsequent examination of the induced hair-cell-like cells. In order to avoid the interference from stromal cells, we cultured OEPs on laminin with different induction media and examined the effects of the induction medium on the differentiation potentials of OEPs into hair-cell-like cells. The results revealed that the culture of OEPs on laminin with the conditioned medium from chicken utricle stromal cells supplemented with EGF and all-trans retinoic acid (RA) could promote the organization of cells into epithelial clusters displaying hair-cell-like cells with stereociliary bundles. These cells also displayed the expected electrophysiological properties. © 2015 Elsevier Ltd",26615761,Article,Final,,Scopus,2-s2.0-84949422129
Lavinsky J.; Ge M.; Crow A.L.; Pan C.; Wang J.; Salehi P.; Myint A.; Eskin E.; Allayee H.; Lusis A.J.; Friedman R.A.,"Lavinsky, Joel (16480726500); Ge, Marshall (57190681209); Crow, Amanda L. (56667233000); Pan, Calvin (15760741700); Wang, Juemei (55651661000); Salehi, Pezhman (55337603400); Myint, Anthony (56667228700); Eskin, Eleazar (7003344359); Allayee, Hooman (56901918400); Lusis, Aldons J. (35463122100); Friedman, Rick A. (12806202500)",16480726500; 57190681209; 56667233000; 15760741700; 55651661000; 55337603400; 56667228700; 7003344359; 56901918400; 35463122100; 12806202500,The genetic architecture of noise-induced hearing loss: Evidence for a gene-by-environment interaction,2016,"G3: Genes, Genomes, Genetics",6,10,,3219,3228,9,20,10.1534/g3.116.032516,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994565833&doi=10.1534%2fg3.116.032516&partnerID=40&md5=73f25bff044a86ec983799f3171f4d3b,"The discovery of environmentally specific genetic effects is crucial to the understanding of complex traits, such as susceptibility to noise-induced hearing loss (NIHL). We describe the first genome-wide association study (GWAS) for NIHL in a large and well-characterized population of inbred mouse strains, known as the Hybrid Mouse Diversity Panel (HMDP). We recorded auditory brainstem response (ABR) thresholds both pre and post 2-hr exposure to 10-kHz octave band noise at 108 dB sound pressure level in 5-6-wk-old female mice from the HMDP (4-5 mice/strain). From the observation that NIHL susceptibility varied among the strains, we performed a GWAS with correction for population structure and mapped a locus on chromosome 6 that was statistically significantly associated with two adjacent frequencies. We then used a ""genetical genomics"" approach that included the analysis of cochlear eQTLs to identify candidate genes within the GWAS QTL. In order to validate the gene-by-environment interaction, we compared the effects of the postnoise exposure locus with that from the same unexposed strains. The most significant SNP at chromosome 6 (rs37517079) was associated with noise susceptibility, but was not significant at the same frequencies in our unexposed study. These findings demonstrate that the genetic architecture of NIHL is distinct from that of unexposed hearing levels and provide strong evidence for gene-by-environment interactions in NIHL. © 2016 Lavinsky et al.",27520957,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84994565833
Wang Y.; Li J.; Yao X.; Li W.; Du H.; Tang M.; Xiong W.; Chai R.; Xu Z.,"Wang, Yanfei (55661812000); Li, Jie (57483829700); Yao, Xuerui (58593876200); Li, Wei (57201905966); Du, Haibo (56347726200); Tang, Mingliang (23989773500); Xiong, Wei (58546607000); Chai, Renjie (37065753300); Xu, Zhigang (14036417300)",55661812000; 57483829700; 58593876200; 57201905966; 56347726200; 23989773500; 58546607000; 37065753300; 14036417300,Loss of CIB2 causes profound hearing loss and abolishes mechanoelectrical transduction in mice,2017,Frontiers in Molecular Neuroscience,10,,401,,,,85,10.3389/fnmol.2017.00401,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041805921&doi=10.3389%2ffnmol.2017.00401&partnerID=40&md5=61ba1b080735070d5f722ed0dca7345e,"Calcium and integrin-binding protein 2 (CIB2) belongs to a protein family with four known members, CIB1 through CIB4, which are characterized by multiple calcium-binding EF-hand domains. Among the family members, the Cib1 and Cib2 genes are expressed in mouse cochlear hair cells, and mutations in the human CIB2 gene have been associated with nonsyndromic deafness DFNB48 and syndromic deafness USH1J. To further explore the function of CIB1 and CIB2 in hearing, we established Cib1 and Cib2 knockout mice using the clustered regularly interspaced short palindromic repeat (CRISPR)-associated Cas9 nuclease (CRISPR/Cas9) genome editing technique. We found that loss of CIB1 protein does not affect auditory function, whereas loss of CIB2 protein causes profound hearing loss in mice. Further investigation revealed that hair cell stereocilia development is affected in Cib2 knockout mice. Noticeably, loss of CIB2 abolishes mechanoelectrical transduction (MET) currents in auditory hair cells. In conclusion, we show here that although both CIB1 and CIB2 are readily detected in the cochlea, only loss of CIB2 results in profound hearing loss, and that CIB2 is essential for auditory hair cell MET. © 2017 Wang, Li, Yao, Li, Du, Tang, Xiong, Chai and Xu.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85041805921
Busch T.; Vanpoucke F.; van Wieringen A.,"Busch, Tobias (57194342035); Vanpoucke, Filiep (6603596663); van Wieringen, Astrid (22942685800)",57194342035; 6603596663; 22942685800,Auditory environment across the life span of cochlear implant users: Insights from data logging,2017,"Journal of Speech, Language, and Hearing Research",60,5,,1362,1377,15,65,10.1044/2016_JSLHR-H-16-0162,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019770546&doi=10.1044%2f2016_JSLHR-H-16-0162&partnerID=40&md5=6eab65d920d980ca497b2c3b8416d112,"Purpose: We describe the natural auditory environment of people with cochlear implants (CIs), how it changes across the life span, and how it varies between individuals. Method: We performed a retrospective cross-sectional analysis of Cochlear Nucleus 6 CI sound-processor data logs. The logs were obtained from 1,501 people with CIs (ages 0-96 years). They covered over 2.4 million hr of implant use and indicated how much time the CI users had spent in various acoustical environments. We investigated exposure to spoken language, noise, music, and quiet, and analyzed variation between age groups, users, and countries. Results: CI users spent a substantial part of their daily life in noisy environments. As a consequence, most speech was presented in background noise. We found significant differences between age groups for all auditory scenes. Yet even within the same age group and country, variability between individuals was substantial. Conclusions: Regardless of their age, people with CIs face challenging acoustical environments in their daily life. Our results underline the importance of supporting them with assistive listening technology. Moreover, we found large differences between individuals’ auditory diets that might contribute to differences in rehabilitation outcomes. Their causes and effects should be investigated further. © 2017 The authors.",28418532,Article,Final,,Scopus,2-s2.0-85019770546
Christov F.; Munder P.; Berg L.; Bagus H.; Lang S.; Arweiler-Harbeck D.,"Christov, F. (56221936300); Munder, P. (57189658747); Berg, L. (57189657587); Bagus, H. (35809770800); Lang, S. (7401700991); Arweiler-Harbeck, D. (6508218296)",56221936300; 57189658747; 57189657587; 35809770800; 7401700991; 6508218296,ECAP analysis in cochlear implant patients as a function of patient's age and electrode-design,2016,"European Annals of Otorhinolaryngology, Head and Neck Diseases",133,,,S1,S3,2,16,10.1016/j.anorl.2016.04.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973879006&doi=10.1016%2fj.anorl.2016.04.015&partnerID=40&md5=ebfd208376c60a61cd3abde5950feabe,"Introduction Electric compound action potentials (ECAPs) provide information about the nerve's and device's function in and after cochlear implantation. In general, lower ECAP values are expected to generate better results. Aim was an analysis of ECAPs in the course of time as a function of the patient's age and electrode design. Patients and methods Between 2008 and 2013, 168 patients of eight defined age groups were included into the investigation. NRTs were measured intraoperatively, after 6 and after 12 months. Results The intraoperative mean value of ECAP was 174.14 CL (current level) and decreased after 6 months to 156.38 CL. Highest ECAPs were achieved intraoperatively in the clusters “younger than 18 months” (181.04 CL) and “older than 80 years” (190.45 CL). CI 422 showed apparently higher ECAP thresholds (182.69) during surgery than CI 24 RE (171.47) and CI 512 (170.64). Conclusion ECAPs are a well-established method to get information about the CI's and nerve's function during and after surgery. After initial higher values NRTs decrease after 6 months and remain stable in the following controls. Very young and older patients tend to have higher thresholds than middle-aged groups. Perimodiolar electrodes are significantly attached to lower values because there is a closer nerve–electrode interaction. © 2016 Elsevier Masson SAS",27262349,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84973879006
Lee M.Y.; Park Y.-H.,"Lee, Min Yong (56691922700); Park, Yong-Ho (56822546100)",56691922700; 56822546100,Potential of Gene and Cell Therapy for Inner Ear Hair Cells,2018,BioMed Research International,2018,,8137614,,,,16,10.1155/2018/8137614,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049306923&doi=10.1155%2f2018%2f8137614&partnerID=40&md5=2a3b87d7a668d0a3f1844aed9231cafe,"Sensorineural hearing loss is caused by the loss of sensory hair cells (HCs) or a damaged afferent nerve pathway to the auditory cortex. The most common option for the treatment of sensorineural hearing loss is hearing rehabilitation using hearing devices. Various kinds of hearing devices are available but, despite recent advancements, their perceived sound quality does not mimic that of the ""naïve"" cochlea. Damage to crucial cochlear structures is mostly irreversible and results in permanent hearing loss. Cochlear HC regeneration has long been an important goal in the field of hearing research. However, it remains challenging because, thus far, no medical treatment has successfully regenerated cochlear HCs. Recent advances in genetic modulation and developmental techniques have led to novel approaches to generating HCs or protecting against HC loss, to preserve hearing. In this review, we present and review the current status of two different approaches to restoring or protecting hearing, gene therapy, including the newly introduced CRISPR/Cas9 genome editing, and stem cell therapy, and suggest the future direction. © 2018 Min Yong Lee and Yong-Ho Park.",30009175,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85049306923
Xu H.; Fan W.; Zhao X.; Li J.; Zhang W.; Lei P.; Liu Y.; Wang H.; Cheng H.; Shi H.,"Xu, Haibo (23669617200); Fan, Wenliang (55624403100); Zhao, Xueyan (55705153300); Li, Jing (57191829314); Zhang, Wenjuan (37021959800); Lei, Ping (56992440900); Liu, Yuan (57192560899); Wang, Haha (57062415200); Cheng, Huamao (26663667200); Shi, Hong (56911494600)",23669617200; 55624403100; 55705153300; 57191829314; 37021959800; 56992440900; 57192560899; 57062415200; 26663667200; 56911494600,Disrupted functional brain connectome in unilateral sudden sensorineural hearing loss,2016,Hearing Research,335,,,138,148,10,41,10.1016/j.heares.2016.02.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961828381&doi=10.1016%2fj.heares.2016.02.016&partnerID=40&md5=026a320ac95b5b414cd03a6032a28382,"Sudden sensorineural hearing loss (SSNHL) is generally defined as sensorineural hearing loss of 30 dB or greater over at least three contiguous audiometric frequencies and within a three-day period. This hearing loss is usually unilateral and can be associated with tinnitus and vertigo. The pathogenesis of unilateral sudden sensorineural hearing loss is still unknown, and the alterations in the functional connectivity are suspected to involve one possible pathogenesis. Despite scarce findings with respect to alterations in brain functional networks in unilateral sudden sensorineural hearing loss, the alterations of the whole brain functional connectome and whether these alterations were already in existence in the acute period remains unknown. The aim of this study was to investigate the alterations of brain functional connectome in two large samples of unilateral sudden sensorineural hearing loss patients and to investigate the correlation between unilateral sudden sensorineural hearing loss characteristics and changes in the functional network properties. Pure tone audiometry was performed to assess hearing ability. Abnormal changes in the peripheral auditory system were examined using conventional magnetic resonance imaging. The graph theoretical network analysis method was used to detect brain connectome alterations in unilateral sudden sensorineural hearing loss. Compared with the control groups, both groups of unilateral SSNHL patients exhibited a significantly increased clustering coefficient, global efficiency, and local efficiency but a significantly decreased characteristic path length. In addition, the primary increased nodal strength (e.g., nodal betweenness, hubs) was observed in several regions primarily, including the limbic and paralimbic systems, and in the auditory network brain areas. These findings suggest that the alteration of network organization already exists in unilateral sudden sensorineural hearing loss patients within the acute period and that the functional connectome of unilateral SSNHL patients is characterized by a shift toward small-worldization. Additionally, we hope that these findings will help to elucidate unilateral SSNHL through a new research perspective and provide insight for the potential pathophysiology of unilateral SSNHL. © 2016 Elsevier B.V.",26969260,Article,Final,,Scopus,2-s2.0-84961828381
Philip R.C.; Rodriguez J.J.; Niihori M.; Francis R.H.; Mudery J.A.; Caskey J.S.; Krupinski E.; Jacob A.,"Philip, Rohit C. (36713924400); Rodriguez, Jeffrey J. (7404696747); Niihori, Maki (6507641241); Francis, Ross H. (57191545854); Mudery, Jordan A. (56342056800); Caskey, Justin S. (57217152464); Krupinski, Elizabeth (26643320200); Jacob, Abraham (13004863900)",36713924400; 7404696747; 6507641241; 57191545854; 56342056800; 57217152464; 26643320200; 13004863900,Automated High-Throughput Damage Scoring of Zebrafish Lateral Line Hair Cells After Ototoxin Exposure,2018,Zebrafish,15,2,,145,155,10,9,10.1089/zeb.2017.1451,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044746905&doi=10.1089%2fzeb.2017.1451&partnerID=40&md5=2d054f48afc0fc212f9ebf4393e9e97d,"Zebrafish have emerged as a powerful biological system for drug development against hearing loss. Zebrafish hair cells, contained within neuromasts along the lateral line, can be damaged with exposure to ototoxins, and therefore, pre-exposure to potentially otoprotective compounds can be a means of identifying promising new drug candidates. Unfortunately, anatomical assays of hair cell damage are typically low-throughput and labor intensive, requiring trained experts to manually score hair cell damage in fluorescence or confocal images. To enhance throughput and consistency, our group has developed an automated damage-scoring algorithm based on machine-learning techniques that produce accurate damage scores, eliminate potential operator bias, provide more fidelity in determining damage scores that are between two levels, and deliver consistent results in a fraction of the time required for manual analysis. The system has been validated against trained experts using linear regression, hypothesis testing, and the Pearson's correlation coefficient. Furthermore, performance has been quantified by measuring mean absolute error for each image and the time taken to automatically compute damage scores. Coupling automated analysis of zebrafish hair cell damage to behavioral assays for ototoxicity produces a novel drug discovery platform for rapid translation of candidate drugs into preclinical mammalian models of hearing loss. © 2018, Mary Ann Liebert, Inc.",29381431,Article,Final,,Scopus,2-s2.0-85044746905
Ishak W.S.; Mukari S.Z.-M.S.; Maamor N.; Hashim W.F.W.,"Ishak, Wan Syafira (37050953500); Mukari, Siti Zamratol-Mai Sarah (6506655442); Maamor, Nashrah (55403315100); Hashim, Wan Fazlina Wan (57191617380)",37050953500; 6506655442; 55403315100; 57191617380,Validation of self-reported hearing loss among multi-ethnic community dwelling older adults in Malaysia,2017,Journal of Clinical and Diagnostic Research,11,10,,MC01,MC05,4,2,10.7860/JCDR/2017/28144.10756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032025654&doi=10.7860%2fJCDR%2f2017%2f28144.10756&partnerID=40&md5=a7d4b365a67f33cd018909de9cd48132,"Introduction: Little is known about the prevalence of hearing loss and the usefulness of self-report hearing loss among older adults in Malaysia. Aim: We conducted a population-based study to investigate the prevalence of self-reported hearing problem and its relationship with audiometric hearing thresholds in older adults in Selangor, Malaysia. We also investigated demographic factors that were associated with the self-reported hearing loss. Materials and Methods: The participants were recruited from Selangor using a multi-stage clustered sampling involving 324 participants aged between 60 to 88-year-old (68.3±5.9 years). All participants underwent a face-to-face interview and pure tone audiometry. Self-reported hearing loss was obtained using three questions. Results: The prevalence of self-reported hearing problems was 53.4%. This prevalence did not differ significantly among age group, gender, race and education level (p>0.05). Univariate and logistic regression analyses found that tinnitus and Pure Tone Average (PTA) of at least moderate hearing loss at 0.5 kHz to 4 kHz contributed significantly to the likelihood of self-reported hearing problem. Participants with tinnitus and participants with PTA at least moderate hearing loss at 0.5 kHz to 4 kHz were twice as likely to report hearing problem than their counterparts. The questions yielded poor sensitivity in identifying at least mild loss and moderate sensitivity for at least moderate hearing loss. Conclusion: The present study highlights the need for a more effective self-report inventory or audiometry instrument that is less sensitive to background noise to better estimate hearing loss prevalence among adults in Malaysia. © 2017, Journal of Clinical and Diagnostic Research. All rights reserved.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85032025654
"Vaden K.I., Jr.; Matthews L.J.; Eckert M.A.; Dubno J.R.","Vaden, Kenneth I. (35316368100); Matthews, Lois J. (7202490616); Eckert, Mark A. (7102209282); Dubno, Judy R. (7003933859)",35316368100; 7202490616; 7102209282; 7003933859,Longitudinal Changes in Audiometric Phenotypes of Age-Related Hearing Loss,2017,JARO - Journal of the Association for Research in Otolaryngology,18,2,,371,385,14,30,10.1007/s10162-016-0596-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994418153&doi=10.1007%2fs10162-016-0596-2&partnerID=40&md5=0bec4cf3296e8f5011dacf6f3026cf43,"Presbyacusis, or age-related hearing loss, can be characterized in humans as metabolic and sensory phenotypes, based on patterns of audiometric thresholds that were established in animal models. The metabolic phenotype is thought to result from deterioration of the cochlear lateral wall and reduced endocochlear potential that decreases cochlear amplification and produces a mild, flat hearing loss at lower frequencies coupled with a gradually sloping hearing loss at higher frequencies. The sensory phenotype, resulting from environmental exposures such as excessive noise or ototoxic drugs, involves damage to sensory and non-sensory cells and loss of the cochlear amplifier, which produces a 50–70 dB threshold shift at higher frequencies. The mixed metabolic + sensory phenotype exhibits a mix of lower frequency, sloping hearing loss similar to the metabolic phenotype, and steep, higher frequency hearing loss similar to the sensory phenotype. The current study examined audiograms collected longitudinally from 343 adults 50–93 years old (n = 686 ears) to test the hypothesis that metabolic phenotypes increase with increasing age, in contrast with the sensory phenotype. A Quadratic Discriminant Analysis (QDA) was used to classify audiograms from each of these ears as (1) Older-Normal, (2) Metabolic, (3) Sensory, or (4) Metabolic + Sensory phenotypes. Although hearing loss increased systematically with increasing age, audiometric phenotypes remained stable for the majority of ears (61.5 %) over an average of 5.5 years. Most of the participants with stable phenotypes demonstrated matching phenotypes for the left and right ears. Audiograms were collected over an average period of 8.2 years for ears with changing audiometric phenotypes, and the majority of those ears transitioned to a Metabolic or Metabolic + Sensory phenotype. These results are consistent with the conclusion that the likelihood of metabolic presbyacusis increases with increasing age in middle to older adulthood. © 2016, Association for Research in Otolaryngology.",27830350,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84994418153
Yamamura D.; Ayaka S.; Tateno T.,"Yamamura, Daiki (57191728784); Ayaka, Sano (57191728656); Tateno, Takashi (7006831936)",57191728784; 57191728656; 7006831936,An analysis of current source density profiles activated by local stimulation in the mouse auditory cortex in vitro,2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),9948 LNCS,,,353,362,9,0,10.1007/978-3-319-46672-9_40,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992630829&doi=10.1007%2f978-3-319-46672-9_40&partnerID=40&md5=15804d961d461cf227d90143fc29ebd2,"To examine microcircuit properties of the mouse auditory cortex (AC) in vitro, we extracellularly recorded spatiotemporal laminar profiles driven by short electric microstimulation on a planar multielectrode array (MEA) substrate. The recorded local field potentials (LFPs) were subsequently evaluated using current source density (CSD) analysis to identify sources and sinks. Current sinks are thought to be an indicator of net synaptic current in a small volume of cortex surrounding the recording site. Thus, CSD analysis combined with MEAs enabled us to compare mean synaptic activity in response to current stimuli on a layer-bylayer basis. Here, we used senescence-accelerated mice (SAM), some strains of which show age-related hearing loss, to examine characteristic spatiotemporal CSD patterns stimulated by electrodes in specific cortical layers. Thus, the CSD patterns were classified into several clusters based on the stimulation sites in the cortical layers. We also found, in a reduced space obtained by principle component analysis, some CSD pattern differences between the two SAM strains in terms of aging and stimulation layers. Finally, on the basis of these results, we discuss the effects of aging on AC microcircuit properties. © Springer International Publishing AG 2016.",,Conference paper,Final,,Scopus,2-s2.0-84992630829
Tikka C.; Verbeek J.H.; Kateman E.; Morata T.C.; Dreschler W.A.; Ferrite S.,"Tikka, Christina (57193124869); Verbeek, Jos H. (7005575160); Kateman, Erik (24344235400); Morata, Thais C. (6701544260); Dreschler, Wouter A. (7003763918); Ferrite, Silvia (8286807700)",57193124869; 7005575160; 24344235400; 6701544260; 7003763918; 8286807700,Interventions to prevent occupational noise-induced hearing loss,2017,Cochrane Database of Systematic Reviews,2017,7,CD006396,,,,50,10.1002/14651858.CD006396.pub4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021788943&doi=10.1002%2f14651858.CD006396.pub4&partnerID=40&md5=d8cff54503b2f3e1d59ea0ed4e834322,"Background: This is the second update of a Cochrane Review originally published in 2009. Millions of workers worldwide are exposed to noise levels that increase their risk of hearing disorders. There is uncertainty about the effectiveness of hearing loss prevention interventions. Objectives: To assess the effectiveness of non-pharmaceutical interventions for preventing occupational noise exposure or occupational hearing loss compared to no intervention or alternative interventions. Search methods: We searched the CENTRAL; PubMed; Embase; CINAHL; Web of Science; BIOSIS Previews; Cambridge Scientific Abstracts; and OSH UPDATE to 3 October 2016. Selection criteria: We included randomised controlled trials (RCT), controlled before-after studies (CBA) and interrupted time-series (ITS) of non-clinical interventions under field conditions among workers to prevent or reduce noise exposure and hearing loss. We also collected uncontrolled case studies of engineering controls about the effect on noise exposure. Data collection and analysis: Two authors independently assessed study eligibility and risk of bias and extracted data. We categorised interventions as engineering controls, administrative controls, personal hearing protection devices, and hearing surveillance. Main results: We included 29 studies. One study evaluated legislation to reduce noise exposure in a 12-year time-series analysis but there were no controlled studies on engineering controls for noise exposure. Eleven studies with 3725 participants evaluated effects of personal hearing protection devices and 17 studies with 84,028 participants evaluated effects of hearing loss prevention programmes (HLPPs). Effects on noise exposure Engineering interventions following legislation One ITS study found that new legislation in the mining industry reduced the median personal noise exposure dose in underground coal mining by 27.7 percentage points (95% confidence interval (CI) -36.1 to -19.3 percentage points) immediately after the implementation of stricter legislation. This roughly translates to a 4.5 dB(A) decrease in noise level. The intervention was associated with a favourable but statistically non-significant downward trend in time of the noise dose of -2.1 percentage points per year (95% CI -4.9 to 0.7, 4 year follow-up, very low-quality evidence). Engineering intervention case studies We found 12 studies that described 107 uncontrolled case studies of immediate reductions in noise levels of machinery ranging from 11.1 to 19.7 dB(A) as a result of purchasing new equipment, segregating noise sources or installing panels or curtains around sources. However, the studies lacked long-term follow-up and dose measurements of workers, and we did not use these studies for our conclusions. Hearing protection devices In general hearing protection devices reduced noise exposure on average by about 20 dB(A) in one RCT and three CBAs (57 participants, low-quality evidence). Two RCTs showed that, with instructions for insertion, the attenuation of noise by earplugs was 8.59 dB better (95% CI 6.92 dB to 10.25 dB) compared to no instruction (2 RCTs, 140 participants, moderate-quality evidence). Administrative controls: information and noise exposure feedback On-site training sessions did not have an effect on personal noise-exposure levels compared to information only in one cluster-RCT after four months' follow-up (mean difference (MD) 0.14 dB; 95% CI -2.66 to 2.38). Another arm of the same study found that personal noise exposure information had no effect on noise levels (MD 0.30 dB(A), 95% CI -2.31 to 2.91) compared to no such information (176 participants, low-quality evidence). Effects on hearing loss Hearing protection devices In two studies the authors compared the effect of different devices on temporary threshold shifts at short-term follow-up but reported insufficient data for analysis. In two CBA studies the authors found no difference in hearing loss from noise exposure above 89 dB(A) between muffs and earplugs at long-term follow-up (OR 0.8, 95% CI 0.63 to 1.03 ), very low-quality evidence). Authors of another CBA study found that wearing hearing protection more often resulted in less hearing loss at very long-term follow-up (very low-quality evidence). Combination of interventions: hearing loss prevention programmes One cluster-RCT found no difference in hearing loss at three- or 16-year follow-up between an intensive HLPP for agricultural students and audiometry only. One CBA study found no reduction of the rate of hearing loss (MD -0.82 dB per year (95% CI -1.86 to 0.22) for a HLPP that provided regular personal noise exposure information compared to a programme without this information. There was very-low-quality evidence in four very long-term studies, that better use of hearing protection devices as part of a HLPP decreased the risk of hearing loss compared to less well used hearing protection in HLPPs (OR 0.40, 95% CI 0.23 to 0.69). Other aspects of the HLPP such as training and education of workers or engineering controls did not show a similar effect. In three long-term CBA studies, workers in a HLPP had a statistically non-significant 1.8 dB (95% CI -0.6 to 4.2) greater hearing loss at 4 kHz than non-exposed workers and the confidence interval includes the 4.2 dB which is the level of hearing loss resulting from 5 years of exposure to 85 dB(A). In addition, of three other CBA studies that could not be included in the meta-analysis, two showed an increased risk of hearing loss in spite of the protection of a HLPP compared to non-exposed workers and one CBA did not. Authors' conclusions: There is very low-quality evidence that implementation of stricter legislation can reduce noise levels in workplaces. Controlled studies of other engineering control interventions in the field have not been conducted. There is moderate-quality evidence that training of proper insertion of earplugs significantly reduces noise exposure at short-term follow-up but long-term follow-up is still needed. There is very low-quality evidence that the better use of hearing protection devices as part of HLPPs reduces the risk of hearing loss, whereas for other programme components of HLPPs we did not find such an effect. The absence of conclusive evidence should not be interpreted as evidence of lack of effectiveness. Rather, it means that further research is very likely to have an important impact. © 2017 The Cochrane Collaboration. Published by John Wiley & Sons, Ltd.",28685503,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85021788943
Healy E.W.; Delfarah M.; Vasko J.L.; Carter B.L.; Wang D.,"Healy, Eric W. (7005887267); Delfarah, Masood (57191855243); Vasko, Jordan L. (57194549083); Carter, Brittney L. (57194543726); Wang, Deliang (7407070944)",7005887267; 57191855243; 57194549083; 57194543726; 7407070944,An algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker,2017,Journal of the Acoustical Society of America,141,6,,4230,4239,9,35,10.1121/1.4984271,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020734953&doi=10.1121%2f1.4984271&partnerID=40&md5=66f7c6cd2d156b10a9a14cb49a04bbf5,"Individuals with hearing impairment have particular difficulty perceptually segregating concurrent voices and understanding a talker in the presence of a competing voice. In contrast, individuals with normal hearing perform this task quite well. This listening situation represents a very different problem for both the human and machine listener, when compared to perceiving speech in other types of background noise. A machine learning algorithm is introduced here to address this listening situation. A deep neural network was trained to estimate the ideal ratio mask for a male target talker in the presence of a female competing talker. The monaural algorithm was found to produce sentence-intelligibility increases for hearing-impaired (HI) and normal-hearing (NH) listeners at various signal-to-noise ratios (SNRs). This benefit was largest for the HI listeners and averaged 59%-points at the least-favorable SNR, with a maximum of 87%-points. The mean intelligibility achieved by the HI listeners using the algorithm was equivalent to that of young NH listeners without processing, under conditions of identical interference. Possible reasons for the limited ability of HI listeners to perceptually segregate concurrent voices are reviewed as are possible implementation considerations for algorithms like the current one. © 2017 Acoustical Society of America.",28618817,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85020734953
Allitt B.J.; Harris A.R.; Morgan S.J.; Clark G.M.; Paolini A.G.,"Allitt, B.J. (55205979800); Harris, A.R. (55279515100); Morgan, S.J. (55207566800); Clark, G.M. (7402875119); Paolini, A.G. (35230424900)",55205979800; 55279515100; 55207566800; 7402875119; 35230424900,Thin-film micro-electrode stimulation of the cochlea in rats exposed to aminoglycoside induced hearing loss,2016,Hearing Research,331,,,13,26,13,10,10.1016/j.heares.2015.10.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945927151&doi=10.1016%2fj.heares.2015.10.003&partnerID=40&md5=05d9e3b1e1820f2b3f9eb233763305c7,"The multi-channel cochlear implant (CI) provides sound and speech perception to thousands of individuals who would otherwise be deaf. Broad activation of auditory nerve fibres when using a CI results in poor frequency discrimination. The CI also provides users with poor amplitude perception due to elicitation of a narrow dynamic range. Provision of more discrete frequency perception and a greater control over amplitude may allow users to better distinguish speech in noise and to segregate sound sources. In this research, thin-film (TF) high density micro-electrode arrays and conventional platinum ring electrode arrays were used to stimulate the cochlea of rats administered sensorineural hearing loss (SNHL) via ototoxic insult, with neural responses taken at 434 multiunit clusters in the central nucleus of the inferior colliculus (CIC). Threshold, dynamic range and broadness of response were used to compare electrode arrays. A stronger current was required to elicit CIC threshold when using the TF array compared to the platinum ring electrode array. TF stimulation also elicited a narrower dynamic range than the PR counterpart. However, monopolar stimulation using the TF array produced more localised CIC responses than other stimulation strategies. These results suggest that individuals with SNHL could benefit from micro stimulation of the cochlea using a monopolar configuration which may provide discrete frequency perception when using TF electrode arrays. © 2015 Elsevier B.V.",26471198,Article,Final,,Scopus,2-s2.0-84945927151
Wu Y.-H.; Ho H.-C.; Hsiao S.-H.; Brummet R.B.; Chipara O.,"Wu, Yu-Hsiang (18038757800); Ho, Hsu-Chueh (7401465234); Hsiao, Shih-Hsuan (8855497400); Brummet, Ryan B. (57115404500); Chipara, Octav (9334529600)",18038757800; 7401465234; 8855497400; 57115404500; 9334529600,Predicting three-month and 12-month post-fitting real-world hearing-aid outcome using pre-fitting acceptable noise level (ANL),2016,International Journal of Audiology,55,5,,285,294,9,13,10.3109/14992027.2015.1120892,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958055516&doi=10.3109%2f14992027.2015.1120892&partnerID=40&md5=ffeba0ceb514f8de58c8427376211651,"Objective: Determine the extent to which pre-fitting acceptable noise level (ANL), with or without other predictors such as hearing-aid experience, can predict real-world hearing-aid outcomes at three and 12 months post-fitting. Design: ANLs were measured before hearing-aid fitting. Post-fitting outcome was assessed using the international outcome inventory for hearing aids (IOI-HA) and a hearing-aid use questionnaire. Models that predicted outcomes (successful vs. unsuccessful) were built using logistic regression and several machine learning algorithms, and were evaluated using the cross-validation technique. Study sample: A total of 132 adults with hearing impairment. Results: The prediction accuracy of the models ranged from 61% to 68% (IOI-HA) and from 55% to 61% (hearing-aid use questionnaire). The models performed more poorly in predicting 12-month than three-month outcomes. The ANL cutoff between successful and unsuccessful users was higher for experienced (∼18 dB) than first-time hearing-aid users (∼10 dB), indicating that most experienced users will be predicted as successful users regardless of their ANLs. Conclusions: Pre-fitting ANL is more useful in predicting short-term (three months) hearing-aid outcomes for first-time users, as measured by the IOI-HA. The prediction accuracy was lower than the accuracy reported by some previous research that used a cross-sectional design. © 2016 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",26878163,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84958055516
Rajkumar S.; Muttan S.; Sapthagirivasan V.; Jaya V.; Vignesh S.S.,"Rajkumar, S. (57197224767); Muttan, S. (14527660100); Sapthagirivasan, V. (36606870800); Jaya, V. (56086274700); Vignesh, S.S. (56084354600)",57197224767; 14527660100; 36606870800; 56086274700; 56084354600,Development of Improved Software Intelligent System for Audiological Solutions,2018,Journal of Medical Systems,42,7,127,,,,4,10.1007/S10916-018-0978-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055616862&doi=10.1007%2fS10916-018-0978-6&partnerID=40&md5=c15d9d32d1d8469e3b8097b3fc9d12bd,"Of late, there has been an increase in hearing impairment cases and to provide the most advantageous solutions to them is an uphill task for audiologists. Significant difficulty faced by the audiologists is in effective programming of hearing aids to provide enhanced satisfaction to the users. The main aim of our study was to develop a software intelligent system (SIS): (i) to perform the required audiological investigations for finding the degree and type of hearing loss, and (ii) to suggest appropriate values of hearing aid parameters for enhancing the speech intelligibility and the satisfaction level among the hearing aid users. In this paper, we present a Neuro-Fuzzy based SIS to automatically predict and suggest the hearing-aid parameters such as gain values, compression ratio and threshold knee point, which are needed to be fixed for different octave frequencies of sound inputs during the hearing-aid trial. The test signals for audiological investigations are generated through the standard hardware present in a personal computer system and with the aid of a software algorithm. The proposed system was validated with 243 subjects’ data collected at the Government General Hospital, Chennai, India. The calculated sensitivity, specificity and accuracy of the proposed audiometer incorporated in the SIS were 98.6%, 96.4 and 98.2%, respectively, by comparing its interpretations with those of the ‘gold standard’ audiometers. Furthermore, 91% (221 of 243) of the hearing impaired subjects attained satisfaction in the first hearing aid trials itself with the gain values as recommended by the improved SIS. The proposed system reduced around 75% of the ‘trial and error’ time spent by audiologists for enhancing satisfactory usage of the hearing aid. Hence, the proposed SIS could be used to find the degree and type of hearing loss and to recommend hearing aid parameters to provide optimal solutions to the hearing aid users. © Springer Science+Business Media, LLC, part of Springer Nature 2018.",29860544,Article,Final,,Scopus,2-s2.0-85055616862
Fasunla A.J.; Ijitola J.O.; Akpa O.M.; Nwaorgu O.G.B.; Taiwo B.; Olaleye D.O.; Murphy R.L.; Adewole I.F.; Akinyinka O.O.,"Fasunla, A.J. (6504667690); Ijitola, J.O. (57195949209); Akpa, O.M. (36607334000); Nwaorgu, O.G.B. (6603844549); Taiwo, B. (6602861177); Olaleye, D.O. (6603859012); Murphy, R.L. (35373811100); Adewole, I.F. (7003978247); Akinyinka, O.O. (6603687925)",6504667690; 57195949209; 36607334000; 6603844549; 6602861177; 6603859012; 35373811100; 7003978247; 6603687925,Is there any relationship between hearing threshold levels and CD4 cell count of human immunodeficiency virus infected adults?,2016,African journal of medicine and medical sciences,45,1,,51,60,9,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030447331&partnerID=40&md5=b327bdb94e094331eb26b28732381a89,"Background The role of viral load level and/or CD4 (Cluster of differentiation 4) cell count in the aetiopathogenesis of hearing loss in HIV infection is unclear. Therefore, we investigated the relationship between CD4 cell counts, viral load and hearing threshold of HIV (Human immunodeficiency virus) infected adults.; METHODS: This cohort audiometric study involved consecutive HIV-infected and HIV-uninfected adults as controls. Clinical data relating to hearing loss, HIV status, and highly -active antiretroviral therapy (HAART) were obtained. Audiornetric evaluation was performed. The most recent CD4 cell counts and RNA viral load-of HIV-infected participants were obtained from clinic records.; RESULTS: There were 299(66.7%) HIV-infected adults and 149(33.3%) controls with mean age of 39.64± 12.45 years and 39.60±12.45 years respectively (p=0.98). In both groups, there were more participants with left hearing loss. Mild to profound hearing loss was found in 65.9% HIV- infected participants and 53.7% controls. Majority (86.3%) of the HIV-infected participants were on HAART. The mean CD4 cell count was 654.58±289.15 in 41 HIV-infected participants not on HAART and 523.95±300.17 in 258 participants on HAART (p=0.01). Majority,- 197 (62%) HIV- infected participants with hearing loss had CD4 cell count ≤200 cells/mm3. Higher viral load significantly correlated with low CD4 cell counts (p<0.0 1; r=0. 18) and low CD4 cell count significantly correlated with high hearing threshold (p<O.01; r=0. 17).; CONCLUSION: There was a trend towards more hearing loss among the HIV-infected adults. The higher hearing threshold in those with low CD4 cell counts of <200 cells/mm3 suggests possible relationship between hearing status and severity of HIV disease.",28686827,Article,Final,,Scopus,2-s2.0-85030447331
Chen G.-D.; Sheppard A.; Salvi R.,"Chen, G.-D. (7406537343); Sheppard, A. (56160036300); Salvi, R. (7005412656)",7406537343; 56160036300; 7005412656,Noise trauma induced plastic changes in brain regions outside the classical auditory pathway,2016,Neuroscience,315,,,228,245,17,35,10.1016/j.neuroscience.2015.12.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951747456&doi=10.1016%2fj.neuroscience.2015.12.005&partnerID=40&md5=346e0cd6e9f6bdab4c232329ec8b5980,"The effects of intense noise exposure on the classical auditory pathway have been extensively investigated; however, little is known about the effects of noise-induced hearing loss on non-classical auditory areas in the brain such as the lateral amygdala (LA) and striatum (Str). To address this issue, we compared the noise-induced changes in spontaneous and tone-evoked responses from multiunit clusters (MUC) in the LA and Str with those seen in auditory cortex (AC) in rats. High-frequency octave band noise (10-20. kHz) and narrow band noise (16-20. kHz) induced permanent threshold shifts at high-frequencies within and above the noise band but not at low frequencies. While the noise trauma significantly elevated spontaneous discharge rate (SR) in the AC, SRs in the LA and Str were only slightly increased across all frequencies. The high-frequency noise trauma affected tone-evoked firing rates in frequency and time-dependent manner and the changes appeared to be related to the severity of noise trauma. In the LA, tone-evoked firing rates were reduced at the high-frequencies (trauma area) whereas firing rates were enhanced at the low-frequencies or at the edge-frequency dependent on severity of hearing loss at the high frequencies. The firing rate temporal profile changed from a broad plateau to one sharp, delayed peak. In the AC, tone-evoked firing rates were depressed at high frequencies and enhanced at the low frequencies while the firing rate temporal profiles became substantially broader. In contrast, firing rates in the Str were generally decreased and firing rate temporal profiles become more phasic and less prolonged. The altered firing rate and pattern at low frequencies induced by high-frequency hearing loss could have perceptual consequences. The tone-evoked hyperactivity in low-frequency MUC could manifest as hyperacusis whereas the discharge pattern changes could affect temporal resolution and integration. © 2015 IBRO. Published by Elsevier Ltd.",26701290,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84951747456
Barman A.; Narne V.K.; Prabhu P.; Singh N.K.; Thammaiah S.,"Barman, Animesh (7003769712); Narne, Vijaya Kumar (23103700400); Prabhu, Prashanth (23095325600); Singh, Niraj Kumar (55450731300); Thammaiah, Spoorthi (57191843126)",7003769712; 23103700400; 23095325600; 55450731300; 57191843126,"Low frequency bi-syllabic wordlists in a South-Indian language, Kannada: development, standardization and validation",2017,"Hearing, Balance and Communication",15,1,,38,47,9,0,10.1080/21695717.2017.1283909,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012040245&doi=10.1080%2f21695717.2017.1283909&partnerID=40&md5=e1bbe4f6492f160100cf57f624862b01,"Objective: The present study aimed to develop, standardize and validate low frequency bi-syllabic wordlists in Kannada, a South-Indian language. Study design: The study was conducted in three different phases. The Kannada low frequency wordlists were developed in Phase I. The procedure involved collecting bi-syllabic familiar words, recording them, selecting the words dominant in low frequency energy by acoustical (Fast Fourier) transform and statistical means (k-means clustering) then generating equivalent wordlists using psychometric function. In Phase II, all the wordlists developed were standardized through estimation of speech identification scores in 100 individuals with normal hearing and through re-verification of equivalence of wordlists’ difficulty level by obtaining psychometric function. Finally, during Phase III, lists developed were evaluated for usefulness by administering them along with conventional phonemically-balanced Kannada wordlist on 10 individuals with cochlear hearing loss having rising audiometric configurations (i.e. more loss at lower frequencies). Results: Phase I resulted in development of seven psychometrically equivalent wordlists. Speech identification scores on 100 individuals with normal hearing showed mean scores greater than 95% for all the lists at 40 dB SL. No statistical difference was noted across wordlists. Further, individuals with rising cochlear hearing loss (RCHL) performed significantly poorer when compared to normal hearing counterparts across wordlists except low frequency wordlist 4 and phonemically balanced wordlist. Conclusions: The study utilized a unique procedure for the development of wordlists which can serve as guidelines for further research. The study has resulted in standardization (along with generation of normative data) and successful validation of the lists (except list 4) developed on a clinical population, i.e. individuals with RCHL. Given the lack of availability and the current clinical/research need of such test materials, the wordlists generated from this study can be useful. © 2017 International Association of Physicians in Audiology.",,Article,Final,,Scopus,2-s2.0-85012040245
Mahmoudian-Sani M.; Mehri-Ghahfarrokhi A.; Poorshahbazi G.; Asadi-Samani M.,"Mahmoudian-Sani, Mohammad (57192430290); Mehri-Ghahfarrokhi, Ameneh (56692946000); Poorshahbazi, Ghollam (57202020716); Asadi-Samani, Majid (55764352600)",57192430290; 56692946000; 57202020716; 55764352600,The application of MIR-183 family and mesenchymal stem cells: A possibility for restoring hearing loss,2017,Indian Journal of Otology,23,4,,217,221,4,0,10.4103/indianjotol.INDIANJOTOL_105_17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046703633&doi=10.4103%2findianjotol.INDIANJOTOL_105_17&partnerID=40&md5=e904221bed83c1aef8e44ceb875595d4,"Hearing loss as one of the most common disabilities approximately over 5% of the world's population - 360 million people - has disabling hearing loss (328 million adults and 32 million children). Recent developments in stem cell technology provide new opportunities for the treatment of deafness. miRNAs are essential factors of an extensively conserved posttranscriptional process controlling gene expression at mRNA level. Various biological processes such as growth and differentiation are regulated by miRNAs. In this review paper we have discussed about the application of miR-183 family and mesenchymal stem cells as a possibility for restoring hearing loss. In this regards, the web of Science and PubMed databases were searched using the Endnote software for the publications about the application of miR-183 family and mesenchymal stem cells (MSCs) to study hearing loss published from 2000 to 2016. The miR-183 family (miR-183, miR-96, and miR-182) is expressed abundantly in sensory cells in inner ear. miR-183 family is significant for the development and persistence of auditory neurons and hair cell. These four genes, i.e. Sox2, Notch1, Jag1, and Hes1, are potentially the targets of miR-183 family. In studies on animal models such as mouse and zebrafish, the time of Atoh1 expression in the hair cells was found to be the E12/5-E14/5 day, and miR-183 family was reported to begin to express on the E14/5 day. Use of human MSCs in differentiating into hair cells has been investigated, demonstrating that MSCs have neuroregenerative capacity. Cell therapy-targeting regeneration of the auditory neurons and hair cell may therefore be a powerful strategy to cure hearing loss that cannot be reversed by current therapies. A combination of the MSCs, specific growth factors and miR-183 cluster (96-182-183) can increase the potential to differentiate into the auditory neurons and hair cell. © 2017 Medknow Publications. All right reserved.",,Review,Final,,Scopus,2-s2.0-85046703633
Rahne T.; Buthut F.; Plößl S.; Plontke S.K.,"Rahne, T. (16048038900); Buthut, F. (56976282600); Plößl, S. (56339997500); Plontke, S.K. (6603541059)",16048038900; 56976282600; 56339997500; 6603541059,A software tool for pure‑tone audiometry: Classification of audiograms for inclusion of patients in clinical trials. English version; [Software-Tool für Reintonaudiometrie: Klassifizierung von Audiogrammen für den Einschluss von Patienten in klinische Studien. Englische Version],2016,HNO,64,,,1,6,5,6,10.1007/s00106-015-0089-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948131830&doi=10.1007%2fs00106-015-0089-3&partnerID=40&md5=6155b0babcc70fa9ea13547e1ca2c59b,"Objective: Selecting subjects for clinical trials on hearing loss therapies relies on the patient meeting the audiological inclusion criteria. In studies on the treatment of idiopathic sudden sensorineural hearing loss, the patient’s acute audiogram is usually compared with a previous audiogram, the audiogram of the non-affected ear, or a normal audiogram according to an ISO standard. Generally, many more patients are screened than actually fulfill the particular inclusion criteria. The inclusion criteria often require a calculation of pure-tone averages, selection of the most affected frequencies, and calculation of hearing loss differences. Materials and methods: A software tool was developed to simplify and accelerate this inclusion procedure for investigators to estimate the possible recruitment rate during the planning phase of a clinical trial and during the actual study. This tool is Microsoft Excel-based and easy to modify to meet the particular inclusion criteria of a specific clinical trial. The tool was retrospectively evaluated on 100 patients with acute hearing loss comparing the times for classifying automatically and manually. The study sample comprised 100 patients with idiopathic sudden sensorineural hearing loss. Results and conclusion: The age- and sex-related normative audiogram was calculated automatically by the tool and the hearing impairment was graded. The estimated recruitment rate of our sample was quickly calculated. Information about meeting the inclusion criteria was provided instantaneously. A significant reduction of 30 % in the time required for classifying (30 s per patient) was observed. © 2015, The Author(s).",26607156,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84948131830
Weston M.D.; Tarang S.; Pierce M.L.; Pyakurel U.; Rocha-Sanchez S.M.; McGee J.; Walsh E.J.; Soukup G.A.,"Weston, Michael D. (7102954781); Tarang, Shikha (15729679200); Pierce, Marsha L. (57215515797); Pyakurel, Umesh (57200855806); Rocha-Sanchez, Sonia M. (6508079951); McGee, JoAnn (35581811400); Walsh, Edward J. (16187659400); Soukup, Garrett A. (6603869560)",7102954781; 15729679200; 57215515797; 57200855806; 6508079951; 35581811400; 16187659400; 6603869560,"A mouse model of MIR-96, MIR-182 and MIR-183 misexpression implicates MIRNAs in cochlear cell fate and homeostasis",2018,Scientific Reports,8,1,3569,,,,10,10.1038/s41598-018-21811-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042549261&doi=10.1038%2fs41598-018-21811-1&partnerID=40&md5=110b246b9beda932ffb4db8681c39fb2,"Germline mutations in Mir96, one of three co-expressed polycistronic miRNA genes (Mir96, Mir182, Mir183), cause hereditary hearing loss in humans and mice. Transgenic FVB/NCrl-Tg(GFAP-Mir183,Mir96,Mir182)MDW1 mice (Tg1MDW), which overexpress this neurosensory-specific miRNA cluster in the inner ear, were developed as a model system to identify, in the aggregate, target genes and biologic processes regulated by the miR-183 cluster. Histological assessments demonstrate Tg1MDW/1MDW homozygotes have a modest increase in cochlear inner hair cells (IHCs). Affymetrix mRNA microarray data analysis revealed that downregulated genes in P5 Tg1MDW/1MDW cochlea are statistically enriched for evolutionarily conserved predicted miR-96, miR-182 or miR-183 target sites. ABR and DPOAE tests from 18 days to 3 months of age revealed that Tg1MDW/1MDW homozygotes develop progressive neurosensory hearing loss that correlates with histologic assessments showing massive losses of both IHCs and outer hair cells (OHCs). This mammalian miRNA misexpression model demonstrates a potency and specificity of cochlear homeostasis for one of the dozens of endogenously co-expressed, evolutionally conserved, small non-protein coding miRNA families. It should be a valuable tool to predict and elucidate miRNA-regulated genes and integrated functional gene expression networks that significantly influence neurosensory cell differentiation, maturation and homeostasis. © 2018 The Author(s).",29476110,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85042549261
Elbasi E.; Ayanoglu D.K.; Zreikat A.,"Elbasi, Ersin (12805511000); Ayanoglu, Demet Kaya (57210283099); Zreikat, Aymen (6506417283)",12805511000; 57210283099; 6506417283,Determination of Patient's Hearing Sensitivity using Data Mining Techniques,2018,"IEEE 12th International Conference on Application of Information and Communication Technologies, AICT 2018 - Proceedings",,,8746924,,,,9,10.1109/ICAICT.2018.8746924,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070203066&doi=10.1109%2fICAICT.2018.8746924&partnerID=40&md5=b6500af7b69b9f6411bff548245f83b4,"The aim of this paper is to analyse and classify an audiometric dataset belongs to 200 patients using data mining techniques. The classification task consists of the classification the data of each patient as belonging to one out of four categories (conductive type, sensorineural hearing loss, mixed type or normal). These classifications show the diverse kinds of hearing misfortune relying upon which part of the hearing way is influenced. The used dataset provides sensitivity test values of the patient's hearing sense and these tests are mostly done by an audiologist using the audiometer experiments. The audiometric tests are used to define the patient's hearing threshold level at several frequencies. The specialists often try to locate the problem of hearing path where exactly, so this characterizes the hearing problem as having a place with one of the classified groups. There are several new data mining algorithms applied in this research to classify patient hearing system. This automated system will help medical specialists to make decision. Experimental results show that Artificial Immune Recognition System (AIRS), Pruned Tree J48 and Random Forest (RF) techniques have given very promising classification results (between 99-100% accuracy) for hearing loss data set. We have better accuracy results than other traditional machine learning methods for hearing dataset. © 2018 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85070203066
Kim S.H.; Han S.-H.; Byun J.Y.; Park M.S.; Kim Y.I.; Yeo S.G.,"Kim, Sang Hoon (57761664600); Han, Seung-Ho (57221062574); Byun, Jae Yong (24079724900); Park, Moon Suh (7404490242); Kim, Young Il (58685264000); Yeo, Seung Geun (55572248100)",57761664600; 57221062574; 24079724900; 7404490242; 58685264000; 55572248100,Expression of C-type lectin receptor mRNA in chronic otitis media with cholesteatoma,2017,Acta Oto-Laryngologica,137,6,,581,587,6,6,10.1080/00016489.2016.1269196,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013743012&doi=10.1080%2f00016489.2016.1269196&partnerID=40&md5=f8a7e11a43fcd15f3810244a81b970dd,"Conclusions: The levels of expression of various C-type lectin receptors (CLRs) messenger ribo nucleic acids (mRNAs) were significantly higher in cholesteatomas than in normal skin, suggesting that these CLRs may be involved in the pathogenesis of cholesteatoma. Objectives: Altered expression of pattern recognition receptors may be associated with immune responses in patients with cholesteatoma. This study assessed the levels of expression of CLR mRNAs in normal skin and in cholesteatoma. Methods: Cholesteatoma specimens were obtained from 38 patients with acquired cholesteatoma. The levels of expression of various CLR mRNAs were assessed quantitatively using real-time RT-PCR (Reverse transcription polymerase chain reaction) and correlated with age, sex, the presence of bacteria, hearing level, frequency of surgery, and degree of ossicle destruction. Results: The levels of CD206 (cluster of differentiation 206), DEC-205 (Dendritic and epithelial cell-205), MGL (monoacylglycerol lipase), CLEC5A (C-type lectin domain family 5 member A), Dectin-2 (dendrite cell-associated C-type lectin-2), BDCA2 (Blood dendritic cell antigen 2), Mincle, DCIR (dendritic cell immunoreceptor), Dectin-1, MICL (Myeloid inhibitory C type-like lectin), and CLEC12B (C-type lectin domain family 12, member B) mRNAs were significantly higher in cholesteatoma than in control skin samples (p < 0.05). The levels of CLEC5A (C-type lectin domain family 5 member) and Dectin-1 mRNAs were significantly higher in cholesteatomas with ≥2 than ≤1 destroyed ossicles (p < 0.05), and the levels of MGL, Mincle, Dectin-1, and CLEC12B mRNAs were significantly higher in recurrent than initial cholesteatoma specimens (p < 0.05). The level of CLEC5A mRNAs was significantly higher in patients with severe than mild-to-moderate hearing loss (p < 0.05). © 2017 Acta Oto-Laryngologica AB (Ltd).",28440726,Article,Final,,Scopus,2-s2.0-85013743012
He J.; Zhu Y.; Aa J.; Smith P.F.; De Ridder D.; Wang G.; Zheng Y.,"He, Jun (57190609093); Zhu, Yejin (57215848135); Aa, Jiye (36337632600); Smith, Paul F. (7408329494); De Ridder, Dirk (7006928697); Wang, Guangji (10639401500); Zheng, Yiwen (7404837924)",57190609093; 57215848135; 36337632600; 7408329494; 7006928697; 10639401500; 7404837924,Brain metabolic changes in rats following acoustic trauma,2017,Frontiers in Neuroscience,11,MAR,148,,,,22,10.3389/fnins.2017.00148,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017095014&doi=10.3389%2ffnins.2017.00148&partnerID=40&md5=73e9b76ec1a2c953b1d7db70ce1f98aa,"Acoustic trauma is the most common cause of hearing loss and tinnitus in humans. However, the impact of acoustic trauma on system biology is not fully understood. It has been increasingly recognized that tinnitus caused by acoustic trauma is unlikely to be generated by a single pathological source, but rather a complex network of changes involving not only the auditory system but also systems related to memory, emotion and stress. One obvious and significant gap in tinnitus research is a lack of biomarkers that reflect the consequences of this interactive ""tinnitus-causing"" network. In this study, we made the first attempt to analyse brain metabolic changes in rats following acoustic trauma using metabolomics, as a pilot study prior to directly linking metabolic changes to tinnitus. Metabolites in 12 different brain regions collected from either sham or acoustic trauma animals were profiled using a gas chromatography mass spectrometry (GC/MS)-based metabolomics platform. After deconvolution of mass spectra and identification of the molecules, the metabolomic data were processed using multivariate statistical analysis. Principal component analysis showed that metabolic patterns varied among different brain regions; however, brain regions with similar functions had a similar metabolite composition. Acoustic trauma did not change the metabolite clusters in these regions. When analyzed within each brain region using the orthogonal projection to latent structures discriminant analysis sub-model, 17 molecules showed distinct separation between control and acoustic trauma groups in the auditory cortex, inferior colliculus, superior colliculus, vestibular nucleus complex (VNC), and cerebellum. Further metabolic pathway impact analysis and the enrichment overview with network analysis suggested the primary involvement of amino acid metabolism, including the alanine, aspartate and glutamate metabolic pathways, the arginine and proline metabolic pathways and the purine metabolic pathway. Our results provide the first metabolomics evidence that acoustic trauma can induce changes in multiple metabolic pathways. This pilot study also suggests that the metabolomic approach has the potential to identify acoustic trauma-specific metabolic shifts in future studies where metabolic changes are correlated with the animal's tinnitus status. © 2017 He, Zhu, Aa, Smith, De Ridder, Wang and Zheng.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85017095014
Fu X.; Zhang L.; Jin Y.; Sun X.; Zhang A.; Wen Z.; Zhou Y.; Xia M.; Gao J.,"Fu, Xiaolong (57189600139); Zhang, Linqing (57192909361); Jin, Yecheng (55605114200); Sun, Xiaoyang (56373124300); Zhang, Aizhen (56321935400); Wen, Zongzhuang (57192904516); Zhou, Yichen (57192907407); Xia, Ming (57214685249); Gao, Jiangang (56555482400)",57189600139; 57192909361; 55605114200; 56373124300; 56321935400; 57192904516; 57192907407; 57214685249; 56555482400,Loss of Myh14 Increases Susceptibility to Noise-Induced Hearing Loss in CBA/CaJ Mice,2016,Neural Plasticity,2016,,6720420,,,,25,10.1155/2016/6720420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008877292&doi=10.1155%2f2016%2f6720420&partnerID=40&md5=fb3b989b1bfba0e38a3d15c1157aad8f,"MYH14 is a member of the myosin family, which has been implicated in many motile processes such as ion-channel gating, organelle translocation, and the cytoskeleton rearrangement. Mutations in MYH14 lead to a DFNA4-type hearing impairment. Further evidence also shows that MYH14 is a candidate noise-induced hearing loss (NIHL) susceptible gene. However, the specific roles of MYH14 in auditory function and NIHL are not fully understood. In the present study, we used CRISPR/Cas9 technology to establish a Myh14 knockout mice line in CBA/CaJ background (now referred to as Myh14-/- mice) and clarify the role of MYH14 in the cochlea and NIHL. We found that Myh14-/- mice did not exhibit significant hearing loss until five months of age. In addition, Myh14-/- mice were more vulnerable to high intensity noise compared to control mice. More significant outer hair cell loss was observed in Myh14-/- mice than in wild type controls after acoustic trauma. Our findings suggest that Myh14 may play a beneficial role in the protection of the cochlea after acoustic overstimulation in CBA/CaJ mice. © 2016 Xiaolong Fu et al.",28101381,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85008877292
Ferrite S.; Mactaggart I.; Kuper H.; Oye J.; Polack S.,"Ferrite, Silvia (8286807700); Mactaggart, Islay (56255420000); Kuper, Hannah (7004023998); Oye, Joseph (22954421000); Polack, Sarah (6602403285)",8286807700; 56255420000; 7004023998; 22954421000; 6602403285,"Prevalence and causes of hearing impairment in Fundong Health District, North-West Cameroon",2017,Tropical Medicine and International Health,22,4,,485,492,7,16,10.1111/tmi.12840,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012892471&doi=10.1111%2ftmi.12840&partnerID=40&md5=30ef47ea741701de2671388d2be35e0c,"Objective: To estimate the prevalence and causes of hearing impairment in Fundong Health District, North-West Cameroon. Methods: We selected 51 clusters of 80 people (all ages) through probability proportionate to size sampling. Initial hearing screening was undertaken through an otoacoustic emission (OAE) test. Participants aged 4+ years who failed this test in both ears or for whom an OAE reading could not be taken underwent a manual pure-tone audiometry (PTA) screening. Cases of hearing impairment were defined as those with pure-tone average ≥41 dBHL in adults and ≥35 dBHL in children in the better ear, or children under age 4 who failed the OAE test in both ears. Each case with hearing loss was examined by an ear, nose and throat nurse who indicated the main likely cause. Results: We examined 3567 (86.9%) of 4104 eligible people. The overall prevalence of hearing impairment was 3.6% (95% confidence interval [CI]: 2.8–4.6). The prevalence was low in people aged 0–17 (1.1%, 0.7–1.8%) and 18–49 (1.1%, 0.5–2.6%) and then rose sharply in people aged 50+ (14.8%, 11.7–19.1%). Among cases, the majority were classified as moderate (76%), followed by severe (15%) and profound (9%). More than one-third of cases of hearing impairment were classified as unknown (37%) or conductive (37%) causes, while sensorineural causes were less common (26%). Conclusions: Prevalence of hearing impairment in North-West Cameroon is in line with the WHO estimate for sub-Saharan Africa. The majority of cases with known causes are treatable, with impacted wax playing a major role. © 2017 John Wiley & Sons Ltd",28102004,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85012892471
Kressner A.A.; Westermann A.; Buchholz J.M.; Rozell C.J.,"Kressner, Abigail A. (37088960800); Westermann, Adam (55354750600); Buchholz, Jörg M. (55764334100); Rozell, Christopher J. (6507755777)",37088960800; 55354750600; 55764334100; 6507755777,Cochlear implant speech intelligibility outcomes with structured and unstructured binary mask errors,2016,Journal of the Acoustical Society of America,139,2,,800,810,10,9,10.1121/1.4941567,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958582406&doi=10.1121%2f1.4941567&partnerID=40&md5=727cb4174a29fac8e3d5b9f6f9ea136c,"It has been shown that intelligibility can be improved for cochlear implant (CI) recipients with the ideal binary mask (IBM). In realistic scenarios where prior information is unavailable, however, the IBM must be estimated, and these estimations will inevitably contain errors. Although the effects of both unstructured and structured binary mask errors have been investigated with normal-hearing (NH) listeners, they have not been investigated with CI recipients. This study assesses these effects with CI recipients using masks that have been generated systematically with a statistical model. The results demonstrate that clustering of mask errors substantially decreases the tolerance of errors, that incorrectly removing target-dominated regions can be as detrimental to intelligibility as incorrectly adding interferer-dominated regions, and that the individual tolerances of the different types of errors can change when both are present. These trends follow those of NH listeners. However, analysis with a mixed effects model suggests that CI recipients tend to be less tolerant than NH listeners to mask errors in most conditions, at least with respect to the testing methods in each of the studies. This study clearly demonstrates that structure influences the tolerance of errors and therefore should be considered when analyzing binary-masking algorithms. © 2016 Acoustical Society of America.",26936562,Article,Final,,Scopus,2-s2.0-84958582406
Rodríguez-de la Rosa L.; Sánchez-Calderón H.; Contreras J.; Murillo-Cuesta S.; Falagan S.; Avendaño C.; Dopazo J.; Varela-Nieto I.; Milo M.,"Rodríguez-de la Rosa, Lourdes (23095591100); Sánchez-Calderón, Hortensia (6506774878); Contreras, Julio (57210466239); Murillo-Cuesta, Silvia (23094658200); Falagan, Sandra (55329332000); Avendaño, Carlos (26643623000); Dopazo, Joaquín (18133480200); Varela-Nieto, Isabel (7004650477); Milo, Marta (6506962964)",23095591100; 6506774878; 57210466239; 23094658200; 55329332000; 26643623000; 18133480200; 7004650477; 6506962964,Comparative gene expression study of the vestibular organ of the Igf1 deficient mouse using whole-transcript arrays,2015,Hearing Research,330,,,62,77,15,12,10.1016/j.heares.2015.08.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948769335&doi=10.1016%2fj.heares.2015.08.016&partnerID=40&md5=e6ea3118c7c0bda9d2d7522241084b02,"The auditory and vestibular organs form the inner ear and have a common developmental origin. Insulin like growth factor 1 (IGF-1) has a central role in the development of the cochlea and maintenance of hearing. Its deficiency causes sensorineural hearing loss in man and mice. During chicken early development, IGF-1 modulates neurogenesis of the cochleovestibular ganglion but no further studies have been conducted to explore the potential role of IGF-1 in the vestibular system. In this study we have compared the whole transcriptome of the vestibular organ from wild type and Igf1-/- mice at different developmental and postnatal times. RNA was prepared from E18.5, P15 and P90 vestibular organs of Igf1-/- and Igf1+/+ mice and the transcriptome analysed in triplicates using Affymetrix® Mouse Gene 1.1 ST Array Plates. These plates are whole-transcript arrays that include probes to measure both messenger (mRNA) and long intergenic non-coding RNA transcripts (lincRNA), with a coverage of over 28 thousand coding transcripts and over 7 thousands non-coding transcripts. Given the complexity of the data we used two different methods VSN-RMA and mmBGX to analyse and compare the data. This is to better evaluate the number of false positives and to quantify uncertainty of low signals. We identified a number of differentially expressed genes that we described using functional analysis and validated using RT-qPCR. The morphology of the vestibular organ did not show differences between genotypes and no evident alterations were observed in the vestibular sensory areas of the null mice. However, well-defined cellular alterations were found in the vestibular neurons with respect their number and size. Although these mice did not show a dramatic vestibular phenotype, we conducted a functional analysis on differentially expressed genes between genotypes and across time. This was with the aim to identify new pathways that are involved in the development of the vestibular organ as well as pathways that maybe affected by the lack of IGF-1 and be associated to the morphological changes of the vestibular neurons that we observed in the Igf1-/- mice. This article is part of a Special Issue entitled <IEB Kyoto>. © 2015 The Authors.",26341476,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84948769335
Mactaggart I.; Kuper H.; Murthy G.V.S.; Oye J.; Polack S.,"Mactaggart, Islay (56255420000); Kuper, Hannah (7004023998); Murthy, G.V.S. (56654874600); Oye, Joseph (22954421000); Polack, Sarah (6602403285)",56255420000; 7004023998; 56654874600; 22954421000; 6602403285,Measuring disability in population based surveys: The interrelationship between clinical impairments and reported functional limitations in Cameroon and India,2016,PLoS ONE,11,10,e0164470,,,,61,10.1371/journal.pone.0164470,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992156919&doi=10.1371%2fjournal.pone.0164470&partnerID=40&md5=755b424734332d3230a2b54f7bdeab78,"Purpose: To investigate the relationship between two distinct measures of disability: self-reported functional limitations and objectively-screened clinical impairments. Methods: We undertook an all age population-based survey of disability in two areas: North-West Cameroon (August/October 2013) and Telangana State, India (Feb/April 2014). Participants were selected for inclusion via two-stage cluster randomised sampling (probability proportionate to size cluster selection and compact segment sampling within clusters). Disability was defined as the presence of self-reported functional limitations across eight domains, or presence of moderate or greater clinical impairments. Clinical impairment screening comprised of visual acuity testing for vision impairment, pure tone audiometry for hearing impairment, musculoskeletal functioning assessment for musculoskeletal impairment, reported seizure history for epilepsy and reported symptoms of clinical depression (depression adults only). Information was collected using structured questionnaires, observations and examinations. Results: Self-reported disability prevalence was 5.9% (95% CI 4.7-7.4) and 7.5% (5.9-9.4) in Cameroon and India respectively. The prevalence of moderate or greater clinical impairments in the same populations were 8.4% (7.5-9.4) in Cameroon and 10.5% (9.4-11.7) in India. Overall disability prevalence (self-report and/or screened positive to a moderate or greater clinical impairment) was 10.5% in Cameroon and 12.2% in India, with limited overlap between the sub-populations identified using the two types of tools. 33% of participants in Cameroon identified to have a disability, and 45% in India, both reported functional limitations and screened positive to objectively-screened impairments, whilst the remainder were identified via one or other tool only. A large proportion of people with moderate or severe clinical impairments did not self-report functional difficulties despite reporting participation restrictions. Conclusion: Tools to assess reported functional limitation alone are insufficient to identify all persons with participation restrictions and moderate or severe clinical impairments. A self-reported functional limitation tool followed by clinical screening of all those who report any level of difficulty would identify 94% of people with disabilities in Cameroon and 95% in India, meeting the study criteria. © 2016 Mactaggart et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",27741320,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84992156919
Dettman S.J.; Dowell R.C.; Choo D.; Arnott W.; Abrahams Y.; Davis A.; Dornan D.; Leigh J.; Constantinescu G.; Cowan R.; Briggs R.J.,"Dettman, Shani Joy (6602738677); Dowell, Richard Charles (7006596173); Choo, Dawn (57211684521); Arnott, Wendy (7006691764); Abrahams, Yetta (57112464000); Davis, Aleisha (57111258200); Dornan, Dimity (22978787800); Leigh, Jaime (14524972600); Constantinescu, Gabriella (27567514700); Cowan, Robert (35551636700); Briggs, Robert J. (57203051384)",6602738677; 7006596173; 57211684521; 7006691764; 57112464000; 57111258200; 22978787800; 14524972600; 27567514700; 35551636700; 57203051384,Long-Term communication outcomes for children receiving cochlear implants younger than 12 months: A multicenter study,2016,Otology and Neurotology,37,2,,e82,e95,13,195,10.1097/MAO.0000000000000915,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957899445&doi=10.1097%2fMAO.0000000000000915&partnerID=40&md5=575bb28c5e107a9b72de2ae0d8d71886,"Objective: Examine the influence of age at implant on speech perception, language, and speech production outcomes in a large unselected paediatric cohort. Study Design: This study pools available assessment data (collected prospectively and entered into respective databases from 1990 to 2014) from three Australian centers. Patients: Children (n=403) with congenital bilateral severe to profound hearing loss who received cochlear implants under 6 years of age (excluding those with acquired onset of profound hearing loss after 12 mo, those with progressive hearing loss and those with mild/moderate/severe additional cognitive delay/disability). Main Outcome Measure(s): Speech perception; open-set words (scored for words and phonemes correct) and sentence understanding at school entry and late primary school time points. Language; PLS and PPVT standard score equivalents at school entry, CELF standard scores. Speech Production; DEAP percentage accuracy of vowels, consonants, phonemes-Total and clusters, and percentage word-intelligibility at school entry. Results: Regression analysis indicated a significant effect for age-At-implant for all outcome measures. Cognitive skills also accounted for significant variance in all outcome measures except open-set phoneme scores. ANOVA with Tukey pairwise comparisons examined group differences for children implanted younger than 12 months (Group 1), between 13 and 18 months (Group 2), between 19 and 24 months (Group 3), between 25 and 42 months (Group 4), and between 43 and 72 months (Group 5). Open-set speech perception scores for Groups 1, 2, and 3 were significantly higher than Groups 4 and 5. Language standard scores for Group 1 were significantly higher than Groups 2, 3, 4, and 5. Speech production outcomes for Group 1 were significantly higher than scores obtained for Groups 2, 3, and 4 combined. Cross tabulation and x2 tests supported the hypothesis that a greater percentage of Group 1 children (than Groups 2, 3, 4, or 5) demonstrated language performance within the normative range by school entry. Conclusions: Results support provision of cochlear implants younger than 12 months of age for children with severe to profound hearing loss to optimize speech perception and subsequent language acquisition and speech production accuracy. © 2015, Otology & Neurotology, Inc.",26756160,Conference paper,Final,,Scopus,2-s2.0-84957899445
Miyasaka Y.; Shitara H.; Suzuki S.; Yoshimoto S.; Seki Y.; Ohshiba Y.; Okumura K.; Taya C.; Tokano H.; Kitamura K.; Takada T.; Hibino H.; Shiroishi T.; Kominami R.; Yonekawa H.; Kikkawa Y.,"Miyasaka, Yuki (54409163300); Shitara, Hiroshi (6701812423); Suzuki, Sari (7405353275); Yoshimoto, Sachi (36129113100); Seki, Yuta (36542931900); Ohshiba, Yasuhiro (55228792000); Okumura, Kazuhiro (35752389700); Taya, Choji (6701592366); Tokano, Hisashi (6602855281); Kitamura, Ken (7403116884); Takada, Toyoyuki (7202751959); Hibino, Hiroshi (7007020846); Shiroishi, Toshihiko (7006576277); Kominami, Ryo (7005821098); Yonekawa, Hiromichi (7007005605); Kikkawa, Yoshiaki (7102254532)",54409163300; 6701812423; 7405353275; 36129113100; 36542931900; 55228792000; 35752389700; 6701592366; 6602855281; 7403116884; 7202751959; 7007020846; 7006576277; 7005821098; 7007005605; 7102254532,"Heterozygous mutation of Ush1g/Sans in mice causes early-onset progressive hearing loss, which is recovered by reconstituting the strain-specific mutation in Cdh23",2016,Human Molecular Genetics,25,10,ddw078,2045,2059,14,19,10.1093/hmg/ddw078,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992208934&doi=10.1093%2fhmg%2fddw078&partnerID=40&md5=d99d8f4932ff4c8f98975839b6600867,"Most clinical reports have suggested that patients with congenital profound hearing loss have recessive mutations in deafness genes, whereas dominant alleles are associated with progressive hearing loss (PHL). Jackson shaker (Ush1gjs) is a mouse model of recessive deafness that exhibits congenital profound deafness caused by the homozygous mutation of Ush1g/Sans on chromosome 11. We found that C57BL/6J-Ush1gjs/+ heterozygous mice exhibited early-onset PHL (ePHL) accompanied by progressive degeneration of stereocilia in the cochlear outer hair cells. Interestingly, ePHL did not develop in mutant mice with the C3H/HeN background, thus suggesting that other genetic factors are required for ePHL development. Therefore, we performed classical genetic analyses and found that the occurrence of ePHL in Ush1gjs/+ mice was associated with an interval in chromosome 10 that contains the cadherin 23 gene (Cdh23), which is also responsible for human deafness. To confirm this mutation effect, we generated C57BL/6J-Ush1gjs/+, Cdh23c.753A/G double-heterozygous mice by using the CRISPR/Cas9-mediated Cdh23c.753A>G knock-in method. The Cdh23c.753A/G mice harbored a one-base substitution (A for G), and the homozygous A allele caused moderate hearing loss with aging. Analyses revealed the complete recovery of ePHL and stereocilia degeneration in C57BL/6J-Ush1gjs/+ mice. These results clearly show that the development of ePHL requires at least two mutant alleles of the Ush1g and Cdh23 genes. Our results also suggest that because the SANS and CDH23 proteins form a complex in the stereocilia, the interaction between these proteins may play key roles in the maintenance of stereocilia and the prevention of ePHL. © The Author 2016. Published by Oxford University Press. All rights reserved.",26936824,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84992208934
Chen J.; Tambalo M.; Barembaum M.; Ranganathan R.; Simões-Costa M.; Bronner M.E.; Streit A.,"Chen, Jingchen (49561099700); Tambalo, Monica (55331270000); Barembaum, Meyer (6508254336); Ranganathan, Ramya (56668811900); Simões-Costa, Marcos (16065254800); Bronner, Marianne E. (7006767803); Streit, Andrea (7003295065)",49561099700; 55331270000; 6508254336; 56668811900; 16065254800; 7006767803; 7003295065,A systems-level approach reveals new gene regulatory modules in the developing ear,2017,Development (Cambridge),144,8,,1531,1543,12,19,10.1242/dev.148494,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017498780&doi=10.1242%2fdev.148494&partnerID=40&md5=965baa1393f2a0dd9e1c1d9640577060,"The inner ear is a complex vertebrate sense organ, yet it arises from a simple epithelium, the otic placode. Specification towards otic fate requires diverse signals and transcriptional inputs that act sequentially and/or in parallel. Using the chick embryo, we uncover novel genes in the gene regulatory network underlying otic commitment and reveal dynamic changes in gene expression. Functional analysis of selected transcription factors reveals the genetic hierarchy underlying the transition from progenitor to committed precursor, integrating known and novel molecular players. Our results not only characterize the otic transcriptome in unprecedented detail, but also identify new gene interactions responsible for inner ear development and for the segregation of the otic lineage from epibranchial progenitors. By recapitulating the embryonic programme, the genes and genetic sub-circuits discovered here might be useful for reprogramming naïve cells towards otic identity to restore hearing loss. © 2017. Published by The Company of Biologists Ltd.",28264836,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85017498780
Deshpande A.K.; Tan L.; Lu L.J.; Altaye M.; Holland S.K.,"Deshpande, Aniruddha K. (56591639700); Tan, Lirong (55878582500); Lu, Long J. (54403388300); Altaye, Mekibib (6603241667); Holland, Scott K. (8144410100)",56591639700; 55878582500; 54403388300; 6603241667; 8144410100,fMRI as a preimplant objective tool to predict children's postimplant auditory and language outcomes as measured by parental observations,2018,Journal of the American Academy of Audiology,29,5,,389,404,15,0,10.3766/jaaa.16149,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046355713&doi=10.3766%2fjaaa.16149&partnerID=40&md5=af9179e7c31404c635bd3faac96e11c5,"Background: The trends in cochlear implantation candidacy and benefit have changed rapidly in the last two decades. It is now widely accepted that early implantation leads to better postimplant outcomes. Although some generalizations can be made about postimplant auditory and language performance, neural mechanisms need to be studied to predict individual prognosis. Purpose: The aim of this study was to use functional magnetic resonance imaging (fMRI) to identify preimplant neuroimaging biomarkers that predict children's postimplant auditory and language outcomes as measured by parental observation/reports. Research Design: This is a pre-post correlational measures study. Study Sample: Twelve possible cochlear implant candidates with bilateral severe to profound hearing loss were recruited via referrals for a clinical magnetic resonance imaging to ensure structural integrity of the auditory nerve for implantation. Intervention: Participants underwent cochlear implantation at a mean age of 19.4 mo. All children used the advanced combination encoder strategy (ACE, Cochlear Corporation, Nucleus Freedom cochlear implants). Three participants received an implant in the right ear; one in the left ear whereas eight participants received bilateral implants. Participants' preimplant neuronal activation in response to two auditory stimuli was studied using an event-related fMRI method. Data Collection and Analysis: Blood oxygen level dependent contrast maps were calculated for speech and noise stimuli. The general linear model was used to create z-maps. The Auditory Skills Checklist (ASC) and the SKI-HI Language Development Scale (SKI-HI LDS) were administered to the parents 2 yr after implantation. A nonparametric correlation analysis was implemented between preimplant fMRI activation and postimplant auditory and language outcomes based on ASC and SKI-HI LDS. Statistical Parametric Mapping software was used to create regression maps between fMRI activation and scores on the aforementioned tests. Regression maps were overlaid on the Imaging Research Center infant template and visualized in MRIcro. Results: Regression maps revealed two clusters of brain activation for the speech versus silence contrast and five clusters for the noise versus silence contrast that were significantly correlated with the parental reports. These clusters included auditory and extra-auditory regions such as the middle temporal gyrus, supramarginal gyrus, precuneus, cingulate gyrus, middle frontal gyrus, subgyral, and middle occipital gyrus. Both positive and negative correlations were observed. Correlation values for the different clusters ranged from 20.90 to 0.95 and were significant at a corrected p value of,0.05. Correlations suggest that postimplant performance may be predicted by activation in specific brain regions. © 2018 American Academy of Audiology. All rights reserved.",29708489,Article,Final,,Scopus,2-s2.0-85046355713
"Cosetti M.K.; Pinkston J.B.; Flores J.M.; Friedmann D.R.; Jones C.B.; Roland J.T., Jr.; Waltzman S.B.","Cosetti, Maura K. (6506353550); Pinkston, James B. (7005738676); Flores, Jose M. (55788247100); Friedmann, David R. (36978083400); Jones, Callie B. (57189270150); Roland, J. Thomas (7101700375); Waltzman, Susan B. (7006482990)",6506353550; 7005738676; 55788247100; 36978083400; 57189270150; 7101700375; 7006482990,Neurocognitive testing and cochlear implantation: Insights into performance in older adults,2016,Clinical Interventions in Aging,11,,,603,613,10,80,10.2147/CIA.S100255,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967138152&doi=10.2147%2fCIA.S100255&partnerID=40&md5=661dfeb993f11d9ad98323fa7fcbc0ba,"Objective: The aim of this case series was to assess the impact of auditory rehabilitation with cochlear implantation on the cognitive function of elderly patients over time. Design: This is a longitudinal case series of prospective data assessing neurocognitive function and speech perception in an elderly cohort pre- and post-implantation. Setting: University cochlear implant center. Participants: The patients were post-lingually deafened elderly female (mean, 73.6 years; SD, 5.82; range, 67–81 years) cochlear implant recipients (n=7). Measurements: A neurocognitive battery of 20 tests assessing intellectual function, learning, short- and long-term memory, verbal fluency, attention, mental flexibility, and processing speed was performed prior to and 2–4.1 years (mean, 3.7) after cochlear implant (CI). Speech perception testing using Consonant–Nucleus–Consonant words was performed prior to implantation and at regular intervals postoperatively. Individual and aggregate differences in cognitive function pre- and post-CI were estimated. Logistic regression with cluster adjustment was used to estimate the association (%improvement or %decline) between speech understanding and years from implantation at 1 year, 2 years, and 3 years post-CI. Results: Improvements after CI were observed in 14 (70%) of all subtests administered. Declines occurred in five (25%) subtests. In 55 individual tests (43%), post-CI performance improved compared to a patient’s own performance before implantation. Of these, nine (45%) showed moderate or pronounced improvement. Overall, improvements were largest in the verbal and memory domains. Logistic regression demonstrated a significant relationship between speech perception and cognitive function over time. Five neurocognitive tests were predictive of improved speech perception following implantation. Conclusion: Comprehensive neurocognitive testing of elderly women demonstrated areas of improvement in cognitive function and auditory perception following cochlear implantation. Multiple neurocognitive tests were strongly associated with current speech perception measures. While these data shed light on the complex relationship between hearing and cognition by showing that CI may slow the expected age-related cognitive decline, further research is needed to examine the impact of hearing rehabilitation on cognitive decline. © 2016 Cosetti et al.",27274210,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84967138152
Goehring T.; Bolner F.; Monaghan J.J.M.; van Dijk B.; Zarowski A.; Bleeck S.,"Goehring, Tobias (57189595633); Bolner, Federico (57189588142); Monaghan, Jessica J.M. (26434339400); van Dijk, Bas (16242980400); Zarowski, Andrzej (6603215762); Bleeck, Stefan (23011378000)",57189595633; 57189588142; 26434339400; 16242980400; 6603215762; 23011378000,Speech enhancement based on neural networks improves speech intelligibility in noise for cochlear implant users,2017,Hearing Research,344,,,183,194,11,91,10.1016/j.heares.2016.11.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008214306&doi=10.1016%2fj.heares.2016.11.012&partnerID=40&md5=71c81a48bee8b9efc213906e7ff2afef,"Speech understanding in noisy environments is still one of the major challenges for cochlear implant (CI) users in everyday life. We evaluated a speech enhancement algorithm based on neural networks (NNSE) for improving speech intelligibility in noise for CI users. The algorithm decomposes the noisy speech signal into time-frequency units, extracts a set of auditory-inspired features and feeds them to the neural network to produce an estimation of which frequency channels contain more perceptually important information (higher signal-to-noise ratio, SNR). This estimate is used to attenuate noise-dominated and retain speech-dominated CI channels for electrical stimulation, as in traditional n-of-m CI coding strategies. The proposed algorithm was evaluated by measuring the speech-in-noise performance of 14 CI users using three types of background noise. Two NNSE algorithms were compared: a speaker-dependent algorithm, that was trained on the target speaker used for testing, and a speaker-independent algorithm, that was trained on different speakers. Significant improvements in the intelligibility of speech in stationary and fluctuating noises were found relative to the unprocessed condition for the speaker-dependent algorithm in all noise types and for the speaker-independent algorithm in 2 out of 3 noise types. The NNSE algorithms used noise-specific neural networks that generalized to novel segments of the same noise type and worked over a range of SNRs. The proposed algorithm has the potential to improve the intelligibility of speech in noise for CI users while meeting the requirements of low computational complexity and processing delay for application in CI devices. © 2016 The Authors",27913315,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85008214306
Meyer C.; Barr C.; Khan A.; Hickson L.,"Meyer, Carly (26027432100); Barr, Caitlin (56039137700); Khan, Asaduzzaman (55256015300); Hickson, Louise (7004043266)",26027432100; 56039137700; 55256015300; 7004043266,Audiologist-patient communication profiles in hearing rehabilitation appointments,2017,Patient Education and Counseling,100,8,,1490,1498,8,22,10.1016/j.pec.2017.03.022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016263329&doi=10.1016%2fj.pec.2017.03.022&partnerID=40&md5=13b9c5a2cb2125d1bf13a7a5d07b7166,"Objective To profile the communication between audiologists and patients in initial appointments on a biomedical-psychosocial continuum; and explore the associations between these profiles and 1) characteristics of the appointment and 2) patients’ decisions to pursue hearing aids. Methods Sixty-three initial hearing assessment appointments were filmed and audiologist-patient communication was coded using the Roter Interaction Analysis System. A hierarchical cluster analysis was conducted to profile audiologist-patient communication, after which regression modelling and Chi-squared analyses were conducted. Results Two distinct audiologist-patient communication profiles were identified during both the history taking phase (46 = biopsychosocial profile, 15 = psychosocial profile) and diagnosis and management planning phase (45 = expanded biomedical profile, 11 = narrowly biomedical profile). Longer appointments were significantly more likely to be associated with an expanded biomedical interaction during the diagnosis and management planning phase. No significant associations were found between audiologist-patient communication profile and patients’ decisions to pursue hearing aids. Conclusion Initial audiology consultations appear to remain clinician-centred. Three quarters of appointments began with a biopsychosocial interaction; however, 80% ended with an expanded biomedical interaction. Practice implications Findings suggest that audiologists could consider modifying their communication in initial appointments to more holistically address the needs of patients. © 2017 Elsevier B.V.",28372897,Article,Final,,Scopus,2-s2.0-85016263329
Bragg D.; Huynh N.; Ladner R.E.,"Bragg, Danielle (43660991100); Huynh, Nicholas (57192544579); Ladner, Richard E. (7005099015)",43660991100; 57192544579; 7005099015,A personalizable mobile sound detector app design for deaf and hard-of-hearing users,2016,ASSETS 2016 - Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility,,,,3,13,10,43,10.1145/2982142.2982171,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006784988&doi=10.1145%2f2982142.2982171&partnerID=40&md5=66d3023c766e3800a4ae2ca6e89ec188,"Sounds provide informative signals about the world around us. In situations where non-Auditory cues are inaccessible, it can be useful for deaf and hard-of-hearing people to be notified about sounds. Through a survey, we explored which sounds are of interest to deaf and hard-of-hearing people, and which means of notification are appropriate. Motivated by these findings, we designed a mobile phone app that alerts deaf and hard-of-hearing people to sounds they care about. The app uses training examples of personally relevant sounds recorded by the user to learn a model of those sounds. It then screens the incoming audio stream from the phone's microphone for those sounds. When it detects a sound, it alerts the user by vibrating and providing a pop-up notification. To evaluate the interface design independent of sound detection errors, we ran a Wizard-of-Oz user study, and found that the app design successfully facilitated deaf and hard-of-hearing users recording training examples. We also explored the viability of a basic machine learning algorithm for sound detection.",,Conference paper,Final,,Scopus,2-s2.0-85006784988
Zhang H.; Pan H.; Zhou C.; Wei Y.; Ying W.; Li S.; Wang G.; Li C.; Ren Y.; Li G.; Ding X.; Sun Y.; Li G.-L.; Song L.; Li Y.; Yang H.; Liu Z.,"Zhang, He (57201821609); Pan, Hong (57209107353); Zhou, Changyang (57194726654); Wei, Yu (57194450331); Ying, Wenqin (57194279782); Li, Shuting (57204271588); Wang, Guangqin (57201821844); Li, Chao (56178682400); Ren, Yifei (57204273253); Li, Gen (57201821300); Ding, Xu (57701596200); Sun, Yidi (57194729017); Li, Geng-Lin (8595887200); Song, Lei (40661926500); Li, Yixue (57192879236); Yang, Hui (57201369054); Liu, Zhiyong (56542067000)",57201821609; 57209107353; 57194726654; 57194450331; 57194279782; 57204271588; 57201821844; 56178682400; 57204273253; 57201821300; 57701596200; 57194729017; 8595887200; 40661926500; 57192879236; 57201369054; 56542067000,Simultaneous zygotic inactivation of multiple genes in mouse through crispr/cas9-mediated base editing,2018,Development (Cambridge),145,20,dev168906,,,,38,10.1242/dev.168906,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055075855&doi=10.1242%2fdev.168906&partnerID=40&md5=a1d15d2b93dab18e8b27436503bce6b6,"In vivo genetic mutation has become a powerful tool for dissecting gene function; however, multi-gene interaction and the compensatory mechanisms involved can make findings from single mutations, at best difficult to interpret, and, at worst, misleading. Hence, it is necessary to establish an efficient way to disrupt multiple genes simultaneously. CRISPR/Cas9-mediated base editing disrupts gene function by converting a protein-coding sequence into a stop codon; this is referred to as CRISPR-stop. Its application in generating zygotic mutations has not been well explored yet. Here, we first performed a proof-of-principle test by disrupting Atoh1, a gene crucial for auditory hair cell generation. Next, we individually mutated vGlut3 (Slc17a8), otoferlin (Otof) and prestin (Slc26a5), three genes needed for normal hearing function. Finally, we successfully disrupted vGlut3, Otof and prestin simultaneously. Our results show that CRISPR-stop can efficiently generate single or triple homozygous F0 mouse mutants, bypassing laborious mouse breeding. We believe that CRISPR-stop is a powerful method that will pave the way for high-throughput screening of mouse developmental and functional genes, matching the efficiency of methods available for model organisms such as Drosophila. © 2018. Published by The Company of Biologists Ltd.",30275281,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85055075855
Mahmud M.S.; Yeasin M.; Shen D.; Arnott S.R.; Alain C.; Bidelman G.M.,"Mahmud, Md Sultan (57195770993); Yeasin, Mohammed (18039042000); Shen, Dawei (14034704300); Arnott, Stephen R. (7005583955); Alain, Claude (7006562076); Bidelman, Gavin M. (26325449700)",57195770993; 18039042000; 14034704300; 7005583955; 7006562076; 26325449700,What brain connectivity patterns from EEG tell us about hearing loss: A graph theoretic approach,2018,ICECE 2018 - 10th International Conference on Electrical and Computer Engineering,,,8636698,205,208,3,10,10.1109/ICECE.2018.8636698,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062892402&doi=10.1109%2fICECE.2018.8636698&partnerID=40&md5=ed5e375867013c210bb3b06a6feb61e7,"We investigated brain connectivity patterns from the electroencephalogram (EEG) to classify and understand hearing loss using a graph theoretic approach. In particular, we investigated global and nodal graph features of normal hearing (NH) and hearing impaired (HI) participants' brain networks via functional connectivity while they responded to clear and noise-degraded speech stimuli. We found that HI listeners had higher eccentricity, diameter and characteristic path length than the NH listeners for clear speech sounds, and larger radii for noisy speech signal. Moreover, we classified groups based on these graph theoretic features using support vector machine (SVM). Maximum classifier accuracy was 85.71 % for clear speech (Fl-score=86.00%) and 71.42% (Fl=67%) for degraded speech signals, respectively. Group classification based on nodal connectivity measures was more accurate in the left brain hemisphere, consistent with the leftward laterality of auditory-linguistic processing. Our data suggest HI listeners have more extended communication pathways and less efficient information exchange among brain regions than NH, establishing new biomarkers of hearing loss based on full-brain connectivity. © 2018 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85062892402
Ramma L.; Sebothoma B.,"Ramma, Lebogang (26650068700); Sebothoma, Ben (57194068315)",26650068700; 57194068315,The prevalence of hearing impairment within the Cape Town Metropolitan area,2016,The South African journal of communication disorders = Die Suid-Afrikaanse tydskrif vir Kommunikasieafwykings,63,1,,,,,14,10.4102/sajcd.v63i1.105,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018549741&doi=10.4102%2fsajcd.v63i1.105&partnerID=40&md5=f57ba865d5f1cf37a6708fa55162e4b3,"METHOD: A cross-sectional household survey involving 2494 partcipants from 718 households was conducted between the months of February and October 2013. Random cluster sampling was used to select four health sub-districts from eight health sub-districts in the Cape Town Metropolitan area using a method of probability proportional to size (PPS). The survey was conducted according to the World Health Organization (WHO) Ear and Hearing Disorders Survey Protocol and the classifcation of hearing impairment matched the WHO's criteria for the grading of hearing impairment.; RESULTS: The overall prevalence of hearing impairment in the population of this study was 12.35% (95%CI: 11.06% - 13.64%) and prevalence of disabling hearing impairment was 4.57% (95% CI: 3.75% - 5.39%) amongst individuals ≥ 4 years old. The following factors were found to be associated with hearing impairment; male gender, age, hypertension, a history of head and neck trauma and a family history of hearing impairment.; CONCLUSION: Based on the data from communities surveyed during this study, hearing impairment is more prevalent than previously estimated based on national population census information. Interventions for the prevention of hearing impairment in these communities should focus on individuals with associated risk factors.; BACKGROUND: There is a lack of data on the prevalence of hearing impairment in South Africa. Current data is unreliable as it is based on national census information which tends to underestimate the prevalence of hearing impairment.; AIM: The aim of this study was to estimate the prevalence of hearing impairment in the Cape Town Metropolitan area and to determine factors associated with hearing impairment.",27247255,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85018549741
Meeuws M.; Pascoal D.; Bermejo I.; Artaso M.; De Ceulaer G.; Govaerts P.J.,"Meeuws, Matthias (57191903273); Pascoal, David (56731076000); Bermejo, Iñigo (55616559300); Artaso, Miguel (56407174300); De Ceulaer, Geert (6602247657); Govaerts, Paul J. (7005148990)",57191903273; 56731076000; 55616559300; 56407174300; 6602247657; 7005148990,Computer-assisted CI fitting: Is the learning capacity of the intelligent agent FOX beneficial for speech understanding?,2017,Cochlear Implants International,18,4,,198,206,8,20,10.1080/14670100.2017.1325093,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019189500&doi=10.1080%2f14670100.2017.1325093&partnerID=40&md5=33ab17a6c531566eed0f142136484e1c,"Objective: The software application FOX (‘Fitting to Outcome eXpert’) is an intelligent agent to assist in the programing of cochlear implant (CI) processors. The current version utilizes a mixture of deterministic and probabilistic logic which is able to improve over time through a learning effect. This study aimed at assessing whether this learning capacity yields measurable improvements in speech understanding. Methods: A retrospective study was performed on 25 consecutive CI recipients with a median CI use experience of 10 years who came for their annual CI follow-up fitting session. All subjects were assessed by means of speech audiometry with open set monosyllables at 40, 55, 70, and 85 dB SPL in quiet with their home MAP. Other psychoacoustic tests were executed depending on the audiologist's clinical judgment. The home MAP and the corresponding test results were entered into FOX. If FOX suggested to make MAP changes, they were implemented and another speech audiometry was performed with the new MAP. Results: FOX suggested MAP changes in 21 subjects (84%). The within-subject comparison showed a significant median improvement of 10, 3, 1, and 7% at 40, 55, 70, and 85 dB SPL, respectively. All but two subjects showed an instantaneous improvement in their mean speech audiometric score. Discussion: Persons with long-term CI use, who received a FOX-assisted CI fitting at least 6 months ago, display improved speech understanding after MAP modifications, as recommended by the current version of FOX. This can be explained only by intrinsic improvements in FOX's algorithms, as they have resulted from learning. This learning is an inherent feature of artificial intelligence and it may yield measurable benefit in speech understanding even in long-term CI recipients. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",28498083,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85019189500
Paul A.; Drecourt A.; Petit F.; Deguine D.D.; Vasnier C.; Oufadem M.; Masson C.; Bonnet C.; Masmoudi S.; Mosnier I.; Mahieu L.; Bouccara D.; Kaplan J.; Challe G.; Domange C.; Mochel F.; Sterkers O.; Gerber S.; Nitschke P.; Bole-Feysot C.; Jonard L.; Gherbi S.; Mercati O.; Ben Aissa I.; Lyonnet S.; Rötig A.; Delahodde A.; Marlin S.,"Paul, Antoine (57191472267); Drecourt, Anthony (57195990658); Petit, Floriane (57195990782); Deguine, Delphine Dupin (57195988743); Vasnier, Christelle (6506206610); Oufadem, Myriam (36988331000); Masson, Cécile (53980210900); Bonnet, Crystel (7102239653); Masmoudi, Saber (7003473163); Mosnier, Isabelle (6603953148); Mahieu, Laurence (24399421400); Bouccara, Didier (7003434874); Kaplan, Josseline (35418321400); Challe, Georges (16941200700); Domange, Christelle (57195988529); Mochel, Fanny (23005241600); Sterkers, Olivier (7005874307); Gerber, Sylvie (7102760264); Nitschke, Patrick (55881783500); Bole-Feysot, Christine (55881037400); Jonard, Laurence (22940629300); Gherbi, Souad (52363621400); Mercati, Oriane (36608501600); Ben Aissa, Ines (57217893236); Lyonnet, Stanislas (35432935300); Rötig, Agnès (7005506929); Delahodde, Agnès (6601956479); Marlin, Sandrine (7003313482)",57191472267; 57195990658; 57195990782; 57195988743; 6506206610; 36988331000; 53980210900; 7102239653; 7003473163; 6603953148; 24399421400; 7003434874; 35418321400; 16941200700; 57195988529; 23005241600; 7005874307; 7102760264; 55881783500; 55881037400; 22940629300; 52363621400; 36608501600; 57217893236; 35432935300; 7005506929; 6601956479; 7003313482,FDXR Mutations Cause Sensorial Neuropathies and Expand the Spectrum of Mitochondrial Fe-S-Synthesis Diseases,2017,American Journal of Human Genetics,101,4,,630,637,7,48,10.1016/j.ajhg.2017.09.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030711848&doi=10.1016%2fj.ajhg.2017.09.007&partnerID=40&md5=022daf41417a658442d7d2743fcd207d,"Hearing loss and visual impairment in childhood have mostly genetic origins, some of them being related to sensorial neuronal defects. Here, we report on eight subjects from four independent families affected by auditory neuropathy and optic atrophy. Whole-exome sequencing revealed biallelic mutations in FDXR in affected subjects of each family. FDXR encodes the mitochondrial ferredoxin reductase, the sole human ferredoxin reductase implicated in the biosynthesis of iron-sulfur clusters (ISCs) and in heme formation. ISC proteins are involved in enzymatic catalysis, gene expression, and DNA replication and repair. We observed deregulated iron homeostasis in FDXR mutant fibroblasts and indirect evidence of mitochondrial iron overload. Functional complementation in a yeast strain in which ARH1, the human FDXR ortholog, was deleted established the pathogenicity of these mutations. These data highlight the wide clinical heterogeneity of mitochondrial disorders related to ISC synthesis. © 2017 American Society of Human Genetics",28965846,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85030711848
Torresen J.; Iversen A.H.; Greisiger R.,"Torresen, Jim (6602518300); Iversen, Andreas Hoyer (57193705828); Greisiger, Ralf (6506505160)",6602518300; 57193705828; 6506505160,Data from past patients used to streamline adjustment of levels for cochlear implant for new patients,2017,"2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016",,,7850063,,,,3,10.1109/SSCI.2016.7850063,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015980253&doi=10.1109%2fSSCI.2016.7850063&partnerID=40&md5=de745f081afc0b2009ad98f86a6b2a4e,"Cochlear implant technology gives deaf people the ability to sense sound and speech. It consists of an electrode array inserted (implanted) in the cochlea of the ear and an external device that wirelessly connects to the electrodes. Each electrode stimulates different areas of the auditory nerve based of what frequency they represent. The sensitivity of auditory nerve fibers varies from patient to patient so upper and lower limits for each electrode must be set for each patient. Currently, this is undertaken by an operator adjusting the levels while the patient gives oral feedback. This process is both time consuming and challenging in that many patients are young children who are only partly able to provide feedback. At Oslo University Hospital, data has been collected on adjustment levels and response measurements from a number of former patients (158 have been used in this project). In this paper, we consider to what extent it is possible to predict values for new patients by using various machine learning techniques on data from previous patients. Although it is not possible to achieve fully automatic adjustments, the experiments show that a good starting point can be provided for manual adjustment. Further, the work has also shown which electrodes are most important to measure to automatically predict levels of other electrodes. © 2016 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-85015980253
Kodituwakku P.; Kodituwakku E.L.,"Kodituwakku, Piyadasa (6602564908); Kodituwakku, E. Louise (37111138800)",6602564908; 37111138800,Fetal alcohol syndrome,2016,"Neuroscience in the 21st Century: From Basic to Clinical, Second Edition",,,,3211,3232,21,0,10.1007/978-1-4939-3474-4_90,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018901503&doi=10.1007%2f978-1-4939-3474-4_90&partnerID=40&md5=601383e9684df39ec8cc75c50a817a5c,"Maternal alcohol consumption during pregnancy is known to produce a spectrum of morphological and neurocognitive outcomes in the offspring. The most severely affected on the spectrum exhibit a cluster of birth defects called fetal alcohol syndrome, which is characterized by a unique pattern of anomalies on the face, prenatal and/or postnatal growth deficiency, and evidence of central nervous system (CNS) dysfunction (Jones et al, Lancet 1:1267-1271, 1973). The characteristic pattern of malformations on the face includes a smooth philtrum, thin upper lip, and short palpebral fissures (see Fig. 1). Children with FASD are usually small in stature, with their height and weight falling below the 10th percentile. The deleterious effects of alcohol on the central nervous system are evidenced by microcephaly and cognitive and behavioral deficits. Children with prenatal alcohol exposure have also been observed to exhibit birth defects involving other systems such as cardiac (e.g., atrial and ventricular septal defects), skeletal (e.g., clinodactyly and camptodactyly), ocular (e.g., strabismus), and auditory (e.g., conductive hearing loss). However, the majority of children on the spectrum display only some or none of the above physical features but exhibit evidence of CNS dysfunction. The term, “alcohol-related neurodevelopmental disorder” (ARND), is used to label neurodevelopmental difficulties in those alcohol-exposed children without clinically discernable physical anomalies (Stratton et al (eds) Fetal alcohol syndrome: diagnosis, epidemiology, prevention, and treatment. National Academy Press, Washington, DC, 1996). Although not a diagnostic label, the term “fetal alcohol spectrum disorders” (FASDs) has been introduced to denote the full spectrum of morphological and neurocognitive outcomes resulting from prenatal alcohol exposure. While estimated prevalence rates of FAS range from.5 to 2 cases per 1,000 live births, the rate of FASD is estimated at 1 per 100. © Springer Science+Business Media, LLC 2013 and Springer Science+Business Media New York 2016.",,Book chapter,Final,,Scopus,2-s2.0-85018901503
Islinger M.; Voelkl A.; Fahimi H.D.; Schrader M.,"Islinger, Markus (6603181490); Voelkl, Alfred (6603277718); Fahimi, H. Dariush (55410219500); Schrader, Michael (22956462200)",6603181490; 6603277718; 55410219500; 22956462200,The peroxisome: an update on mysteries 2.0,2018,Histochemistry and Cell Biology,150,5,,443,471,28,179,10.1007/s00418-018-1722-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053618828&doi=10.1007%2fs00418-018-1722-5&partnerID=40&md5=40fa445482a56cfe736962fb8b9b086e,"Peroxisomes are key metabolic organelles, which contribute to cellular lipid metabolism, e.g. the β-oxidation of fatty acids and the synthesis of myelin sheath lipids, as well as cellular redox balance. Peroxisomal dysfunction has been linked to severe metabolic disorders in man, but peroxisomes are now also recognized as protective organelles with a wider significance in human health and potential impact on a large number of globally important human diseases such as neurodegeneration, obesity, cancer, and age-related disorders. Therefore, the interest in peroxisomes and their physiological functions has significantly increased in recent years. In this review, we intend to highlight recent discoveries, advancements and trends in peroxisome research, and present an update as well as a continuation of two former review articles addressing the unsolved mysteries of this astonishing organelle. We summarize novel findings on the biological functions of peroxisomes, their biogenesis, formation, membrane dynamics and division, as well as on peroxisome–organelle contacts and cooperation. Furthermore, novel peroxisomal proteins and machineries at the peroxisomal membrane are discussed. Finally, we address recent findings on the role of peroxisomes in the brain, in neurological disorders, and in the development of cancer. © 2018, The Author(s).",30219925,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85053618828
Taylor K.R.; Booth K.T.; Azaiez H.; Sloan C.M.; Kolbe D.L.; Glanz E.N.; Shearer A.E.; DeLuca A.P.; Anand V.N.; Hildebrand M.S.; Simpson A.C.; Eppsteiner R.W.; Scheetz T.E.; Braun T.A.; Huygen P.L.M.; Smith R.J.H.; Casavant T.L.,"Taylor, Kyle R. (37062196200); Booth, Kevin T. (56196413600); Azaiez, Hela (6505967691); Sloan, Christina M. (54786942200); Kolbe, Diana L. (56675936800); Glanz, Emily N. (57189263421); Shearer, A. Eliot (7005515619); DeLuca, Adam P. (25921876700); Anand, V. Nikhil (57197116442); Hildebrand, Michael S. (34570227500); Simpson, Allen C. (56504570400); Eppsteiner, Robert W. (24536850500); Scheetz, Todd E. (6603782802); Braun, Terry A. (7202108129); Huygen, Patrick L.M. (7006415660); Smith, Richard J.H. (16073972500); Casavant, Thomas L. (7005751228)",37062196200; 56196413600; 6505967691; 54786942200; 56675936800; 57189263421; 7005515619; 25921876700; 57197116442; 34570227500; 56504570400; 24536850500; 6603782802; 7202108129; 7006415660; 16073972500; 7005751228,Audioprofile surfaces: The 21st century audiogram,2016,"Annals of Otology, Rhinology and Laryngology",125,5,,361,368,7,6,10.1177/0003489415614863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966784030&doi=10.1177%2f0003489415614863&partnerID=40&md5=908ddef9d23ed6e62978115f1956ac3c,"Objective: To present audiometric data in 3 dimensions by considering age as an addition dimension. Methods: Audioprofile surfaces (APSs) were fitted to a set of audiograms by plotting each measurement of an audiogram as an independent point in 3 dimensions with the x, y, and z axes representing frequency, hearing loss in dB, and age, respectively. Results: Using the Java-based APS viewer as a standalone application, APSs were pre-computed for 34 loci. By selecting APSs for the appropriate genetic locus, a clinician can compare this APS-generated average surface to a specific patient s audiogram. Conclusion: Audioprofile surfaces provide an easily interpreted visual representation of a person s hearing acuity relative to others with the same genetic cause of hearing loss. Audioprofile surfaces will support the generation and testing of sophisticated hypotheses to further refine our understanding of the biology of hearing. © The Author(s) 2015.",26530094,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84966784030
Hunt L.; Mulwafu W.; Knott V.; Ndamala C.B.; Naunje A.W.; Dewhurst S.; Hall A.; Mortimer K.,"Hunt, Luke (56785205000); Mulwafu, Wakisa (16316845600); Knott, Victoria (56785589200); Ndamala, Chifundo B. (57192717794); Naunje, Andrew W. (56485972600); Dewhurst, Sam (57200041224); Hall, Andrew (37035982000); Mortimer, Kevin (8685854000)",56785205000; 16316845600; 56785589200; 57192717794; 56485972600; 57200041224; 37035982000; 8685854000,Prevalence of paediatric chronic suppurative otitis media and hearing impairment in rural Malawi: A cross-sectional survey,2017,PLoS ONE,12,12,e0188950,,,,29,10.1371/journal.pone.0188950,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038905907&doi=10.1371%2fjournal.pone.0188950&partnerID=40&md5=f45b050e144298ff2eb44ea323d777b2,"Objective To estimate the prevalence of World Health Organization-defined chronic suppurative otitis media (CSOM) and mild hearing impairment in a population representative sample of school-entry age children in rural Malawi. A secondary objective was to explore factors associated with CSOM in this population. Methods We performed a community-based cross-sectional study of children aged 4–6 years in Chikhwawa District, Southern Malawi, utilising a village-level cluster design. Participants underwent a structured clinical assessment, including video-otoscopy and screening audiometry. Diagnoses were made remotely by two otolaryngologists who independently reviewed clinical data and images collected in the field. Hearing impairment was classified as failure to hear a pure tone of 25dB or greater at 1, 2 or 4kHz. Results We recruited 281 children across 10 clusters. The prevalence estimates of CSOM, unilateral hearing impairment and bilateral hearing impairment were 5.4% (95%CI 2.2–8.6), 24.5% (95%CI 16.3–30.0), and 12.5% (95%CI 6.2–16.9) respectively. Middle ear disease was seen in 46.9% of children with hearing impairment. A trend towards increased risk of CSOM was observed with sleeping in a house with >2 other children. Interpretation We found a high burden of middle ear disease and preventable hearing impairment in our sample of school-entry age children in rural Malawi. There are important public health implications of these findings as CSOM and hearing impairment can affect educational outcomes, and may impact subsequent development. The identification and management of middle ear disease and hearing impairment represent major unmet needs in this population. © 2017 Hunt et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",29267304,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85038905907
Allan T.W.; Besle J.; Langers D.R.M.; Davies J.; Hall D.A.; Palmer A.R.; Adjamian P.,"Allan, Thomas W. (56201902900); Besle, Julien (24068781300); Langers, Dave R.M. (6505955275); Davies, Jeff (56621434100); Hall, Deborah A. (35229238900); Palmer, Alan R. (7401780993); Adjamian, Peyman (6506924444)",56201902900; 24068781300; 6505955275; 56621434100; 35229238900; 7401780993; 6506924444,Neuroanatomical alterations in tinnitus assessed with magnetic resonance imaging,2016,Frontiers in Aging Neuroscience,8,SEP,221,,,,36,10.3389/fnagi.2016.00221,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992153860&doi=10.3389%2ffnagi.2016.00221&partnerID=40&md5=2d02d93bf1f1ce46ea523579e7455858,"Previous studies of anatomical changes associated with tinnitus have provided inconsistent results, with some showing significant cortical and subcortical changes, while others have found effects due to hearing loss, but not tinnitus. In this study, we examined changes in brain anatomy associated with tinnitus using anatomical scans from 128 participants with tinnitus and hearing loss, tinnitus with clinically normal hearing, and non-tinnitus controls with clinically normal hearing. The groups were matched for hearing loss, age and gender. We employed voxel- and surface-based morphometry (SBM) to investigate gray and white matter volume and thickness within regions-of-interest (ROI) that were based on the results of previous studies. The largest overall effects were found for age, gender, and hearing loss. With regard to tinnitus, analysis of ROI revealed numerous small increases and decreases in gray matter and thickness between tinnitus and non-tinnitus controls, in both cortical and subcortical structures. For whole brain analysis, the main tinnitus-related significant clusters were found outside sensory auditory structures. These include a decrease in cortical thickness for the tinnitus group compared to controls in the left superior frontal gyrus (SFG), and a decrease in cortical volume with hearing loss in left Heschl's gyrus (HG). For masked analysis, we found a decrease in gray matter volume in the right Heschle's gyrus for the tinnitus group compared to the controls. We found no changes in the subcallosal region as reported in some previous studies. Overall, while some of the morphological differences observed in this study are similar to previously published findings, others are entirely different or even contradict previous results. We highlight other discrepancies among previous results and the increasing need for a more precise subtyping of the condition. ï¿½ 2016 Allan, Besle, Langers, Davies,Hall, Palmer and Adjamian.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84992153860
Schlittenlacher J.; Turner R.E.; Moore B.C.J.,"Schlittenlacher, Josef (36635228400); Turner, Richard E. (57214257840); Moore, Brian C. J. (57203291320)",36635228400; 57214257840; 57203291320,Audiogram estimation using Bayesian active learning,2018,Journal of the Acoustical Society of America,144,1,,421,430,9,24,10.1121/1.5047436,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051116924&doi=10.1121%2f1.5047436&partnerID=40&md5=492b1864a10b07886b3d06d48e239737,"Two methods for estimating audiograms quickly and accurately using Bayesian active learning were developed and evaluated. Both methods provided an estimate of threshold as a continuous function of frequency. For one method, six successive tones with decreasing levels were presented on each trial and the task was to count the number of tones heard. A Gaussian Process was used for classification and maximum-information sampling to determine the frequency and levels of the stimuli for the next trial. The other method was based on a published method using a Yes/No task but extended to account for lapses. The obtained audiograms were compared to conventional audiograms for 40 ears, 19 of which were hearing impaired. The threshold estimates for the active-learning methods were systematically from 2 to 4 dB below (better than) those for the conventional audiograms, which may indicate a less conservative response criterion (a greater willingness to respond for a given amount of sensory information). Both active-learning methods were able to allow for wrong button presses (due to lapses of attention) and provided accurate audiogram estimates in less than 50 trials or 4 min. For a given level of accuracy, the counting task was slightly quicker than the Yes/No task. © 2018 Acoustical Society of America.",30075695,Article,Final,,Scopus,2-s2.0-85051116924
Norman-Haignere S.V.; Albouy P.; Caclin A.; McDermott J.H.; Kanwisher N.G.; Tillmann B.,"Norman-Haignere, Sam V. (37051186800); Albouy, Philippe (55682546200); Caclin, Anne (15519602000); McDermott, Josh H. (7202518254); Kanwisher, Nancy G. (7007112379); Tillmann, Barbara (7005560313)",37051186800; 55682546200; 15519602000; 7202518254; 7007112379; 7005560313,Pitch-responsive cortical regions in congenital amusia,2016,Journal of Neuroscience,36,10,,2986,2994,8,44,10.1523/JNEUROSCI.2705-15.2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960338355&doi=10.1523%2fJNEUROSCI.2705-15.2016&partnerID=40&md5=b69c9cc37eee37c01f8539e781f2ccfb,"Congenital amusia is a lifelong deficit in music perception thought to reflect an underlying impairment in the perception and memory of pitch. The neural basis of amusic impairments is actively debated. Some prior studies have suggested that amusia stems from impaired connectivity between auditory and frontal cortex. However, it remains possible that impairments in pitch coding within auditory cortex also contribute to the disorder, in part because prior studies have not measured responses from the cortical regions most implicated in pitch perception in normal individuals. We addressed this question by measuring fMRI responses in 11 subjects with amusia and 11 ageand education-matched controls to a stimulus contrast that reliably identifies pitch-responsive regions in normal individuals: harmonic tones versus frequency-matched noise. Our findings demonstrate that amusic individuals with a substantial pitch perception deficit exhibit clusters of pitch-responsive voxels that are comparable in extent, selectivity, and anatomical location to those of control participants. Wediscuss possible explanations for why amusics might be impaired at perceiving pitch relations despite exhibiting normal fMRI responses to pitch in their auditory cortex: (1) individual neurons within the pitch-responsive region might exhibit abnormal tuning or temporal coding not detectable with fMRI, (2) anatomical tracts that link pitch-responsive regions to other brain areas (e.g., frontal cortex) might be altered, and (3) cortical regions outside of pitch-responsive cortex might be abnormal. The ability to identify pitch-responsive regions in individual amusic subjects will make it possible to ask more precise questions about their role in amusia in future work. © 2016 the authors.",26961952,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84960338355
Greenberg B.; Carlos M.,"Greenberg, Benjamin (57204647493); Carlos, Megan (57204648619)",57204647493; 57204648619,Psychometric properties and factor structure of a new scale to measure hyperacusis: Introducing the inventory of hyperacusis symptoms,2018,Ear and Hearing,39,5,,1025,1034,9,35,10.1097/AUD.0000000000000583,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056522875&doi=10.1097%2fAUD.0000000000000583&partnerID=40&md5=55cf1532e958fc85a4dbb13d032b0d13,"Objectives: Despite increasing interest in hyperacusis and other disorders of auditory sensitivity, there is still a lack of valid, standardized assessment tools to measure symptom severity, treatment outcomes, and diagnostic differentiation. Accordingly, this study sought to create a new scale that is reliable, valid, brief, and easy to score with the purpose of filling this gap. Design: Original items were constructed through review of currently existing models of hyperacusis measurement, as well as qualitative data collected from professional audiologists and individuals reporting heightened audiological sensitivity with tinnitus. An initial 26-item scale yielded sound reliability and validity properties. Refinement based on review of initial data resulted in a 25-question second version with a maximum score of 100. A total of 450 completed survey protocols were analyzed from 469 refined Inventory of Hyperacusis Symptoms (IHS) administrations collected online, representing individuals from 37 countries with a mean age of 34.8 years. Results: Internal consistency reliability analysis yielded a Cronbach's α of 0.93, indicating excellent reliability. Furthermore, the IHS showed sound convergent validity with established measures of quality of life, anxiety, and depression in bivariate correlation analysis of Pearson's r. Factor analysis revealed a dimensional structure containing five factors, which were designated psychosocial impact, emotional arousal, functional impact, general loudness, and communication. Analysis of variance between perceived global hyperacusis severity categories provided a preliminary framework for scoring thresholds. Although the level of hearing loss did not correlate with IHS scores, increased tinnitus symptoms were a significant factor in predicting hyperacusis distress and severity. Conclusions: These initial results demonstrated sound statistical properties of the IHS and usefulness as a hyperacusis measurement tool in research and clinical practice. Factor structure and scale dimensions allow for differentiation between subtypes of loudness, annoyance, fear, and pain based on responses to clusters of specific items within the dimensional factor structure of the scale, and may thus prove useful in clinical practice and research. Copyright © 2018 Wolters Kluwer Health, Inc. All rights reserved • Printed in the U.S.A.",29742543,Article,Final,,Scopus,2-s2.0-85056522875
Mahboubi H.; Lin H.W.; Bhattacharyya N.,"Mahboubi, Hossein (45761408900); Lin, Harrison W. (56668042000); Bhattacharyya, Neil (7102522026)",45761408900; 56668042000; 7102522026,"Prevalence, characteristics, and treatment patterns of hearing difficulty in the United States",2018,JAMA Otolaryngology - Head and Neck Surgery,144,1,,65,70,5,42,10.1001/jamaoto.2017.2223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041093745&doi=10.1001%2fjamaoto.2017.2223&partnerID=40&md5=64439f90873e25aafb7f13ac2e42c5f4,"Importance: Hearing loss is one of the most prevalent chronic conditions in the United States and has been associated with negative physical, social, cognitive, economic, and emotional consequences. Despite the high prevalence of hearing loss, substantial gaps in the utilization of amplification options, including hearing AIDS and cochlear implants (CI), have been identified. Objective: To investigate the contemporary prevalence, characteristics, and patterns of specialty referral, evaluation, and treatment of hearing difficulty among adults in the United States. Design, Setting, and Participants: A cross-sectional analysis of responses from a nationwide clustered representative sample of adults who participated in the 2014 National Health Interview Survey and responded to the hearing module questions was carried out. Main Outcomes and Measures: Data regarding demographics aswell as self-reported hearing status, functional hearing, laterality, onset, and primary cause of the hearing loss were collected. In addition, specific data regarding hearing-related clinician visits, hearing tests, referrals to hearing specialist, and utilization of hearing AIDS and CIs were analyzed. Results: Among 239.6 million adults, 40.3 million (16.8%) indicated their hearing was less than ""excellent/good,"" ranging from ""a little trouble hearing"" to ""deaf."" The mean (SD) age of participants was 47 (0.2) years with 48.2%being men and 51.8%women. Approximately 48.8 million (20.6%) had visited a physician for hearing problems in the preceding 5 years. Of these, 32.6%were referred to an otolaryngologist and 27.3%were referred to an audiologist. Functional hearing was reported as the ability to hear ""whispering"" or ""normal voice"" (225.4 million; 95.5%), to ""only hear shouting"" (8.0 million; 3.4%), and ""not appreciating shouting"" (2.8 million; 1.1%). Among the last group, 5.3%were recommended to have a CI, of which 22.1% had received one. Of the adults who indicated their hearing from ""a little trouble hearing"" to being ""deaf,"" 12.9 million (32.2%) had never seen a clinician for hearing problems and 11.1 million (28.0%) had never had their hearing tested. Conclusions and Relevance: There are considerable gaps between self-reported hearing loss and patients receiving medical evaluation and recommended treatments for hearing loss. Improved awareness regarding referrals to otolaryngologists and audiologists as well as auditory rehabilitative options among clinicians may improve hearing loss care. © 2017 American Medical Association. All rights reserved.",29167904,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85041093745
Cai T.; McPherson B.; Li C.; Yang F.,"Cai, Ting (57191921127); McPherson, Bradley (7006800770); Li, Caiwei (57193417851); Yang, Feng (57191867132)",57191921127; 7006800770; 57193417851; 57191867132,Tone perception in Mandarin-speaking school age children with otitis media with effusion,2017,PLoS ONE,12,8,e0183394,,,,2,10.1371/journal.pone.0183394,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028045144&doi=10.1371%2fjournal.pone.0183394&partnerID=40&md5=212b9149a53b924327dea5ea85c54acb,"Objectives: The present study explored tone perception ability in school age Mandarin-speaking      children      with otitis media with effusion (OME) in noisy listening environments.      The study      investigated the interaction effects of noise, tone type, age, and hearing      status      on monaural tone perception, and assessed the application of a hierarchical      clustering      algorithm for profiling hearing impairment in children with OME. Methods:      Forty-one      children with normal hearing and normal middle ear status and 84 children      with      OME with or without hearing loss participated in this study. The children with      OME      were further divided into two subgroups based on their severity and pattern      of      hearing loss using a hierarchical clustering algorithm. Monaural tone recognition      was      measured using a picture-identification test format incorporating six sets of      monosyllabic      words conveying four lexical tones under speech spectrum noise, with      the signal-to-noise      ratio (SNR) conditions ranging from -9 to -21 dB. Results: Linear      correlation      indicated tone recognition thresholds of children with OME were significantly      correlated      with age and pure tone hearing thresholds at every frequency tested. Children      with      hearing thresholds less affected by OME performed similarly to their peers with      normal      hearing. Tone recognition thresholds of children with auditory status more      affected      by OME were significantly inferior to those of children with normal hearing      or      with minor hearing loss. Younger children demonstrated poorer tone recognition      performance      than older children with OME. A mixed design repeated-measure ANCOVA      showed      significant main effects of listening condition, hearing status, and tone      type      on tone recognition. Contrast comparisons revealed that tone recognition scores      were      significantly better under -12 dB SNR than under -15 dB SNR conditions and tone      recognition      scores were significantly worse under -18 dB SNR than those obtained      under -15      dB SNR conditions. Tone 1 was the easiest tone to identify and Tone 3 was      the      most difficult tone to identify for all participants, when considering -12, -15,      and      -18 dB SNR as within-subject variables. The interaction effect between hearing      status      and tone type indicated that children with greater levels of OME-related hearing      loss      had more impaired tone perception of Tone 1 and Tone 2 compared to their peers      with      lesser levels of OME-related hearing loss. However, tone perception of Tone      3      and Tone 4 remained similar among all three groups. Tone 2 and Tone 3 were the      most      perceptually difficult tones for children with or without OME-related hearing      loss      in all listening conditions. Conclusions: The hierarchical clustering algorithm      demonstrated      usefulness in risk stratification for tone perception deficiency in      children      with OME-related hearing loss. There was marked impairment in tone perception      in      noise for children with greater levels of OME-related hearing loss. Monaural      lexical      tone perception in younger children was more vulnerable to noise and OME-related      hearing      loss than that in older children. © 2017 Cai et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",28829840,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85028045144
Yamamura D.; Sano A.; Tateno T.,"Yamamura, Daiki (57191728784); Sano, Ayaka (57193140464); Tateno, Takashi (7006831936)",57191728784; 57193140464; 7006831936,An analysis of current source density profiles activated by local stimulation in the mouse auditory cortex in vitro,2017,Brain Research,1659,,,96,112,16,8,10.1016/j.brainres.2017.01.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011016321&doi=10.1016%2fj.brainres.2017.01.021&partnerID=40&md5=c0dbd886030a58247a4d146f064b1994,"To examine local network properties of the mouse auditory cortex in vitro, we recorded extracellular spatiotemporal laminar profiles driven by short electric local stimulation on a planar multielectrode array substrate. The recorded local field potentials were subsequently evaluated using current source density (CSD) analysis to identify sources and sinks. Current sinks are thought to be an indicator of net synaptic current in the small volume of cortex surrounding the recording site. Thus, CSD analysis combined with multielectrode arrays enabled us to compare mean synaptic activity in response to small current stimuli on a layer-by-layer basis. We also used senescence-accelerated mice (SAM), some strains of which show earlier onset of age-related hearing loss, to examine the characteristic spatiotemporal CSD profiles stimulated by electrodes in specific cortical layers. Thus, the CSD patterns were classified into several clusters based on stimulation sites in the cortical layers. We also found some differences in CSD patterns between the two SAM strains in terms of aging according to principle component analysis with dimension reduction. For simultaneous two-site stimulation, we modeled the obtained CSD profiles as a linear superposition of the CSD profiles to individual single-site stimulation. The model analysis indicated the nonlinearity of spatiotemporal integration over stimulus-driven activity in a layer-specific manner. Finally, on the basis of these results, we discuss the auditory cortex local network properties and the effects of aging on these mouse strains. © 2017 Elsevier B.V.",28119054,Article,Final,,Scopus,2-s2.0-85011016321
Barbour D.L.,"Barbour, Dennis L. (7003532294)",7003532294,Formal idiographic inference in medicine,2018,JAMA Otolaryngology - Head and Neck Surgery,144,6,,467,468,1,4,10.1001/jamaoto.2018.0254,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049412412&doi=10.1001%2fjamaoto.2018.0254&partnerID=40&md5=a6e727bce4d243c08295c08e65ee00e5,[No abstract available],29801065,Note,Final,,Scopus,2-s2.0-85049412412
Aldaz G.; Puria S.; Leifer L.J.,"Aldaz, Gabriel (56100692500); Puria, Sunil (6603522130); Leifer, Larry J. (7005163298)",56100692500; 6603522130; 7005163298,Smartphone-based system for learning and inferring hearing aid settings,2016,Journal of the American Academy of Audiology,27,9,,732,749,17,24,10.3766/jaaa.15099,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991489122&doi=10.3766%2fjaaa.15099&partnerID=40&md5=6a4912ac57429e5e40fc222bebce46d7,"Background: Previous research has shown that hearing aid wearers can successfully self-train their instruments' gain-frequency response and compression parameters in everyday situations. Combining hearing aids with a smartphone introduces additional computing power, memory, and a graphical user interface that may enable greater setting personalization. To explore the benefits of self-training with a smartphone-based hearing system, a parameter space was chosen with four possible combinations of microphone mode (omnidirectional and directional) and noise reduction state (active and off). The baseline for comparison was the ""untrained system,"" that is, the manufacturer's algorithm for automatically selecting microphone mode and noise reduction state based on acoustic environment. The ""trained system"" first learned each individual's preferences, self-entered via a smartphone in real-world situations, to build a trained model. The system then predicted the optimal setting (among available choices) using an inference engine, which considered the trained model and current context (e.g., sound environment, location, and time). Purpose: To develop a smartphone-based prototype hearing system that can be trained to learn preferred user settings. Determine whether user study participants showed a preference for trained over untrained system settings. Research Design: An experimental within-participants study. Participants used a prototype hearing system - comprising two hearing aids, Android smartphone, and body-worn gateway device - for ~6 weeks. Study Sample: Sixteen adults with mild-to-moderate sensorineural hearing loss (HL) (ten males, six females; mean age = 55.5 yr). Fifteen had ≥ 6 mo of experience wearing hearing aids, and 14 had previous experience using smartphones. Intervention: Participants were fitted and instructed to perform daily comparisons of settings (""listening evaluations"") through a smartphone-based software application called Hearing Aid Learning and Inference Controller (HALIC). In the four-week-long training phase, HALIC recorded individual listening preferences along with sensor data from the smartphone - including environmental sound classification, sound level, and location - to build trained models. In the subsequent two-week-long validation phase, participants performed blinded listening evaluations comparing settings predicted by the trained system (""trained settings"") to those suggested by the hearing aids' untrained system (""untrained settings""). Data Collection and Analysis: We analyzed data collected on the smartphone and hearing aids during the study. We also obtained audiometric and demographic information. Results: Overall, the 15 participants with valid data significantly preferred trained settings to untrained settings (paired-samples t test). Seven participants had a significant preference for trained settings, while one had a significant preference for untrained settings (binomial test). The remaining seven participants had nonsignificant preferences. Pooling data across participants, the proportion of times that each setting was chosen in a given environmental sound class was on average very similar. However, breaking down the data by participant revealed strong and idiosyncratic individual preferences. Fourteen participants reported positive feelings of clarity, competence, and mastery when training via HALIC. Conclusions: The obtained data, as well as subjective participant feedback, indicate that smartphones could become viable tools to train hearing aids. Individuals who are tech savvy and have milder HL seem well suited to take advantages of the benefits offered by training with a smartphone.",27718350,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84991489122
Abdala C.; Kalluri R.,"Abdala, Carolina (57213738124); Kalluri, Radha (35869702000)",57213738124; 35869702000,Towards a joint reflection-distortion otoacoustic emission profile: Results in normal and impaired ears,2017,Journal of the Acoustical Society of America,142,2,,812,824,12,18,10.1121/1.4996859,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027272144&doi=10.1121%2f1.4996859&partnerID=40&md5=98c4843aac85e31c3299a9741c5f7a03,"Otoacoustic emissions (OAEs) provide salient information about cochlear function and dysfunction. Two broad classes of emissions, linear reflection and nonlinear distortion, arise via distinct cochlear processes and hence, appear to provide independent information about cochlear health and hearing. Considered in combination, these two OAE types may characterize sensory hearing loss most effectively. In this study, the level-dependent growth of stimulus-frequency OAEs (a reflection-type emission) and distortion-product OAEs (a distortion-type emission) were measured in ten normal-hearing ears and eight ears with slight-to-moderate sensorineural hearing loss. Metrics of OAE strength and compression were derived from OAE input/output functions and then considered in a combined fashion. Results indicate that SFOAEs and DPOAEs differ significantly in their strength and compression features. When SFOAE and DPOAE metrics are displayed together on a two-dimensional plot, relatively well-defined data clusters describe their normative relationship. In hearing-impaired ears, this relationship is disrupted but not in a uniform way across ears; ears with similar audiograms showed differently altered joint-OAE profiles. Hearing loss sometimes affected only one OAE or one more than the other. Results suggest a joint-OAE profile is promising and warrants study in a large group of subjects with sensory hearing loss of varied etiologies. © 2017 Acoustical Society of America.",28863614,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85027272144
Tan L.; Holland S.K.; Deshpande A.K.; Chen Y.; Choo D.I.; Lu L.J.,"Tan, Lirong (55878582500); Holland, Scott K. (8144410100); Deshpande, Aniruddha K. (56591639700); Chen, Ye (55330145300); Choo, Daniel I. (7004288603); Lu, Long J. (54403388300)",55878582500; 8144410100; 56591639700; 55330145300; 7004288603; 54403388300,A semi-supervised Support Vector Machine model for predicting the language outcomes following cochlear implantation based on pre-implant brain fMRI imaging,2015,Brain and Behavior,5,12,,1,25,24,27,10.1002/brb3.391,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954364514&doi=10.1002%2fbrb3.391&partnerID=40&md5=cc32b706a95747189a11ad437f3adf96,"Introduction: We developed a machine learning model to predict whether or not a cochlear implant (CI) candidate will develop effective language skills within 2 years after the CI surgery by using the pre-implant brain fMRI data from the candidate. Methods: The language performance was measured 2 years after the CI surgery by the Clinical Evaluation of Language Fundamentals-Preschool, Second Edition (CELF-P2). Based on the CELF-P2 scores, the CI recipients were designated as either effective or ineffective CI users. For feature extraction from the fMRI data, we constructed contrast maps using the general linear model, and then utilized the Bag-of-Words (BoW) approach that we previously published to convert the contrast maps into feature vectors. We trained both supervised models and semi-supervised models to classify CI users as effective or ineffective. Results: Compared with the conventional feature extraction approach, which used each single voxel as a feature, our BoW approach gave rise to much better performance for the classification of effective versus ineffective CI users. The semi-supervised model with the feature set extracted by the BoW approach from the contrast of speech versus silence achieved a leave-one-out cross-validation AUC as high as 0.97. Recursive feature elimination unexpectedly revealed that two features were sufficient to provide highly accurate classification of effective versus ineffective CI users based on our current dataset. Conclusion: We have validated the hypothesis that pre-implant cortical activation patterns revealed by fMRI during infancy correlate with language performance 2 years after cochlear implantation. The two brain regions highlighted by our classifier are potential biomarkers for the prediction of CI outcomes. Our study also demonstrated the superiority of the semi-supervised model over the supervised model. It is always worthwhile to try a semi-supervised model when unlabeled data are available. © 2015 Published by Wiley Periodicals, Inc.",26807332,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84954364514
Salehi H.; Suelzle D.; Folkeard P.; Parsa V.,"Salehi, Haniyeh (57169931900); Suelzle, David (35076487200); Folkeard, Paula (55503455900); Parsa, Vijay (7004309682)",57169931900; 35076487200; 55503455900; 7004309682,Learning-based reference-free speech quality measures for hearing aid applications,2018,IEEE/ACM Transactions on Audio Speech and Language Processing,26,12,8423164,2277,2288,11,13,10.1109/TASLP.2018.2860786,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050761034&doi=10.1109%2fTASLP.2018.2860786&partnerID=40&md5=9eabc118eb9a6aa0b1b303019c838e6c,"Objective measures of speech quality are highly desirable in benchmarking and monitoring the performance of hearing aids (HAs). Existing HA speech quality indices such as the hearing aid speech quality index (HASQI) are intrusive in that they require a properly time-aligned and frequency-shaped reference signal to predict the quality of HA output. Two new reference-free HA speech quality indices are proposed in this paper, based on a model that amalgamates perceptual linear prediction (PLP), hearing loss (HL) modeling, and machine learning concepts. For the first index, HL-modified PLP coefficients and their statistics were used as the feature set, which was subsequently mapped to the predicted quality scores using support vector regression (SVR). For the second index, HL-impacted gammatone auditory filterbank energies and their second-order statistics constituted the feature set, which was again mapped using SVR. Two databases involving HA recordings were collected and utilized for the evaluation of the robustness and generalizability of the two indices. Experimental results showed that the index based on the gammatone filterbank energies not only correlated well with HA quality ratings by hearing impaired listeners, but also exhibited robust performance across different test conditions and was comparable to the full-reference HASQI performance. © 2018 IEEE.",,Article,Final,,Scopus,2-s2.0-85050761034
Panniello M.; King A.J.; Dahmen J.C.; Walker K.M.M.,"Panniello, Mariangela (57201797565); King, Andrew J. (26642878800); Dahmen, Johannes C. (15843000200); Walker, Kerry M. M. (23391107500)",57201797565; 26642878800; 15843000200; 23391107500,Local and global spatial organization of interaural level difference and frequency preferences in auditory cortex,2018,Cerebral Cortex,28,1,,350,369,19,20,10.1093/cercor/bhx295,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046086325&doi=10.1093%2fcercor%2fbhx295&partnerID=40&md5=2e0b53a0438d1df724e64a5a0ecc5c19,"Despite decades of microelectrode recordings, fundamental questions remain about how auditory cortex represents sound-source location. Here, we used in vivo 2-photon calcium imaging to measure the sensitivity of layer II/III neurons in mouse primary auditory cortex (A1) to interaural level differences (ILDs), the principal spatial cue in this species. Although most ILD-sensitive neurons preferred ILDs favoring the contralateral ear, neurons with either midline or ipsilateral preferences were also present. An opponent-channel decoder accurately classified ILDs using the difference in responses between populations of neurons that preferred contralateral-ear-greater and ipsilateral-ear-greater stimuli. We also examined the spatial organization of binaural tuning properties across the imaged neurons with unprecedented resolution. Neurons driven exclusively by contralateral ear stimuli or by binaural stimulation occasionally formed local clusters, but their binaural categories and ILD preferences were not spatially organized on a more global scale. In contrast, the sound frequency preferences of most neurons within local cortical regions fell within a restricted frequency range, and a tonotopic gradient was observed across the cortical surface of individual mice. These results indicate that the representation of ILDs in mouse A1 is comparable to that of most other mammalian species, and appears to lack systematic or consistent spatial order. © The Author 2017.",29136122,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85046086325
Demeester K.; Topsakal V.; Hendrickx J.-J.; Fransen E.; Van Laer L.; Van Camp G.; Van De Heyning P.; Van Wieringen A.,"Demeester, Kelly (22134112300); Topsakal, Vedat (22137091700); Hendrickx, Jan-Jaap (7007161763); Fransen, Erik (7004158064); Van Laer, Lut (57194695768); Van Camp, Guy (34573802800); Van De Heyning, Paul (7005171191); Van Wieringen, Astrid (22942685800)",22134112300; 22137091700; 7007161763; 7004158064; 57194695768; 34573802800; 7005171191; 22942685800,"Hearing disability measured by the speech, spatial, and qualities of hearing scale in clinically normal-hearing and hearing-impaired middle-aged persons, and disability screening by means of a reduced SSQ (the SSQ5)",2012,Ear and Hearing,33,5,,615,626,11,83,10.1097/AUD.0b013e31824e0ba7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865803515&doi=10.1097%2fAUD.0b013e31824e0ba7&partnerID=40&md5=9ae9b7d816c014d0117b8e3c88ce77c1,"OBJECTIVES:: The goals of the present study were twofold: in the first part, the prevalence and profile of hearing disability in healthy, middle-aged persons were determined by the speech, spatial, and qualities of hearing scale (SSQ). In the second part of this study, the number of SSQ items was reduced to five to make this questionnaire available for routine usage in clinical settings and for screening purposes. METHODS:: SSQ responses derived from 103 normal-hearing 18- to 25-year-old persons were compared with the SSQ responses of 24 clinically normal-hearing (all thresholds between 125 and 8000 Hz ≤25 dB HL) and 109 healthy, 55- to 65-year-old persons with age-related hearing impairment to determine the prevalence and profile of hearing disability. The 45 items of the SSQ were reduced to five by cluster analyses and binary logistic regression analyses. The robustness of this five-item version (SSQ5) was determined in three control populations: an adult 25- to 55-year-old population (n = 159), an ENT-patient population (n = 60), and a population of hearing aid candidates (n = 50). The feasibility of the SSQ5 for screening was compared with the feasibility of the simple question ""Do you have hearing loss?"" by determining, respectively, the sensitivity, specificity, and maximum achievable discriminatory power for predicting hearing status according to speech-in-noise performance. RESULTS:: Prevalence numbers showed data of healthy, middle-aged persons with significant disability, despite minimal impairment (25%) versus data of middle-aged persons with significant impairment and nevertheless, minimal disability (61%). The profile of hearing disability seemed similar in all normal-hearing and hearing-impaired subgroups (i.e., most problems with understanding speech especially in noise conditions, and least problems with sound quality). Compared with the single question: ""Do you have hearing loss?"" the use of the SSQ5 had 37% more maximum discriminatory power for determining hearing status category based on speech-in-noise performance in 55- to 65-year-old persons. In addition, the SSQ5 seemed robust in adult populations of different ages (89.6% correlation between the answers of the SSQ5 and SSQ45), as well as in ENT-patient populations (93.7% correlation) and hearing aid candidate populations (79.2% correlation). CONCLUSIONS:: The results of this study suggest that disability measures and measures for hearing impairment cannot replace each other, but are complementary. Therefore, it is advised to implement both disability measures and impairment measures in screening and referral policies for hearing loss. To get a first impression of hearing disability, our results suggest that it is useful to ask five disability questions (SSQ5) instead of one general question like ""Do you have hearing loss?"". Copyright © 2012 by Lippincott Williams & Wilkins.",22568994,Article,Final,,Scopus,2-s2.0-84865803515
Gordon K.A.; Tanaka S.; Wong D.D.E.; Stockley T.; Ramsden J.D.; Brown T.; Jewell S.; Papsin B.C.,"Gordon, K.A. (56262823700); Tanaka, S. (56301842300); Wong, D.D.E. (24598422900); Stockley, T. (6603460973); Ramsden, J.D. (35973486000); Brown, T. (26632800300); Jewell, S. (35810539500); Papsin, B.C. (7007086575)",56262823700; 56301842300; 24598422900; 6603460973; 35973486000; 26632800300; 35810539500; 7007086575,Multiple effects of childhood deafness on cortical activity in children receiving bilateral cochlear implants simultaneously,2011,Clinical Neurophysiology,122,4,,823,833,10,24,10.1016/j.clinph.2010.10.037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952311624&doi=10.1016%2fj.clinph.2010.10.037&partnerID=40&md5=163e6969121b444bb10b048a6fe04233,"Objective: Auditory development is disrupted without normal hearing but might proceed to some extent depending on the type and onset of deafness. We therefore hypothesized that activity in the auditory cortex would be highly variable in children who are deaf. Methods: To answer this, activity in the deaf brain was evoked by electrical pulses from newly provided bilateral cochlear implants (CIs) in 72 children (n=144 responses). Results: Responses were categorized by visual inspection into 3 main types which were validated by principal component cluster analyses; 49% had a negative amplitude wave similar to that previously reported in pre-term infants, 26% were dominated by a positive peak typical of responses in young normal hearing children and experienced paediatric CI users, 25% were novel multi-peaked responses. No significant demographic differences, including duration and onset of deafness, were found between response types. However, children with severe biallelic mutations of GJB-2 showed predominately negative peak type responses (79%) as compared with their peers without these mutations who had a more equal distribution between cortical response types. Conclusion: Cortical development in children who are deaf is heterogeneous but can be better predicted when the genotype is known to be a GJB-2 mutation. Significance: Remediation of childhood deafness seeks to restore normal development and function of central auditory functions and thus may need to be tailored to account for effects specific to the aetiology of deafness. © 2010 International Federation of Clinical Neurophysiology.",21094084,Article,Final,,Scopus,2-s2.0-79952311624
Mishra A.; Verma V.; Shukla G.K.; Mishra S.C.; Dwivedi R.,"Mishra, Anupam (7201439884); Verma, Veerendra (35831940500); Shukla, Girish Kumar (54795893300); Mishra, Subhash Chandra (17735617400); Dwivedi, Raghav (25653932100)",7201439884; 35831940500; 54795893300; 17735617400; 25653932100,"Prevalence of hearing impairement in the district of Lucknow, India.",2011,Indian journal of public health,55,2,,132,134,2,14,10.4103/0019-557X.85251,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84555189180&doi=10.4103%2f0019-557X.85251&partnerID=40&md5=80ae665b7e5c45a4886166fb0aa8edf3,"A multi-cluster study (survey) was carried out by department of ENT KG Medical University, Lucknow from July 2003 to August 2004 in rural and urban population of Lucknow district to estimate prevalence and causes of hearing impairment in the community. Data included audiological profile and basic ear examination that was analysed through EARFORM software program of WHO. Overall hearing impairment was seen in 15.14% of rural as opposed to 5.9% of urban population. A higher prevalence of disabling hearing impairment (DHI) in elderly and deafness in 0-10 years age group was seen. The prevalence of sensorineural deafness necessitating hearing aids was 20% in rural and 50% in urban areas respectively. The presence of DHI was seen in 1/2 urban subjects and 1/3rd of rural counterparts. The incidence of cerumen / debris was very common in both types of population and the need of surgery was much more amongst rural subjects indicating more advanced / dangerous ear disease.",21941050,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84555189180
Berg R.L.; Pickett W.; Fitz-Randolph M.; Broste S.K.; Knobloch M.J.; Wood D.J.; Kirkhorn S.R.; Linneman J.G.; Marlenga B.,"Berg, Richard L. (7402880130); Pickett, William (7102833854); Fitz-Randolph, Marcy (35751774100); Broste, Steven K. (7003844198); Knobloch, Mary Jo (6701892377); Wood, Douglas J. (55468928100); Kirkhorn, Steven R. (6603281756); Linneman, James G. (15832154200); Marlenga, Barbara (6601976109)",7402880130; 7102833854; 35751774100; 7003844198; 6701892377; 55468928100; 6603281756; 15832154200; 6601976109,Hearing conservation program for agricultural students: Short-term outcomes from a cluster-randomized trial with planned long-term follow-up,2009,Preventive Medicine,49,6,,546,552,6,21,10.1016/j.ypmed.2009.09.020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70849107841&doi=10.1016%2fj.ypmed.2009.09.020&partnerID=40&md5=beb3bb646f55d01aebdaf45b2815958b,"Objectives: (1) To conduct a contemporary analysis of historical data on short-term efficacy of a 3-year hearing conservation program conducted from 1992 to 1996 in Wisconsin, USA, with 753 high school students actively involved in farm work; (2) to establish procedures for assessment of hearing loss for use in a recently funded follow-up of this same hearing conservation program cohort. Methods: We analyzed a pragmatic cluster-randomized controlled trial, with schools as the unit of randomization. Thirty-four rural schools were recruited and randomized to intervention or control. The intervention included classroom instruction, distribution of hearing protection devices, direct mailings, noise level assessments, and yearly audiometric testing. The control group received the audiometric testing. Results: Students exposed to the hearing conservation program reported more frequent use of hearing protection devices, but there was no evidence of reduced levels of noise-induced hearing loss (NIHL). Conclusion: Our analysis suggests that, since NIHL is cumulative, a 3-year study was likely not long enough to evaluate the efficacy of this intervention. While improvements in reported use of hearing protection devices were noted, the lasting impact of these behaviors is unknown and the finding merits corroboration by longer term objective hearing tests. A follow-up study of the cohort has recently been started. © 2009 Elsevier Inc. All rights reserved.",19800914,Article,Final,,Scopus,2-s2.0-70849107841
Yuvaraj P.; Mannarukrishnaiah J.,"Yuvaraj, Pradeep (57070162100); Mannarukrishnaiah, Jayaram (15122073600)",57070162100; 15122073600,Cortical evoked potentials and hearing aids in individuals with auditory Dys-synchrony,2015,Journal of International Advanced Otology,11,3,,236,242,6,3,10.5152/iao.2015.1162,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975759968&doi=10.5152%2fiao.2015.1162&partnerID=40&md5=668b26a979068ce838decb62b2131e13,"OBJECTIVE: The purpose of the present study was to investigate the relationship between cortical processing of speech and benefit from hearing aids in individuals with auditory dys-synchrony. MATERIALS and METHODS: Data were collected from 38 individuals with auditory dys-synchrony. Participants were selected based on hearing thresholds, middle ear reflexes, otoacoustic emissions, and auditory brain stem responses. Cortical-evoked potentials were recorded for click and speech. Participants with auditory dys-synchrony were fitted with bilateral multichannel wide dynamic range compression hearing aids. Aided and unaided speech identification scores for 40 words were obtained for each participant. RESULTS: Hierarchical cluster analysis using Ward’s method clearly showed four subgroups of participants with auditory dys-synchrony based on the hearing aid benefit score (aided minus unaided speech identification score). The difference in the mean aided and unaided speech identification scores was significantly different in participants with auditory dys-synchrony. However, the mean unaided speech identification scores were not significantly different between the four subgroups. The N2 amplitude and P1 latency of the speech-evoked cortical potentials were significantly different between the four subgroups formed based on hearing aid benefit scores. CONCLUSION: The results indicated that subgroups of individuals with auditory dys-synchrony who benefit from hearing aids exist. Individuals who benefitted from hearing aids showed decreased N2 amplitudes compared with those who did not. N2 amplitude is associated with greater suppression of background noise while processing speech. © The Mediterranean Society of Otology and Audiology.",26915156,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84975759968
Lee C.-Y.; Hwang J.-H.; Hou S.-J.; Liu T.-C.,"Lee, Cheng-Yung (37018444000); Hwang, Juen-Haur (7403896819); Hou, Szu-Jen (55817802500); Liu, Tien-Chen (7405914488)",37018444000; 7403896819; 55817802500; 7405914488,Using cluster analysis to classify audiogram shapes,2010,International Journal of Audiology,49,9,,628,633,5,17,10.3109/14992021003796887,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955596369&doi=10.3109%2f14992021003796887&partnerID=40&md5=4c7ee07ad32f7f9829016c0ca7924729,"The purpose of this study was to design a statistical classification system of audiogram shapes in order to improve and integrate shape recognition across clinical settings. The study included 1633 adult subjects with normal hearing or symmetric sensorineural hearing impairment who underwent pure-tone audiometry between July 2007 and December 2008. K-means cluster analysis was employed to categorize audiometric shapes. Eleven audiogram shapes were identified: rising, flat, peaked 8-kHz dip, 4-kHz dip, 8-kHz dip, mild sloping, severe 8-kHz dip, sloping, abrupt loss, severe sloping, and profound abrupt loss. By using the classification system and nomenclature identified for audiogram shapes as outlined in this study, errors based on personal experiences can be reduced and a consistency can be developed across clinics. Sumario El propsito de este estudio fue disear un sistema de clasificacin estadstica de formas de audiogramas para mejorar e integrar el reconocimiento de formas en los diferentes contextos clnicos. El estudio incluy 1633 sujetos adultos con audicin normal o con hipoacusias sensorineurales simétricas, que se sometieron a una audiometra tonal entre julio del 2007 y diciembre del 2008. El anlisis en grupo con medios K fue utilizado para organizar las formas audiométricas. Se identificaron once formas audiométricas: en ascenso, planas, con cada puntiaguda en 8 kHz, con cada en 4 kHz, con cada en 8 kHz, con pendiente suave, con cada severa en 8 kHz, con pendiente, pérdida abrupta, pendiente severa y pérdida profunda abrupta. Utilizando el sistema de clasificacin y la nomenclatura identificada para las formas de audiograma conforme se delinea en este estudio, los errores basados en la experiencia personal pueden reducirse y puede desarrollarse consistencia entre las clnicas audiolgicas. © 2010 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",20553102,Article,Final,,Scopus,2-s2.0-77955596369
Bu X.; Liu C.; Xing G.; Zhou L.; Liang C.; Zheng Y.; Meng J.; Wang Y.; Yang C.; Liu Y.; Du B.; Zhang Y.; Du B.,"Bu, Xingkuan (7103052929); Liu, Cheng (48561247800); Xing, Guangqian (55767037000); Zhou, Ling (57199016694); Liang, Chuanyu (7403280460); Zheng, Yun (55761883100); Meng, Juang (54416154200); Wang, Youqin (7601497514); Yang, Chongling (37118224000); Liu, Yuqing (57192571089); Du, Baodong (8367049400); Zhang, Yan (57225168539); Du, Bo (57217375265)",7103052929; 48561247800; 55767037000; 57199016694; 7403280460; 55761883100; 54416154200; 7601497514; 37118224000; 57192571089; 8367049400; 57225168539; 57217375265,WHO Ear and Hearing Disorders Survey in four provinces in China,2011,Audiological Medicine,9,4,,141,146,5,9,10.3109/1651386X.2011.631285,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81255167092&doi=10.3109%2f1651386X.2011.631285&partnerID=40&md5=237799395e41ade72212e0d8d3def992,"Objective: To investigate the population based prevalence of ear diseases and hearing impairment in Jiangsu, Sichuan, Guizhou and Jilin Provinces in China, develop strategies to provide scientific data for the global database and to draw up prevention and intervention strategies. Methods: Using the WHO Ear and Hearing Disorders Survey Protocol and the probability proportion to size (PPS) sampling technique, 30,733 residents were targeted for investigation in 150 clusters in four provinces. Every subject had an ear examination and pure tone audiometry. Definitions of disabling hearing loss and the classification of hearing impairment used were in accordance with WHO recommendations. Results: Among 30,733 targeted residents, 29,246 individuals (95.2%) participated in the survey. One thousand, three hundred and sixty individuals (4.4%) were absent; 127 individuals (0.4%) refused. The prevalences of hearing impairment and disabling hearing impairment were 14.2% and 5.2% of investigated individuals, respectively: 9.1% of the sample had a mild hearing loss, 3.8% a moderate degree of hearing loss, 1.1% a severe and 0.3% a profound hearing loss. Using data from the fifth population census in China (2000), we calculated the standardized rates of hearing impairment and hearing disability in our study to be 11.7% and 4.4%, respectively. There was a significant difference in the prevalence between males and females, urban and rural dwellers, as well as for different ages. The prevalence of ear diseases was 6.5% of investigated individuals: the standardized rate was 5.9%; 0.2% of investigated individuals had auricle malformation, 2.2% impacted cerumen, 0.2% otitis externa, 0.3% fungi, 0.1% foreign body, 0.1% acute otitis media, 0.9% chronic suppurative otitis media, 1.8% serous otitis media and 1.3% dry perforation of tympanic membrane. Overall, 8.0% of investigated persons were assessed to be likely to benefit from hearing aids, while 4.0% of persons needed medication, 0.1% language/speech rehabilitation, 1.5% non-urgent surgery and 0.9% other treatment. Conclusions: The high prevalence of hearing impairment and disability is a heavy burden on social development and also hinders normal family life. The government and society as a whole should show more concern about these problems. Strategies for prevention and intervention should be focused on less developed regions, rural areas, aging people and non-infectious conditions. Hearing aids services, medication, professional education and training are particularly important in developing countries. © 2011 Informa Healthcare.",,Article,Final,,Scopus,2-s2.0-81255167092
Yang M.; Liu B.; Teng G.-J.; Huang Z.-C.; Gao W.-W.; Ji H.; Wu M.; Feng X.; Zhang H.-Y.; Wang J.,"Yang, Ming (56442950900); Liu, Bing (57859723500); Teng, Gao-Jun (7004411906); Huang, Zhi-Chun (22979451800); Gao, Wei-Wei (55231035100); Ji, Hui (7201738459); Wu, Min (57198542429); Feng, Xu (55860205400); Zhang, Hong-Ying (57089234600); Wang, Jian (56374868100)",56442950900; 57859723500; 7004411906; 22979451800; 55231035100; 7201738459; 57198542429; 55860205400; 57089234600; 56374868100,Functional MRI in normal subjects and sudden unilateral sensorineural hearing loss patients,2009,National Medical Journal of China,89,33,,2329,2332,3,1,10.3760/cma.j.issn.0376-2491.2009.33.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871448549&doi=10.3760%2fcma.j.issn.0376-2491.2009.33.007&partnerID=40&md5=2092bfb8381ea96f7ef7f460b3ee3c38,"Objective: Brain activities in responses to amplitude modulation (AM) was evaluated using functional MRT (fMRI) in subjects with sudden unilateral sensorineural hearing loss (SSNHL) and those with normal hearing (NH). Methods: Totally 25 subjects with normal hearing and 30 with SSNHL were examined with fMRI in response to AM tones of 500, 2000 and 4000 Hz respectively with the modulation frequency at 8 Hz. The fMRI was examined within 12 days after the onset of SSNHL. The AM signals were presented at 96 dB SPL binaurally. An event-related design was combined with a sparse clustered volume acquisitioning paradigm in data collection in the attempt to reduce the influence of acoustic scanner noise. SPM2 software was used for offline data analyzing. Results: Brain activation in fMRI image was found mainly in the primary auditory cortex (PAC) in both subjects with NH and SSNHL. NH subjects showed a clear lateralization to left cerebral hemisphere(11/16) and SSNHL patients showed a lateralization ipsilateral to the impaired ear(16/22). The activation voxel and intensity shown in BOLD were found to be decreased with increasing signal frequency in both groups. Conclusion: The difference in the lateralization between the two groups suggests that an adaptive process occurs shortly after the onset of SSNHL.",20095354,Article,Final,,Scopus,2-s2.0-84871448549
Jaramillo C.A.; Cooper D.B.; Wang C.-P.; Tate D.F.; Eapen B.C.; York G.E.; Pugh M.J.,"Jaramillo, Carlos A. (7005412154); Cooper, Douglas B. (15749768500); Wang, Chen-Pin (16432971400); Tate, David F. (7103286989); Eapen, Blessen C. (55946643000); York, Gerald E. (7005085503); Pugh, Mary Jo (9246674700)",7005412154; 15749768500; 16432971400; 7103286989; 55946643000; 7005085503; 9246674700,Subgroups of US IRAQ and Afghanistan veterans: associations with traumatic brain injury and mental health conditions,2015,Brain Imaging and Behavior,9,3,,445,455,10,23,10.1007/s11682-015-9402-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942368134&doi=10.1007%2fs11682-015-9402-8&partnerID=40&md5=c73823d262a9115d90161a80d81b400f,"U. S. veterans of Iraq and Afghanistan are known to have a high prevalence of traumatic brain injury (TBI), posttraumatic stress disorder (PTSD), and depression, which are often comorbid and share many symptoms. Attempts to describe this cohort by single diagnoses have limited our understanding of the complex nature of this population. The objective of this study was to identify subgroups of Iraq and Afghanistan veterans (IAVs) with distinct compositions of symptoms associated with TBI, PTSD, and depression. Our cross-sectional, observational study included 303,716 IAVs who received care in the Veterans Health Administration in 2010–2011. Symptoms and conditions were defined using International Classification of Diseases, Ninth Revision codes and symptom-clusters were identified using latent class analysis. We identified seven classes with distinct symptom compositions. One class had low probability of any condition and low health care utilization (HCU) (48 %). Other classes were characterized by high probabilities of mental health comorbidities (14 %); chronic pain and sleep disturbance (20 %); headaches and memory problems (6 %); and auditory problems (2.5 %). Another class had mental health comorbidities and chronic pain (7 %), and the last had high probabilities of most symptoms examined (3 %). These last two classes had the highest likelihood of TBI, PTSD, and depression and were identified as high healthcare utilizers. There are subgroups of IAVs with distinct clusters of symptom that are meaningfully associated with TBI, PTSD, depression, and HCU. Additional studies examining these veteran subgroups could improve our understanding of this complex comorbid patient population. © 2015, Springer Science+Business Media New York.",25963862,Article,Final,,Scopus,2-s2.0-84942368134
Montes-Jovellar L.; Guillen-Grima F.; Perez-Fernandez N.,"Montes-Jovellar, Lourdes (23493002100); Guillen-Grima, Francisco (55527622700); Perez-Fernandez, Nicolas (6602382611)",23493002100; 55527622700; 6602382611,Cluster analysis of auditory and vestibular test results in definite menière's disease,2011,Laryngoscope,121,8,,1810,1817,7,9,10.1002/lary.21844,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960955460&doi=10.1002%2flary.21844&partnerID=40&md5=7f04049eb833310e126ba0b2981a4003,"Objectives/Hypothesis: To determine whether patients with Menière's disease can be grouped into distinct subtypes based on a cluster analysis of distinct disease parameters. Study Design: Prospective study at a tertiary center associated with a university hospital. Methods: The study included 153 patients diagnosed with unilateral definite Menière's disease. The main variables employed were taken from auditory, vestibular, posturographic, and disability assessments. Results: A four-cluster solution best fitted the data. Each cluster represented a distinct patient profile. Cluster 1 patients (13.1%) were the eldest, with the worst hearing bilaterally and good vestibular function but with a significant postural impact and a low level of disability. Cluster 2 patients (41.2%) were the least affected in all the parameters that were close to normal. Cluster 3 patients (34.6%) were the most affected, experiencing frequent and intense vertigo attacks, and they were visually dependent. Cluster 4 patients (11.1%) had strong asymmetric hearing between both ears and the most uncompensated vestibular deficit; they were moderately disabled. Conclusions: We have identified four distinct profiles of patients with definite Menière's disease that we consider as ""mildly active elderly,"" ""mildly active young,"" ""active compensated,"" and ""active uncompensated."" We have demonstrated that only in a restricted population of patients can the American Academy of Otolaryngology-Head and Neck Surgery staging system provide analysis of subtypes of the disease. Copyright © 2011 The American Laryngological, Rhinological, and Otological Society, Inc.",21792974,Review,Final,,Scopus,2-s2.0-79960955460
Song X.D.; Wallace B.M.; Gardner J.R.; Ledbetter N.M.; Weinberger K.Q.; Barbour D.L.,"Song, Xinyu D. (56956060700); Wallace, Brittany M. (56956411600); Gardner, Jacob R. (56461974500); Ledbetter, Noah M. (26428216000); Weinberger, Kilian Q. (8279937900); Barbour, Dennis L. (7003532294)",56956060700; 56956411600; 56461974500; 26428216000; 8279937900; 7003532294,"Fast, Continuous Audiogram Estimation Using Machine Learning",2015,Ear and Hearing,36,6,,e326,e335,9,38,10.1097/AUD.0000000000000186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943539010&doi=10.1097%2fAUD.0000000000000186&partnerID=40&md5=cc405c27c0edfa6fc7ed3e27db2fbd85,"Objectives: Pure-tone audiometry has been a staple of hearing assessments for decades. Many different procedures have been proposed for measuring thresholds with pure tones by systematically manipulating intensity one frequency at a time until a discrete threshold function is determined. The authors have developed a novel nonparametric approach for estimating a continuous threshold audiogram using Bayesian estimation and machine learning classification. The objective of this study was to assess the accuracy and reliability of this new method relative to a commonly used threshold measurement technique. Design: The authors performed air conduction pure-tone audiometry on 21 participants between the ages of 18 and 90 years with varying degrees of hearing ability. Two repetitions of automated machine learning audiogram estimation and one repetition of conventional modified Hughson-Westlake ascending-descending audiogram estimation were acquired by an audiologist. The estimated hearing thresholds of these two techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). Results: The two threshold estimate methods delivered very similar estimates at standard audiogram frequencies. Specifically, the mean absolute difference between estimates was 4.16 ± 3.76 dB HL. The mean absolute difference between repeated measurements of the new machine learning procedure was 4.51 ± 4.45 dB HL. These values compare favorably with those of other threshold audiogram estimation procedures. Furthermore, the machine learning method generated threshold estimates from significantly fewer samples than the modified Hughson-Westlake procedure while returning a continuous threshold estimate as a function of frequency. Conclusions: The new machine learning audiogram estimation technique produces continuous threshold audiogram estimates accurately, reliably, and efficiently, making it a strong candidate for widespread application in clinical and research audiometry. © 2015 Wolters Kluwer Health, Inc. All rights reserved • Printed in the U.S.A.",26258575,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84943539010
Xu Q.; Zhai S.; Han D.; Yang S.; Shen W.,"Xu, Qingqing (57033238700); Zhai, Suoqiang (56233134100); Han, Dongyi (7403219667); Yang, Shiming (8074203500); Shen, Weidong (8363378300)",57033238700; 56233134100; 7403219667; 8074203500; 8363378300,Meta-analysis on effectiveness of prelingually deaf patients at different ages following cochlear implantation,2015,"Lin chuang er bi yan hou tou jing wai ke za zhi = Journal of clinical otorhinolaryngology, head, and neck surgery",29,4,,310,314,4,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955420402&partnerID=40&md5=a9b2ba795fa9f873114a35342287ef10,"OBJECTIVE: To assess the clinical effeetiveness of prelingually deaf children after cochlear implantation at different ages so as to provide reasonable expectations for the patients and guidance for the clinical treatment.; METHOD: Electronic databases PubMed, YZ365. COM, WANFANG DATA, CMJD, CHKD, CNKI were searched using relevant keywords. Extracted data included author, year of publication, diagnosis, et al. Reported treatment outcomes were clustered into speech discrimination and hearing abilities. Meta-analyses were performed on studies with numerical results using random or fixed effects model.; RESULT: There were eight randomized control studies including 442 patients. Comparing speech perception of prelingually deaf children after cochlear implantation younger than three years old (experimental group) and 3-6 years old (control group), three and six months after operation showed that experimental group performed significantly worse than control group; 12 months after operation showed that experimental group performed significantly better than control group. Comparing hearing abilities, three and six months after operation showed that experimental group performed significantly worse than control group; 12 months after operation showed showed that experimental group performed significantly better than control group. Comparing speech perception of younger or older than 4. 5 years old children showed that after 1.5-2 years of operation children implanted younger than 4.5 years of age performed significantly better than children implanted older than 4.5 years old. Comparing speech perception of 7-12 years old children showed that after 3, 6, 12 months of operation patients of 7-12 years old performed significantly better than those children older than 12 years old. Comparing speech perception of implantation younger or older than 18 years old (7-14 yeas old was group A, > 14-18 yeas old was group B, older than 18 yeas old was group C) showed that after one and four years of operation A > B > C, and there were significant differences among them. Comparing warble tone threshold average (WTA) showed that after one year of operation A < B < C, and there were significant differences among them. However, after four years of operation, there was no significant difference among them.; CONCLUSION: Prelinguistically deafened patients younger than three years old with cochlear implantation, insisting on scienctific rehabilitation training for a long period of time can receive the optimal recovery effect. The older patients are suggested as early as possible receiving cochlear implantation. The longer they are implanted, the better results they will receive. Moreover, the younger age they are implanted, the faster postoperative language progress they will receive. Further controlled studies with longer follow-up periods and more person included may make the effectiveness of cochlear implantaion more reliable.",26121827,Article,Final,,Scopus,2-s2.0-84955420402
Bas Infante E.; Channer G.A.; Telischi F.F.; Gupta C.; Dinh J.T.; Vu L.; Eshraghi A.A.A.; Van De Water T.R.,"Bas Infante, Esperanza (12753444100); Channer, Guyan A. (55362108300); Telischi, Fred F. (35429750700); Gupta, Chhavi (35603234500); Dinh, John T. (55363205600); Vu, Ly (54388382900); Eshraghi, Adrien A. A. (7003677831); Van De Water, Thomas R. (35553077000)",12753444100; 55362108300; 35429750700; 35603234500; 55363205600; 54388382900; 7003677831; 35553077000,Mannitol protects hair cells against tumor necrosis factor α-induced loss,2012,Otology and Neurotology,33,9,,1656,1663,7,15,10.1097/MAO.0b013e31826bedd9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870336076&doi=10.1097%2fMAO.0b013e31826bedd9&partnerID=40&md5=f89269e7e5ea5080ae6cefa6c31a1719,"HYPOTHESIS: Mannitol has otoprotective effects against tumor necrosis factor (TNF) α-induced auditory hair cell (HC) loss. BACKGROUND: Mannitol has been demonstrated to possess cytoprotective effects in several organ systems. Its protective effect on postischemic hearing loss has also been shown. Mannitol's otoprotective mechanism and site of action are at present unknown. MATERIALS AND METHODS: Organ of Corti (OC) explants were dissected from 3 day-old rat pups. The safety (nonototoxicity) of mannitol was assessed at 4 different concentrations (1-100 mM). Three experimental arms were designed including: a control group, TNFα group, and TNFα + mannitol group. Cell viability was determined by counts of fluorescein isothiocyanate (FITC) phalloidin stained HC. Immunofluorescence assay of phospho-c-Jun and the proapoptotic mediators, cleaved caspase-3, apoptosis inducing factor (AIF), and endonuclease G (Endo G) were performed. RESULTS: Analysis of HC density confirmed the safety of mannitol at concentration ranges of 1 to 100 mM. The ototoxic effect of TNFα was demonstrated (p < 0.05). The otoprotective effect of 100 mM mannitol in TNFα-challenged OC explants was also demonstrated (p < 0.001). Mannitol treatment reduced the high levels of phospho-c-Jun observed in the TNFα-challenged group. AIF cluster formation and EndoG translocation into the nuclei of HCs were also reduced by mannitol treatment. CONCLUSION: Mannitol significantly reduces the ototoxic effects of TNFα against auditory HC's potentially by inhibiting c-Jun N terminal kinase (JNK) activation pathway and AIF, EndoG nuclear translocation. This local otoprotective effect may have therapeutic implications in inner ear surgery, for example, cochlear implants, protection of residual hearing, as well as implications for postischemic inner ear insults. © 2012 Otology & Neurotology, Inc.",22996158,Article,Final,,Scopus,2-s2.0-84870336076
Nothwang H.G.; Engel J.; Knipper M.; Friauf E.,"Nothwang, Hans Gerd (7003310160); Engel, Jutta (35298876800); Knipper, Marlies (7003962174); Friauf, Eckhard (7004595442)",7003310160; 35298876800; 7003962174; 7004595442,L-type calcium channels in the auditory system; [L-Typ-Kalzium-Kanäle im Hörsystem],2014,Neuroforum,20,3,,8545,8553,8,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908086285&partnerID=40&md5=8eb3a2c5c71e585edf1e9ee5cfbc99b5,"The voltage-activated L-type calcium channels Cay1.2 and Cay1.3 mediate Ca2+influx into neurons at the soma or at dendrites, whereas they are not observed at the presynapse. Surprisingly, in the inner ear, Cay1.3 is indispensable for signal transmission from the cochlear inner hair cells to the postsynaptic auditory nerve fibers. Due to Cav1.3 channel clustering at ribbons, i.e. specific presynaptic structures of the hair cells, they promote Ca2+influx which triggers calcium-dependent fusion of synaptic vesicles with the plasma membrane. Consequently, mutations in Cacnald, the gene that encodes Cay1.3, cause deafness. Additionally, Cay1.3 plays an important part in the central auditory system. Lack of the channel results in severe changes in auditory pathway cytoarchitecture and in abnormal electrophysiological performance of auditory neurons. Furthermore, developmental refinement of tonotopic inhibitory projections in sound localization circuits is disrupted. These aberrations are associated with abnormal sound processing in the auditory pathway. Cacnald therefore represents a prototypal deafness associated gene, in which mutations result in both peripheral and central auditory deficiencies. This, in turn, has implications for auditory rehabilitation using cochlear implants which address only peripheral dysfunctions. Exploratory research into the closely related Cay1.2 isoform points to an important role of this channel in acoustic trauma. Cay1.2 is mainly expressed in the auditory nerve, but apparently not essential for normal auditory function. Rather, loss of function of the channel does influence the effects of traumatic noise exposure. Loss of this channel induced by noise trauma results in reduced auditory threshold increase. This phenomenon points to the fact that Cay1.2-mediated Ca2+ influx is involved in noise trauma induced damage. Deeper insight into this function might result in new therapeutic approaches. © Springer Verlag 2014.",,Article,Final,,Scopus,2-s2.0-84908086285
Ji H.; Huang Z.; Yang M.; Feng X.; Meng L.,"Ji, Hui (7201738459); Huang, Zhichun (22979451800); Yang, Ming (56442950900); Feng, X. (55860205400); Meng, Liping (58404338100)",7201738459; 22979451800; 56442950900; 55860205400; 58404338100,[Functional MRI study of auditory cortical responses in normal subjects and unilateral sensorineural hearing loss subjects].,2010,"Lin chuang er bi yan hou tou jing wai ke za zhi = Journal of clinical otorhinolaryngology, head, and neck surgery",24,22,,1018,1022,4,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053433403&partnerID=40&md5=3e91f9feadb641754170c12e179e9fbe,"Amplitude modulation of auditory cortical responses was evaluated with functional MRI (fMRI) in subjects of unilateral sensorineural hearing loss (USNHL) and those of normal hearing (NH). Twenty-one subjects with USNHL and 11 with normal hearing were examined with fMRI in response to amplitude modulation tones of 500 Hz with the modulation frequency at 8 Hz. An event related design was combined with a sparse clustered volume acquisitioning paradigm in data collection in order to reduce the influence of acoustic scanner noise. SPM2 software was used for offline data analyzing. Significant activation, including volume and intensity, were found in the temporal lobe of control subjects, and significant differences in the volume and intensity were noted between the contralateral and ipsilateral activated auditory cortexes in them, exhibiting clearly contralateral predominance. When the normal ear with unilateral sensorineural hearing loss received signals, while significant activations in bilateral auditory cortexes, greater activation in the contralateral auditory cortexes was found in the normal ear. The difference in the lateralization between the two groups suggests the plasticity of auditory cortex with unilateral sensorineural hearing loss.",21322926,Article,Final,,Scopus,2-s2.0-80053433403
Tomoda A.; Kinoshita S.; Korenaga Y.; Mabe H.,"Tomoda, Akemi (55680967100); Kinoshita, Sumihito (56237524400); Korenaga, Yuki (36613240400); Mabe, Hiroyo (6603692629)",55680967100; 56237524400; 36613240400; 6603692629,Pseudohypacusis in childhood and adolescence is associated with increased gray matter volume in the medial frontal gyrus and superior temporal gyrus,2012,Cortex,48,4,,492,503,11,10,10.1016/j.cortex.2010.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857139631&doi=10.1016%2fj.cortex.2010.10.001&partnerID=40&md5=65da33e5face6306e6d96ab69f7fe1f0,"Pseudohypacusis is a somatoform disorder characterized by hearing loss with discrepancies between pure-tone audiometry and auditory brainstem response (ABR), but the underlying neuronal mechanisms remain unclear. Using voxel-based morphometry (VBM) with magnetic resonance (MR) imaging for 14 unmedicated, right-handed patients and 35 healthy control subjects, we investigated whether functional hearing loss was associated with discernible changes of brain morphology. Group differences in gray matter volume (GMV) were assessed using high-resolution, T1-weighted, volumetric MR imaging datasets (3T Trio scanner; Siemens AG) and analyzed with covariant factors of age, sex, socioeconomic status (SES), and total GMV, which was increased by 27.9% in the left medial frontal gyrus (MFG) (Brodmann area 10) (p=.001, corrected cluster level) and by 14.4% in the right superior temporal gyrus (STG) and the adjacent middle temporal gyrus (MTG) (BA42 to 21) (p=.009, corrected cluster level) in patients with pseudohypacusis. The GMV in the right STG (BA42) and verbal intelligence quotient (IQ) were correlated significantly with the Wechsler Intelligence Scale for Children - Third Edition (WISC-III) (ß= -.57, p<.0001) and level of SES (ß=-55, p<.0001). The present findings suggest that the development of the auditory association cortex involved in language processing is affected, causing insufficient pruning during brain development. We therefore assert that differences in the neuroanatomical substrate of pseudohypacusis subjects result from a developmental disorder in auditory processing. © 2010 Elsevier Srl.",,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84857139631
Shivdasani M.N.; Mauger S.J.; Rathbone G.D.; Paolini A.G.,"Shivdasani, Mohit N. (23390953100); Mauger, Stefan J. (23467203700); Rathbone, Graeme D. (6603147292); Paolini, Antonio G. (35230424900)",23390953100; 23467203700; 6603147292; 35230424900,Neural synchrony in ventral cochlear nucleus neuron populations is not mediated by intrinsic processes but is stimulus induced: Implications for auditory brainstem implants,2009,Journal of Neural Engineering,6,6,65003,,,,9,10.1088/1741-2560/6/6/065003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849144930&doi=10.1088%2f1741-2560%2f6%2f6%2f065003&partnerID=40&md5=d225b2c319ed0c59baf16d45b6202047,"The aim of this investigation was to elucidate if neural synchrony forms part of the spike time-based theory for coding of sound information in the ventral cochlear nucleus (VCN) of the auditory brainstem. Previous research attempts to quantify the degree of neural synchrony at higher levels of the central auditory system have indicated that synchronized firing of neurons during presentation of an acoustic stimulus could play an important role in coding complex sound features. However, it is unknown whether this synchrony could in fact arise from the VCN as it is the first station in the central auditory pathway. Cross-correlation analysis was conducted on 499 pairs of multiunit clusters recorded in the urethane-anesthetized rat VCN in response to pure tones and combinations of two tones to determine the presence of neural synchrony. The shift predictor correlogram was used as a measure for determining the synchrony owing to the effects of the stimulus. Without subtraction of the shift predictor, over 65% of the pairs of multiunit clusters exhibited significant correlation in neural firing when the frequencies of the tones presented matched their characteristic frequencies (CFs). In addition, this stimulus-evoked neural synchrony was dependent on the physical distance between electrode sites, and the CF difference between multiunit clusters as the number of correlated pairs dropped significantly for electrode sites greater than 800 νm apart and for multiunit cluster pairs with a CF difference greater than 0.5 octaves. However, subtraction of the shift predictor correlograms from the raw correlograms resulted in no remaining correlation between all VCN pairs. These results suggest that while neural synchrony may be a feature of sound coding in the VCN, it is stimulus induced and not due to intrinsic neural interactions within the nucleus. These data provide important implications for stimulation strategies for the auditory brainstem implant, which is used to provide functional hearing to the profoundly deaf through electrical stimulation of the VCN. © 2009 IOP Publishing Ltd.",19850978,Article,Final,,Scopus,2-s2.0-72849144930
Jung S.; Oshima-Takago T.; Chakrabarti R.; Wong A.B.; Jing Z.; Yamanbaeva G.; Picher M.M.; Wojcik S.M.; Göttfert F.; Predoehl F.; Michel K.; Hell S.W.; Schoch S.; Strenzke N.; Wichmann C.; Moser T.,"Jung, Sangyong (55433059200); Oshima-Takago, Tomoko (55308029300); Chakrabarti, Rituparna (57267247000); Wong, Aaron B. (56002403200); Jing, Zhizi (55614911500); Yamanbaeva, Gulnara (56711957700); Picher, Maria Magdalena (55383569500); Wojcik, Sonja M. (9942685300); Göttfert, Fabian (55785672700); Predoehl, Friederike (55354343700); Michel, Katrin (57225443983); Hell, Stefan W. (7006579024); Schoch, Susanne (7003886023); Strenzke, Nicola (12752910700); Wichmann, Carolin (12775533400); Moser, Tobias (7007050113)",55433059200; 55308029300; 57267247000; 56002403200; 55614911500; 56711957700; 55383569500; 9942685300; 55785672700; 55354343700; 57225443983; 7006579024; 7003886023; 12752910700; 12775533400; 7007050113,Rab3-interacting molecules 2α and 2β promote the abundance of voltage-gated CaV1.3 Ca2+ channels at hair cell active zones,2015,Proceedings of the National Academy of Sciences of the United States of America,112,24,,E3141,E3149,8,50,10.1073/pnas.1417207112,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935871875&doi=10.1073%2fpnas.1417207112&partnerID=40&md5=eff6fdc3ef9113d4e2db1b40b7eff5d9,"Ca2+ influx triggers the fusion of synaptic vesicles at the presynaptic active zone (AZ). Here we demonstrate a role of Ras-related in brain 3 (Rab3)-interacting molecules 2α and β (RIM2α and RIM2β) in clustering voltage-gated CaV1.3 Ca2+ channels at the AZs of sensory inner hair cells (IHCs). We show that IHCs of hearing mice express mainly RIM2α, but also RIM2β and RIM3γ, which all localize to the AZs, as shown by immunofluorescence microscopy. Immunohistochemistry, patch-clamp, fluctuation analysis, and confocal Ca2+ imaging demonstrate that AZs of RIM2α-deficient IHCs cluster fewer synaptic CaV1.3 Ca2+ channels, resulting in reduced synaptic Ca2+ influx. Using superresolution microscopy, we found that Ca2+ channels remained clustered in stripes underneath anchored ribbons. Electron tomography of high-pressure frozen synapses revealed a reduced fraction of membrane-tethered vesicles, whereas the total number of membrane-proximal vesicles was unaltered. Membrane capacitance measurements revealed a reduction of exocytosis largely in proportion with the Ca2+ current, whereas the apparent Ca2+ dependence of exocytosis was unchanged. Hair cell-specific deletion of all RIM2 isoforms caused a stronger reduction of Ca2+ influx and exocytosis and significantly impaired the encoding of sound onset in the postsynaptic spiral ganglion neurons. Auditory brainstem responses indicated a mild hearing impairment on hair cell-specific deletion of all RIM2 isoforms or global inactivation of RIM2α. We conclude that RIM2α and RIM2β promote a large complement of synaptic Ca2+ channels at IHC AZs and are required for normal hearing. © 2015, National Academy of Sciences. All rights reserved.",26034270,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84935871875
Van Kerschaver E.,"Van Kerschaver, E. (6602189792)",6602189792,Universal neonatal hearing screening in Flanders reveals socio-demographic risk factors for hearing impairment,2013,B-ENT,,SUPPL. 21,,3,8,5,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890254040&partnerID=40&md5=ae2f8fb47bcece699279ebf96ce5b714,"Introduction: Permanent congenital hearing impairment (CHI) occurs in approximately 1.4 per 1,000 newborns. Early treatment and rehabilitation is essential to prevent the delayed development of speech and language. This paper describes the special collaborative approach of the Flemish screening programme. It also discusses the results and the new insights into socio-demographic risk factors for CHI. Methods'. In the period 1999-2008, the entire population of 628,337 newborns in Flanders was tested using an AABR hearing screener. Positive results were referred for confirmation of the CHI diagnosis to specialised referral centres. Socio-demographic factors were investigated to study any relationship with CHI. Results: The referral rate after two screenings was 2.7-7.2% of screened babies depending on the screener used. All children were referred to specialised centres and there was almost no loss to follow-up. The diagnosis of hearing loss was confirmed in 77-82% of the babies referred. The socio-demographic factors of gender, birth order and birth length, initial feeding type, level of education and origin of the mother were found to be independent predictors of CHI. Most of these risk factors can be linked to poverty. The observation that 50% of babies with CHI have no risk factors from the classic AAP list may be partly explained by the non-inclusion of socio-demographic risk factors. Conclusions: This integrated programme opens up new perspectives for hearing-impaired babies. The social impact of the screening programme is considerable. A cluster of socio-demographic risk factors for CHI can be added to the classic AAP list.",24383217,Article,Final,,Scopus,2-s2.0-84890254040
Yan D.; Xing Y.; Ouyang X.; Zhu J.; Chen Z.-Y.; Lang H.; Liu X.Z.,"Yan, Denise (7401863128); Xing, Yazhi (55174493600); Ouyang, Xiaomei (7102723612); Zhu, Juhong (57198763921); Chen, Zheng-Yi (57209865740); Lang, Hainan (7402486012); Liu, Xue Z. (26642875300)",7401863128; 55174493600; 7102723612; 57198763921; 57209865740; 7402486012; 26642875300,Analysis of miR-376 RNA cluster members in the mouse inner ear,2012,International Journal of Experimental Pathology,93,6,,450,457,7,14,10.1111/j.1365-2613.2012.00840.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869008349&doi=10.1111%2fj.1365-2613.2012.00840.x&partnerID=40&md5=bb17df8855a77d1d4e3fc8aff9dfdaa2,"Mutations in phosphoribosyl pyrophosphate synthetase 1 (PRPS1) are associated with a spectrum of non-syndromic to syndromic hearing loss. PRPS1 transcript levels have been shown to be regulated by the microRNA-376 genes. The long primary RNA transcript of the miR-376 RNA cluster members undergo extensive and simultaneous A → I editing at one or both of two specific sites (+4 and +44) in particular human and mouse tissues. The PRPS1 gene, which contains target sites for the edited version of miR-376a-5p within its 3′UTR, has been shown to be repressed in a tissue-specific manner. To investigate whether the transcription of Prps1 is regulated by miR-376 cluster members in the mouse inner ear, we first quantified the expression of the mature miR-376 RNAs by quantitative real-time-PCR. The spatio-temporal patterns of miR-376 expression were assessed by in situ hybridization. Finally, we examined whether A →I editing of pri-miR-376 RNAs occurs in mouse inner ear by direct sequencing. Our data showed that the miR-376a-3p, b-3p, c-3p are present in mouse embryonic inner ears and intensive expression of miR-376a-3p/b-3p was detected in the sensory epithelia and ganglia of both auditory and vestibular portions of the inner ear. In adult inner ear, the expression of miR-376a-3p/b-3p is restricted within ganglion neurons of auditory and vestibular systems as well as the cells in the stria vascularis. Only unedited pri-miR-376 RNAs were detected in the cochlea suggesting that the activity of PRPS1 in the inner ear may not be regulated through the editing of miR-376 cluster. © 2012 The Authors. International Journal of Experimental Pathology © 2012 International Journal of Experimental Pathology.",23136997,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84869008349
Birman C.S.; Brew J.A.; Gibson W.P.R.; Elliott E.J.,"Birman, Catherine S. (6603045270); Brew, Jane A. (9842396900); Gibson, William P.R. (7202910690); Elliott, Elizabeth J. (7101764161)",6603045270; 9842396900; 7202910690; 7101764161,CHARGE syndrome and Cochlear implantation: Difficulties and outcomes in the paediatric population,2015,International Journal of Pediatric Otorhinolaryngology,79,4,,487,492,5,31,10.1016/j.ijporl.2015.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924043872&doi=10.1016%2fj.ijporl.2015.01.004&partnerID=40&md5=b17e441dc3be52bf1c5e2b7ac7ad31c7,"Objectives: CHARGE syndrome is a complex cluster of congenital abnormalities, these children may have absent or hypoplastic auditory nerves. Our objective was to assess preoperative factors and outcomes for paediatric cochlear implant recipients with CHARGE syndrome, to enable better surgical preparation and family counselling. Methods: The Sydney Cochlear Implant Centre database was searched for children with CHARGE syndrome who had received a cochlear implant at ages 16 and less. Data were collected regarding clinical history; hearing assessments; MRI and CT scan findings; preoperative transtympanic electrical Auditory Brainstem Response (ABR); intraoperative findings and intraoperative electrical ABR and Neural Response Telemetry; and language outcomes in terms of main language used and Categories of Auditory Performance scores (0-7 ranking). Results: Ten children were identified. All seven prelingual profoundly deaf children with CHARGE syndrome had hypoplastic or absent auditory nerves bilaterally on MRI scans. Middle ear anatomy was often abnormal, affecting surgical landmarks and making identification of the cochlea very difficult in some cases. Three cases required repeated surgery to obtain successful cochlear implant insertion, one under CT scan image guided technique. All seven children used sign language, or simpler gestures, as their main mode of communication. Two children of of these children, who were implanted early, also attained some spoken language. CAP scores ranged from 0 to 6.The three children with CHARGE syndrome and progressive sensorineural hearing loss had a normal auditory nerve in at least one ear on MRI scans. All had preoperative verbal language, with CAP scores of 6, and continued with CAP scores of 6 following receipt of the cochlear implant. Conclusion: Children with CHARGE and congenital profound hearing loss all had hypoplasia or absent auditory nerves, affecting their outcomes with cochlear implants. They often had markedly abnormal middle ear anatomy and CT image guided surgery can be helpful. These children should be offered a bilingual early intervention approach, using sign language and verbal language, to ensure best language outcomes. Children with CHARGE syndrome and progressive profound hearing loss did well with cochlear implants and continue to be able to use verbal language. © 2015 Elsevier Ireland Ltd.",25649713,Article,Final,,Scopus,2-s2.0-84924043872
Classon E.; Löfkvist U.; Rudner M.; Rönnberg J.,"Classon, Elisabet (55464013700); Löfkvist, Ulrika (55368959500); Rudner, Mary (22956531400); Rönnberg, Jerker (7006652012)",55464013700; 55368959500; 22956531400; 7006652012,Verbal fluency in adults with postlingually acquired hearing impairment,2014,"Speech, Language and Hearing",17,2,,88,100,12,13,10.1179/205057113X13781290153457,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928158722&doi=10.1179%2f205057113X13781290153457&partnerID=40&md5=c48f5c29ae3d5dcd2d3cf9c3c7fa7967,"This study examined verbal retrieval in participants with acquired moderate-to-severe sensorineural hearing impairment (M age = 63, M education level = 13 years) compared to participants with normal hearing thresholds (M age = 62, M education level = 14 years) using the letter and category fluency tasks. Analyses of number of words produced, clustering, and switching, were conducted. There was no significant difference between the groups in category fluency performance. In letter fluency, however, the participants with hearing impairment produced significantly fewer words than the normal hearing participants and their production was characterized by fewer switches. Regression analyses were conducted to examine the relationship between demographic, auditory, and cognitive variables and letter fluency performance in the two groups. Phonological skills and auditory acuity predicted letter fluency output only in participants with hearing impairment and a hearing-related link between phonological skills, working memory capacity, and letter fluency switching was found. © W. S. Maney & Son Ltd 2014.",,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84928158722
Nakeva Von Mentzer C.; Lyxell B.; Sahlén B.; Dahlström Ö.; Lindgren M.; Ors M.; Kallioinen P.; Engström E.; Uhlén I.,"Nakeva Von Mentzer, Cecilia (55914684600); Lyxell, Björn (6701463936); Sahlén, Birgitta (6602458478); Dahlström, Örjan (24331177900); Lindgren, Magnus (55154695300); Ors, Marianne (6602311971); Kallioinen, Petter (55641286600); Engström, Elisabet (56519563000); Uhlén, Inger (22956690800)",55914684600; 6701463936; 6602458478; 24331177900; 55154695300; 6602311971; 55641286600; 56519563000; 22956690800,Segmental and suprasegmental properties in nonword repetition - An explorative study of the associations with nonword decoding in children with normal hearing and children with bilateral cochlear implants,2015,Clinical Linguistics and Phonetics,29,3,,216,235,19,14,10.3109/02699206.2014.987926,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923000043&doi=10.3109%2f02699206.2014.987926&partnerID=40&md5=2f56eee971e97ef023cb83586e402b26,"This study explored nonword repetition (NWR) and nonword decoding in normal-hearing (NH) children and in children with bilateral cochlear implants (CI). Participants were 11 children, with CI, 5:0-7:11 years (M = 6.5 years), and 11 NH children, individually age-matched to the children with CI. This study fills an important gap in research, since it thoroughly describes detailed aspects of NWR and nonword decoding and their possible associations. All children were assessed after having practiced with a computer-assisted reading intervention with a phonics approach during four weeks. Results showed that NH children outperformed children with CI on the majority of aspects of NWR. The analysis of syllable number in NWR revealed that children with CI made more syllable omissions than did the NH children, and predominantly in prestressed positions. In addition, the consonant cluster analysis in NWR showed significantly more consonant omissions and substitutions in children with CI suggesting that reaching fine-grained levels of phonological processing was particularly difficult for these children. No significant difference was found for nonword-decoding accuracy between the groups, as measured by whole words correct and phonemes correct, but differences were observed regarding error patterns. In children with CI phoneme, deletions occurred significantly more often than in children with NH. The correlation analysis revealed that the ability to repeat consonant clusters in NWR had the strongest associations to nonword decoding in both groups. The absence of as frequent significant associations between NWR and nonword decoding in children with CI compared to children with NH suggest that these children partly use other decoding strategies to compensate for less precise phonological knowledge, for example, lexicalizations in nonword decoding, specifically, making a real word of a nonword. © 2015 Informa UK Ltd.",25489675,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84923000043
Coate T.M.; Kelley M.W.,"Coate, Thomas M. (9632426300); Kelley, Matthew W. (7403230326)",9632426300; 7403230326,Making connections in the inner ear: Recent insights into the development of spiral ganglion neurons and their connectivity with sensory hair cells,2013,Seminars in Cell and Developmental Biology,24,5,,460,469,9,64,10.1016/j.semcdb.2013.04.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879183602&doi=10.1016%2fj.semcdb.2013.04.003&partnerID=40&md5=c307f04971b54ec3f93d7739653a0cc8,"In mammals, auditory information is processed by the hair cells (HCs) located in the cochlea and then rapidly transmitted to the CNS via a specialized cluster of bipolar afferent connections known as the spiral ganglion neurons (SGNs). Although many anatomical aspects of SGNs are well described, the molecular and cellular mechanisms underlying their genesis, how they are precisely arranged along the cochlear duct, and the guidance mechanisms that promote the innervation of their hair cell targets are only now being understood. Building upon foundational studies of neurogenesis and neurotrophins, we review here new concepts and technologies that are helping to enrich our understanding of the development of the nervous system within the inner ear. © 2013.",,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84879183602
Zirn S.; Hempel J.-M.; Schuster M.; Hemmert W.,"Zirn, Stefan (55538857500); Hempel, John-Martin (7006348376); Schuster, Maria (7202798421); Hemmert, Werner (6601954688)",55538857500; 7006348376; 7202798421; 6601954688,Comodulation masking release induced by controlled electrical stimulation of auditory nerve fibers,2013,Hearing Research,296,,,60,66,6,4,10.1016/j.heares.2012.11.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871640937&doi=10.1016%2fj.heares.2012.11.023&partnerID=40&md5=4762c4486892fdcf0706543adb451ae0,"Normal-hearing listeners can perceptually segregate concurrent sound sources, but listeners with significant hearing loss or who wear a Cochlear Implant (CI) lag behind in this ability. Perceptual grouping mechanisms are essential to segregate concurrent sound sources and affect Comodulation Masking Release (CMR). Thus, CMR measurements in CI users could shed light on segregation cues needed for forming and grouping of auditory objects. CMR illustrates the fact that detection of a target sound embedded in a fluctuating masker is improved by the addition of masker energy remote from the target frequency, provided the envelope fluctuations across masker components are coherent. We modified such a CMR experiment to electrically-induced hearing using direct stimulation and measured the effect in 21 CI users. Cluster analysis of our data revealed two groups: one showed no or only small CMR of 0.1 dB ± 2.7 (N = 14) and a second group achieved a CMR of 10.7 dB ± 3.2 (N = 7), a value that is close to the enhancement observed in a comparable acoustic experiment in normal-hearing listeners (12.9 dB ± 2.6, N = 6). Interestingly, we observed that CMR in CI users may relate to hearing etiology and duration of hearing loss pre-implantation. Our study demonstrates for the first time that a substantial minority of cochlear-implant listeners (about a third) can show significant CMR. This outcome motivates the development of physiologically inspired multi-band gain control and/or different coding strategies for these groups in order to better preserve coherent modulation and thus to take advantage of the individual remaining capabilities to analyze spectro-temporal patterns. © 2012 Elsevier B.V..",23220120,Article,Final,,Scopus,2-s2.0-84871640937
Howell K.B.; McMahon J.M.; Carvill G.L.; Tambunan D.; Mackay M.T.; Rodriguez-Casero V.; Webster R.; Clark D.; Freeman J.L.; Calvert S.; Olson H.E.; Mandelstam S.; Poduri A.; Mefford H.C.; Harvey A.S.; Scheffer I.E.,"Howell, Katherine B. (57210784884); McMahon, Jacinta M. (56605585500); Carvill, Gemma L. (24723693100); Tambunan, Dimira (55356407300); Mackay, Mark T. (7103172855); Rodriguez-Casero, Victoria (6505985322); Webster, Richard (35587406100); Clark, Damian (56602126600); Freeman, Jeremy L. (55472392300); Calvert, Sophie (24281063100); Olson, Heather E. (41562009700); Mandelstam, Simone (6603576169); Poduri, Annapurna (9269628600); Mefford, Heather C. (6602349321); Harvey, A. Simon (7402410288); Scheffer, Ingrid E. (7006332397)",57210784884; 56605585500; 24723693100; 55356407300; 7103172855; 6505985322; 35587406100; 56602126600; 55472392300; 24281063100; 41562009700; 6603576169; 9269628600; 6602349321; 7402410288; 7006332397,SCN2A encephalopathy,2015,Neurology,85,11,,958,966,8,191,10.1212/WNL.0000000000001926,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947230795&doi=10.1212%2fWNL.0000000000001926&partnerID=40&md5=13cdabc3e70a2e1114622d361af69354,"Objective: De novo SCN2A mutations have recently been associated with severe infantile-onset epilepsies. Herein, we define the phenotypic spectrum of SCN2A encephalopathy. Methods: Twelve patients with an SCN2A epileptic encephalopathy underwent electroclinical phenotyping. Results: Patients were aged 0.7 to 22 years; 3 were deceased. Seizures commenced on day 1-4 in 8, week 2-6 in 2, and after 1 year in 2. Characteristic features included clusters of brief focal seizures with multiple hourly (9 patients), multiple daily (2), or multiple weekly (1) seizures, peaking at maximal frequency within 3 months of onset. Multifocal interictal epileptiform discharges were seen in all. Three of 12 patients had infantile spasms. The epileptic syndrome at presentation was epilepsy of infancy with migrating focal seizures (EIMFS) in 7 and Ohtahara syndrome in 2. Nine patients had improved seizure control with sodium channel blockers including supratherapeutic or high therapeutic phenytoin levels in 5. Eight had severe to profound developmental impairment. Other features included movement disorders (10), axial hypotonia (11) with intermittent or persistent appendicular spasticity, early handedness, and severe gastrointestinal symptoms. Mutations arose de novo in 11 patients; paternal DNA was unavailable in one. Conclusions: Review of our 12 and 34 other reported cases of SCN2A encephalopathy suggests 3 phenotypes: neonatal-infantile-onset groups with severe and intermediate outcomes, and a childhood-onset group. Here, we show that SCN2A is the second most common cause of EIMFS and, importantly, does not always have a poor developmental outcome. Sodium channel blockers, particularly phenytoin, may improve seizure control. © 2015 American Academy of Neurology.",26291284,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84947230795
,,,"Human Capital Development for Progress: 2009 ITI 7th International Conference on Information and Communications Technology, ICICT 2009",2009,"Human Capital Development for Progress: 2009 ITI 7th International Conference on Information and Communications Technology, ICICT 2009",,,,,,106,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949316500&partnerID=40&md5=55762340489c66abd08f0eb25bddc44f,The proceedings contain 11 papers. The topics discussed include: creating a strategic competitive advantage for an offshoring outsourcing industry; competency management and assessment - the inseparable elements of a quality framework for human resources development; industry institute interaction for capability building in engineering education in India: a study on the Indian information technology companies; e-learning for healthcare professionals towards his in Egypt; distance education degree programs for the Malaysian working adults: acceptability and negotiability perspectives; characterizing leadership and role management for resource sharing; computer mediated collaborative learning; clustering of content supporting computer mediated courseware development; human capital development: the importance of constructing auditory processing intervention instrument for underachiever students; and accessibility system for deaf Arab students.,,Conference review,Final,,Scopus,2-s2.0-77949316500
Tsai L.P.; Liao H.-M.; Chen Y.-J.; Fang J.-S.; Chen C.-H.,"Tsai, L.P. (7203033466); Liao, H.-M. (7201506792); Chen, Y.-J. (7601438568); Fang, J.-S. (7402966217); Chen, Chia-Hsiang (35197794800)",7203033466; 7201506792; 7601438568; 7402966217; 35197794800,A novel microdeletion at chromosome 2q31.1-31.2 in a three-generation family presenting duplication of great toes with clinodactyly,2009,Clinical Genetics,75,5,,449,456,7,15,10.1111/j.1399-0004.2008.01147.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-65449134777&doi=10.1111%2fj.1399-0004.2008.01147.x&partnerID=40&md5=26f0d75946a8e7c071b7a2c975fb5623,"HOXD gene cluster maps to chromosome 2q31 and plays a key role in embryonic limb morphogenesis. Mutations of the HOXD13 and HOXD10 genes have been found to be associated with digital and limb malformations. In addition, dysregulation of HOXD gene cluster has been proposed to account for the limb abnormalities in patients with chromosome 2q rearrangements. In this report, we investigated a three-generation family presenting clinical phenotypes of duplication of great toes, tapering fingers, and clinodactyly of the fifth finger in both hands, which were transmitted in a dominant fashion in this family. We identified and validated an interstitial microdeletion of ∼3.4Mb at chromosome 2q31.1-31.2 by array-based comparative genomic hybridization, fluorescence in situ hybridization, and real-time quantitative polymerase chain reaction that cosegregates with the clinical phenotypes in this family. The microdeletion removes 30 labeled genes including the entire HOXD gene cluster, suggesting that the digital abnormalities of this family may be attributed to the haploinsufficiency of the HOXD gene cluster. The delineation of the microdeletion region may contribute to the genotype-phenotype correlation study in patients with genomic rearrangements of the long arm of chromosome 2 and helps to understand the pathogenesis of haploinsufficiency of the HOXD gene cluster. © 2009 John Wiley & Sons A/S.",19459884,Article,Final,,Scopus,2-s2.0-65449134777
Liu C.; Xing G.; Xu X.; Chen Z.; Zhou H.; Wang D.; Tian H.; Bu X.,"Liu, Cheng (48561247800); Xing, Guangqian (55767037000); Xu, Xia (56168074900); Chen, Zhibin (55605762653); Zhou, Han (56074286400); Wang, Dengyuan (15520332900); Tian, Huiqin (35207033200); Bu, Xingkuan (7103052929)",48561247800; 55767037000; 56168074900; 55605762653; 56074286400; 15520332900; 35207033200; 7103052929,[The application of improved CHQS for mass epidemiology study on hearing impairment].,2010,"Lin chuang er bi yan hou tou jing wai ke za zhi = Journal of clinical otorhinolaryngology, head, and neck surgery",24,1,,19,"20,24",,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052062035&partnerID=40&md5=590b99f677b37b6eab6f595430107751,"To develop and evaluate the improved Chinese hearing questionnaire for school children (CHQS) for mass epidemiology study on hearing impairment in China. Using the probability proportion to size (PPS) method, 8412 residents were investigated in 40 clusters in Jiangsu province with the WHO ear diseases and hearing disorders survey protocol. 87.9% of the residents aged 7 years and over answered the questionnaire and accepted the pure tone audiometry. The prevalence of hearing impairment was 12.9% by the questionnaire. Compared with ""golden standard"" (pure tone audiometry), Sen = 58.5%, Spe = 96.7%, PV+ = 78.9%, PV- = 91.7%, overall accuracy = 90.0%. The sensitivity for women was higher than men. The questionnaire produced high efficiency and specificity values. It could be used in mass hearing screening, particularly in remote and rural area, although the sensitivity was as low as most questionnaires.",20235451,Article,Final,,Scopus,2-s2.0-80052062035
Coppens K.M.; Tellings A.; Verhoeven L.; Schreuder R.,"Coppens, Karien M. (36008302000); Tellings, Agnes (6506633056); Verhoeven, Ludo (6603731251); Schreuder, Robert (36805750100)",36008302000; 6506633056; 6603731251; 36805750100,Reading vocabulary in children with and without hearing loss: The roles of task and word type,2013,"Journal of Speech, Language, and Hearing Research",56,2,,654,666,12,13,10.1044/1092-4388(2012/11-0138),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878090286&doi=10.1044%2f1092-4388%282012%2f11-0138%29&partnerID=40&md5=6ec8f5b4548d38fbcc0df5238cfd39c2,"Purpose: To address the problem of low reading comprehension scores among children with hearing impairment, it is necessary to have a better understanding of their reading vocabulary. In this study, the authors investigated whether task and word type differentiate the reading vocabulary knowledge of children with and without severe hearing loss. Method: Seventy-two children with hearing loss and 72 children with normal hearing performed a lexical and a use decision task. Both tasks contained the same 180 words divided over 7 clusters, each cluster containing words with a similar pattern of scores on 8 word properties (word class, frequency, morphological family size, length, age of acquisition, mode of acquisition, imageability, and familiarity). Results: Whereas the children with normal hearing scored better on the 2 tasks than the children with hearing loss, the size of the difference varied depending on the type of task and word. Conclusions: Performance differences between the 2 groups increased as words and tasks became more complex. Despite delays, children with hearing loss showed a similar pattern of vocabulary acquisition as their peers with normal hearing. For the most precise assessment of reading vocabulary possible, a range of tasks and word types should be used. © American Speech-Language-Hearing Association.",23090964,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84878090286
Deike S.; Denham S.L.; Sussman E.,"Deike, Susann (6506110474); Denham, Susan L. (7006765598); Sussman, Elyse (7005297588)",6506110474; 7006765598; 7005297588,Probing auditory scene analysis,2014,Frontiers in Neuroscience,8,SEP,Article 293,,,,4,10.3389/fnins.2014.00293,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907930527&doi=10.3389%2ffnins.2014.00293&partnerID=40&md5=fabf98feb450d67367ce0a3aa3ddc758,[No abstract available],,Editorial,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84907930527
Miya F.; Mutai H.; Fujii M.; Boroevich K.A.; Matsunaga T.; Tsunoda T.,"Miya, Fuyuki (19836851500); Mutai, Hideki (6603240487); Fujii, Masato (7403351669); Boroevich, Keith A. (8505888200); Matsunaga, Tatsuo (7401741650); Tsunoda, Tatsuhiko (7203020452)",19836851500; 6603240487; 7403351669; 8505888200; 7401741650; 7203020452,Gene expression profiling of DBA/2J mice cochleae treated with l-methionine and valproic acid,2015,Genomics Data,5,,,323,325,2,1,10.1016/j.gdata.2015.06.022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937217276&doi=10.1016%2fj.gdata.2015.06.022&partnerID=40&md5=f70e415dd4d09f9612c83916f1dabb2c,"DBA/2J mice, which have homozygous mutations in Cdh23 and Fscn2, are characterized by early onset hearing loss at as early as three-weeks of age (Noben-Trauth et al., 2003 [1]) and are an animal model for progressive hearing loss research. Recently, it has been reported that epigenetic regulatory pathways likely play an important role in hearing loss (Provenzano and Domann, 2007 [2]; Mutai et al., 2009 [3]; Waldhaus et al., 2012 [4]). We previously reported that DBA/2J mice injected subcutaneously with a combination of epigenetic modifying reagents, l-methionine (MET) as methyl donor and valproic acid (VPA) as a pan-histone deacetylases (Hdac) inhibitor, showed a significant attenuation of progressive hearing loss by measuring their auditory brainstem response (ABR) thresholds (Mutai et al., 2015 [5]). Here we present genome wide expression profiling of the DBA/2J mice cochleae, with and without treatment of MET and VPA, to identify the genes involved in the reduction of progressive hearing loss. The raw and normalized data were deposited in NCBI's Gene Expression Omnibus (GEO ID: GSE62173) for ease of reproducibility and reanalysis. © 2015.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84937217276
Chen G.-D.; Stolzberg D.; Lobarinas E.; Sun W.; Ding D.; Salvi R.,"Chen, Guang-Di (7406537343); Stolzberg, Daniel (16043543000); Lobarinas, Edward (6506251900); Sun, Wei (55726611000); Ding, Dalian (7201760987); Salvi, Richard (7005412656)",7406537343; 16043543000; 6506251900; 55726611000; 7201760987; 7005412656,"Salicylate-induced cochlear impairments, cortical hyperactivity and re-tuning, and tinnitus",2013,Hearing Research,295,,,100,113,13,79,10.1016/j.heares.2012.11.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872004463&doi=10.1016%2fj.heares.2012.11.016&partnerID=40&md5=b525125af565a683afe90878ff256ecd,"High doses of sodium salicylate (SS) have long been known to induce temporary hearing loss and tinnitus, effects attributed to cochlear dysfunction. However, our recent publications reviewed here show that SS can induce profound, permanent, and unexpected changes in the cochlea and central nervous system. Prolonged treatment with SS permanently decreased the cochlear compound action potential (CAP) amplitude in vivo. In vitro, high dose SS resulted in a permanent loss of spiral ganglion neurons and nerve fibers, but did not damage hair cells. Acute treatment with high-dose SS produced a frequency-dependent decrease in the amplitude of distortion product otoacoustic emissions and CAP. Losses were greatest at low and high frequencies, but least at the mid-frequencies (10-20 kHz), the mid-frequency band that corresponds to the tinnitus pitch measured behaviorally. In the auditory cortex, medial geniculate body and amygdala, high-dose SS enhanced sound-evoked neural responses at high stimulus levels, but it suppressed activity at low intensities and elevated response threshold. When SS was applied directly to the auditory cortex or amygdala, it only enhanced sound evoked activity, but did not elevate response threshold. Current source density analysis revealed enhanced current flow into the supragranular layer of auditory cortex following systemic SS treatment. Systemic SS treatment also altered tuning in auditory cortex and amygdala; low frequency and high frequency multiunit clusters up-shifted or down-shifted their characteristic frequency into the 10-20 kHz range thereby altering auditory cortex tonotopy and enhancing neural activity at mid-frequencies corresponding to the tinnitus pitch. These results suggest that SS-induced hyperactivity in auditory cortex originates in the central nervous system, that the amygdala potentiates these effects and that the SS-induced tonotopic shifts in auditory cortex, the putative neural correlate of tinnitus, arises from the interaction between the frequency-dependent losses in the cochlea and hyperactivity in the central nervous system. © 2012 Elsevier B.V.",23201030,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84872004463
Verbeek J.H.; Kateman E.; Morata T.C.; Dreschler W.A.; Mischke C.,"Verbeek, Jos H (7005575160); Kateman, Erik (24344235400); Morata, Thais C (6701544260); Dreschler, Wouter A (7003763918); Mischke, Christina (55488876700)",7005575160; 24344235400; 6701544260; 7003763918; 55488876700,Interventions to prevent occupational noise-induced hearing loss.,2012,Cochrane database of systematic reviews (Online),10,,,CD006396,,,66,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871874557&partnerID=40&md5=2cd7a95990e414e840a81cf9c682863a,"Millions of workers worldwide are exposed to noise levels that increase their risk of hearing impairment. Little is known about the effectiveness of hearing loss prevention interventions. To assess the effectiveness of non-pharmaceutical interventions for preventing occupational noise exposure or occupational hearing loss compared to no intervention or alternative interventions. We searched the Cochrane Central Register of Controlled Trials (CENTRAL); PubMed; EMBASE; CINAHL; Web of Science; BIOSIS Previews; Cambridge Scientific Abstracts; and OSH update to 25 January 2012. We included randomised controlled trials (RCT), controlled before-after studies (CBA) and interrupted time-series (ITS) of non-clinical hearing loss prevention interventions under field conditions among workers exposed to noise. Two authors independently assessed study eligibility and risk of bias and extracted data. We included 25 studies. We found no controlled studies on engineering controls for noise exposure but one study evaluated legislation to reduce noise exposure in a 12-year time-series analysis. Eight studies with 3,430 participants evaluated immediate and long-term effects of personal hearing protection devices (HPDs) and sixteen studies with 82,794 participants evaluated short and long-term effects of hearing loss prevention programmes (HLPPs). The overall quality of studies was low to very low.The one ITS study that evaluated the effect of new legislation in reducing noise exposure found that the median noise level decreased by 27.7 dB(A) (95% confidence interval (CI) -36.1 to -19.3 dB) immediately after the implementation of stricter legislation and that this was associated with a favourable downward trend in time of -2.1 dB per year (95% CI -4.9 to 0.7).Hearing protection devices attenuated noise with about 20 dB(A) with variation among brands and types but for ear plugs these findings depended almost completely on proper instruction of insertion. Noise attenuation ratings of hearing protection under field conditions were consistently lower than the ratings provided by the manufacturers.One cluster-RCT compared a three-year information campaign as part of a hearing loss prevention programme for agricultural students to audiometry only with three and 16-year follow-up but there were no significant differences in hearing loss. Another study compared a HLPP, which provided regular personal noise exposure information, to a programme without this information in a CBA design. Exposure information was associated with a favourable but non-significant reduction of the rate of hearing loss of -0.82 dB per year (95% CI -1.86 to 0.22). Another cluster-RCT evaluated the effect of extensive on-site training sessions and the use of personal noise-level indicators versus information only on noise levels but did not find a significant difference after four months follow-up (Mean Difference (MD) -0.30 dB(A) (95%CI -3.95 to 3.35).There was very low quality evidence in four very long-term studies, that better use of HPDs as part of a HLPP decreased the risk of hearing loss compared to less well used hearing protection in HLPPs. Other aspects of the HLPP such as training and education of workers or engineering controls did not show a similar effect.In four long-term studies, workers in a HLPP still had a 0.5 dB greater hearing loss at 4 kHz than workers that were not exposed to noise (95% CI -0.5 to 1.7) which is about the level of hearing loss caused by exposure to 85 dB(A). In addition, two other studies showed substantial risk of hearing loss in spite of the protection of a HLPP compared to non-exposed workers. There is low quality evidence that implementation of stricter legislation can reduce noise levels in workplaces. Even though case studies show that substantial reductions in noise levels in the workplace can be achieved, there are no controlled studies of the effectiveness of such measures. The effectiveness of hearing protection devices depends on training and their proper use. There is very low quality evidence that the better use of hearing protection devices as part of HLPPs reduces the risk of hearing loss, whereas for other programme components of HLPPs we did not find such an effect. Better implementation and reinforcement of HLPPs is needed. Better evaluations of technical interventions and long-term effects are needed.",23076923,Review,Final,,Scopus,2-s2.0-84871874557
Haque S.; Togneri R.,"Haque, Serajul (8940578800); Togneri, Roberto (6603345772)",8940578800; 6603345772,Perceptual features for robust speech recognition,2011,"Deafness, Hearing Loss and the Auditory System",,,,333,374,41,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893005470&partnerID=40&md5=f5c981f658843d0818db49b4c38e6372,"Automatic speech recognition (ASR) broadly encompasses the recognition of human speech by a machine or by some artificial intelligence. The recognition process should be robust, that is, it should accurately recognise the spoken word in the presence of speaker variabilities, word perplexities, and speech corrupted by noise which are introduced during transmission and in the communication channels itself. Research in the past several decades has produced speech processing techniques like the short-time Fourier transform (STFT), the linear prediction (LP) and autoregressive (AR) methods, and the mel-frequency cepstral coefficients (MFCC), which have contributed significantly to robust speech recognition. The ability of the human auditory system to recognize speech in adverse and noisy conditions has motivated speech researchers to include features of human perception in speech recognition systems. Particularly in the early 1980s, several computational models of the auditory periphery based on physiological measurements of the response on individual fibres of the auditory nerve were proposed [1],[2],[3]. These ""cochlear models"" only provided marginal improvements at higher computational costs when applied to speech recognition. As a result, a decline in the interest in auditory models was observed until computing resources were able to meet the intensive computational requirements of such models. In recent years, there has been a resurgence in perceptual speech processing after research provided evidence that it may lead to improved recognition performances [12],[13],[14]. This chapter describes several psychoacoustic properties ofthe peripheral auditorysys-tem applied to a speech recognition front-end. Dynamic behaviour of the auditory nerves are incorporated in speech parametrization utilizing temporal processing, so that time domain information as appropriate time constants are incorporated in speech parameterization. A simplified method of synaptic adaptation as determined by psychoacoustic observations in an auditory nerve is described. It utilizes a high pass infinite impulse response (IIR) temporal filter to enhance the signal onsets and the subsequent dynamic and the steady-state characteristics [15],[16]. Speech features are extracted in the temporal mode utilizing a zero-crossing algorithm [5]. The two-tone suppression as observed in the non-linear response of the basilar membrane is described in a zero-crossing auditory front-end using a temporal companding strategy [18],[17]. This may introduce asymmetric gain control without degrading the spectral contrast. The word recognitions are evaluated by continuous density hidden Markov models and are shown to provide improvements over conventional parameterizations in clean and noise conditions. Some ofthese perceptual algorithms may also benefit people with sensorineural hearing loss and may be implemented in hearing aids and cochlear implants for the hearing impaired through VLSI implementations [18]. ©2010 Nova Science Publishers, Inc. All rights reserved.",,Book chapter,Final,,Scopus,2-s2.0-84893005470
Takada Y.; Beyer L.A.; Swiderski D.L.; O'Neal A.L.; Prieskorn D.M.; Shivatzki S.; Avraham K.B.; Raphael Y.,"Takada, Yohei (36133941100); Beyer, Lisa A. (7101994613); Swiderski, Donald L. (35493322600); O'Neal, Aubrey L. (55990509900); Prieskorn, Diane M. (6603737569); Shivatzki, Shaked (55578880200); Avraham, Karen B. (7007074258); Raphael, Yehoash (35468719800)",36133941100; 7101994613; 35493322600; 55990509900; 6603737569; 55578880200; 7007074258; 35468719800,Connexin 26 null mice exhibit spiral ganglion degeneration that can be blocked by BDNF gene therapy,2014,Hearing Research,309,,,124,135,11,43,10.1016/j.heares.2013.11.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891766892&doi=10.1016%2fj.heares.2013.11.009&partnerID=40&md5=d1ea3ee424325eb0f55b8acc1f0eb59c,"Mutations in the connexin 26 gene (GJB2) are the most common genetic cause of deafness, leading to congenital bilateral non-syndromic sensorineural hearing loss. Here we report the generation of a mouse model for a connexin 26 (Cx26) mutation, in which cre-Sox10 drives excision of the Cx26 gene from non-sensory cells flanking the auditory epithelium. We determined that these conditional knockout mice, designated Gjb2-CKO, have a severe hearing loss. Immunocytochemistry of the auditory epithelium confirmed absence of Cx26 in the non-sensory cells. Histology of the organ of Corti and the spiral ganglion neurons (SGNs) performed at ages 1, 3, or 6 months revealed that in Gjb2-CKO mice, the organ of Corti began to degenerate in the basal cochlear turn at an early stage, and the degeneration rapidly spread to the apex. In addition, the density of SGNs in Rosenthal's canal decreased rapidly along a gradient from the base of the cochlea to the apex, where some SGNs survived until at least 6 months of age. Surviving neurons often clustered together and formed clumps of cells in the canal. We then assessed the influence of brain derived neurotrophic factor (BDNF) gene therapy on the SGNs of Gjb2-CKO mice by inoculating Adenovirus with the BDNF gene insert (Ad.BDNF) into the base of the cochlea via the scala tympani or scala media. We determined that over-expression of BDNF beginning around 1 month of age resulted in a significant rescue of neurons in Rosenthal's canal of the cochlear basal turn but not in the middle or apical portions. This data may be used to design therapies for enhancing the SGN physiological status in all GJB2 patients and especially in a sub-group of GJB2 patients where the hearing loss progresses due to ongoing degeneration of the auditory nerve, thereby improving the outcome of cochlear implant therapy in these ears. © 2013 Elsevier B.V.",24333301,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84891766892
Allen P.D.; Eddins D.A.,"Allen, Paul D. (57203600614); Eddins, David A. (6701739273)",57203600614; 6701739273,Presbycusis phenotypes form a heterogeneous continuum when ordered by degree and configuration of hearing loss,2010,Hearing Research,264,01-Feb,,10,20,10,47,10.1016/j.heares.2010.02.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952671979&doi=10.1016%2fj.heares.2010.02.001&partnerID=40&md5=153be10873c06377018c838d4dcc7998,"Many reports have documented age-by-frequency increases in average auditory thresholds in various human populations. Despite this, the prevalence of different patterns of hearing loss in presbycusis remains uncertain. We examined 'presbycusis phenotypes' in a database of 960 subjects (552 female, 408 male, 18-92years) that each had 30 measures of peripheral hearing sensitivity: pure tone audiograms for left and right ears from 0.25 to 8kHz and DPOAE for each ear with Fmean=1-6.4kHz. Surprisingly, the hearing phenotypes did not naturally separate into discrete classes of presbycusis. Principal component (PC) analysis revealed that two principal components account for 74% of the variance among the 30 measures of hearing. The two components represent the overall degree (PC1) and configuration of loss (Flat vs. Sloping; PC2) and the phenotypes form a continuum when plotted against them. A heuristic partitioning of this continuum produced classes of presbycusis that vary in their degree of Sloping or Flat hearing loss, suggesting that the previously reported sub-types of presbycusis arise from the categorical segregation of a continuous and heterogeneous distribution. Further, most phenotypes lie intermediate to the extremes of either Flat or Sloping loss, indicating that if audiometric configuration does predict presbycusis etiology, then a mixed origin is the most prevalent. © 2010 Elsevier B.V.",20144701,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-77952671979
Huber M.; Burger T.; Illg A.; Kunze S.; Giourgas A.; Braun L.; Kröger S.; Nickisch A.; Rasp G.; Becker A.; Keilmann A.,"Huber, Maria (8598148600); Burger, Thorsten (7006658732); Illg, Angelika (36107888900); Kunze, Silke (8323147000); Giourgas, Alexandros (36448930500); Braun, Ludwig (35868833200); Kröger, Stefanie (26537696800); Nickisch, Andreas (6602486086); Rasp, Gerhard (7003838466); Becker, Andreas (57203272195); Keilmann, Annerose (7003687645)",8598148600; 7006658732; 36107888900; 8323147000; 36448930500; 35868833200; 26537696800; 6602486086; 7003838466; 57203272195; 7003687645,Mental health problems in adolescents with cochlear implants: Peer problems persist after controlling for additional handicaps,2015,Frontiers in Psychology,6,JUL,953,,,,33,10.3389/fpsyg.2015.00953,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941220978&doi=10.3389%2ffpsyg.2015.00953&partnerID=40&md5=d88da5c180398f90d0129f7d30c26778,"The aims of the present multi-center study were to investigate the extent of mental health problems in adolescents with a hearing loss and cochlear implants (CIs) in comparison to normal hearing (NH) peers and to investigate possible relations between the extent of mental health problems of young CI users and hearing variables, such as age at implantation, or functional gain of CI. The survey included 140 adolescents with CI (mean age = 14.7, SD = 1.5 years) and 140 NH adolescents (mean age = 14.8, SD = 1.4 years), their parents and teachers. Participants were matched by age, gender and social background. Within the CI group, 35 adolescents were identified as ""risk cases"" due to possible and manifest additional handicaps, and 11 adolescents were non-classifiable. Mental health problems were assessed with the Strengths and Difficulties Questionnaire (SDQ) in the versions ""Self,"" ""Parent,"" and ""Teacher."" The CI group showed significantly more ""Peer Problems"" than the NH group. When the CI group was split into a ""risk-group"" (35 ""risk cases"" and 11 non-classifiable persons) and a ""non-risk group"" (n = 94), increased peer problems were perceived in both CI subgroups by adolescents themselves. However, no further differences between the CI non-risk group and the NH group were observed in any rater. The CI risk-group showed significantly more hyperactivity compared to the NH group and more hyperactivity and conduct problems compared to the CI non-risk group. Cluster analyses confirmed that there were significantly more adolescents with high problems in the CI risk-group compared to the CI non-risk group and the NH group. Adolescents with CI, who were able to understand speech in noise had significantly less difficulties compared to constricted CI users. Parents, teachers, and clinicians should be aware that CI users with additionally special needs may have mental health problems. However, peer problems were also experienced by CI adolescents without additional handicaps. © 2015 Huber, Burger, Illg, Kunze, Giourgas, Braun, Kröger, Nickisch, Rasp, Becker and Keilmann.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84941220978
,,,"Proceedings of the 2013 IEEE Symposium on Computational Intelligence in Rehabilitation and Assistive Technologies, CIRAT 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013",2013,"Proceedings of the 2013 IEEE Symposium on Computational Intelligence in Rehabilitation and Assistive Technologies, CIRAT 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013",,,,,,56,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886665581&partnerID=40&md5=12e9170465baead2dae0461c58a87557,The proceedings contain 8 papers. The topics discussed include: a novel hand strength assessment method integrated into haptic knob for stroke rehabilitation; classification of silent speech using adaptive collection; real-time upper-body detection and orientation estimation via depth cues for assistive technology; handheld device based personal auditory training system to hearing loss; control of a wheelchair using an adaptive k-means clustering of head poses; a biomimetic similarity index for prosthetic hands; effects of behavior network as a suggestion system to assist BCI users; and gesture recognition system for wheelchair control using a depth sensor.,,Conference review,Final,,Scopus,2-s2.0-84886665581
Laplante-Lévesque A.; Nielsen C.; Jensen L.D.; Naylor G.,"Laplante-Lévesque, Ariane (6506488140); Nielsen, Claus (57057009100); Jensen, Lisbeth Dons (55499191400); Naylor, Graham (12761085700)",6506488140; 57057009100; 55499191400; 12761085700,Patterns of hearing aid usage predict hearing aid use amount (data logged and self-reported) and overreport,2014,Journal of the American Academy of Audiology,25,2,,187,198,11,44,10.3766/jaaa.25.2.7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901274673&doi=10.3766%2fjaaa.25.2.7&partnerID=40&md5=c432c8010dd44f2f86619ce48b774119,"Background: Previous studies found that, on average, users overreport their daily amount of hearing aid use compared to objective measures such as data logging. However, the reasons for this are unclear. Purpose: This study assessed data-logged and self-reported amount of hearing aid use in a clinical sample of hearing aid users. It identified predictors of data-logged hearing aid use, self-reported hearing aid use, and hearing aid use overreport. Research Design: This observational study recruited adult hearing aid users from 22 private dispensers in the Netherlands and in Denmark. Study Sample: The sample consisted of 228 hearing aid users. Typical participants were over the age of 65 and retired, were fitted binaurally, and had financially contributed to the cost of their hearing aids. Participants had on average a mild-to-severe sloping bilateral hearing impairment. Data Collection and Analysis: Participants completed a purposefully designed questionnaire regarding hearing aid usage and the International Outcome Inventory - Hearing Aids. Dispensers collected audiometric results and data logging. Multiple linear regression identified predictors of data-logged hearing aid use, self-reported hearing aid use, and hearing aid use overreport when controlling for covariates. Results: Data logging showed on average 10.5 hr of hearing aid use (n = 184), while participants reported on average 11.8 hr of daily hearing aid use (n = 206). In participants for which both data-logged and self-reported hearing aid use data were available (n = 166), the average absolute overreport of daily hearing aid use was 1.2 (1 hr and 11 min). Relative overreport was expressed as a rate of absolute overreport divided by data-logged hearing aid use. A positive rate denotes hearing aid use overreport: the average overreport rate was .38. Cluster analysis identified two data-logged patterns: ""Regular,"" where hearing aids are typically switched on for between 12 and 20 hr before their user powers them off (57% of the sample), and ""On-off,"" where hearing aids are typically switched on for shorter periods of time before being powered off (43% of the sample). In terms of self-report, 77% of the sample described their hearing aid use to be the same every day, while 23% of the sample described their hearing aid use to be different from day to day. Participants for whom data logging showed an On-off pattern or who reported their hearing aid use to be different from day to day had significantly fewer data-logged and self-reported hours of hearing aid use. Having an On-off data-logging pattern or describing hearing aid use as the same every day was associated with a significantly greater hearing aid use overreport. Conclusions: Data-logged and self-reported usage patterns significantly predicted data-logged hearing aid use, self-reported hearing aid use, and overreport when controlling for covariates. The results point to patterns of hearing aid usage as being at least as important a concept as amount of hearing aid use. Dispensers should discuss not only the ""how much"", but also the ""how"" of hearing aid usage with their clients.",24828219,Article,Final,,Scopus,2-s2.0-84901274673
Oshima K.; Shin K.; Diensthuber M.; Peng A.W.; Ricci A.J.; Heller S.,"Oshima, Kazuo (14036069600); Shin, Kunyoo (7402410434); Diensthuber, Marc (36110585800); Peng, Anthony W. (25646523100); Ricci, Anthony J. (7202337862); Heller, Stefan (7101979349)",14036069600; 7402410434; 36110585800; 25646523100; 7202337862; 7101979349,Mechanosensitive Hair Cell-like Cells from Embryonic and Induced Pluripotent Stem Cells,2010,Cell,141,4,,704,716,12,261,10.1016/j.cell.2010.03.035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952493569&doi=10.1016%2fj.cell.2010.03.035&partnerID=40&md5=ff33170ccecc4f63920a3fc689aabbae,"Mechanosensitive sensory hair cells are the linchpin of our senses of hearing and balance. The inability of the mammalian inner ear to regenerate lost hair cells is the major reason for the permanence of hearing loss and certain balance disorders. Here, we present a stepwise guidance protocol starting with mouse embryonic stem and induced pluripotent stem cells, which were directed toward becoming ectoderm capable of responding to otic-inducing growth factors. The resulting otic progenitor cells were subjected to varying differentiation conditions, one of which promoted the organization of the cells into epithelial clusters displaying hair cell-like cells with stereociliary bundles. Bundle-bearing cells in these clusters responded to mechanical stimulation with currents that were reminiscent of immature hair cell transduction currents. © 2010 Elsevier Inc.",20478259,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-77952493569
Kim E.; Kang H.; Lee H.; Lee H.-J.; Suh M.-W.; Song J.-J.; Oh S.-H.; Lee D.S.,"Kim, Eunkyung (57205350824); Kang, Hyejin (56525710600); Lee, Hyekyoung (14919622000); Lee, Hyo-Jeong (54581192700); Suh, Myung-Whan (7103253889); Song, Jae-Jin (56294178300); Oh, Seung-Ha (56582818600); Lee, Dong Soo (56580452900)",57205350824; 56525710600; 14919622000; 54581192700; 7103253889; 56294178300; 56582818600; 56580452900,Morphological brain network assessed using graph theory and network filtration in deaf adults,2014,Hearing Research,315,,,88,98,10,33,10.1016/j.heares.2014.06.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904862389&doi=10.1016%2fj.heares.2014.06.007&partnerID=40&md5=39650ebaa46e26e19822c1bdf654712e,"Prolonged deprivation of auditory input can change brain networks in pre- and postlingual deaf adults by brain-wide reorganization. To investigate morphological changes in these brains voxel-based morphometry, voxel-wise correlation with the primary auditory cortex, and whole brain network analyses using morphological covariance were performed in eight prelingual deaf, eleven postlingual deaf, and eleven hearing adults. Network characteristics based on graph theory and network filtration based on persistent homology were examined. Gray matter density in the primary auditor cortex was preserved in prelingual deafness, while it tended to decrease in postlingual deafness. Unlike postlingual, prelingual deafness showed increased bilateral temporal connectivity of the primary auditory cortex compared to the hearing adults.Of the graph theory-based characteristics, clustering coefficient, betweenness centrality, and nodal efficiency all increased in prelingual deafness, while all the parameters of postlingual deafness were similar to the hearing adults. Patterns of connected components changing during network filtration were different between prelingual deafness and hearing adults according to the barcode, dendrogram, and single linkage matrix representations, while these were the same in postlingual deafness. Nodes in fronto-limbic and left temporal components were closely coupled, and nodes in the temporo-parietal component were loosely coupled, in prelingual deafness. Patterns of connected components changing in postlingual deafness were the same as hearing adults. We propose that the preserved density of auditory cortex associated with increased connectivity in prelingual deafness, and closer coupling between certain brain areas, represent distinctive reorganization of auditory and related cortices compared with hearing or postlingual deaf adults. The differential network reorganization in the prelingual deaf adults could be related to the absence of auditory speech experience. © 2014 Elsevier B.V.",25016143,Article,Final,,Scopus,2-s2.0-84904862389
Sharma S.; Nag T.C.; Bhardwaj D.N.; Vanamail P.; Roy T.S.,"Sharma, S. (55734218200); Nag, T.C. (6603950309); Bhardwaj, D.N. (7003388665); Vanamail, Perumal (6701666881); Roy, T.S. (7202953212)",55734218200; 6603950309; 7003388665; 6701666881; 7202953212,Changing population of neurons and glia in the human cochlear nucleus with progressive age - A stereological study,2014,Journal of the Anatomical Society of India,63,2,,142,150,8,6,10.1016/j.jasi.2014.11.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920617424&doi=10.1016%2fj.jasi.2014.11.002&partnerID=40&md5=5b6a67e596e188d39a2dcf5f5b549fa8,"Introduction: The human cochlear nucleus (CN) is populated by morphologically diverse types of neurons that contribute specifically in the formation of the complex functional networks in the auditory pathway. On the basis of cytoarchitecture and topography different types of neurons can be identified in the CN. The present study was undertaken to investigate the morphological parameters of neurons and glia of the human CN with aging. Methods: Forty-one brainstems (Birth-90 years) from cadaveric donors were collected from the mortuary of the All India Institute of Medical Sciences (AIIMS), New Delhi, with ethical committee permission. They were grouped into nine decades and processed for light microscopy and morphometry. Hierarchical clustering was done to classify the neuron population according to their neuronal and nuclear area into different clusters. Results: There was a gradual increase in the mean neuronal and neuronal nucleus volume from decade 1 to 3. Decade 1 had minimum and 3 had maximum nuclear volume and neuron number respectively. An increase in total glial population was observed in decade 9. Eight neuron clusters were identified which were present in the decades 2 and 3 whereas decades 1 and 4 had seven, decades 5-8 had six and decade 9 had four clusters respectively. Discussion: Major changes were observed within the clusters from middle to old age, especially after decade 5. This may be useful in explaining the vulnerability of some specific subpopulation of neurons more than others and understanding the pathophysiology of altered hearing loss with age. © 2014 Anatomical Society of India.",,Article,Final,,Scopus,2-s2.0-84920617424
Jiang J.; Jia J.; Tian Y.; Wang Y.; Cai L.,"Jiang, Jianbo (55605502700); Jia, Jia (35200619700); Tian, Ye (57198239193); Wang, Yongxin (37074941400); Cai, Lianhong (7401563540)",55605502700; 35200619700; 57198239193; 37074941400; 7401563540,Tone enhancing model for disyllable words in Chinese Mandarin speech,2014,Applied Mathematics and Information Sciences,8,1 L,,201,208,7,0,10.12785/amis/081L25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896867113&doi=10.12785%2famis%2f081L25&partnerID=40&md5=577e23fa1c0d28a0ebb5e1ef55dd4e7a,"Tone recognition is the core function in Chinese speech perception. The tone perception ability of people with sensorineural hearing loss (SNHL) is often weaker than normal people. Automatically tone enhancement would be useful in helping them understand Chinese speech better. In this paper, we focus on the tone enhancing model for Chinese disyllable words. We first analyze the acoustic features related to tone perception. By agglomerative hierarchical clustering method, the first and second syllables of disyllable words are clustered into 6 clusters respectively. Discriminative features of these clusters are experimentally determined from a set of possible features related to tone perception, such as the pitch value, pitch range and position of minimum pitch, etc. We further propose a practicable tone enhancing model with these discriminative features: 1) an input pitch contour is classified by calculating the distance between it and the centroid of each cluster, and 2) selecting the smallest distance, then the unclassified pitch contour belongs to this cluster, 3) the pitch contour is modified for tone enhancement with model parameters corresponding to this cluster using TD-PSOLA. Both statistical and subjective experiments show that higher hit rate of tone recognition can be obtained after tone enhancement with the proposed model. Especially, the proposed enhancing model can also avoid traditional tone recognition, which is more convictive and less laborious. © 2014 NSP Natural Sciences Publishing Cor.",,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84896867113
Konrad-Martin D.; Reavis K.M.; McMillan G.P.; Dille M.F.,"Konrad-Martin, Dawn (6603455821); Reavis, Kelly M. (15726372000); McMillan, Garnett P. (7006767888); Dille, Marilyn F. (22733744300)",6603455821; 15726372000; 7006767888; 22733744300,Multivariate DPOAE metrics for identifying changes in hearing: Perspectives from ototoxicity monitoring,2012,International Journal of Audiology,51,SUPPL. 1,,S51,S62,11,20,10.3109/14992027.2011.635713,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856155838&doi=10.3109%2f14992027.2011.635713&partnerID=40&md5=d7112693b107f9ef8327c47d27af6834,"Distortion-product otoacoustic emissions (DPOAEs) provide a window into real-time cochlear mechanical function. Yet, relationships between the changes in DPOAE metrics and auditory sensitivity are still poorly understood. Explicating these relationships might support the use of DPOAEs in hearing conservation programs (HCPs) for detecting early damage leading to noise-induced hearing loss (NIHL) so that mitigating steps might be taken to limit any lasting damage. This report describes the development of DPOAE-based statistical models to assess the risk of hearing loss from cisplatin treatment among cancer patients. Ototoxicity risk assessment (ORA) models were constructed using a machine learning paradigm in which partial least squares and leave-one-out cross-validation were applied, yielding optimal screening algorithms from a set of known risk factors for ototoxicity and DPOAE changes from pre-exposure baseline measures. Single DPOAE metrics alone were poorer indicators of the risk of ototoxic hearing shifts than the best performing multivariate models. This finding suggests that multivariate approaches applied to the use of DPOAEs in a HCP, will improve the ability of DPOAE measures to identify ears with noise-induced mechanical damage and/or hearing loss at each monitoring interval. This prediction must be empirically assessed in noise-exposed subjects. © 2012 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",22264063,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84856155838
Fernández A.; Marey J.; Ortega M.; Penedo M.G.,"Fernández, A. (36170381500); Marey, J. (57509706200); Ortega, M. (24475406900); Penedo, M.G. (7004450125)",36170381500; 57509706200; 24475406900; 7004450125,Interest operator analysis for automatic assessment of spontaneous gestures in audiometries,2014,ICAART 2014 - Proceedings of the 6th International Conference on Agents and Artificial Intelligence,1,,,221,229,8,0,10.5220/0004926102210229,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902329254&doi=10.5220%2f0004926102210229&partnerID=40&md5=13c61b0cabf084d61c08a4c4e50903a0,"Hearing loss is a common disease which affects a large percentage of the population. Hearing loss may have a negative impact on health, social participation, and daily activities, so its diagnosis and monitoring is indeed important. The audiometric tests related to this diagnosis are constrained when the patient suffers from some form of cognitive impairment. In these cases, audilogist must try to detect particular facial reactions that may indicate auditory perception. With the aim of supporting the audiologist in this evaluation, a screening method that analyzes video sequences and seeks for facial reactions within the eye area was proposed. In this research, a comprehensive survey of one of the most relevent steps of this methodology is presented. This survey considers different alternatives for the detection of the interest points and the classsification techniques. The provided results allow to determine the most suitable configuration for this domain.",,Conference paper,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84902329254
Zou B.; Mittal R.; Grati M.; Lu Z.; Shu Y.; Tao Y.; Feng Y.; Xie D.; Kong W.; Yang S.; Chen Z.-Y.; Liu X.,"Zou, Bing (56673554700); Mittal, Rahul (7202560100); Grati, M'hamed (14058092400); Lu, Zhongmin (7404769187); Shu, Yilai (56577263700); Tao, Yong (57214854051); Feng, Youg (55547104967); Xie, Dinghua (7202588267); Kong, Weijia (56673536800); Yang, Shiming (8074203500); Chen, Zheng-Yi (57209865740); Liu, Xuezhong (26642875300)",56673554700; 7202560100; 14058092400; 7404769187; 56577263700; 57214854051; 55547104967; 7202588267; 56673536800; 8074203500; 57209865740; 26642875300,The application of genome editing in studying hearing loss,2015,Hearing Research,327,,,102,108,6,43,10.1016/j.heares.2015.04.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930667125&doi=10.1016%2fj.heares.2015.04.016&partnerID=40&md5=cba44c47c49731edfb27a805493319a9,"Targeted genome editing mediated by clustered, regularly interspaced, short palindromic repeat (CRISPR)/CRISPR-associated nuclease 9 (Cas9) technology has emerged as one of the most powerful tools to study gene functions, and with potential to treat genetic disorders. Hearing loss is one of the most common sensory disorders, affecting approximately 1 in 500 newborns with no treatment. Mutations of inner ear genes contribute to the largest portion of genetic deafness. The simplicity and robustness of CRISPR/Cas9-directed genome editing in human cells and model organisms such as zebrafish, mice and primates make it a promising technology in hearing research. With CRISPR/Cas9 technology, functions of inner ear genes can be studied efficiently by the disruption of normal gene alleles through non-homologous-end-joining (NHEJ) mechanism. For genetic hearing loss, CRISPR/Cas9 has potential to repair gene mutations by homology-directed-repair (HDR) or to disrupt dominant mutations by NHEJ, which could restore hearing. Our recent work has shown CRISPR/Cas9-mediated genome editing can be efficiently performed in the mammalian inner ear invivo. Thus, application of CRISPR/Cas9 in hearing research will open up new avenues for understanding the pathology of genetic hearing loss and provide new routes in the development of treatment to restore hearing. In this review, we describe major methodologies currently used for genome editing. We will highlight applications of these technologies in studies of genetic disorders and discuss issues pertaining to applications of CRISPR/Cas9 in auditory systems implicated in genetic hearing loss. © 2015 Elsevier B.V.",25987504,Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84930667125
Sommerlad S.F.; Morton J.M.; Haile-Mariam M.; Johnstone I.; Seddon J.M.; O'Leary C.A.,"Sommerlad, Susan F. (6602603716); Morton, John M. (24328459100); Haile-Mariam, Mekonnen (6602532347); Johnstone, Isobel (36956850300); Seddon, Jennifer M. (7103239740); O'Leary, Caroline A. (7005038476)",6602603716; 24328459100; 6602532347; 36956850300; 7103239740; 7005038476,Prevalence of congenital hereditary sensorineural deafness in Australian Cattle Dogs and associations with coat characteristics and sex,2012,BMC Veterinary Research,8,,202,,,,22,10.1186/1746-6148-8-202,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867901688&doi=10.1186%2f1746-6148-8-202&partnerID=40&md5=bcb059b9dd3774666c527c36c43953c5,"Background: Congenital hereditary sensorineural deafness (CHSD) occurs in many dog breeds, including Australian Cattle Dogs. In some breeds, CHSD is associated with a lack of cochlear melanocytes in the stria vascularis, certain coat characteristics, and potentially, abnormalities in neuroepithelial pigment production. This study investigates phenotypic markers for CHSD in 899 Australian Cattle Dogs.Results: Auditory function was tested in 899 Australian Cattle Dogs in family groups using brainstem auditory evoked response testing. Coat colour and patterns, facial and body markings, gender and parental hearing status were recorded.Deafness prevalence among all 899 dogs was 10.8% with 7.5% unilaterally deaf, and 3.3% bilaterally deaf, and amongst pups from completely tested litters (n = 696) was 11.1%, with 7.5% unilaterally deaf, and 3.6% bilaterally deaf.Univariable and multivariable analyses revealed a negative association between deafness and bilateral facial masks (odds ratio 0.2; P ≤ 0.001). Using multivariable logistic animal modelling, the risk of deafness was lower in dogs with pigmented body spots (odds ratio 0.4; P = 0.050).No significant associations were found between deafness and coat colour.Within unilaterally deaf dogs with unilateral facial masks, no association was observed between the side of deafness and side of mask. The side of unilateral deafness was not significantly clustered amongst unilaterally deaf dogs from the same litter. Females were at increased risk of deafness (odds ratio from a logistic animal model 1.9; P = 0.034) after adjusting for any confounding by mask type and pigmented body spots.Conclusions: Australian Cattle Dogs suffer from CHSD, and this disease is more common in dogs with mask-free faces, and in those without pigmented body patches. In unilaterally deaf dogs with unilateral masks, the lack of observed association between side of deafness and side of mask suggests that if CHSD is due to defects in molecular pigment pathways, the molecular control of embryonic melanoblast migration from ectoderm to skin differs from control of migration from ectoderm to cochlea. In Australian Cattle Dogs, CHSD may be more common in females. © 2012 Sommerlad et al.; licensee BioMed Central Ltd.",23107143,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84867901688
Benson R.R.; Gattu R.; Cacace A.T.,"Benson, Randall R. (7202598463); Gattu, Ramtilak (23008054600); Cacace, Anthony T. (7006517674)",7202598463; 23008054600; 7006517674,Left hemisphere fractional anisotropy increase in noise-induced tinnitus: A diffusion tensor imaging (DTI) study of white matter tracts in the brain,2014,Hearing Research,309,,,8,16,8,36,10.1016/j.heares.2013.10.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888121846&doi=10.1016%2fj.heares.2013.10.005&partnerID=40&md5=6cd84b192d5027ba7a633d4e6ce726e3,"Diffusion tensor imaging (DTI) is a contemporary neuroimaging modality used to study connectivity patterns and microstructure of white matter tracts in the brain. The use of DTI in the study of tinnitus is a relatively unexplored methodology with no studies focusing specifically on tinnitus induced by noise exposure. In this investigation, participants were two groups of adults matched for etiology, age, and degree of peripheral hearing loss, but differed by the presence or absence (+/-) of tinnitus. It is assumed that matching individuals on the basis of peripheral hearing loss, allows for differentiating changes in white matter microstructure due to hearing loss from changes due to the effects of chronic tinnitus. Alterations in white matter tracts, using the fractional anisotropy (FA) metric, which measures directional diffusion of water, were quantified using tract-based spatial statistics (TBSS) with additional details provided by in vivo probabilistic tractography. Our results indicate that 10 voxel clusters differentiated the two groups, including 9 with higher FA in the group with tinnitus. A decrease in FA was found for a single cluster in the group with tinnitus. However, seven of the 9 clusters with higher FA were in left hemisphere thalamic, frontal, and parietal white matter. These foci were localized to the anterior thalamic radiations and the inferior and superior longitudinal fasciculi. The two right-sided clusters with increased FA were located in the inferior fronto-occipital fasciculus and superior longitudinal fasciculus. The only decrease in FA for the tinnitus-positive group was found in the superior longitudinal fasciculus of the left parietal lobe. © 2013 Elsevier B.V.",24212050,Article,Final,,Scopus,2-s2.0-84888121846
Leong U.-C.; Barsz K.; Allen P.D.; Walton J.P.,"Leong, U-Cheng (26030446700); Barsz, Kathy (6507400869); Allen, Paul D. (57203600614); Walton, Joseph P. (7401785051)",26030446700; 6507400869; 57203600614; 7401785051,Neural correlates of age-related declines in frequency selectivity in the auditory midbrain,2011,Neurobiology of Aging,32,1,,168,178,10,16,10.1016/j.neurobiolaging.2009.01.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449313444&doi=10.1016%2fj.neurobiolaging.2009.01.006&partnerID=40&md5=cd41f0218ea34dba85d18768ae45e40f,"Reduced frequency selectivity is associated with an age-related decline in speech recognition in background noise and reverberant environments. To elucidate neural correlates of age-related alteration in frequency selectivity, the present study examined frequency response areas (FRAs) of multi-unit clusters in the inferior colliculus of young, middle-aged, and old CBA/CaJ mice. The FRAs in middle-aged and old mice were found to be broader and more asymmetric in shape. In addition to a decrease of closed/complex FRAs in both middle age and old groups, there was a transient decrease in V-shaped FRAs and a concomitant increase in multipeak FRAs in middle age. Intensity coding was also affected by age, as observed in an increase of monotonic responses in middle-aged and old mice. While a decline in low-level activity began in middle age, reduced driven rates at suprathreshold levels occurred later in old age. Collectively, these results support the view that aging alters frequency selectivity by widening excitatory FRAs and that these changes begin to appear in middle age. © 2009 Elsevier Inc.",19246123,Article,Final,,Scopus,2-s2.0-78449313444
McCreery R.W.; Walker E.A.; Spratford M.; Bentler R.; Holte L.; Roush P.; Oleson J.; Van Buren J.; Moeller M.P.,"McCreery, Ryan W. (35230437200); Walker, Elizabeth A. (36612490900); Spratford, Meredith (55535467000); Bentler, Ruth (7003880284); Holte, Lenore (6603558528); Roush, Patricia (14020476500); Oleson, Jacob (14040397100); Van Buren, John (57063085200); Moeller, Mary Pat (7101886426)",35230437200; 36612490900; 55535467000; 7003880284; 6603558528; 14020476500; 14040397100; 57063085200; 7101886426,Longitudinal predictors of aided speech audibility in infants and children,2015,Ear and Hearing,36,,,24S,37S,13,69,10.1097/AUD.0000000000000211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988625065&doi=10.1097%2fAUD.0000000000000211&partnerID=40&md5=a64addcccdbc548e7694ba7d468e332e,"Objectives: Amplification is a core component of early intervention for children who are hard of hearing, but hearing aids (HAs) have unique effects that may be independent from other components of the early intervention process, such as caregiver training or speech and language intervention. The specific effects of amplification are rarely described in studies of developmental outcomes. The primary purpose of this article is to quantify aided speech audibility during the early childhood years and examine the factors that influence audibility with amplification for children in the Outcomes of Children with Hearing Loss study. Design: Participants were 288 children with permanent hearing loss who were followed as part of the Outcomes of Children with Hearing Loss study. All of the children in this analysis had bilateral hearing loss and wore air-conduction behind-the-ear HAs. At every study visit, hearing thresholds were measured using developmentally appropriate behavioral methods. Data were obtained for a total of 1043 audiometric evaluations across all subjects for the first four study visits. In addition, the aided audibility of speech through the HA was assessed using probe microphone measures. Hearing thresholds and aided audibility were analyzed. Repeated-measures analyses of variance were conducted to determine whether patterns of thresholds and aided audibility were significantly different between ears (left versus right) or across the first four study visits. Furthermore, a cluster analysis was performed based on the aided audibility at entry into the study, aided audibility at the child's final visit, and change in aided audibility between these two intervals to determine whether there were different patterns of longitudinal aided audibility within the sample. Results: Eighty-four percent of children in the study had stable audiometric thresholds during the study, defined as threshold changes <10 dB for any single study visit. There were no significant differences in hearing thresholds, aided audibility, or deviation of the HA fitting from prescriptive targets between ears or across test intervals for the first four visits. Approximately 35% of the children in the study had aided audibility that was below the average for the normative range for the Speech Intelligibility Index based on degree of hearing loss. The cluster analysis of longitudinal aided audibility revealed three distinct groups of children: a group with consistently high aided audibility throughout the study, a group with decreasing audibility during the study, and a group with consistently low aided audibility. Conclusions: The current results indicated that approximately 65% of children in the study had adequate aided audibility of speech and stable hearing during the study period. Limited audibility was associated with greater degrees of hearing loss and larger deviations from prescriptive targets. Studies of developmental outcomes will help to determine how aided audibility is necessary to affect developmental outcomes in children who are hard of hearing. Copyright © 2015 Wolters Kluwer Health, Inc. All rights reserved.",26731156,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84988625065
Kushalnagar R.; Ramachandran V.; Oh T.,"Kushalnagar, Raja (36142036500); Ramachandran, Vignesh (57210536211); Oh, Tae (57190755232)",36142036500; 57210536211; 57190755232,Tactile captions: Augmenting visual captions,2014,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),8547 LNCS,PART 1,,25,32,7,0,10.1007/978-3-319-08596-8_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904152842&doi=10.1007%2f978-3-319-08596-8_5&partnerID=40&md5=123067dadb8c4947608d0138c4fff7db,"We explore the efficacy of tactile captions as a supplement to online captioned video. Closed captions are not fully accessible, because many auditory signals are not easily represented by words, e.g., the sound of the ball being hit by a bat, or to describe a ring tone. The goal is to explore whether audiovisual information can be effectively represented through an equivalent tactile-visual interface. We compare viewers preferences between viewing video with captions alone, and captions plus tactile captions. Our study showed that viewers significantly preferred tactile captions to captions. © 2014 Springer International Publishing.",,Conference paper,Final,,Scopus,2-s2.0-84904152842
Waldhaus J.; Cimerman J.; Gohlke H.; Ehrich M.; Müller M.; Löwenheim H.,"Waldhaus, Jörg (23502501100); Cimerman, Jelka (15922200000); Gohlke, Henning (7006624645); Ehrich, Mathias (8899209900); Müller, Marcus (16212781100); Löwenheim, Hubert (55942647300)",23502501100; 15922200000; 7006624645; 8899209900; 16212781100; 55942647300,Stemness of the organ of Corti relates to the epigenetic status of Sox2 enhancers,2012,PLoS ONE,7,5,e36066,,,,22,10.1371/journal.pone.0036066,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860537890&doi=10.1371%2fjournal.pone.0036066&partnerID=40&md5=b1222fe7d786505f3b7a74372c55550e,"In the adult mammalian auditory epithelium, the organ of Corti, loss of sensory hair cells results in permanent hearing loss. The underlying cause for the lack of regenerative response is the depletion of otic progenitors in the cell pool of the sensory epithelium. Here, we show that an increase in the sequence-specific methylation of the otic Sox2 enhancers NOP1 and NOP2 is correlated with a reduced self-renewal potential in vivo and in vitro; additionally, the degree of methylation of NOP1 and NOP2 is correlated with the dedifferentiation potential of postmitotic supporting cells into otic stem cells. Thus, the stemness the organ of Corti is related to the epigenetic status of the otic Sox2 enhancers. These observations validate the continued exploration of treatment strategies for dedifferentiating or reprogramming of differentiated supporting cells into progenitors to regenerate the damaged organ of Corti. © 2012 Waldhaus et al.",22570694,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84860537890
Xu Z.; Li Z.; Chen Y.; He Y.; Chunyu X.; Wang F.; Zhang P.; Gao L.; Qiu S.; Liu S.; Qiao L.; Qiu J.,"Xu, Zhan (57198998400); Li, Zonghua (41861607700); Chen, Yang (36150452300); He, Y. (7404942870); Chunyu, Xiujie (36120059600); Wang, Fangyuan (57207266558); Zhang, Pengzhi (16044456000); Gao, Lei (57198647478); Qiu, Shuping (48561555500); Liu, Shunli (37075167600); Qiao, L. (57220639164); Qiu, Jianhua (7403310284)",57198998400; 41861607700; 36150452300; 7404942870; 36120059600; 57207266558; 16044456000; 57198647478; 48561555500; 37075167600; 57220639164; 7403310284,[Hearing the impact of MP3 on a survey of middle school students].,2011,"Lin chuang er bi yan hou tou jing wai ke za zhi = Journal of clinical otorhinolaryngology, head, and neck surgery",25,4,,151,153,2,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054819671&partnerID=40&md5=b6fe907cb6b210ddee57137f8b03d6bc,"To understand the usage of MP3 and effects on hearing of middle school students in Xi'an, and discuss controlling strategies. Stratified random cluster sampling method was used in the 1567 middle school students in Xi'an through questionnaire survey, ear examination and hearing examination, data were analysed by the SPSS13.0 statistical software. 1) The rate of holding MP3 in the middle school students was 85.2%. Average daily use time was (1.41 +/- 1.11) h. 2) The noise group of pure tone hearing threshold was significantly higher compared with the control group (P<0.01), and increased the detection rate of hearing loss with the increasing use of MP3. 3) The detection rate of symptoms increased with the increasing use of MP3. The usage of MP3 can harm hearing in middle school students, which can result in neurasthenic syndrome.",21563460,Article,Final,,Scopus,2-s2.0-80054819671
Luo H.; Yang T.; Jin X.; Pang X.; Li J.; Chai Y.; Li L.; Zhang Y.; Zhang L.; Zhang Z.; Wu W.; Zhang Q.; Hu X.; Sun J.; Jiang X.; Fan Z.; Huang Z.; Wu H.,"Luo, Huajie (37004518000); Yang, Tao (56431700100); Jin, Xiaojie (7402589120); Pang, Xiuhong (55879489200); Li, Jiping (9240181500); Chai, Yongchuan (37033504500); Li, Lei (56867926700); Zhang, Yi (57203829588); Zhang, Luping (56125446400); Zhang, Zhihua (56598160700); Wu, Wenjing (57213422207); Zhang, Qin (58606835600); Hu, Xianting (58353534600); Sun, Jingwen (55880162300); Jiang, Xuemei (55880158900); Fan, Zhuping (7402099487); Huang, Zhiwu (9336671200); Wu, Hao (55762405900)",37004518000; 56431700100; 7402589120; 55879489200; 9240181500; 37033504500; 56867926700; 57203829588; 56125446400; 56598160700; 57213422207; 58606835600; 58353534600; 55880162300; 55880158900; 7402099487; 9336671200; 55762405900,Association of GRM7 Variants with Different Phenotype Patterns of Age-Related Hearing Impairment in an Elderly Male Han Chinese Population,2013,PLoS ONE,8,10,e77153,,,,22,10.1371/journal.pone.0077153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885417489&doi=10.1371%2fjournal.pone.0077153&partnerID=40&md5=67ef3dd4d4aaf24b3625cdb4528aa374,"Several single nucleotide polymorphisms (SNPs) of the Glutamate metabotrophic receptor 7 gene (GRM7) have recently been identified by the genome-wide association study (GWAS) as potentially playing a role in susceptibility to age-related hearing impairment (ARHI), however this has not been validated in the Han Chinese population. The aim of this study was to determine if these SNPs are also associated with ARHI in an elderly male Han Chinese population. In this case-control candidate genes association study, a total of 982 men with ARHI and 324 normal-hearing controls subjects were studied. Using K-means cluster analysis, four audiogram shape subtypes of ARHI were identified in the case group: ''flat shape (FL)'', ''sloping shape (SL)'', ''2-4 kHz abrupt loss (AL) shape'' and ''8 kHz dip (8D) shape''. Results suggested that the SNP rs11928865 (A>T) of GRM7 was significantly associated with ARHI after adjusting for non-genetic factors (p= 0.000472, OR= 1.599, 95%CI= 1.229~2.081). Furthermore, frequency of TT genotype (rs11928865) were significant higher in the SL subgroup and AL subgroup with compared to controls group (p= 9.41E-05, OR= 1.945, 95%CI= 1.393~2.715; p= 0.000109, OR= 1.915, 95%CI= 1.378~2.661 adjusted, respectively) after Bonferroni correction. However, there wasn't significant difference in the frequency of the TT genotype between cases in the FL subgroup or the 8D subgroup with when compared with controls. Results of the current study suggest that, in an elderly male Han Chinese population, GRM7 SNP rs11928865 (TT) occurs more frequently in ARHI patients with SL and AL phenotype patterns. © 2013 Luo et al.",24146964,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84885417489
Alvarenga K.F.; Amorim R.B.; Agostinho-Pesse R.S.; Costa O.A.; Nascimento L.T.; Bevilacqua M.C.,"Alvarenga, Kátia F. (8222013800); Amorim, Raquel Beltrão (37010664000); Agostinho-Pesse, Raquel Sampaio (8435549500); Costa, Orozimbo Alves (7006489364); Nascimento, Leandra Tabanez (7005960013); Bevilacqua, Maria Cecilia (23766911200)",8222013800; 37010664000; 8435549500; 7006489364; 7005960013; 23766911200,Speech perception and cortical auditory evoked potentials in cochlear implant users with auditory neuropathy spectrum disorders,2012,International Journal of Pediatric Otorhinolaryngology,76,9,,1332,1338,6,35,10.1016/j.ijporl.2012.06.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865400523&doi=10.1016%2fj.ijporl.2012.06.001&partnerID=40&md5=a856469b49fde99641b27a49a4105922,"Objective: To characterize the P1 component of long latency auditory evoked potentials (LLAEPs) in cochlear implant users with auditory neuropathy spectrum disorder (ANSD) and determine firstly whether they correlate with speech perception performance and secondly whether they correlate with other variables related to cochlear implant use. Methods: This study was conducted at the Center for Audiological Research at the University of São Paulo. The sample included 14 pediatric (4-11 years of age) cochlear implant users with ANSD, of both sexes, with profound prelingual hearing loss. Patients with hypoplasia or agenesis of the auditory nerve were excluded from the study. LLAEPs produced in response to speech stimuli were recorded using a Smart EP USB Jr. system. The subjects' speech perception was evaluated using tests 5 and 6 of the Glendonald Auditory Screening Procedure (GASP). Results: The P1 component was detected in 12/14 (85.7%) children with ANSD. Latency of the P1 component correlated with duration of sensorial hearing deprivation (*p=0.007, r=0.7278), but not with duration of cochlear implant use. An analysis of groups assigned according to GASP performance (k-means clustering) revealed that aspects of prior central auditory system development reflected in the P1 component are related to behavioral auditory skills. Conclusions: In children with ANSD using cochlear implants, the P1 component can serve as a marker of central auditory cortical development and a predictor of the implanted child's speech perception performance. © 2012 Elsevier Ireland Ltd.",22796193,Article,Final,,Scopus,2-s2.0-84865400523
Francis S.P.; Krey J.F.; Krystofiak E.S.; Cui R.; Nanda S.; Xu W.; Kachar B.; Barr-Gillespie P.G.; Shin J.-B.,"Francis, Shimon P. (26030309500); Krey, Jocelyn F. (55555401100); Krystofiak, Evan S. (55357850000); Cui, Runjia (56800012100); Nanda, Sonali (58400878200); Xu, Wenhao (8644519500); Kachar, Bechara (24540064000); Barr-Gillespie, Peter G. (7005143141); Shin, Jung-Bum (7402724393)",26030309500; 55555401100; 55357850000; 56800012100; 58400878200; 8644519500; 24540064000; 7005143141; 7402724393,A short splice form of Xin-actin binding repeat containing 2 (XIRP2) lacking the xin repeats is required for maintenance of stereocilia morphology and hearing function,2015,Journal of Neuroscience,35,5,,1999,2014,15,36,10.1523/JNEUROSCI.3449-14.2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922355311&doi=10.1523%2fJNEUROSCI.3449-14.2015&partnerID=40&md5=a375a164c45f0aee6c9011e6d06117a8,"Approximately one-third of known deafness genes encode proteins located in the hair bundle, the sensory hair cell’s mechanoreceptive organelle. In previous studies, we used mass spectrometry to characterize the hair bundle’s proteome, resulting in the discovery of novel bundle proteins. One such protein is Xin-actin binding repeat containing 2 (XIRP2), an actin-cross-linking protein previously reported to be specifically expressed in striated muscle. Because mutations in other actin-cross-linkers result in hearing loss, we investigated the role of XIRP2 in hearing function. In the inner ear, XIRP2 is specifically expressed in hair cells, colocalizing with actin-rich structures in bundles, the underlying cuticular plate, and the circumferential actin belt. Analysis using peptide mass spectrometry revealed that the bundle harbors a previously uncharacterized XIRP2 splice variant, suggesting XIRP2’s role in the hair cell differs significantly from that reported in myocytes. To determine the role of XIRP2 in hearing, we applied clustered regularly interspaced short palindromic repeat (CRISPR)/Cas9-mediated genome-editing technology to induce targeted mutations into the mouse Xirp2 gene, resulting in the elimination of XIRP2 protein expression in the inner ear. Functional analysis of hearing in the resulting Xirp2-null mice revealed high-frequency hearing loss, and ultrastructural scanning electron microscopy analyses of hair cells demonstrated stereocilia degeneration in these mice. We thus conclude that XIRP2 is required for long-term maintenance of hair cell stereocilia, and that its dysfunction causes hearing loss in the mouse. © 2015 the authors.",25653358,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84922355311
Harding G.W.; Bohne B.A.,"Harding, Gary W. (7201960545); Bohne, Barbara A. (7005173566)",7201960545; 7005173566,Relation of focal hair-cell lesions to noise-exposure parameters from a 4- or a 0.5-kHz octave band of noise,2009,Hearing Research,254,01-Feb,,54,63,9,14,10.1016/j.heares.2009.04.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649464252&doi=10.1016%2fj.heares.2009.04.011&partnerID=40&md5=576c59d2153d5372e9978e0969a2bdbb,"In a previous study, we examined the relation between total energy in a noise exposure and the percentage losses of outer (OHC) and inner (IHC) hair cells in the basal and apical halves of 607 chinchilla cochleae [Harding, G.W., Bohne, B.A., 2004a. Noise-induced hair-cell loss and total exposure energy: analysis of a large data set. J. Acoust. Soc. Am. 115, 2207-2220]. The animals had been exposed continuously to either a 4-kHz octave band of noise (OBN) at 47-108 dB SPL for 0.5 h-36 d, or a 0.5-kHz OBN at 65-128 dB SPL for 3.5 h-433 d. Interrupted exposures were also employed with both OBNs. Post-exposure recovery times ranged from 0 to 913 days. Cluster analysis was used to separate the data into three magnitudes of damage. The data were also separated into recovery times of 0 days (acute) and >0 days (chronic) and the apical and basal halves of the organ of Corti (OC). A substantial part of these hair-cell losses occurred in focal lesions (i.e., ≥50% loss of IHCs, OHCs or both over a distance of ≥0.03 mm). This aspect of the damage from noise was not included in the previous analysis. The present analysis describes, within the same three clusters, the apex-to-base distribution of 1820 focal lesions found in 468 of 660 (71%) noise-exposed cochleae. In these cochleae, OC length in mm was converted to percent distance from the apex. The lesion data were analyzed for location in percent distance from the apex and size (mm) of the lesions. In 55 of 140 (39%) non-noise-exposed, control OCs, there were 186 focal hair-cell lesions, the characteristics of which were also determined. Focal lesions with hair-cell loss ≥50% involved predominantly OHCs, IHCs only, or both OHCs and IHCs (i.e., combined OHC-IHC lesions). The predominantly OHC and combined lesions were pooled together for the analysis. The distributions of lesion location (in percent distance from the apex), weighted by lesion size (in percent of OC length) were tallied in 2%-distance bins. In controls, focal lesions were uniformly distributed from apex to base and 70% of them were pure IHC lesions. In cochleae exposed to the 4-kHz OBN, lesions were distributed throughout the basal half of the OC. In cochleae exposed to the 0.5-kHz OBN, lesions occurred in both halves of the OC. With continuous exposures, 74% of the lesions were predominantly OHC or combined lesions. With interrupted exposures, 52% of the lesions were OHC or combined lesions. Lesion size was generally larger in the chronic compared to acute cochleae with similar exposures. There was a minimum total energy at which focal lesions began to appear and slightly higher energies resulted in nearly all exposed cochleae having focal lesions. © 2009 Elsevier B.V. All rights reserved.",19393307,Article,Final,,Scopus,2-s2.0-67649464252
Beitel R.E.; Vollmer M.; Raggio M.W.; Schreiner C.E.,"Beitel, Ralph E. (6701331833); Vollmer, Maike (56261340600); Raggio, Marcia W. (6603873505); Schreiner, Christoph E. (7006315409)",6701331833; 56261340600; 6603873505; 7006315409,Behavioral training enhances cortical temporal processing in neonatally deafened juvenile cats,2011,Journal of Neurophysiology,106,2,,944,959,15,19,10.1152/jn.00731.2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051486093&doi=10.1152%2fjn.00731.2010&partnerID=40&md5=cb811880baef4a64d544df704ce9cb94,"Deaf humans implanted with a cochlear prosthesis depend largely on temporal cues for speech recognition because spectral information processing is severely impaired. Training with a cochlear prosthesis is typically required before speech perception shows improvement, suggesting that relevant experience modifies temporal processing in the central auditory system. We tested this hypothesis in neonatally deafened cats by comparing temporal processing in the primary auditory cortex (AI) of cats that received only chronic passive intracochlear electric stimulation (ICES) with cats that were also trained with ICES to detect temporally challenging trains of electric pulses. After months of chronic passive stimulation and several weeks of detection training in behaviorally trained cats, multineuronal AI responses evoked by temporally modulated ICES were recorded in anesthetized animals. The stimulus repetition rates that produced the maximum number of phase-locked spikes (best repetition rate) and 50% cutoff rate were significantly higher in behaviorally trained cats than the corresponding rates in cats that received only chronic passive ICES. Behavioral training restored neuronal temporal following ability to levels comparable with those recorded in naïve prior normal-hearing adult deafened animals. Importantly, best repetitition rates and cutoff rates were highest for neuronal clusters activated by the electrode configuration used in behavioral training. These results suggest that neuroplasticity in the AI is induced by behavioral training and perceptual learning in animals deprived of ordinary auditory experience during development and indicate that behavioral training can ameliorate or restore temporal processing in the AI of profoundly deaf animals. © 2011 the American Physiological Society.",21543753,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-80051486093
Sheets L.; Trapani J.G.; Mo W.; Obholzer N.; Nicolson T.,"Sheets, Lavinia (35082688400); Trapani, Josef G. (8056139700); Mo, Weike (23670326700); Obholzer, Nikolaus (35797361500); Nicolson, Teresa (7003625622)",35082688400; 8056139700; 23670326700; 35797361500; 7003625622,Ribeye is required for presynaptic CaV1.3a channel localization and afferent innervation of sensory hair cells,2011,Development,138,7,,1309,1319,10,101,10.1242/dev.059451,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955158904&doi=10.1242%2fdev.059451&partnerID=40&md5=d9659a7822e6240d8dcbfd1b5e064c30,"Ribbon synapses of the ear, eye and pineal gland contain a unique protein component: Ribeye. Ribeye consists of a novel aggregation domain spliced to the transcription factor CtBP2 and is one of the most abundant proteins in synaptic ribbon bodies. Although the importance of Ribeye for the function and physical integrity of ribbon synapses has been shown, a specific role in synaptogenesis has not been described. Here, we have modulated Ribeye expression in zebrafish hair cells and have examined the role of Ribeye in synapse development. Knockdown of ribeye resulted in fewer stimulus-evoked action potentials from afferent neurons and loss of presynaptic CaV1.3a calcium channel clusters in hair cells. Additionally, afferent innervation of hair cells was reduced in ribeye morphants, and the reduction was correlated with depletion of Ribeye punctae. By contrast, transgenic overexpression of Ribeye resulted in CaV1.3a channels colocalized with ectopic aggregates of Ribeye protein. Overexpression of Ribeye, however, was not sufficient to create ectopic synapses. These findings reveal two distinct functions of Ribeye in ribbon synapse formation - clustering CaV1.3a channels at the presynapse and stabilizing contacts with afferent neurons - and suggest that Ribeye plays an organizing role in synaptogenesis. © 2011. Published by The Company of Biologists Ltd.",21350006,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-79955158904
Paulraj M.P.; Subramaniam K.; Yaccob S.B.; Hamid A.; Hema C.R.,"Paulraj, M.P. (16203599500); Subramaniam, Kamalraj (55599278500); Yaccob, Sazali Bin (6505641077); Hamid, Abdul (6506600412); Hema, C.R. (16202600500)",16203599500; 55599278500; 6505641077; 6506600412; 16202600500,EEG based detection of conductive and sensorineural hearing loss using artificial neural networks,2013,Journal of Next Generation Information Technology,4,3,,204,212,8,5,10.4156/jnit.vol4.issue3.24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880972968&doi=10.4156%2fjnit.vol4.issue3.24&partnerID=40&md5=740ec677225ac997ed1532e9a9280511,"In this paper, a simple method has been proposed to distinguish the normal and abnormal hearing subjects (conductive or sensorineural hearing loss) using acoustically stimulated EEG signals. Auditory Evoked Potential (AEP) signals are unilaterally recorded with monaural acoustical stimulus from the normal and abnormal hearing subjects with conductive or sensorineural hearing loss. Spectral power and spectral entropy features of gamma rhythms are extracted from the recorded AEP signals. The extracted features are applied to machine-learning algorithms to categorize the AEP signal dynamics into their hearing threshold states (normal hearing, abnormal hearing) of the subjects. Feed forward and feedback neural network models are employed with gamma band features and their performances are analyzed in terms of specificity, sensitivity and classification accuracy for the left and right ears across 9 subjects. The maximum classification accuracy of the developed neural network was observed as 96.75 per cent in discriminating the normal and hearing loss (conductive or sensorineural) subjects. From the neural network models, it has been inferred that network models were able to classify the normal hearing and abnormal hearing subjects with conductive or sensorineural hearing loss. Further, this study proposed a feature band-score index to explore the feasibility of using fewer electrode channels to detect the type of hearing loss for newborns, infants, and multiple handicaps, person who lacks verbal communication and behavioral response to the auditory stimulation.",,Article,Final,,Scopus,2-s2.0-84880972968
Van Houtte E.; Casselman J.; Janssens S.; De Kegel A.; Maes L.; Dhooge I.,"Van Houtte, Evelyne (35410838800); Casselman, Jan (16179254500); Janssens, Sandra (7005391887); De Kegel, Alexandra (37001497200); Maes, Leen (16310276100); Dhooge, Ingeborg (7003466602)",35410838800; 16179254500; 7005391887; 37001497200; 16310276100; 7003466602,Middle and inner ear malformations in two siblings exposed to valproic acid during pregnancy: A case report,2014,International Journal of Pediatric Otorhinolaryngology,78,11,,2007,2010,3,5,10.1016/j.ijporl.2014.08.030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907958769&doi=10.1016%2fj.ijporl.2014.08.030&partnerID=40&md5=491876caeadaf2ba6761dcec5d10840f,"Valproic acid (VPA) is a known teratogenic drug. Exposure to VPA during the pregnancy can lead to a distinct facial appearance, a cluster of major and minor anomalies and developmental delay. In this case report, two siblings with fetal valproate syndrome and a mild conductive hearing loss were investigated. Radiologic evaluation showed middle and inner ear malformations in both children. Audiologic, vestibular and motor examination was performed. This is the first case report to describe middle and inner ear malformations in children exposed to VPA. © 2014 Elsevier Ireland Ltd.",25216807,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84907958769
Fallon J.B.; Shepherd R.K.; Irvine D.R.F.,"Fallon, James B. (9435651900); Shepherd, Robert K. (7202338759); Irvine, Dexter R. F. (7101951078)",9435651900; 7202338759; 7101951078,Effects of chronic cochlear electrical stimulation after an extended period of profound deafness on primary auditory cortex organization in cats,2014,European Journal of Neuroscience,39,5,,811,820,9,23,10.1111/ejn.12445,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896738002&doi=10.1111%2fejn.12445&partnerID=40&md5=026357e43db64f14efcf3e91d96e61c6,"Extended periods of deafness have profound effects on central auditory system function and organization. Neonatal deafening results in loss of the normal cochleotopic organization of the primary auditory cortex (AI), but environmentally-derived intracochlear electrical stimulation, via a cochlear implant, initiated shortly after deafening, can prevent this loss. We investigated whether such stimulation initiated after an extended period of deafness can restore cochleotopy. In two groups of neonatally-deafened cats, a multi-channel intracochlear electrode array was implanted at 8 weeks of age. One group received only minimal stimulation, associated with brief recordings at 4-6-week intervals, over the following 6 months to check the efficacy of the implant. In the other group, this 6-month period was followed by 6 months of near-continuous intracochlear electrical stimulation from a modified clinical cochlear implant system. We recorded multi-unit clusters in the auditory cortex and used two different methods to define the region of interest in the putative AI. There was no evidence of cochleotopy in any of the minimally stimulated animals, confirming our earlier finding. In three of six chronically stimulated cats there was clear evidence of AI cochleotopy, and in a fourth cat in which the majority of penetrations were in the anterior auditory field there was clear evidence of cochleotopy in that field. The finding that chronic intracochlear electrical stimulation after an extended period of deafness is able to restore cochleotopy in some (but not all) cases has implications for the performance of patients implanted after an extended period of deafness. © 2013 Federation of European Neuroscience Societies and John Wiley & Sons Ltd.",24325274,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84896738002
Brisset S.; Slamova Z.; Dusatkova P.; Briand-Suleau A.; Milcent K.; Metay C.; Simandlova M.; Sumnik Z.; Tosca L.; Goossens M.; Labrune P.; Zemankova E.; Lebl J.; Tachdjian G.; Sedlacek Z.,"Brisset, Sophie (6601996254); Slamova, Zuzana (14009929200); Dusatkova, Petra (24280339600); Briand-Suleau, Audrey (54394921800); Milcent, Karen (24401545400); Metay, Corinne (37102415500); Simandlova, Martina (6508281439); Sumnik, Zdenek (6603897982); Tosca, Lucie (8880393800); Goossens, Michel (7101703913); Labrune, Philippe (23990861400); Zemankova, Elsa (56048464100); Lebl, Jan (36850852500); Tachdjian, Gerard (55648851400); Sedlacek, Zdenek (7004177164)",6601996254; 14009929200; 24280339600; 54394921800; 24401545400; 37102415500; 6508281439; 6603897982; 8880393800; 7101703913; 23990861400; 56048464100; 36850852500; 55648851400; 7004177164,"Anophthalmia, hearing loss, abnormal pituitary development and response to growth hormone therapy in three children with microdeletions of 14q22q23",2014,Molecular Cytogenetics,7,1,17,,,,11,10.1186/1755-8166-7-17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898540824&doi=10.1186%2f1755-8166-7-17&partnerID=40&md5=a705677fbbd9c2b46122ef78c96a06c4,"Background: Microdeletions of 14q22q23 have been associated with eye abnormalities and pituitary defects. Other phenotypic features in deletion carriers including hearing loss and response to growth hormone therapy are less well recognized. We studied genotype and phenotype of three newly identified children with 14q22q23 deletions, two girls and one boy with bilateral anophthalmia, and compared them with previously published deletion patients and individuals with intragenic defects in genes residing in the region. Results: The three deletions were de novo and ranged in size between 5.8 and 8.9 Mb. All three children lacked one copy of the OTX2 gene and in one of them the deletion involved also the BMP4 gene. All three patients presented partial conductive hearing loss which tended to improve with age. Analysis of endocrine and growth phenotypes showed undetectable anterior pituitary, growth hormone deficiency and progressive growth retardation in all three patients. Growth hormone therapy led to partial catch-up growth in two of the three patients but just prevented further height loss in the third. Conclusions: The pituitary hypoplasia, growth hormone deficiency and growth retardation associated with 14q22q23 microdeletions are very remarkable, and the latter appears to have an atypical response to growth hormone therapy in some of the cases. © 2014 Brisset et al.; licensee BioMed Central Ltd.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84898540824
Laplante-Lévesque A.; Hickson L.; Worrall L.,"Laplante-Lévesque, Ariane (6506488140); Hickson, Louise (7004043266); Worrall, Linda (7003861894)",6506488140; 7004043266; 7003861894,Stages of change in adults with acquired hearing impairment seeking help for the first time: Application of the transtheoretical model in audiologic rehabilitation,2013,Ear and Hearing,34,4,,447,457,10,67,10.1097/AUD.0b013e3182772c49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881542273&doi=10.1097%2fAUD.0b013e3182772c49&partnerID=40&md5=39aaeff4ea8b92b410192239fbdcfbf3,"Objectives: This study investigated the application of the transtheoreti-cal (stages-of-change) model in audiologic rehabilitation. More specifi-cally, it described the University of Rhode Island Change Assessment (URICA) scores of adults with acquired hearing impairment. It reported the psychometric properties (construct, concurrent, and predictive validity) of the stages-of-change model in this population. Design: At baseline, 153 adults with acquired hearing impairment seeking help for the first time completed the URICA as well as measures of degree of hearing impairment, self-reported hearing disability, and years since hearing impairment onset. Participants were subsequently offered intervention options: hearing aids, communication programs, and no intervention. Their intervention uptake and adherence were assessed 6 months later and their intervention outcomes were assessed 3 months after intervention completion. First, the stages-of-change construct validity was evaluated by investigating the URICA factor structure (principal component analysis), internal consistency, and correlations between stage scores. The URICA scores were reported in terms of the scores for each stage of change, composite scores, stages with highest scores, and stage clusters (cluster analysis). Second, the concurrent validity was assessed by examining associations between stages of change and degree of hearing impairment, self-reported hearing disability, and years since hearing impairment onset. Third, the predictive validity was evaluated by investigating associations between stages of change and intervention uptake, adherence, and outcomes. Results: First, in terms of construct validity, the principal component analysis identified four instead of three stages (precontemplation, contemplation, preparation, and action) for which the internal consistency was good. Most of the sample was in the action stage. Correlations between stage scores supported the model. Cluster analysis identified four stages-of-change clusters, which the authors named active change, initiation, disengagement, and ambivalence. In terms of concurrent validity, participants who reported a more advanced stage of change had a more severe hearing impairment, reported greater hearing disability, and had a hearing impairment for a longer period of time. In terms of predictive validity, participants who reported a more advanced stage of change were more likely to take up an intervention and to report successful intervention outcomes. However, stages of change did not predict intervention adherence. Conclusions: The majority of the sample was in the action stage. The construct, concurrent, and predictive validity of the stages-of-change model were good. The stages-of-change model has some validity in the rehabilitation of adults with hearing impairment. The data support that change might be better represented on a continuum rather than by movement from one step to the next. Of all the measures, the precon-templation stage score had the best concurrent and predictive validity. Therefore, further research should focus on addressing the precontem-plation stage with a measure suitable for clinical use. Copyright © 2012 by Lippincott Williams & Wilkins.",23364333,Article,Final,,Scopus,2-s2.0-84881542273
Milo M.; Cacciabue-Rivolta D.; Kneebone A.; Van Doorninck H.; Johnson C.; Lawoko-Kerali G.; Niranjan M.; Rivolta M.; Holley M.,"Milo, Marta (6506962964); Cacciabue-Rivolta, Daniela (6505475623); Kneebone, Adam (16233864600); Van Doorninck, Hikke (6602938340); Johnson, Claire (18434379100); Lawoko-Kerali, Grace (6507778129); Niranjan, Mahesan (57205698392); Rivolta, Marcelo (7004561959); Holley, Matthew (7005551370)",6506962964; 6505475623; 16233864600; 6602938340; 18434379100; 6507778129; 57205698392; 7004561959; 7005551370,Genomic analysis of the function of the transcription factor gata3 during development of the mammalian inner ear,2009,PLoS ONE,4,9,e7144,,,,19,10.1371/journal.pone.0007144,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349613023&doi=10.1371%2fjournal.pone.0007144&partnerID=40&md5=49b69229b93f43375700b71409f855f1,"We have studied the function of the zinc finger transcription factor gata3 in auditory system development by analysing temporal profiles of gene expression during differentiation of conditionally immortal cell lines derived to model specific auditory cell types and developmental stages. We tested and applied a novel probabilistic method called the gamma Model for Oligonucleotide Signals to analyse hybridization signals from Affymetrix oligonucleotide arrays. Expression levels estimated by this method correlated closely (p,0.0001) across a 10-fold range with those measured by quantitative RT-PCR for a sample of 61 different genes. In an unbiased list of 26 genes whose temporal profiles clustered most closely with that of gata3 in all cell lines, 10 were linked to Insulin-like Growth Factor signalling, including the serine/threonine kinase Akt/PKB. Knock-down of gata3 in vitro was associated with a decrease in expression of genes linked to IGF-signalling, including IGF1, IGF2 and several IGF-binding proteins. It also led to a small decrease in protein levels of the serine-threonine kinase Akt2/ PKBβ, a dramatic increase in Akt1/PKBα protein and relocation of Akt1/PKBα from the nucleus to the cytoplasm. The cyclin-dependent kinase inhibitor p27kip1, a known target of PKB/Akt, simultaneously decreased. In heterozygous gata3 null mice the expression of gata3 correlated with high levels of activated Akt/PKB. This functional relationship could explain the diverse function of gata3 during development, the hearing loss associated with gata3 heterozygous null mice and the broader symptoms of human patients with Hearing-Deafness-Renal anomaly syndrome. © 2009 Milo et al.",19774072,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-70349613023
Nakano Y.; Jahan I.; Bonde G.; Sun X.; Hildebrand M.S.; Engelhardt J.F.; Smith R.J.H.; Cornell R.A.; Fritzsch B.; Bánfi B.,"Nakano, Yoko (55137556000); Jahan, Israt (57529666100); Bonde, Gregory (8733263000); Sun, Xingshen (8519507800); Hildebrand, Michael S. (34570227500); Engelhardt, John F. (7102715519); Smith, Richard J. H. (16073972500); Cornell, Robert A. (7103379927); Fritzsch, Bernd (7006714975); Bánfi, Botond (6604074726)",55137556000; 57529666100; 8733263000; 8519507800; 34570227500; 7102715519; 16073972500; 7103379927; 7006714975; 6604074726,A Mutation in the Srrm4 Gene Causes Alternative Splicing Defects and Deafness in the Bronx Waltzer Mouse,2012,PLoS Genetics,8,10,e1002966,,,,66,10.1371/journal.pgen.1002966,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868110688&doi=10.1371%2fjournal.pgen.1002966&partnerID=40&md5=f28dc275c12c46ff41a6f367092ae72f,"Sensory hair cells are essential for hearing and balance. Their development from epithelial precursors has been extensively characterized with respect to transcriptional regulation, but not in terms of posttranscriptional influences. Here we report on the identification and functional characterization of an alternative-splicing regulator whose inactivation is responsible for defective hair-cell development, deafness, and impaired balance in the spontaneous mutant Bronx waltzer (bv) mouse. We used positional cloning and transgenic rescue to locate the bv mutation to the splicing factor-encoding gene Ser/Arg repetitive matrix 4 (Srrm4). Transcriptome-wide analysis of pre-mRNA splicing in the sensory patches of embryonic inner ears revealed that specific alternative exons were skipped at abnormally high rates in the bv mice. Minigene experiments in a heterologous expression system confirmed that these skipped exons require Srrm4 for inclusion into the mature mRNA. Sequence analysis and mutagenesis experiments showed that the affected transcripts share a novel motif that is necessary for the Srrm4-dependent alternative splicing. Functional annotations and protein-protein interaction data indicated that the encoded proteins cluster in the secretion and neurotransmission pathways. In addition, the splicing of a few transcriptional regulators was found to be Srrm4 dependent, and several of the genes known to be targeted by these regulators were expressed at reduced levels in the bv mice. Although Srrm4 expression was detected in neural tissues as well as hair cells, analyses of the bv mouse cerebellum and neocortex failed to detect splicing defects. Our data suggest that Srrm4 function is critical in the hearing and balance organs, but not in all neural tissues. Srrm4 is the first alternative-splicing regulator to be associated with hearing, and the analysis of bv mice provides exon-level insights into hair-cell development. © 2012 Nakano et al.",23055939,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84868110688
Egbert M.,"Egbert, Maria (6602002786)",6602002786,"Technology and social interaction in the multimodal, multispace setting of audiometric testing",2012,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),7258 LNAI,,,240,252,12,1,10.1007/978-3-642-32090-3_22,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865960926&doi=10.1007%2f978-3-642-32090-3_22&partnerID=40&md5=fa0649e7533e4fa45b339fb6c15f3ca5,"A frequent motivation for integrating the technological and the social sciences lies in understanding the users of technologies in order to innovate [1-3]. This paper argues that a shift is necessary from 'the user' to 'the interaction in the participation framework' because it is here where the interactants display to each other their relevancies. Using Conversation Analysis [5-8], this point is exemplified by the examination of interaction in an audiological consultation where the interface of sociality and technology is relevant as a barrier. The analysis focuses on what aspects the participants in their talk and nonverbal conduct orient to as problematic given the task and the technology in this multimodal, multispace environment. The analytical results are discussed for innovation within the framework of User-Centered Design. © 2012 Springer-Verlag.",,Conference paper,Final,,Scopus,2-s2.0-84865960926
Taylor K.R.; Deluca A.P.; Shearer A.E.; Hildebrand M.S.; Black-Ziegelbein E.A.; Anand V.N.; Sloan C.M.; Eppsteiner R.W.; Scheetz T.E.; Huygen P.L.M.; Smith R.J.H.; Braun T.A.; Casavant T.L.,"Taylor, Kyle R. (37062196200); Deluca, Adam P. (25921876700); Shearer, A. Eliot (7005515619); Hildebrand, Michael S. (34570227500); Black-Ziegelbein, E. Ann (55351186300); Anand, V. Nikhil (57197116442); Sloan, Christina M. (54786942200); Eppsteiner, Robert W. (24536850500); Scheetz, Todd E. (6603782802); Huygen, Patrick L.M. (7006415660); Smith, Richard J.H. (16073972500); Braun, Terry A. (7202108129); Casavant, Thomas L. (7005751228)",37062196200; 25921876700; 7005515619; 34570227500; 55351186300; 57197116442; 54786942200; 24536850500; 6603782802; 7006415660; 16073972500; 7202108129; 7005751228,AudioGene: Predicting Hearing Loss Genotypes from Phenotypes to Guide Genetic Screening,2013,Human Mutation,34,4,,539,545,6,30,10.1002/humu.22268,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875493103&doi=10.1002%2fhumu.22268&partnerID=40&md5=7e89e01575a751687c6f58292a305b4d,"Autosomal dominant nonsyndromic hearing loss (ADNSHL) is a common and often progressive sensory deficit. ADNSHL displays a high degree of genetic heterogeneity and varying rates of progression. Accurate, comprehensive, and cost-effective genetic testing facilitates genetic counseling and provides valuable prognostic information to affected individuals. In this article, we describe the algorithm underlying AudioGene, a software system employing machine-learning techniques that utilizes phenotypic information derived from audiograms to predict the genetic cause of hearing loss in persons segregating ADNSHL. Our data show that AudioGene has an accuracy of 68% in predicting the causative gene within its top three predictions, as compared with 44% for a majority classifier. We also show that AudioGene remains effective for audiograms with high levels of clinical measurement noise. We identify audiometric outliers for each genetic locus and hypothesize that outliers may reflect modifying genetic effects. As personalized genomic medicine becomes more common, AudioGene will be increasingly useful as a phenotypic filter to assess pathogenicity of variants identified by massively parallel sequencing. This article describes an accurate method for the diagnosis of mutations in genes, with pseudogene copies, at the single cell level for preimplantation genetic diagnostic purposes. The method is sensitive enough to detect germline mosaicism in single gametes. © 2012 Wiley Periodicals, Inc.",23280582,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84875493103
Xue T.; Wei L.I.; Zha D.-J.; Qiao L.I.; Lu L.-J.; Chen F-Q.; Qiu J.-H.,"Xue, Tao (56587513100); Wei, L.I. (57225867414); Zha, Ding-Jun (15057241900); Qiao, L.I. (57203581587); Lu, Lian-Jun (7403963586); Chen, Fu-Quan (55574106500); Qiu, Jian-Hua (7403310284)",56587513100; 57225867414; 15057241900; 57203581587; 7403963586; 55574106500; 7403310284,Exposure to acoustic stimuli promotes the development and differentiation of neural stem cells from the cochlear nuclei through the clusterin pathway,2015,International Journal of Molecular Medicine,35,3,,637,644,7,5,10.3892/ijmm.2015.2075,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921826420&doi=10.3892%2fijmm.2015.2075&partnerID=40&md5=4df9af9040d4aba8073f4cd92159e78f,"Stem cell therapy has attracted widespread attention for a number of diseases. Recently, neural stem cells (NSCs) from the cochlear nuclei have been identified, indicating a potential direction for the treatment of sensorineural hearing loss. Acoustic stimuli play an important role in the development of the auditory system. In this study, we aimed to determine whether acoustic stimuli induce NSC development and differentiation through the upregulation of clusterin (CLU) in NSCs isolated from the cochlear nuclei. To further clarify the underlying mechanisms involved in the development and differentiation of NSCs exposed to acoustic stimuli, we successfully constructed animal models in which was CLU silenced by an intraperitoneal injection of shRNA targeting CLI. As expected, the NSCs from rats treated with LV-CLU shRNA exhibited a lower proliferation ratio when exposed to an augmente d acoustic environment (AAE). Furthermore, the inhibition of cell apoptosis induced by exposure to AAE was abrogated after silencing the expression of the CLU gene. During the differentiation of acoustic stimuli-exposed stem cells into neurons, the number of astrocytes was significantly reduced, as evidenced by the expression of the cell markers, microtubule associated protein-2 (MAP-2) and glial fibrillary acidic protein (GFAP), which was markedly inhibited when the CLU gene was silenced. Our results indicate that acoustic stimuli may induce the development and differentiation of NSCs from the cochlear nucleus mainly through the CLU pathway. Our study suggests that CLU may be a novel target for the treatment of sensorineural hearing loss.",25605314,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84921826420
Hertzano R.; Elkon R.; Kurima K.; Morrisson A.; Chan S.-L.; Sallin M.; Biedlingmaier A.; Darling D.S.; Griffith A.J.; Eisenman D.J.; Strome S.E.,"Hertzano, Ronna (6507790490); Elkon, Ran (6507427079); Kurima, Kiyoto (6602900261); Morrisson, Annie (53866976400); Chan, Siaw-Lin (25627548200); Sallin, Michelle (57201779381); Biedlingmaier, Andrew (52263109200); Darling, Douglas S. (7004779951); Griffith, Andrew J. (7006238207); Eisenman, David J. (6701403121); Strome, Scott E. (7004882323)",6507790490; 6507427079; 6602900261; 53866976400; 25627548200; 57201779381; 52263109200; 7004779951; 7006238207; 6701403121; 7004882323,Cell type-specific transcriptome analysis reveals a major role for Zeb1 and miR-200b in mouse inner ear morphogenesis,2011,PLoS Genetics,7,9,e1002309,,,,69,10.1371/journal.pgen.1002309,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053437834&doi=10.1371%2fjournal.pgen.1002309&partnerID=40&md5=4a2f0d4ab2ae9790a8c5c5d00c6b697b,"Cellular heterogeneity hinders the extraction of functionally significant results and inference of regulatory networks from wide-scale expression profiles of complex mammalian organs. The mammalian inner ear consists of the auditory and vestibular systems that are each composed of hair cells, supporting cells, neurons, mesenchymal cells, other epithelial cells, and blood vessels. We developed a novel protocol to sort auditory and vestibular tissues of newborn mouse inner ears into their major cellular components. Transcriptome profiling of the sorted cells identified cell type-specific expression clusters. Computational analysis detected transcription factors and microRNAs that play key roles in determining cell identity in the inner ear. Specifically, our analysis revealed the role of the Zeb1/miR-200b pathway in establishing epithelial and mesenchymal identity in the inner ear. Furthermore, we detected a misregulation of the ZEB1 pathway in the inner ear of Twirler mice, which manifest, among other phenotypes, malformations of the auditory and vestibular labyrinth. The association of misregulation of the ZEB1/miR-200b pathway with auditory and vestibular defects in the Twirler mutant mice uncovers a novel mechanism underlying deafness and balance disorders. Our approach can be employed to decipher additional complex regulatory networks underlying other hearing and balance mouse mutants. © 2011 Hertzano et al.",21980309,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-80053437834
Cone B.K.; Wake M.; Tobin S.; Poulakis Z.; Rickards F.W.,"Cone, Barbara K. (7003878063); Wake, Melissa (7101653914); Tobin, Sherryn (16033458300); Poulakis, Zeffie (6602408422); Rickards, Field W. (7003382928)",7003878063; 7101653914; 16033458300; 6602408422; 7003382928,"Slight-mild sensorineural hearing loss in children: Audiometric, clinical, and risk factor profiles",2010,Ear and Hearing,31,2,,202,212,10,67,10.1097/AUD.0b013e3181c62263,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949373140&doi=10.1097%2fAUD.0b013e3181c62263&partnerID=40&md5=60e7eb308a30145b106a70f976ffac14,"Objectives: Slight or mild hearing loss has been posited as a factor affecting speech, language, learning, and academic outcomes, but the risk factors for slight-mild sensorineural hearing loss (SNHL) have not been ascertained. The two specific aims for this research were (1) to describe the audiometric and clinical characteristics of children identified with slight-mild bilateral SNHL and (2) to compare children with slight-mild SNHL with those with normal hearing (NH) with respect to potential risk factors for congenital or acquired for hearing loss. Design: A cross-sectional cluster sample survey of 6581 children enrolled in years 1 and 5 of Australian elementary school was completed. Children were screened for slight-mild SNHL, defined as a low- and/or high-frequency pure-tone average of 16 to 40 dB HL in the better ear, with air-bone gaps <10 dB. Children who did not pass the screen received air and bone conduction threshold and tympanometry tests to determine the type and degree of hearing loss. The parents of every child who participated in this study completed a questionnaire, before the hearing screening, to ascertain possible risk indicators. The questionnaire included items regarding the family's demographics, hearing status of family members, the presence of risk factors, and parental concern regarding the child's hearing. Results: Fifty-five children with slight-mild SNHL and 5490 with NH were identified. Of the group with SNHL, 39 children had a slight loss (16 to 25 dB HL) and 16 had a mild loss (26 to 40 dB HL). The majority of the losses were bilateral and symmetrical, and the mean pure-tone average for the better ear for all 55 children was 22.4 dB HL (SD, 5.2). The most prevalent risk factor was ""neonatal intensive care unit/special care nursery admission,"" which was reported for 12.5% of the SNHL and 8.4% of the NH group. Reported use of personal stereos was a significant risk factor with an odds ratio of 1.7 (95% confidence interval = 1.0 to 3.0, p = 0.05). The questions relating to parental concern for their child's hearing had low sensitivity (<30%) and very low positive predictive values (<3%) for detecting slight-mild Snhl. Conclusions: Slight-mild SNHL had a prevalence of 0.88% among the school-aged population sampled, with the majority of these children exhibiting bilateral, symmetrical audiometric configurations. Conventional risk factors for hearing loss were not strongly predictive of slight-mild SNHL nor were parental concerns about the child's hearing ability. The association between slight-mild SNHL and the parent report of personal stereo use suggests that this type of noise exposure may be a risk factor for acquired hearing loss. This seems to be the first documentation of such an association in a large sample of young children. Copyright © 2010 by Lippincott Williams & Wilkins.",20054279,Article,Final,,Scopus,2-s2.0-77949373140
Klenke C.; Janowski S.; Borck D.; Widera D.; Ebmeyer J.; Kalinowski J.; Leichtle A.; Hofestädt R.; Upile T.; Kaltschmidt C.; Kaltschmidt B.; Sudhoff H.,"Klenke, Christin (55535100900); Janowski, Sebastian (36020307800); Borck, Daniela (36087054500); Widera, Darius (8875165400); Ebmeyer, Jörg (6506213768); Kalinowski, Jörn (7101959761); Leichtle, Anke (6506992864); Hofestädt, Ralf (6701732268); Upile, Tahwinder (14829598000); Kaltschmidt, Christian (7003915652); Kaltschmidt, Barbara (6701680723); Sudhoff, Holger (7006806083)",55535100900; 36020307800; 36087054500; 8875165400; 6506213768; 7101959761; 6506992864; 6701732268; 14829598000; 7003915652; 6701680723; 7006806083,Identification of Novel Cholesteatoma-Related Gene Expression Signatures Using Full-Genome Microarrays,2012,PLoS ONE,7,12,e52718,,,,37,10.1371/journal.pone.0052718,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871445299&doi=10.1371%2fjournal.pone.0052718&partnerID=40&md5=08fab62cf7d32ac6a8b65401377cdb75,"Background: Cholesteatoma is a gradually expanding destructive epithelial lesion within the middle ear. It can cause extensive local tissue destruction in the temporal bone and can initially lead to the development of conductive hearing loss via ossicular erosion. As the disease progresses, sensorineural hearing loss, vertigo or facial palsy may occur. Cholesteatoma may promote the spread of infection through the tegmen of the middle ear and cause meningitis or intracranial infections with abscess formation. It must, therefore, be considered as a potentially life-threatening middle ear disease. Methods and Findings: In this study, we investigated differentially expressed genes in human cholesteatomas in comparison to regular auditory canal skin using Whole Human Genome Microarrays containing 19,596 human genes. In addition to already described up-regulated mRNAs in cholesteatoma, such as MMP9, DEFB2 and KRT19, we identified 3558 new cholesteatoma-related transcripts. 811 genes appear to be significantly differentially up-regulated in cholesteatoma. 334 genes were down-regulated more than 2-fold. Significantly regulated genes with protein metabolism activity include matrix metalloproteinases as well as PI3, SERPINB3 and SERPINB4. Genes like SPP1, KRT6B, PRPH, SPRR1B and LAMC2 are known as genes with cell growth and/or maintenance activity. Transport activity genes and signal transduction genes are LCN2, GJB2 and CEACAM6. Three cell communication genes were identified; one CDH19 and two from the S100 family. Conclusions: This study demonstrates that the expression profile of cholesteatoma is similar to a metastatic tumour and chronically inflamed tissue. Based on the investigated profiles we present novel protein-protein interaction and signal transduction networks, which include cholesteatoma-regulated transcripts and may be of great value for drug targeting and therapy development. © 2012 Klenke et al.",23285167,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84871445299
Healy E.W.; Yoho S.E.; Chen J.; Wang Y.; Wang D.,"Healy, Eric W. (7005887267); Yoho, Sarah E. (55550257500); Chen, Jitong (55448469000); Wang, Yuxuan (57189030317); Wang, Deliang (7407070944)",7005887267; 55550257500; 55448469000; 57189030317; 7407070944,An algorithm to increase speech intelligibility for hearing-impaired listeners in novel segments of the same noise type,2015,Journal of the Acoustical Society of America,138,3,,1660,1669,9,69,10.1121/1.4929493,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943144867&doi=10.1121%2f1.4929493&partnerID=40&md5=a0c55c53a8f084535a398962fcca1c2a,"Machine learning algorithms to segregate speech from background noise hold considerable promise for alleviating limitations associated with hearing impairment. One of the most important considerations for implementing these algorithms into devices such as hearing aids and cochlear implants involves their ability to generalize to conditions not employed during the training stage. A major challenge involves the generalization to novel noise segments. In the current study, sentences were segregated from multi-talker babble and from cafeteria noise using an algorithm that employs deep neural networks to estimate the ideal ratio mask. Importantly, the algorithm was trained on segments of noise and tested using entirely novel segments of the same nonstationary noise type. Substantial sentence-intelligibility benefit was observed for hearing-impaired listeners in both noise types, despite the use of unseen noise segments during the test stage. Interestingly, normal-hearing listeners displayed benefit in babble but not in cafeteria noise. This result highlights the importance of evaluating these algorithms not only in human subjects, but in members of the actual target population. © 2015 Acoustical Society of America.",26428803,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84943144867
Gingras B.; Honing H.; Peretz I.; Trainor L.J.; Fisher S.E.,"Gingras, Bruno (43861203600); Honing, Henkjan (6603233047); Peretz, Isabelle (7006137534); Trainor, Laurel J. (7004512217); Fisher, Simon E. (7401755825)",43861203600; 6603233047; 7006137534; 7004512217; 7401755825,Defining the biological bases of individual differences in musicality,2015,Philosophical Transactions of the Royal Society B: Biological Sciences,370,1664,20140092,,,15,61,10.1098/rstb.2014.0092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922179963&doi=10.1098%2frstb.2014.0092&partnerID=40&md5=1c614cab9b08c0ef17e29f2616e738c2,"Advances in molecular technologies make it possible to pinpoint genomic factors associated with complex human traits. For cognition and behaviour, identification of underlying genes provides new entry points for deciphering the key neurobiological pathways. In the past decade, the search for genetic correlates of musicality has gained traction. Reports have documented familial clustering for different extremes of ability, including amusia and absolute pitch (AP), with twin studies demonstrating high heritability for some music-related skills, such as pitch perception. Certain chromosomal regions have been linked to APand musical aptitude, while individual candidate genes have been investigated in relation to aptitude and creativity. Most recently, researchers in this field started performing genome-wide association scans. Thus far, studies have been hampered by relatively small sample sizes and limitations in defining components of musicality, including an emphasis on skills that can only be assessed in trained musicians. With opportunities to administer standardized aptitude tests online, systematic large-scale assessment of musical abilities is now feasible, an important step towards high-powered genome-wide screens. Here, we offer a synthesis of existing literatures and outline concrete suggestions for the development of comprehensive operational tools for the analysis of musical phenotypes. © 2015 The Author(s) Published by the Royal Society. All rights reserved.",25646515,Review,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84922179963
Wang P.; Carrion P.; Qiao Y.; Tyson C.; Hrynchak M.; Calli K.; Lopez-Rangel E.; Andrieux J.; Delobel B.; Duban-Bedu B.; Thuresson A.-C.; Annerén G.; Liu X.; Rajcan-Separovic E.; Suzanne Lewis M.E.,"Wang, Peter (57198929628); Carrion, Prescilla (55760664000); Qiao, Ying (24467009700); Tyson, Christine (9736469300); Hrynchak, Monica (6508309860); Calli, Kristina (55175654500); Lopez-Rangel, Elena (16162319600); Andrieux, Joris (56524198100); Delobel, Bruno (7004469764); Duban-Bedu, Bénédicte (23477248800); Thuresson, Ann-Charlotte (6507566511); Annerén, Göran (7005617614); Liu, Xudong (26660561700); Rajcan-Separovic, Evica (6701711485); Suzanne Lewis, M.E. (6508297213)",57198929628; 55760664000; 24467009700; 9736469300; 6508309860; 55175654500; 16162319600; 56524198100; 7004469764; 23477248800; 6507566511; 7005617614; 26660561700; 6701711485; 6508297213,Genotype-phenotype analysis of 18q12.1-q12.2 copy number variation in autism,2013,European Journal of Medical Genetics,56,8,,420,425,5,9,10.1016/j.ejmg.2013.05.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881546916&doi=10.1016%2fj.ejmg.2013.05.006&partnerID=40&md5=d6f86e03cbeff267f582f154f9336cdd,"Autism Spectrum Disorders (ASD) are complex neurodevelopmental conditions characterized by delays in social interactions and communication as well as displays of restrictive/repetitive interests. DNA copy number variants have been identified as a genomic susceptibility factor in ASDs and imply significant genetic heterogeneity. We report a 7-year-old female with ADOS-G and ADI-R confirmed autistic disorder harbouring a de novo 4Mb duplication (18q12.1). Our subject displays severely deficient expressive language, stereotypic and repetitive behaviours, mild intellectual disability (ID), focal epilepsy, short stature and absence of significant dysmorphic features. Search of the PubMed literature and DECIPHER database identified 4 additional cases involving 18q12.1 associated with autism and/or ID that overlap our case: one duplication, two deletions and one balanced translocation. Notably, autism and ID are seen with genomic gain or loss at 18q12.1, plus epilepsy and short stature in duplication cases, and hypotonia and tall stature in deletion cases. No consistent dysmorphic features were noted amongst the reviewed cases. We review prospective ASD/ID candidate genes integral to 18q12.1, including those coding for the desmocollin/desmoglein cluster, ring finger proteins 125 and 138, trafficking protein particle complex 8 and dystrobrevin-alpha. The collective clinical and molecular features common to microduplication 18q12.1 suggest that dosage-sensitive, position or contiguous gene effects may be associated in the etiopathogenesis of this autism-ID-epilepsy syndrome. © 2013 Elsevier Masson SAS.",23727450,Article,Final,,Scopus,2-s2.0-84881546916
Modongo C.; Pasipanodya J.G.; Zetola N.M.; Williams S.M.; Sirugo G.; Gumboc T.,"Modongo, Chawangwa (40561516600); Pasipanodya, Jotam G. (16646340800); Zetola, Nicola M. (15062018200); Williams, Scott M. (7404835124); Sirugo, Giorgio (7003946450); Gumboc, Tawanda (57207612545)",40561516600; 16646340800; 15062018200; 7404835124; 7003946450; 57207612545,Amikacin concentrations predictive of ototoxicity in multidrug-resistant tuberculosis patients,2015,Antimicrobial Agents and Chemotherapy,59,10,,6337,6343,6,62,10.1128/AAC.01050-15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942935430&doi=10.1128%2fAAC.01050-15&partnerID=40&md5=223a19775501ac32853ea9a33aacecf3,"Aminoglycosides, such as amikacin, are used to treat multidrug-resistant tuberculosis. However, ototoxicity is a common problem and is monitored using peak and trough amikacin concentrations based on World Health Organization recommendations. Our objective was to identify clinical factors predictive of ototoxicity using an agnostic machine learning method. We used classification and regression tree (CART) analyses to identify clinical factors, including amikacin concentration thresholds that predicted audiometry-confirmed ototoxicity among 28 multidrug-resistant pulmonary tuberculosis patients in Botswana. Amikacin concentrations were measured for all patients. The quantitative relationship between predictive factors and the probability of ototoxicity were then identified using probit analyses. The primary predictors of ototoxicity on CART analyses were cumulative days of therapy, followed by cumulative area under the concentration-time curve (AUC), which improved on the primary predictor by 87%. The area under the receiver operating curve was 0.97 on the test set. Peak and trough were not predictors in any tree. When algorithms were forced to pick peak and trough as primary predictors, the area under the receiver operating curve fell to 0.46. Probit analysis revealed that the probability of ototoxicity increased sharply starting after 6 months of therapy to near maximum at 9 months. A 10% probability of ototoxicity occurred with a threshold cumulative AUC of 87,232 days · mg · h/liter, while that of 20% occurred at 120,000 days · mg · h/liter. Thus, cumulative amikacin AUC and duration of therapy, and not peak and trough concentrations, should be used as the primary decision-making parameters to minimize the likelihood of ototoxicity in multidrug-resistant tuberculosis. Copyright © 2015, Modongo et al.",26248372,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84942935430
Hu Y.; Loizou P.C.,"Hu, Yi (55695353000); Loizou, Philipos C. (57207534685)",55695353000; 57207534685,Environment-specific noise suppression for improved speech intelligibility by cochlear implant users,2010,Journal of the Acoustical Society of America,127,6,,3689,3695,6,54,10.1121/1.3365256,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953548295&doi=10.1121%2f1.3365256&partnerID=40&md5=3c16d2142f8c11fc5fb8cbefdad6832a,"Attempts to develop noise-suppression algorithms that can significantly improve speech intelligibility in noise by cochlear implant (CI) users have met with limited success. This is partly because algorithms were sought that would work equally well in all listening situations. Accomplishing this has been quite challenging given the variability in the temporal/spectral characteristics of real-world maskers. A different approach is taken in the present study focused on the development of environment-specific noise suppression algorithms. The proposed algorithm selects a subset of the envelope amplitudes for stimulation based on the signal-to-noise ratio (SNR) of each channel. Binary classifiers, trained using data collected from a particular noisy environment, are first used to classify the mixture envelopes of each channel as either target-dominated (SNR0≥dB) or masker-dominated (SNR<0 dB). Only target-dominated channels are subsequently selected for stimulation. Results with CI listeners indicated substantial improvements (by nearly 44 percentage points at 5 dB SNR) in intelligibility with the proposed algorithm when tested with sentences embedded in three real-world maskers. The present study demonstrated that the environment-specific approach to noise reduction has the potential to restore speech intelligibility in noise to a level near to that attained in quiet. © 2010 Acoustical Society of America.",20550267,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-77953548295
Chen Y.-J.; Chang C.-J.; Wu J.-L.; Lin Y.-H.; Yang H.-M.,"Chen, Yeou-Jiunn (7601440288); Chang, Chia-Jui (55907774300); Wu, Jiunn-Liang (57154876800); Lin, Yi-Hui (49763400300); Yang, Hui-Mei (7406569511)",7601440288; 55907774300; 57154876800; 49763400300; 7406569511,Handheld device based personal auditory training system to hearing loss,2013,"Proceedings of the 2013 IEEE Symposium on Computational Intelligence in Rehabilitation and Assistive Technologies, CIRAT 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013",,,6613818,19,23,4,1,10.1109/CIRAT.2013.6613818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886703017&doi=10.1109%2fCIRAT.2013.6613818&partnerID=40&md5=fde69ba1d9211813ff223e5124f4c342,"The assistive hearing devices are the only aids to help subjects with hearing loss to use their residual hearing. However, the performance of those devices is closely dependent on auditory training. To develop handheld devices based personal auditory training system with perceptional discrimination analysis and automatic test item generation is very helpful for subjects with hearing loss. Besides, it would ease the burden of speech-language pathologists in developing a personal auditory training. In this study, the mel-frequency cepstrum coefficients and automatic speech recognition are applied to objectively estimate the phonemic confusions. For reducing computational complex, multidimensional scaling is then used to transfer the phonemic confusions into a Euclidean space. Thus, a suitable training material could be automatically generated by simple random process. Finally, the Android based mobile phones are selected as a platform for auditory training. It is convenient for subjects to use the auditory training system. The experimental results show that the average score of mean opinion score is 3.73, which means that the system is very useful. © 2013 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-84886703017
Moore D.R.; Cowan J.A.; Riley A.; Edmondson-Jones A.M.; Ferguson M.A.,"Moore, David R. (35580993300); Cowan, Justin A. (12762079000); Riley, Alison (7102277094); Edmondson-Jones, A. Mark (15724910300); Ferguson, Melanie A. (7402593041)",35580993300; 12762079000; 7102277094; 15724910300; 7402593041,Development of auditory processing in 6- to 11-yr-old children,2011,Ear and Hearing,32,3,,269,285,16,99,10.1097/AUD.0b013e318201c468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955534726&doi=10.1097%2fAUD.0b013e318201c468&partnerID=40&md5=b93e49483c3c1e53932b00b13842fad6,"Objectives: The aim of this study is to provide developmental standards on a variety of temporal, spectral, and binaural psychoacoustic (auditory processing [AP]) tests in typically developing children, including immediate and delayed retest reliability, and comparisons between single listener performance on different tests. This study also informs choices on the selection of tests for clinical evaluation of hearing and listening (e.g., for auditory processing disorder). Design: This is a laboratory-based study of AP threshold and variability of 75 children, aged 6 to 11 yrs, and 21 young adults with normal audiometry recruited from local schools and colleges. Data were gathered in clinic-like conditions, without training and across two sessions. Eleven individual (e.g., simultaneous masking and backward masking [BM], amplitude modulation [AM], and frequency modulation [FM] detection) and three derived (temporal integration, frequency resolution, masking level difference) measure tests were embedded within a suite of computer games, each employing a three-interval, three-alternative (odd-one-out) forced choice response paradigm and a staircase adaptive method. Results: AP measures generally showed lower thresholds and reduced variance with increasing age. At 6 to 7 yrs, performance was markedly poorer than in the older groups; 35% of the children could not do the test of frequency discrimination (FD). However, on all the tasks, some children in the same group performed at near-adult levels. The distribution of performance between individuals varied widely across tasks, with clustered performance on tests of tone detection (with or without a simultaneous masker) and AM detection, and scattered performance on BM, FM detection, and FD. Threshold maturity was achieved at different rates across tests and by 10 to 11 yrs of age on all tests except FD. Masking level difference (MLD) performance did not change with age. Retest reliability was mostly high within test sessions but, again, was poorer for some of the younger children. Between test sessions separated by one to several weeks, reliability varied from poor (for FM detection) to high (for long tone detection in quiet, BM, and FD). Correlations between thresholds on different tests were generally low. Conclusions: Data suggest that the perception of different auditory stimuli occurs and develops using rather independent mechanisms, even for tasks that are closely related in procedure. While individual children can perform reliably on several distinct tasks, differences between individuals on the same tasks can be large. Because some of the youngest children perform reliably across time, at or near adult levels, immaturity between 6 and 11 yrs of age, as reflected in group statistics, reflects poor performance of some individual children rather than obligate, age-related deficits in AP. While several of the tests used were found to have potential clinical applicability, because of their reliability and ability to distinguish between individuals, it is currently unclear how performance on such tests relates to everyday listening skills. © 2011 Lippincott Williams & Wilkins, Inc.",21233712,Article,Final,,Scopus,2-s2.0-79955534726
Mugagga P.K.B.; Winberg S.,"Mugagga, Pius Kavuma Basajjabaka (57188716984); Winberg, Simon (57194855045)",57188716984; 57194855045,Sound source localisation on Android smartphones: A first step to using smartphones as auditory sensors for training A.I systems with Big Data,2015,IEEE AFRICON Conference,2015-November,,7331970,,,,7,10.1109/AFRCON.2015.7331970,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962509835&doi=10.1109%2fAFRCON.2015.7331970&partnerID=40&md5=a3e90034903e5600a52ebf670d680876,"The ability to estimate positions of sound sources is one that gives animals a 360° awareness of their acoustic environment. This helps complement the visual scene which is restricted to 180° in humans. Unfortunately, deaf people are left out on this ability. Smart phones are rapidly becoming a common tool amongst mobile users in developed and emerging markets. Their processing ability has more than doubled since their introduction to mass consumer markets by Apple in 2007. Top-end smart phones such as the Samsung Galaxy Series; 3, 4, and 5 models, have two microphones with which one can acquire stereo recordings. The purpose of this research project was to establish a feasible Sound source localization algorithm for current top-end smart phones, and to recommend hardware improvements for future smart phones, to pave way for the use of smart phones as advanced auditory sensory devices capable of acting as avatars for intelligent remote systems to learn about different acoustic scenes with help of human users. © 2015 IEEE.",,Conference paper,Final,,Scopus,2-s2.0-84962509835
Laplante-Lévesque A.; Brännström K.J.; Ingo E.; Andersson G.; Lunner T.,"Laplante-Lévesque, Ariane (6506488140); Brännström, K. Jonas (30367573700); Ingo, Elisabeth (56333830100); Andersson, Gerhard (7202645907); Lunner, Thomas (6602520682)",6506488140; 30367573700; 56333830100; 7202645907; 6602520682,Stages of change in adults who have failed an online hearing screening,2015,Ear and Hearing,36,1,,92,101,9,38,10.1097/AUD.0000000000000085,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027929246&doi=10.1097%2fAUD.0000000000000085&partnerID=40&md5=435201126d2ceed2ada72028f406e6a9,"OBJECTIVES: Hearing screening has been proposed to promote help-seeking and rehabilitation in adults with hearing impairment. However, some longitudinal studies point to low help-seeking and subsequent rehabilitation after a failed hearing screening (positive screening result). Some barriers to help-seeking and rehabilitation could be intrinsic to the profiles and needs of people who have failed a hearing screening. Theories of health behavior change could help to understand this population. One of these theories is the transtheoretical (stages-of-change) model of health behavior change, which describes profiles and needs of people facing behavior changes such as seeking help and taking up rehabilitation. According to this model, people go through distinct stages toward health behavior change: precontemplation, contemplation, action, and finally, maintenance. The present study describes the psychometric properties (construct validity) of the stages of change in adults who have failed an online hearing screening. Stages of change were measured with the University of Rhode Island Change Assessment (URICA). Principal component analysis is presented, along with cluster analysis. Internal consistency was investigated. Finally, relationships between URICA scores and speech-in-noise recognition threshold, self-reported hearing disability, and self-reported duration of hearing disability are presented.; DESIGN: In total, 224 adults who had failed a Swedish online hearing screening test (measure of speech-in-noise recognition) completed further questionnaires online, including the URICA.; RESULTS: A principal component analysis identified the stages of precontemplation, contemplation, and action, plus an additional stage, termed preparation (between contemplation and action). According to the URICA, half (50%) of the participants were in the preparation stage of change. The contemplation stage was represented by 38% of participants, while 9% were in the precontemplation stage. Finally, the action stage was represented by approximately 3% of the participants. Cluster analysis identified four stages-of-change clusters: they were named decision making (44% of sample), participation (28% of sample), indecision (16% of sample), and reluctance (12% of sample). The construct validity of the model was good. Participants who reported a more advanced stage of change had significantly greater self-reported hearing disability. However, participants who reported a more advanced stage of change did not have a significantly worse speech-in-noise recognition threshold or reported a significantly longer duration of hearing impairment.; CONCLUSION: The additional stage this study uncovered, and which other studies have also uncovered, preparation, highlights the need for adequate guidance for adults who are yet to seek help for their hearing. The fact that very few people were in the action stage (approximately 3% of the sample) signals that screening alone is unlikely to be enough to improve help-seeking and rehabilitation rates. As expected, people in the later stages of change reported significantly greater hearing disability. The lack of significant relationships between stages-of-change measures and speech-in-noise recognition threshold and self-reported duration of hearing disability highlights the complex interplay between impairment, disability, and behaviors in adults who have failed an online hearing screening and who are yet to seek help. Copyright © 2015 Wolters Kluwer Health, Inc. All rights reserved.",25158981,Article,Final,,Scopus,2-s2.0-85027929246
Chon H.; Jo Kraft S.; Zhang J.; Loucks T.; Ambrose N.G.,"Chon, HeeCheong (55313293800); Jo Kraft, Shelly (37101904100); Zhang, Jingfei (56191925600); Loucks, Torrey (6602591089); Ambrose, Nicoline G. (7004955919)",55313293800; 37101904100; 56191925600; 6602591089; 7004955919,Individual variability in delayed auditory feedback effects on speech fluency and rate in normally fluent adults,2013,"Journal of Speech, Language, and Hearing Research",56,2,,489,504,15,19,10.1044/1092-4388(2012/11-0303),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878023847&doi=10.1044%2f1092-4388%282012%2f11-0303%29&partnerID=40&md5=8212204995a780b3cbb158b4a6d31935,"Purpose: Delayed auditory feedback (DAF) is known to induce stuttering-like disfluencies (SLDs) and cause speech rate reductions in normally fluent adults, but the reason for speech disruptions is not fully known, and individual variation has not been well characterized. Studying individual variation in susceptibility to DAF may identify factors that predispose an individual to be more or less dependent on auditory feedback. Method: Participants were 62 normally fluent adults. Each participant performed a spontaneous speech task in 250-ms DAF and amplified nondelayed auditory feedback (NAF) conditions. SLDs, other disfluencies (ODs), speech errors (SEs), and articulation rate (AR) were measured under each condition. Results: In the DAF condition, SLDs and SEs significantly increased, and AR decreased. Sex had a limited effect in that mean exhibited higher rates of ODs and faster AR than women. More important, parametric cluster analysis identified that 2-and 3-subgroup solutions reveal important variation that differentiates tendencies toward disfluency changes and rate reduction under DAF, which are theoretically and empirically preferred to a single-group solution. Conclusion: Individual variability in response to DAF may be accounted for by subgroups of individuals. This suggests that certain normally fluent individuals could be more dependent on intact feedback to maintain fluency. © American Speech-Language-Hearing Association.",22992711,Article,Final,,Scopus,2-s2.0-84878023847
Aliabadi M.; Farhadian M.; Darvishi E.,"Aliabadi, Mohsen (55411400800); Farhadian, Maryam (55252532800); Darvishi, Ebrahim (56431047600)",55411400800; 55252532800; 56431047600,Prediction of hearing loss among the noise-exposed workers in a steel factory using artificial intelligence approach,2015,International Archives of Occupational and Environmental Health,88,6,,779,787,8,38,10.1007/s00420-014-1004-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938996944&doi=10.1007%2fs00420-014-1004-z&partnerID=40&md5=9052d1f2552623c69cbb30e2ba62c9df,"Purpose: Prediction of hearing loss in noisy workplaces is considered to be an important aspect of hearing conservation program. Artificial intelligence, as a new approach, can be used to predict the complex phenomenon such as hearing loss. Using artificial neural networks, this study aims to present an empirical model for the prediction of the hearing loss threshold among noise-exposed workers. Methods: Two hundred and ten workers employed in a steel factory were chosen, and their occupational exposure histories were collected. To determine the hearing loss threshold, the audiometric test was carried out using a calibrated audiometer. The personal noise exposure was also measured using a noise dosimeter in the workstations of workers. Finally, data obtained five variables, which can influence the hearing loss, were used for the development of the prediction model. Multilayer feed-forward neural networks with different structures were developed using MATLAB software. Neural network structures had one hidden layer with the number of neurons being approximately between 5 and 15 neurons. Results: The best developed neural networks with one hidden layer and ten neurons could accurately predict the hearing loss threshold with RMSE = 2.6 dB and R2 = 0.89. The results also confirmed that neural networks could provide more accurate predictions than multiple regressions. Conclusions: Since occupational hearing loss is frequently non-curable, results of accurate prediction can be used by occupational health experts to modify and improve noise exposure conditions. © 2014, Springer-Verlag Berlin Heidelberg.",25432298,Article,Final,,Scopus,2-s2.0-84938996944
Dubno J.R.; Eckert M.A.; Lee F.-S.; Matthews L.J.; Schmiedt R.A.,"Dubno, Judy R. (7003933859); Eckert, Mark A. (7102209282); Lee, Fu-Shing (7403111888); Matthews, Lois J. (7202490616); Schmiedt, Richard A. (7003429369)",7003933859; 7102209282; 7403111888; 7202490616; 7003429369,Classifying human audiometric phenotypes of age-related hearing loss from animal models,2013,JARO - Journal of the Association for Research in Otolaryngology,14,5,,687,701,14,131,10.1007/s10162-013-0396-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884287238&doi=10.1007%2fs10162-013-0396-x&partnerID=40&md5=b8e26b25d6ccef37f5bf0b00f2b3f238,"Age-related hearing loss (presbyacusis) has a complex etiology. Results from animal models detailing the effects of specific cochlear injuries on audiometric profiles may be used to understand the mechanisms underlying hearing loss in older humans and predict cochlear pathologies associated with certain audiometric configurations (""audiometric phenotypes""). Patterns of hearing loss associated with cochlear pathology in animal models were used to define schematic boundaries of human audiograms. Pathologies included evidence for metabolic, sensory, and a mixed metabolic + sensory phenotype; an older normal phenotype without threshold elevation was also defined. Audiograms from a large sample of older adults were then searched by a human expert for ""exemplars"" (best examples) of these phenotypes, without knowledge of the human subject demographic information. Mean thresholds and slopes of higher frequency thresholds of the audiograms assigned to the four phenotypes were consistent with the predefined schematic boundaries and differed significantly from each other. Significant differences in age, gender, and noise exposure history provided external validity for the four phenotypes. Three supervised machine learning classifiers were then used to assess reliability of the exemplar training set to estimate the probability that newly obtained audiograms exhibited one of the four phenotypes. These procedures classified the exemplars with a high degree of accuracy; classifications of the remaining cases were consistent with the exemplars with respect to average thresholds and demographic information. These results suggest that animal models of age-related hearing loss can be used to predict human cochlear pathology by classifying audiograms into phenotypic classifications that reflect probable etiologies for hearing loss in older humans. © 2013 Association for Research in Otolaryngology.",23740184,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84884287238
Fernández A.; Marey J.; Ortega M.; Penedo M.G.,"Fernández, A. (36170381500); Marey, J. (57509706200); Ortega, M. (24475406900); Penedo, M.G. (7004450125)",36170381500; 57509706200; 24475406900; 7004450125,Influence of the interest operators in the detection of spontaneous reactions to the sound,2015,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),8946,,,346,361,15,0,10.1007/978-3-319-25210-0_21,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950273177&doi=10.1007%2f978-3-319-25210-0_21&partnerID=40&md5=b1ec5aac39debb88e6dee8f524955118,"Hearing plays a key role in our social participation and daily activities. In health, hearing loss in one of the most common conditions, so its diagnosis and monitoring is highly important. The standard test for the evaluation of hearing is the pure tone audiometry, which is a behavioral test that requires a proper interaction and communication between the patient and the audiologist. This need of understanding is which makes this test unworkable when dealing with patients with severe cognitive decline or other communication disorders. In these particular cases, the audiologist base the evaluation in the detection of spontaneous facial reaction that may indicate auditory perception. With the aim of supporting the audiologist, a screening method that analyzes video sequences and seeks for eye gestural reactions was proposed. In this paper, a comprehensive survey about one of the crucial steps of the methodology is presented. This survey determines the optimal configuration for all of them, and evaluates in detail their combination with different classification techniques. The obtained results provide a global vision of the suitability of the different interest operators. © Springer International Publishing Switzerland 2015.",,Conference paper,Final,,Scopus,2-s2.0-84950273177
Samimi H.; Forouzanfar M.; Dajani H.R.,"Samimi, Hamed (57193666290); Forouzanfar, Mohamad (23004223900); Dajani, Hilmi R. (6602700591)",57193666290; 23004223900; 6602700591,Automatic recognition of speech-evoked brainstem responses to English vowels,2015,"Proceedings of the IASTED International Conference on Computational Intelligence, CI 2015",,,,207,211,4,0,10.2316/P.2015.827-019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015691826&doi=10.2316%2fP.2015.827-019&partnerID=40&md5=60f49bcbc4fd21b10b5477b57ed6bfc5,"The objective of this study is to investigate automatic recognition of speech-evoked auditory brainstem responses (speech ABR) to the five English vowels (/a/, /ae/, /?/, /i/ and /u/). We used different automatic speech recognition methods to discriminate between the responses to the vowels. The best recognition result was obtained by applying principal component analysis (PCA) on the amplitudes of the first ten harmonic components of the envelope following response (based on spectral components at fundamental frequency and its harmonics) and of the frequency following response (based on spectral components in first formant region) and combining these two feature sets. With this combined feature set used as input to an artificial neural network, a recognition accuracy of 86.3% was achieved. This study could be extended to more complex stimuli to improve assessment of the auditory system for speech communication in hearing impaired individuals, and potentially help in the objective fitting of hearing aids.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85015691826
Heisterüber M.; Gröne B.; Domahs F.; Binkofski F.,"Heisterüber, Miriam (55497517000); Gröne, Berthold (35795308000); Domahs, Frank (6603351384); Binkofski, Ferdinand (7003382482)",55497517000; 35795308000; 6603351384; 7003382482,Intensive treatment of auditory analysis in a 16-year-old aphasic patient; [Hochfrequentes Training der auditiven Analyse bei Aphasie],2012,Forum Logopadie,26,6,,6,11,5,0,10.2443/skv-s-2012-53020120601,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869756015&doi=10.2443%2fskv-s-2012-53020120601&partnerID=40&md5=83dc376464e3fd5bac81024660898830,"Aim of this treatment study was to improve speech comprehension of a 16-year-old patient with Wernicke's aphasia and a partial disorder of auditory analysis (""word sound deafness""). To this end, tasks addressing phoneme-grapheme correspondence with syllables were used as well as speech discrimination tasks with syllables, consonant clusters and neologisms. The patient showed significant improvement with trained items and generalization effects to untrained items. Furthermore, secondary improvements could be observed in tasks which are based on the auditory analysis (e.g. lexical decision). However, performance in an untrained control task (rime generation) did not change, indicating that the effects of therapy were specific. Moreover, the patient showed an enhanced self-monitoring, evidenced by an increased rate of self-corrections. Copyright © Schulz-Kirchner Verlag, Idstein.",,Article,Final,,Scopus,2-s2.0-84869756015
Fulcher A.; Baker E.; Purcell A.; Munro N.,"Fulcher, Anne (55388271400); Baker, Elise (55375526800); Purcell, Alison (7005219863); Munro, Natalie (25825496100)",55388271400; 55375526800; 7005219863; 25825496100,Typical consonant cluster acquisition in auditory-verbal children with early-identified severe/profound hearing loss,2014,International Journal of Speech-Language Pathology,16,1,,69,81,12,8,10.3109/17549507.2013.808698,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892581064&doi=10.3109%2f17549507.2013.808698&partnerID=40&md5=22edfd58a4b0ee27133f64294676975c,"Early-identified severe/profound hearing loss (HL) following universal newborn hearing screening (UNHS) has been associated with improved speech and language outcomes. However, speech outcome reports have typically been based on broad measures of speech intelligibility and/or singleton consonant accuracy, with little known about production of consonant clusters. Using a prospective design, the range and accuracy of consonant clusters produced by a homogenous cohort of 12 children early-identified with severe/profound HL aged 3- and 4-years were examined. All children demonstrated bilateral aided thresholds within a range of 15-25 dB HL across all frequencies, were optimally amplified with cochlear implants (11/12) or hearing aids (1/12), and attended auditory-verbal (AV) early intervention. Standardized speech and language assessments were administered. Consonant clusters were strategically sampled in single-word and conversational speech contexts. All standard scores for speech, receptive, and expressive language were within normal limits. All children produced consonant clusters commensurate with expectations for typically-developing hearing peers at 3- and 4- years-of-age. Children's production of phonetically complex morphophonemes (final consonant clusters marking grammatical morphemes) was also in keeping with developmental expectations. Factors which contributed to these encouraging outcomes require further investigation. © 2014 The Speech Pathology Association of Australia Limited.",24001172,Article,Final,,Scopus,2-s2.0-84892581064
Jiang H.; Wang L.; Beier K.T.; Cepko C.L.; Fekete D.M.; Brigande J.V.,"Jiang, Han (57191445261); Wang, Lingyan (37011581500); Beier, Kevin T. (36672493600); Cepko, Constance L. (10240780700); Fekete, Donna M. (7005752044); Brigande, John V. (6505804884)",57191445261; 37011581500; 36672493600; 10240780700; 7005752044; 6505804884,Lineage Analysis of the Late Otocyst Stage Mouse Inner Ear by Transuterine Microinjection of A Retroviral Vector Encoding Alkaline Phosphatase and an Oligonucleotide Library,2013,PLoS ONE,8,7,e69314,,,,17,10.1371/journal.pone.0069314,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880844253&doi=10.1371%2fjournal.pone.0069314&partnerID=40&md5=6edf29d39036deb977a0a97a1bb50ba8,"The mammalian inner ear subserves the special senses of hearing and balance. The auditory and vestibular sensory epithelia consist of mechanically sensitive hair cells and associated supporting cells. Hearing loss and balance dysfunction are most frequently caused by compromise of hair cells and/or their innervating neurons. The development of gene- and cell-based therapeutics will benefit from a thorough understanding of the molecular basis of patterning and cell fate specification in the mammalian inner ear. This includes analyses of cell lineages and cell dispersals across anatomical boundaries (such as sensory versus nonsensory territories). The goal of this study was to conduct retroviral lineage analysis of the embryonic day 11.5(E11.5) mouse otic vesicle. A replication-defective retrovirus encoding human placental alkaline phosphatase (PLAP) and a variable 24-bp oligonucleotide tag was microinjected into the E11.5 mouse otocyst. PLAP-positive cells were microdissected from cryostat sections of the postnatal inner ear and subjected to nested PCR. PLAP-positive cells sharing the same sequence tag were assumed to have arisen from a common progenitor and are clonally related. Thirty five multicellular clones consisting of an average of 3.4 cells per clone were identified in the auditory and vestibular sensory epithelia, ganglia, spiral limbus, and stria vascularis. Vestibular hair cells in the posterior crista were related to one another, their supporting cells, and nonsensory epithelial cells lining the ampulla. In the organ of Corti, outer hair cells were related to a supporting cell type and were tightly clustered. By contrast, spiral ganglion neurons, interdental cells, and Claudius' cells were related to cells of the same type and could be dispersed over hundreds of microns. These data contribute new information about the developmental potential of mammalian otic precursors in vivo. © 2013 Jiang et al.",23935981,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84880844253
Marlenga B.; Linneman J.G.; Pickett W.; Wood D.J.; Kirkhorn S.R.; Broste S.K.; Knobloch M.J.; Berg R.L.,"Marlenga, Barbara (6601976109); Linneman, James G. (15832154200); Pickett, William (7102833854); Wood, Douglas J. (55468928100); Kirkhorn, Steven R. (6603281756); Broste, Steven K. (7003844198); Knobloch, Mary Jo (6701892377); Berg, Richard L. (7402880130)",6601976109; 15832154200; 7102833854; 55468928100; 6603281756; 7003844198; 6701892377; 7402880130,Randomized trial of a hearing conservation intervention for rural students: Long-term outcomes,2011,Pediatrics,128,5,,e1139,e1146,7,17,10.1542/peds.2011-0770,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80355131206&doi=10.1542%2fpeds.2011-0770&partnerID=40&md5=ffc525f3407c85653335baa36d9332ca,"OBJECTIVES: We had the rare opportunity to conduct a cluster-randomized controlled trial to observe the long-term (16-year) effects of a well-designed hearing conservation intervention for rural high school students. This trial assessed whether the intervention resulted in (1) reduced prevalence of noise-induced hearing loss (NIHL) assessed clinically and/or (2) sustained use of hearing protection devices. METHODS: In 1992-1996, 34 rural Wisconsin schools were recruited and 17 were assigned randomly to receive a comprehensive, 3-year, hearing conservation intervention. In 2009 -2010, extensive efforts were made to find and contact all students who completed the original trial. Participants in the 16-year follow-up study completed an exposure history questionnaire and a clinical audiometric examination. Rates of NIHL and use of hearing protection were compared. RESULTS: We recruited 392 participants from the original trial, 200 (53%) from the intervention group and 192 (51%) from the control group. Among participants with exposure to agricultural noise, the intervention group reported significantly greater use of hearing protection compared with the control group (25.9% vs 19.6%; P=.015). The intervention group also reported significantly greater use of hearing protection for shooting guns (56.2% vs 41.6%; P = .029), but the groups reported similar uses of protection in other contexts. There was no significant difference between groups with respect to objective measures of NIHL. CONCLUSION: This novel trial provides objective evidence that a comprehensive educational intervention by itself may be of limited effectiveness in preventing NIHL in a young rural population. Copyright © 2011 by the American Academy of Pediatrics.",21987700,Article,Final,,Scopus,2-s2.0-80355131206
Hertzano R.; Puligilla C.; Chan S.-L.; Timothy C.; Depireux D.A.; Ahmed Z.; Wolf J.; Eisenman D.J.; Friedman T.B.; Riazuddin S.; Kelley M.W.; Strome S.E.,"Hertzano, Ronna (6507790490); Puligilla, Chandrakala (17135779100); Chan, Siaw-Lin (25627548200); Timothy, Caroline (36775613600); Depireux, Didier A. (6602912099); Ahmed, Zubair (35314502900); Wolf, Jeffrey (7403565201); Eisenman, David J. (6701403121); Friedman, Thomas B. (34569115500); Riazuddin, Sheikh (57210225043); Kelley, Matthew W. (7403230326); Strome, Scott E. (7004882323)",6507790490; 17135779100; 25627548200; 36775613600; 6602912099; 35314502900; 7403565201; 6701403121; 34569115500; 57210225043; 7403230326; 7004882323,CD44 is a marker for the outer pillar cells in the early postnatal mouse inner ear,2010,JARO - Journal of the Association for Research in Otolaryngology,11,3,,407,418,11,34,10.1007/s10162-010-0211-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650195911&doi=10.1007%2fs10162-010-0211-x&partnerID=40&md5=76a0ac8b255f4442e4d6daa8e75f38ef,"Cluster of differentiation antigens (CD proteins) are classically used as immune cell markers. However, their expression within the inner ear is still largely undefined. In this study, we explored the possibility that specific CD proteins might be useful for defining inner ear cell populations. mRNA expression profiling of microdissected auditory and vestibular sensory epithelia revealed 107 CD genes as expressed in the early postnatal mouse inner ear. The expression of 68 CD genes was validated with real-time RT-PCR using RNA extracted from microdissected sensory epithelia of cochleae, utricles, saccules, and cristae of newborn mice. Specifically, CD44 was identified as preferentially expressed in the auditory sensory epithelium. Immunohistochemistry revealed that within the early postnatal organ of Corti, the expression of CD44 is restricted to outer pillar cells. In order to confirm and expand this finding, we characterized the expression of CD44 in two different strains of mice with loss- and gain-of-function mutations in Fgfr3 which encodes a receptor for FGF8 that is essential for pillar cell development. We found that the expression of CD44 is abolished from the immature pillar cells in homozygous Fgfr3 knockout mice. In contrast, both the outer pillar cells and the aberrant Deiters' cells in the Fgfr3 P24RR/+ mice express CD44. The deafness phenotype segregating in DFNB51 families maps to a linkage interval that includes CD44. To study the potential role of CD44 in hearing, we characterized the auditory system of CD44 knockout mice and sequenced the entire open reading frame of CD44 of affected members of DFNB51 families. Our results suggest that CD44 does not underlie the deafness phenotype of the DFNB51 families. Finally, our study reveals multiple potential new cell type-specific markers in the mouse inner ear and identifies a new marker for outer pillar cells. © 2010 Association for Research in Otolaryngology.",20386946,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-78650195911
Poost-Foroosh L.; Jennings M.B.; Shaw L.; Meston C.N.; Cheesman M.F.,"Poost-Foroosh, Laya (55053558600); Jennings, Mary Beth (8856456500); Shaw, Lynn (35307664700); Meston, Christine N. (54393691600); Cheesman, Margaret F. (7003599259)",55053558600; 8856456500; 35307664700; 54393691600; 7003599259,Factors in Client–Clinician Interaction That Influence Hearing Aid Adoption,2011,Trends in Amplification,15,3,,127,139,12,76,10.1177/1084713811430217,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857727049&doi=10.1177%2f1084713811430217&partnerID=40&md5=d189e04e55a40d0e0442eccb9828e986,"The influence of client–clinician interactions has not been emphasized in hearing health care, despite the extensive evidence of the impact of the provider–patient interaction on health outcomes. The purpose of this study was to identify factors in the client–clinician interaction that may influence hearing aid adoption. Thirteen adults who had received a hearing aid recommendation within the previous 3 months and 10 audiologists participated in a study to generate, sort, and rate the importance of factors in client–clinician interaction that may influence the hearing aid purchase decision. A concept mapping approach was used to define meaningful clusters of factors. Quantitative analysis and qualitative interpretation of the statements resulted in eight concepts. The concepts in order of their importance are (a) Ensuring client comfort, (b) Understanding and meeting client needs, (c) Client-centered traits and actions, (d) Acknowledging client as an individual, (e) Imposing undue pressure and discomfort, (f) Conveying device information by clinician, (g) Supporting choices and shared decision making, and (h) Factors in client readiness. Two overarching themes of client-centered interaction and client empowerment were identified. Results highlight the influence of the client–clinician interaction in hearing aid adoption and suggest the possibility of improving hearing aid adoption by empowering clients through a client-centered interaction. © 2011, SAGE Publications. All rights reserved.",22155784,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84857727049
Ostadimoghaddam H.; Mirhajian H.; Yekta A.; Sobhani Rad D.; Heravian J.; Malekifar A.; Khabazkhoob M.,"Ostadimoghaddam, Hadi (6603691944); Mirhajian, Hanieh (57190792416); Yekta, AbbasAli (6603699234); Sobhani Rad, Davood (36471193600); Heravian, Javad (6507758751); Malekifar, Azam (57221776921); Khabazkhoob, Mehdi (16067093200)",6603691944; 57190792416; 6603699234; 36471193600; 6507758751; 57221776921; 16067093200,Eye problems in children with hearing impairment,2015,Journal of Current Ophthalmology,27,01-Feb,,56,59,3,8,10.1016/j.joco.2015.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983167710&doi=10.1016%2fj.joco.2015.10.001&partnerID=40&md5=21aeeab3d63bcc1b4e16b38021185f89,"Purpose: To compare the prevalence of refractive errors, amblyopia, and strabismus between hearing-impaired and normal children (7-22 years old) in Mashhad. Methods: In this cross-sectional study, cases were selected from hearing-impaired children in Mashhad. The control group consisted of children with no hearing problem. The sampling was done utilizing the cluster sampling method. All of the samples underwent refraction, cover test, and visual examinations. Results: 254 children in the hearing-impaired group (case) and 506 children in the control group were assessed. The mean spherical equivalent was 1.7 ± 1.9 D in the case group, which was significantly different from the control group (0.2 ± 1.5) (P < 0.001). The prevalence of hyperopia was 57.15% and 21.5% in deaf and normal children, respectively, but myopia was mostly seen in the control group (5.5% versus 11.9%, P = 0.007). The mean cylinder was 0.65 ± 1.3 D and 0.43 ± 0.62 D in deaf and normal subjects, respectively (P = 0.002). 12.2% of deaf subjects and 1.2% of normal subjects were amblyopic (P < 0.001), and the prevalence of strabismus was 3.1% in the case group and 2.6% in the control group (P = 0.645). Conclusion: In a comparison of children of the same ages, hearing-impaired children have significantly more eye problems; therefore, a possible relation between deafness and eye problems must exist. Paying attention to eye health assessment in hearing-impaired children may help prevent adding eye problems to hearing difficulties. © 2015 Iranian Society of Ophthalmology.",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84983167710
Bush M.L.; Christian W.J.; Bianchi K.; Lester C.; Schoenberg N.,"Bush, Matthew L. (24721230400); Christian, Warren Jay (7006318256); Bianchi, Kristin (55901591200); Lester, Cathy (55901252300); Schoenberg, Nancy (7003479999)",24721230400; 7006318256; 55901591200; 55901252300; 7003479999,Targeting regional pediatric congenital hearing loss using a spatial scan statistic,2015,Ear and Hearing,36,2,,212,216,4,6,10.1097/AUD.0000000000000101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937972810&doi=10.1097%2fAUD.0000000000000101&partnerID=40&md5=f2067a02c3ce02c9f5a025558bd82f30,"Objectives: Congenital hearing loss is a common problem, and timely identification and intervention are paramount for language development. Patients from rural regions may have many barriers to timely diagnosis and intervention. The purpose of this study was to examine the spatial and hospital-based distribution of failed infant hearing screening testing and pediatric congenital hearing loss throughout Kentucky. Design: Data on live births and audiological reporting of infant hearing loss results in Kentucky from 2009 to 2011 were analyzed. The authors used spatial scan statistics to identify high-rate clusters of failed newborn screening tests and permanent congenital hearing loss (PCHL), based on the total number of live births per county. The authors conducted further analyses on PCHL and failed newborn hearing screening tests, based on birth hospital data and method of screening. Results: The authors observed four statistically significant (p < 0.05) high-rate clusters with failed newborn hearing screenings in Kentucky, including two in the Appalachian region. Hospitals using two-stage otoacoustic emission testing demonstrated higher rates of failed screening (p = 0.009) than those using two-stage automated auditory brainstem response testing. A significant cluster of high rate of PCHL was observed in Western Kentucky. Five of the 54 birthing hospitals were found to have higher relative risk of PCHL, and two of those hospitals are located in a very rural region of Western Kentucky within the cluster. Conclusions: This spatial analysis in children in Kentucky has identified specific regions throughout the state with high rates of congenital hearing loss and failed newborn hearing screening tests. Further investigation regarding causative factors is warranted. This method of analysis can be useful in the setting of hearing health disparities to focus efforts on regions facing high incidence of congenital hearing loss. © 2014 Wolters Kluwer Health, Inc.",25225918,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84937972810
Kodituwakku P.; Kodituwakku E.L.,"Kodituwakku, Piyadasa (6602564908); Kodituwakku, E. Louise (37111138800)",6602564908; 37111138800,Fetal alcohol syndrome,2013,Neuroscience in the 21st Century: From Basic to Clinical,,,,2411,2430,19,0,10.1007/978-1-4614-1997-6_90,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929281465&doi=10.1007%2f978-1-4614-1997-6_90&partnerID=40&md5=d49055a236c96db0bf6ae8f3439f4551,"Maternal alcohol consumption during pregnancy is known to produce a spectrum of morphological and neurocognitive outcomes in the offspring. The most severely affected on the spectrum exhibit a cluster of birth defects called fetal alcohol syndrome, which is characterized by a unique pattern of anomalies on the face, prenatal and/or postnatal growth deficiency, and evidence of central nervous system (CNS) dysfunction (Jones et al. 1973). The characteristic pattern of malformations on the face includes a smooth philtrum, thin upper lip, and short palpebral fissures (see Fig. 80.1). Children with FASD are usually small in stature, with their height and weight falling below the 10th percentile. The deleterious effects of alcohol on the central nervous system are evidenced by microcephaly and cognitive and behavioral deficits. Children with prenatal alcohol exposure have also been observed to exhibit birth defects involving other systems such as cardiac (e.g., atrial and ventricular septal defects), skeletal (e.g., clinodactyly and camptodactyly), ocular (e.g., strabismus), and auditory (e.g., conductive hearing loss). However, the majority of children on the spectrum display only some or none of the above physical features but exhibit evidence of CNS dysfunction. The term, alcohol-related neurodevelopmental disorder (ARND), is used to label neurodevelopmental difficulties in those alcohol-exposed children without clinically discernable physical anomalies (Stratton et al. 1996). Although not a diagnostic label, the term fetal alcohol spectrum disorders (FASDs) has been introduced to denote the full spectrum of morphological and neurocognitive outcomes resulting from prenatal alcohol exposure. While estimated prevalence rates of FAS range from.5 to 2 cases per 1,000 live births, the rate of FASD is estimated at 1 per 100 (Sampson et al. 1997) © 2013 Springer Science+Business Media, LLC. All rights are reserved.",,Book chapter,Final,,Scopus,2-s2.0-84929281465
Hooper R.E.,"Hooper, R.E. (57198104000)",57198104000,Acoustic shock controversies,2014,Journal of Laryngology and Otology,128,SUPPL. S2,,S2,S9,7,8,10.1017/S0022215114000309,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903556086&doi=10.1017%2fS0022215114000309&partnerID=40&md5=a60fa3d09fdb6fe0b36b8d1cefed4901,"Background: The diagnosis 'acoustic shock' has been made increasingly in the health care industry in recent years. This paper aims to question the validity of acoustic shock as an organic pathological entity. Methods: The experiences of 16 individuals diagnosed as having acoustic shock, within a medico-legal practice, are reviewed. Results: The commonest symptom was otalgia, followed by noise sensitivity, tinnitus, hearing disturbance and dizziness. Conclusion: The presence of noise-limiting technology in the workplace, the variation in the nature of the acoustic incident involved (ranging from a shriek, through feedback noise, to a male voice), and the marked variation in the time of symptom onset (following the acoustic incident) all suggest that the condition termed acoustic shock is predominantly psychogenic. Cases of pseudohypacusis indicate that malingering is a factor in some cases. Clusters of acoustic shock events occurring in the same call centres suggest that hysteria may play a part. The condition is usually only seen when work-related issues are apparent. Copyright © JLO (1984) Limited 2014.",24565111,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84903556086
Jyothi V.; Li M.; Kilpatrick L.A.; Smythe N.; LaRue A.C.; Zhou D.; Schulte B.A.; Schmiedt R.A.; Lang H.,"Jyothi, Vinu (35772221100); Li, Manna (36611976000); Kilpatrick, Lauren A. (35746414500); Smythe, Nancy (8080233200); LaRue, Amanda C. (7003852334); Zhou, Daohong (7403394355); Schulte, Bradley A. (7102826478); Schmiedt, Richard A. (7003429369); Lang, Hainan (7402486012)",35772221100; 36611976000; 35746414500; 8080233200; 7003852334; 7403394355; 7102826478; 7003429369; 7402486012,Unmyelinated auditory type i spiral ganglion neurons in congenic Ly5.1 mice,2010,Journal of Comparative Neurology,518,16,,3254,3271,17,23,10.1002/cne.22398,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954613965&doi=10.1002%2fcne.22398&partnerID=40&md5=44622b0c70879680b183ae8505c8edeb,"With the exception of humans, the somata of type I spiral ganglion neurons (SGNs) of most mammalian species are heavily myelinated. In an earlier study, we used Ly5.1 congenic mice as transplant recipients to investigate the role of hematopoietic stem cells in the adult mouse inner ear. An unanticipated finding was that a large percentage of the SGNs in this strain were unmyelinated. Further characterization of the auditory phenotype of young adult Ly5.1 mice in the present study revealed several unusual characteristics, including 1) large aggregates of unmyelinated SGNs in the apical and middle turns, 2) symmetrical junction-like contacts between the unmyelinated neurons, 3) abnormal expression patterns for CNPase and connexin 29 in the SGN clusters, 4) reduced SGN density in the basal cochlea without a corresponding loss of sensory hair cells, 5) significantly delayed auditory brainstem response (ABR) wave I latencies at low and middle frequencies compared with control mice with similar ABR threshold, and 6) elevated ABR thresholds and deceased wave I amplitudes at high frequencies. Taken together, these data suggest a defect in Schwann cells that leads to incomplete myelinization of SGNs during cochlear development. The Ly5.1 mouse strain appears to be the only rodent model so far identified with a high degree of the ""human-like"" feature of unmyelinated SGNs that aggregate into neural clusters. Thus, this strain may provide a suitable animal platform for modeling human auditory information processing such as synchronous neural activity and other auditory response properties. © 2010 Wiley-Liss, Inc.",20575058,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-77954613965
Vaerenberg B.; Govaerts P.J.; De Ceulaer G.; Daemers K.; Schauwers K.,"Vaerenberg, Bart (36351308400); Govaerts, Paul J (7005148990); De Ceulaer, Geert (6602247657); Daemers, Kristin (6603575391); Schauwers, Karen (6506231132)",36351308400; 7005148990; 6602247657; 6603575391; 6506231132,"Experiences of the use of FOX, an intelligent agent, for programming cochlear implant sound processors in new users",2010,International Journal of Audiology,50,1,,50,58,8,21,10.3109/14992027.2010.531294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650279265&doi=10.3109%2f14992027.2010.531294&partnerID=40&md5=97a1c59d9539ec0b5a4075f43f1b082d,"Objective. This report describes the application of the software tool ""Fitting to Outcomes eXpert"" (FOX) in programming the cochlear implant (CI) processor in new users. FOX is an intelligent agent to assist in the programming of CI processors. The concept of FOX is to modify maps on the basis of specific outcome measures, achieved using heuristic logic and based on a set of deterministic ""rules"". Design. A prospective study was conducted on eight consecutive CI-users with a follow-up of three months. Study Sample. Eight adult subjects with postlingual deafness were implanted with the Advanced Bionics HiRes90k device. The implants were programmed using FOX, running a set of rules known as Eargroup's EG0910 advice, which features a set of ""automaps"". The protocol employed for the initial 3 months is presented, with description of the map modifications generated by FOX and the corresponding psychoacoustic test results. Results. The 3 month median results show 25 dBHL as PTA, 77% (55 dBSPL) and 71% (70 dBSPL) phoneme score at speech audiometry and loudness scaling in or near to the normal zone at different frequencies. Conclusions. It is concluded that this approach is feasible to start up CI fitting and yields good outcome. © 2011 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",21091083,Article,Final,,Scopus,2-s2.0-78650279265
Chang Y.; Lee H.-R.; Paik J.-S.; Lee K.-Y.; Lee S.-H.,"Chang, Yongmin (7501840633); Lee, Hye-Ryung (35215746900); Paik, Jong-Soo (57197239205); Lee, Kyu-Yup (22135779500); Lee, Sang-Heun (56044373300)",7501840633; 35215746900; 57197239205; 22135779500; 56044373300,Voxel-wise analysis of diffusion tensor imaging for clinical outcome of cochlear implantation: Retrospective study,2012,Clinical and Experimental Otorhinolaryngology,5,SUPPL. 1,,S37,S42,5,19,10.3342/ceo.2012.5.S1.S37,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862275256&doi=10.3342%2fceo.2012.5.S1.S37&partnerID=40&md5=8c22ce98405fd4e13b25111e4e6b836d,"Objectives: To evaluate retrospectively, the possible difference in diffusion tensor imaging (DTT) metric of fractional anisot-ropy (FA) between good and poor surgical outcome cochlear implantation (CI) patients using investigator-independent voxel-wise analysis. Methods: Eighteen patients (11 males, 7 females; mean age, 5.9 years) with profound sensorineural hearing loss underwent DTI scans using a 3.0 Tesla magnetic resonance scanner. Among the 18 patients, 10 patients with categories of auditory performance (CAP) score over 6 were classified into the good outcome group and 8 patients with CAP score below 6 were classified into the poor outcome group. The diffusion tensor scalar measure was calculated from the eigenvalues of the tensor on a voxel-by-voxel basis from each subject and two-sample r-test evaluation between good and poor outcome subjects were performed for each voxel of FA values, across the entire brain, with a voxel-wise intensity threshold of P< 0.0005 (uncorrected) and a contiguous cluster size of 64 voxels. Individual values of FA were measured by using the region-of-interest based analysis for correlation analysis with CAP scores, open sentence and open word scores. Results: Two-sample r-test evaluation using SPM voxel-wise analysis found significantly higher FA values at the several brain areas including Broca's area, genu of the corpus callosum, and auditory tract in good outcome subjects compared to poor outcome subjects. Correlation analyses between FA and CAP scores, open sentence and open word scores revealed strong correlations at medial geniculate nucleus, Broca's area, genu of the corpus callosum and auditory tract. Conclusion: Investigator- independent voxel-based analysis of DTI image demonstrated that good outcome subjects showed better neural integrity at brain areas associated with language and auditory functions, suggesting that the conservation of microstructural integrity of these brain areas is important. Preoperative functional imaging may be helpful for CI. Copyright © 2012 by Korean Society of Otorhinolaryngology-Head and Neck Surgery.",,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84862275256
Sidi S.; Busch-Nentwich E.; Friedrich R.; Schoenberger U.; Nicolson T.,"Sidi, Samuel (6602304161); Busch-Nentwich, Elisabeth (57195384757); Friedrich, Rainer (57219519595); Schoenberger, Ulrike (6508057488); Nicolson, Teresa (7003625622)",6602304161; 57195384757; 57219519595; 6508057488; 7003625622,gemini Encodes a Zebrafish L-Type Calcium Channel That Localizes at Sensory Hair Cell Ribbon Synapses,2004,Journal of Neuroscience,24,17,,4213,4223,10,77,10.1523/JNEUROSCI.0223-04.2004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442444290&doi=10.1523%2fJNEUROSCI.0223-04.2004&partnerID=40&md5=ece606f0a0c44a49ff74e878717a57fb,"L-type Ca2+ channels (LTCCs) drive the bulk of voltage-gated Ca2+ entry in vertebrate inner ear hair cells (HCs) and are essential for mammalian auditory processing. LTCC currents have been implicated in neurotransmitter release at the HC afferent active zone, the ribbon synapse. It is likely that LTCCs play a direct role in vesicle fusion; however, the subcellular localization of the channels in HCs has not been fully resolved. Via positional cloning, we show that mutations in a zebrafish LTCC encoding gene, cav1.3a, underlie the auditory-vestibular defects of gemini (gem) circler mutants. gem homozygous receptor mutant HCs display normal cell viability, afferent synaptogenesis, and peripheral innervation, yet exhibit strongly reduced extracellular potentials (∼50% of wild-type potentials). Apical FM1-43 uptake, however, is unaffected in gem mutant HCs, suggesting that mechanotransduction channels are functional. Using a Gem-specific antibody, we show that the bulk of Gem/Cav1.3a immunoreactivity in HCs is restricted to basally located focal spots. The number and location of focal spots relative to nerve terminals, and their remarkable ring-shaped structure, which is reminiscent of synaptic dense bodies, are consistent with Gem/Ca v1.3a channels clustering at HC ribbon synapses.",15115817,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-2442444290
Samson Y.; Belin P.; Thivard L.; Boddaert N.; Crozier S.; Zilbovicius M.,"Samson, Y. (7006646196); Belin, P. (7004230885); Thivard, L. (6602387773); Boddaert, N. (57203073518); Crozier, S. (7005802839); Zilbovicius, M. (7003390309)",7006646196; 7004230885; 6602387773; 57203073518; 7005802839; 7003390309,Auditory perception and language: Functional imaging of speech sensitive auditory cortex; [Perception auditive et langage: Imagerie fonctionnelle du cortex auditif sensible au langage],2001,Revue Neurologique,157,8-9 I,,837,846,9,22,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034795894&partnerID=40&md5=98c523284d2a82db00514b47c49a2709,"Since the description of cortical deafness, it has been known that the superior temporal cortex is bilaterally involved in the initial stages of language auditory perception but the precise anatomical limits and the function of this area remain debated. Here we reviewed more than 40 recent papers of positron emission tomography and functional magnetic resonance imaging related to language auditory perception, and we performed a meta-analysis of the localization of the peaks of activation in the Talairach's space. We found 8 studies reporting word versus non-word listening contrasts with 54 activation peaks in the temporal lobes. These peaks clustered in a bilateral and well-limited area of the temporal superior cortex, which is here operationally defined as the speech sensitive auditory cortex. This area is more than 4cm long, located in the superior temporal gyrus and the superior temporal sulcus, both anterior and posterior to Heschl's gyrus. It do not include the primary auditory cortex nor the ascending part of the planum temporale. The speech sensitive auditory cortex is not activated by pure tones, environmental sounds, or attention directed toward elementary components of a sound such as intensity, pitch, or duration, and thus has some specificity for speech signals. The specificity is not perfect, since we found a number of non-speech auditory stimuli activating the speech sensitive auditory cortex. Yet the latter studies always involve auditory perception mechanisms which are also relevant to speech perception either at the level of primitive auditory scene analysis processes, or at the level of specific schema-based recognition processes. The dorsal part of the speech sensitive auditory cortex may be involved in primitive scene analysis processes, whereas distributed activation of this area may contribute to the emergence of a broad class of « voice » schemas and of more specific « speech sche- mas/phonetic modules » related to different languages. In addition, this area is activated by language-related lip movement, suggesting that a multimodal integration of the auditory and the visual information relevant in speech perception occurs at this level. Finally, there is a task- related top-down modulation of the pattern of activation of the speech sensitive auditory cortex which may reflect the fact that the different parts of this structure are connected to different down-stream cortical regions involved in the neural processing of different types of tasks.",11677406,Conference paper,Final,,Scopus,2-s2.0-0034795894
Hickok G.; Poeppel D.,"Hickok, Gregory (7004718457); Poeppel, David (7003791677)",7004718457; 7003791677,Dorsal and ventral streams: A framework for understanding aspects of the functional anatomy of language,2004,Cognition,92,01-Feb,,67,99,32,1623,10.1016/j.cognition.2003.10.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1442351125&doi=10.1016%2fj.cognition.2003.10.011&partnerID=40&md5=2f741156bd87757291498b6ff08546e2,"Despite intensive work on language-brain relations, and a fairly impressive accumulation of knowledge over the last several decades, there has been little progress in developing large-scale models of the functional anatomy of language that integrate neuropsychological, neuroimaging, and psycholinguistic data. Drawing on relatively recent developments in the cortical organization of vision, and on data from a variety of sources, we propose a new framework for understanding aspects of the functional anatomy of language which moves towards remedying this situation. The framework posits that early cortical stages of speech perception involve auditory fields in the superior temporal gyrus bilaterally (although asymmetrically). This cortical processing system then diverges into two broad processing streams, a ventral stream, which is involved in mapping sound onto meaning, and a dorsal stream, which is involved in mapping sound onto articulatory-based representations. The ventral stream projects ventro-laterally toward inferior posterior temporal cortex (posterior middle temporal gyrus) which serves as an interface between sound-based representations of speech in the superior temporal gyrus (again bilaterally) and widely distributed conceptual representations. The dorsal stream projects dorso-posteriorly involving a region in the posterior Sylvian fissure at the parietal-temporal boundary (area Spt), and ultimately projecting to frontal regions. This network provides a mechanism for the development and maintenance of ""parity"" between auditory and motor representations of speech. Although the proposed dorsal stream represents a very tight connection between processes involved in speech perception and speech production, it does not appear to be a critical component of the speech perception process under normal (ecologically natural) listening conditions, that is, when speech input is mapped onto a conceptual representation. We also propose some degree of bi-directionality in both the dorsal and ventral pathways. We discuss some recent empirical tests of this framework that utilize a range of methods. We also show how damage to different components of this framework can account for the major symptom clusters of the fluent aphasias, and discuss some recent evidence concerning how sentence-level processing might be integrated into the framework. © 2004 Elsevier B.V. All rights reserved.",15037127,Article,Final,,Scopus,2-s2.0-1442351125
Tokumasu K.; Fujino A.; Naganuma H.; Hoshino I.; Arai M.,"Tokumasu, Koji (7004438151); Fujino, Akito (7006146667); Naganuma, Hideaki (7102453132); Hoshino, Isao (7004364741); Arai, Motohiro (55536238800)",7004438151; 7006146667; 7102453132; 7004364741; 55536238800,Initial symptoms and retrospective evaluation of prognosis in Meniere's disease,1996,"Acta Oto-Laryngologica, Supplement",,524,,43,49,6,38,10.3109/00016489609124348,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029692037&doi=10.3109%2f00016489609124348&partnerID=40&md5=36621e42e4da66aab7e0446d0cf5568f,"Clinical studies on an initial symptom and a long-term course of vertigo and hearing impairment and retrospective evaluation of the prognosis were performed in Meniere's disease. One hundred and fifty-one patients (67 males and 84 females) with Meniere's disease were treated in the Neuro-otological clinic, Kitasato University Hospital from 1990 to 1995. Ages ranged from 17 to 77 years (mean 47.3 years) at the onset of the disease when the first vertigo attack occurred. There were 106 (70.1%) in their 30s, 40s and 50s, and 28 (18.5%) aged 60 years or over. Seventy-eight patients visited the clinic within one year of the onset of the disease, but the mean interval was 4 years and 5 months (the longest was 25 years). The mean duration time for the follow-up studies from the time of their first visit to the hospital was 2 years and 5 months. The bilateral ears were invaded in 19 patients (12.6%) and the mean length of their time course was 9 years and 10 months which is longer than the length in unilateral cases. Several important key points for diagnosis of Meniere's disease were investigated in 28 of the 151 cases who had been followed up successfully over a relatively long time course (the mean follow-up time was 7 years and 3 months). Fluctuated or stational cochlear signs, such as tinnitus, hearing impairment and/or fullness in the ear, had started prior to the onset of the first vertigo attack in 17 (61%) of 28 cases. Vertigo without cochlear sign appearing at the onset and cochlear signs were combined later in six (21%) of the 28 cases. Only five (18%) of the 28 cases had vertigo combined with a cochlear sign simultaneously at the onset of the disease. The affected ear was on the left in 15 cases and on the right in seven of 22 unilateral cases. In six bilateral cases the left ear was the first to be invaded in four out of six cases. The interval between the first and second attacks was over 1 year in six of the 28 cases and over 6 months in 10 of the 28 cases. Nine out of the 28 patients had recurrence of vertigo attacks during the first month and five of the nine had a cluster of attacks in the first month. Our study of 28 patients over a long time course revealed eight patients (28.6%) free from the disease. These patients had no recurrence of vertigo for more than 2 years after their last attack, and sixteen (57.1%) of the 28 patients had no recurrence of vertigo for more than 1 year. However, a long period of relief time of more than 2 years in 11 of the 28 patients and a period of more than I year was noticed in 16 of the 28 patients. Hearing levels at the middle and low frequencies in the firrst hearing test were compared with the last test. The mean of hearing levels changed from 38.1 to 36.2 dB after 2 years and I month in six cases with the right ear affected and from 34.1 to 45.3 dB after 5 years and 3 months in 15 cases with the left ear affected, but in seven cases with bilateral diseased ears the hearing in both ears became worse, from 25.5 to 57.1 dB in the right ear and from 30.5 to 53.6 dB in the left ear during a period of more than 10 years. These clinical findings should be utilized for diagnosis at the onset of Meniere's disease to determine the interval for observation in order to evaluate the efficacy of treatment.",8790762,Article,Final,,Scopus,2-s2.0-0029692037
Cheung S.W.,"Cheung, Steven W. (7202473469)",7202473469,Frequency map variations in squirrel monkey primary auditory cortex,2005,Laryngoscope,115,7,,1136,1144,8,6,10.1097/01.MLG.0000165369.65046.CD,https://www.scopus.com/inward/record.uri?eid=2-s2.0-21844466462&doi=10.1097%2f01.MLG.0000165369.65046.CD&partnerID=40&md5=54be795ef5202d240433b35e9cea2138,"Objective: The goal of this work is to understand the neural basis for cortical representation of hearing in highly vocal primates to gain insights into the substrates for communication. Variation patterns in frequency representation among animals are incorporated into an explanatory model to reconcile heterogeneous observations. Study Design: Prospective. Methods: Thirty-four squirrel monkeys underwent microelectrode mapping experiments in primary auditory cortex (AI) using tone pip stimuli. Characteristic frequency (CF) was extracted from the excitatory frequency receptive field. Frequency maps were reconstructed using Voronoi-Dirichlet tessellation. The spatial locations (rostral vs. caudal) of highest CF isofrequency contours (minimum length 1 mm) and highest CF neuronal clusters on the temporal gyral surface were analyzed. Results: Isofrequency contours at least 1 mm long with CFs greater than 2.9 kHz (75% cases) are accessible on the temporal gyrus. Variability of the highest CF isofrequency contours accessible on the temporal gyrus has an interquartile range from 2.9 to 5.1 (mean 4.3) kHz. The highest CF isofrequency contours are located mainly in rostral AI, whereas the highest CF neuronal clusters flanking fully expressed isofrequency contours are equally distributed in rostral and caudal locations. Conclusions: Squirrel monkey AI frequency map variations are sizeable across animals and small within single animals (interhemispheric comparison). AI frequency map variations, modeled as translations and rotations relative to the lateral sulcus, are independent transfers. Caution must be exercised when interpreting nominal frequency map changes that are attributed to hearing loss and auditory learning effects.",15995498,Article,Final,,Scopus,2-s2.0-21844466462
Smith A.W.; Hatcher J.; Mackenzie I.J.; Thompson S.; Bal I.; Macharia I.; Mugwe P.; Okoth-Olende C.; Oburra H.; Wanjohi Z.,"Smith, Andrew W. (55740319800); Hatcher, Juanita (57197277873); Mackenzie, Ian J. (57196010095); Thompson, Simon (57212595261); Bal, Inderjit (6602211565); Macharia, Isaac (6602209688); Mugwe, Peter (6506123608); Okoth-Olende, Chimmie (6505869353); Oburra, Herbert (6603420905); Wanjohi, Zachary (6506264379)",55740319800; 57197277873; 57196010095; 57212595261; 6602211565; 6602209688; 6506123608; 6505869353; 6603420905; 6506264379,Randomised controlled trial of treatment of chronic suppurative otitis media in Kenyan schoolchildren,1996,Lancet,348,9035,,1128,1133,5,58,10.1016/S0140-6736(96)09388-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10244247781&doi=10.1016%2fS0140-6736%2896%2909388-9&partnerID=40&md5=badeae98724307e50706ed3f3e49e77d,"Background. The outcomes of treatment of chronic otitis media (CSOM) are disappointing and uncertain, especially in developing countries. Because CSOM is the commonest cause of hearing impairment in children in these countries, an effective method of management that can be implemented on a wide scale is needed. We report a randomised, controlled trial of treatment of CSOM among children in Kenya; unaffected schoolchildren were taught to administer the interventions. Methods. We enrolled 524 children with CSOM, aged 5-15 years, from 145 primary schools in Kiambu district of Kenya. The schools were randomly assigned treatments in clusters of five in a ratio of two to dry mopping alone (201 children), two to dry mopping with topical and systemic antibiotics and topical steroids (221 children), and one to no specific treatment (102 children). Schools were matched on factors thought to be related to their socioeconomic status. The primary outcome measures were resolution of otorrhoea and healing of tympanic membranes on otoscopy by 8, 12, and 16 weeks after induction. Absence of perforation was confirmed by tympanometry, and hearing levels were assessed by audiometry. 29 children were withdrawn from the trial because they took non-trial antibiotics. There was no evidence of differences in timing of withdrawals between the groups. Findings. By the 16-week follow-up visit, otorrhoea had resolved in a weighted mean proportion of 51% (95% CI 42-59) of children who received dry mopping with antibiotics, compared with 22% (14-31) of those who received dry mopping alone and 22% (9-35) of controls. Similar differences were recorded by the 8-week and 12-week visits. The weighted mean proportions of children with healing of the tympanic membranes by 16 weeks were 15% (10-21) in the dry-mopping plus antibiotics group, 13% (5-20) in the dry-mopping alone group, and 13% (3-23) in the control group. The proportion with resolution in the dry-mopping alone group did not differ significantly from that in the control group at any time. Hearing thresholds were significantly better for children with no otorrhoea at 16 weeks than for those who had otorrhoea, and were also significantly better for those whose ears had healed than for those with otorrhoea at all times. Interpretation. Our finding that dry mopping plus topical and systemic antibiotics is superior to dry mopping alone contrasts with that of the only previous community-based trial in a developing country, though it accords with findings of most other trials in developed countries. The potential role of antibiotics needs further investigation. Further, similar trials are needed to identify the most cost-effective and appropriate treatment regimen for CSOM in children in developing countries.; 524 children aged 5-15 years with chronic suppurative otitis media (CSOM) were enrolled in a study to determine the effectiveness of different treatment regimens. The subjects were from 145 primary schools in Kenya's Kiambu district. 201 children received dry mopping treatment, 221 received dry mopping with topical and systemic antibiotics and topical steroids, and 102 received no treatment. Participating schools were matched on factors thought to be related to their socioeconomic status. 29 children were withdrawn from the trial for taking non-trial antibiotics, with no evidence observed of differences in the timing of withdrawals between the two groups. At 16 weeks of follow-up, otorrhoea had resolved in a weighted mean proportion of 51% of children who received dry mopping with antibiotics, 22% of children who received dry mopping alone, and 22% of untreated children. Similar differences were observed at 8 and 12 weeks of follow-up. The weighted mean proportions of children with healing of the tympanic membranes by 16 weeks were 15% in the dry-mopping plus antibiotics group, 13% in the dry-mopping alone group, and 13% in the control group. Hearing thresholds were significantly better for children with no otorrhoea at 16 weeks than for those who had otorrhoea, and were also significantly better for those whose ears had healed than for those with otorrhoea at all times.",8888166,Article,Final,,Scopus,2-s2.0-10244247781
Fallon J.B.; Irvine D.R.F.; Shepherd R.K.,"Fallon, James B. (9435651900); Irvine, Dexter R.F. (7101951078); Shepherd, Robert K. (7202338759)",9435651900; 7101951078; 7202338759,Cochlear implant use following neonatal deafness influences the cochleotopic organization of the primary auditory cortex in cats,2009,Journal of Comparative Neurology,512,1,,101,114,13,93,10.1002/cne.21886,https://www.scopus.com/inward/record.uri?eid=2-s2.0-58249087952&doi=10.1002%2fcne.21886&partnerID=40&md5=e277cdb32f488d09f3740970148311ab,"Electrical stimulation of spiral ganglion neurons in a deafened cochlea, via a cochlear implant, provides a means of investigating the effects of the removal and subsequent restoration of afferent input on the functional organization of the primary auditory cortex (AI). We neonatally deafened 17 cats before the onset of hearing, thereby abolishing virtually all afferent input from the auditory periphery. In seven animals the auditory pathway was chronically reactivated with environmentally derived electrical stimuli presented via a multichannel intracochlear electrode array implanted at 8 weeks of age. Electrical stimulation was provided by a clinical cochlear implant that was used continuously for periods of up to 7 months. In 10 long-term deafened cats and three age-matched normal-hearing controls, an intracochlear electrode array was implanted immediately prior to cortical recording. We recorded from a total of 812 single unit and multiunit clusters in AI of all cats as adults using a combination of single tungsten and multichannel silicon electrode arrays. The absence of afferent activity in the long-term deafened animals had little effect on the basic response properties of AI neurons but resulted in complete loss of the normal cochleotopic organization of AI. This effect was almost completely reversed by chronic reactivation of the auditory pathway via the cochlear implant. We hypothesize that maintenance or reestablishment of a cochleotopically organized AI by activation of a restricted sector of the cochlea, as demonstrated in the present study, contributes to the remarkable clinical performance observed among human patients implanted at a young age. © 2008 Wiley-Liss, Inc.",18972570,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-58249087952
Westerberg B.D.; Lee P.K.; Lukwago L.; Zaramba S.; Bubikere S.; Stewart I.,"Westerberg, Brian D. (7003608113); Lee, Patricia K. (57217503245); Lukwago, Luswa (6504618819); Zaramba, Sam (6506572495); Bubikere, Stanley (40261198300); Stewart, Irwin (57617065100)",7003608113; 57217503245; 6504618819; 6506572495; 40261198300; 57617065100,Cross-sectional survey of hearing impairment and ear disease in uganda,2008,Journal of Otolaryngology - Head and Neck Surgery,37,6,,753,758,5,28,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-64349120840&partnerID=40&md5=92e11a57538d94dd983114b5c2823a3d,"OBJECTIVE: To determine the prevalence and causes of disabling hearing loss in adults and children in Uganda. STUDY DESIGN: Cross-sectional survey of ear disease and hearing impairment. SETTING: A random cluster sample design of the population from the Masindi district of Uganda following the World Health Organization (WHO) guidelines, using a modified version of the WHO Ear Disease Survey Protocol. MAIN OUTCOME MEASURE: The prevalence of disabling hearing impairment using the WHO definitions (excluding 0.5 kHz owing to high background noise levels). RESULTS: In the study, 6041 participants were enrolled and underwent audiometric evaluation and an ear examination. The prevalence of disabling hearing impairment was 11.7% in adults and 10.2% in children. A further 2.3% of children in whom thresholds could not be measured were deemed to have significant hearing loss based on screening questions and/or sound-field stimuli. Correctable causes such as dry perforations, cerumen impaction, and chronic suppurative otitis media resulted in disabling hearing loss in 17% of adult subjects and 41% of children. Preventable hearing loss, such as meningitis and noise-induced hearing loss, was present in a further significant percentage of subjects. CONCLUSIONS: Ear disease and hearing impairment were found to be important health problems in the Ugandan population. Preventable ear disease is a major cause of hearing loss in the population. It is hoped that the findings of this study will draw attention to the problem in Uganda and will lead to proper allocation of resources for the prevention and treatment of hearing loss and ear disease.",19128699,Article,Final,,Scopus,2-s2.0-64349120840
Harding G.W.; Bohne B.A.,"Harding, Gary W. (7201960545); Bohne, Barbara A. (7005173566)",7201960545; 7005173566,Noise-induced hair-cell loss and total exposure energy: Analysis of a large data set,2004,Journal of the Acoustical Society of America,115,5 I,,2207,2220,13,31,10.1121/1.1689961,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2142662221&doi=10.1121%2f1.1689961&partnerID=40&md5=c1689f69470c95d7925e0fbd1556cea0,"The relation between total noise-exposure energy, recovery time, or rest during the exposure and amount of hair-cell loss was examined in 416 chinchillas. The exposures were octave bands of noise (OBN) with a center frequency of either 4 kHz at 47-108 dB sound pressure level (SPL) for 0.5 h to 36 d, or 0.5 kHz at 65-128 dB SPL for 3.5 h to 432 d. Recovery times varied from 0 to 365 d. With both OBNs, some animals were exposed on interrupted schedules. Hair-cell loss as a function of age in nonexposed animals (N = 117) was used to correct for sensory-cell loss due to aging. For both OBNs, the ears (N = 607) were separated into three subsets to characterize the primary hair-cell loss from noise and the secondary post-exposure loss and to determine if rest during the exposure decreased loss. Cluster and regression analyses were performed on data from the basal and apical halves of the cochlea to determine the specific rates for these three factors. It was found that: (1) when the OBN was above a critical level, there was no relation between total energy and hair-cell loss; (2) below a critical level, there were highly significant log-linear relations between total energy and hair-cell loss, but not at rates predicted by the equal-energy hypothesis; (3) rest periods during either OBN exposure reduced hair-cell loss; more so for the 4 kHz OBN than the 0.5 kHz OBN; (4) except for the highest exposure levels, the majority of outer hair cell loss from the 4 kHz OBN occurred after the exposure had terminated, while that from the 0.5 kHz OBN occurred during the exposure; and (5) a majority of the inner hair cell loss from both OBNs occurred post-exposure. © 2004 Acoustical Society of America.",15139632,Conference paper,Final,,Scopus,2-s2.0-2142662221
Lang H.; Schulte B.A.; Goddard J.C.; Hedrick M.; Schulte J.B.; Wei L.; Schmiedt R.A.,"Lang, Hainan (7402486012); Schulte, Bradley A. (7102826478); Goddard, John C. (8399464200); Hedrick, Michelle (24080257500); Schulte, Jason B. (55983969900); Wei, Ling (13008588400); Schmiedt, Richard A. (7003429369)",7402486012; 7102826478; 8399464200; 24080257500; 55983969900; 13008588400; 7003429369,Transplantation of mouse embryonic stem cells into the cochlea of an auditory-neuropathy animal model: Effects of timing after injury,2008,JARO - Journal of the Association for Research in Otolaryngology,9,2,,225,240,15,73,10.1007/s10162-008-0119-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-44449093933&doi=10.1007%2fs10162-008-0119-x&partnerID=40&md5=340a0132e32baca5cc4358c8c11f8447,"Application of ouabain to the round window membrane of the gerbil selectively induces the death of most spiral ganglion neurons and thus provides an excellent model for investigating the survival and differentiation of embryonic stem cells (ESCs) introduced into the inner ear. In this study, mouse ESCs were pretreated with a neural-induction protocol and transplanted into Rosenthal's canal (RC), perilymph, or endolymph of Mongolian gerbils either 1-3 days (early post-injury transplant group) or 7 days or longer (late post-injury transplant group) after ouabain injury. Overall, ESC survival in RC and perilymphatic spaces was significantly greater in the early post-injury microenvironment as compared to the later post-injury condition. Viable clusters of ESCs within RC and perilymphatic spaces appeared to be associated with neovascularization in the early post-injury group. A small number of ESCs transplanted within RC stained for mature neuronal or glial cell markers. ESCs introduced into perilymph survived in several locations, but most differentiated into glia-like cells. ESCs transplanted into endolymph survived poorly if at all. These experiments demonstrate that there is an optimal time window for engraftment and survival of ESCs that occurs in the early post-injury period. © 2008 Association for Research in Otolaryngology.",18449604,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-44449093933
Dunmade A.O.; Dunmade A.D.; Taiwo O.A.; Tomori A.R.; Komolafe T.M.,"Dunmade, A.O. (57209964275); Dunmade, A.D. (15043966200); Taiwo, O.A. (35801473300); Tomori, A.R. (57337043300); Komolafe, T.M. (57209967696)",57209964275; 15043966200; 35801473300; 57337043300; 57209967696,A Software system for diagnosis and classification of deafness,2009,European Journal of Scientific Research,25,4,,597,605,8,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-65449146749&partnerID=40&md5=4509d1713c50c2d4fc0965df8817f85f,"This work attempts to model the expert reasoning processes of an Ear, Nose and Throat surgeon (otorhinolaryngologist) in his everyday work of diagnosing the level of deafness in his patients, via the use of the Pure Tone Audiometry (PTA) test. The coding is done using the Visual Prolog language. Data obtained from five patients is used to test the software. © EuroJournals Publishing, Inc. 2009.",,Article,Final,,Scopus,2-s2.0-65449146749
Reed C.M.; Delhorne L.A.,"Reed, Charlotte M. (56686615400); Delhorne, Lorraine A. (6603497781)",56686615400; 6603497781,Reception of environmental sounds through cochlear implants,2005,Ear and Hearing,26,1,,48,61,13,37,10.1097/00003446-200502000-00005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-13444278830&doi=10.1097%2f00003446-200502000-00005&partnerID=40&md5=8848e0e2c24c083124e6911b92c28c55,"Objective: The objective of this study was to measure the performance of persons with cochlear implants on a test of environmental-sound reception. Design: The reception of environmental sounds was studied using a test employing closed sets of 10 sounds in each of four different settings (General Home, Kitchen, Office, and Outside). The participants in the study were 11 subjects with cochlear implants. Identification testing was conducted under each of the four closed sets of stimuli using a one-interval, 10-alternative, forced-choice procedure. The data were summarized in terms of overall percent correct identification scores and information transfer (IT) in bits. Confusion patterns were described using a hierarchical-clustering analysis. In addition, individual performance on the environmental-sound task was related to the ability to recognize isolated words through the cochlear implant alone. Results: Levels of performance were similar across the four stimulus sets. Mean scores across subjects ranged from 45.3% correct (and IT of 1.5 bits) to 93.8% correct (and IT of 3.1 bits). Performance on the environmental-sound identification test was roughly related to NU-6 word recognition ability. Specifically, those subjects with word scores greater than 34% correct performed at levels of 80 to 94% on environmental-sound recognition, whereas subjects with word scores less than 34% had greater difficulty on the task. Results of the hierarchical clustering analysis, conducted on two groups of subjects (a high-performing [HP] group and a low-performing [LP] group), indicated that confusions were confined to three or four specific stimuli for the HP subjects and that larger clusters of confused stimuli were observed in the data of the LP group. Signals with distinct temporal-envelope characteristics were easily perceived by all subjects, and confused items tended to share similar overall durations and temporal envelopes. Conclusions: Temporal-envelope cues appear to play a large role in the identification of environmental sounds through cochlear implants. The finer distinctions made by the HP group compared with the LP group may be related to a better ability both to resolve temporal differences and to use gross spectral cues. These findings are qualitatively consistent with patterns of confusions observed in the reception of speech segments through cochlear implants.",15692304,Article,Final,,Scopus,2-s2.0-13444278830
Wake M.; Tobin S.; Cone-Wesson B.; Dahl H.-H.; Gillam L.; McCormick L.; Poulakis Z.; Rickards F.W.; Saunders K.; Ukoumunne O.C.; Williams J.,"Wake, Melissa (7101653914); Tobin, Sherryn (16033458300); Cone-Wesson, Barbara (7003878063); Dahl, Hans-Henrik (7101725390); Gillam, Lynn (9942152500); McCormick, Lisa (57196886990); Poulakis, Zeffie (6602408422); Rickards, Field W. (7003382928); Saunders, Kerryn (55732153000); Ukoumunne, Obioha C. (6701555392); Williams, Joanne (7409579087)",7101653914; 16033458300; 7003878063; 7101725390; 9942152500; 57196886990; 6602408422; 7003382928; 55732153000; 6701555392; 7409579087,Slight/mild sensorineural hearing loss in children,2006,Pediatrics,118,5,,1842,1851,9,116,10.1542/peds.2005-3168,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750943514&doi=10.1542%2fpeds.2005-3168&partnerID=40&md5=3007710ae491350a07229b8fcef499da,"OBJECTIVE. The goal was to determine the prevalence and effects of slight/mild bilateral sensorineural hearing loss among children in elementary school. METHODS.A cross-sectional, cluster-sample survey of 6581 children (response: 85%; grade 1: n = 3367; grade 5: n = 3214) in 89 schools in Melbourne, Australia, was performed. Slight/mild bilateral sensorineural hearing loss was defined as a lowfrequency pure-tone average across 0.5, 1, and 2 kHz and/or a high-frequency pure-tone average across 3, 4, and 6 kHz of 16 to 40 dB hearing level in the better ear, with air/bone-conduction gaps of <10 dB. Parents reported children's healthrelated quality of life and behavior. Each child with slight/mild bilateral sensorineural hearing loss, matched to 2 normally hearing children (low-frequency pure-tone average and high-frequency pure-tone average of ≤15 dB hearing level in both ears), completed standardized assessments. Whole-sample comparisons were adjusted for type of school, grade level, and gender, and matched-sample comparisons were adjusted for nonverbal IQ scores. RESULTS. Fifty-five children (0.88%) had slight/mild bilateral sensorineural hearing loss. Children with and without sensorineural hearing loss scored similarly in language (mean: 97.2 vs 99.7), reading (101.1 vs 102.8), behavior (8.4 vs 7.0), and parent- and child-reported child health-related quality of life (77.6 vs 80.0 and 76.1 vs 77.0, respectively), but phonologic short-term memory was poorer (91.0 vs 102.8) in the sensorineural hearing loss group. CONCLUSIONS. The prevalence of slight/mild bilateral sensorineural hearing loss was lower than reported in previous studies. There was no strong evidence that slight/mild bilateral sensorineural hearing loss affects adversely language, reading, behavior, or health-related quality of life in children who are otherwise healthy and of normal intelligence. Copyright © 2006 by the American Academy of Pediatrics.",17079553,Article,Final,,Scopus,2-s2.0-33750943514
Sarro E.C.; Kotak V.C.; Sanes D.H.; Aoki C.,"Sarro, Emma C. (25652110100); Kotak, Vibhakar C. (6701724207); Sanes, Dan H. (7005743550); Aoki, Chiye (7006209038)",25652110100; 6701724207; 7005743550; 7006209038,Hearing loss alters the subcellular distribution of presynaptic GAD and postsynaptic GABAA receptors in the auditory cortex,2008,Cerebral Cortex,18,12,,2855,2867,12,55,10.1093/cercor/bhn044,https://www.scopus.com/inward/record.uri?eid=2-s2.0-56449091441&doi=10.1093%2fcercor%2fbhn044&partnerID=40&md5=fbfb6d11f36ba05a5b47c6a2da1ad517,"We have shown previously that auditory experience regulates the maturation of excitatory synapses in the auditory cortex (ACx). In this study, we used electron microscopic immunocytochemistry to determine whether the heightened excitability of the ACx following neonatal sensorineural hearing loss (SNHL) also involves pre- or postsynaptic alterations of GABAergic synapses. SNHL was induced in gerbils just prior to the onset of hearing (postnatal day 10). At P17, the gamma-aminobutyri acid type A (GABAA) receptor's β2/3-subunit (GABAAβ2/3) clusters residing at plasma membranes in layers 2/3 of ACx was reduced significantly in size (P < 0.05) and number (P < 0.005), whereas the overall number of immunoreactive puncta (intracellular + plasmalemmal) remained unchanged. The reduction of GABA Aβ2/3 was observed along perikaryal plasma membranes of excitatory neurons but not of GABAergic interneurons. This cell-specific change can contribute to the enhanced excitability of SNHL ACx. Presynaptically, GABAergic axon terminals were significantly larger but less numerous and contained 47% greater density of glutamic acid decarboxylase immunoreactivity (P < 0.05). This suggests that GABA synthesis may be upregulated by a retrograde signal arising from lowered levels of postsynaptic GABAAR. Thus, both, the pre- and postsynaptic sides of inhibitory synapses that form upon pyramidal neurons of the ACx are regulated by neonatal auditory experience. © The Author 2008. Published by Oxford University Press. All rights reserved.",18403398,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-56449091441
Beaubien A.R.; Karpinski K.; Ormsby E.,"Beaubien, A.R. (7004041400); Karpinski, K. (6701372295); Ormsby, E. (6603055785)",7004041400; 6701372295; 6603055785,Toxicodynamics and toxicokinetics of amikacin in the guinea pig cochlea,1995,Hearing Research,83,01-Feb,,62,79,17,15,10.1016/0378-5955(94)00192-S,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028958278&doi=10.1016%2f0378-5955%2894%2900192-S&partnerID=40&md5=7d203f3b7303d185e6aa4e02203efe3b,"An extensive overview of the relationship between cochlear toxicity and amikacin blood concentrations in teh guinea pig is provided which should assist in the clinical application of this class of antibiotic. A data set previously used to relate the incidence of amikacin ototoxicity to dosing rates and blood concentrations was re-examined to assess the toxicodynamics of amikacin in terms of decibels of hearing loss across dosing rate, hearing frequency and time following drug exposure. Animals in this data set had received continuously i.v. infused amikacin over an 8-fold range of dosing rates. Preliminary analysis indicated that the data were consistent with a sigmoid relationship between hearing loss (decibels) and area under the amikacin plasma concentration vs time curve cumulated over the entire course of drug administration (cAUC). The sigmoid model was therefore used as the backbone of a far more comprehensive toxicodynamic model which described all the data with a single equation. Testing with this model showed that the cAUC required to produce half-maximum hearing loss (cAUC-1/2) was related to dosing rate (P < 0.01), to hearing frequency (P < 0.00001), and to post-drug interval (P < 0.00001). Maximum hearing loss (difference between upper and lower sigmoid asymptotes) was less than total and was significantly related to frequency (P < 0.00001). No effects could be detected on the sigmoid slope. Further modelling of the significant effects detected by the comprehensive toxicodynamic model was doen to determine if they could be described by simple relationships or by biologically relevant sub-models. Modelling of maximum hearing loss (postulated to represent loss of mainly outer hair cell function) indicated that this parameter was constant at about 61 decibels or 2-12 kHz and linearly decreased with log frequency for frequencies > 12 kHz. Modelling of cAUC-1/2 on frequency indicated that there was a strong inverse linear relationship to log frequency. Modelling of cAUC-1/2 on post-drug interval indicated that delayed ototoxicity continued at progressively slower rates for at least 56 days after drug administration had ceased. Modelling of cAUC-1/2 on dosing rate showed an increased requirement for drug as the dosing rate decreased. However, cAUC-1/2 changed no more than 20% across the range of dosing rates compared to the 8-fold difference in mean steady-state plasma concentrations, suggesting that plasma concentration is not a primary determinant of ototoxicity. A toxicokinetic model was developed which explained the dosing rate effect on cAUC-1/2 very successfully. This model postulated (1) zero order accumulation of drug in the ototoxic pool at a rate directly proportional to steady-state amikacin plasma concentration, (2) first order disappearance kinetics from the ototoxic pool, and (3) that the level of drug accumulation in the ototoxic pool required to produce a given severity of hearing loss is the same for all dosing rates or plasma concentrations. The disappearance half-life from the ototoxic pool calculated from the fit of this toxicokinetic model to the data was about 80 days. Since the sloping portion of the sigmoid relationship for any one frequency covered several octaves of differential sensitivity to drug, it would appear that the slope results principally from row-to-row and to within row differences in drug sensitivity rather than to longitudinal differences. Cluster analysis of standardized hearing loss values (obtained by removing the influence of all significant effects from the residuals to the final toxicodynamic model) about a common sigmoid curve indicated that the hearing loss data falls into 4 main clusters whose means are about 20 dB apart, presumably corresponding to the loss of 0, 1, 2, or 3 rows of outer hair cells. These results show that, for a limited range of dosing exposures, amikacin-induced hearing loss in the guinea pig cochlea is well described as a sigmoid function of cAUC (R2 = 0.71 with statistically significant parameters modelled in), and that sensitivity to drug can be expressed as a complex mathematical function of hearing frequency, dosing rate and post exposure time within an expanded sigmoid model. The estimate of a very long disappearance half-life of drug at the ototoxic pool has important clinical implications. © 1995.",7607992,Article,Final,,Scopus,2-s2.0-0028958278
Hwang J.-H.; Wu C.-W.; Lee C.-W.; Chen J.-H.; Liu T.-C.,"Hwang, Juen-Haur (7403896819); Wu, Chang-Wei (14322580200); Lee, Chia-Wei (56100888600); Chen, Jyh-Horng (13310081700); Liu, Tien-Chen (7405914488)",7403896819; 14322580200; 56100888600; 13310081700; 7405914488,Brain activation in patients with congenital bilateral hearing impairment,2007,NeuroReport,18,14,,1483,1486,3,0,10.1097/WNR.0b013e3282e9a73e,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548062035&doi=10.1097%2fWNR.0b013e3282e9a73e&partnerID=40&md5=47ae58444c86ce385e667945440de690,"Twelve patients with idiopathic, congenital, symmetric, moderate-to-severe sensorineural hearing loss participated in this study. Functional magnetic resonance imaging was performed while speech sounds were presented to each patient monaurally. Notable blood oxygenation level-dependent responses were clustered mainly in the superior temporal gyrus and transverse temporal gyrus of both hemispheres during right and left ear stimulation. In addition, the middle temporal gyrus of the right hemisphere was activated during right ear stimulation. The activation pattern was very similar to that of participants with normal hearing. Thus, as long as peripheral acoustic stimulation has not been totally absent from childhood, the classical activation pattern can be elicited in patients with congenital bilateral hearing impairment. © 2007 Lippincott Williams & Wilkins, Inc.",17712279,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-34548062035
Buller G.; Hoth S.; Suchandt S.,"Buller, G. (56899819000); Hoth, S. (56256772700); Suchandt, S. (57190434612)",56899819000; 56256772700; 57190434612,Expert system for aiding the diagnosis in hearing screening; [Expertensystem zur diagnoseunterstutzung bei horprufungen],2000,Biomedizinische Technik,45,9,,248,254,6,0,10.1515/bmte.2000.45.9.248,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034283180&doi=10.1515%2fbmte.2000.45.9.248&partnerID=40&md5=2a165e24f01a8d4d1e4ea791a8767937,"For expert systems intended to aid diagnosis, a structure with five levels is proposed. These levels are the original area, the parameter and a reduced parameter layer, the classification and the final-decision layer. On the basis of this structures, an expert system was developed specifically for neonatal hearing screening with transitory evoked otoacoustic emissions (TEOAE). In a second step, this system was investigated for its suitability to classify emissions, regardless of patient age. For the comparison measurements in 252 mainly adult patients, some with an acquired hearing impairment, were used. To adapt the pass/fail decision to the extended evaluation criteria, the false classifications from a first run with the new data were used for training. Thereafter, the expert system, working with a wider data basis, classified the new data with a sensitivity that was increased by 4.8 % to 97.2 %, and a 2.0 % improvement in specificity to 95.5 % when classifying new data, These results, together with those of 97.3 % and 94.3 % achieved with exclusively neonatal TEOAE classification, clearly show the advantage of the expert system structures chosen, and document evidence of the practical applicability of the method.; For expert systems intended to aid diagnosis, a structure with five levels is proposed. These levels are the original area, the parameter and a reduced parameter layer, the classification and the final-decision layer. On the basis of this structures, an expert system was developed specifically for neonatal hearing screening with transitory evoked otoacoustic emissions (TEOAE). In a second step, this system was investigated for its suitability to classify emissions, regardless of patient age. For the comparison measurements in 252 mainly adult patients, some with an acquired hearing impairment, were used. To adapt the pass/fail decision to the extended evaluation criteria, the false classifications from a first run with the new data were used for training. Thereafter, the expert system, working with a wider data basis, classified the new data with a sensitivity that was increased by 4.8% to 97.2%, and a 2.0% improvement in specificity to 95.5% when classifying new data. These results, together with those of 97.3% and 94.3% achieved with exclusively neonatal TEOAE classification, clearly show the advantage of the expert system structures chosen, and document evidence of the practical applicability of the method.",11030095,Article,Final,,Scopus,2-s2.0-0034283180
Fransen E.; Topsakal V.; Hendrickx J.-J.; Van Laer L.; Huyghe J.R.; Van Eyken E.; Lemkens N.; Hannula S.; Mäki-Torkko E.; Jensen M.; Demeester K.; Tropitzsch A.; Bonaconsa A.; Mazzoli M.; Espeso A.; Verbruggen K.; Huyghe J.; Huygen P.L.M.; Kunst S.; Manninen M.; Diaz-Lacava A.; Steffens M.; Wienker T.F.; Pyykkö I.; Cremers C.W.R.J.; Kremer H.; Dhooge I.; Stephens D.; Orzan E.; Pfister M.; Bille M.; Parving A.; Sorri M.; Van De Heyning P.; Van Camp G.,"Fransen, Erik (7004158064); Topsakal, Vedat (22137091700); Hendrickx, Jan-Jaap (7007161763); Van Laer, Lut (57194695768); Huyghe, Jeroen R. (23009108400); Van Eyken, Els (22136771700); Lemkens, Nele (6506395126); Hannula, Samuli (21833944000); Mäki-Torkko, Elina (6701471380); Jensen, Mona (23009017200); Demeester, Kelly (22134112300); Tropitzsch, Anke (6603274770); Bonaconsa, Amanda (22133561700); Mazzoli, Manuela (7004316776); Espeso, Angeles (23388861200); Verbruggen, Katia (22137089400); Huyghe, Joke (22134810500); Huygen, Patrick L. M. (7006415660); Kunst, Sylvia (14058316500); Manninen, Minna (58336040600); Diaz-Lacava, Amalia (23008393100); Steffens, Michael (56652442800); Wienker, Thomas F. (7006044822); Pyykkö, Ilmari (35592905500); Cremers, Cor W. R. J. (7103079207); Kremer, Hannie (36014154200); Dhooge, Ingeborg (7003466602); Stephens, Dafydd (55565834700); Orzan, Eva (6602167303); Pfister, Markus (55391491800); Bille, Michael (57110094100); Parving, Agnete (7006350908); Sorri, Martti (7006399253); Van De Heyning, Paul (7005171191); Van Camp, Guy (34573802800)",7004158064; 22137091700; 7007161763; 57194695768; 23009108400; 22136771700; 6506395126; 21833944000; 6701471380; 23009017200; 22134112300; 6603274770; 22133561700; 7004316776; 23388861200; 22137089400; 22134810500; 7006415660; 14058316500; 58336040600; 23008393100; 56652442800; 7006044822; 35592905500; 7103079207; 36014154200; 7003466602; 55565834700; 6602167303; 55391491800; 57110094100; 7006350908; 7006399253; 7005171191; 34573802800,"Occupational noise, smoking, and a high body mass index are risk factors for age-related hearing impairment and moderate alcohol consumption is protective: A European population-based multicenter study",2008,JARO - Journal of the Association for Research in Otolaryngology,9,3,,264,276,12,213,10.1007/s10162-008-0123-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749125930&doi=10.1007%2fs10162-008-0123-1&partnerID=40&md5=de2587a68ea329a453af1fea017c78ad,"A multicenter study was set up to elucidate the environmental and medical risk factors contributing to age-related hearing impairment (ARHI). Nine subsamples, collected by nine audiological centers across Europe, added up to a total of 4,083 subjects between 53 and 67 years. Audiometric data (pure-tone average [PTA]) were collected and the participants filled out a questionnaire on environmental risk factors and medical history. People with a history of disease that could affect hearing were excluded. PTAs were adjusted for age and sex and tested for association with exposure to risk factors. Noise exposure was associated with a significant loss of hearing at high sound frequencies (>1 kHz). Smoking significantly increased high-frequency hearing loss, and the effect was dose-dependent. The effect of smoking remained significant when accounting for cardiovascular disease events. Taller people had better hearing on average with a more pronounced effect at low sound frequencies (<2 kHz). A high body mass index (BMI) correlated with hearing loss across the frequency range tested. Moderate alcohol consumption was inversely correlated with hearing loss. Significant associations were found in the high as well as in the low frequencies. The results suggest that a healthy lifestyle can protect against age-related hearing impairment. © 2008 Association for Research in Otolaryngology.",18543032,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-48749125930
Selvadurai D.K.; Gibbin K.P.,"Selvadurai, D.K. (24597870400); Gibbin, K.P. (7003874500)",24597870400; 7003874500,Case report: Cochlear implantation in Mondini dysplasia with congenital footplate defect - Implications for meningitis risks during implantation,2003,Cochlear Implants International,4,4,,196,200,4,4,10.1002/cii.81,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1342311672&doi=10.1002%2fcii.81&partnerID=40&md5=0853cad5de98fdace80ef896ee54960a,"Following the reports of a cluster of meningitis cases in recently implanted patients the FDA issued cautionary advice relating to the risk of meningitis after cochlear implantation (US Food and Drug Administration, 2002). Similar advice and a national reporting call has been issued by the Department of Health in the UK (Medical Devices Agency, 2002) and universal prophylactic pneumococcal vaccination started. We present a case of bilateral Mondini-type dysplasia associated with a defective stapes footplate and highlight the need for surgical vigilance to reduce the risks of meningitis from undiagnosed anatomical defects. 2003 © Whurr Publishers Ltd.",,Article,Final,,Scopus,2-s2.0-1342311672
Hildebrand M.S.; Tack D.; McMordie S.J.; DeLuca A.; Hur I.A.; Nishimura C.; Huygen P.; Casavant T.L.; Smith R.J.H.,"Hildebrand, Michael S. (34570227500); Tack, Dylan (7006836096); McMordie, Sarah J. (18634875600); DeLuca, Adam (25921876700); Hur, In Ae (56350547200); Nishimura, Carla (7102715745); Huygen, Patrick (7006415660); Casavant, Thomas L. (7005751228); Smith, Richard J. H. (16073972500)",34570227500; 7006836096; 18634875600; 25921876700; 56350547200; 7102715745; 7006415660; 7005751228; 16073972500,Audioprofile-directed screening identifies novel mutations in KCNQ4 causing hearing loss at the DFNA2 locus,2008,Genetics in Medicine,10,11,,797,804,7,39,10.1097/GIM.0b013e318187e106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57449102040&doi=10.1097%2fGIM.0b013e318187e106&partnerID=40&md5=77541893024c7fe040e1086a2c941db2,"Purpose: Gene identification in small families segregating autosomal dominant sensorineural hearing loss presents a significant challenge. To address this challenge, we have developed a machine learning-based software tool, AudioGene v2.0, to prioritize candidate genes for mutation screening based on audioprofiling. Methods: We analyzed audiometric data from a cohort of American families with high-frequency autosomal dominant sensorineural hearing loss. Those families predicted to have a DFNA2 audioprofile by AudioGene v2.0 were screened for mutations in the KCNQ4 gene. Results: Two novel missense mutations and a stop mutation were detected in three American families predicted to have DFNA2-related deafness for a positive predictive value of 6.3%. The false negative rate was 0%. The missense mutations were located in the channel pore region and the stop mutation was in transmembrane domain S5. The latter is the first DFNA2-causing stop mutation reported in KCNQ4. Conclusions: Our data suggest that the N-terminal end of the P-loop is crucial in maintaining the integrity of the KCNQ4 channel pore and AudioGene audioprofile analysis can effectively prioritize genes for mutation screening in small families segregating high-frequency autosomal dominant sensorineural hearing loss. AudioGene software will be made freely available to clinicians and researchers once it has been fully validated.",18941426,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-57449102040
Flynn M.C.; Lunner T.,"Flynn, Mark C. (7201787848); Lunner, Thomas (6602520682)",7201787848; 6602520682,Clinical verification of a hearing aid with Artificial Intelligence,2005,Hearing Journal,58,2,,34,38,4,2,10.1097/01.HJ.0000286116.92711.77,https://www.scopus.com/inward/record.uri?eid=2-s2.0-15944415798&doi=10.1097%2f01.HJ.0000286116.92711.77&partnerID=40&md5=6a8ab441dff3a8c0072823dfa9662428,"In summary, it is crucial to remember that we observed differences between the standard digital hearing instruments and those built on a platform of parallel processing on measures of performance in background noise and complex listening situations. While standard instruments will use single pieces of information in trying to predict the auditory environment, Oticon Syncro uses parallel processing to analyze multiple processing options and select the best solution. The underlying processing strategy is to maximize the speech-to-noise ratio at all times and thereby optimize speech understanding.",,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-15944415798
Noreña A.J.; Tomita M.; Eggermont J.J.,"Noreña, Arnaud J. (6602587116); Tomita, Masahiko (7402962490); Eggermont, Jos J. (7103339415)",6602587116; 7402962490; 7103339415,Neural changes in cat auditory cortex after a transient pure-tone trauma,2003,Journal of Neurophysiology,90,4,,2387,2401,14,138,10.1152/jn.00139.2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0142027018&doi=10.1152%2fjn.00139.2003&partnerID=40&md5=1c30d2289a473336a0e38fb120167ab0,"Here we present the changes in cortical activity occurring within a few hours after a 1-h exposure to a 120-dB SPL pure tone (5 or 6 kHz). The changes in primary auditory cortex of 16 ketamine-anesthetized cats were assessed by recording, with two 8-microelectrode arrays, from the same multiunit clusters before and after the trauma. The exposure resulted in a peripheral threshold increase that stabilized after a few hours to on average 40 dB in the frequency range of 6-32 kHz, as measured by the auditory brain stem response. The trauma induced a shift in characteristic frequency toward lower frequencies, an emergence of new responses, a broadening of the tuning curve, and an increase in the maximum of driven discharges. In addition, the onset response after the trauma was of shorter duration than before the trauma. The results suggest the involvement of both a decrease and an increase in inhibition. They are discussed in terms of changes in central inhibition and its implications for tonotopic map plasticity.",12773493,Article,Final,,Scopus,2-s2.0-0142027018
Hallberg L.R.M.; Johnsson T.; Axelsson A.,"Hallberg, Lillemor R.M. (26643628100); Johnsson, Tommy (7003809486); Axelsson, Alf (7102946846)",26643628100; 7003809486; 7102946846,"Structure of perceived handicap in middle-aged males with noise-induced hearing loss, with and without tinnitus",1993,International Journal of Audiology,32,2,,137,152,15,14,10.3109/00206099309071863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027418885&doi=10.3109%2f00206099309071863&partnerID=40&md5=2666f7d880611ceac1ff4d8c3e037c84,"By using a modified stepwise regression analysis technique, the structure of self-perceived handicap and tinnitus annoyance in 89 males with noise-induced hearing loss was described. Handicap was related to three clusters of variables, reflecting individual, environmental, and socioeconomic aspects, and 60% of the variance in self-perceived handicap was explained by the representatives of these clusters: i.e. 'acceptance of hearing problems' 'social support related to tinnitus' and 'years of education' Tinnitus had no impact of its own on self-perceived handicap and only a modest portion (36% of the variance in tinnitus annoyance was explained by 'sleep disturbance' and 'auditory perceptual difficulties' © 1993 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",8476352,Article,Final,,Scopus,2-s2.0-0027418885
Mak D.; Mackendrick A.; Bulsara M.; Coates H.; Lannigan F.; Lehmann D.; Leidwinger L.; Weeks S.,"Mak, Donna (7006357868); Mackendrick, A. (6507157272); Bulsara, M. (7003936097); Coates, H. (7007040339); Lannigan, F. (7004146347); Lehmann, D. (57204686734); Leidwinger, L. (8083754500); Weeks, S. (8083754800)",7006357868; 6507157272; 7003936097; 7007040339; 7004146347; 57204686734; 8083754500; 8083754800,Outcomes of myringoplasty in Australian aboriginal children and factors associated with success: A prospective case series,2004,Clinical Otolaryngology and Allied Sciences,29,6,,606,611,5,25,10.1111/j.1365-2273.2004.00896.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-9344264082&doi=10.1111%2fj.1365-2273.2004.00896.x&partnerID=40&md5=a789cf0c5c1ae0b3402e687c2bc9f64f,"The objective of this study was to assess the outcomes of myringoplasties in Aboriginal children and to identify factors associated with a successful outcome with the use of prospective case series from primary health care clinics and hospitals in four rural and remote regions of Western Australia. All 58 Aboriginal children, aged 5-15 years, who underwent 78 myringoplasties between 1 January 2000 and 30 June 2001 were included in the study. Complete postoperative (post-op) follow-up was achieved following 78% of myringoplasties. The main outcome measures were (a) success, i.e. an intact tympanic membrane and normal hearing six or more months post-op in the operated ear, (b) closure of the perforation, (c) Post-op hearing improvement. Forty-nine per cent of myringoplasties were successful, 72% resulted in closure or reduction in the size of the perforation and 51% resulted in hearing improvement. After controlling for age, sex, clustering and number of previous myringoplasties, no association was observed between success or hearing improvement and perforation size, or the presence of serous aural discharge at the time of surgery. Myringoplasty resulted in hearing improvement and/ or perforation closure in a significant proportion of children. Thus, primary school-aged Aboriginal children in whom conservative management of chronic suppurative otitis media has been unsuccessful should have access to myringoplasty because of the positive impact on their socialization, language and learning that results from improved hearing.",15533146,Article,Final,,Scopus,2-s2.0-9344264082
Kapteyn T.S.,"Kapteyn, T.S. (7003993286)",7003993286,Ways of rehabilitation of hearing-impaired persons; [Revalidatiemogelijkheden voor slechthorenden],1998,Nederlands Tijdschrift voor Geneeskunde,142,2,,63,67,4,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032501756&partnerID=40&md5=24ca8fde91287ba9136348963cda4207,"Hearing impairment is a symptom, not a diagnosis. A number of types of hearing impairment can be distinguished. The self-reported hearing problems cluster around six hearing factors, the most important of which are speech understanding in noise and localisation of a sound source. For these capabilities equivalent functioning of both ears is important. The general practitioner can determine diagnosis and severity of the impairment using rather simple tools. When the cause of the impairment cannot be reduced in a proper way an adaptation of the sound to the impaired ear will be indicated. This can be arranged by either an ENT specialist or a centre for audiology. The selection of a proper hearing aid requires expertise and particular attention for the complaints. It is of the utmost importance that the hearing-impaired person can try out the effects of the hearing aid in daily circumstances for some weeks. If the patient, members of the family or the prescriber are not satisfied with the results, supplementary help is required for example training in communication skills or special devices.",9556995,Review,Final,,Scopus,2-s2.0-0032501756
Arch-Tirado E.; Verduzco-Mendoza A.; Valdés M.M.; Reyes-García C.A.; Alfaro-Rodríguez A.; Sánchez M.D.C.; Martínez-Cruz C.F.; Taboada-Picazo V.,"Arch-Tirado, Emilio (6506357120); Verduzco-Mendoza, Antonio (8299191000); Valdés, Mario Mandujano (53870817800); Reyes-García, Carlos Alberto (6506984520); Alfaro-Rodríguez, Alfonso (6603295548); Sánchez, María Del Carmen (55460738300); Martínez-Cruz, Carlos Fabián (6506580521); Taboada-Picazo, Verónica (8312476500)",6506357120; 8299191000; 53870817800; 6506984520; 6603295548; 55460738300; 6506580521; 8312476500,Cry analisys of deaf and normal hearing zero-to two-year old childrens; [Análisis del llanto en niños hipoacúsicos y normoyentes de 0 a 2 años de edad],2006,Salud Mental,29,6,,31,38,7,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846830014&partnerID=40&md5=cca8c32f4e19fa23923b0bbc4a1305e1,"Infant crying is a complex phenomenon that implies several functions: breathing, action of laryngeal and supra-laryngeal muscles under the control of the neurovegetative systems of the brainstem, and the limbic system, and the association of cortical areas and the cerebellum. Although it is a communication system different to babbling and language, it is related with the future development of phonation. Cry analysis provides information about the neurophysiologic and psychological states of newborns and the identification of perinatal abnormalities. It is necessary to discuss the subject extensively because there are new data on situations such as laringomalacia, congenital hypothyroidism, deafness and sleep apnea that seem to be associated to infantile crying behaviors. Infant cries can be analyzed as behavioral conditions (hunger, anger and pain cries) allows knowing of mother-child relationship or the effect under diverse cultural conditions, such as stress, emotional deprivation or illness. A spectrographic analysis of the cries may identify several characteristics: threshold, latency, duration of phonation, maximum and minimum of the fundamental frequency (F0), occurrence and maximum pitch of shift, gliding, melody, biphonation, bifurcation, noise concentration, quality of the voice, double harmonic break, glottal plosives, vibratos, melody types, F0 stability and inspiratory stridor. To date, it has not been possible to establish alteration patterns. The best studied variables are F0, its harmonics and the duration of each emission; it is accepted that F0 varies between 400 and 600 Hz, during 1.4 ± 0.6 s. Under such approaches, diverse alterations and risk factors have been studied: congenital alterations, malnutrition, sudden death, maternal exposition to drugs, prematurely born babies or perinatal asphyxia and disturbances of the central nervous system. Authors have reported F0 equal or less than 300 Hz in cases of sudden death or with high frequencies, near the 1000 Hz in the Cri du chat syndrome, perinatal asphyxia and other cases who died suddenly. During the cry, there is an increase of intra-abdominal pressure, heart rate and blood pressure, reduction of oxygen saturation, increase of the intra cranial-pressure, beginning of stress reactions, depletion of the energy anf oxygen reserves, such as the found in the Valsalva's maneuver. Every event of prolonged cries implies alteration of the breathing control like a Hering-Breuer reflex. Considering that some authors have proposed early vocalizations are a good predictor of deafness, in a previous paper we reported the characteristics of the cry of 20 deaf neonates. However, we were not able to demonstrate differences when comparing them with normal hearing neonates and infants, using only parametric methods. Still, we decided to go further and investigate the quality of infant cries of deaf neonates and infants. Material and methods. Twenty zero-to two-year old cases were studied; they were deaf children of both sexes; all cases were included in a follow-up program on the Human Communication Department of the National Institute of Perinatology of Mexico and were compared with 20 normal hearing children. We recorded Brain Stem Evoked Auditory Responses (BEAR) and cry recording using a digital Sony recorder during the physical exploration. We analyzed the frequency (Hz) and duration of the espiratory cries, the duration of inspiration between two cry emissions and the characteristics of the spectrogram. Quantitative analysis. The usual estimates of means and standard variation were obtained and they were compared with one way analysis of variance. We organized typologies of frequency by means of cluster techniques (Ward method). The distribution of the duration of the periods of crying and silence was explored with a contingency tables. Qualitative analysis. Two standardized observers visually analyzed all the cries to determine any variation of F0 and of harmonic frequencies. Whenever a variation of F0 was observed, we obtained maximum and minimum frequencies, as well as average duration of each cry emission. The procedure was validated by means of the graphic comparison with a Fourier's analysis. Results. Mean duration of cries in the deaf group was 0.5845 ± 0.6150 s (range 0.08-5.2 s), while in the group of normal hearing cases was 0.5387 ± 0.2631 (range 0.06-1.75 s). From the deaf group, five cases had very prolonged duration of cries, without statistical significance. The mean duration of the inspiration was 0.3962 ± 0.2326, with a range of 0.06 to 1.75 in the deaf group and of 0.4083 ± 0.1854, with a range of 0.21 at 0.96, in the controls, without difference among groups. There was no correlation between the time of espiratory cry and that of the inspiration. Three cry topologies were organized: one of shorter duration (mean 0.30 s), with 111 spectrograms, an intermediate one (mean 0.73) with 85 spectrograms and one of prolonged duration (mean 4.5 s) with spectrograms of three cases. Three topologies of the inspiratory period were obtained: one of short periods (mean 0.33 s), with 171 spectrograms, one of intermediate duration (mean 0.80 s) with 18 spectrograms and one of prolonged duration (mean 1.60 s) with three cases. There were no statistical differences of tipologies between the deaf groups and normal hearing cases. On the qualitative analysis of cries, we came across several variations which are interpreted as abnormalities: vibratos, poor melodic control, loss of fundamental frequencies, harmonic limited production, plosives, gliding, bi phonation, and a loss of intensity at end of cry emissions. These changes were also observed on the control cases, but only in a very limited number. Discussion. Cry spectrogram analysis are non invasive indicators of the neonate's neurophysiologic organization. Although cry duration varies in healthy newborns, the accepted variation for a normal range is 1.1 to 2.8 s, with standard deviations around 0.6 s. Consistent differences have not been demonstrated between risk and control groups. However, abnormal cases such as Down syndrome or severe asphyxia have very short cries, whereas on the Cri du chat syndrome the duration of cries is prolonged. Extended cries imply cardiac and respiratory risks which have been associated with later outcomes as development retardation and sudden death. There are also some questions to solve, such as the regulation and control of cry, starting from breathing mechanisms or from a sensorial afferent, mediated by hearing. The deaf infants are constituted in a study model, considering that the auditory afference is suppressed and the control of the cry is restricted to the breathing environment. In the studied spectrograms, the duration of the cry was within reported normal limits by other authors, inasmuch in the normal hearing control cases as in the deaf, except the dissident cases, but without these reaching statistical significance. Further research of brainstem function is needed for the abnormal cases with prolonged cry periods, since such cries are interpreted as an alteration of the breathing reflexes of Hering-Breuer, which might have a pathological meaning in the sense of the sob's spasm or even more severe risk factors as sleep apnea and even sudden death. The qualitative analysis in the deaf individuals demonstrated a poor quality and unstable character of melodic control, with a smaller number of harmonics. The deaf cases lost the relationship between the fundamental frequencies and their harmonics, mainly because of the participation of supraglottic structures that modulate pitch and due to the poorness of melodic control, either for monotony or due to the impossibility of returning to a normal pattern, following variations such as vibrato, plosives or noise concentration. In the cases of prolonged cries, starting from the third second, the sound intensity tends to diminish and the harmonics are lost, perhaps due to a decrease of the subglottal pressure of phonation. This finding supports the auditory control of crying related to breathing mechanisms. Conclusions. In preliminary terms, by means of the melodic analysis of the spectrograms, differences are demonstrated between the cries of the deaf and of the normal hearing cases. The increase of the complexity of the melody of the cry, or their poverty, are indicative of the neuromuscular function and they may support the evaluation of phonation before language development. The study of the spectrograms of deaf individuals does not constitute an element for the detection or for diagnosis since, to date, estimators of sensibility or of specificity have not been established, but they constitute a support for its integral evaluation, with the possibility of evaluating and of improving therapeutic rehabilitation.",,Article,Final,,Scopus,2-s2.0-33846830014
McCullagh P.; Wang H.; Zheng H.; Lightbody G.; McAllister G.,"McCullagh, Paul (35566862700); Wang, Haiying (55914042800); Zheng, Huiru (8982328500); Lightbody, Gaye (16241903100); McAllister, Gerry (7005046243)",35566862700; 55914042800; 8982328500; 16241903100; 7005046243,A comparison of supervised classification methods for auditory brainstem response determination,2007,Studies in Health Technology and Informatics,129,,,1289,1293,4,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35748960269&partnerID=40&md5=401d5a065a23c967fed2c2f7b26de1c9,"The ABR is commonly used in the Audiology clinic to determine and quantify hearing loss. Its interpretation is subjective, dependent upon the expertise and experience of the clinical scientist. In this study we investigated the role of machine learning for pattern classification in this domain. We extracted features from the ABRs of 85 test subjects (550 waveforms) and compared four complimentary supervised classification methods: Naïve Bayes, Support Vector Machine Multi-Layer Perceptron and KStar. The Abr dataset comprised both high level and near threshold recordings, labeled as 'response' or 'no response' by the human expert. Features were extracted from single averaged recordings to make the classification process straightforward. A best classification accuracy of 83.4% was obtained using Naïve Bayes and five relevant features extracted from time and wavelet domains. Naïve Bayes also achieved the highest specificity (86.3%). The highest sensitivity (93.1%) was obtained with Support Vector Machine-based classification models. In terms of the overall classification accuracy, four classifiers have shown the consistent, relatively high performance, indicating the relevance of selected features and the feasibility of using machine learning and statistical classification models in the analysis of ABR. © 2007 The authors. All rights reserved.",17911922,Conference paper,Final,,Scopus,2-s2.0-35748960269
Reed C.M.; Delhorne L.A.,"Reed, Charlotte M. (56686615400); Delhorne, Lorraine A. (6603497781)",56686615400; 6603497781,The Reception of Environmental Sounds Through Wearable Tactual Aids,2003,Ear and Hearing,24,6,,528,538,10,22,10.1097/01.AUD.0000100207.97243.88,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345599130&doi=10.1097%2f01.AUD.0000100207.97243.88&partnerID=40&md5=143e8689891cebbfa5a141a6fc20039d,"Objective: The objective of this study was to investigate the ability to identify environmental sounds through a wearable tactual aid. Design: A test of the ability to identify environmental sounds was developed, employing closed sets of ten sounds in each of four different settings (General Home, Kitchen, Office, and Outdoors). The participants in the study included a group of three laboratory-trained subjects with normal hearing and a group of three subjects with profound deafness who were experienced users of a tactual device (the Tactaid 7). Identification testing was conducted in each of the four environmental-sound settings using a one-interval, ten-alternative, forced-choice procedure. The laboratory-trained subjects received training with trial-by-trial correct-answer feedback, followed by testing in the absence of feedback using the Tactaid 7 device. The experienced tactual-aid users were tested initially without feedback to establish baseline levels of performance derived from their prior field experience with the Tactaid 7. These subjects then received additional trials in the presence of correct-answer feedback to determine the effects of training on their performance. The data were summarized in terms of overall percent-correct identification scores and information transfer (IT) in bits. Confusion patterns were described using a hierarchical clustering analysis. Results: Post-training results with the laboratory-trained subjects on the Tactaid 7 indicated that performance was similar for the four test environments, with percent-correct scores averaging 65% (and IT of 2.0 bits). For the experienced tactual-aid users, performance was similar across the four environments, averaging 36% correct (and IT of 1.4 bits) for initial testing without feedback. Scores were increased to 60% correct (and IT of 1.9 bits) in the presence of correct-answer feedback. Similar trends were observed in the hierarchical-clustering analysis across both groups of subjects. Within each stimulus set, certain items tended to cluster together, whereas other items tended to appear in single-item clusters. The highly identified stimuli tended to be characterized by unique temporal patterns and confused stimuli seemed to be most similar in terms of their spectral characteristics. Conclusions: Through the multi-channel spectral display of the Tactaid 7 device, subjects were able to identify roughly 2 bits of information in each of four 10-item sets of sounds representative of different environmental settings. Temporal cues appeared to play a larger role in identification of sounds than spectral or intensive cues.",14663352,Article,Final,,Scopus,2-s2.0-0345599130
Alasti F.; Sadeghi A.; Sanati M.H.; Farhadi M.; Stollar E.; Somers T.; Van Camp G.,"Alasti, Fatemeh (23101970700); Sadeghi, Abdorrahim (23988105400); Sanati, Mohammad Hossein (56071497500); Farhadi, Mohammad (6602260143); Stollar, Elliot (6507298042); Somers, Thomas (55612575300); Van Camp, Guy (34573802800)",23101970700; 23988105400; 56071497500; 6602260143; 6507298042; 55612575300; 34573802800,A Mutation in HOXA2 Is Responsible for Autosomal-Recessive Microtia in an Iranian Family,2008,American Journal of Human Genetics,82,4,,982,991,9,78,10.1016/j.ajhg.2008.02.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-41549169516&doi=10.1016%2fj.ajhg.2008.02.015&partnerID=40&md5=3f93eaa7fba2f530ba57ce098aa2d4b0,"Microtia, a congenital deformity manifesting as an abnormally shaped or absent external ear, occurs in one out of 8,000-10,000 births. We ascertained a consanguineous Iranian family segregating with autosomal-recessive bilateral microtia, mixed symmetrical severe to profound hearing impairment, and partial cleft palate. Genome-wide linkage analysis localized the responsible gene to chromosome 7p14.3-p15.3 with a maximum multi-point LOD score of 4.17. In this region, homeobox genes from the HOXA cluster were the most interesting candidates. Subsequent DNA sequence analysis of the HOXA1 and HOXA2 homeobox genes from the candidate region identified an interesting HOXA2 homeodomain variant: a change in a highly conserved amino acid (p.Q186K). The variant was not found in 231 Iranian and 109 Belgian control samples. The critical contribution of HoxA2 for auditory-system development has already been shown in mouse models. We built a homology model to predict the effect of this mutation on the structure and DNA-binding activity of the homeodomain by using the program Modeler 8v2. In the model of the mutant homeodomain, the position of the mutant lysine side chain is consistently farther away from a nearby phosphate group; this altered position results in the loss of a hydrogen bond and affects the DNA-binding activity. © 2008 The American Society of Human Genetics.",18394579,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-41549169516
Von Hehn C.A.A.; Bhattacharjee A.; Kaczmarek L.K.,"Von Hehn, Christian A. A. (8711614200); Bhattacharjee, Arin (7102556884); Kaczmarek, Leonard K. (56724715800)",8711614200; 7102556884; 56724715800,Loss of Kv3.1 Tonotopicity and Alterations in cAMP Response Element-Binding Protein Signaling in Central Auditory Neurons of Hearing Impaired Mice,2004,Journal of Neuroscience,24,8,,1936,1940,4,82,10.1523/JNEUROSCI.4554-03.2004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1442324763&doi=10.1523%2fJNEUROSCI.4554-03.2004&partnerID=40&md5=a05e03a986a7f19d360c6e4f71ad8015,"The promoter for the kv3.1 potassium channel gene is regulated by a Ca 2+ -cAMP responsive element, which binds the transcription factor cAMP response element-binding protein (CREB). Kv3.1 is expressed in a tonotopic gradient within the medial nucleus of the trapezoid body (MNTB) of the auditory brainstem, where Kv3.1 levels are highest at the medial end, which corresponds to high auditory frequencies. We have compared the levels of Kv3.1, CREB, and the phosphorylated form of CREB (pCREB) in a mouse strain that maintains good hearing throughout life, CBA/J (CBA), with one that suffers early cochlear hair cell loss, C57BL/6 (BL/6). A gradient of Kv3.1 immunoreactivity in the MNTB was detected in both young (6 week) and older (8 month) CBA mice. Although no gradient of CREB was detected, pCREB-immunopositive cells were grouped together in distinct clusters along the tonotopic axis. The same pattern of Kv3.1, CREB, and pCREB localization was also found in young BL/6 mice at a time (6 weeks) when hearing is normal. In contrast, at 8 months, when hearing is impaired, the gradient of Kv3.1 was abolished. Moreover, in the older BL/6 mice there was a decrease in CREB expression along the tonotopic axis, and the pattern of pCREB labeling appeared random, with no discrete clusters of pCREB-positive cells along the tonotopic axis. Our findings are consistent with the hypothesis that ongoing activity in auditory brainstem neurons is necessary for the maintenance of Kv3.1 tonotopicity through the CREB pathway.",14985434,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-1442324763
Christensen N.; D'Souza M.; Zhu X.; Frisina R.D.,"Christensen, Nathan (58597847800); D'Souza, Mary (35865056800); Zhu, Xiaoxia (55696601100); Frisina, Robert D. (7003355646)",58597847800; 35865056800; 55696601100; 7003355646,Age-related hearing loss: Aquaporin 4 gene expression changes in the mouse cochlea and auditory midbrain,2009,Brain Research,1253,,,27,34,7,31,10.1016/j.brainres.2008.11.070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-58249127681&doi=10.1016%2fj.brainres.2008.11.070&partnerID=40&md5=59b40383418ac55b2efab4e80d8868ae,"Presbycusis - age-related hearing loss, is the number one communication disorder, and one of the top three chronic medical conditions of our aged population. Aquaporins, particularly aquaporin 4 (Aqp4), are membrane proteins with important roles in water and ion flux across cell membranes, including cells of the inner ear and pathways of the brain used for hearing. To more fully understand the biological bases of presbycusis, 39 CBA mice, a well-studied animal model of presbycusis, underwent non-invasive hearing testing as a function of sound frequency (auditory brainstem response - ABR thresholds, and distortion-product otoacoustic emission - DPOAE magnitudes), and were clustered into four groups based on age and hearing ability. Aqp4 gene expression, as determined by genechip microarray analysis and quantitative real-time PCR, was compared to the young adult control group in the three older groups: middle aged with good hearing, old age with mild presbycusis, and old age with severe presbycusis. Linear regression and ANOVA showed statistically significant changes in Aqp4 gene expression and ABR and DPOAE hearing status in the cochlea and auditory midbrain - inferior colliculus. Down-regulation in the cochlea was seen, and an initial down-, then up-regulation was discovered for the inferior colliculus Aqp4 expression. It is theorized that these changes in Aqp4 gene expression represent an age-related disruption of ion flux in the fluids of the cochlea that are responsible for ionic gradients underlying sound transduction in cochlear hair cells necessary for hearing. In regard to central auditory processing at the level of the auditory midbrain, aquaporin gene expression changes may affect neurotransmitter cycling involving supporting cells, thus impairing complex sound neural processing with age. © 2008 Elsevier B.V. All rights reserved.",19070604,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-58249127681
Seghier M.L.; Boëx C.; Lazeyras F.; Sigrist A.; Pelizzone M.,"Seghier, Mohamed L. (6602537740); Boëx, Colette (6602240083); Lazeyras, François (57203078278); Sigrist, Alain (6602944015); Pelizzone, Marco (7004695610)",6602537740; 6602240083; 57203078278; 6602944015; 7004695610,fMRI evidence for activation of multiple cortical regions in the primary auditory cortex of deaf subjects users of multichannel cochlear implants,2005,Cerebral Cortex,15,1,,40,48,8,22,10.1093/cercor/bhh106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10944243544&doi=10.1093%2fcercor%2fbhh106&partnerID=40&md5=842bb733e8b9b6b76f9198301b4bdd16,"To investigate the activation of the auditory cortex by fMRI, three deaf subjects users of the Ineraid cochlear implant participated in our study. Possible interference between fMRI acquisition and the implanted electrodes was controlled and safe experimental conditions were obtained. For each subject, electrical stimuli were applied on different intracochlear electrodes, in monopolar mode. Stimulation of each electrode was actually producing auditory sensations of different pitches, as demonstrated by psychophysical pitch-ranking measurements in the same subjects. Because deaf subjects did not hear scanner noise, the data were collected in 'silent background' conditions, i.e. as a result of pure auditory sensations. Functional maps showed activation of the primary auditory cortex, predominantly in the left hemisphere. Stimulation of each different intracochlear electrode revealed different clusters of activation. After cluster grouping, at least three regions have been identified in the auditory cortex of each subject, and comparisons with previous architectonic and functional studies are proposed. However, a tonotopic organization could not be clearly identified within each region. These arguments, obtained without interference with unwanted scanner noise, plead in favor of a functional subdivision of the primary auditory cortex into multiple cortical regions in cochlear implant users.",15238446,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-10944243544
Lin C.-Y.; Yang Y.-C.; Guo Y.L.; Wu C.-H.; Chang C.-J.; Wu J.-L.,"Lin, Cheng-Yu (8512304600); Yang, Yi-Ching (7409384845); Guo, Yueliang Leon (7406307492); Wu, Chih-Hsing (15844670300); Chang, Chih-Jen (57154874600); Wu, Jiunn-Liang (57154876800)",8512304600; 7409384845; 7406307492; 15844670300; 57154874600; 57154876800,Prevalence of hearing impairment in an adult population in southern Taiwan,2007,International Journal of Audiology,46,12,,732,737,5,16,10.1080/14992020701448986,https://www.scopus.com/inward/record.uri?eid=2-s2.0-36749056406&doi=10.1080%2f14992020701448986&partnerID=40&md5=1b342f22031bb5cc06c3021f9f380248,"The objective of this study was to estimate the prevalence of hearing impairment in a representative adult population in southern Taiwan and compare the results to those of similar studies in other countries. A stratified systematic cluster sample of 1140 residents, aged ≥20 years, of Tainan City was studied from 2001 to 2003. The test battery included otoscopy, pure-tone audiometry, and a questionnaire covering relevant personal, occupational, and family history. The hearing threshold level (HTL) was defined as the better ear pure-tone average (BPTA) (i.e. the average of hearing thresholds at frequencies 500, 1000, 2000, and 4000 Hz). The prevalence of hearing impairment was 21.4% (95% confidence interval: 19.3-23.7%) at BPTA ≥25 dB HTL. Middle ear disease was a significant risk factor for hearing impairment in addition to age and gender. The overall prevalence of hearing impairment may be higher in Taiwan (17.1%) than in western populations (11.5%), but differences in the definition of hearing impairment severity and variation in sex distribution among studies may account for this higher prevalence. © 2007 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.",18049962,Article,Final,,Scopus,2-s2.0-36749056406
Lanson B.G.; Green J.E.; Roland Jr. J.T.; Lalwani A.K.; Waltzman S.B.,"Lanson, Biana G. (16686741800); Green, Janet E. (35597066400); Roland Jr., J Thomas (7101700375); Lalwani, Anil K. (7006501804); Waltzman, Susan B. (7006482990)",16686741800; 35597066400; 7101700375; 7006501804; 7006482990,Cochlear implantation in children with CHARGE syndrome: Therapeutic decisions and outcomes,2007,Laryngoscope,117,7,,1260,1266,6,54,10.1097/MLG.0b013e31806009c9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34347355596&doi=10.1097%2fMLG.0b013e31806009c9&partnerID=40&md5=85f99c3eef6783d7b88a2787764f6e5a,"OBJECTIVES: Ear anomalies and deafness are associated with CHARGE syndrome, which also presents with a cluster of features including coloboma of the eye, heart defects, atresia of the choanae, developmental retardation, and genitourinary abnormalities. The aim of this study is to explore the viability of cochlear implantation in children with CHARGE syndrome and to assess the outcome. STUDY DESIGN: Retrospective chart review. METHODS: Eleven children presenting with severe to profound sensorineural hearing loss associated with CHARGE syndrome were the subjects of this study. Routine audiometric measurements and the Infant Toddler Meaningful Auditory Integration Scale (IT-MAIS) were performed pre- and postoperatively. In addition, the degree of the subjects' cochlear deformity were measured and correlated to outcome. RESULTS: All patients had varying degrees of ear anomalies, seven patients suffered from coloboma of the eyes, two had heart defects, five exhibited choanal atresia, eleven showed developmental retardation, and six had genitourinary abnormalities. Ten of the children underwent cochlear implantation with complete insertion of the electrode array without complication and were followed over a 3-month to a 7-year period. The eleventh child was not implanted because of severe retardation. All of the implanted children showed varying, but limited degrees, of auditory benefit as measured by routine audiometry and the IT-MAIS. CONCLUSIONS: Careful treatment planning for children with sensorineural hearing loss and CHARGE syndrome can lead to varying, but limited degrees, of auditory benefit with no increase in surgical complications. Although the implant enhanced the children's 'connectivity' to the environment, it did not promote the development of oral language skills in this population. © The American Laryngological, Rhinological & Otological Society, Inc.",17507827,Article,Final,,Scopus,2-s2.0-34347355596
McFerran D.J.; Baguley D.M.,"McFerran, Don J. (6701780722); Baguley, D.M. (7006369497)",6701780722; 7006369497,Acoustic shock,2007,Journal of Laryngology and Otology,121,4,,301,305,4,34,10.1017/S0022215107006111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248172326&doi=10.1017%2fS0022215107006111&partnerID=40&md5=b69ccba0fa3ff582af00e7dc4cb9315e,"Acoustic shock is a recently recognised clinical entity: following an abrupt, intense and unanticipated acoustic stimulus, usually delivered by a telephone handset or headset, some individuals report a symptom cluster that includes otalgia, altered hearing, aural fullness, imbalance, tinnitus, dislike or even fear of loud noises, and anxiety and/or depression. Symptoms start shortly after the triggering acoustic incident and can be short-lived or can last for a considerable time. If persistent, the condition can lead to significant disability. Proposed mechanisms include involvement of the tensor tympani muscle, hyperexcitability of central auditory pathways, and a precursive state of raised anxiety or arousal. A formal treatment programme has not yet been proposed, but the potential utility of modern therapeutic techniques for tinnitus and hyperacusis are considered. Given the large number of UK residents working in telephone call centres, this condition is of considerable clinical importance. © 2007 JLO (1984) Limited.",17306048,Review,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-34248172326
Kentala E.,"Kentala, Erna (41661515000)",41661515000,Characteristics of six otologic diseases involving vertigo,1996,American Journal of Otology,17,6,,883,892,9,66,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029999958&partnerID=40&md5=32c22e15a229bfc38739ab1d4afaad43,"To characterize otologic causes for vertigo, data on 564 patients with the six most common diseases involving vertigo were retrieved from the database of a computer-aided diagnostic system for neurotologic diseases. The diseases were Meniere's disease, vestibular schwannoma, benign paroxysmal positional vertigo, vestibular neuritis, sudden deafness, and traumatic vertigo. The prevalence of tinnitus in the study population was 76%. The most severe forms of vertigo and nausea were found in vestibular neuritis, whereas the most severe case of tinnitus appeared in Meniere's disease. Of the patients with vestibular schwannoma, 49% had had vertigo. A linear discrimination analysis using case history classified 90% of the patients into correct groups. The key questions discriminating between the diseases concerned the frequency and duration of vertigo attacks, the duration of hearing loss and vertigo, and the occurrence of head injury. Making a correct diagnosis during the first office visit can be difficult, especially for sudden deafness, vestibular schwannoma, and Meniere's disease. Neurotologic and audiometric information was of minor value in distinguishing between these six diseases. Vestibular schwannoma had significantly greater asymmetry in electronystagmography and smaller gains in smooth pursuit in comparison with the other diseases. Factorial analysis did not aid the clustering of these diseases.",8915417,Article,Final,,Scopus,2-s2.0-0029999958
Kuk F.; Ludvigsen C.; Paludan-Müller C.,"Kuk, Francis (7004486340); Ludvigsen, Carl (7003839068); Paludan-Müller, Carsten (57194742896)",7004486340; 7003839068; 57194742896,Improving hearing aid performance in noise: Challenges and strategies,2002,Hearing Journal,55,4,,34,46,12,19,10.1097/01.HJ.0000293357.41334.07,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036528739&doi=10.1097%2f01.HJ.0000293357.41334.07&partnerID=40&md5=b657a1e6f24a321d051267b3f18789a8,[No abstract available],,Article,Final,,Scopus,2-s2.0-0036528739
Kamke M.R.; Brown M.; Irvine D.R.F.,"Kamke, Marc R. (9276121300); Brown, Mel (57197409571); Irvine, Dexter R.F. (7101951078)",9276121300; 57197409571; 7101951078,Plasticity in the tonotopic organization of the medial geniculate body in adult cats following restricted unilateral cochlear lesions,2003,Journal of Comparative Neurology,459,4,,355,367,12,59,10.1002/cne.10586,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037433776&doi=10.1002%2fcne.10586&partnerID=40&md5=98a83e8c3d92d83b0b7659cd4a25e8f7,"To investigate subcortical contributions to cortical reorganization, the frequency organization of the ventral nucleus of the medial geniculate body (MGv) in six normal adult cats and in eight cats with restricted unilateral cochlear lesions was investigated using multiunit electrophysiological recording techniques. The tonotopic organization of MGv in the lesioned animals, with severe mid-to-high frequency hearing losses, was investigated 40-186 days following the lesioning procedure. Frequency maps were generated from neural responses to pure tone bursts presented separately to each ear under barbiturate anesthesia. Consideration of the frequency organization in normal animals, and of the apparently normal representation of the ipsilateral (unlesioned) cochlea in lesioned animals, allowed for a detailed specification of the extent of changes observed in MGv. In the lesioned animals it was found that, in the region of MGv in which mid-to-high frequencies are normally represented, there was an ""expanded representation"" of lesion-edge frequencies. Neuron clusters within these regions of enlarged representation that had ""new"" characteristic frequencies displayed response properties (latency, bandwidth) very similar to those in normal animals. Thresholds of these neurons were not consistent with the argument that the changes merely reflect the residue of prelesion responses, suggesting a dynamic process of reorganization. The tonotopic reorganization observed in MGv is similar to that seen in the primary auditory cortex and is more extensive than the reorganization found in the auditory midbrain, suggesting that the auditory thalamus plays an important role in cortical plasticity. © 2003 Wiley-Liss, Inc.",12687704,Article,Final,,Scopus,2-s2.0-0037433776
Ciletti L.; Flamme G.A.,"Ciletti, Lindsay (26532247300); Flamme, Gregory A. (6507905227)",26532247300; 6507905227,Prevalence of hearing impairment by gender and audiometric configuration: Results from the National Health and Nutrition Examination Survey (1999-2004) and the Keokuk County Rural Health Study (1994-1998),2008,Journal of the American Academy of Audiology,19,9,,672,685,13,41,10.3766/jaaa.19.9.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-65349113907&doi=10.3766%2fjaaa.19.9.3&partnerID=40&md5=e5433eafdd4f9025eff5300b17bd2cd3,"Purpose: This study describes the most common audiometric configurations and the prevalence of these configurations among adults (ages 20 to 69) in the noninstitutionalized population of the United States and in a sample of residents of a rural county in Iowa. Research Design: This was a cross-sectional population-based study. Study Sample: Estimates generalizing to the noninstitutionalized population of the United States were based on National Health and Nutrition Examination Survey (NHANES) data collected from 2819 women and 2525 men between 1999 and 2004. Estimates from the rural county were based on Keokuk County Rural Health Study (KCRHS) data collected from 892 women and 750 men between 1994 and 1998. Data Collection and Analysis: Cluster analyses (k-means) were used to divide participants into groups including maximally similar bilateral air conduction audiograms. Separate cluster analyses were conducted for each gender. For NHANES data, prevalence and error estimates were obtained using sample weights intended to provide data generalizing to the noninstitutionalized population of the United States within this age range. Results: The hierarchical structure of audiometric configurations revealed that approximately 25% of women and 50% of men aged 20 to 69 in the noninstitutionalized population of the United States were best described by a configuration consistent with a marked hearing impairment in at least one frequency. Hearing impairments were more common among participants in the KCRHS. Gently sloping configurations of hearing impairment were dominant among women, while configurations featuring a greater slope were dominant among men. There was a greater variety of audiometric configurations in men than women. Conclusions: In addition to their descriptive value, these data can be used to inform future studies of risk factors and progression of hearing loss, and to improve the generalizability of studies involving rehabilitative options for people with hearing impairment.",19418707,Article,Final,,Scopus,2-s2.0-65349113907
Davis R.R.; Newlander J.K.; Ling X.-B.; Cortopassi G.A.; Krieg E.F.; Erway L.C.,"Davis, Rickie R. (7410190276); Newlander, J. Kelly (15723586400); Ling, Xiao-Bing (56272151200); Cortopassi, Gino A. (7004495393); Krieg, Edward F. (7004557052); Erway, Lawrence C. (7004411228)",7410190276; 15723586400; 56272151200; 7004495393; 7004557052; 7004411228,Genetic basis for susceptibility to noise-induced hearing loss in mice,2001,Hearing Research,155,01-Feb,,82,90,8,136,10.1016/S0378-5955(01)00250-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035033104&doi=10.1016%2fS0378-5955%2801%2900250-7&partnerID=40&md5=0983b60c524e478131839d22f31a5eca,"The C57BL/6J (B6) and DBA/2J (D2) inbred strains of mice exhibit an age-related hearing loss (AHL) due to a recessive gene (Ahl) that maps to Chromosome 10. The Ahl gene is also implicated in the susceptibility to noise-induced hearing loss (NIHL). The B6 mice (Ahl/Ahl) are more susceptible to NIHL than the CBA/CaJ (CB) mice (+Ahl). The B6×D2.F1 hybrid mice (Ahl/Ahl) are more susceptible to NIHL than the CB×B6.F1 mice (+/Ahl) [Erway et al., 1996. Hear. Res. 93, 181-187]. These genetic effects implicate the Ahl gene as contributing to NIHL susceptibility. The present study demonstrates segregation for the putative Ahl gene and mapping of such a gene to Chromosome 10, consistent with other independent mapping of Ahl for AHL in 10 strains of mice [Johnson et al., 2000. Genomics 70, 171-180]. The present study was based on a conventional cross between two inbred strains, CB×B6.F1 backcrossed to B6 with segregation for the putative +/Ahl:Ahl/Ahl. These backcross progeny were exposed to 110 dB SPL noise for 8 h. All of the progeny were tested for auditory evoked brainstem responses and analyzed for any significant permanent threshold shift of NIHL. Cluster analyses were used to distinguish the two putative genotypes, the least affected with NIHL (+/Ahl) and most affected with PTS (Ahl/Ahl). Approximately 1/2 of the backcross progeny exhibited PTS, particularly at 16 kHz. These mice were genotyped for two D10Mit markers. Quantitative trait loci analyses (log of the odds=15) indicated association of the genetic factor within a few centiMorgan of the best evidence for Ahl [Johnson et al., 2000. Genomics 70, 171-180]. All of the available evidence supports a role for the Ahl gene in both AHL and NIHL among these strains of mice. Copyright © 2001 Elsevier Science B.V.",11335078,Article,Final,,Scopus,2-s2.0-0035033104
Kates J.M.,"Kates, James M. (7006961166)",7006961166,Classification of background noises for hearing-aid applications,1995,Journal of the Acoustical Society of America,97,1,,461,470,9,44,10.1121/1.412274,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028819020&doi=10.1121%2f1.412274&partnerID=40&md5=db3ce1b59ceae2ca4180ee0bcdacdaec,"A background-noise classification procedure is being developed for hearing-aid applications, wherein the hearing-aid response would be adjusted in response to changes in the noise environment. The classification procedure is based on measuring four signal features giving the fluctuations of the signal envelope and the mean frequency and low- and high-frequency slopes of the average spectrum. A more complicated procedure, based on determining the envelope modulation spectra in auditory critical bands, was also investigated and was found to offer no advantages over the simpler procedure. The accuracy of the classification procedure was determined for eleven everyday background noises under optimal conditions where the training and test noise sequences were different portions of the same short noise recording. A cluster analysis was used to determine the similarities among the feature vectors for the noises, and when the noises are grouped into a reduced number of clusters the noise-classification accuracy using the four features exceeds 90%. © 1995, Acoustical Society of America. All rights reserved.",7860827,Article,Final,,Scopus,2-s2.0-0028819020
Leisenberg M.,"Leisenberg, Manfred (6602407379)",6602407379,Unsupervised neural networks for speech perception with cochlear implant systems for the profoundly deaf,1995,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),930,,,462,470,8,1,10.1007/3-540-59497-3_210,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947440929&doi=10.1007%2f3-540-59497-3_210&partnerID=40&md5=863408942121563d49e3635c58266f80,"Recently we have proposed a new speech processing concept for Cochlear Implant (C O - systems. The concept is based on speaker independent signal representation and a neural net classifier which can be combined with the well known CI- speech- coding- strategies. This paper describes some new simulation results: For every speech input frame a 4- dimensional feature vector has been extracted by employing a relative spectral perceptual linear predictive (RASTA-PLP) technique. To classify the feature vectors into so called “auditory related units (ARU)” we applied the self-organizing Kohonen neural net. The best matching ARU's will directly control the synthesis of a “alphabet” of patient adapted stimulus patterns. Simulation results show that the Kohonen algorithm finds representative clusters in the feature vector space for different net dimensions. A discussion of the results and a overview of present experiments with deaf patients will be given. © 1995, Springer Verlag. All rights reserved.",,Conference paper,Final,,Scopus,2-s2.0-84947440929
Liu C.; Bu X.K.; Xing G.Q.; Zhou L.; Xu X.; Wang D.Y.; Chen Z.B.; Zhou H.; Tian H.Q.; Li X.L.; Lu L.; Zhao X.N.; Li F.L.; Tan C.Q.,"Liu, Cheng (48561247800); Bu, Xing-Kuan (7103052929); Xing, Guang-qian (55767037000); Zhou, Ling (57199017435); Xu, Xia (56168074900); Wang, Deng-yuan (15520332900); Chen, Zhi-bin (55605762653); Zhou, Han (56074286400); Tian, Hui-qin (35207033200); Li, Xiao-lu (7501701782); Lu, Ling (39863315600); Zhao, Xiao-nian (7407576773); Li, Fang-li (55315236400); Tan, Chang-qiang (37001835300)",48561247800; 7103052929; 55767037000; 57199017435; 56168074900; 15520332900; 55605762653; 56074286400; 35207033200; 7501701782; 39863315600; 7407576773; 55315236400; 37001835300,Epidemiologic study on hearing impairment and ear diseases in old people.,2006,Zhonghua er bi yan hou tou jing wai ke za zhi = Chinese journal of otorhinolaryngology head and neck surgery,41,9,,661,664,3,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957697340&partnerID=40&md5=60997c9a536d82d8543f0613faeacbcf,"To investigate the prevalence of hearing impairment and ear diseases in old people and provide scientific data for drawing up the prevention and treatment strategies. Using the probability proportion to size (PPS) method, 1261 people over 60 years were investigated in 40 clusters in Jiangsu Province with the WHO protocol. The prevalence of hearing impairment was 58.1% (the standardized rate: 59.5% in the whole country, 60.9% in Jiangsu province). Degrees of hearing impairment were mild (33.1%), moderate (17.8%), severe (5.9%) and profound (1.3%). The prevalence of hearing disability was 25.0% (the standardized rate: 26.6% in the whole country, 28.1% in Jiangsu province). There were significant difference of the prevalence between male and female, as well as urban and rural, and different ages. The prevalence of the ear diseases was auricle malformation (0.2%), wax (1.7%), otitis externa (0.1%), fungi (0.5%), serous otitis media (1.2%), chronic suppurative otitis media (1.6%), dry perforation of tympanic membrance (2.3%). The causes of hearing impairment were ear diseases (2.9%), non-infectious condition (92.6%), genetic condition (0.3%) and undetermined causes (4.2%). Of which, 31.1% of persons needed hearing aids while 2.3% of persons needed medicine treatment, but 0.9% of persons needed non-urgent surgery and 1.0% of persons needed other treatment. The prevalence of hearing impairment and disability in the old rised obviously than the last investigation in 1987. It was a heavy burden for social development in China. The government and the whole society should take more concern about the problem. The scientific strategies of prevention and treatment were urgently needed and implemented.",17111805,Article,Final,,Scopus,2-s2.0-79957697340
Castañeda-Villa N.; James C.J.,"Castañeda-Villa, N. (16174477800); James, C.J. (7203017474)",16174477800; 7203017474,Objective source selection in Blind Source Separation of AEPs in children with Cochlear Implants.,2007,Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference,,,,6224,6227,3,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903812023&partnerID=40&md5=34669ac3392a5544c4c71a1958ce913b,"Multi-channel Auditory Evoked Potentials (AEPs) are a useful methodology for evaluating the auditory performance of children with Cochlear Implants (CIs). These recordings are generally contaminated, not only with well known physiological artifacts (blinking, muscle) and line noise etc., but also by CI artifact. The CI induces an artifact in the recording at the electrodes in the temporal lobe area (where it is implanted) when specific tones are presented, this artifact in particular makes the detection and analysis of AEPs much more challenging. This paper evaluates the convenience of using Blind Source Separation (BSS) and Independent Component Analysis (ICA) in order to identify the AEPs from ongoing recordings and to isolate the artifact when testing a child with a CI. We propose a new procedure to elicit an objective differentiation between the independent components (ICs) related to the AEPs and CI artifact; two concepts are fundamental in this procedure Mutual Information (MI) and Clustering. Finally, the variability of three BSS/ICA algorithms is assessed; in order to determine which one is more convenient to isolate the respective ICs of interest. Temporal decorrelation based ICA showed the least change in the estimation of both the AEPs and the CI artifact; this has allowed for considerable autonomy in the construction of relevant, consistent clusters.",18003443,Article,Final,,Scopus,2-s2.0-84903812023
Andersson G.; Melin L.; Lindberg P.; Scott B.,"Andersson, Gerhard (7202645907); Melin, Lennart (7004720017); Lindberg, Per (7102352501); Scott, Berit (7403291462)",7202645907; 7004720017; 7102352501; 7403291462,"Dispositional optimism, dysphoria, health, and coping with hearing impairment in elderly adults: Original paper",1995,International Journal of Audiology,34,2,,76,84,8,21,10.3109/00206099509071900,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029155978&doi=10.3109%2f00206099509071900&partnerID=40&md5=aa911868c5d8f3cd800382f12bcfeb52,"Sixty-eight elderly hearing impaired subjects were interviewed and completed self-report measures on hearing disability, dispositional optimism, dysphoria, and general health. The measures used were the Hearing Coping Assessment (HCA), the Hearing Questions (HQ), the Life Orientation Test (LOT), The Beck Depression Inventory (BDI), and a subscale from the Göteborg Quality of Life (GQL). Psychometric analyses of HCA, HQ, LOT, BDI, and GQL revealed high reliability in terms of Cronbach's Alpha and split-half r's. Significant inter-correlations were found between several measures, but not with pure-tone audiometry (0.5,1,2, and 3 kHz). Cluster analysis was used to identify subgroups in the sample. As a result three clusters were identified interpreted as 'high copers', 'copers with moderate psychological and somatic complaints', and 'low copers'. Results from the cluster analyses were confirmed by using two different clustering methods and by between-cluster comparisons on the HQ, which had not been used to obtain the clusters. © 1995 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",8561685,Article,Final,,Scopus,2-s2.0-0029155978
Harrison R.V.; Stanton S.G.; Mount R.J.,"Harrison, Robert V. (7403907290); Stanton, Susan G. (35990773400); Mount, Richard J. (7006132836)",7403907290; 35990773400; 7006132836,Effects of chronic cochlear damage on threshold and frequency tuning of neurons in AI auditory cortex,1995,Acta Oto-Laryngologica,115,S519,,30,35,5,10,10.3109/00016489509121867,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028987749&doi=10.3109%2f00016489509121867&partnerID=40&md5=0cf838db78caf3345d6a3d4d999cb906,"We describe the effects of long-term cochlear lesions on the frequency response properties of AI cortical neurons in the cat. Young animals were treated with amikacin to produce bilateral, basal to mid-turn cochlear lesions. After 12-24 months the response properties of single neurons or small unit clusters in primary auditory cortex were recorded in anesthetized animals. Responses to stimulus frequency and intensity were mapped in detail and frequency rhreshold curves (FTCs)and Q10db values were derived. Subsequent to recording experiments, scanning electron microscopy of the sensory epithelium was used to characterize the degree and extent of the cochlear damage. In normal control animals, Q10de values were, on average, lower than those derived by others from cochlear nerve fibre recordings in the same species. In amikacin-treated animals, deterioration was evident in the threshold and tuning properties of cortical neurons, particularly in those cells whose input originated in damaged cochlear regions. Often, neurons associated with normal cochlear areas (as assessed by scanning microscopy) also had poor frequency tuning compared with controls. As an animal model of sensorineural hearing loss, we consider the cat with long-term cochlear lesions to be more appropriate than animals with acute or short-term pathology. We also suggest that in making physiological-psychophysicdl correlations, neural responses from the central auditory system (e.g. cortex) should perhaps be given more consideration than data derived at the cochlear level. © 1995 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",7610889,Article,Final,,Scopus,2-s2.0-0028987749
Schattner A.; Halperin D.; Wolf D.; Zimhony O.,"Schattner, Ami (35508559100); Halperin, Doron (8230755300); Wolf, Dana (7402650512); Zimhony, Oren (6701362428)",35508559100; 8230755300; 7402650512; 6701362428,Enteroviruses and sudden deafness,2003,CMAJ. Canadian Medical Association Journal,168,11,,1421,1423,2,21,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037865311&partnerID=40&md5=8ff19e43bb55651d363005f0110d2167,"A YOUNG, HEALTHY MAN PRESENTED with sudden severe sensorineural hearing loss and tinnitus. The results of the workup and neuroimaging were normal, as were the auditory brain stem responses. Methylprednisolone pulse therapy was associated with significant hearing improvement within 10 days. A history of a short self-limited febrile illness preceding admission (with headache, photophobia, myalgia and fatigue), a raised serum C-reactive protein level and transient leukopenia suggested an infectious cause. Lumbar puncture revealed a mononuclear pleocytosis of the cerebrospinal fluid, with negative cultures but positive polymerase chain reaction test results for enterovirus, which was later cultured from the patient's stool. The patient's wife and baby had had a similar febrile illness without hearing loss 10 days earlier, and an outbreak of enterovirus meningitis was identified in the area, which was associated with familial clustering and echovirus serotype 4 infection. The varied causes of sudden sensorineural hearing loss, which should include enterovirus, are reviewed here.",12771071,Article,Final,,Scopus,2-s2.0-0037865311
Langereis M.C.; Bosman A.J.; van Olphen A.F.; Smoorenburg G.F.,"Langereis, Margreet C. (6701770777); Bosman, Arjan J. (7005489528); van Olphen, Adriaan F. (6701497038); Smoorenburg, Guido F. (35586603500)",6701770777; 7005489528; 6701497038; 35586603500,Changes in vowel quality in post-lingually deafened cochlear implant users,1997,International Journal of Audiology,36,5,,279,297,18,21,10.3109/00206099709071980,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030870471&doi=10.3109%2f00206099709071980&partnerID=40&md5=b034b99319e5f1701e1c42f5f120d1fa,"The present study addresses the effect of cochlear implantation on vowel production of 20 post-lingually deafened Dutch subjects. All subjects received the Nucleus 22 implant (3 WSP and 17 MSP processors). Speech recordings were made pre-implantation and three and twelve months post-implantation with the implant switched on and off. The first and second formant frequencies were measured for eleven Dutch vowels (monophthongs only) in an h-vowel-t context. Twelve months post-implantation, the results showed an increase in the ranges of the first and second formant frequency covered by the respective vowels when the implant was switched on. The increase in the formant frequency range was most marked for some subjects with a relatively small formant range pre-implantation. Also, at 12 months post-implantation with the implant switched on we found a significant shift of the first and second formant frequency towards the normative, values, Moreover, at this time the results showed significantly increased clustering of the respective vowels, suggesting an improvement in the ability to produce phonological contrasts between vowels. Clustering is defined as the ratio of the between-vowel variance of the first and second formant frequency and the within-vowel variance of three tokens of the same vowel. © 1997, Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",9305524,Article,Final,,Scopus,2-s2.0-0030870471
Massaro D.W.; Light J.,"Massaro, Dominic W. (35515982200); Light, Joanna (7102483085)",35515982200; 7102483085,Using Visible Speech to Train Perception and Production of Speech for Individuals with Hearing Loss,2004,"Journal of Speech, Language, and Hearing Research",47,2,,304,320,16,89,10.1044/1092-4388(2004/025),https://www.scopus.com/inward/record.uri?eid=2-s2.0-2142771706&doi=10.1044%2f1092-4388%282004%2f025%29&partnerID=40&md5=e90f93ec5d5262ee53c717d63601d4dc,"The main goal of this study was to implement a computer-animated talking head, Baldi, as a language tutor for speech perception and production for individuals with hearing loss. Baldi can speak slowly; illustrate articulation by making the skin transparent to reveal the tongue, teeth, and palate; and show supplementary articulatory features, such as vibration of the neck to show voicing and turbulent airflow to show frication. Seven students with hearing loss between the ages of 8 and 13 were trained for 6 hours across 21 weeks on 8 categories of segments (4 voiced vs. voiceless distinctions, 3 consonant cluster distinctions, and 1 fricative vs. affricate distinction). Training included practice at the segment and the word level. Perception and production improved for each of the 7 children. Speech production also generalized to new words not included in the training lessons. Finally, speech production deteriorated somewhat after 6 weeks without training, indicating that the training method rather than some other experience was responsible for the improvement that was found.",15157132,Article,Final,,Scopus,2-s2.0-2142771706
Willott J.F.; Aitkin L.M.; McFadden S.L.,"Willott, James F. (7004900031); Aitkin, Lindsay M. (7005169640); McFadden, Sandra L. (7005942948)",7004900031; 7005169640; 7005942948,Plasticity of auditory cortex associated with sensorineural hearing loss in adult C57BL/6J mice,1993,Journal of Comparative Neurology,329,3,,402,411,9,151,10.1002/cne.903290310,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027409478&doi=10.1002%2fcne.903290310&partnerID=40&md5=411c7f3ce5144ec445456a7aa2545bd7,"The representation of frequency was mapped in the primary auditory cortex (AI) of C57BL/6J (C57) mice during young adulthood (1.5–2 months) when hearing is optimal, and at 3, 6, and 12 months of age, a period during which progressive, high frequency, sensorineural hearing loss occurs in this strain. Maps were also obtained from CBA/CaJ mice which retain good hearing as they age. In AI of young adult C57 mice, and CBA mice, characteristic frequencies (CFs) of multiple‐unit clusters were easily identified with extracellular recordings, and a general tonotopic organization was observed from dorsal (high frequency) to ventral and caudal (low frequency). In individual cases there appeared to be deviations from the above tonotopic organization, despite the fact that inbred mice are genetically invariant. As progressive loss of high frequency sensitivity ensued peripherally, a substantially increased representation of middle frequencies was observed in AI. There was no apparent change in the surface area of the auditory cortex despite the elimination of high frequencies, and virtually the entire auditory cortex became devoted to the middle frequencies (especially 10–13 kHz) for which sensitivity remained high. Similar age‐related changes were not observed in normal‐hearing CBA mice. These findings indicate that plasticity in the representation of frequency in AI is associated with high frequency hearing loss in C57 mice. © 1993 Wiley‐Liss, Inc. Copyright © 1993 Wiley‐Liss, Inc.",8459051,Article,Final,,Scopus,2-s2.0-0027409478
Zhao H.; Dai C.-F.; Liu J.-P.; Wang Z.-M.,"Zhao, Hui (55619309450); Dai, Chun-Fu (26424927000); Liu, Jian-Pin (37076031300); Wang, Zheng-Min (8541265200)",55619309450; 26424927000; 37076031300; 8541265200,The surgical management of facial nerve tumor,2006,Fudan University Journal of Medical Sciences,33,2,,183,186,3,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248557644&partnerID=40&md5=3e34201fb516864e192721620d7ed902,"Purpose To improve the diagnosis and management of facial nerve tumor. Methods Eighteen patients with facial nerve tumor were retrospectively analyzed during 1993-2004. All patients were undergone either CT scan or MRI, or both. The period of follow-up varies from 6 months to 5 years (average 40 months). Facial nerve function was evaluated with House-Brackman (H-B) grading system. Results Totally 14 cases complained of facial paralysis, 9 presented with hearing loss, 2 seeked for medical care due to mass in external auditory canal, and 2 had mass in parotid gland. Image studies revealed mass located along the facial nerve course from the parotid gland to internal auditory meatus. Intraoperative findings showed mass involved in internal auditory meatus to parotid gland. Furthermore, mass involved in multiple segment of facial nerve in 12 cases. In 2 cases tumor was pearl-ball cluster along the facial nerve from the internal auditory canal to parotid gland. Postoperative pathological diagnosis demonstrated 14 Schwannoma, 3 neurinoma and 1 case hemangioma. Seven patients were undergone facial nerve graft, 2 recovered to H-B III and the other 5 reached H-B IV, postoperatively. Facial nerve anastomosis was performed on 1 patient, and postoperative outcome was H-B IV. Two patients underwent tumor resection, while the continuity of facial nerve was preserved; their facial nerve function was H-B II and H-B III, respectively. One patient operated with facial nerve decompression recovered postoperative facial nerve function to H-B I. No facial nerve reconstruction was done on other 7 patients. Conclusions The presentation of facial nerve tumor was various, multiple origins of facial nerve tumor were noted. Postoperative facial nerve function was associated with the surgical procedure and preoperative facial nerve function.",,Article,Final,,Scopus,2-s2.0-34248557644
Leao R.N.; Oieskevich S.; Sun H.; Bautista M.; Fyffe R.E.W.; Walmsley B.,"Leao, Richardson N. (6603722079); Oieskevich, Sharon (6504053587); Sun, Hong (55729326200); Bautista, Melissa (7006592848); Fyffe, Robert E. W. (7004239889); Walmsley, Bruce (7004689358)",6603722079; 6504053587; 55729326200; 7006592848; 7004239889; 7004689358,Differences in Glycinergic mIPSCs in the Auditory Brain Stem of Normal and Congenitally Deaf Neonatal Mice,2004,Journal of Neurophysiology,91,2,,1006,1012,6,41,10.1152/jn.00771.2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0842306345&doi=10.1152%2fjn.00771.2003&partnerID=40&md5=34344fab311cd7241bf9ec7dc66d2c3f,"We have investigated the fundamental properties of central auditory glycinergic synapses in early postnatal development in normal and congenitally deaf (dn/dn) mice. Glycinergic miniature inhibitory postsynaptic currents (mIPSCs) were recorded using patch-clamp methods in neurons from a brain slice preparation of the medial nucleus of the trapezoid body (MNTB), at 12-14 days postnatal age. Our results show a number of significant differences between normal and deaf mice. The frequency of mIPSCs is greater (50%) in deaf versus normal mice. Mean mIPSC amplitude is smaller in deaf mice than in normal mice (mean mIPSC amplitude: deaf, 64 pA; normal, 106 pA). Peak-scaled fluctuation analysis of mIPSCs showed that mean single channel conductance is greater in the deaf mice (deaf, 64 pS; normal, 45 pS). The mean decay time course of mIPSCs is slower in MNTB neurons from deaf mice (mean half-width: deaf, 2.9 ms; normal, 2.3 ms). Light- and electron-microscopic immunolabeling results showed that MNTB; neurons from deaf mice have more (30%) inhibitory synaptic sites (postsynaptic gephyrin clusters) than MNTB neurons in normal mice. Our results demonstrate substantial differences in glycinergic transmission in normal and congenitally deaf mice, supporting a role for activity during development in regulating both synaptic structure (connectivity) and the fundamental (quantal) properties of mIPSCs at central glycinergic synapses.",14561690,Article,Final,,Scopus,2-s2.0-0842306345
Rovers M.M.; Straatman H.; Ingels K.; van der Wilt G.J.; van den Broek P.; Zielhuis G.A.,"Rovers, M.M. (7003571463); Straatman, H. (7003770206); Ingels, K. (7003648348); van der Wilt, G.J. (6701654928); van den Broek, P. (7102569234); Zielhuis, G.A. (7006808137)",7003571463; 7003770206; 7003648348; 6701654928; 7102569234; 7006808137,The effect of ventilation tubes on language development in infants with otitis media with effusion: A randomized trial.,2000,Pediatrics,106,3,,E42,,,95,10.1542/peds.106.3.e42,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034269011&doi=10.1542%2fpeds.106.3.e42&partnerID=40&md5=f9bf4503ef8979c8698bee6582c97841,"OBJECTIVE: To study the effectiveness of ventilation tubes on the language development in infants with persistent otitis media with effusion (OME). All existing studies addressed children 3 years of age or older. Currently, OME is detected and treated with ventilation tubes at a younger age. Because of the critical relationship between age, hearing, and language development, we conducted a study of the effects of ventilation tubes on language development in infants 1 to 2 years old with persistent OME. DESIGN: A multicenter, randomized, controlled trial (embedded in a cohort) with 2 treatment arms: 1) treatment with ventilation tubes (VT group; n = 93); or 2) with a period of watchful waiting (WW group; n = 94). Hearing loss and expressive and comprehensive language were assessed every 6 months, while tympanometry and otoscopy were performed every 3 months. Other factors with potential influence on language development were also included: adenoidectomy, hospital, attending day care, sex, age at randomization, educational level of the mother, upper respiratory infections, and the native country of the parents and older siblings. The trial was designed to allow for the detection of a mean difference in language development of 3 months or more between children allocated to the VT and WW groups. RESULTS: No relevant differences were found in expressive or comprehensive language between the 2 groups after adjustment for educational level of the mother, IQ of the child, and differences at baseline. A principal component analysis showed that in the VT group, the children with frequent complaints improved 1.6 months more in comprehensive language than those with no or some complaints. The children with favorable language stimulation, however, did not improve more than the children with less favorable stimulation. No differences were found for expressive language among the various clusters. The probability to improve >3 months in comprehensive language was.48 (95% confidence interval [CI]:.29-.68) for children with highly educated mothers versus.09 (95% CI:.02-.30) for children whose mothers had a low educational level. In the WW group, these changes were.30 (95% CI:.14-.53) and.14 (95% CI:.04-.35), respectively. The probability to improve >4 months in expressive language was.52 (95% CI:.32-.71) for children with highly educated mothers versus.06 (95% CI:.01-.31) for children whose mothers had a low educational level. In the WW group these changes were.42 (95% CI:.23-.64) and.11 (95% CI:.03-.35), respectively. In addition, there were delays in expressive language in both groups compared with their age expected values. The comprehensive language of the children who were effusion-free during the follow-up (n = 54) improved 1.5 months (95% CI: -.2-3.2) more than that of the children who had persistent effusion during the entire follow-up (n = 28). No differences were found for expressive language development. Disregarding the intervention contrast, improvements in hearing seemed to be related to improvements in language development, especially in verbal comprehension. DISCUSSION: In this study, we used the Reynell, Schlichting, and Lexi tests to study the relation between early persistent OME and language development. These tests are directly related to normal language, widely accepted, and validated. It cannot be ruled out that more specific measures such as auditory perception tests would have produced more differences between groups, but the focus was on general language development. A total of 10 children in the WW group received treatment with ventilation tubes during follow-up. A further 11 children dropped out during the trial. A sensitivity analysis with the 10 children who received ventilation tubes did not change the results, and baseline differences were not found between the 11 children who dropped out and those who completed the trial. CONCLUSIONS: In the total group of infants with persistent OME, ventilation tubes did not h",10969126,Article,Final,,Scopus,2-s2.0-0034269011
Asakage T.,"Asakage, T. (6602133443)",6602133443,A case of CHARGE association. Hearing loss and language development,1994,Otolaryngology - Head and Neck Surgery (Tokyo),66,4,,334,338,4,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028328518&partnerID=40&md5=7a89333d022a744c1ead33eb058c8490,"CHARGE association is a recently described cluster of congenital defects including coloboma, heart disease, atresia choanae, retarded growth and/or retarded development and/or CNS anomalies, genital hypoplasia, ear anomalies and/or deafness. The authors reported a 4-year-old girl with CHARGE association and discussed especially on her hearing loss and language development. ABR and COR revealed a 40-50 dB hearing loss. CT scan showed middle ear anomalies which explained her hearing loss. We suspected developmental retardation of her language was associated with mental retardation.",,Article,Final,,Scopus,2-s2.0-0028328518
Drayton M.; Noben-Trauth K.,"Drayton, Meghan (58262393900); Noben-Trauth, Konrad (6701346970)",58262393900; 6701346970,Mapping quantitative trait loci for hearing loss in Black Swiss mice,2006,Hearing Research,212,01-Feb,,128,139,11,39,10.1016/j.heares.2005.11.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-32844457979&doi=10.1016%2fj.heares.2005.11.006&partnerID=40&md5=21e8fbd7f0ba02afe6071ec438c3a66b,"In common inbred mouse strains, hearing loss is a highly prevalent quantitative trait, which is mainly controlled by the Cdh23753A variant and alleles at numerous other strain-specific loci. Here, we investigated the genetic basis of hearing loss in non-inbred strains. Mice of Swiss Webster, CF-1, NIH Swiss, ICR, and Black Swiss strains exhibited hearing profiles characteristic of progressive, sensorineural hearing impairment. In particular, CF-1, Black Swiss, and NIH Swiss mice showed early-onset hearing impairment, ICR and Swiss Webster mice expressed a delayed-onset hearing loss, and NMRI mice had normal hearing. By quantitative trait locus (QTL) mapping, two significant QTLs were identified underlying hearing loss in Black Swiss mice: one QTL mapped to chromosome (chr) 10 (named ahl5, LOD 8.9, peak association 35-42 cM) and a second QTL localized to chr 18 (ahl6, LOD 3.8, 38-44 cM). Ahl5 and ahl6 account for 61% and 32% of the variation in the backcross, respectively. Cadherin 23 (Cdh23) and protocadherin 15 (Pcdh15), mapping within the 95% confidence interval of ahl5, bear nucleotide polymorphisms in coding exons, but these appear to be unrelated to the hearing phenotype. Haplotype analyses across the Cdh23 locus demonstrated the phylogenetic relationship between Black Swiss and common inbred strains. © 2005 Elsevier B.V. All rights reserved.",16426780,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-32844457979
Béria J.U.; Raymann B.C.W.; Gigante L.P.; Figueiredo A.C.L.; Jotz G.; Roithman R.; Da Costa S.S.; Garcez V.; Scherer C.; Smith A.,"Béria, Jorge Umberto (6701360675); Raymann, Beatriz Carmen Warth (15758244500); Gigante, Luciana Petrucci (6601984130); Figueiredo, Andréia Cristina Leal (15756734300); Jotz, Geraldo (6508357031); Roithman, Renato (22938782700); Da Costa, Sady Selaimen (7005345105); Garcez, Vera (22937556200); Scherer, Caroline (24329714200); Smith, Andrew (55740319800)",6701360675; 15758244500; 6601984130; 15756734300; 6508357031; 22938782700; 7005345105; 22937556200; 24329714200; 55740319800,Hearing impairment and socioeconomic factors: A population-based survey of an urban locality in southern Brazil,2007,Revista Panamericana de Salud Publica/Pan American Journal of Public Health,21,6,,381,387,6,50,10.1590/S1020-49892007000500006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35449007256&doi=10.1590%2fS1020-49892007000500006&partnerID=40&md5=a9c6717754ab9a7cc49ee493ac66060a,"Objective. To provide the first population-based data on deafness and hearing impairment in Brazil. Methods. In 2003, a cross-sectional household survey was conducted of 2 427 persons 4 years old and over. The study population was composed of 1 040 systematically chosen households in 40 randomly selected census tracts (dwelling clusters) in the city of Canoas, which is in the state of Rio Grande do Sul, in southern Brazil. Hearing function was evaluated in all subjects by both pure-tone audiometry and physical examination, using the World Health Organization Ear and Hearing Disorders Survey Protocol and definitions of hearing levels. The socioeconomic data that were gathered included the amount of schooling of all individuals tested and the income of the head of the household. Results. It was found that 26.1% of the population studied showed some level of hearing impairment, and 6.8% (95% confidence interval (CI) = 5.5%-8.1%) were classified in the disabling hearing impairment group. The prevalence of moderate hearing loss was 5.4% (95% CI = 4.4%-6.4%); for severe hearing loss, 1.2% (95% CI = 0.7%-1.7%); and for profound hearing loss, 0.2% (95% CI = 0.03%-0.33%). The groups at higher risk for hearing loss were men (odds ratio (OR) = 1.54; 95% CI = 1.06-2.23); participants 60 years of age and over (OR = 12.55; 95% CI = 8.38-18.79); those with fewer years of formal schooling (OR = 3.92; 95% CI = 2.14-7.16); and those with lower income (OR = 1.56; 95% CI = 1.06-2.27). Conclusions. These results support advocacy by health policy planners and care providers for the prevention of deafness and hearing impairment. The findings could help build awareness in the community, in universities, and in government agencies of the health care needs that hearing problems create.",17761050,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-35449007256
van Weerdenburg M.; Verhoeven L.; van Balkom H.,"van Weerdenburg, Marjolijn (13003016800); Verhoeven, Ludo (6603731251); van Balkom, Hans (6507409907)",13003016800; 6603731251; 6507409907,Towards a typology of specific language impairment,2006,Journal of Child Psychology and Psychiatry and Allied Disciplines,47,2,,176,189,13,49,10.1111/j.1469-7610.2005.01454.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645893195&doi=10.1111%2fj.1469-7610.2005.01454.x&partnerID=40&md5=8a71e9bf2618ef9c7b5728383891dce6,"Background: The population of children with specific language impairments (SLI) is heterogeneous. The present study was conducted to examine this heterogeneity more closely, by identifying and describing subgroups within the population of children with SLI in the Netherlands. Method: A broad battery of language tests and language-related cognitive tests were administered to 147 six-year-old and 136 eight-year-old children with SLI. Results: Factor analyses revealed 4 factors indicating 4 distinctive linguistic domains for both age samples: 1) lexical-semantic abilities, 2) auditory conceptualization, 3) verbal sequential memory and 4) speech production. These empirical findings were further validated by the positive correlations found between the language factors and the judgments of teachers and speech therapists. Finally, a cluster analysis revealed 4 distinct clusters of SLI children for each sample with specific language profiles based on the 4 factors. Results were nearly the same for both age samples. Conclusions: The language problems that emerged from the two samples of children with SLI could be described as falling into four types. Based on these language types, four subgroups of children with SLI could be distinguished, each with a specific profile. Some subgroups had severe problems on one specific type of language problem; others had severe problems in more than one type of language problem when compared to the other subgroups of the same age sample. The different profiles may indicate that a more dynamic approach is needed in intervention, considering the presence of both compensating and restricting factors within each child with SLI. © 2005 Association for Child Psychology and Psychiatry.",16423149,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-33645893195
Marttila T.I.; Karikoski J.O.,"Marttila, Timo I. (6603876400); Karikoski, Jukka O. (6507140818)",6603876400; 6507140818,"Identification of childhood hearing impairment in Uusimaa County, Finland",1996,International Journal of Pediatric Otorhinolaryngology,34,01-Feb,,45,51,6,12,10.1016/0165-5876(95)01238-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030028724&doi=10.1016%2f0165-5876%2895%2901238-9&partnerID=40&md5=f957af5fcc6d2ecceef163779588bbae,"The purpose was to report the identification age of the hard-of-hearing children born between 1 January 1973 and 31 December 1990. The subjects comprised all children (353) fitted with hearing aid in an age-matched target population of 270726 persons in Uusimaa County including Helsinki. The age of identification was studied in three groups: pure tone average (0.5, 1 and 2 kHz) ≥ 30 dB, ≤ 35 dB and ≥ 50 dB HL enabling comparison with the identification ages reported in the literature. In the first group the median identification age was 3.6 years (mean 4.2), in the second 2.9 years (mean 3.8) and in the third 2.1 years (mean 2.8). The first group was identified significantly later than the third one (P = 0.004). The second group differed from the third significantly in detection age as well (P = 0.004). The severity of hearing impairment correlated highly with the detection age (r = -0.69, P < 0.0001). The data clustered at the ages of 1-2.5 years (hearing level 90-120 dB) and at 4-8 years (30-60 dB).",8770672,Article,Final,,Scopus,2-s2.0-0030028724
Huang C.-M.; Huang R.H.,"Huang, Chi-Ming (7406887856); Huang, Rosa H. (7402950638)",7406887856; 7402950638,Ethanol inhibits the sensory responses of cerebellar granule cells in anesthetized cats,2007,Alcoholism: Clinical and Experimental Research,31,2,,336,344,8,17,10.1111/j.1530-0277.2006.00309.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846519379&doi=10.1111%2fj.1530-0277.2006.00309.x&partnerID=40&md5=e4c2b3bfc4e0256fbd3197e0d64f26e4,"Background: Granule cells occupy a strategic position in the transmission of afferent information to the cerebellar cortex. They are also the most abundant type of neurons in the cerebellum. The functions of the cerebellum are thought to be sensitive to acute alcohol intoxication. The effects of acute alcohol intoxication on the in vivo physiology of cerebellar granule cells are, however, not completely known. Methods: We studied chloralose-anesthetized cats at ethanol doses relevant to human drinking (0.3-1.2 g/kg). We recorded the electrophysiological responses of granule cell clusters to auditory and visual stimulation, and simultaneously monitored the concentration of ethanol in the cerebrospinal fluid (CSF). Results: At an intravenous ethanol dose of 0.3 g/kg, CSF ethanol concentration peaked in 10 minutes at 17 mM, equivalent to a blood alcohol concentration (BAC) of about 0.08 g/dL. Ethanol quickly and almost completely abolished both auditory and visual responses from granule cells. Complete or near-complete inhibition lasted 15 to 20 minutes; ∼50% recovery required an additional 15 minutes, and a full recovery yet another 15 minutes. A higher ethanol dose at 1.2 g/kg resulted in a more severe inhibition and required longer time for recovery. The relationship between ethanol dose, CSF ethanol concentration, and granule cell responses was dynamic and nonlinear, critically depending upon the elapsed time. Conclusions: Cerebellar granule cell sensory responses are highly sensitive to ethanol inhibition. A rapid development of acute tolerance appears to be a major factor contributing to the dynamic and nonlinear relationship among ethanol dosage, CSF ethanol concentration, and granule cell responses. It is likely that a generalized de-afferentation of the cerebellum from its mossy fiber afferents, followed by the subsequent development of acute tolerance may play major roles by which alcohol intoxication affects cerebellar functions. Copyright © 2007 by the Research Society on Alcoholism.",17250627,Article,Final,,Scopus,2-s2.0-33846519379
Bondy J.; Bruce I.C.; Dong R.; Becker S.; Haykin S.,"Bondy, Jeff (6701866591); Bruce, Ian C. (55727010900); Dong, Rong (7102338857); Becker, Suzanna (7402398897); Haykin, Simon (7101764513)",6701866591; 55727010900; 7102338857; 7402398897; 7101764513,Modeling intelligibility of hearing-aid compression circuits,2003,"Conference Record of the Asilomar Conference on Signals, Systems and Computers",1,,,720,724,4,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4143149413&partnerID=40&md5=bff09c62b564c042f205e8ea34a45ccd,"The active filtering effect in the inner ear is disrupted with sensorineural hearing impairment. This causes a loss of frequency selectivity and dynamic range. Compression is often used in hearing-aids in an attempt to re-establish the normal dynamic range of the cochlear response. While some studies show increased speech intelligibility with artificial noise sources for compressive hearing-aids, most show little (< 1 dB versus linear aids) or no advantage in competing speech. In this paper we explore a quantitative model to explain the empirical performance of compressive hearing-aids in competing speech. By combining an accurate cochlear model with a model of higher auditory feature analysis based on spectral-temporal clustering of onsets, we provide an explanation for the failure of hearing-aid compression algorithms to increase intelligibility. Our proposed spectral-temporal intelligibility model suggests that increasing intelligibility for a hearing impaired person in competing speech requires both spectral and temporal suppression.",,Conference paper,Final,,Scopus,2-s2.0-4143149413
Seki S.; Eggermont J.J.,"Seki, Satoshi (8141961100); Eggermont, Jos J. (7103339415)",8141961100; 7103339415,Changes in spontaneous firing rate and neural synchrony in cat primary auditory cortex after localized tone-induced hearing loss,2003,Hearing Research,180,01-Feb,,28,38,10,252,10.1016/S0378-5955(03)00074-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038699296&doi=10.1016%2fS0378-5955%2803%2900074-1&partnerID=40&md5=1a1f42e10fcc666a9878141150e22bef,"Increase in spontaneous neural activity after noise-induced hearing loss has frequently been associated with the phenomenon of tinnitus. Eighteen juvenile and adult cats were exposed for 2 h to a 6 kHz tone with an intensity of 115 dB SPL at the cat's head. Seven non-exposed littermates and seven other normal hearing cats were used as age-matched controls. The trauma cats showed localized hearing losses, as assessed by ABR, ranging from less than 20 to 60 dB. The frequency representation in primary auditory cortex was mapped using an eight-electrode array. Single-unit spontaneous activity was recorded for 15 min. Peak cross-correlation coefficients (R) for unit cluster activity recorded on separate electrodes were calculated. We found elevated spontaneous firing rates in regions with reorganization of the tonotopic map compared to the neurons in the non-reorganized cortical regions in the same animals. A second finding was that in these regions the peak cross-correlation coefficients were also increased relative to the non-reorganized parts. A third finding was that exposed animals showed higher spontaneous activity compared to controls regardless of the presence of cortical reorganization. This may be a correlate of tinnitus in the presence of only minor hearing losses. © 2003 Elsevier Science B.V. All rights reserved.",12782350,Article,Final,,Scopus,2-s2.0-0038699296
Tharpe A.M.; Biswas G.; Hall 3rd. J.W.,"Tharpe, A.M. (7003792370); Biswas, G. (57211726890); Hall 3rd., J.W. (35564263700)",7003792370; 57211726890; 35564263700,Development of an expert system for pediatric auditory brainstem response interpretation.,1993,Journal of the American Academy of Audiology,4,3,,163,171,8,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027597844&partnerID=40&md5=14036cb5280d7f958532c9081611b326,"Expert systems are computer programs which incorporate artificial intelligence technology and are created to emulate the decision-making abilities of human experts. The advantage of such systems lies in their ability to capture and model expert problem solving knowledge in a domain and make it available to an unlimited number of consumers in an economic and efficient way. The purpose of this project was to develop an expert system to interpret infant auditory brainstem response data as entered by the user. The resulting system provides diagnostic conclusions regarding hearing status, type of hearing loss, and brainstem function at an accuracy level equal to that of a human expert.",8318707,Article,Final,,Scopus,2-s2.0-0027597844
Wik P.; Engwall O.,"Wik, Preben (26647253800); Engwall, Olov (6506726055)",26647253800; 6506726055,Can visualization of internal articulators support speech perception?,2008,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",,,,2627,2630,3,11,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867227459&partnerID=40&md5=ac643e4c4feeca2485f7c16c9c758fc9,"This paper describes the contribution to speech perception given by animations of intra-oral articulations. 18 subjects were asked to identify the words in acoustically degraded sentences in three different presentation modes: acoustic signal only, audiovisual with a front view of a synthetic face and an audiovisual with both front face view and a side view, where tongue movements were visible by making parts of the cheek transparent. The augmented reality side-view did not help subjects perform better overall than with the front view only, but it seems to have been beneficial for the perception of palatal plosives, liquids and rhotics, especially in clusters. The results indicate that it cannot be expected that intra-oral animations support speech perception in general, but that information on some articulatory features can be extracted. Animations of tongue movements have hence more potential for use in computer-assisted pronunciation and perception training than as a communication aid for the hearing-impaired. Copyright © 2008 ISCA.",,Conference paper,Final,,Scopus,2-s2.0-84867227459
Platt S.R.; Freeman J.; Di Stefani A.; Wieczorek L.; Henley W.,"Platt, Simon R. (7102914165); Freeman, Julia (55472396800); Di Stefani, Alberta (15729028200); Wieczorek, Lara (13610484800); Henley, William (8860721500)",7102914165; 55472396800; 15729028200; 13610484800; 8860721500,Prevalence of unilateral and bilateral deafness in border collies and association with phenotype,2006,Journal of Veterinary Internal Medicine,20,6,,1355,1362,7,47,10.1892/0891-6640(2006)20[1355:POUABD]2.0.CO;2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845711194&doi=10.1892%2f0891-6640%282006%2920%5b1355%3aPOUABD%5d2.0.CO%3b2&partnerID=40&md5=f3df3ba61c8efa09d505df5ed50236c4,"Background: Congenital sensorineural deafness (CSD) occurs in Border Collies, but its prevalence and inheritance are unknown. This study estimated the prevalence of CSD in Border Collies and investigated its association with phenotypic attributes linked to the merle gene, including coat pigmentation and iris color. Hypothesis: Deafness in Border Collies is associated with pigmentation patterns linked to the merle gene. Animals: A total of 2597 Border Collies from the United Kingdom. Methods: A retrospective study of Border Collies tested, during 1994-2002, by using brainstem auditory evoked responses. Associations between deafness and phenotypic attributes were assessed by using generalized logistic regression. Results: The prevalence of CSD in puppies was estimated as 2.8%. The corresponding rates of unilateral and bilateral CSD were 2.3 and 0.5%, respectively. Adjustment for clustering of hearing status by litter reduced the overall prevalence estimate to 1.6%. There was no association between CSD and sex (P = .2). Deaf Border Collies had higher rates of merle coat pigmentation, blue iris pigment, and excess white on the head than normal hearing Border Collies (all P < .001). The odds of deafness were increased by a factor of 14 for Border Collies with deaf dams, relative to the odds for dogs with normal dams (P = .007), after adjustment for phenotypic attributes. Conclusions and Clinical Importance: Associations between CSD and pigmentation patterns linked to the merle gene were demonstrated for Border Collies. Evidence for an inherited component to CSD in Border Collies supports selective breeding from only tested and normal parents to reduce the prevalence of this disease. Copyright © 2006 by the American College of Veterinary Internal Medicine.",17186850,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-33845711194
Strauss D.J.; Corona-Strauss F.I.; Bernarding C.; Reith W.; Latzel M.; Froehlich M.,"Strauss, Daniel J. (7103392351); Corona-Strauss, Farah I. (21741886300); Bernarding, Corinna (35773999800); Reith, Wolfgang (35248921600); Latzel, Matthias (6603457228); Froehlich, Matthias (16021662200)",7103392351; 21741886300; 35773999800; 35248921600; 6603457228; 16021662200,On the cognitive neurodynamics of listening effort: A phase clustering analysis of large-scale neural correlates,2009,"Proceedings of the 31st Annual International Conference of the IEEE Engineering in Medicine and Biology Society: Engineering the Future of Biomedicine, EMBC 2009",,,5333956,2078,2081,3,7,10.1109/IEMBS.2009.5333956,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950982508&doi=10.1109%2fIEMBS.2009.5333956&partnerID=40&md5=c997f1b32ea99adbf03d4237711f2db8,"An increased listening effort represents a major problem in humans with hearing impairment. Neurodiagnostic methods for an objective listening effort estimation could revolutionize auditory rehabilitation. However the cognitive neurodynamics of listening effort is not understood and research related its neural correlates is still in its infancy. In this paper we present a phase clustering analysis of large-scale listening effort correlates in auditory late responses (ALRs). For this we apply the complex wavelet transform as well as tight Gabor Frame (TGF) operators. We show (a) that phase clustering on the unit circle can separate ALR data from auditory paradigms which require a graduated effort for their solution; (b) the application of TGFs for an inverse artificial phase stabilization at the α/θ-border enlarges the endogenously driven listening effort correlates in the reconstructed time-domain waveforms. It is concluded that listening effort correlates can be extracted from ALR sequences using an instantaneous phase clustering analysis, at least by means of the applied experimental pure tone paradigm. ©2009 IEEE.",19964575,Conference paper,Final,,Scopus,2-s2.0-77950982508
Strauss D.J.; Delb W.; Plinkert P.K.,"Strauss, Daniel J. (7103392351); Delb, Wolfgang (55952532200); Plinkert, Peter K. (7006006768)",7103392351; 55952532200; 7006006768,Objective detection of the central auditory processing disorder: A new machine learning approach,2004,IEEE Transactions on Biomedical Engineering,51,7,,1147,1155,8,10,10.1109/TBME.2004.827948,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2942729638&doi=10.1109%2fTBME.2004.827948&partnerID=40&md5=0208fddec6ef21e0b47b36caa93476c3,"The objective detection of binaural interaction is of diagnostic interest for the evaluation of the central auditory processing disorder (CAPD). The β-wave of the binaural interaction component in auditory brainstem responses has been suggested as an objective measure of binaural interaction and has been shown to be of diagnostic value in the CAPD diagnosis. However, a reliable and automated detection of the β-wave capable of clinical use still remains a challenge. We propose a new machine learning approach to the detection of the CAPD that is based on adapted tight frame decompositions which are tailored for support vector machines with radial kernels. Using shift-invariant scale and morphological features of the binaurally evoked brainstem potentials, our approach provides at least comparable results to the β-wave detection in view of the discrimination of subjects being at risk for CAPD and subjects being not at risk for CAPD. Furthermore, as no information from the monaurally potentials is necessary, the measurement cost is reduced by two-thirds compared to the computation of the binaural interaction component. We conclude that a machine learning approach in the form of a hybrid tight frame-support vector classification is effective in the objective detection of the CAPD.",15248531,Article,Final,,Scopus,2-s2.0-2942729638
Gopal K.V.; Kowalski J.,"Gopal, Kamakshi V. (7006101724); Kowalski, Jacek (57197495331)",7006101724; 57197495331,Slope analysis of auditory brainstem responses in children at risk of central auditory processing disorders,1999,Scandinavian Audiology,28,2,,85,90,5,16,10.1080/010503999424806,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033055432&doi=10.1080%2f010503999424806&partnerID=40&md5=7eaa018335a56275e4df4daafc4767f1,"The method of slope vectors was used to quantify Auditory Brainstem Responses (ABR) obtained from nine normal children and nine children at risk for central auditory processing disorders (CAPD) with language impairment, for monaural and binaural stimulation conditions. Slopes thus obtained were subjected to K-Means Cluster Analysis. Distinction between the two groups was obtained only for binaural stimulation conditions, wherein all normal children were grouped under cluster 1 with higher slope values and 6 out of 9 CAPD children were grouped under cluster 2 with lower slopes. The results suggest that there may be several subcategories among children who are found to be at risk for CAPD. One of the subcategories may comprise children who exhibit poor ABR morphology, especially during binaural stimulation conditions, which could be due to binaural interference.",10384895,Article,Final,,Scopus,2-s2.0-0033055432
Gillespie P.G.; Hasson T.; Garcia J.A.; Corey D.P.,"Gillespie, P.G. (7005143141); Hasson, T. (7004180850); Garcia, J.A. (56288476000); Corey, D.P. (7102202079)",7005143141; 7004180850; 56288476000; 7102202079,Multiple myosin isozymes and hair-cell function,1996,Cold Spring Harbor Symposia on Quantitative Biology,61,,,309,318,9,10,10.1101/sqb.1996.061.01.034,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030428855&doi=10.1101%2fsqb.1996.061.01.034&partnerID=40&md5=a0a63edb1601add69489ab27596c1288,"The above enumeration does not conclusively summarize identities and functions of all hair-cell myosin isozymes. The RT-PCR screen described by Sole et al. (1994) demonstrated that other myosin isozymes, including myosin Iα and myosin X, are also found in hair-cell-containing epithelia; in addition, primer sets used may have missed other classes; for example, homologous of myosins III and Vb. Additional cataloging of myosins mRNAs from frog sacculus and other auditory and vestibular tissues will no doubt identify additional myosin isozymes expressed in hair cells. Myosin molecules besides myosin VI and VIIa are likely to be essential for hair cells. Genes for several myosin isozymes, including those for myosins Iβ, Iγ, and VIIb, are predicted to map closely to the chromosomal locations of at least one human deafness gene (Hasson et al. 1996). Mutations in their hair-cell myosin isozymes may not manifest as human deafnesses if the isozyme in question is employed for other essential roles. Although distribution of myosin molecules within the auditory and vestibular systems is complicated, we believe that a specific, principal role can be ascribed to each isozyme. Myosin V is not found in hair cells and likely serves the same role in afferent nerve processes that it plays elsewhere in the nervous system. Myosin Ī probably mediates adaptation and may contribute to transport of proteins throughout stereocilia. Myosin VI appears to cross-link actin filaments within the cuticular plate and perhaps between the cuticular plate and stereociliary rootlets; mutations in myosin VI may disrupt these structures and prevent bundle formation. Myosin VIIa may actually hold stereocilia together, mutations in myosin VIIa may therefore cause stereocilia to splay apart, preventing proper assembly into a hair bundle. Myosin Iβ, VI, and VIIa are each at unusually high concentrations in bundles of the most newly formed hair cells, usually at the sensory epithelium's periphery (Gillespie et al. 1993; T. Hasson et al., in prep.); these three isozymes may therefore play additional, more specialized roles during hair-bundle development (Tilney et al. 1992). In the future, we expect that exciting results will come from experiments designed to test these predictions. A key conclusion from hair- cell myosin localization is that these myosin molecules are not necessarily concentrated in regions of high actin density. Despite the similarity of their catalytic domains, each of the myosin isozymes found in hair cells has a distinctive subcellular localization. Furthermore, each hair-cell myosin isozyme appears in multiple specific locations. The ability of myosin molecules to bind to and translocate along actin filaments must therefore be heavily regulated; for dictating location, the affinity of myosin molecules for other proteins may be just as important as their affinity for actin. The nonhomologous tail domains of each class must contribute substantially to this differential localization. A critical goal for the field is therefore identification of hair-cell proteins that bind to myosin molecules, because their localization and abundance relative to each myosin isozyme may establish the final destination of a given myosin molecule. Finally, we wonder why myosin molecules would be employed in capacities that appear, at first consideration, to be entirely structural. In particular, our hypothesized roles for myosins VI and VIIa-maintaining cuticular-plate and bundle structural integrity-do not require force-producing molecules. Proteins that simply cross-link actin or connect actin to specific membrane receptors would seem to function adequately. Because the cell expends considerable energy to transcribe and translate relatively large myosin motor domains instead of smaller actin-binding structures, it seems likely that actin-activated ATPase plays a fundamental role in the behavior of these myosin isozymes. Because myosins VI and VIIa are not simply targeted to distal ends of actin filaments, but are instead found in association with specific actin-filament domains, the role of the motor activity must be relatively subtle. It seems likely that by understanding this paradox, we will understand the precise role of each myosin isozyme in the hair cell.",9246460,Conference paper,Final,,Scopus,2-s2.0-0030428855
Howard R.J.; Clark K.A.; Holton J.M.; Minor Jr. D.L.,"Howard, Rebecca J. (7403673385); Clark, Kimberly A. (7402415504); Holton, James M. (7101772066); Minor Jr., Daniel L. (7003380876)",7403673385; 7402415504; 7101772066; 7003380876,Structural Insight into KCNQ (Kv7) Channel Assembly and Channelopathy,2007,Neuron,53,5,,663,675,12,143,10.1016/j.neuron.2007.02.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847091589&doi=10.1016%2fj.neuron.2007.02.010&partnerID=40&md5=fb98b7162f373cb7c12d55d7f489b999,"Kv7.x (KCNQ) voltage-gated potassium channels form the cardiac and auditory IKs current and the neuronal M-current. The five Kv7 subtypes have distinct assembly preferences encoded by a C-terminal cytoplasmic assembly domain, the A-domain Tail. Here, we present the high-resolution structure of the Kv7.4 A-domain Tail together with biochemical experiments that show that the domain is a self-assembling, parallel, four-stranded coiled coil. Structural analysis and biochemical studies indicate conservation of the coiled coil in all Kv7 subtypes and that a limited set of interactions encode assembly specificity determinants. Kv7 mutations have prominent roles in arrhythmias, deafness, and epilepsy. The structure together with biochemical data indicate that A-domain Tail arrhythmia mutations cluster on the solvent-accessible surface of the subunit interface at a likely site of action for modulatory proteins. Together, the data provide a framework for understanding Kv7 assembly specificity and the molecular basis of a distinct set of Kv7 channelopathies. © 2007 Elsevier Inc. All rights reserved.",17329207,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-33847091589
Hirayama M.; Shitara T.; Okamoto M.; Sano H.,"Hirayama, Masatoshi (57198200515); Shitara, Tetsuya (7005867421); Okamoto, Makito (57040400400); Sano, Hajime (7403159215)",57198200515; 7005867421; 57040400400; 7403159215,Study on the distribution of hearing levels in idiopathic bilateral sensorineural hearing loss,1994,Acta Oto-Laryngologica,114,S514,,73,77,4,1,10.3109/00016489409127565,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028182401&doi=10.3109%2f00016489409127565&partnerID=40&md5=4eadc8855e66083d2c1b77358304891e,"The pattern of aggravation in hearing was investigated in 105 patients who were diagnosed as having idiopathic bilateral sensorineural hearing loss at the Hearing Loss Clinic, Department of Otolaryngology Kitasato University Hospital. Audiograms were taken 1,069 times from the 105 cases over more than 3 years, and were used to obtain the distribution of hearing levels at each test frequency. The clinical course of idiopathic bilateral sensorineural hearing loss was divided into three stages: Stages I, II and III, based on the pattern of aggravation. The pattern of distribution of hearing levels at different stages was compared with each other with reference to peaks or clustering points. Similar peaks were noted at Stage II and Stage III as aggravation proceeded from Stage I. Another peak was noted in the zone of scale-out. © 1994 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",8073891,Article,Final,,Scopus,2-s2.0-0028182401
Kentala E.; Pyykkö I.; Auramo Y.; Juhola M.,"Kentala, E. (41661515000); Pyykkö, I. (35592905500); Auramo, Y. (6602458319); Juhola, M. (55230878300)",41661515000; 35592905500; 6602458319; 55230878300,Computer assisted data collection in vestibular disorders,1995,Acta Oto-Laryngologica,115,S520,,205,206,1,3,10.3109/00016489509125229,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028971883&doi=10.3109%2f00016489509125229&partnerID=40&md5=5ada692fb5e6db1f06c52530d4ca2149,"We have developed an interactive database for vertigo than can be used to assist in the diagnostic procedure and to store the data in a form of a database. The database offers the possibility to split and reunite the collected information in a desired way. The database contains detailed information about patient history, symptoms and findings in neurotological, audiological and imaging tests. The symptoms are classified into three sets of questions: vertigo (including postural instability). hearing loss and tinnitus, and provoking Factors. Confounding disorders are screened. The neurotological tests involve saccades. smooth pursuit, posturography and caloric test. In addition. findings in specified antibody testing. clinical neurotological tests, MRI, brain stem audiometry and electrocochleography are included. The input information can be applied in an expert system ONE for vertigo work-up. The database is user-friendly. Besides diagnostic purposes the database is excellent for research purposes. and combined with the expert system it works as a tutorial guide for medical students. © 1995 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",8749120,Article,Final,,Scopus,2-s2.0-0028971883
Kaartinen V.; Nagy A.; Gonzalez-Gomez I.; Groffen J.; Heisterkamp N.,"Kaartinen, Vesa (7003370070); Nagy, Andre (35420160900); Gonzalez-Gomez, Ignacio (7004571469); Groffen, John (7005004098); Heisterkamp, Nora (7006740132)",7003370070; 35420160900; 7004571469; 7005004098; 7006740132,Vestibular dysgenesis in mice lacking Abr and Bcr Cdc42/RacGAPs,2002,Developmental Dynamics,223,4,,517,525,8,27,10.1002/dvdy.10071,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036203487&doi=10.1002%2fdvdy.10071&partnerID=40&md5=5827e057247e56b59d9154f2d19e6e77,"The inner ear develops from a simple epithelium (otic placode) into the complex structures specialized for balance (vestibule) and sound (cochlea) detection. Abnormal vestibular and cochlear development is associated with many birth defects. During recent years, considerable progress has been made in understanding the molecular bases of these conditions. To determine the biological function of two closely related GTPase activating proteins for the Cdc42/Rac GTPases, Abr and Bcr, we generated a mouse strain deficient in both of these proteins. Double null mutant mice exhibit hyperactivity, persistent circling, and are unable to swim. These phenotypes are typically found in mice with vestibular defects. Indeed, adult double null mutants display abnormal dysmorphic structures of both the saccule and utricle. Moreover, a total loss of otoconia can be seen in the utricle, whereas in the saccule, otoconia are either missing or their number is drastically decreased and they are abnormally large. Interestingly, both the cochlea and semicircular canals are normal and the double null mutant mice are not deaf. These data demonstrate that Abr and Bcr play important complementary roles during vestibular morphogenesis and that a function of Cdc42/RacGAPs and, therefore, that of the small Rho-related GTPases is critically important for balance and motor coordination. © 2002 Wiley-Liss, Inc.",11921339,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-0036203487
Chen F.L.; Liu Y.; Song X.Y.; Hu H.Y.; Xu H.B.; Zhang X.M.; Shi J.H.; Hu J.; Shen Y.; Lu B.; Wang X.C.; Hu R.M.,"Chen, F.L. (55556397800); Liu, Y. (55742307700); Song, X.Y. (55202501900); Hu, H.Y. (56217498100); Xu, H.B. (56144066100); Zhang, X.M. (57207322152); Shi, J.H. (57207270417); Hu, J. (55499411400); Shen, Y. (7404767569); Lu, B. (7401752589); Wang, X.C. (7501864343); Hu, R.M. (7202640826)",55556397800; 55742307700; 55202501900; 56217498100; 56144066100; 57207322152; 57207270417; 55499411400; 7404767569; 7401752589; 7501864343; 7202640826,A novel mitochondrial DNA missense mutation at G3421A in a family with maternally inherited diabetes and deafness,2006,Mutation Research - Fundamental and Molecular Mechanisms of Mutagenesis,602,01-Feb,,26,33,7,9,10.1016/j.mrfmmm.2006.07.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750608223&doi=10.1016%2fj.mrfmmm.2006.07.006&partnerID=40&md5=0c2e2253da3253761e4c6e9259b6de28,"Objective: Mutations in mtDNA are thought to be responsible for the pathogenesis of maternally inherited diabetes. Here, we report a family with maternally inherited diabetes and deafness whose members did not harbour the mtDNA A3243G mutation, the most frequent point mutation in mitochondrial diabetic patients. This study aimed to investigate a possible other mtDNA mutation and its prevalence in type 2 diabetic patients. Methods: Height, body weight, waistline, and hip circumference were measured and serum biochemical marks determined in all members of the family. In addition, a 75 g oral glucose tolerance test and electric listening test were conducted in these members. Genomic DNA was prepared from peripheral leukocytes. Direct sequencing of PCR products was used to detect the mtDNA mutation in this family. The prevalence of mtDNA G3421A nucleotide substitutions was investigated by restriction fragment length polymorphism analysis in 1350 unrelated type 2 diabetic patients recruited by random cluster sampling from the central city area of Shanghai, China. Results: (1) A new missense homoplasmic mutation of mtDNA G3421A was found in a maternally inherited diabetic family and existed neither in 1350 unrelated type 2 diabetic patients nor in 50 non-diabetic individuals. (2) The mode of mutation and diabetes transmission was typical maternal inheritance in this family. (3) All diabetic family members were found to have an onset at 35-42 years of age, accompanied by deafness of varying degrees. Conclusion: mtDNA G3421A (Val39Ile) found in a family with maternally inherited diabetes and deafness is a novel missense mutation. Whether this is a diabetogenic mutation and its effect on mitochondrial function needs to be further studied. © 2006 Elsevier B.V. All rights reserved.",16949108,Article,Final,,Scopus,2-s2.0-33750608223
Lacas-Gervais S.; Guo J.; Strenzke N.; Scarfone E.; Kolpe M.; Jahkel M.; De Camilli P.; Moser T.; Rasband M.N.; Solimena M.,"Lacas-Gervais, Sandra (6508056694); Guo, Jun (56165557300); Strenzke, Nicola (12752910700); Scarfone, Eric (6603521513); Kolpe, Melanie (6507740051); Jahkel, Monika (6601953816); De Camilli, Pietro (7103290939); Moser, Tobias (7007050113); Rasband, Matthew N. (6601917419); Solimena, Michele (7006817892)",6508056694; 56165557300; 12752910700; 6603521513; 6507740051; 6601953816; 7103290939; 7007050113; 6601917419; 7006817892,βIVΣ1 spectrin stabilizes the nodes of Ranvier and axon initial segments,2004,Journal of Cell Biology,166,7,,983,990,7,117,10.1083/jcb.200408007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4644286228&doi=10.1083%2fjcb.200408007&partnerID=40&md5=9d586fdd1c4119429069bb3286c4c5d9,"Saltatory electric conduction requires clustered voltage-gated sodium channels (VGSCs) at axon initial segments (AIS) and nodes of Ranvier (NR). A dense membrane undercoat is present at these sites, which is thought to be key for the focal accumulation of channels. Here, we prove that βIVΣ1 spectrin, the only βIV spectrin with an actin-binding domain, is an essential component of this coat. Specifically, βIVΣ1 coexists with βIVΣ6 at both AIS and NR, being the predominant spectrin at AIS. Removal of βIVΣ1 alone causes the disappearance of the nodal coat, an increased diameter of the NR, and the presence of dilations filled with organelles. Moreover, in myelinated cochlear afferent fibers, VGSC and ankyrin G clusters appear fragmented. These ultrastructural changes can explain the motor and auditory neuropathies present in βIVΣ1 -/- mice and point to the βIVΣ1 spectrin isoform as a master-stabilizing factor of AIS/NR membranes.",15381686,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-4644286228
Fukuda S.; Fukushima K.; Toida N.; Tsukamura K.; Maeda Y.; Kibayashi N.; Nagayasu R.; Orita Y.; Kasai N.; Kataoka Y.; Nishizaki K.,"Fukuda, Shoichiro (7403145829); Fukushima, Kunihiro (7402494929); Toida, Naomi (36792865000); Tsukamura, Keiko (6602467165); Maeda, Yukihide (7402845489); Kibayashi, Namiki (6505996866); Nagayasu, Rie (6506388590); Orita, Yorihisa (7103373415); Kasai, Norio (7102867148); Kataoka, Yuko (7202205249); Nishizaki, Kazunori (7005031400)",7403145829; 7402494929; 36792865000; 6602467165; 7402845489; 6505996866; 6506388590; 7103373415; 7102867148; 7202205249; 7005031400,Monosyllable speech perception of Japanese hearing aid users with prelingual hearing loss: Implications for surgical indication of cochlear implant,2003,International Journal of Pediatric Otorhinolaryngology,67,10,,1061,1067,6,8,10.1016/S0165-5876(03)00187-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10744224348&doi=10.1016%2fS0165-5876%2803%2900187-3&partnerID=40&md5=34e701522cd8710aea9ecf63a1b608bc,"Objective: The monosyllable speech perception ability after years of educational intervention was compared between prelingually deafened pediatric hearing aid users and their cochlear implant counterparts. Design: An open-set monosyllabic speech perception test was conducted on all subjects. The test required subjects to indicate a corresponding Japanese character to that spoken by the examiner. Fifty-two subjects with prelingual hearing impairment (47 hearing aid users and 5 cochlear implant users) were examined. Results: Hearing aid users with average pure-tone thresholds less than 90 dB HL demonstrated generally better monosyllable perception than 70%, which was equivalent or better performance than that of the cochlear implant group. Widely dispersed speech perception was observed within the 90-99 dB HL hearing-aid user group with most subjects demonstrating less than 50% speech perception. In the cluster of > 100 dB HL, few cases demonstrated more than 50% in speech perception. The perception ability of the vowel part of each mora within the cochlear implant group was 100% and corresponding to that of hearing aid users with moderate and severe hearing loss. Conclusion: Hearing ability among cochlear implant users can be comparable with that of hearing aid users with average unaided pure-tone thresholds of 90 dB HL, after monosyllabic speech perception testing was performed. © 2003 Elsevier Ireland Ltd. All rights reserved.",14550959,Article,Final,,Scopus,2-s2.0-10744224348
Cha Y.-H.; Kane M.J.; Baloh R.W.,"Cha, Yoon-Hee (56104862400); Kane, Michael J. (57197495284); Baloh, Robert W. (7103239122)",56104862400; 57197495284; 7103239122,"Familial clustering of migraine, episodic vertigo, and Méniè re's disease",2008,Otology and Neurotology,29,1,,93,96,3,89,10.1097/mao.0b013e31815c2abb,https://www.scopus.com/inward/record.uri?eid=2-s2.0-38349027309&doi=10.1097%2fmao.0b013e31815c2abb&partnerID=40&md5=0d88dae6312fd19debeb1e17baaf3a59,"OBJECTIVE: To evaluate the association between migraine, episodic vertigo, and Ménière's disease in families. STUDY DESIGN: Clinical report. SETTING: University Neurotology Clinic. PATIENTS: Index patients identified with Ménière's disease and migraine and their family members. INTERVENTION: Structured interview to assess a diagnosis of migraine, episodic vertigo, and Ménière's disease in 6 families. Genotyping was performed on 3 sets of twins to analyze monozygosity or dizygosity. MAIN OUTCOME MEASURES: Clinical history of migraine, episodic vertigo, and Ménière's disease. RESULTS: Six index patients and 57 family members were interviewed either by a senior neurologist in person or over the phone by a trained study coordinator. An additional 6 family members completed questionnaires by mail. All 6 index patients had Ménière's disease and migraine. Twenty-six (41%) of the 63 relatives met International Classification of Headache Disorders II criteria for migraine headaches. Thirteen (50%) of these 26 experienced migraine with aura. Three others experienced typical aura without headache. Seventeen (27%) of 63 family members experienced recurrent spells of spontaneous episodic vertigo. There was one twin pair in each of 3 families; 2 pairs were monozygotic and one was dizygotic. In each twin pair, one twin had migraine and Ménière's disease, whereas the other experienced migraine and episodic vertigo without auditory symptoms. CONCLUSION: The frequent association of episodic vertigo, migraine, and Ménière's disease in closely related individuals, including identical twins supports the heritability of a migraine-Ménière's syndrome, with variable expression of the individual features of hearing loss, episodic vertigo, and migraine headaches. © 2008 Otology & Neurotology, Inc.",18046258,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-38349027309
Liu M.; Su Z.-Z.; Chen X.-H.; Xiong G.-X.; Li G.-Z.; Li Q.-F.; Wang X.-G.,"Liu, Min (58842269800); Su, Zhen-Zhong (58278574700); Chen, Xi-Hui (14055605500); Xiong, Guan-Xia (14068202700); Li, Guang-Zhi (55713421900); Li, Qian-Fei (18935521800); Wang, Xin-Guang (55950709300)",58842269800; 58278574700; 14055605500; 14068202700; 55713421900; 18935521800; 55950709300,Auditory steady-state response measurement in evaluating hearing loss milder than moderate to severe level,2006,Chinese Journal of Clinical Rehabilitation,10,46,,198,200,2,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846055705&partnerID=40&md5=101de7aa36d6cfad9a46b2f3714acd77,"Background: Auditory steady-state responses (ASSR) is an objective method of hearing examination in clinic in recent years. ASSR has the frequency specificity as compared with previous auditory brainstem responses (ABR). Objective: To investigate the accuracy of ASSR in objective hearing assessment. Design: A case-control observation. Setting: Department of Otorhinolaryngology, the First Affiliated Hospital of Sun Yat-sen University. Participants: The subjects in the normal hearing group were the 21 undergraduates (42 ears) were enrolled, they all had not any symptoms of ear disease, without history of noise exposure and disease of vestibule system, and they were normal in otoscopy. The outpatients and inpatients with neurosensory deafness were selected from the Department of Otorhinolaryngology, the First Affiliated Hospital of Sun Yat-sen University. All the children cases worn hearing aids, and had the speech ability, and cooperated in the examination. The main types included 6 ears of sudden deafness, 8 ears of presbycusis, and 20 ears of neurosensory deafness due to other unknown causes. Central lesions were excluded by MR examination, and all the patients agreed with the enrollment. The results of pure-tone audiometry were all flat or descending audiogram. According to the severity of hearing damage, the patients were divided into mild deafness group (13 ears), moderate deafness group (9 ears) and moderate-to-severe deafness group (12 ears). Methods: 1 The pure-tone audiometry was performed at the frequencies of 0.125-8 000 Hz in a sound insulation room. The auditory threshold grades of the subjects with normal hearing all accorded with the standards of GB-7583-87 expected value distribution. The average value of air-conduction auditory thresholds of pure-tone audiometry at the frequencies of 0.5, 1, 2 and 4 kHz was calculated. 2 ASSR measurement was performed with the synchronous stimulation pattern in a sound and electromagnetic shielding room, including 8 points for both ears of the same stimulation intensity and the carrier frequency tones of 0.5, 1, 2 and 4 kHz respectively. 3 ABR examination was performed by click sounds with sparse waves in a sound and electromagnetic shielding room, and insert earphones were used. The threshold results were judged according to the minimal stimulation sound intensity of the distinguishable V wave. 4 The results of pure-tone audiometry were compared with those of ABR examination, and the results of ASSR measurement in different hearing groups were processed with analysis of variance, multi-classification discrimination based Bayes standard and q test. Main outcome measures: The thresholds of pure-tone audiometry, ASSR measurement and ABR examination, and the correct rate analyzed by the multi-classification discrimination based Bayes standard were mainly observed. Results: The indexes of the 42 ears in the normal hearing group, 13, 9 and 12 ears in the mild, moderate and moderate-to-severe deafness groups were all involved in the analysis of results. 1 The ABR values were accorded with the actual hearing levels, and the closest to the ASSR thresholds at 1-2 kHz; ASSR reflected induction rates at different frequencies were gradually decreased with the aggravation of hearing damage, and that at each frequency varied with the changes of hearing level, the induction rates of ASSR responses were all 100% for the subjects with normal hearing and patients with mild deafness, but those for the patients with moderate and moderate-to-severe deafness were decreased (0.5 kHz: 77.8%, 92.8%; 4 kHz: 88.9%, 85.7%). At different frequencies, the ASSR thresholds in the moderate-to-severe deafness group were significantly higher than those in the normal hearing group (P < 0.05). The ASSR thresholds at 0.5 and 4 kHz in the moderate-to-severe deafness group were significantly higher than those in the mild deafness group (P < 0.05). The ASSR threshold at 2 kHz in the mild deafness group was significantly higher than that in the normal hearing group (P < 0.05). The ASSR thresholds at 4 kHz in the moderate-to-severe deafness group were significantly higher than those in the normal hearing group and mild deafness group. 2 The incorrect discriminations of actual pure-tone audiometry were analyzed with the interactive clustering discriminant analysis of ASSR measurement and actual pure-tone audiometry, and the results showed that the correct rate of discrimination was 100% in the normal hearing group; Only 1 of the 12 cases in the mild deafness group was incorrectly judged, and the correct rate was 92%; Only 1 of the 19 cases in the moderate deafness group was incorrectly judged, and the correct rate was 89%; the correct rate in the moderate-to-severe deafness group was 83%. Conclusion: The results of ASSR measurement can detect the incorrect discrimination of objective hearing condition by taking the results of pure-tone audiometry as the standards. ASSR has an acceptable accuracy for deafness higher than mild level in estimating objective hearing, and it has a better prospect of application in practice.",,Article,Final,,Scopus,2-s2.0-33846055705
Yuen K.C.P.; McPherson B.,"Yuen, K.C.P. (7202333756); McPherson, B. (7006800770)",7202333756; 7006800770,Audiometric configurations of hearing impaired children in Hong Kong: Implications for amplification,2002,Disability and Rehabilitation,24,17,,904,913,9,11,10.1080/09638280210148602,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037146342&doi=10.1080%2f09638280210148602&partnerID=40&md5=d26fcb3590d859711368545a953a35a1,"Purpose: Children with hearing loss who require special school placement may have a wide range of audiometric configurations. Since such children will vary in auditory status their amplification requirements may also be diverse. This study examined the audiological records of 231 children attending four schools for hearing impaired children in Hong Kong to gain an understanding of common audiometric patterns found in the school children and their auditory rehabilitation needs. Method: Data on the children's aetiology of hearing loss, hearing status, tympanometric findings and the electroacoustic characteristics of their hearing aids were obtained. For 424 children's ears considered having essentially sensorineural hearing loss, k-means cluster analysis methods were used to categorize audiometric configuration groups Results: Cluster analysis that indicated that five distinct audiometric configurations could be found among the school children. Different clusters contained children who had differing amplification needs. The study analysed a number of parameters to check fitting outcomes, including average prescribed gain, frequency-specific measured versus prescribed gain, prescribed frequency response, measured versus prescribed frequency response and the predicted aided thresholds for the children. Conclusion: The amplification needs associated with these five configurations, including recommended prescription gain, maximum power output and possible signal processing strategies, were considered. The clustering algorithm approach proved useful as a means of grouping distinctive audiometric profiles.",12519486,Article,Final,,Scopus,2-s2.0-0037146342
Bernal B.; Altman N.R.,"Bernal, Byron (6602879799); Altman, Nolan R. (7102404808)",6602879799; 7102404808,Speech Delay in Children: A Functional MR Imaging Study,2003,Radiology,229,3,,651,658,7,22,10.1148/radiol.2293021746,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344153269&doi=10.1148%2fradiol.2293021746&partnerID=40&md5=a651af61e9f5aa1d046092a71d97eba3,"PURPOSE: To determine if children with speech delay who have been sedated have patterns of activation to passive language paradigms that are different than those of children with normal speech. MATERIALS AND METHODS: Seventeen children with speech delay (age range, 2-7 years; mean, 4.0 years) and 35 age-matched children with normal speech (age range, 2-8 years; mean, 4.2 years) were evaluated. The subjects in the control group were selected from patients referred for conventional magnetic resonance (MR) imaging. All children had absence of auditory impairment or mental retardation, and MR findings indicated that brain structure was normal. Sedation was achieved with pentobarbital (3-5 mg/kg) or chloral hydrate (75 mg/kg). Functional MR imaging was performed with a single-shot echo-planar blood oxygen-level-dependent technique and a passive block paradigm, in which the child listened to his or her mother's prerecorded voice. Statistical postprocessing of functional MR images was performed with the t test and cluster detection methods. Comparison between groups was performed depending on the type of data with a nonparametrical Mann-Whitney test, parametrical t test, or Fisher exact test. RESULTS: Five (83%) of the six children older than 3 years with speech delay had lateralized activation of functional MR imaging signal in the right hemisphere. Ten (71%) of 14 age-matched patients with normal speech had activation in the left hemisphere when exposed to the same passive listening tasks. When these groups were compared, this difference was statistically significant. (P = .036). No statistically significant lateralization was seen across all age groups in children with activation. CONCLUSION: Children older than 3 years with speech delay have activation in the right hemisphere more frequently than children older than 3 years with normal speech, who often have the expected finding of activation in the left hemisphere. © RSNA, 2003.",14657303,Article,Final,,Scopus,2-s2.0-0344153269
Morrell C.H.; Pearson J.D.; Brant L.J.; Gordon-Salant S.,"Morrell, Christopher H. (7006700127); Pearson, Jay D. (12770740500); Brant, Larry J. (35447480400); Gordon-Salant, Sandra (7003302144)",7006700127; 12770740500; 35447480400; 7003302144,Construction of hearing percentiles in women with non-constant variance from the linear mixed-effects model,1997,Statistics in Medicine,16,21,,2475,2488,13,9,10.1002/(SICI)1097-0258(19971115)16:21<2475::AID-SIM669>3.0.CO;2-D,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030778049&doi=10.1002%2f%28SICI%291097-0258%2819971115%2916%3a21%3c2475%3a%3aAID-SIM669%3e3.0.CO%3b2-D&partnerID=40&md5=80c555ee52536446b7367d4bfd48fbb5,"Current age-specific reference standards for adult hearing thresholds are primarily cross-sectional in nature and vary in the degree of screening of the reference sample for noise-induced hearing loss and other hearing problems. We develop methods to construct age-specific percentiles for longitudinal data that have been modelled using the linear mixed-effects model. We apply these methods to construct percentiles of hearing level using data from a carefully screened sample of women from the Baltimore Longitudinal Study of Aging. However, the variation in the residuals and random effects from the linear mixed-effects model does not remain constant with age and frequency of the stimulus tone. In addition, the distribution of the hearing levels is not symmetric about the mean. We develop a number of methods to use the output from the linear mixed-effects model to construct percentiles that do not have constant variance. We use a transformation of the hearing levels to provide for skewness in the final percentile curves. The change in the variation of the residuals and random effects is modelled as a function of beginning age and frequency and we use this variance function to construct the hearing percentiles. We present a number of approaches. First, we use the absolute values of the population residuals to model the total deviation about the mean as a function of beginning age and frequency. Second, we model the standard deviation in the person-specific (cluster) residuals as well as the standard deviation in the estimated random effects. Finally, we use weighted least squares with the regressions on the absolute cluster residuals and absolute estimated random effects where the weights are the reciprocal of the standard deviations of their estimates.",9364655,Article,Final,,Scopus,2-s2.0-0030778049
Shriberg L.D.; Flipsen Jr. P.; Kwiatkowski J.; McSweeny J.L.,"Shriberg, Lawrence D. (7006854107); Flipsen Jr., Peter (6602706967); Kwiatkowski, Joan (7004689157); McSweeny, Jane L. (6602660184)",7006854107; 6602706967; 7004689157; 6602660184,A diagnostic marker for speech delay associated with otitis media with effusion: The intelligibility-speech gap,2003,Clinical Linguistics and Phonetics,17,7,,507,528,21,17,10.1080/0269920031000138169,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242269082&doi=10.1080%2f0269920031000138169&partnerID=40&md5=6d14c3a587a21c8c52c0048fdc0febae,"The goal of this study was to determine if notably reduced intelligibility is a potential diagnostic marker for children with speech delay and histories of early recurrent otitis media with effusion (SD-OME). Intelligibility was assessed in one 5-10 minute conversational speech sample from each of 281 speakers. The OME histories of 148 of these children with normal speech acquisition were described in two prior reports. OME histories of 85 additional children with speech delay were obtained from case history reports. For both groups, the children with positive OME (OME+) histories had significantly lower intelligibility scores but significantly higher speech production scores than children with negative OME (OME-) histories. Findings for a diagnostic marker to discriminate speech delayed children with OME+ versus OME-histories were promising, considering that the data were obtained retrospectively and did not include audiological information characterizing children's concurrent fluctuant hearing loss. The formula for the diagnostic marker, termed the Intelligibility-Speech Gap, was identified by a machine learning routine. Diagnostic accuracy findings for the marker were as follows: positive predictive value = 74%, negative predictive value = 86%, sensitivity = 79%, specificity = 83%, positive likelihood ratio = 4.6 and negative likelihood ratio = 0.25. Discussion considers speech processing perspectives on the source of the intelligibility-speech gap in children with suspected SD-OME, and methodological perspectives on its development as a diagnostic marker of one etiological subtype of speech delay.",14608797,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-0242269082
Glueckert R.; Pfaller K.; Kinnefors A.; Rask-Andersen H.; Schrott-Fischer A.,"Glueckert, Rudolf (55923185200); Pfaller, Kristian (7004242183); Kinnefors, Anders (6602239644); Rask-Andersen, Helge (7006223005); Schrott-Fischer, Anneliese (55403356500)",55923185200; 7004242183; 6602239644; 7006223005; 55403356500,"The human spiral ganglion: New insights into ultrastructure, survival rate and implications for cochlear implants",2005,Audiology and Neurotology,10,5,,258,273,15,75,10.1159/000086000,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23844552101&doi=10.1159%2f000086000&partnerID=40&md5=64a6880b91258da1ee7e785045dcb976,"This study was based on high-resolution SEM assessment of freshly fixed, normal-hearing, human inner ear tissue. In addition, semiquantitative observations were made in long-term deafened temporal bone material, focusing on the spiral ganglia and nerve projections, and a detailed study of the fine bone structure in macerated tissues was performed. Our main findings detail the presence of extensive bony fenestrae surrounding the nerve elements, permitting a relatively free flow of perilymph to modiolar structures. The clustering of the spiral ganglion cells in Rosenthal's canal and the detailed and intricate course of postganglionic axons are described. The close proximity of fibers to cell soma is demonstrated by impression in cell surfaces, and presence of small microvilli-like structures at the contact regions, anchoring nerve fibers to the cell wall. Extensive fenestrae and the presence of a fragile network of endosteal bony structures at the surfaces guiding nerve fibers are described in detail for the first time. This unique freshly prepared human material offers the opportunity for a detailed ultrastructural study not previously possible on postmortem fixed material and more accurate information to model electrostimulation of the human auditory nerve through a cochlear implant. On the basis of this study, we suggest that the concentration and high density of spiral ganglion cells, and the close physical interaction between neural elements, may explain the slow retrograde degeneration found in humans after loss of peripheral receptors. Moreover, the fragile bony columns connecting the spiral canal with the osseous spiral lamina may be a potential site for trauma in (perimodiolar) electrode positioning. Copyright © 2005 S. Karger AG.",15925863,Article,Final,,Scopus,2-s2.0-23844552101
Iguchi H.; Anniko M.,"Iguchi, Hiroyoshi (7102161588); Anniko, Matti (55140104300)",7102161588; 55140104300,Interleukin 8 can affect inner ear function,1998,ORL,60,4,,181,189,8,14,10.1159/000027591,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031864947&doi=10.1159%2f000027591&partnerID=40&md5=b29f18b8ccdc3a2ac5452d3139af72f8,"The chemokine interleukin 8 (IL-8) was instilled into the round window niche of rats through a small perforation in the tympanic membrane in order to study its effect on inner ear function by electrophysiological and morphological techniques. The frequency-specific auditory brainstem response (ABR) was recorded at the frequencies 4, 8, 10, 12, 16 and 20 kHz just before and 1, 2, 5 and 14 days after instilling IL-8 to ascertain the hearing level during each interval. Morphological examination by light microscopy was performed during the same interval following the instillation of IL-8. On day 1, the rise in ABR threshold was within 5 dB SPL (non-significant elevation). However, a significant threshold elevation (above 5 dB SPL) occurred in high-frequency areas (16 and 20 kHz) on day 2, and in middle frequency areas (10 and 12 kHz) on day 5 with sensorineural hearing loss type intensity-latency curves. By day 14, the elevated thresholds had returned to pre-instillation levels. In the lowest areas (4 and 8 kHz), no significant threshold elevation was detected at any time during the observation period. By light microscopy, on day 1, clusters of inflammatory cells (predominantly neutrophils) were observed just outside the round window membrane (RWM), while only a few neutrophils were detected in the cochlea. These cells were still present outside the RWM on day 2. The neutrophils had disappeared by day 5 and only macrophages were present on the middle ear side of the RWM. However, throughout the observation period, the organ of Corti and stria vascularis appeared to be intact. These results suggest that IL-8 in the middle ear cavity is able to influence inner ear function.",9646304,Article,Final,,Scopus,2-s2.0-0031864947
Howard R.; Almeida O.; Levy R.,"Howard, Robert (34769841900); Almeida, Osvaldo (35481288100); Levy, Raymond (7404060972)",34769841900; 35481288100; 7404060972,"Phenomenology, Demography and Diagnosis in Late Paraphrenia",1994,Psychological Medicine,24,2,,397,410,13,76,10.1017/S0033291700027379,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028278512&doi=10.1017%2fS0033291700027379&partnerID=40&md5=7f5c4b7ab354a43089232d4e8f227018,"One hundred and one patients with late paraphrenia were examined using the Present State Examination. The established high prevalence rates of female gender, the unmarried state and sensory impairment were confirmed. All of the symptoms of schizophrenia, with the exception of formal thought disorder, were found in the subjects with approximately the same prevalence as reported in schizophrenics with a symptom onset in younger life. The presence of visual hallucinosis was significantly associated with visual impairment, but the same association was not found between auditory hallucinations and deafness. Mean age at onset of symptoms was high at 74.1 years. Using ICD-10 diagnostic criteria the patients were categorized as schizophrenia (61.4%), delusional disorder (30.7%) and schizoaffective disorder (7.9%). Patients in these diagnostic categories differed in their pre-morbid IQ estimations, current cognitive state measured by the Mini-Mental State Examination and in the number of scored positive psychotic PSE symptoms and their systematization of and preoccupation with delusions and hallucinations. There were no significant differences between the patients in the ICD-10 schizophrenia and delusional disorder groups in terms of age at symptom onset, sex ratio, response to treatment, being unmarried, the presence of insight or sensory impairment. The high degree of clinical similarity between patients with late paraphrenia combined with the inability of ICD-10 to define diagnostic subgroups that correspond to patient clusters derived from clinical symptoms or which are meaningfully different from each other in terms of demographic and prognostic factors provide a strong argument for the retention of late paraphrenia as the most appropriate diagnosis for such patients. © 1994, Cambridge University Press. All rights reserved.",8084935,Article,Final,,Scopus,2-s2.0-0028278512
Beitel R.E.; Snyder R.L.; Schreiner C.E.; Raggio M.W.; Leake P.A.,"Beitel, Ralph E. (6701331833); Snyder, Russell L. (57207897133); Schreiner, Christoph E. (7006315409); Raggio, Marcia W. (6603873505); Leake, Patricia A. (6701777885)",6701331833; 57207897133; 7006315409; 6603873505; 6701777885,Electrical cochlear stimulation in the deaf cat: Comparisons between psychophysical and central auditory neuronal thresholds,2000,Journal of Neurophysiology,83,4,,2145,2162,17,26,10.1152/jn.2000.83.4.2145,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034093138&doi=10.1152%2fjn.2000.83.4.2145&partnerID=40&md5=dda608f17333c3c2b88a20e1bdd9baea,"Cochlear prostheses for electrical stimulation of the auditory nerve ('electrical hearing') can provide auditory capacity for profoundly deaf adults and children, including in many cases a restored ability to perceive speech without visual cues. A fundamental challenge in auditory neuroscience is to understand the neural and perceptual mechanisms that make rehabilitation of hearing possible in these deaf humans. We have developed a feline behavioral model that allows us to study behavioral and physiological variables in the same deaf animals. Cats deafened by injection of ototoxic antibiotics were implanted with either a monopolar round window electrode or a multichannel scala tympani electrode array. To evaluate the effects of perceptually significant electrical stimulation of the auditory nerve on the central auditory system, an animal was trained to avoid a mild electrocutaneous shock when biphasic current pulses (0.2 ms/phase) were delivered to its implanted cochlea. Psychophysical detection thresholds and electrical auditory brain stem response (EABR) thresholds were estimated in each cat. At the conclusion of behavioral testing, acute physiological experiments were conducted, and threshold responses were recorded for single neurons and multineuronal clusters in the central nucleus of the inferior colliculus (ICC) and the primary auditory cortex (A1). Behavioral and neurophysiological thresholds were evaluated with reference to cochlear histopathology in the same deaf cats. The results of the present study include: 1) in the cats implanted with a scala tympani electrode array, the lowest ICC and A1 neural thresholds were virtually identical to the behavioral thresholds for intracochlear bipolar stimulation; 2) behavioral thresholds were lower than ICC and A1 neural thresholds in each of the cats implanted with a monopolar round window electrode; 3) EABR thresholds were higher than behavioral thresholds in all of the cats (mean difference = 6.5 dB); and 4) the cumulative number of action potentials for a sample of ICC neurons increased monotonically as a function of the amplitude and the number of stimulating biphasic pulses. This physiological result suggests that the output from the ICC may be integrated spatially across neurons and temporally integrated across pulses when the auditory nerve array is stimulated with a train of biphasic current pulses. Because behavioral thresholds were lower and reaction times were faster at a pulse rate of 30 pps compared with a pulse rate of 2 pps, spatial-temporal integration in the central auditory system was presumably reflected in psychophysical performance.",10758124,Article,Final,,Scopus,2-s2.0-0034093138
Leisenberg Manfred,"Leisenberg, Manfred (6602407379)",6602407379,Hearing aids for the profoundly deaf based on neural net speech processing,1995,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",5,,,3535,3538,3,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028996650&partnerID=40&md5=d53428516c073fb917e3f91a6703de66,"A new speech processing concept for Cochlear Implant (CI) - systems has been developed. It is based on robust feature extraction and a neural net classifier: Feature coefficients, extracted either by relative spectral perceptual linear predictive technique or regular CI-filtering, are classified into 'auditory related units'. The classifier is based on an adapted self-organizing Kohonen algorithm which finds representative clusters in the input feature vector space. These clusters are closely related to the statistical distribution of the feature coefficients and represent phonetic units. Firing neural net output nodes control the synthesis of a limited 'stimulus pattern alphabet'. Each 'letter' represents a subphoneme and is linked to a highly distinguishable complex stimulus pattern. The concept has been implemented with CINSTIM V2.0. First experimental results confirm the new CI speech processing strategy.",,Conference paper,Final,,Scopus,2-s2.0-0028996650
Stevenson D.A.; Bleyl S.B.; Maxwell T.; Brothman A.R.; South S.T.,"Stevenson, David A. (8347410600); Bleyl, Steven B. (6507620798); Maxwell, Teresa (7004872357); Brothman, Arthur R. (7005560379); South, Sarah T. (14036367400)",8347410600; 6507620798; 7004872357; 7005560379; 14036367400,Mandibulofacial dysostosis in a patient with a de novo 2;17 translocation that disrupts the HOXD gene cluster,2007,"American Journal of Medical Genetics, Part A",143,10,,1053,1059,6,12,10.1002/ajmg.a.31715,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248163494&doi=10.1002%2fajmg.a.31715&partnerID=40&md5=1475f9a8d785777415659128aae4ecc9,"Treacher Collins syndrome (TCS) is the prototypical mandibulofacial dysostosis syndrome, but other mandibulofacial dysostosis syndromes have been described. We report an infant with mandibulofacial dysostosis and an apparently balanced de novo 2;17 translocation. She presented with severe lower eyelid colobomas requiring skin grafting, malar and mandibular hypoplasia, bilateral microtia with external auditory canal atreasia, dysplastic ossicles, hearing loss, bilateral choanal stenosis, cleft palate without cleft lip, several oral frenula of the upper lip/gum, and micrognathia requiring tracheostomy. Her limbs were normal. Chromosome analysis at the 600-band level showed a 46,XX,t(2;17)(q24.3;q23) karyotype. Sequencing of the entire TCOF1 coding region did not show evidence of a sequence variation. High-resolution genomic microarray analysis did not identify a cryptic imbalance. FISH mapping refined the breakpoints to 2q31.1 and 17q24.3-25.1 and showed the 2q31.1 breakpoint likely affects the HOXD gene cluster. Several atypical findings and lack of an identifiable TCOF1 mutation suggest that this child has a provisionally unique mandibulofacial dysostosis syndrome. The apparently balanced de novo translocation provides candidate loci for atypical and TCOF1 mutation negative cases of TCS. Based on the agreement of our findings with one previous case of mandibulofacial dysostosis with a 2q31.1 transocation, we hypothesize that misexpression of genes in the HOXD gene cluster produced the described phenotype in this patient. © 2007 Wiley-Liss, Inc.",17431905,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-34248163494
Aizawa N.; Eggermont J.J.,"Aizawa, Naotaka (12762664000); Eggermont, Jos J. (7103339415)",12762664000; 7103339415,Mild noise-induced hearing loss at young age affects temporal modulation transfer functions in adult cat primary auditory cortex,2007,Hearing Research,223,01-Feb,,71,82,11,20,10.1016/j.heares.2006.09.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845622436&doi=10.1016%2fj.heares.2006.09.016&partnerID=40&md5=42e5885b2e28aea746143d52b3da0aa2,"Kittens were exposed for 2 h to a 1/3rd octave band of noise centered at 5 kHz and at 120 dB SPL. After the exposure, they were kept in a quiet room for at least 4 weeks, and until they were mature. The noise-exposed cats showed on average 16.5 dB higher ABR thresholds and 13.2 dB higher thresholds at the characteristic frequency (CF) than the control cats for frequencies between 4 and 16 kHz. The frequency-tuning curve bandwidth at 20 dB above threshold was significantly increased compared to controls in the CF region of the hearing loss. In noise-exposed cats, temporal modulation-transfer functions (tMTFs) to amplitude-modulated (AM) noise, but not to periodic click trains, showed a marked increase for modulation frequencies (MFs) below 6 Hz. The vectorstrength in noise-exposed cats increased for all modulation frequencies below 32 Hz for neurons with a CF in the range of the hearing loss. The tMTFs for AMnoise in the noise-exposed group were less band-pass compared to the controls, and in that sense the mild hearing loss could be considered as effectively reducing the central activation in the same way as a reduced sound pressure level. Effects of reduced central inhibition are visible in the broadening of frequency-tuning curves, and in the increased limiting rates for AMnoise. © 2006 Elsevier B.V. All rights reserved.",17123758,Article,Final,,Scopus,2-s2.0-33845622436
Morioka I.; Luo W.Z.; Miyashita K.; Takeda S.; Wang Y.X.; Li S.C.,"Morioka, I. (7003971873); Luo, W.Z. (12754852100); Miyashita, K. (7202708248); Takeda, S. (7403066820); Wang, Y.X. (55954538600); Li, S.C. (36447649700)",7003971873; 12754852100; 7202708248; 7403066820; 55954538600; 36447649700,Hearing impairment among young Chinese in a rural area,1996,Public Health,110,5,,293,297,4,25,10.1016/S0033-3506(96)80092-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029790907&doi=10.1016%2fS0033-3506%2896%2980092-8&partnerID=40&md5=bf145fc25fc244d6f59e47102906b24b,"To evaluate hearing levels in Chinese young people, audiometry was carried out at a rural village in Shandong Prefecture. The subjects were 282 healthy school children and students ranging in age from 7-17 y. All subjects were asked to complete a brief questionnaire on otological symptoms, personal histories and use of noisy playthings. Audiometric threshold testing was performed at the audiometric frequencies of 0.5, 1, 2, 4 and 8 kHz. Cluster analysis was used to estimate the associations between questions in the questionnaire and hearing impairment. Fifty-six subjects (20% subjects) were excluded from the normal groups. Twenty-two ears of the excluded subjects showed 4 kHz-dip and 38 ears showed high frequency hearing loss. An increased prevalence of hearing impairment was found when compared with young Japanese (1% from the nationwide school health survey) and with young Chinese in Shandong Prefecture (0.5%). In the questionnaire, 4 questions on dizziness, head trauma, aminoglycoside administration, and suspicion of Meniere's syndrome, were included in the cluster of hearing impairment. The cause of this hearing impairment was proposed to be the potentiating effects of aminoglycoside antibiotics and exposure to noise.",8885666,Article,Final,,Scopus,2-s2.0-0029790907
Ono Y.,"Ono, Yuichi (55741741500)",55741741500,A longitudinal study of hearing level aggravation due to aging,1996,Journal of Otolaryngology of Japan,99,4,,558,566,8,1,10.3950/jibiinkoka.99.558,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030119561&doi=10.3950%2fjibiinkoka.99.558&partnerID=40&md5=f12ad88c536f2a6cc4435136bdd0ac24,"It has been reported that hearing aggravation due to aging is predominantly in the high frequency range and that there are rapid and slow phase of aggravation in hearing level. In the present study, the pattern of aggravation of hearing level due to aging was investigated in 387 adults of over 35 years of age who had visited the Kitasato Health Science Center for a regular health check-up annually for more than 5 years, and were diagnosed as having neither external of middle ear diseases nor hearing impairment of obvious origin at their first visit. The subjects were divided into 8 groups according to their ages in increments of 5 years. Their audiograms were obtained annually, and the results were used to obtain the distribution of the hearing level at each test frequency. All of the subjects were examined for individual changes in audiograms and those who showed 20 dB or more aggravation of hearing in a 1-year period without subsequent improvement were defined as having a rapid phase of aggravation. There were clustering points in hearing distribution at around 30 dB and 60 dB at the test frequency of 8 kHz in those subjects showing a rapid phase of aggravation. Similar clustering points were also noted in those subjects who showed gradual aggravation of 20 dB or more in a 5-year period and who had 20 dB or more aggravation in one year but showed later improvement. As for the test frequencies lower than 4 kHz, there appeared to be a clustering point at around 30 dB. The incidence of the rapid phase of aggravation was then determined in each group, in order to investigate the relationship between aging and the appearance of the rapid phase of aggravation. The rapid phase was already noted in the youngest age group (range, 35-39 years), while the incidence gradually increased up to the 50-54-year group and stayed at a constant level in the 55-69-year groups. The incidence markedly decreased thereafter. The results suggest that hearing aggravation due to aging does not occur at any particular age. Rather, the hearing aggravaion appeared to be closely related to the hearing level, and to manifest itself when the hearing level approaches 30 dB and 60 dB.",8683366,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-0030119561
Resendes B.L.; Robertson N.G.; Szustakowski J.D.; Resendes R.J.; Weng Z.; Morton C.C.,"Resendes, Barbara L. (6602485617); Robertson, Nahid G. (7102941229); Szustakowski, Joseph D. (6505831589); Resendes, Robert J. (6701619857); Weng, Zhiping (7102672712); Morton, Cynthia C. (7201605341)",6602485617; 7102941229; 6505831589; 6701619857; 7102672712; 7201605341,Gene discovery in the auditory system: Characterization of additional cochlear-expressed sequences,2002,JARO - Journal of the Association for Research in Otolaryngology,3,1,,45,53,8,27,10.1007/s101620020005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035985507&doi=10.1007%2fs101620020005&partnerID=40&md5=a35ce88f0e7949eac67bc0830b0a4f96,"To identify genes involved in hearing, 8494 expressed sequence tags (ESTs) were generated from a human fetal cochlear cDNA library in two distinct sequencing projects. Analysis of the first set of 4304 ESTs revealed clones representing 517 known human genes, 41 mammalian genes not previously detected in human tissues, 487 ESTs from other human tissues, and 541 cochlear-specific ESTs (http://hearing.bwh.harvard.edu). We now report results of a DNA sequence similarity (BLAST) analysis of an additional 4190 cochlear ESTs and a comparison to the first set. Among the 4190 new cochlear ESTs, 959 known human genes were identified; 594 were found only among the new ESTs and 365 were found among ESTs from both sequencing projects. COL1A2 was the most abundant transcript among both sets of ESTs, followed in order by COL3A1, SPARC, EEF1A1, and TPTI. An additional 22 human homologs of known nonhuman mammalian genes and 1595 clusters of ESTs, of which 333 are cochlear-specific, were identified among the new cochlear ESTs. Map positions were determined for 373 of the new cochlear ESTs and revealed 318 additional loci. Forty-nine of the mapped ESTs are located within the genetic interval of 23 deafness loci. Reanalysis of unassigned ESTs from the prior study revealed 338 additional known human genes. The total number of known human genes identified from 8494 cochlear ESTs is 1449 and is represented by 4040 ESTs. Among the known human genes are 14 deafness-associated genes, including GJB2 (connexin 26) and KVLQT1. The total number of nonhuman mammalian genes identified is 43 and is represented by 58 ESTs. The total number of ESTs without sequence similarity to known genes is 4055. Of these, 778 also do not have sequence similarity to any other ESTs, are categorized into 700 clusters, and may represent genes uniquely or preferentially expressed in the cochlea. Identification of additional known genes, ESTs, and cochlear-specific ESTs provides new candidate genes for both syndromic and nonsyndromic deafness disorders.",12083723,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-0035985507
Cryns K.; Pfister M.; Pennings R.J.E.; Bom S.J.H.; Flothmann K.; Caethoven G.; Kremer H.; Schatteman I.; Köln K.A.; Tóth T.; Kupka S.; Blin N.; Nürnberg P.; Thiele H.; Van De Heyning P.H.; Reardon W.; Stephens D.; Cremers C.W.R.J.; Smith R.J.H.; Van Camp G.,"Cryns, Kim (6602940684); Pfister, Markus (55391491800); Pennings, Ronald J.E. (6603865407); Bom, Steven J.H. (6602518973); Flothmann, Kris (6602872650); Caethoven, Goele (6505880817); Kremer, Hannie (36014154200); Schatteman, Isabelle (6603609006); Köln, Karen A. (6505553177); Tóth, Tímea (7102154904); Kupka, Susan (7004242578); Blin, Nikolaus (7004442702); Nürnberg, Peter (57200185922); Thiele, Holger (57223640812); Van De Heyning, Paul H. (7005171191); Reardon, William (55797287600); Stephens, Dafydd (55565834700); Cremers, Cor W.R.J. (7103079207); Smith, Richard J.H. (16073972500); Van Camp, Guy (34573802800)",6602940684; 55391491800; 6603865407; 6602518973; 6602872650; 6505880817; 36014154200; 6603609006; 6505553177; 7102154904; 7004242578; 7004442702; 57200185922; 57223640812; 7005171191; 55797287600; 55565834700; 7103079207; 16073972500; 34573802800,Mutations in the WFS1 gene that cause low-frequency sensorineural hearing loss are small non-inactivating mutations,2002,Human Genetics,110,5,,389,394,5,76,10.1007/s00439-002-0719-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036590143&doi=10.1007%2fs00439-002-0719-1&partnerID=40&md5=6f67a92f24803c8c961a7ee3e678f961,"Hereditary hearing impairment is an extremely heterogeneous trait, with more than 70 identified loci. Only two of these loci are associated with an auditory phenotype that predominantly affects the low frequencies (DFNA1 and DFNA6/14). In this study, we have completed mutation screening of the WFS1 gene in eight autosomal dominant families and twelve sporadic cases in which affected persons have low-frequency sensorineural hearing impairment (LFSNHI). Mutations in this gene are known to be responsible for Wolfram syndrome or DIDMOAD (diabetes insipidus, diabetes mellitus, optic atrophy, and deafness), which is an autosomal recessive trait. We have identified seven missense mutations and a single amino acid deletion affecting conserved amino acids in six families and one sporadic case, indicating that mutations in WFS1 are a major cause of inherited but not sporadic low-frequency hearing impairment. Among the ten WFS1 mutations reported in LFSNHI, none is expected to lead to premature protein truncation, and nine cluster in the C-terminal protein domain. In contrast, 64% of the Wolfram syndrome mutations are inactivating. Our results indicate that only non-inactivating mutations in WFS1 are responsible for non-syndromic low-frequency hearing impairment. © Springer-Verlag 2002.",12073007,Article,Final,,Scopus,2-s2.0-0036590143
De Ridder D.; Ryu H.; Møller A.R.; Nowé V.; Van De Heyning P.; Verlooy J.; Sindou M.P.; Samii M.; Gharabaghi A.; Casey K.F.; Jannetta P.J.; Kileny P.R.,"De Ridder, Dirk (7006928697); Ryu, Hiroshi (56248975600); Møller, Aage R. (7401763694); Nowé, Vicky (6507115558); Van De Heyning, Paul (7005171191); Verlooy, Jan (7004835075); Sindou, Marc P. (7102597617); Samii, Madjid (56024678300); Gharabaghi, Alireza (23018633600); Casey, Kenneth F. (7102432266); Jannetta, Peter J. (7005856728); Kileny, Paul R. (7005345764)",7006928697; 56248975600; 7401763694; 6507115558; 7005171191; 7004835075; 7102597617; 56024678300; 23018633600; 7102432266; 7005856728; 7005345764,Functional Anatomy of the Human Cochlear Nerve and Its Role in Microvascular Decompressions for Tinnitus,2004,Neurosurgery,54,2,,381,390,9,57,10.1227/01.NEU.0000103420.53487.79,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10744224752&doi=10.1227%2f01.NEU.0000103420.53487.79&partnerID=40&md5=116b94fd49f513038995202bfd538391,"OBJECTIVE: The functional anatomy (i.e., tonotopy) of the human cochlear nerve is unknown. A better understanding of the tonotopy of the central nervous system segment of the cochlear nerve and of the pathophysiology of tinnitus might help to ameliorate the disappointing results obtained with microvascular decompressions in patients with tinnitus. METHODS: We assume that vascular compression of the cochlear nerve can induce a frequency-specific form of hearing loss and that when the nerve is successfully decompressed, this hearing loss can recuperate. Thirty-one patients underwent a microvascular decompression of the vestibulocochlear nerve for vertigo or tinnitus. Preoperative audiograms were subtracted from postoperative audiograms, regardless of the surgical result with regard to the tinnitus and vertigo, because the hearing improvement could be the only sign of the vascular compression. The frequency of maximal improvement was then correlated to the site of vascular compression. A tonotopy of the cochlear nerve was thus obtained. RESULTS: A total of 18 correlations can be made between the site of compression and postoperative maximal hearing improvement frequency when 5-dB hearing improvement is used as threshold, 13 when 10-dB improvement is used as threshold. A clear distribution can be seen, with clustering of low frequencies at the posterior and inferior side of the cochlear nerve, close to the brainstem, and close to the root exit zone of the facial nerve. High frequencies are distributed closer to the internal acoustic meatus and more superiorly along the posterior aspect of the cochlear nerve. CONCLUSION: The tonotopic organization of the cisternal segment of the cochlear nerve has an oblique rotatory structure as a result of the rotatory course of the cochlear nerve in the posterior fossa. Knowledge of this tonotopic organization of the auditory nerve in its cisternal course might benefit surgeons who perform microvascular decompression operations for the vestibulocochlear compression syndrome, especially in the treatment of unilateral severe tinnitus.",14744285,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-10744224752
Barry J.G.; Blamey P.J.; Martin L.F.A.; Lee K.Y.-S.; Tang T.; Ming Y.Y.; Van Hasselt C.A.,"Barry, Johanna G. (7402082521); Blamey, Peter J. (7006768969); Martin, Lois F.A. (7403866235); Lee, Kathy Y.-S. (7501501830); Tang, Tempo (7401988724); Ming, Yuen Yuet (7006306833); Van Hasselt, Charles Andrew (7103394173)",7402082521; 7006768969; 7403866235; 7501501830; 7401988724; 7006306833; 7103394173,Tone discrimination in Cantonese-speaking children using a cochlear implant,2002,Clinical Linguistics and Phonetics,16,2,,79,99,20,35,10.1080/02699200110109802,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036116908&doi=10.1080%2f02699200110109802&partnerID=40&md5=5b4a1bb66b6ff5028b55db60c527bff6,"Most tone perception tests for Cantonese-speaking cochlear implant users have been based on tone identification tasks which require significant cognitive development to be successfully completed. Results from such tests suggest that cochlear implant child users are performing at about chance level and may not be receiving much information about pitch using the implant. This paper reports on the ability of cochlear implant child users to discriminate pitch variations in Cantonese by using an experimental procedure based on play audiometry. As part of the study, the usefulness of higher rates of electrode stimulation for aiding tone discrimination is also examined. Cochlear implant users are shown to derive sufficient information about pitch to discriminate most tone contrasts relatively successfully, with performance being most variable for contrasts involving tones clustered in the lower register of the speaker's fundamental frequency range. Contrary to hypothesis, higher electrode stimulation rates are not found to offer significant benefits for aiding pitch discrimination.",11987495,Article,Final,,Scopus,2-s2.0-0036116908
Matthies M.L.; Guenther F.H.; Denny M.; Perkell J.S.; Burton E.; Vick J.; Lane H.; Tiede M.; Zandipour M.,"Matthies, Melanie L. (7006850732); Guenther, Frank H. (7003640507); Denny, Margaret (7007106770); Perkell, Joseph S. (7004249379); Burton, Ellen (15764605100); Vick, Jennell (7006450232); Lane, Harlan (7102110160); Tiede, Mark (6602833091); Zandipour, Majid (6602580520)",7006850732; 7003640507; 7007106770; 7004249379; 15764605100; 7006450232; 7102110160; 6602833091; 6602580520,Perception and production of /r/ allophones improve with hearing from a cochlear implant,2008,Journal of the Acoustical Society of America,124,5,,3191,3202,11,13,10.1121/1.2987427,https://www.scopus.com/inward/record.uri?eid=2-s2.0-56749175708&doi=10.1121%2f1.2987427&partnerID=40&md5=63d9bb1a6d829356a0474af76286749c,"Tongue shape can vary greatly for allophones of /r/ produced in different phonetic contexts but the primary acoustic cue used by listeners, lowered F3, remains stable. For the current study, it was hypothesized that auditory feedback maintains the speech motor control mechanisms that are constraining acoustic variability of F3 in /r/; thus the listener's percept remains /r/ despite the range of articulatory configurations employed by the speaker. Given the potential importance of auditory feedback, postlingually deafened speakers should show larger acoustic variation in /r/ allophones than hearing controls, and auditory feedback from a cochlear implant could reduce that variation over time. To test these hypotheses, measures were made of phoneme perception and of production of tokens containing /r/, stop consonants, and /r/+stop clusters in hearing controls and in eight postlingually deafened adults pre- and postimplant. Postimplant, seven of the eight implant speakers did not differ from the control mean. It was also found that implant users' production of stop and stop+/r/ blend improved with time but the measured acoustic contrast between these was still better in the control speakers than for the implant group even after the implant users had experienced a year of improved auditory feedback. © 2008 Acoustical Society of America.",19045803,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-56749175708
Harding G.W.; Bohne B.A.,"Harding, Gary W. (7201960545); Bohne, Barbara A. (7005173566)",7201960545; 7005173566,Distribution of focal lesions in the chinchilla organ of Corti following exposure to a 4-kHz or a 0.5-kHz octave band of noise,2007,Hearing Research,225,01-Feb,,50,59,9,7,10.1016/j.heares.2006.12.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847049833&doi=10.1016%2fj.heares.2006.12.012&partnerID=40&md5=08753979611c2773873dbc87752ee512,"An octave band of noise (OBN) delivers fairly uniform acoustic energy over a specific range of frequencies. Above and below this range, energy is at least 30 dB SPL less than that within the OBN. When the ear is exposed to an OBN, hair-cell loss often occurs outside the octave band. The frequency location of hair-cell loss is evident when the percent distance from the apex of focal lesions is analyzed. Focal lesions involve substantial loss of outer hair cells (OHCs) only, inner hair cells (IHCs) only, or both OHCs and IHCs (i.e., combined lesions) in a specific region of the organ of Corti (OC). Data sets were assembled from our permanent collection of noise-exposed chinchillas as follows: (1) the sum of exposure duration and recovery time was less than or equal to 11 d; (2) the exposure level was less than or equal to 108 dB SPL; and (3) focal lesions were less than 1.5 mm in length. The data sets included a variety of exposures ranging from high-level, short duration to moderate-level, moderate duration. The center of each focal lesion was expressed as percent distance from the OC apex. Means, standard deviations and medians were calculated for focal-lesion size resulting from exposure to a 4-kHz or a 0.5-kHz OBN. Histograms were then constructed from the percent-location data using 2.0% bins. For the 4-kHz OBN, 5% of the lesions were in the apical half of the OC and 95% were in the basal half. The mean lesion size was 1.68% of total OC length for OHC and combined focal lesions and 0.42% for IHC focal lesions. Most OHC and combined lesions occurred in the 5-7-kHz region, at and just above the upper edge of the OBN. Clusters of lesions were also found around 8 and 12 kHz. A cluster was present at and just below the lower edge of the OBN, as well as another in the 1.5-kHz region. For the 0.5-kHz OBN, 34% of the lesions were in the apical half of the OC and 66% were in the basal half. The mean lesion size was 0.93% for OHC and combined focal lesions and 0.32% for IHC focal lesions. OHC and combined focal-lesion distribution showed clusters at 0.25, 0.75 and 1.5 kHz in the apical half of the OC. In the basal half, the distribution of focal lesions was similar to that seen with the 4-kHz OBN (r = 0.54). With both OBNs, most IHC focal lesions occurred in the basal half of the OC. High resolution power spectrum analysis of each OBN and non-invasive tests for harmonics and distortion products in a chinchilla were performed to look for exposure energy above and below the OBN. No energy was found that could explain the OC damage. © 2007 Elsevier B.V. All rights reserved.",17291699,Article,Final,,Scopus,2-s2.0-33847049833
Griffiths T.D.,"Griffiths, T.D. (7102183421)",7102183421,Musical hallucinosis in acquired deafness phenomenology and brain substrate,2000,Brain,123,10,,2065,2076,11,209,10.1093/brain/123.10.2065,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033779060&doi=10.1093%2fbrain%2f123.10.2065&partnerID=40&md5=0eab0393dd9c18ff4ee7ced80f845d84,"Six subjects with musical hallucinations following acquired deafness are described. The subjects all experienced the condition in the absence of any other features to suggest epilepsy or psychosis. I propose a neuropsychological model for the condition consistent with detailed observation of the subjects' phenomenology. The model is based on spontaneous activity within a cognitive module for the analysis of temporal pattern in segmented sound. Functional imaging was carried out to test the hypothesis that musical hallucinosis is due to activity within such a module, for which the neural substrate is a distributed network distinct from the primary auditory cortex. PET was carried out on the six subjects to identify areas where brain activity increased as a function of the severity of the hallucination. In a group analysis, no effect was demonstrated in the primary auditory cortices. Clusters of correlated activity were demonstrated in the posterior temporal lobes, the right basal ganglia, the cerebellum and the inferior frontal cortices. This network is similar to that previously demonstrated during the normal perception and imagery of patterned-segmented sound, and is consistent with the proposed neuropsychological and neural mechanism.",11004124,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-0033779060
Tian J.; Juhola M.; Grönfors T.,"Tian, Jilei (36983672800); Juhola, Martti (55230878300); Grönfors, Tapio (6701634961)",36983672800; 55230878300; 6701634961,Segmentation of auditory brainstem response signals,1996,International Journal of Bio-Medical Computing,43,3,,215,226,11,1,10.1016/S0020-7101(96)01212-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030482661&doi=10.1016%2fS0020-7101%2896%2901212-3&partnerID=40&md5=d4fad9d755cd02f475e04123e7711917,"Auditory brainstem responses are used to detect hearing defects in audiology and otoneurology. The use of computer programs for the analysis of such recordings is increasing. To identify their detailed properties a pattern recognition algorithm implemented in an analysis program must be highly reliable, for the recognition process, some preprocessing phases after recording are necessary, such as filtering and often also segmentation. In the following, we will explore segmentation, which can be used in preprocessing of biomedical signals after filtering. We studied linear segmentation, where slopes of short signal segments are computed and divided into different classes according to their values. A segment length of 8 samples for a sampling frequency of 50 kHz employed was best according to our tests and error criteria. Using clustering, we found that less than 10 segment classes is suitable for pattern recognition.; Auditory brainstem responses are used to detect hearing defects in audiology and otoneurology. The use of computer programs for the analysis of such recordings is increasing. To identify their detailed properties a pattern recognition algorithm implemented in an analysis program must be highly reliable. For the recognition process, some preprocessing phases after recording are necessary, such as filtering and often also segmentation. In the following, we will explore segmentation, which can be used in preprocessing of biomedical signals after filtering. We studied linear segmentation, where slopes of short signal segments are computed and divided into different classes according to their values. A segment length of 8 samples for a sampling frequency of 50 kHz employed was best according to our tests and error criteria. Using clustering, we found that less than 10 segment classes is suitable for pattern recognition.",9032010,Article,Final,,Scopus,2-s2.0-0030482661
Higgins M.B.; Carney A.E.; Schulte L.,"Higgins, M.B. (7202136472); Carney, A.E. (7005865289); Schulte, L. (35957987000)",7202136472; 7005865289; 35957987000,Physiological assessment of speech and voice production of adults with hearing loss,1994,Journal of Speech and Hearing Research,37,3,,510,521,11,40,10.1044/jshr.3703.510,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028332117&doi=10.1044%2fjshr.3703.510&partnerID=40&md5=f8b41eb26afa301187d331eec7d36a25,"The purpose of this investigation was to study the impact of hearing loss on phonatory velopharyngeal, and articulatory functioning using a comprehensive physiological approach Electroglottograph (EGG), nasal/oral air flow, and intraoral air pressure signals were recorded simultaneously from adults with impaired and normal hearing as they produced syllables and words of varying physiological difficulty. The individuals with moderate-to- profound hearing loss had good to excellent oral communication skills. Intraoral pressure, nasal air flow, durations of lip, velum, and vocal fold articulations, estimated subglottal pressure, mean phonatory air flow fundamental frequency, and EGG abduction quotient were compared between the two subject groups. Data from the subjects with hearing loss also were compared across aided and unaided conditions to investigate the influence of auditory feedback on speech motor control. The speakers with hearing loss had significantly higher intraoral pressures, subglottal pressures, laryngeal resistances, and fundamental frequencies than those with normal hearing. There was notable between-subject variability. All of the individuals with profound hearing loss had at least one speech/voice physiology measure that fell outside of the normal range, and most of the subjects demonstrated unique clusters of abnormal behaviors. Abnormal behaviors were more evident in the phonatory than articulatory or velopharyngeal systems and were generally consistent with vocal fold hyperconstriction. There was evidence from individual data that vocal fold posturing influenced articulatory timing. The results did not support the idea that the speech production skills of adults with moderate-to-profound hearing loss who are good oral communicators deteriorate when there are increased motoric demands on the velopharyngeal and phonatory mechanism. Although no significant differences were found between the aided and unaided conditions, 7 of 10 subjects showed the same direction of change for subglottal pressure, intraoral pressure, nasal air flow, and the duration of lip and vocal fold articulations. We conclude that physiological assessments provide important information about the speech/voice production abilities of individuals with moderate-to- profound hearing loss and are a valuable addition to standard assessment batteries.",8084183,Article,Final,,Scopus,2-s2.0-0028332117
Homøe P.; Rosborg J.,"Homøe, Preben (6701542980); Rosborg, J. (6603166533)",6701542980; 6603166533,Family cluster of cholesteatoma,2007,Journal of Laryngology and Otology,121,1,,65,67,2,14,10.1017/S0022215106004117,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846846521&doi=10.1017%2fS0022215106004117&partnerID=40&md5=85287a234656869c4dd3bdcfa0da4e86,"Objective: We report an extremely rare case of family clustering of cholesteatoma. Method: Case reports and a review of the world literature concerning cholesteatoma and heredity are presented. Results: The family consists of parents and seven siblings of whom the mother and three sons have been surgically treated for cholesteatoma. All cholesteatomas in the family are acquired and all have a history of otitis media. Cholesteatomas occur with an incidence of 5/100 000 in Greenland, corresponding to two to three new cholesteatoma patients per year among the 57 000 inhabitants of Greenland. The family is very exceptional and interesting for further research concerning heredity in the pathogenesis of acquired cholesteatoma. Conclusion: To our knowledge this is the first report in the world literature of family clustering of acquired cholesteatoma. This case indicates that hereditary factors interplay with other factors in the pathogenesis of cholesteatoma. © 2007 JLO (1984) Limited.",17059626,Review,Final,,Scopus,2-s2.0-33846846521
Kroodsma D.E.; Konishi M.,"Kroodsma, Donald E. (6701696398); Konishi, Masakazu (35546535100)",6701696398; 35546535100,"A suboscine bird (eastern phoebe, Sayornis phoebe) develops normal song without auditory feedback",1991,Animal Behaviour,42,3,,477,487,10,235,10.1016/S0003-3472(05)80047-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026293290&doi=10.1016%2fS0003-3472%2805%2980047-8&partnerID=40&md5=e1eced7064d85a4b7db9aad6fc3e3cdf,"Imitative song development, its requisite auditory feedback, and the underlying neural control of learned song are becoming increasingly well known in songbirds, but the evolution of these characteristics from songbird ancestors is poorly understood. Suboscine flycatchers, which belong to the evolutionary sister group of the oscine songbirds (in the same order, Passeriformes), are thought not to imitate songs from other individuals. This study therefore examines the role of auditory feedback in song development and provides preliminary comments on neural control. Four eastern phoebes, Sayornis phoebe, were collected at 10-12 days of age and hand-reared in the laboratory; at approximately 35 days of age, before they began to sing, the birds were bilaterally deafened by removal of the cochlea. Songs of these phoebes, two males and two females, were judged to be normal when compared with songs of males recorded in nature and to songs of laboratory-reared, intact males and females. Like several non-passerines (representatives of Galliformes and Columbiformes), the eastern phoebe requires no auditory feedback for normal vocal development. Brain sections of phoebes contain no obvious cell clusters like the forebrain song nuclei of songbirds. If some of these nuclei mediate auditory feedback control of song development, the apparent absence of these nuclei in the phoebe is consistent with its ability to develop normal song without auditory feedback. © 1991 The Association for the Study of Animal Behaviour.",,Article,Final,,Scopus,2-s2.0-0026293290
Shiloh Y.; Litvak G.; Ziv Y.; Lehner T.; Sandkuyl L.; Hildesheimer M.; Buchris V.; Cremers F.P.M.; Szabo P.; White B.N.; Holden J.J.A.; Ott J.,"Shiloh, Yosef (7006163089); Litvak, Gilad (7003303067); Ziv, Yael (7007131363); Lehner, Thomas (57207903064); Sandkuyl, Lodewijk (6603956879); Hildesheimer, Minka (7004147251); Buchris, Vered (6507398305); Cremers, Frans P. M. (7005749034); Szabo, Paul (7102397482); White, Bradley N. (58711330400); Holden, Jeanette J. A. (7201609731); Ott, Jurg (7202757548)",7006163089; 7003303067; 7007131363; 57207903064; 6603956879; 7004147251; 6507398305; 7005749034; 7102397482; 58711330400; 7201609731; 7202757548,Genetic mapping of X-linked albinism-deafness syndrome (ADFN) to Xq26.3-q27.1,1990,American Journal of Human Genetics,47,1,,20,27,7,33,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025375331&partnerID=40&md5=24af48556361619a2a27872dd0d070ca,"X-linked albinism-deafness syndrome (ADFN) was described in one Israeli Jewish family and is characterized by congenital nerve deafness and piebaldness. The ADFN mutation probably affects the migration of neural crest-derived precursors of the melanocytes. As a first step toward identifying the ADFN gene, a linkage study was performed to localize the disease locus on the X chromosome. The family was found to be informative for 11 of 107 RFLPs along the X, and two-point analysis showed four of them - factor 9 (F9), DXS91, DXS37, and DNF1-to have definite or suggestive linkage with ADFN. Multipoint linkage analysis indicated two possible orders within this cluster of loci, neither of which was preferable. In both orders F9 was the most distal, and the best estimate for the location of ADFN was between F9 and the next proximal marker (8.6 cM from F9 [Z = 8.1] or 8.3 cM from F9 [Z = 7.9]). These results suggest that the ADFN is at Xq26.3-q27.1. Disagreement between our data and previous localization of DXS91 at Xq11-q13 was resolved by hybridization of the probe pXG-17, which detects the DXS91 locus, to a panel of somatic cell hybrids containing different portions of the X chromosome. This experiment showed that this locus is definitely at Xq24-q26. Together with the linkage data, our results place DXS91 at Xq26 and underscore the importance of using more than one mapping method for the localization of molecular probes.",2349949,Article,Final,,Scopus,2-s2.0-0025375331
Erlandsson S.I.; Rubinstein B.; Axelsson A.; Carlsson S.G.,"Erlandsson, S.I. (6701900928); Rubinstein, B. (7005304208); Axelsson, A. (7102946846); Carlsson, S.G. (7102417771)",6701900928; 7005304208; 7102946846; 7102417771,Psychological dimensions in patients with disabling tinnitus and craniomandibular disorders,1991,British Journal of Audiology,25,1,,15,24,9,45,10.3109/03005369109077860,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025974867&doi=10.3109%2f03005369109077860&partnerID=40&md5=c7da675b52fcc83bc7f66b04e3059a52,"Forty-two patients with severe linnitus and craniomandibular disorders (CMD) arc presented from an audiological and psychological point of view. During a 2-week period, the palients rated their mood and their tinnitus. Based upon mood ratings, palienls were grouped inlo three clusters (high, medium and low mood). The three groups differed in a number of respects, audiological as well as psychological. Patients in the low mood group experienced significantly more intense and severe tinnitus and more daily stress than patients in the high mood group. Ratings of irritation and concentration difficulties seemed to be mood related, and discriminated between patients in the low mood group and patients in the moderate and the high mood groups. Difference in hearing level between the left and the right ear was more pronounced in patients with low mood. There were, however, no significant differences between the groups in the slomalognathic variables. It is concluded that the above mentioned audiological and psychological observations should be considered as potentially important for satisfactory management of individual tinnitus patients. Further studies of the effects of optimally compensated hearing on depressed mood in patients with noise-induced hearing loss (N1HL) and tinnitus are required. © 1991, Informa UK Ltd. All rights reserved.",2012899,Article,Final,,Scopus,2-s2.0-0025974867
Hirayama M.,"Hirayama, Masatoshi (57198200515)",57198200515,Hearing distribution of idiopathic bilateral sensorineural hearing loss,1993,Nippon Jibiinkoka Gakkai Kaiho,96,1,,18,23167,23149,1,10.3950/jibiinkoka.96.18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027352093&doi=10.3950%2fjibiinkoka.96.18&partnerID=40&md5=c1ee663729ad401ccd275ad9408f0e17,"We investigated the mode of progression of idiopathic bilateral sensorineural hearing loss diagnosed in patients seen in the Hearing Loss Clinic at the Department of Otolaryngology of Kitasato University Hospital. Entered into the study were 105 patients whose courses could be observed for more than 3 years. Audiograms were taken 1069 times in these 105 patients and were examined with regard to the distribution of hearing levels by frequency. Idiopathic bilateral sensorineural hearing loss was divided into three stages from the aspect of the time of hearing change stages I, II and III. Hearing clustering points of the respective stages were compared with each other. Proceeding from the peak of stage I to that of stage II was found to take place at the same peak as that of stage III. Another peak hearing clustering point was noted at s.o. © 1993, The Oto-Rhino-Laryngological Society of Japan, Inc. All rights reserved.",8459305,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-0027352093
Rowed D.W.,"Rowed, David W. (7003730478)",7003730478,Chronic Cluster Headache Managed by Nervus Intermedius Section,1990,Headache: The Journal of Head and Face Pain,30,7,,401,406,5,37,10.1111/j.1526-4610.1990.hed3007401.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025153367&doi=10.1111%2fj.1526-4610.1990.hed3007401.x&partnerID=40&md5=f8f4be3123de2d88bb53aa3cf0fa8638,"SYNOPSIS Cluster headache sufferers who become candidates for surgical treatment are those relatively rare patients who are refractory to all attempts at pharmacological relief. Ablative surgical procedures have been directed against either the trigeminal nerve or the nervus intermedius/greater superficial petrosal (NI/GSP) pathway. Both carry nociceptive impulses from the head and face, and the NI also carries parasympathetic fibres which appear to be responsible for the autonomic concomitants of cluster headache. Trigeminal operative procedures are not consistently helpful in chronic cluster headache, while NI section has been shown to give potentially long lasting relief but carries the potential risks of cerebellopontine angle surgery. In eight selected cases of chronic cluster headache we have demonstrated a high early success rate for pain relief, with few complications, in the performance of NI section, combined, when indicated, with microvascular decompression of the trigeminal main sensory root. We believe that cochlear nerve monitoring helps prevent postoperative hearing impairment. An intimate relationship between the NI and arterial loops of the anterior inferior cerebellar artery (AICA) or the internal auditory artery has been frequently observed in our chronic cluster headache patients. Copyright © 1990, Wiley Blackwell. All rights reserved",2401621,Article,Final,,Scopus,2-s2.0-0025153367
Little P.; Bridges A.; Guragain R.; Friedman D.; Prasad R.; Weir N.,"Little, Paul (7201984993); Bridges, Alison (57189680897); Guragain, Rajendra (57189675066); Friedman, Del (57189675358); Prasad, Rakesh (7402378215); Weir, Neil (15822803600)",7201984993; 57189680897; 57189675066; 57189675358; 7402378215; 15822803600,Hearing impairment and ear pathology in Nepal,1993,The Journal of Laryngology & Otology,107,5,,395,400,5,38,10.1017/S0022215100123278,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027194065&doi=10.1017%2fS0022215100123278&partnerID=40&md5=1f1446dcf9ac80401a24e958ec791b63,"A stratified random cluster sample of 15, 845 subjects was performed in two regions of Nepal to determine the prevalence and main causes of hearing impairment (the most common disability) and the prevalence of ear disease. Subjects reporting current ear pain, or ear discharge, or hearing impairment on direct questioning by a Nepali health worker (primary screening failed), had otoscopy and audiometry (using the Liverpool Field Audiometer) performed, and a questionnaire administered relating to past history. In every fifth house subjects who passed the primary screening (1, 716 subjects) were examined to assess the false negative rate of screening. An estimated 16.6 per cent of the study population have hearing impairment (either ear worse than 30 dB hearing threshold level (HTL) 1.0-4.0 kHz, or 50 dB HTL 0.5 kHz), and 7.4 per cent ear drum pathology, equivalent to respectively 2.71 and 1.48 million people extrapolated to the whole of Nepal. Most hearing impairment in the school age group (55.2 per cent) is associated with otitis media or its sequelae. Probably at least 14 per cent of sensorineural deafness is preventable (7 per cent infectious disease, 3.9 per cent trauma, 0.8 per cent noise exposure, 1 per cent cretinism, and 1 per cent abnormal pregnancy or labour). Most individuals reporting current ear pathology (61 per cent) had never attended a health post, and of those receiving ear drop treatment, 84 per cent still had serious pathology. Of subjects who reported ear drop treatment at any time, 31 per cent still had serious pathology. The use of traditional remedies was prevalent. In conclusion this study shows high prevalences of hearing impairment and ear drum pathology. To reduce hearing impairment in Nepal, particularly in the school age group, a priority should be the effective treatment of otitis media. © 1993, JLO (1984) Limited. All rights reserved.",8326217,Article,Final,,Scopus,2-s2.0-0027194065
Metz D.E.; Schiavetti N.; Knight S.D.,"Metz, Dale Evan (7102848460); Schiavetti, Nicholas (6603758130); Knight, Stephen D. (24321013900)",7102848460; 6603758130; 24321013900,The use of artificial neural networks to estimate speech intelligibility from acoustic variables: A preliminary analysis,1992,Journal of Communication Disorders,25,1,,43,53,10,4,10.1016/0021-9924(92)90013-M,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026657023&doi=10.1016%2f0021-9924%2892%2990013-M&partnerID=40&md5=aee9ffeac2c9d6acec2a80dac4c11dbb,Previous research has used regression analysis to attempt to predict the intelligibility of hearing-impaired speakers from acoustic speech parameters. Improvement of prediction may be achieved by the use of computerized artificial neural networks to process mathematically the acoustic input variables as part of the intelligibility process. A preliminary scheme for estimating speech intelligibility from acoustic parameters using a neural network is outlined and preliminary data illustrate its use. © 1992.,1401230,Article,Final,,Scopus,2-s2.0-0026657023
Felix H.; Fraissinette A.D.; Johnsson L.-G.; Gleeson M.J.,"Felix, Heidi (7006242022); Fraissinette, Anne De (57213790544); Johnsson, Lars-Goran (7006729556); Gleeson, Michael J. (55546457100)",7006242022; 57213790544; 7006729556; 55546457100,Morphological features of human reissner's membrane,1993,Acta Oto-Laryngologica,113,3,,321,325,4,16,10.3109/00016489309135817,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027266923&doi=10.3109%2f00016489309135817&partnerID=40&md5=b10cc3bf418b6a875128d96a742dcd3b,"Light and electronmicroscopic investigations of Reissner's membrane were undertaken on 10 cochleae from 6 patients with normal hearing for their age. The membrane consisted of two layers, an epithelium and a mesothelium separated by a basement membrane. The mesothelium was formed by a single thin layer which was intermittently discontinuous. The melanocytes were localized on the mesothelial side of the basement membrane. Their number was 2-4 times greater in the upper half of the basal turn and in the middle turn than elsewhere. The epithelium was much thicker and had more irregular features than the mesothelium. It was composed of two types of epithelial cells, flat and rounded. The flat cells were more regular in shape than the rounded cells and they were mainly distributed in the middle and apical turns. Judging from their structure they were in a resting state. The rounded cells covered a smaller area than the flat ones and had numerous microvilli. They assumed three different shapes, cuboidal, spindle-form and spherical and were arranged in four different patterns, namely bands, strands, whorls and clusters. The rounded cells were the most active according to the composition of the cytoplasm and dominated the cell population in the hook and the lower half of the basal turn where the age-related sensorineural degeneration is most apparent. © 1993 Informa UK Ltd All rights reserved: reproduction in whole or part not permitted.",8517135,Article,Final,,Scopus,2-s2.0-0027266923
Hashino E.; Tanaka Y.; Salvi R.J.; Sokabe M.,"Hashino, Eri (6701761104); Tanaka, Yasuo (57203379640); Salvi, Richard J. (7005412656); Sokabe, Masahiro (7006682509)",6701761104; 57203379640; 7005412656; 7006682509,Hair cell regeneration in the adult budgerigar after kanamycin ototoxicity,1992,Hearing Research,59,1,,46,58,12,50,10.1016/0378-5955(92)90101-R,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026545521&doi=10.1016%2f0378-5955%2892%2990101-R&partnerID=40&md5=780e94dfeb10a982f472b524a99920a7,"Adult budgerigars were given kanamycin at a dose of 200 mg/kg/day for 10 successive days. At 1, 7, 14 and 28 days after the drug treatment, the cochleae of the birds were processed for scanning electron microscopy (SEM). Complete degeneration of sensory hair cells was observed in the basal 55-75% of the basilar papilla immediately after the treatment. Regenerating hair cells, characterized by clusters of microvilli and small apical surfaces, were present in the basal end of the papilla as early as one day post-treatment. During the 28 day recovery period, the number of hair cells progressively increased beginning at the base and spreading toward the apex. Although the appearance of the basilar papilla had improved considerably by 28 days post-treatment, the sensory epithelium still contained a number of pathologies, most noticeably, incomplete restoration of hair cell number in the most apical part of the damaged region and the disorganization of hair cell packing. These remaining pathologies may be responsible for the permanent threshold shifts observed in budgerigars exposed to the same dose of kanamycin treatment (Hashino and Sokabe, 1989). © 1992.",1629046,Article,Final,,Scopus,2-s2.0-0026545521