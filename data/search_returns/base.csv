language,keywords,note,year,url,publisher,author,title,ENTRYTYPE,ID,contributor,howpublished
{en},{Speech and Hearing},"{Source: The Hearing Journal ; volume 73, issue 11, page 8,9 ; ISSN 0745-7472}",2020,http://dx.doi.org/10.1097/01.hj.0000722496.35603.8a,{Ovid Technologies (Wolters Kluwer Health)},"Crowson, Matthew G.",{Artificial Intelligence to Support Hearing Loss Diagnostics},article,1ca093c245a226bbb3ba4db5a51894248dce81f3c64da32bbd0d4d7e31897a9f,,
{en},{Speech and Hearing},"{Source: The Hearing Journal ; volume 74, issue 5, page 20,21 ; ISSN 0745-7472}",2021,http://dx.doi.org/10.1097/01.hj.0000752308.11373.cb,{Ovid Technologies (Wolters Kluwer Health)},"Crowson, Matthew G.",{Predicting Depression from Hearing Loss Using Artificial Intelligence},article,7830a35815abc859a842a02284f1e47f3cdb2748554de6adfcb9d6478c9bde1a,,
{en},{Multidisciplinary},"{Source: Scientific Reports ; volume 12, issue 1 ; ISSN 2045-2322 ; Description: Abstract Despite the significance of predicting the prognosis of idiopathic sudden sensorineural hearing loss (ISSNHL), no predictive models have been established. This study used artificial intelligence to develop prognosis models to predict recovery from ISSNHL. We retrospectively reviewed the medical data of 453 patients with ISSNHL (men, 220; women, 233; mean age, 50.3 years) who underwent treatment at a tertiary hospital between January 2021 and December 2019 and were followed up after 1 month. According to Siegel{\textquoteright}s criteria, 203 patients recovered in 1 month. Demographic characteristics, clinical and laboratory data, and pure-tone audiometry were analyzed. Logistic regression (baseline), a support vector machine, extreme gradient boosting, a light gradient boosting machine, and multilayer perceptron were used. The outcomes were the area under the receiver operating characteristic curve (AUROC) primarily, area under the precision-recall curve, Brier score, balanced accuracy, and F1 score. The light gradient boosting machine model had the best AUROC and balanced accuracy. Together with multilayer perceptron, it was also significantly superior to logistic regression in terms of AUROC. Using the SHapley Additive exPlanation method, we found that the initial audiogram shape is the most important prognostic factor. Machine/deep learning methods were successfully established to predict the prognosis of ISSNHL.}",2022,http://dx.doi.org/10.1038/s41598-022-07881-2,{Springer Science and Business Media LLC},"Lee, Min Kyu AND Jeon, Eun-Tae AND Baek, Namyoung AND Kim, Jeong Hwan AND Rah, Yoon Chan AND Choi, June",{Prediction of hearing recovery in unilateral sudden sensorineural hearing loss using artificial intelligence},article,9158d0bbce26d12ea481340f7390bb51b416245de56f219c4d04ed133ca6b2ea,{Korea University Grants},
{EN},{Medicine},"{Source: Scientific Reports, Vol 12, Iss 1, Pp 1-10 (2022) ; Description: Abstract Despite the significance of predicting the prognosis of idiopathic sudden sensorineural hearing loss (ISSNHL), no predictive models have been established. This study used artificial intelligence to develop prognosis models to predict recovery from ISSNHL. We retrospectively reviewed the medical data of 453 patients with ISSNHL (men, 220; women, 233; mean age, 50.3 years) who underwent treatment at a tertiary hospital between January 2021 and December 2019 and were followed up after 1 month. According to Siegel{\textquoteright}s criteria, 203 patients recovered in 1 month. Demographic characteristics, clinical and laboratory data, and pure-tone audiometry were analyzed. Logistic regression (baseline), a support vector machine, extreme gradient boosting, a light gradient boosting machine, and multilayer perceptron were used. The outcomes were the area under the receiver operating characteristic curve (AUROC) primarily, area under the precision-recall curve, Brier score, balanced accuracy, and F1 score. The light gradient boosting machine model had the best AUROC and balanced accuracy. Together with multilayer perceptron, it was also significantly superior to logistic regression in terms of AUROC. Using the SHapley Additive exPlanation method, we found that the initial audiogram shape is the most important prognostic factor. Machine/deep learning methods were successfully established to predict the prognosis of ISSNHL.}",2022,https://doi.org/10.1038/s41598-022-07881-2,{Nature Portfolio},Min Kyu Lee AND Eun-Tae Jeon AND Namyoung Baek AND Jeong Hwan Kim AND Yoon Chan Rah AND June Choi,{Prediction of hearing recovery in unilateral sudden sensorineural hearing loss using artificial intelligence},article,6cfbbc993d05376d1be834ec593581d78e83499da31cdf53234964d7d2ee2282,,
{EN},{hearing-loss symptoms},"{Source: Sustainability; Volume 13; Issue 10; Pages: 5406 ; Description: Multidisciplinary Digital Publishing Institute ; Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively.}",2021,https://doi.org/10.3390/su13105406,,Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},misc,06fe4d8387ec01609152b04cdfc03887f18094b39aeedf0d3f45812e7a44c757,,
{EN},{hearing-loss symptoms},"{Source: Sustainability, Vol 13, Iss 5406, p 5406 (2021) ; Description: Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively.}",2021,https://doi.org/10.3390/su13105406,{MDPI AG},Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},article,1d3953ebf37cb3b504828eee1356c2781bd59a6d07fd8e5604d88232c4955a6c,,
{en},{Multidisciplinary},"{Source: Arabian Journal for Science and Engineering ; volume 48, issue 11, page 14883-14899 ; ISSN 2193-567X 2191-4281}",2023,http://dx.doi.org/10.1007/s13369-023-07927-1,{Springer Science and Business Media LLC},"Sankari, V. M. Raja AND Snekhalatha, U. AND Murugappan, M. AND Chowdhury, Muhammad E. H. AND Chamkha, Zeinab A.",{Artificial Intelligence-Based Hearing Loss Detection Using Acoustic Threshold and Speech Perception Level},article,7a4940223e75199d0c3ec54178a93042eb93b1f0ffd127a275252e880aa80978,,
,,"{Description: Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively. ; hearing-loss symptoms; frequent pattern growth; multivariate Bernoulli na{\""\i}ve Bayes; machine learning techniques; identification model}",,https://www.mdpi.com/2071-1050/13/10/5406/pdf,,Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},article,a5b4385ce702d812526c42ef9f2ae1b19035c368edbe20d957c9cfe3988733cc,,
{en},"{Public Health, Environmental and Occupational Health}","{Source: International Archives of Occupational and Environmental Health ; volume 88, issue 6, page 779-787 ; ISSN 0340-0131 1432-1246}",2014,http://dx.doi.org/10.1007/s00420-014-1004-z,{Springer Science and Business Media LLC},"Aliabadi, Mohsen AND Farhadian, Maryam AND Darvishi, Ebrahim",{Prediction of hearing loss among the noise-exposed workers in a steel factory using artificial intelligence approach},article,5a61a98a3db23713ad7171e66525e81493e217e2f750c1bf824fdab315fea05a,,
{en},{Speech and Hearing},"{Source: The Hearing Journal ; volume 72, issue 6, page 8,9 ; ISSN 0745-7472}",2019,http://dx.doi.org/10.1097/01.hj.0000558452.52280.9b,{Ovid Technologies (Wolters Kluwer Health)},"Shew, Matthew AND Staecker, Hinrich",{Using Machine Learning to Predict Sensorineural Hearing Loss},article,0450550955d30e032e8f8b74552d710d13dd4a8de0b7c0826e5d2778e65705df,,
{en},{Q Science (General)},"{Description: There is potential knowledge inherent in vast amounts of untapped and possibly valuable data generated by healthcare providers. Clinicians rely in their knowledge and experience and the basic diagnostic procedure to determine the likely symptom of a disease. Sometimes, many stages of diagnosis and longer procedures can leads to longer consultation hours and can consequently results to longer waiting time for other patients that need to be attended to. This can results to stress and anxiety on the part of those patients. This research presents an efficient way to facilitate the hearing loss symptoms diagnosis process by designing a symptoms identification model that efficiently identify hearing loss symptoms based on air and bone conduction pure-tone audiometry data. The model is implemented using both unsupervised and supervised machine learning techniques in the form of Frequent Pattern Growth (FP-Growth) algorithm as feature transformation method and multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. In order to find, the correlation that exist between the hearing thresholds and symptoms of hearing loss, FP-Growth and association rule algorithms were first used to experiment with a small sample and large sample datasets. The result of these two experiments showed the existence of this relationship and the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing loss symptoms was found to be efficient with very minimum error rate.}",2014,http://eprints.utem.edu.my/id/eprint/14995/,,Nasiru Garba Noma,{Identification model for hearing loss symptoms using machine learning techniques},misc,9efb3b8e25ec5877aed1e2dc9dea53db002466550b2b4341f125a2ea19b87bb4,,{Thesis}
{en},{Hearing loss},"{Description: University of Toronto ; Objectives: Hearing loss is the most common sensory loss in humans and carries an enhanced risk of depression. No prior studies have attempted a contemporary machine learning approach to predict depression using subjective and objective hearing loss predictors. The objective was to deploy supervised machine learning to predict scores on a validated depression scale using subjective and objective audiometric variables and other health determinant predictors. Design: A large predictor set of health determinants from the National Health and Nutrition Examination Survey 2015{\textendash}2016 database was used to predict adults{\textquoteright} scores on a validated instrument to screen for the presence and severity of depression (Patient Health Questionnaire-9 [PHQ-9]). After model training, the relative influence of individual predictors on depression scores was stratified and analyzed. Model prediction performance was determined by prediction error metrics. Results: The test set mean absolute error was 3.03 (95\% confidence interval: 2.91 to 3.14) and 2.55 (95\% confidence interval: 2.48 to 2.62) on datasets with audiology-only predictors and all predictors, respectively, on the PHQ-9{\textquoteright}s 27-point scale. Participants{\textquoteright} self-reported frustration when talking to members of family or friends due to hearing loss was the fifth-most influential of all predictors. Of the top 10 most influential audiometric predictors, five were related to social contexts, two for significant noise exposure, two objective audiometric parameters, and one presence of bothersome tinnitus. Conclusions: Machine learning algorithms can accurately predict PHQ-9 depression scale scores from National Health and Nutrition Examination Survey data. The most influential audiometric predictors of higher scores on a validated depression scale were social dynamics of hearing loss and not objective audiometric testing. Such models could be useful in predicting depression scale scores at the point-of-care in conjunction with a standard audiologic assessment.}",2021,http://hdl.handle.net/1807/106608,,"Crowson, Matthew G AND Franck, Kevin H AND Rosella, Laura C AND Chan, Timothy C Y",{Predicting Depression From Hearing Loss Using Machine Learning},misc,0f81e5dfe7857e646ffd63e83e817d1f578fd36efd770bc906481bef510637b3,,
{en},{Speech and Hearing},"{Source: Ear & Hearing ; volume 42, issue 4, page 982-989 ; ISSN 1538-4667 ; Description: Objectives: Hearing loss is the most common sensory loss in humans and carries an enhanced risk of depression. No prior studies have attempted a contemporary machine learning approach to predict depression using subjective and objective hearing loss predictors. The objective was to deploy supervised machine learning to predict scores on a validated depression scale using subjective and objective audiometric variables and other health determinant predictors. Design: A large predictor set of health determinants from the National Health and Nutrition Examination Survey 2015{\textendash}2016 database was used to predict adults{\textquoteright} scores on a validated instrument to screen for the presence and severity of depression (Patient Health Questionnaire-9 [PHQ-9]). After model training, the relative influence of individual predictors on depression scores was stratified and analyzed. Model prediction performance was determined by prediction error metrics. Results: The test set mean absolute error was 3.03 (95\% confidence interval: 2.91 to 3.14) and 2.55 (95\% confidence interval: 2.48 to 2.62) on datasets with audiology-only predictors and all predictors, respectively, on the PHQ-9{\textquoteright}s 27-point scale. Participants{\textquoteright} self-reported frustration when talking to members of family or friends due to hearing loss was the fifth-most influential of all predictors. Of the top 10 most influential audiometric predictors, five were related to social contexts, two for significant noise exposure, two objective audiometric parameters, and one presence of bothersome tinnitus. Conclusions: Machine learning algorithms can accurately predict PHQ-9 depression scale scores from National Health and Nutrition Examination Survey data. The most influential audiometric predictors of higher scores on a validated depression scale were social dynamics of hearing loss and not objective audiometric testing. Such models could be useful in predicting depression scale scores at the point-of-care in conjunction with a standard audiologic assessment.}",2021,http://dx.doi.org/10.1097/aud.0000000000000993,{Ovid Technologies (Wolters Kluwer Health)},"Crowson, Matthew G. AND Franck, Kevin H. AND Rosella, Laura C. AND Chan, Timothy C. Y.",{Predicting Depression From Hearing Loss Using Machine Learning},article,ade0f3a38984d43f1b262c79938ec6d866f50b8c25633ee1f1431224ce907dda,,
{en},,"{Description: A research report submitted in partial fulfilment of the requirements for the degree Master of Arts in eScience to the Faculty of Humanities, School of Social Sciences, University of the Witwatersrand, 2021 ; Deafness is one of the most commonly occurring birth conditions in children worldwide creating an increasingly significant global health concern. Failure to early identify hearing loss and provide subsequent intervention services will likely have negative consequences on language, cognition, and socio-emotional development. Current approaches in detecting neonatal hearing loss are limited specifically in developing countries such as South Africa. Machine learning offers an opportunity to create models which could predict the likelihood of a hearing loss occurring in high-risk neonates allowing for early identification and intervention to occur. Thus, the main aim of the current study was to use predictive modelling to predict the likelihood of hearing loss in high-risk neonates. The study sample comprised of 12 044 male and female hearing and deaf and/or hard-of-hearing South African children who either formed part of the HI HOPES or universal newborn screening programme implemented at the Netcare Hospital Group. A nonexperimental, predictive modelling design was employed for the purpose of the current study. Predictive variables used in the current study included mode of delivery, prematurity, gestational age, family history of hearing loss, extracorporeal membrane oxygenation (ECMO), in-utero infections, craniofacial anomalies, physical findings, syndromes associated with hearing loss, neurodegenerative disorders, cultural-positive infections, meningitis, maternal and/or infant HIV infection, and ototoxic medication. The results from several Chi-Square (X 2 ) analyses showed significant correlations between each birth type (i.e., natural, elective caesarean, emergency caesarean), prematurity, family history, ECMO, in-utero infection, craniofacial anomalies, physical findings, syndromes associated with ...}",2021,https://hdl.handle.net/10539/33857,,"Ismail, Safiyyah",{Detecting hearing loss in high-risk neonates using machine learning},misc,fb961a501a1ad53fc0ff41c44c4037706d411d7fa522533bcb30c8b0f49189b4,,{Thesis}
{EN},{sudden hearing loss},"{Source: Clinical and Experimental Otorhinolaryngology, Vol 13, Iss 2, Pp 148-156 (2020) ; Description: Objectives. Prognosticating idiopathic sudden sensorineural hearing loss (ISSNHL) is an important challenge. In our study, a dataset was split into training and test sets and cross-validation was implemented on the training set, thereby determining the hyperparameters for machine learning models with high test accuracy and low bias. The effectiveness of the following five machine learning models for predicting the hearing prognosis in patients with ISSNHL after 1 month of treatment was assessed: adaptive boosting, K-nearest neighbor, multilayer perceptron, random forest (RF), and support vector machine (SVM). Methods. The medical records of 523 patients with ISSNHL admitted to Korea University Ansan Hospital between January 2010 and October 2017 were retrospectively reviewed. In this study, we analyzed data from 227 patients (recovery, 106; no recovery, 121) after excluding those with missing data. To determine risk factors, statistical hypothesis tests (e.g., the two-sample t-test for continuous variables and the chi-square test for categorical variables) were conducted to compare patients who did or did not recover. Variables were selected using an RF model depending on two criteria (mean decreases in the Gini index and accuracy). Results. The SVM model using selected predictors achieved both the highest accuracy (75.36\%) and the highest F-score (0.74) on the test set. The RF model with selected variables demonstrated the second-highest accuracy (73.91\%) and F-score (0.74). The RF model with the original variables showed the same accuracy (73.91\%) as that of the RF model with selected variables, but a lower F-score (0.73). All the tested models, except RF, demonstrated better performance after variable selection based on RF. Conclusion. The SVM model with selected predictors was the best-performing of the tested prediction models. The RF model with selected predictors was the second-best model. Therefore, machine learning models can be used to predict hearing recovery in patients with ISSNHL.}",2020,https://doi.org/10.21053/ceo.2019.01858,{Korean Society of Otorhinolaryngology-Head and Neck Surgery},Keon Vin Park AND Kyoung Ho Oh AND Yong Jun Jeong AND Jihye Rhee AND Mun Soo Han AND Sung Won Han AND June Choi,{Machine Learning Models for Predicting Hearing Prognosis in Unilateral Idiopathic Sudden Sensorineural Hearing Loss},article,b790b3454f62fd6dcf0f064b80c111ee4b834caff76a2f1da923873d9dfe116d,,
{en},{Otorhinolaryngology},"{Source: Otolaryngology–Head and Neck Surgery ; volume 169, issue 3, page 504-513 ; ISSN 0194-5998 1097-6817 ; Description: Abstract Objective Hearing loss (HL) is highly prevalent, yet underrecognized and underdiagnosed. Lack of standardized screening, awareness, cost, and access to hearing testing present barriers to HL identification. To facilitate prescreening and selection of patients who warrant audiometric evaluation, we developed a machine learning (ML) model to predict speech-frequency pure-tone average (PTA). Study Design Cross-sectional study. Setting National Health and Nutrition Examination Survey (NHANES). Methods The cohort included 8918 adults (>=20 years) who completed audiometric testing with NHANES (2012-2018). The primary outcome measure was the prediction of better hearing ear speech-frequency PTA. Relevant predictors included demographics, medical conditions, and subjective assessment of hearing. Supervised ML with a tree-based architecture was used. Regression performance was determined by the mean absolute error (MAE) with binary classification assessed with area under the receiver operating characteristic curve (AUC). Results Using the full set of predictors, the test set MAE between the ML-predicted and actual PTA was 5.29 dB HL (95\% confidence interval [CI]: 4.97-5.61). The 5 most influential predictors of higher PTA were increased age, worse subjective hearing, male gender, increased body mass index, and history of smoking. The 5-factor abbreviated model performed comparably to the extended feature set with MAE 5.36 (95\% CI: 5.03-5.69) and AUC for PTA > 25 dB HL of 0.92 (95\% CI: 0.90-0.94). Conclusion The ML model was able to predict PTA with patient demographics, clinical factors, and subjective hearing status. ML-based prediction may be used to identify individuals who could benefit most from audiometric evaluation.}",2023,http://dx.doi.org/10.1002/ohn.288,{Wiley},"Gathman, Tyler J. AND Choi, Janet S. AND Vasdev, Ranveer M.S. AND Schoephoerster, Jamee A. AND Adams, Meredith E.","{Machine Learning Prediction of Objective Hearing Loss With Demographics, Clinical Factors, and Subjective Hearing Status}",article,a39e8777d5fda8d6afad8d3fe56185a984361bcf4ce669d953067ea443998251,,
{en},{Otorhinolaryngology},"{Source: Clinical Otolaryngology ; volume 43, issue 3, page 868-874 ; ISSN 1749-4478 1749-4486 ; Description: Objective Sudden sensorineural hearing loss ( SSHL ) is a multifactorial disorder with high heterogeneity, thus the outcomes vary widely. This study aimed to develop predictive models based on four machine learning methods for SSHL , identifying the best performer for clinical application. Design Single-centre retrospective study. Setting Chinese People{\textquoteright}s liberation army ( PLA ) hospital, Beijing, China. Participants A total of 1220 in-patient SSHL patients were enrolled between June 2008 and December 2015. Main outcome measures An advanced deep learning technique, deep belief network ( DBN ), together with the conventional logistic regression ( LR ), support vector machine ( SVM ) and multilayer perceptron ( MLP ) were developed to predict the dichotomised hearing outcome of SSHL by inputting six feature collections derived from 149 potential predictors. Accuracy, precision, recall, F -score and the area under the receiver operator characteristic curves ( ROC - AUC ) were exploited to compare the prediction performance of different models. Results Overall the best predictive ability was provided by the DBN model when tested in the raw data set with 149 variables, achieving an accuracy of 77.58\% and AUC of 0.84. Nevertheless, DBN yielded inferior performance after feature pruning. In contrast, the LR , SVM and MLP models demonstrated opposite trend as the greatest individual prediction powers were obtained when included merely three variables, with the ROC - AUC ranging from 0.79 to 0.81, and then decreased with the increasing size of input features combinations. Conclusions With the input of enough features, DBN can be a robust prediction tool for SSHL . But LR is more practical for early prediction in routine clinical application using three readily available variables, that is time elapse between symptom onset and study entry, initial hearing level and audiogram.}",2018,http://dx.doi.org/10.1111/coa.13068,{Wiley},"Bing, D. AND Ying, J. AND Miao, J. AND Lan, L. AND Wang, D. AND Zhao, L. AND Yin, Z. AND Yu, L. AND Guan, J. AND Wang, Q.",{Predicting the hearing outcome in sudden sensorineural hearing loss via machine learning models},article,9351be112ef3ba4a47ea91bd0fde47f144b80b20c796e61557766d0af8340db0,{National Natural Science Foundation of China},
{en},"{Public Health, Environmental and Occupational Health}","{Source: International Archives of Occupational and Environmental Health ; volume 94, issue 5, page 1097-1111 ; ISSN 0340-0131 1432-1246 ; Description: Abstract Purpose Noise-induced hearing loss (NIHL) is a global issue that impacts people{\textquoteright}s life and health. The current review aims to clarify the contributions and limitations of applying machine learning (ML) to predict NIHL by analyzing the performance of different ML techniques and the procedure of model construction. Methods The authors searched PubMed, EMBASE and Scopus on November 26, 2020. Results Eight studies were recruited in the current review following defined inclusion and exclusion criteria. Sample size in the selected studies ranged between 150 and 10,567. The most popular models were artificial neural networks ( n = 4), random forests ( n = 3) and support vector machines ( n = 3). Features mostly correlated with NIHL and used in the models were: age ( n = 6), duration of noise exposure ( n = 5) and noise exposure level ( n = 4). Five included studies used either split-sample validation ( n = 3) or ten-fold cross-validation ( n = 2). Assessment of accuracy ranged in value from 75.3\% to 99\% with a low prediction error/root-mean-square error in 3 studies. Only 2 studies measured discrimination risk using the receiver operating characteristic (ROC) curve and/or the area under ROC curve. Conclusion In spite of high accuracy and low prediction error of machine learning models, some improvement can be expected from larger sample sizes, multiple algorithm use, completed reports of model construction and the sufficient evaluation of calibration and discrimination risk.}",2021,http://dx.doi.org/10.1007/s00420-020-01648-w,{Springer Science and Business Media LLC},"Chen, Feifan AND Cao, Zuwei AND Grais, Emad M. AND Zhao, Fei",{Contributions and limitations of using machine learning to predict noise-induced hearing loss},article,97f90608146d34971202581775c69e1f63e52c304528f7755f3ca31a90f7a3d2,{National Natural Science Foundation of China},
{en},{Review Article},"{Source: Int Arch Occup Environ Health ; Description: Springer Berlin Heidelberg ; PURPOSE: Noise-induced hearing loss (NIHL) is a global issue that impacts people{\textquoteright}s life and health. The current review aims to clarify the contributions and limitations of applying machine learning (ML) to predict NIHL by analyzing the performance of different ML techniques and the procedure of model construction. METHODS: The authors searched PubMed, EMBASE and Scopus on November 26, 2020. RESULTS: Eight studies were recruited in the current review following defined inclusion and exclusion criteria. Sample size in the selected studies ranged between 150 and 10,567. The most popular models were artificial neural networks (n = 4), random forests (n = 3) and support vector machines (n = 3). Features mostly correlated with NIHL and used in the models were: age (n = 6), duration of noise exposure (n = 5) and noise exposure level (n = 4). Five included studies used either split-sample validation (n = 3) or ten-fold cross-validation (n = 2). Assessment of accuracy ranged in value from 75.3\% to 99\% with a low prediction error/root-mean-square error in 3 studies. Only 2 studies measured discrimination risk using the receiver operating characteristic (ROC) curve and/or the area under ROC curve. CONCLUSION: In spite of high accuracy and low prediction error of machine learning models, some improvement can be expected from larger sample sizes, multiple algorithm use, completed reports of model construction and the sufficient evaluation of calibration and discrimination risk.}",2021,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8238747/,,"Chen, Feifan AND Cao, Zuwei AND Grais, Emad M. AND Zhao, Fei",{Contributions and limitations of using machine learning to predict noise-induced hearing loss},misc,b7971ce26b8a8e9d5764d4442c32f627faab4a07a8bf7266a797f67d162bbf72,,
{en},{Article},"{Source: Ear Hear ; Description: OBJECTIVES. A confluence of recent developments in cloud computing, real-time web audio and machine learning psychometric function estimation has made wide dissemination of sophisticated turn-key audiometric assessments possible. The authors have combined these capabilities into an online (i.e., web-based) pure-tone audiogram estimator intended to empower researchers and clinicians with advanced hearing tests without the need for custom programming. The objective of this study is to assess the accuracy and reliability of this new online machine learning audiogram method relative to a commonly used hearing threshold estimation technique also implemented online for the first time in the same platform. DESIGN. The authors performed air-conduction pure-tone audiometry on 21 participants between the ages of 19 and 79 years (mean 41, standard deviation 21) exhibiting a wide range of hearing abilities. For each ear, two repetitions of online machine learning audiogram estimation and two repetitions of online modified Hughson-Westlake ascending-descending audiogram estimation were acquired by an audiologist using the online software tools. The estimated hearing thresholds of these two techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). RESULTS. The two threshold estimation methods delivered very similar threshold estimates at standard audiogram frequencies. Specifically, the mean absolute difference between threshold estimates was 3.24 {\textpm} 5.15 dB. The mean absolute differences between repeated measurements of the online machine learning procedure and between repeated measurements of the Hughson-Westlake procedure were 2.85 {\textpm} 6.57 dB and 1.88 {\textpm} 3.56 respectively. The machine learning method generated estimates of both threshold and spread (i.e., the inverse of psychometric slope) continuously across the entire frequency range tested from fewer samples on average than the modified Hughson-Westlake procedure required to estimate 6 discrete thresholds. CONCLUSIONS. Online machine ...}",2019,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6476703/,,"Barbour, Dennis L. AND Howard, Rebecca T. AND Song, Xinyu D. AND Metzger, Nikki AND Sukesan, Kiron A. AND DiLorenzo, James C. AND Snyder, Braham R. D. AND Chen, Jeff Y. AND Degen, Eleanor A. AND Buchbinder, Jenna M. AND Heisey, Katherine L.",{Online Machine Learning Audiometry},misc,a7c4618922f24f4bdfd93182b65edd0510b2073a9f2a4a703da70a976ef954f9,,
{en},{Speech and Hearing},"{Source: Ear & Hearing ; volume 40, issue 4, page 918-926 ; ISSN 0196-0202 ; Description: Objectives: A confluence of recent developments in cloud computing, real-time web audio and machine learning psychometric function estimation has made wide dissemination of sophisticated turn-key audiometric assessments possible. The authors have combined these capabilities into an online (i.e., web-based) pure-tone audiogram estimator intended to empower researchers and clinicians with advanced hearing tests without the need for custom programming or special hardware. The objective of this study was to assess the accuracy and reliability of this new online machine learning audiogram method relative to a commonly used hearing threshold estimation technique also implemented online for the first time in the same platform. Design: The authors performed air conduction pure-tone audiometry on 21 participants between the ages of 19 and 79 years (mean 41, SD 21) exhibiting a wide range of hearing abilities. For each ear, two repetitions of online machine learning audiogram estimation and two repetitions of online modified Hughson-Westlake ascending-descending audiogram estimation were acquired by an audiologist using the online software tools. The estimated hearing thresholds of these two techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). Results: The two threshold estimation methods delivered very similar threshold estimates at standard audiogram frequencies. Specifically, the mean absolute difference between threshold estimates was 3.24 {\textpm} 5.15 dB. The mean absolute differences between repeated measurements of the online machine learning procedure and between repeated measurements of the Hughson-Westlake procedure were 2.85 {\textpm} 6.57 dB and 1.88 {\textpm} 3.56 dB, respectively. The machine learning method generated estimates of both threshold and spread (i.e., the inverse of psychometric slope) continuously across the entire frequency range tested from fewer samples on average than the modified Hughson-Westlake procedure required to estimate six discrete thresholds. Conclusions: Online ...}",2018,http://dx.doi.org/10.1097/aud.0000000000000669,{Ovid Technologies (Wolters Kluwer Health)},"Barbour, Dennis L. AND Howard, Rebecca T. AND Song, Xinyu D. AND Metzger, Nikki AND Sukesan, Kiron A. AND DiLorenzo, James C. AND Snyder, Braham R. D. AND Chen, Jeff Y. AND Degen, Eleanor A. AND Buchbinder, Jenna M. AND Heisey, Katherine L.",{Online Machine Learning Audiometry},article,88b7dc44d97ff300a514a86fdd0ce02a4a705982334dcbf84b3ec4310aca5165,,
{en},{Article},"{Source: Ear Hear ; Description: OBJECTIVES: When one ear of an individual can hear significantly better than the other ear, evaluating the worse ear with loud probe tones may require delivering masking noise to the better ear in order to prevent the probe tones from inadvertently being heard by the better ear. Current masking protocols are confusing, laborious and time consuming. Adding a standardized masking protocol to an active machine learning audiogram procedure could potentially alleviate all of these drawbacks by dynamically adapting the masking as needed for each individual. The goal of this study is to determine the accuracy and efficiency of automated machine learning masking for obtaining true hearing thresholds. DESIGN: Dynamically masked automated audiograms were collected for 29 participants between the ages of 21 and 83 (mean 43, SD 20) with a wide range of hearing abilities. Normal hearing listeners were given unmasked and masked machine learning audiogram tests. Listeners with hearing loss were given a standard audiogram test by an audiologist, with masking stimuli added as clinically determined, followed by a masked machine learning audiogram test. The hearing thresholds estimated for each pair of techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). RESULTS: Masked and unmasked machine learning audiogram threshold estimates matched each other well in normal hearing listeners, with a mean absolute difference between threshold estimates of 3.4 dB. Masked machine learning audiogram thresholds also matched well the thresholds determined by a conventional masking procedure, with a mean absolute difference between threshold estimates for listeners with low asymmetry and high asymmetry between the ears, respectively, of 4.9 dB and 2.6 dB. Notably, out of 6200 masked machine learning audiogram tone deliveries for this study, no instances of tones detected by the non test ear were documented. The machine learning methods were also generally faster than the manual methods, and for some ...}",2020,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7725866/,,"Heisey, Katherine L. AND Walker, Alexandra M. AND Xie, Kevin AND Abrams, Jenna M. AND Barbour, Dennis L.",{Dynamically Masked Audiograms with Machine Learning Audiometry},misc,3e72029d783983f9a26ea2e633fb2dd0616c5f9c26635150253d2e280f3a4dea,,
{en},{Speech and Hearing},"{Source: The Hearing Journal ; volume 74, issue 3, page 40,43,44 ; ISSN 0745-7472}",2021,http://dx.doi.org/10.1097/01.hj.0000737592.24476.88,{Ovid Technologies (Wolters Kluwer Health)},"Barbour, Dennis L. AND Wasmann, Jan-Willem A.",{Performance and Potential of Machine Learning Audiometry},article,cad542bcda71321acdfbc54b789c5e67f51a582969693937b6a03462d47e6b47,,
{en},{Speech and Hearing},"{Source: Ear & Hearing ; volume 41, issue 6, page 1692-1702 ; ISSN 1538-4667 0196-0202 ; Description: Objectives: When one ear of an individual can hear significantly better than the other ear, evaluating the worse ear with loud probe tones may require delivering masking noise to the better ear to prevent the probe tones from inadvertently being heard by the better ear. Current masking protocols are confusing, laborious, and time consuming. Adding a standardized masking protocol to an active machine learning audiogram procedure could potentially alleviate all of these drawbacks by dynamically adapting the masking as needed for each individual. The goal of this study is to determine the accuracy and efficiency of automated machine learning masking for obtaining true hearing thresholds. Design: Dynamically masked automated audiograms were collected for 29 participants between the ages of 21 and 83 (mean 43, SD 20) with a wide range of hearing abilities. Normal-hearing listeners were given unmasked and masked machine learning audiogram tests. Listeners with hearing loss were given a standard audiogram test by an audiologist, with masking stimuli added as clinically determined, followed by a masked machine learning audiogram test. The hearing thresholds estimated for each pair of techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz). Results: Masked and unmasked machine learning audiogram threshold estimates matched each other well in normal-hearing listeners, with a mean absolute difference between threshold estimates of 3.4 dB. Masked machine learning audiogram thresholds also matched well the thresholds determined by a conventional masking procedure, with a mean absolute difference between threshold estimates for listeners with low asymmetry and high asymmetry between the ears, respectively, of 4.9 and 2.6 dB. Notably, out of 6200 masked machine learning audiogram tone deliveries for this study, no instances of tones detected by the nontest ear were documented. The machine learning methods were also generally faster than the manual methods, and for some listeners, ...}",2020,http://dx.doi.org/10.1097/aud.0000000000000891,{Ovid Technologies (Wolters Kluwer Health)},"Heisey, Katherine L. AND Walker, Alexandra M. AND Xie, Kevin AND Abrams, Jenna M. AND Barbour, Dennis L.",{Dynamically Masked Audiograms With Machine Learning Audiometry},article,52d5bb287d56eb3a5df4115ba7d346be01cc12c2d4f85d9c5b1bca40ab4afeda,,
,,{Description: Washington University in St. Louis},2017,https://dx.doi.org/10.7936/k77s7n6j,,"Song, Xinyu",{Improving Pure-Tone Audiometry Using Probabilistic Machine Learning Classification ...},misc,f67243d7bf355b68663826c6c99284b6a9b5f39402c0e0b138de2a8c97cdda4e,,
{English (en)},{Audiometry},"{Source: McKelvey School of Engineering Theses & Dissertations ; Description: Washington University Open Scholarship ; Hearing loss is a critical public health concern, affecting hundreds millions of people worldwide and dramatically impacting quality of life for affected individuals. While treatment techniques have evolved in recent years, methods for assessing hearing ability have remained relatively unchanged for decades. The standard clinical procedure is the modified Hughson-Westlake procedure, an adaptive pure-tone detection task that is typically performed manually by audiologists, costing millions of collective hours annually among healthcare professionals. In addition to the high burden of labor, the technique provides limited detail about an individual{\textquoteright}s hearing ability, estimating only detection thresholds at a handful of pre-defined pure-tone frequencies (a threshold audiogram). An efficient technique that produces a detailed estimate of the audiometric function, including threshold and spread, could allow for better characterization of particular hearing pathologies and provide more diagnostic value. Parametric techniques exist to efficiently estimate multidimensional psychometric functions, but are ill-suited for estimation of audiometric functions because these functions cannot be easily parameterized. The Gaussian process is a compelling machine learning technique for inference of nonparametric multidimensional functions using binary data. The work described in this thesis utilizes Gaussian process classification to build an automated framework for efficient, high-resolution estimation of the full audiometric function, which we call the machine learning audiogram (MLAG). This Bayesian technique iteratively computes a posterior distribution describing its current belief about detection probability given the current set of observed pure tones and detection responses. The posterior distribution can be used to provide a current point estimate of the psychometric function as well as to select an informative query point for the next stimulus to be provided to the listener. The Gaussian process covariance function ...}",2017,https://openscholarship.wustl.edu/eng_etds/310,,"Song, Xinyu",{Improving Pure-Tone Audiometry Using Probabilistic Machine Learning Classification},misc,eaa067e7ff40e6a8a6debde603644ec387f0cef7fb33032e8602f746028371d5,,
{en},{Neurology (clinical)},"{Source: Otology & Neurotology ; volume 43, issue 5, page e530-e534 ; ISSN 1531-7129 1537-4505 ; Description: Objective: The aim of this study is to compare machine learning algorithms and established rule-based evaluations in screening audiograms for the purpose of diagnosing vestibular schwannomas. A secondary aim is to assess the performance of rule-based evaluations for predicting vestibular schwannomas using the largest dataset in the literature. Study Design: Retrospective case-control study. Setting: Tertiary referral center. Patients: Seven hundred sixty seven adult patients with confirmed vestibular schwannoma and a pretreatment audiogram on file and 2000 randomly selected adult controls with audiograms. Intervention(s): Audiometric data were analyzed using machine learning algorithms and standard rule-based criteria for defining asymmetric hearing loss. Main Outcome Measures: The primary outcome is the ability to identify patients with vestibular schwannomas based on audiometric data alone, using machine learning algorithms and rule-based formulas. The secondary outcome is the application of conventional rule-based formulas to a larger dataset using advanced computational techniques. Results: The machine learning algorithms had mildly improved specificity in some fields compared with rule-based evaluations and had similar sensitivity to previous rule-based evaluations in diagnosis of vestibular schwannomas. Conclusions: Machine learning algorithms perform similarly to rule-based evaluations in identifying patients with vestibular schwannomas based on audiometric data alone. Performance of established rule-based formulas was consistent with earlier performance metrics, when analyzed using a large dataset.}",2022,http://dx.doi.org/10.1097/mao.0000000000003539,{Ovid Technologies (Wolters Kluwer Health)},"Carey, Grace E. AND Jacobson, Clare E. AND Warburton, Alyssa N. AND Biddle, Elliot AND Mannarelli, Greg AND Wilson, Michael AND Stucken, Emily Z.",{Machine Learning for Vestibular Schwannoma Diagnosis Using Audiometrie Data Alone},article,3f85d303f5f9cda2bfd30a10b72927341fda4a28b2497a1c803749c9e4a2b0ab,,
,,"{Source: 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C)}",2022,http://dx.doi.org/10.1109/i4c57141.2022.10057711,{IEEE},"Gopinath, Anagha AND H, Akshitha AND Loomba, Arshya AND Kumar, Ranveer AND Narayanappa, CK",{Data Driven Machine Learning Model for Audiometric Threshold classification},proceedings,abe91b3684b37bffd24c85727109782e2d7c73bfcb95ee4161a00d74f11f0b75,,
,,{Description: Open Science Framework ; Supplementary materials and data related to dynamically masked audiometry research. ...},2022,https://dx.doi.org/10.17605/osf.io/gj8s5,,"Barbour, Dennis AND Heisey, Katherine AND Xie, Kevin AND Buchbinder, Jenna AND Walker, Alexandra",{Dynamically Masked Audiograms with Machine Learning Audiometry Supplement ...},misc,aefe6dba96ce365277c0aebe4de3e8eba9332e400686217b6eb41907fa11277e,,
{en},,"{Description: University of Liverpool ; Time Series Clustering Analysis: Exploring the Patterns of Hearing Loss in Adults (50+) in Cheshire and Merseyside ICS, 2013-2022 For more detailed information on this type of spatial analysis, please visit https://pro.arcgis.com/en/pro-app/latest/tool-reference/space-time-pattern-mining/time-series-clustering.htm}",2023,https://datacat.liverpool.ac.uk/2277/,,"Tsimpida, Dialechti","{Time Series Clustering Analysis: Exploring the Patterns of Hearing Loss in Adults (50 years old and above) in Cheshire and Merseyside ICS, 2013-2022. An Interactive Map Application.}",misc,32cf6167bdc4424da3db0ffc66022ca5d378b1900b8aecb9e0ade41a692ae837,,
,,"{Description: University of Liverpool ; Time Series Clustering Analysis: Exploring the Patterns of Hearing Loss in Adults (50+) in Cheshire and Merseyside ICS, 2013-2022 For more detailed information on this type of spatial analysis, please visit https://pro.arcgis.com/en/pro-app/latest/tool-reference/space-time-pattern-mining/time-series-clustering.htm ...}",2023,https://dx.doi.org/10.17638/datacat.liverpool.ac.uk/2277,,"Tsimpida, Dialechti","{Time Series Clustering Analysis: Exploring the Patterns of Hearing Loss in Adults (50 years old and above) in Cheshire and Merseyside ICS, 2013-2022. An Interactive Map Application. ...}",misc,724d899471958f0788805b76b94d2f10cfd10ebe0996dfe178df325e3c4ac82f,,
{en},,,2023,https://eprints.soton.ac.uk/484684/,,"Tsimpida, Dalia","{Time series clustering analysis: exploring the patterns of hearing loss in adults (50 years old and above) in Cheshire and Merseyside ICS, 2013-2022. An interactive map application}",misc,73f9e963d275f9d807d119fef69408f4ea5cf070856c424606850c6dd3162c3f,,
{EN},{hearing-loss symptoms},"{Source: Sustainability; Volume 13; Issue 10; Pages: 5406 ; Description: Multidisciplinary Digital Publishing Institute ; Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively.}",2021,https://doi.org/10.3390/su13105406,,Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},misc,06fe4d8387ec01609152b04cdfc03887f18094b39aeedf0d3f45812e7a44c757,,
{EN},{hearing-loss symptoms},"{Source: Sustainability, Vol 13, Iss 5406, p 5406 (2021) ; Description: Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively.}",2021,https://doi.org/10.3390/su13105406,{MDPI AG},Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},article,1d3953ebf37cb3b504828eee1356c2781bd59a6d07fd8e5604d88232c4955a6c,,
,{Otorhinolaryngology},"{Description: Background:Machine Learning models have been applied in various healthcare fields, including Audiology, to predict disease outcomes. The prognosis of sudden sensorineural hearing loss is difficult to predict due to the variable course of the disease. Hence, researchers have attempted to utilize ML models to predict the outcome of patients with sudden sensorineural hearing loss. The objectives of this study were to review the performance of these machine learning models and assess their applicability in real-world settings.Methods:A systematic search was conducted in PubMed, Web of Science and Scopus. Only studies that built machine learning prediction models were included, and studies that used algorithms such as logistic regression only for the purpose of adjusting for confounding variables were excluded. The risk of bias was assessed using the Prediction model Risk of Bias Assessment Tool (PROBAST).Results:After screening, a total of 7 papers were eligible for synthesis. In total, these studies built 48 ML ...}",2023,https://dx.doi.org/10.25384/sage.c.6892035.v1,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,9f7ce94375313f0da7c74edfd0486a495e817f7721e6f72b6dfb3134c278178a,,
{en},{Neurology (clinical)},"{Source: Otology & Neurotology ; volume 42, issue 9, page e1286-e1292 ; ISSN 1531-7129 1537-4505 ; Description: Objectives: Vibrant Soundbridge (VSB) was developed for treatment of hearing loss, but clinical outcomes vary and prognostic factors predicting the success of the treatment remain unknown. We examined clinical outcomes of VSB for conductive or mixed hearing loss, prognostic factors by analyzing prediction models, and cut-off values to predict the outcomes. Study design: Retrospective chart review. Setting: Tertiary care hospital. Patients: Thirty patients who underwent VSB surgery from January 2017 to December 2019 at our hospital. Intervention: Audiological tests were performed prior to and 3 months after surgery; patients completed questionnaires 3 months after surgery. Main outcome measures: We used a multiregression and the random forest algorithm for predictions. Mean absolute errors and coefficient of determinations were calculated to estimate prediction accuracies. Coefficient values in the multiregression model and the importance of features in the random forest model were calculated to clarify prognostic factors. Receiver operation characteristic curves were plotted. Results: All audiological outcomes improved after surgery. The random forest model (mean absolute error: 0.06) recorded more accuracy than the multiregression model (mean absolute error: 0.12). Speech discrimination score in a silent context in patients with hearing aids was the most influential factor (coefficient value: 0.51, featured value: 0.71). The candidate cut-off value was 36\% (sensitivity: 89\%, specificity: 75\%). Conclusions: VSB is an effective treatment for conductive or mixed hearing loss. Machine learning demonstrated more precise predictions, and speech discrimination scores in a silent context in patients with hearing aids were the most important factor in predicting clinical outcomes.}",2021,http://dx.doi.org/10.1097/mao.0000000000003271,{Ovid Technologies (Wolters Kluwer Health)},"Koyama, Hajime AND Mori, Anjin AND Nagatomi, Daisuke AND Fujita, Takeshi AND Saito, Kazuya AND Osaki, Yasuhiro AND Yamasoba, Tatsuya AND Doi, Katsumi",{Machine Learning Technique Reveals Prognostic Factors of Vibrant Soundbridge for Conductive or Mixed Hearing Loss Patients},article,6d5e172708d488f744dfcb2aa66e224591f39dbaa0cbd4d4f5caa2eae8960d6f,,
{en},{Multidisciplinary},"{Source: Scientific Reports ; volume 9, issue 1 ; ISSN 2045-2322 ; Description: Abstract Hearing loss (HL) is the most common neurodegenerative disease worldwide. Despite its prevalence, clinical testing does not yield a cell or molecular based identification of the underlying etiology of hearing loss making development of pharmacological or molecular treatments challenging. A key to improving the diagnosis of inner ear disorders is the development of reliable biomarkers for different inner ear diseases. Analysis of microRNAs (miRNA) in tissue and body fluid samples has gained significant momentum as a diagnostic tool for a wide variety of diseases. In previous work, we have shown that miRNA profiling in inner ear perilymph is feasible and may demonstrate distinctive miRNA expression profiles unique to different diseases. A first step in developing miRNAs as biomarkers for inner ear disease is linking patterns of miRNA expression in perilymph to clinically available metrics. Using machine learning (ML), we demonstrate we can build disease specific algorithms that predict the presence of sensorineural hearing loss using only miRNA expression profiles. This methodology not only affords the opportunity to understand what is occurring on a molecular level, but may offer an approach to diagnosing patients with active inner ear disease.}",2019,http://dx.doi.org/10.1038/s41598-019-40192-7,{Springer Science and Business Media LLC},"Shew, Matthew AND New, Jacob AND Wichova, Helena AND Koestler, Devin C. AND Staecker, Hinrich",{Using Machine Learning to Predict Sensorineural Hearing Loss Based on Perilymph Micro RNA Expression Profile},article,aec94d0092b6b0db052420717ec1d2f34246ba2f77f955283317701e677caa44,,
,{Otorhinolaryngology},"{Description: Background:Machine Learning models have been applied in various healthcare fields, including Audiology, to predict disease outcomes. The prognosis of sudden sensorineural hearing loss is difficult to predict due to the variable course of the disease. Hence, researchers have attempted to utilize ML models to predict the outcome of patients with sudden sensorineural hearing loss. The objectives of this study were to review the performance of these machine learning models and assess their applicability in real-world settings.Methods:A systematic search was conducted in PubMed, Web of Science and Scopus. Only studies that built machine learning prediction models were included, and studies that used algorithms such as logistic regression only for the purpose of adjusting for confounding variables were excluded. The risk of bias was assessed using the Prediction model Risk of Bias Assessment Tool (PROBAST).Results:After screening, a total of 7 papers were eligible for synthesis. In total, these studies built 48 ML ...}",2023,https://dx.doi.org/10.25384/sage.c.6892035,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,b576fb8d37b8d90c7c9c455431e3fe2f69b03df6006a199639239234ce895e29,,
{en},{Article},"{Description: Nature Publishing Group UK ; Hearing loss (HL) is the most common neurodegenerative disease worldwide. Despite its prevalence, clinical testing does not yield a cell or molecular based identification of the underlying etiology of hearing loss making development of pharmacological or molecular treatments challenging. A key to improving the diagnosis of inner ear disorders is the development of reliable biomarkers for different inner ear diseases. Analysis of microRNAs (miRNA) in tissue and body fluid samples has gained significant momentum as a diagnostic tool for a wide variety of diseases. In previous work, we have shown that miRNA profiling in inner ear perilymph is feasible and may demonstrate distinctive miRNA expression profiles unique to different diseases. A first step in developing miRNAs as biomarkers for inner ear disease is linking patterns of miRNA expression in perilymph to clinically available metrics. Using machine learning (ML), we demonstrate we can build disease specific algorithms that predict the presence of sensorineural hearing loss using only miRNA expression profiles. This methodology not only affords the opportunity to understand what is occurring on a molecular level, but may offer an approach to diagnosing patients with active inner ear disease.}",2019,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6399453/,,"Shew, Matthew AND New, Jacob AND Wichova, Helena AND Koestler, Devin C. AND Staecker, Hinrich",{Using Machine Learning to Predict Sensorineural Hearing Loss Based on Perilymph Micro RNA Expression Profile},misc,2cb86643f4d798d1b9ccdde22669a0f0ca7c088f69cfd62c8df91b09e7f45fa8,,
,,"{Source: 2022 6th International Conference On Computing, Communication, Control And Automation (ICCUBEA}",2022,http://dx.doi.org/10.1109/iccubea54992.2022.10011011,{IEEE},"Vanjari, Hrishikesh B. AND Kolte, Mahesh T. AND Chopade, Nilkanth",{Hearing Loss Adaptivity of Machine Learning Based Compressive Sensing Speech Enhancement for Hearing Aids},proceedings,38ca22a5336fb7a354b07792638fb5e008086ecca2c928550315a1b1779cb046,,
{en},{Otorhinolaryngology},"{Source: American Journal of Otolaryngology ; volume 42, issue 2, page 102858 ; ISSN 0196-0709}",2021,http://dx.doi.org/10.1016/j.amjoto.2020.102858,{Elsevier BV},"Uhm, Taewoong AND Lee, Jae Eun AND Yi, Seongbaek AND Choi, Sung Won AND Oh, Se Joon AND Kong, Soo Keun AND Lee, Il Woo AND Lee, Hyun Min",{Predicting hearing recovery following treatment of idiopathic sudden sensorineural hearing loss with machine learning models},article,807977baddc889dff3a0efb652625cc4a5b1eda463b4f2794d1617389e5075b1,{Pusan National University Yangsan Hospital},
{en},,"{Description: Article published in International Archives of Occupational and Environmental Health available open access at https://doi.org/10.1007/s00420-020-01648-w ; Purpose Noise-induced hearing loss (NIHL) is a global issue that impacts people{\textquoteright}s life and health. The current review aims to clarify the contributions and limitations of applying machine learning (ML) to predict NIHL by analyzing the performance of different ML techniques and the procedure of model construction. Methods The authors searched PubMed, EMBASE and Scopus on November 26, 2020. Results Eight studies were recruited in the current review following defined inclusion and exclusion criteria. Sample size in the selected studies ranged between 150 and 10,567. The most popular models were artificial neural networks (n = 4), random forests (n = 3) and support vector machines (n = 3). Features mostly correlated with NIHL and used in the models were: age (n = 6), duration of noise exposure (n = 5) and noise exposure level (n = 4). Five included studies used either split-sample validation (n = 3) or ten-fold cross-validation (n = 2). Assessment of accuracy ranged in value from 75.3\% to 99\% with a low prediction error/root-mean-square error in 3 studies. Only 2 studies measured discrimination risk using the receiver operating characteristic (ROC) curve and/or the area under ROC curve. Conclusion In spite of high accuracy and low prediction error of machine learning models, some improvement can be expected from larger sample sizes, multiple algorithm use, completed reports of model construction and the sufficient evaluation of calibration and discrimination risk.}",2021,http://hdl.handle.net/10369/11272,{Springer},"Chen, Feifan AND Cao, Zuwei AND Grais, Emad M. AND Zhao, Fei",{Contributions and limitations of using machine learning to predict noise-induced hearing loss},article,98587f908f12fa1d83fff6aea9e50752ad9d10a9c7f4fb278c73c46496e3ee57,,
,,"{Description: Physicians depend on their insight and experience and on a fundamentally indicative or symptomatic approach to decide on the possible ailment of a patient. However, numerous phases of problem identification and longer strategies can prompt a longer time for consulting and can subsequently cause other patients that require attention to wait for longer. This can bring about pressure and tension concerning those patients. In this study, we focus on developing a decision-support system for diagnosing the symptoms as a result of hearing loss. The model is implemented by utilizing machine learning techniques. The Frequent Pattern Growth (FP-Growth) algorithm is used as a feature transformation method and the multivariate Bernoulli na{\""\i}ve Bayes classification model as the classifier. To find the correlation that exists between the hearing thresholds and symptoms of hearing loss, the FP-Growth and association rule algorithms were first used to experiment with small sample and large sample datasets. The result of these two experiments showed the existence of this relationship, and that the performance of the hybrid of the FP-Growth and na{\""\i}ve Bayes algorithms in identifying hearing-loss symptoms was found to be efficient, with a very small error rate. The average accuracy rate and average error rate for the multivariate Bernoulli model with FP-Growth feature transformation, using five training sets, are 98.25\% and 1.73\%, respectively. ; hearing-loss symptoms; frequent pattern growth; multivariate Bernoulli na{\""\i}ve Bayes; machine learning techniques; identification model}",,https://www.mdpi.com/2071-1050/13/10/5406/pdf,,Mohd Khanapi Abd Ghani AND Nasir G. Noma AND Mazin Abed Mohammed AND Karrar Hameed Abdulkareem AND Begonya Garcia-Zapirain AND Mashael S. Maashi AND Salama A. Mostafa,{Innovative Artificial Intelligence Approach for Hearing-Loss Symptoms Identification Model Using Machine Learning Techniques},article,a5b4385ce702d812526c42ef9f2ae1b19035c368edbe20d957c9cfe3988733cc,,
,,{Source: 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)},2019,http://dx.doi.org/10.1109/sitis.2019.00034,{IEEE},"Ilyas, Muhammad AND Nait-ali, Amine",{Machine Learning Based Detection of Hearing Loss Using Auditory Perception Responses},proceedings,990378f3fe801ebf21b4a29eec57474ce12bf7f7a975b8f8aa1459816e3035b4,,
{en},{General Medicine},"{Source: Annals of Otology, Rhinology & Laryngology ; volume 133, issue 3, page 268-276 ; ISSN 0003-4894 1943-572X ; Description: Background: Machine Learning models have been applied in various healthcare fields, including Audiology, to predict disease outcomes. The prognosis of sudden sensorineural hearing loss is difficult to predict due to the variable course of the disease. Hence, researchers have attempted to utilize ML models to predict the outcome of patients with sudden sensorineural hearing loss. The objectives of this study were to review the performance of these machine learning models and assess their applicability in real-world settings. Methods: A systematic search was conducted in PubMed, Web of Science and Scopus. Only studies that built machine learning prediction models were included, and studies that used algorithms such as logistic regression only for the purpose of adjusting for confounding variables were excluded. The risk of bias was assessed using the Prediction model Risk of Bias Assessment Tool (PROBAST). Results: After screening, a total of 7 papers were eligible for synthesis. In total, these studies built 48 ML models. The most common utilized algorithms were Logistic Regression, Support Vector Machine (SVM) and boosting. The area under the curve of the receiver operating characteristic curve ranged between 0.59 and 0.915. All of the included studies had a high risk of bias; hence there are concerns regarding their applicability. Conclusion: Although these models showed great performance and promising results, future studies are still needed before these models can be applied in a real-world setting. Future studies should employ multiple cohorts, different feature selection methods, and external validation to further validate the models{\textquoteright} applicability.}",2023,http://dx.doi.org/10.1177/00034894231206902,{SAGE Publications},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review},article,eb3215291a18f23128793edf022632920d7ca9ab8fe9de428adda9767fffa3c1,,
{en},,"{Description: Article published in International Archives of Occupational and Environmental Health available open access at https://doi.org/10.1007/s00420-020-01648-w ; Purpose Noise-induced hearing loss (NIHL) is a global issue that impacts people{\textquoteright}s life and health. The current review aims to clarify the contributions and limitations of applying machine learning (ML) to predict NIHL by analyzing the performance of different ML techniques and the procedure of model construction. Methods The authors searched PubMed, EMBASE and Scopus on November 26, 2020. Results Eight studies were recruited in the current review following defined inclusion and exclusion criteria. Sample size in the selected studies ranged between 150 and 10,567. The most popular models were artificial neural networks (n = 4), random forests (n = 3) and support vector machines (n = 3). Features mostly correlated with NIHL and used in the models were: age (n = 6), duration of noise exposure (n = 5) and noise exposure level (n = 4). Five included studies used either split-sample validation (n = 3) or ten-fold cross-validation (n = 2). Assessment of accuracy ranged in value from 75.3\% to 99\% with a low prediction error/root-mean-square error in 3 studies. Only 2 studies measured discrimination risk using the receiver operating characteristic (ROC) curve and/or the area under ROC curve. Conclusion In spite of high accuracy and low prediction error of machine learning models, some improvement can be expected from larger sample sizes, multiple algorithm use, completed reports of model construction and the sufficient evaluation of calibration and discrimination risk.}",2021,http://hdl.handle.net/10369/11272,{Springer},"Chen, Feifan AND Cao, Zuwei AND Grais, Emad M. AND Zhao, Fei",{Contributions and limitations of using machine learning to predict noise-induced hearing loss},article,98587f908f12fa1d83fff6aea9e50752ad9d10a9c7f4fb278c73c46496e3ee57,,
,,{Source: 2022 IEEE North Karnataka Subsection Flagship International Conference (NKCon)},2022,http://dx.doi.org/10.1109/nkcon56289.2022.10127090,{IEEE},"Pai K, Venkataramana AND Thilagam, P. Santhi","{Hearing Loss Prediction in Newborns, Infants and Toddlers using Machine Learning}",proceedings,b9a28b6c6155ae286523aaf5c6abe241dc3e2bec0a63ab17fd7c48d9ca09911f,,
{en},{[INFO]Computer Science [cs]},"{Source: 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS) ; https://hal.u-pec.fr/hal-04323908 ; 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), Nov 2019, Sorrento, Italy. pp.146-150, &#x27E8;10.1109/SITIS.2019.00034&#x27E9; ; Description: International audience}",2019,https://hal.u-pec.fr/hal-04323908,"{HAL CCSD, IEEE}","Ilyas, Muhammad AND Nait-Ali, Amine",{Machine Learning Based Detection of Hearing Loss Using Auditory Perception Responses},proceedings,7030568dd2c40f23b8e9fcfb94637a1153b900324ff229345941d21f66a04c31,"{Laboratoire Images, Signaux et Syst{\`e}mes Intelligents (LISSI)}",
,{Gene Sequencing},"{Description: This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2}",2021,https://doi.org/10.17632/6mh8mpnbgv.1,,xiao mei luo (10220563),"{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations}",misc,5648b6206dab65e05090dbd61a9a1f9a9e2360b19dad8071c07ef64e5845e267,,
,{Gene Sequencing},"{Description: Mendeley ; This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2 ...}",2021,https://dx.doi.org/10.17632/6mh8mpnbgv.1,,"Luo, Xiao Mei","{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations ...}",misc,31f0914625ebd40b52b14336882d28b853967644107e14e241aaad4f8f18c445,,
{eng},,"{Description: Purpose: The aim of this study was to analyze the performance of multivariate machine learning (ML) models applied to a speech-in-noise hearing screening test and investigate the contribution of the measured features toward hearing loss detection using explainability techniques.Method: Seven different ML techniques, including transparent (i.e., decision tree and logistic regression) and opaque (e.g., random forest) models, were trained and evaluated on a data set including 215 tested ears (99 with hearing loss of mild degree or higher and 116 with no hearing loss). Post hoc explainability techniques were applied to highlight the role of each feature in predicting hearing loss.Results: Random forest (accuracy =.85, sensitivity =.86, specificity =.85, precision =.84) performed, on average, better than decision tree (accuracy =.82, sensitivity =.84, specificity =.80, precision =.79). Support vector machine, logistic regression, and gradient boosting had similar performance as random forest. According to post hoc explainability analysis on models generated using random forest, the features with the highest relevance in predicting hearing loss were age, number and percentage of correct responses, and average reaction time, whereas the total test time had the lowest relevance.Conclusions: This study demonstrates that a multivariate approach can help detect hearing loss with satisfactory performance. Further research on a bigger sample and using more complex ML algorithms and explainability techniques is needed to fully investigate the role of input features (including additional features such as risk factors and individual responses to low-/high-frequency stimuli) in predicting hearing loss.}",2022,https://hdl.handle.net/11311/1233530,,"Lenatti, Marta AND Moreno-Sánchez, Pedro A AND Polo, Edoardo M AND Mollura, Maximiliano AND Barbieri, Riccardo AND Paglialonga, Alessia",{Evaluation of Machine Learning Algorithms and Explainability Techniques to Detect Hearing Loss From a Speech-in-Noise Screening Test},article,afb4fcd4fcc56f1fe0edae066ca62791da5ff7b2889dc6365db666686d62aaee,"{Lenatti, Marta}",
{en},"{General Biochemistry, Genetics and Molecular Biology}","{Source: eBioMedicine ; volume 69, page 103322 ; ISSN 2352-3964}",2021,http://dx.doi.org/10.1016/j.ebiom.2021.103322,{Elsevier BV},"Luo, Xiaomei AND Li, Fengmei AND Xu, Wenchang AND Hong, Kaicheng AND Yang, Tao AND Chen, Jiansheng AND Chen, Xiaohe AND Wu, Hao","{Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants}",article,c5b68120a8122f2457f50f0d1a3913a0e0b3cd455ae18ffb67082f1570298733,{National Key Research and Development Program of China},
,{Otorhinolaryngology},"{Description: Supplemental material, sj-docx-2-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417423.v1,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-docx-2-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,a7498b76753388b6007f871e0769f24e17163296faac0a264ec9eeaec5635f78,,
{English},{Computer Science},{Source: http://rave.ohiolink.edu/etdc/view?acc_num=ucin1447689755 ; Description: University of Cincinnati / OhioLINK},2015,http://rave.ohiolink.edu/etdc/view?acc_num=ucin1447689755,,"Tan, Lirong",{Identification of Disease Biomarkers from Brain fMRI Data using Machine Learning Techniques: Applications in Sensorineural Hearing Loss and Attention Deficit Hyperactivity Disorder},misc,92c82eb555c359371e098e8c085f27dbf01504bf953744d9ed86f35a25c2a232,,
,{Otorhinolaryngology},"{Description: SAGE Journals ; Supplemental material, sj-csv-3-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417417,,"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-csv-3-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},misc,6c6ec7c4db9c978cf3889ed8cf150ff9042c0ff4997eb2fd0b7a1a740c660df0,,
,{Otorhinolaryngology},"{Description: Supplemental material, sj-docx-1-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417420,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-docx-1-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,339d1c86ba9b03c04ea9601039955558f463946d6b770ff8bd40e1ab92f3d595,,
,{Otorhinolaryngology},"{Description: Supplemental material, sj-docx-1-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417420.v1,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-docx-1-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,85c675b9e9e28c9438c9447f003400eaeb78158e611d640dbc8b5984dbb037d0,,
{EN},{AlexNet},"{Source: International Journal of Cognitive Computing in Engineering, Vol 2, Iss , Pp 144-153 (2021) ; Description: Hearing is a very important feeling for humans. It helps to perceive the environment around us and can warn us of any imminent dangers around us. Hearing loss is an impaired ability to hear sound. Sensorineural hearing loss (SNHL) is very common in today{\textquoteright}s society. Classification of hearing loss is helpful for clinical diagnosis, finding suitable treatment methods and allocating appropriate medical interventions. This paper presents a novel method for hearing loss classification based on magnetic resonance images, which can automatically recognize tissue specific features in a given MRI image. The study involved magnetic resonance images (MRI) of 60 participants in three categories of balance: left SNHL, right SNHL, and a healthy control group. Our method uses AlexNet to extract the features of a single category, and uses Extreme Learning Machine to form a triclassifier for automatic SNHL classification. From the experimental results and the practicability of the algorithm, the classification performance is obviously better than the standard deep learning method and other traditional methods.}",2021,https://doi.org/10.1016/j.ijcce.2021.09.002,"{KeAi Communications Co., Ltd.}",Bin Li,{Hearing loss classification via AlexNet and extreme learning machine},article,05984d21c23b887737b5e56f97d91e138d6ae4ada91a0a17709496fb4aa247ba,,
{en},{Engineering (miscellaneous)},"{Source: International Journal of Cognitive Computing in Engineering ; volume 2, page 144-153 ; ISSN 2666-3074}",2021,http://dx.doi.org/10.1016/j.ijcce.2021.09.002,{Elsevier BV},"Li, Bin",{Hearing loss classification via AlexNet and extreme learning machine},article,b2a38916a81b6ba7fa2b973af3ed857080d608e360263ec99c57a2702608e076,,
{EN},{Hearing Impairment},"{Source: Iraqi Journal for Computer Science and Mathematics, Vol 4, Iss 2 (2023) ; Description: : Hearing loss or hearing impairment is one of the most leading cause highly affecting the people around the world in present days. Also, the youngsters and adults are mostly affecting by this disease, which affects their normal/social life, carrier, education, and etc. Hence, it should be properly identified and diagnosed for providing an earlier treatments to save the people live. For this purpose, the different types of automated hearing loss prediction/detection systems are developed in the conventional works. The existing works are mainly focused on deploying the machine learning/deep learning based prediction approaches for disease identification. However, it lacks with the flaws of difficult computational steps, more training \& testing time, increased mis-prediction results, and error outputs. Therefore, the proposed work objects to develop a Human Age - Hearing Impairment \& Level (HAHIL) prediction system by using the machine learning methodologies. Here, three distinct prediction models are deployed for age prediction, hearing loss detection, and its severity level prediction. The Biased Probability Neural Network (BPNN) technique is utilized to predict the age based on simulated human acoustical signals. Then, the Regularized Extreme Learning Machine (RELM) mechanism is deployed for predicting the hearing impairment by constructing the weight and target matrices. During evaluation, the performance of the proposed HAHIL prediction system is validated and tested by using various evaluation indicators.}",2023,https://doi.org/10.52866/ijcsm.2023.02.02.005,"{College of Education, Al-Iraqia University}",Selvaganesh N AND Shanthi D AND Rajesh Pandian N,{A Novel Biased Probability Neural Network (BPNN) and Regularized Extreme Learning Machine (RELM) based Hearing Loss Prediction System},article,f37acfe6f1ed1ac0b0a60ac4c59589a9468a38f22fb9aa36684d2ba016ac4ed2,,
,{Uncategorized},"{Description: Sensorineural hearing loss (SNHL) is a common hearing disorder or deafness which accounts for about 90\% of the reported hearing loss. Magnetic resonance imaging (MRI) has been found to be an effective neuroimaging technique for detecting SNHL. However, manual detection methods, mainly based on the visual inspection of MRI, are cumbersome, time-consuming and need skilled supervision. Hence, there is a great need to design a computer-aided detection system for fast, accurate and automated detection of SNHL. This paper presents a new method for automated diagnosis of SNHL through brain MR images. Fast discrete curvelet transform is employed for image decomposition. The features are extracted from various decomposed subbands at different scales and orientations. A set of discriminant features is then derived using PCA+LDA algorithm. A hybrid classifier is suggested by integrating extreme learning machine and Jaya optimization with mutation (MJaya-ELM) to distinguish hearing loss images from healthy MR images. The proposed hybrid method overcomes the drawbacks of traditional ELM and other learning algorithms for single layer feedforward neural network. The concept of mutation is introduced to conventional Jaya optimization (MJaya) for improving the global search ability of the solutions by providing additional diversity. The proposed system is evaluated on a well-studied database. The comparison results demonstrate that the proposed scheme outperforms the existing schemes in terms of overall accuracy and sensitivity over different classes. The effectiveness of the proposed MJaya-ELM algorithm is also compared with its counterparts such as PSO-ELM, DE-ELM, and Jaya-ELM, and the results indicate the superiority of MJaya-ELM.}",2019,https://figshare.com/articles/journal_contribution/MJaya-ELM_A_Jaya_algorithm_with_mutation_and_extreme_learning_machine_based_approach_for_sensorineural_hearing_loss_detection/11944830,,Deepak R. Nayaka AND Yudong Zhang AND Dibya S. Das AND Subinita Panda,{MJaya-ELM: A Jaya algorithm with mutation and extreme learning machine based approach for sensorineural hearing loss detection},article,48430a362f84ee43210dd849e7605fcc08c2e4926c5b14526ed972d15c5bf622,,
{en},{Multidisciplinary},"{Source: PLOS ONE ; volume 14, issue 6, page e0217790 ; ISSN 1932-6203}",2019,http://dx.doi.org/10.1371/journal.pone.0217790,{Public Library of Science (PLoS)},"Chang, Young-Soo AND Park, Heesung AND Hong, Sung Hwa AND Chung, Won-Ho AND Cho, Yang-Sun AND Moon, Il Joon",{Predicting cochlear dead regions in patients with hearing loss through a machine learning-based approach: A preliminary study},article,24e88adca0a625869d4b7462ecfefc8dc3f5015416f3e567cd5d550b1f84886f,"{Buechner, Andreas}",
,{Gene Sequencing},"{Description: Mendeley ; This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2 ...}",2021,https://dx.doi.org/10.17632/6mh8mpnbgv.1,,"Luo, Xiao Mei","{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 mutations ...}",misc,31f0914625ebd40b52b14336882d28b853967644107e14e241aaad4f8f18c445,,
,{Gene Sequencing},"{Description: Mendeley ; This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2 ...}",2021,https://dx.doi.org/10.17632/6mh8mpnbgv.2,,"Luo, Xiao Mei","{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants ...}",misc,bbb0899f1648018b0ef8301ff09d980b8303ad8885038340fb1f5b7100d41e53,,
,{Gene Sequencing},"{Description: Mendeley ; This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2 ...}",2021,https://dx.doi.org/10.17632/6mh8mpnbgv,,"Luo, Xiao Mei","{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants ...}",misc,01fdeb02465bc3f5c8dd49dc1c87b2d5540834fd311ca1abb71ec5c2dc1a63e7,,
{en},{217 Medical engineering},"{Description: Purpose: The aim of this study was to analyze the performance of multivariate machine learning (ML) models applied to a speech-in-noise hearing screening test and investigate the contribution of the measured features toward hearing loss detection using explainability techniques. Method: Seven different ML techniques, including transparent (i.e., decision tree and logistic regression) and opaque (e.g., random forest) models, were trained and evaluated on a data set including 215 tested ears (99 with hearing loss of mild degree or higher and 116 with no hearing loss). Post hoc explainability techniques were applied to highlight the role of each feature in predicting hearing loss. Results: Random forest (accuracy = .85, sensitivity = .86, specificity = .85, precision = .84) performed, on average, better than decision tree (accuracy = .82, sensitivity = .84, specificity = .80, precision = .79). Support vector machine, logistic regression, and gradient boosting had similar performance as random forest. According to post hoc explainability analysis on models generated using random forest, the features with the highest relevance in predicting hearing loss were age, number and percentage of correct responses, and average reaction time, whereas the total test time had the lowest relevance. Conclusions: This study demonstrates that a multivariate approach can help detect hearing loss with satisfactory performance. Further research on a bigger sample and using more complex ML algorithms and explainability techniques is needed to fully investigate the role of input features (including additional features such as risk factors and individual responses to low-/high-frequency stimuli) in predicting hearing loss. ; Peer reviewed}",2022,https://trepo.tuni.fi/handle/10024/143753,,"Lenatti, Marta AND Moreno-S{\'a}nchez, Pedro A. AND Polo, Edoardo M. AND Mollura, Maximiliano AND Barbieri, Riccardo AND Paglialonga, Alessia",{Evaluation of Machine Learning Algorithms and Explainability Techniques to Detect Hearing Loss From a Speech-in-Noise Screening Test},article,4daf9d4a54fe548e19f650cd26510dcf413e9d795f50d2dcbe6f6673a6b00bd5,{Tampere University},
{eng},,"{Description: Purpose: The aim of this study was to analyze the performance of multivariate machine learning (ML) models applied to a speech-in-noise hearing screening test and investigate the contribution of the measured features toward hearing loss detection using explainability techniques.Method: Seven different ML techniques, including transparent (i.e., decision tree and logistic regression) and opaque (e.g., random forest) models, were trained and evaluated on a data set including 215 tested ears (99 with hearing loss of mild degree or higher and 116 with no hearing loss). Post hoc explainability techniques were applied to highlight the role of each feature in predicting hearing loss.Results: Random forest (accuracy =.85, sensitivity =.86, specificity =.85, precision =.84) performed, on average, better than decision tree (accuracy =.82, sensitivity =.84, specificity =.80, precision =.79). Support vector machine, logistic regression, and gradient boosting had similar performance as random forest. According to post hoc explainability analysis on models generated using random forest, the features with the highest relevance in predicting hearing loss were age, number and percentage of correct responses, and average reaction time, whereas the total test time had the lowest relevance.Conclusions: This study demonstrates that a multivariate approach can help detect hearing loss with satisfactory performance. Further research on a bigger sample and using more complex ML algorithms and explainability techniques is needed to fully investigate the role of input features (including additional features such as risk factors and individual responses to low-/high-frequency stimuli) in predicting hearing loss.}",2022,https://hdl.handle.net/11311/1233530,,"Lenatti, Marta AND Moreno-Sánchez, Pedro A AND Polo, Edoardo M AND Mollura, Maximiliano AND Barbieri, Riccardo AND Paglialonga, Alessia",{Evaluation of Machine Learning Algorithms and Explainability Techniques to Detect Hearing Loss From a Speech-in-Noise Screening Test},article,afb4fcd4fcc56f1fe0edae066ca62791da5ff7b2889dc6365db666686d62aaee,"{Lenatti, Marta}",
{en},{Research Paper},"{Source: EBioMedicine ; Description: Elsevier ; BACKGROUND: Hereditary hearing loss (HHL) is the most common sensory deficit, which highly afflicts humans. With gene sequencing technology development, more variants will be identified and support genetic diagnoses, which is difficult for human experts to diagnose. This study aims to develop a machine learning-based genetic diagnosis model of HHL-related variants of GJB2, SLC26A4 and MT-RNR1. METHODS: This case-control study included 1898 subjects, among which 1354 were HHL patients and 544 were carriers. Risk assessment models were established based on variants at 144 sites in three genes related to HHL by building six machine learning (ML) models. We compared the ML models with the genetic risk score (GRS) and expert interpretation (EI) to verify the clinical performance. FINDINGS: Among the six ML models, the support vector machine (SVM) showed the best performance. For the prediction of HHL-related gene sites in subjects with variants, the area under the receiver operating characteristic (AUC) of the SVM model was 0.803 (0.680{\textendash}0.814) in the 10-fold stratified cross-validation and 0.751 (0.635{\textendash}0.779) in external validation. The predicted results were better than both EI and GRS. Furthermore, 11 sites were identified as the smallest feature set that can be accurately predicted. INTERPRETATION: The developed SVM model has great potential to be an efficient and effective tool for HHL prediction when high throughput sequencing data are available.}",2021,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8237285/,,"Luo, Xiaomei AND Li, Fengmei AND Xu, Wenchang AND Hong, Kaicheng AND Yang, Tao AND Chen, Jiansheng AND Chen, Xiaohe AND Wu, Hao","{Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants}",misc,2e8224d8578b298126dfc126d848672a28477d24cb12cdc6de2cdc87c5520cbe,,
{EN},{Hereditary hearing loss},"{Source: EBioMedicine, Vol 69, Iss , Pp 103322- (2021) ; Description: Background: Hereditary hearing loss (HHL) is the most common sensory deficit, which highly afflicts humans. With gene sequencing technology development, more variants will be identified and support genetic diagnoses, which is difficult for human experts to diagnose. This study aims to develop a machine learning-based genetic diagnosis model of HHL-related variants of GJB2, SLC26A4 and MT-RNR1. Methods: This case-control study included 1898 subjects, among which 1354 were HHL patients and 544 were carriers. Risk assessment models were established based on variants at 144 sites in three genes related to HHL by building six machine learning (ML) models. We compared the ML models with the genetic risk score (GRS) and expert interpretation (EI) to verify the clinical performance. Findings: Among the six ML models, the support vector machine (SVM) showed the best performance. For the prediction of HHL-related gene sites in subjects with variants, the area under the receiver operating characteristic (AUC) of the SVM model was 0.803 (0.680{\textendash}0.814) in the 10-fold stratified cross-validation and 0.751 (0.635{\textendash}0.779) in external validation. The predicted results were better than both EI and GRS. Furthermore, 11 sites were identified as the smallest feature set that can be accurately predicted. Interpretation: The developed SVM model has great potential to be an efficient and effective tool for HHL prediction when high throughput sequencing data are available.}",2021,https://doi.org/10.1016/j.ebiom.2021.103322,{Elsevier},Xiaomei Luo AND Fengmei Li AND Wenchang Xu AND Kaicheng Hong AND Tao Yang AND Jiansheng Chen AND Xiaohe Chen AND Hao Wu,"{Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants}",article,e1f3713f48a6cc6bdb247271035b18d8e6b907aeadc30c2a4e51a6d1e2ec1a28,,
{en},{Research Article},"{Description: Public Library of Science ; We propose a machine learning (ML)-based model for predicting cochlear dead regions (DRs) in patients with hearing loss of various etiologies. Five hundred and fifty-five ears from 380 patients (3,770 test samples) diagnosed with sensorineural hearing loss (SNHL) were analyzed. A threshold-equalizing noise (TEN) test was applied to detect the presence of DRs. Data were collected on sex, age, side of the affected ear, hearing loss etiology, word recognition scores (WRS), and pure-tone thresholds at each frequency. According to the cause of hearing loss as diagnosed by the physician, we categorized the patients into six groups: 1) SNHL with unknown etiology; 2) sudden sensorineural hearing loss (SSNHL); 3) vestibular schwannoma (VS); 4) Meniere{\textquoteright}s disease (MD); 5) noise-induced hearing loss (NIHL); or 6) presbycusis or age-related hearing loss (ARHL). To develop a predictive model, we performed recursive partitioning and regression for classification, logistic regression, and random forest. The overall prevalence of one or more DRs in test ears was 20.36\% (113 ears). Among the 3,770 test samples, the overall frequency-specific prevalence of DR was 6.7\%. WRS, pure-tone thresholds at each frequency, disease type (VS or MD), and frequency information were useful for predicting DRs. Sex and age were not associated with detecting DRs. Based on these results, we suggest possible predictive factors for determining the presence of DRs. To improve the predictive power of the model, a more flexible model or more clinical features, such as the duration of hearing loss or risk factors for developing DRs, may be needed.}",2019,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6546232/,,"Chang, Young-Soo AND Park, Heesung AND Hong, Sung Hwa AND Chung, Won-Ho AND Cho, Yang-Sun AND Moon, Il Joon",{Predicting cochlear dead regions in patients with hearing loss through a machine learning-based approach: A preliminary study},misc,021d79b5328c6b88b49094e177c329146b596875d5f94c9265551a50fa4e2226,,
{en},{Digital Health},"{Source: Front Digit Health ; Description: Frontiers Media S.A. ; Even before the COVID-19 pandemic, there was mounting interest in remote testing solutions for audiology. The ultimate goal of such work was to improve access to hearing healthcare for individuals that might be unable or reluctant to seek audiological help in a clinic. In 2015, Diane Van Tasell patented a method for measuring an audiogram when the precise signal level was unknown (patent US 8,968,209 B2). In this method, the slope between pure-tone thresholds measured at 2 and 4 kHz is calculated and combined with questionnaire information in order to reconstruct the most likely audiograms from a database of options. An approach like the Van Tasell method is desirable because it is quick and feasible to do in a patient{\textquoteright}s home where exact stimulus levels are unknown. The goal of the present study was to use machine learning to assess the effectiveness of such audiogram-estimation methods. The National Health and Nutrition Examination Survey (NHANES), a database of audiologic and demographic information, was used to train and test several machine learning algorithms. Overall, 9,256 cases were analyzed. Audiometric data were classified using the Wisconsin Age-Related Hearing Impairment Classification Scale (WARHICS), a method that places hearing loss into one of eight categories. Of the algorithms tested, a random forest machine learning algorithm provided the best fit with only a few variables: the slope between 2 and 4 kHz; gender; age; military experience; and self-reported hearing ability. Using this method, 54.79\% of the individuals were correctly classified, 34.40\% were predicted to have a milder loss than measured, and 10.82\% were predicted to have a more severe loss than measured. Although accuracy was low, it is unlikely audibility would be severely affected if classifications were used to apply gains. Based on audibility calculations, underamplification still provided sufficient gain to achieve ~95\% correct (Speech Intelligibility Index >= 0.45) for sentence materials for 88\% of individuals. Fewer than 1\% ...}",2021,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8521948/,,"Ellis, Gregory M. AND Souza, Pamela E.",{Using Machine Learning and the National Health and Nutrition Examination Survey to Classify Individuals With Hearing Loss},misc,56087d4067b7941b2926124e5012adbae88b46684fe2f9bffcaa605ae9c8311f,,
,,"{Source: ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}",2023,http://dx.doi.org/10.1109/icassp49357.2023.10095325,{IEEE},"Khalil, Rana M. AND Papanicolaou, Alexandra AND Chou, Renee Ti AND Gibbs, Bobby E. AND Anderson, Samira AND Gordon-Salant, Sandra AND Cummings, Michael P. AND Goupell, Matthew J.","{Using Machine Learning to Understand the Relationships Between Audiometric Data, Speech Perception, Temporal Processing, And Cognition}",proceedings,448168c0c567fec4a9a7f32ed230c7d3efc2c2620a6fa311b2e7244a7b7a5506,{University of Maryland},
{EN},{audiometry},"{Source: Diagnostics; Volume 13; Issue 3; Pages: 575 ; Description: Multidisciplinary Digital Publishing Institute ; This study uses machine learning to perform the hearing test (audiometry) processes autonomously with EEG signals. Sounds with different amplitudes and wavelengths given to the person tested in standard hearing tests are assigned randomly with the interface designed with MATLAB GUI. The person stated that he heard the random size sounds he listened to with headphones but did not take action if he did not hear them. Simultaneously, EEG (electro-encephalography) signals were followed, and the waves created in the brain by the sounds that the person attended and did not hear were recorded. EEG data generated at the end of the test were pre-processed, and then feature extraction was performed. The heard and unheard information received from the MATLAB interface was combined with the EEG signals, and it was determined which sounds the person heard and which they did not hear. During the waiting period between the sounds given via the interface, no sound was given to the person. Therefore, these times are marked as not heard in EEG signals. In this study, brain signals were measured with Brain Products Vamp 16 EEG device, and then EEG raw data were created using the Brain Vision Recorder program and MATLAB. After the data set was created from the signal data produced by the heard and unheard sounds in the brain, machine learning processes were carried out with the PYTHON programming language. The raw data created with MATLAB was taken with the Python programming language, and after the pre-processing steps were completed, machine learning methods were applied to the classification algorithms. Each raw EEG data has been detected by the Count Vectorizer method. The importance of each EEG signal in all EEG data has been calculated using the TF-IDF (Term Frequency-Inverse Document Frequency) method. The obtained dataset has been classified according to whether people can hear the sound. Na{\""\i}ve Bayes, Light Gradient Strengthening Machine (LGBM), support vector machine (SVM), decision tree, k-NN, logistic regression, and ...}",2023,https://doi.org/10.3390/diagnostics13030575,,"Mustafa K{\""u}{\c c}{\""u}kakarsu AND Ahmet Kavsao{\u g}lu AND Fayadh Alenezi AND Adi Alhudhaif AND Raghad Alwadie AND Kemal Polat",{A Novel Automatic Audiometric System Design Based on Machine Learning Methods Using the Brain{\textquoteright}s Electrical Activity Signals},misc,a130ef7b327a2975a262bd6064ede2e76e88cfda3c677ec28bea9e493efc01cb,,
{EN},{audiometry},"{Source: Diagnostics, Vol 13, Iss 3, p 575 (2023) ; Description: This study uses machine learning to perform the hearing test (audiometry) processes autonomously with EEG signals. Sounds with different amplitudes and wavelengths given to the person tested in standard hearing tests are assigned randomly with the interface designed with MATLAB GUI. The person stated that he heard the random size sounds he listened to with headphones but did not take action if he did not hear them. Simultaneously, EEG (electro-encephalography) signals were followed, and the waves created in the brain by the sounds that the person attended and did not hear were recorded. EEG data generated at the end of the test were pre-processed, and then feature extraction was performed. The heard and unheard information received from the MATLAB interface was combined with the EEG signals, and it was determined which sounds the person heard and which they did not hear. During the waiting period between the sounds given via the interface, no sound was given to the person. Therefore, these times are marked as not heard in EEG signals. In this study, brain signals were measured with Brain Products Vamp 16 EEG device, and then EEG raw data were created using the Brain Vision Recorder program and MATLAB. After the data set was created from the signal data produced by the heard and unheard sounds in the brain, machine learning processes were carried out with the PYTHON programming language. The raw data created with MATLAB was taken with the Python programming language, and after the pre-processing steps were completed, machine learning methods were applied to the classification algorithms. Each raw EEG data has been detected by the Count Vectorizer method. The importance of each EEG signal in all EEG data has been calculated using the TF-IDF (Term Frequency-Inverse Document Frequency) method. The obtained dataset has been classified according to whether people can hear the sound. Na{\""\i}ve Bayes, Light Gradient Strengthening Machine (LGBM), support vector machine (SVM), decision tree, k-NN, logistic regression, and ...}",2023,https://doi.org/10.3390/diagnostics13030575,{MDPI AG},"Mustafa K{\""u}{\c c}{\""u}kakarsu AND Ahmet Re{\c s}it Kavsao{\u g}lu AND Fayadh Alenezi AND Adi Alhudhaif AND Raghad Alwadie AND Kemal Polat",{A Novel Automatic Audiometric System Design Based on Machine Learning Methods Using the Brain{\textquoteright}s Electrical Activity Signals},article,48ed6b9c4955f70d9a38f2cbf565b42bc38bc8acf588e44c54cd706d6b9f7959,,
{eng},{Audiometry},"{Description: The authors extend their appreciation to the Deputyship for Research \& Innovation, Ministry of Education in Saudi Arabia for funding this research work through project number 223202. ; This study uses machine learning to perform the hearing test (audiometry) processes autonomously with EEG signals. Sounds with different amplitudes and wavelengths given to the person tested in standard hearing tests are assigned randomly with the interface designed with MATLAB GUI. The person stated that he heard the random size sounds he listened to with headphones but did not take action if he did not hear them. Simultaneously, EEG (electro-encephalography) signals were followed, and the waves created in the brain by the sounds that the person attended and did not hear were recorded. EEG data generated at the end of the test were pre-processed, and then feature extraction was performed. The heard and unheard information received from the MATLAB interface was combined with the EEG signals, and it was determined which sounds the person heard and which they did not hear. During the waiting period between the sounds given via the interface, no sound was given to the person. Therefore, these times are marked as not heard in EEG signals. In this study, brain signals were measured with Brain Products Vamp 16 EEG device, and then EEG raw data were created using the Brain Vision Recorder program and MATLAB. After the data set was created from the signal data produced by the heard and unheard sounds in the brain, machine learning processes were carried out with the PYTHON programming language. The raw data created with MATLAB was taken with the Python programming language, and after the pre-processing steps were completed, machine learning methods were applied to the classification algorithms. Each raw EEG data has been detected by the Count Vectorizer method. The importance of each EEG signal in all EEG data has been calculated using the TF-IDF (Term Frequency-Inverse Document Frequency) method. The obtained dataset has been ...}",2023,https://hdl.handle.net/20.500.12491/11664,{MDPI},"K{\""u}{\c c}{\""u}kakarsu, Mustafa AND Kavsao{\u g}lu, Ahmet Re{\c s}it AND Alenezi, Fayadh AND Alhudhaif, Adi AND Alwadie, Raghad AND Polat, Kemal",{A novel automatic audiometric system design based on machine learning methods using the brain{\textquoteright}s electrical activity signals},article,9e5f9bd2d61368b238f97e3cc1706cf94ae99d6fb1904e0276019ae4cedc242c,"{BA{\.I}B{\""U}, M{\""u}hendislik Fak{\""u}ltesi, Elektrik Elektronik M{\""u}hendisli{\u g}i B{\""o}l{\""u}m{\""u}}",
{en},{Digital Health},"{Source: Front Digit Health ; Description: Frontiers Media S.A. ; Even before the COVID-19 pandemic, there was mounting interest in remote testing solutions for audiology. The ultimate goal of such work was to improve access to hearing healthcare for individuals that might be unable or reluctant to seek audiological help in a clinic. In 2015, Diane Van Tasell patented a method for measuring an audiogram when the precise signal level was unknown (patent US 8,968,209 B2). In this method, the slope between pure-tone thresholds measured at 2 and 4 kHz is calculated and combined with questionnaire information in order to reconstruct the most likely audiograms from a database of options. An approach like the Van Tasell method is desirable because it is quick and feasible to do in a patient{\textquoteright}s home where exact stimulus levels are unknown. The goal of the present study was to use machine learning to assess the effectiveness of such audiogram-estimation methods. The National Health and Nutrition Examination Survey (NHANES), a database of audiologic and demographic information, was used to train and test several machine learning algorithms. Overall, 9,256 cases were analyzed. Audiometric data were classified using the Wisconsin Age-Related Hearing Impairment Classification Scale (WARHICS), a method that places hearing loss into one of eight categories. Of the algorithms tested, a random forest machine learning algorithm provided the best fit with only a few variables: the slope between 2 and 4 kHz; gender; age; military experience; and self-reported hearing ability. Using this method, 54.79\% of the individuals were correctly classified, 34.40\% were predicted to have a milder loss than measured, and 10.82\% were predicted to have a more severe loss than measured. Although accuracy was low, it is unlikely audibility would be severely affected if classifications were used to apply gains. Based on audibility calculations, underamplification still provided sufficient gain to achieve ~95\% correct (Speech Intelligibility Index >= 0.45) for sentence materials for 88\% of individuals. Fewer than 1\% ...}",2021,http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8521948/,,"Ellis, Gregory M. AND Souza, Pamela E.",{Using Machine Learning and the National Health and Nutrition Examination Survey to Classify Individuals With Hearing Loss},misc,56087d4067b7941b2926124e5012adbae88b46684fe2f9bffcaa605ae9c8311f,,
,,"{Source: Frontiers in Digital Health ; volume 3 ; ISSN 2673-253X ; Description: Even before the COVID-19 pandemic, there was mounting interest in remote testing solutions for audiology. The ultimate goal of such work was to improve access to hearing healthcare for individuals that might be unable or reluctant to seek audiological help in a clinic. In 2015, Diane Van Tasell patented a method for measuring an audiogram when the precise signal level was unknown (patent US 8,968,209 B2). In this method, the slope between pure-tone thresholds measured at 2 and 4 kHz is calculated and combined with questionnaire information in order to reconstruct the most likely audiograms from a database of options. An approach like the Van Tasell method is desirable because it is quick and feasible to do in a patient{\textquoteright}s home where exact stimulus levels are unknown. The goal of the present study was to use machine learning to assess the effectiveness of such audiogram-estimation methods. The National Health and Nutrition Examination Survey (NHANES), a database of audiologic and demographic information, was used to train and test several machine learning algorithms. Overall, 9,256 cases were analyzed. Audiometric data were classified using the Wisconsin Age-Related Hearing Impairment Classification Scale (WARHICS), a method that places hearing loss into one of eight categories. Of the algorithms tested, a random forest machine learning algorithm provided the best fit with only a few variables: the slope between 2 and 4 kHz; gender; age; military experience; and self-reported hearing ability. Using this method, 54.79\% of the individuals were correctly classified, 34.40\% were predicted to have a milder loss than measured, and 10.82\% were predicted to have a more severe loss than measured. Although accuracy was low, it is unlikely audibility would be severely affected if classifications were used to apply gains. Based on audibility calculations, underamplification still provided sufficient gain to achieve ~95\% correct (Speech Intelligibility Index >= 0.45) for sentence materials for 88\% of individuals. Fewer than 1\% ...}",2021,http://dx.doi.org/10.3389/fdgth.2021.723533,{Frontiers Media SA},"Ellis, Gregory M. AND Souza, Pamela E.",{Using Machine Learning and the National Health and Nutrition Examination Survey to Classify Individuals With Hearing Loss},article,71f53cf12a84fbd64dccb4e04cd1bb511fcbff4d78a11b328cdf8db813734991,{National Institute on Deafness and Other Communication Disorders},
,,"{Description: We propose a machine learning (ML)-based model for predicting cochlear dead regions (DRs) in patients with hearing loss of various etiologies. Five hundred and fifty-five ears from 380 patients (3,770 test samples) diagnosed with sensorineural hearing loss (SNHL) were analyzed. A threshold-equalizing noise (TEN) test was applied to detect the presence of DRs. Data were collected on sex, age, side of the affected ear, hearing loss etiology, word recognition scores (WRS), and pure-tone thresholds at each frequency. According to the cause of hearing loss as diagnosed by the physician, we categorized the patients into six groups: 1) SNHL with unknown etiology; 2) sudden sensorineural hearing loss (SSNHL); 3) vestibular schwannoma (VS); 4) Meniere{\textquoteright}s disease (MD); 5) noise-induced hearing loss (NIHL); or 6) presbycusis or age-related hearing loss (ARHL). To develop a predictive model, we performed recursive partitioning and regression for classification, logistic regression, and random forest. The overall prevalence of one or more DRs in test ears was 20.36\% (113 ears). Among the 3,770 test samples, the overall frequency-specific prevalence of DR was 6.7\%. WRS, pure-tone thresholds at each frequency, disease type (VS or MD), and frequency information were useful for predicting DRs. Sex and age were not associated with detecting DRs. Based on these results, we suggest possible predictive factors for determining the presence of DRs. To improve the predictive power of the model, a more flexible model or more clinical features, such as the duration of hearing loss or risk factors for developing DRs, may be needed.}",,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0217790,,Young-Soo Chang AND Heesung Park AND Sung Hwa Hong AND Won-Ho Chung AND Yang-Sun Cho AND Il Joon Moon,{Predicting cochlear dead regions in patients with hearing loss through a machine learning-based approach: A preliminary study},article,9b72721e3ab9864fb0d6b2fa2056df8fb2d01bdc75c91724abdea5243563029e,,
,{Interdisciplinary sciences},"{Description: This is the Supporting Datasets for the manuscript ""Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants"" by Luo et al in EBiomedicine . The two data sets were processed sequencing data, of which the Discovery Set was from the medical records and the Validation Set was from the Disabled Persons{\textquoteright} Federation. PS: No mutations found were indicated by 0, heterozygous mutations by 1, and homozygous mutations by 2}",2021,http://nbn-resolving.org/urn:nbn:nl:ui:13-d4-z19p,,"luo, X (via Mendeley Data)","{Data for: Machine learning-based genetic diagnosis models for hereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 variants}",misc,69e9300ac278907c26e2e96ca8f63e1b87f054c8b9457e5b9b655456b683982f,,
{eng},{Technology and Engineering},"{Source: 2022 ARO, the 45th Annual MidWinter Meeting, Abstract book}",2022,https://biblio.ugent.be/publication/8758193,,"Wouters, Marjoleen AND Drakopoulos, Fotios AND Verhulst, Sarah",{Learning from model-based approaches for hearing loss compensation : which speech features are enhanced in machine-learning-based audio algorithms for cochlear synaptopathy compensation?},proceedings,49362aad4b252cf7ba38edc766634a5a6598a416f2feee26704d5db029e17983,,
,{WN Radiology. Diagnostic Imaging},"{Description: Objectives: Immediately or after head-and-neck (H\&N) cancer chemoradiotherapy (CRT), patients may undergone significant sensorineural hearing loss (SNHL) which could affect their quality of life. Radiomic feature analysis is proposed to predict SNHL induced by CRT. Material and methods: 490 image features of 94 cochlea from 47 patients treated with three dimensional conformal RT (3DCRT) for different H\&N cancers were extracted from CT images. Different machine learning (ML) algorithms and also least absolute shrinkage and selection operator (LASSO) penalized logistic regression were implemented on radiomic features for feature selection, classification and prediction. Also, LASSO penalized logistic model was used for outcome modelling. Results: The predictive power of ten ML methods was more than 70 (in accuracy, precision and area under the curve of receiver operating characteristic curve (AUC)). According to the LASSO penalized logistic modelling, 10 of the 490 radiomic features selected as the associated features with SNHL status. All of the 10 features were statistically associated with SNHL (all of adjusted P-values <.001). Conclusion: CT radiomic analysis proposed in this study, could help in the prediction of hearing loss induced by chemoradiation. Our study also, demonstrates that combination of radiomic features with clinical and dosimetric variables can model radiotherapy outcome such as SNHL. {\^A}{\textcopyright} 2017 Associazione Italiana di Fisica Medica}",2018,http://eprints.iums.ac.ir/5971/,,"Abdollahi, H. AND Mostafaei, S. AND Cheraghi, S. AND Shiri, I. AND Rabi Mahdavi, S. AND Kazemnejad, A.",{Cochlea CT radiomics predicts chemoradiotherapy induced sensorineural hearing loss in head and neck cancer patients: A machine learning and multi-variable modelling study},article,c47240dfa796c93d719ebda1321bb3d819ffb96eb482da42ad1e6e04565cd18d,,
,,"{Description: Objectives: Immediately or after head-and-neck (H\&N) cancer chemoradiotherapy (CRT), patients may undergone significant sensorineural hearing loss (SNHL) which could affect their quality of life. Radiomic feature analysis is proposed to predict SNHL induced by CRT. Material and methods: 490 image features of 94 cochlea from 47 patients treated with three dimensional conformal RT (3DCRT) for different H\&N cancers were extracted from CT images. Different machine learning (ML) algorithms and also least absolute shrinkage and selection operator (LASSO) penalized logistic regression were implemented on radiomic features for feature selection, classification and prediction. Also, LASSO penalized logistic model was used for outcome modelling. Results: The predictive power of ten ML methods was more than 70 (in accuracy, precision and area under the curve of receiver operating characteristic curve (AUC)). According to the LASSO penalized logistic modelling, 10 of the 490 radiomic features selected as the associated features with SNHL status. All of the 10 features were statistically associated with SNHL (all of adjusted P-values <.001). Conclusion: CT radiomic analysis proposed in this study, could help in the prediction of hearing loss induced by chemoradiation. Our study also, demonstrates that combination of radiomic features with clinical and dosimetric variables can model radiotherapy outcome such as SNHL. {\^A}{\textcopyright} 2017 Associazione Italiana di Fisica Medica}",2018,http://eprints.iums.ac.ir/876/,,"Abdollahi, H. AND Mostafaei, S. AND Cheraghi, S. AND Shiri, I. AND Rabi Mahdavi, S. AND Kazemnejad, A.",{Cochlea CT radiomics predicts chemoradiotherapy induced sensorineural hearing loss in head and neck cancer patients: A machine learning and multi-variable modelling study},article,f85ca15a124815ffab83a85f692077eea8343661273082b0e0108bac547085d4,,
{en},{General Physics and Astronomy},"{Source: Physica Medica ; volume 45, page 192-197 ; ISSN 1120-1797}",2018,http://dx.doi.org/10.1016/j.ejmp.2017.10.008,{Elsevier BV},"Abdollahi, Hamid AND Mostafaei, Shayan AND Cheraghi, Susan AND Shiri, Isaac AND Rabi Mahdavi, Seied AND Kazemnejad, Anoshirvan",{Cochlea CT radiomics predicts chemoradiotherapy induced sensorineural hearing loss in head and neck cancer patients: A machine learning and multi-variable modelling study},article,f6b57b70941b281ac41cd0eb83180fca1d9f94d314a4d85add64529e00fed64c,,
,{Otorhinolaryngology},"{Description: SAGE Journals ; Supplemental material, sj-csv-3-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417417.v1,,"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-csv-3-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},misc,371db69a454e721d442e213e4b3dc75b709d666dbe3a813188483f45b474dc91,,
,{Otorhinolaryngology},"{Description: Supplemental material, sj-docx-1-aor-10.1177_00034894231206902 for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review by Amirhossein Aghakhani, Milad Yousefi and Mir Saeed Yekaninejad in Annals of Otology, Rhinology \& Laryngology ...}",2023,https://dx.doi.org/10.25384/sage.24417420.v1,{SAGE Journals},"Aghakhani, Amirhossein AND Yousefi, Milad AND Yekaninejad, Mir Saeed",{sj-docx-1-aor-10.1177_00034894231206902 {\textendash} Supplemental material for Machine Learning Models for Predicting Sudden Sensorineural Hearing Loss Outcome: A Systematic Review ...},article,85c675b9e9e28c9438c9447f003400eaeb78158e611d640dbc8b5984dbb037d0,,
