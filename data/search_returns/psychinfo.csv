ORN,VN,DB,AN,TI,DP,YR,PH,AU,MA,SO,MO,OL,AB,CP,JN,VO,IP,PG,FTURL,XL,PE,OC,CA,PS,URL
1,Ovid Technologies,APA PsycInfo,2024-54571-035,Phenotypes and clinical subgroups in vestibular migraine: A cross-sectional study with cluster analysis. [References].,Mar 2024,2024,"First Posting: Oct 2023

Accepted: Oct 2023

First Submitted: Aug 2023.","Teggi, Roberto

Colombo, Bruno

Cugnata, Federica

Albera, Roberto

Libonati, Giacinto Asprella

Balzanelli, Cristiano

Casani, Augusto Pietro

Cangiano, Iacopo

Familiari, Marco

Lucisano, Sergio

Mandala, Marco

Neri, Giampiero

Pecci, Rudi

Bussi, Mario

Filippi, Massimo","Teggi, Roberto: teggi.roberto@hsr.it","Neurological Sciences. Vol.45,(3), 2024, pp. 1209-1216.",Mar,Italian Journal of Neurological Sciences,"Objective: The aim of this multicentric cross-sectional study was to collect phenotypes and clinical variability on a large sample of 244 patients enrolled in different university centers in Italy, trying to differentiate subtypes of VM. Background: VM is one of the most frequent episodic vertigo characterized by a great clinical variability for duration of attacks and accompanying symptoms. Diagnosis is based only on clinical history of episodic vertigo in 50% of cases associated with migrainous headache or photo/phonophobia. Methods: We enrolled in different university centers 244 patients affected by definite VM according to the criteria of the Barany Society between January 2022 and December 2022. An audiometric examination and a CNS MRI were performed before inclusion. Patients with low-frequency sensorineural hearing loss were not included, as well as patients with an MRI positive otherwise that for microischemic lesions. Patients were asked to characterize vestibular symptoms choosing among (multiple answers were allowed): internal vertigo, dizziness, visuo-vestibular symptoms/external vertigo; onset of vertigo and duration, neurovegetative, and cochlear accompanying symptoms (hearing loss, tinnitus, and fullness during attacks) were collected as well as migrainous headache and/or photo/phonophobia during vertigo; autoimmune disorders were also analyzed. A bedside examination was performed including study of spontaneous-positional nystagmus with infrared video goggles, post head shaking ny, skull vibration test, and video head impulse test. Results: We included 244 subjects, 181 were females (74.2%). The age of onset of the first vertigo was 36.6 +/- 14.5 while of the first headache was 23.2 +/- 10.1. A positive correlation has been found between the first headache and the first vertigo. The mean duration of vertigo attacks was 11 +/- 16 h. We carried on a cluster analysis to identify subgroups of patients with common clinical features. Four variables allowed to aggregate clusters: age of onset of vertigo, duration of vertigo attacks, presence of migrainous headache during vertigo, and presence of cochlear symptoms during vertigo. We identified 5 clusters: cluster 1/group 1 (23 subjects, 9.4%) characterized by longer duration of vertigo attacks; cluster 2/group 2 (52 subjects, 21.3%) characterized by absence of migrainous headache and cochlear symptoms during vertigo; cluster 3/group 3 (44 subjects, 18%) characterized by presence of cochlear symptoms during vertigo but not headache; cluster 4/group 4 (57 subjects, 23.4%) by the presence of both cochlear symptoms and migrainous headache during vertigo; cluster 5/group 5 (68 subjects, 27.9%) characterized by migrainous headache but no cochlear symptoms during vertigo. Conclusion: VM is with any evidence a heterogeneous disorder and clinical presentations exhibit a great variability. In VM, both symptoms orienting toward a peripheral mechanism (cochlear symptoms) and central ones (long lasting positional non-paroxysmal vertigo) may coexist. Our study is the first published trying to characterize subgroups of VM subjects, thus orienting toward different pathophysiological mechanisms. (PsycInfo Database Record (c) 2024 APA, all rights reserved)","HOLDER: Fondazione Societa Italiana di Neurologia
YEAR: 2023",Neurological Sciences,45,3,1209-1216,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1007%2fs10072-023-07116-w
2,Ovid Technologies,APA PsycInfo,2024-14784-001,Investigation of hearing loss in elderly vertigo and dizziness patients in the past 10 years. [References].,"Sep 15, 2023",2023,"First Posting: Sep 2023

Accepted: Aug 2023

First Submitted: May 2023.","Wang, Qian

Chen, Aiting

Hong, Mengdi

Liu, Xingjian

Du, Yi

Wu, Ziming

Cheng, Wenbo

Ji, Fei","Ji, Fei: argfei301@163.com","Frontiers in Aging Neuroscience. Vol.15, 2023, ArtID 1225786.",Sep,,"Background: Vertigo and hearing loss are both prevalent in the elderly. This study retrospectively analyzed hearing test results from elderly patients experiencing vertigo and dizziness at ENT outpatient over a 10-year period, in order to study the patterns of hearing loss in this patient population. Methods: Nine thousand three hundred eighty four patients over 50 years old underwent retrospective collection and screening of outpatient diagnosis, pure tone audiometry, acoustic immittance measurement (tympanogram) and auditory brainstem response (ABR) test. The patient's audiograms are divided into 7 subtypes according to a set of fixed criteria. Meanwhile, K-Means clustering analysis method was used to classify the audiogram. Results: The Jerger classification of tympanogram in elderly patients with vertigo and dizziness showed the majority falling under type A. The leading audiogram shapes were flat (27.81% in right ear and 26.89% in left ear), high-frequency gently sloping (25.97% in right ear and 27.34% in left ear), and high-frequency steeply sloping (21.60% in right ear and 22.53% in left ear). Meniere's disease (MD; 30.87%), benign recurrent vertigo (BRV; 19.07%), and benign paroxysmal positional vertigo (BPPV; 15.66%) were the most common etiologies in elderly vestibular diseases. We observed statistically significant differences in hearing thresholds among these vestibular diseases (P < 0.001). K-Means clustering analysis suggested that the optimal number of clusters was three, with sample sizes for the three clusters being 2,747, 2,413, and 4,139, respectively. The ANOVA statistical results of each characteristic value showed P < 0.001. Conclusion: The elderly patients often have mild to moderate hearing loss as a concomitant symptom with vertigo. Female patients have better hearing thresholds than males. The dominant audiometric shapes in this patient population were flat, high-frequency gently sloping, and high-frequency steeply sloping according to a set of fixed criteria. This study highlights the need for tailored strategies in managing hearing loss in elderly patients with vertigo and dizziness. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
HOLDER: Wang, Chen, Hong, Liu, Du, Wu, Cheng and Ji
YEAR: 2023",Frontiers in Aging Neuroscience,15,,,Click here for full text options,SFX,11,"Frontiers Research Foundation, Switzerland",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.3389%2ffnagi.2023.1225786
3,Ovid Technologies,APA PsycInfo,2023-86540-005,The future of hearing aid technology: Can technology turn us into superheroes? [References].,Jul 2023,2023,"First Posting: Apr 2023

Accepted: Mar 2023

First Submitted: Feb 2023.","Hohmann, Volker","Hohmann, Volker: volker.hohmann@uol.de","Zeitschrift fur Gerontologie und Geriatrie. Vol.56,(4), 2023, pp. 283-289.",Jul,Zeitschrift fur Gerontologie,"Background: Hearing aid technology has proven to be successful in the rehabilitation of hearing loss, but its performance is still limited in difficult everyday conditions characterized by noise and reverberation. Objective: Introduction to the current state of hearing aid technology and presentation of the current state of research and future developments. Methods: The current literature was analyzed and several specific new developments are presented. Results: Both objective and subjective data from empirical studies show the limitations of the current technology. Examples of current research show the potential of machine learning-based algorithms and multimodal signal processing for improving speech processing and perception, of using virtual reality for improving hearing device fitting and of mobile health technology for improving hearing health services. Conclusion: Hearing device technology will remain a key factor in the rehabilitation of hearing impairments. New technology, such as machine learning and multimodal signal processing, virtual reality and mobile health technology, will improve speech enhancement, individual fitting and communication training, thus providing better support for all hearing-impaired patients, including older patients with disabilities or declining cognitive skills. (PsycInfo Database Record (c) 2023 APA, all rights reserved)
Abstract (German)
Hintergrund: Die Horgeratetechnologie hat sich bei der Rehabilitation von Horverlusten als erfolgreich erwiesen, aber ihre Leistung ist unter schwierigen Alltagsbedingungen, die durch Larm und Nachhall gekennzeichnet sind, immer noch begrenzt. Zielsetzung: Einfuhrung in den aktuellen Stand der Horgeratetechnologie und Darstellung des aktuellen Forschungsstandes und der zukunftigen Entwicklung. Methoden: Die aktuelle Literatur wird analysiert und mehrere spezifische Neuentwicklungen werden vorgestellt. Ergebnisse: Sowohl objektive als auch subjektive Daten aus empirischen Studien zeigen die Grenzen der derzeitigen Technologie auf. Beispiele aus der aktuellen Forschung belegen das Potenzial von auf maschinellem Lernen basierenden Algorithmen und multimodaler Signalverarbeitung zur Verbesserung der Sprachverarbeitung und -wahrnehmung, der Nutzung von virtueller Realitat zur Verbesserung der Horgerateanpassung und von mobiler Gesundheitstechnologie zur Verbesserung der Horgesundheitsdienste. Schlussfolgerung: Die Horgeratetechnologie wird ein Schlusselfaktor bei der Rehabilitation von Horschaden bleiben. Neue Technologien wie maschinelles Lernen und multimodale Signalverarbeitung, virtuelle Realitat und mobile Gesundheitstechnologien werden die Sprachverbesserung, die individuelle Anpassung und das Kommunikationstraining verbessern. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature
YEAR: 2023",Zeitschrift fur Gerontologie und Geriatrie,56,4,283-289,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1007%2fs00391-023-02179-y
4,Ovid Technologies,APA PsycInfo,2023-25052-001,How much individualization is required to predict the individual effect of suprathreshold processing deficits? Assessing plomp's distortion component with psychoacoustic detection thresholds and FADE. [References].,Dec 2022,2022,"First Posting: Sep 2022

Accepted: Sep 2022

Revised: Aug 2022

First Submitted: Dec 2021.","Hulsmeier, David

Kollmeier, Birger","Kollmeier, Birger: birger.kollmeier@uol.de","Hearing Research. Vol.426, 2022, pp. 1-14.  ArtID 108609.",Dec,,"Plomp introduced an empirical separation of the increased speech recognition thresholds (SRT) in listeners with a sensorineural hearing loss into an Attenuation (A) component (which can be compensated by amplification) and a non-compensable Distortion (D) component. Previous own research backed up this notion by speech recognition models that derive their SRT prediction from the individual audiogram with or without a psychoacoustic measure of suprathreshold processing deficits. To determine the precision in separating the A and D component for the individual listener with various individual measures and individualized models, SRTs with 40 listeners with a variation in hearing impairment were obtained in quiet, stationary noise, and fluctuating noise (ICRA 5-250 and babble). Both the clinical audiogram and an adaptive, precise sweep audiogram were obtained as well as tone-in-noise detection thresholds at four frequencies to characterize the individual hearing impairment. For predicting the SRT, the FADE-model (which is based on machine learning) was used with either of the two audiogram procedures and optionally the individual tone-in-noise detection thresholds. The results indicate that the precisely measured swept tone audiogram allows for a more precise prediction of the individual SRT in comparison to the clinical audiogram (RMS error of 4.3 dB vs. 6.4 dB, respectively). While an estimation from the precise audiogram and FADE performed equally well in predicting the individual A and D component, the further refinement of including the tone-in-noise detection threshold with FADE led to a slight improvement of prediction accuracy (RMS error of 3.3 dB, 4.6 dB and 1.4 dB, for SRT, A and D component, respectively). Hence, applying FADE is advantageous for scientific purposes where a consistent modeling of different psychoacoustical effects in the same listener with a minimum amount of assumptions is desirable. For clinical purposes, however, a precisely measured audiogram and an estimation of the expected D component using a linear regression appears to be a satisfactory first step towards precision audiology. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: Elsevier B.V.
YEAR: 2022",Hearing Research,426,,1-14,Click here for full text options,SFX,14,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.heares.2022.108609
5,Ovid Technologies,APA PsycInfo,2024-00930-001,A multidimensional characterization of the neurocognitive architecture underlying age-related temporal speech processing. [References].,Sep 2023,2023,"First Posting: Jul 2023

Accepted: Jul 2023

Revised: Jul 2023

First Submitted: Jul 2022.","Elmer, Stefan

Kurthen, Ira

Meyer, Martin

Giroud, Nathalie","Elmer, Stefan: s.elmer@psychologie.uzh.ch","NeuroImage. Vol.278, 2023, pp. 1-16.  ArtID 120285.",Sep,,"Healthy aging is often associated with speech comprehension difficulties in everyday life situations despite a pure-tone hearing threshold in the normative range. Drawing on this background, we used a multidimensional approach to assess the functional and structural neural correlates underlying age-related temporal speech processing while controlling for pure-tone hearing acuity. Accordingly, we combined structural magnetic resonance imaging and electroencephalography, and collected behavioral data while younger and older adults completed a phonetic categorization and discrimination task with consonant-vowel syllables varying along a voice-onset time continuum. The behavioral results confirmed age-related temporal speech processing singularities which were reflected in a shift of the boundary of the psychometric categorization function, with older adults perceiving more syllable characterized by a short voice-onset time as /ta/ compared to younger adults. Furthermore, despite the absence of any between-group differences in phonetic discrimination abilities, older adults demonstrated longer N100/P200 latencies as well as increased P200 amplitudes while processing the consonant-vowel syllables varying in voice-onset time. Finally, older adults also exhibited a divergent anatomical gray matter infrastructure in bilateral auditory-related and frontal brain regions, as manifested in reduced cortical thickness and surface area. Notably, in the younger adults but not in the older adult cohort, cortical surface area in these two gross anatomical clusters correlated with the categorization of consonant-vowel syllables characterized by a short voice-onset time, suggesting the existence of a critical gray matter threshold that is crucial for consistent mapping of phonetic categories varying along the temporal dimension. Taken together, our results highlight the multifaceted dimensions of age-related temporal speech processing characteristics, and pave the way toward a better understanding of the relationships between hearing, speech and the brain in older age. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
HOLDER: The Authors
YEAR: 2023",NeuroImage,278,,1-16,Click here for full text options,SFX,16,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1016%2fj.neuroimage.2023.120285
6,Ovid Technologies,APA PsycInfo,2023-84477-003,Digital approaches to automated and machine learning assessments of hearing: Scoping review. [References].,Feb 2022,2022,"First Posting: Feb 2022

Accepted: Dec 2021

Revised: Dec 2021

First Submitted: Aug 2021.","Wasmann, Jan-Willem

Pragt, Leontien

Eikelboom, Robert

Swanepoel, De Wet","Wasmann, Jan-Willem: Jan-Willem.Wasmann@radboudumc.nl","Journal of Medical Internet Research. Vol.24,(2), 2022, pp. 1-17.",Feb,,"Background: Hearing loss affects 1 in 5 people worldwide and is estimated to affect 1 in 4 by 2050. Treatment relies on the accurate diagnosis of hearing loss; however, this first step is out of reach for > 80% of those affected. Increasingly automated approaches are being developed for self-administered digital hearing assessments without the direct involvement of professionals. Objective: This study aims to provide an overview of digital approaches in automated and machine learning assessments of hearing using pure-tone audiometry and to focus on the aspects related to accuracy, reliability, and time efficiency. This review is an extension of a 2013 systematic review. Methods: A search across the electronic databases of PubMed, IEEE, and Web of Science was conducted to identify relevant reports from the peer-reviewed literature. Key information about each report's scope and details was collected to assess the commonalities among the approaches. Results: A total of 56 reports from 2012 to June 2021 were included. From this selection, 27 unique automated approaches were identified. Machine learning approaches require fewer trials than conventional threshold-seeking approaches, and personal digital devices make assessments more affordable and accessible. Validity can be enhanced using digital technologies for quality surveillance, including noise monitoring and detecting inconclusive results. Conclusions: In the past 10 years, an increasing number of automated approaches have reported similar accuracy, reliability, and time efficiency as manual hearing assessments. New developments, including machine learning approaches, offer features, versatility, and cost-effectiveness beyond manual audiometry. Used within identified limitations, automated assessments using digital devices can support task-shifting, self-care, telehealth, and clinical care pathways. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.
HOLDER: Jan-Willem Wasmann, Leontien Pragt, Robert Eikelboom, De Wet Swanepoel",Journal of Medical Internet Research,24,2,1-17,Click here for full text options,SFX,,"Gunther Eysenbach, Canada",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.2196%2f32581
7,Ovid Technologies,APA PsycInfo,2023-79585-006,Evaluation of machine learning algorithms and explainability techniques to detect hearing loss from a speech-in-noise screening test. [References].,"Sep 21, 2022",2022,"Accepted: May 2022

Revised: Dec 2021

First Submitted: Sep 2021.","Lenatti, Marta

Moreno-Sanchez, Pedro A

Polo, Edoardo M

Mollura, Maximiliano

Barbieri, Riccardo

Paglialonga, Alessia","Lenatti, Marta: marta.lenatti@ieiit.cnr.it","American Journal of Audiology. Vol.31,(3, Suppl), 2022, pp. 961-979.",Sep,,"Purpose: The aim of this study was to analyze the performance of multivariate machine learning (ML) models applied to a speech-in-noise hearing screening test and investigate the contribution of the measured features toward hearing loss detection using explainability techniques. Method: Seven different ML techniques, including transparent (i.e., decision tree and logistic regression) and opaque (e.g., random forest) models, were trained and evaluated on a data set including 215 tested ears (99 with hearing loss of mild degree or higher and 116 with no hearing loss). Post hoc explainability techniques were applied to highlight the role of each feature in predicting hearing loss. Results: Random forest (accuracy = .85, sensitivity = .86, specificity = .85, precision = .84) performed, on average, better than decision tree (accuracy = .82, sensitivity = .84, specificity = .80, precision = .79). Support vector machine, logistic regression, and gradient boosting had similar performance as random forest. According to post hoc explainability analysis on models generated using random forest, the features with the highest relevance in predicting hearing loss were age, number and percentage of correct responses, and average reaction time, whereas the total test time had the lowest relevance. Conclusions: This study demonstrates that a multivariate approach can help detect hearing loss with satisfactory performance. Further research on a bigger sample and using more complex ML algorithms and explainability techniques is needed to fully investigate the role of input features (including additional features such as risk factors and individual responses to low-/high-frequency stimuli) in predicting hearing loss. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.
HOLDER: The Authors
YEAR: 2022",American Journal of Audiology,31,"3, Suppl",961-979,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1044%2f2022_AJA-21-00194
8,Ovid Technologies,APA PsycInfo,2023-49518-001,Different neuroanatomical correlates for temporal and spectral supra-threshold auditory tasks and speech in noise recognition in older adults with hearing impairment. [References].,Mar 2023,2023,"Accepted: Jan 2023

Revised: Aug 2022

First Submitted: Apr 2021.","Neuschwander, Pia

Schmitt, Raffael

Jagoda, Laura

Kurthen, Ira

Giroud, Nathalie

Meyer, Martin","Meyer, Martin: martin.meyer@uzh.ch","European Journal of Neuroscience. Vol.57,(6), 2023, pp. 981-1002.",Mar,,"Varying degrees of pure-tone hearing loss in older adults are differentially associated with cortical volume (CV) and thickness (CT) within and outside of the auditory pathway. This study addressed the question to what degree supra-threshold auditory performance (i.e., temporal compression and frequency selectivity) as well as speech in noise (SiN) recognition are associated with neurostructural correlates in a sample of 59 healthy older adults with mild to moderate pure-tone hearing loss. Using surface-based morphometry on T1-weighted MRI images, CT, CV, and surface area (CSA) of several regions-of-interest were obtained. The results showed distinct neurostructural patterns for the different tasks in terms of involved regions as well as morphometric parameters. While pure-tone averages (PTAs) positively correlated with CT in a right hemisphere superior temporal sulcus and gyrus cluster, supra-threshold auditory perception additionally extended significantly to CV and CT in left and right superior temporal clusters including Heschl's gyrus and sulcus, the planum polare and temporale. For SiN recognition, we found significant correlations with an auditory-related CT cluster and furthermore with language-related areas in the prefrontal cortex. Taken together, our results show that different auditory abilities are differently associated with cortical morphology in older adults with hearing impairment. Still, a common pattern is that greater PTAs and poorer supra-threshold auditory performance as well as poorer SiN recognition are all related to cortical thinning and volume loss but not to changes in CSA. These results support the hypothesis that mostly CT undergoes alterations in the context of auditory decline, while CSA remains stable. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: Published by Federation of European Neuroscience Societies and John Wiley & Sons Ltd. This is an open access article under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial and no modifications or adaptations are made.
HOLDER: University of Zurich and The Authors-European Journal of Neuroscience
YEAR: 2023",European Journal of Neuroscience,57,6,981-1002,Click here for full text options,SFX,,"Blackwell Publishing, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&DO=10.1111%2fejn.15922
9,Ovid Technologies,APA PsycInfo,2023-29001-001,Special needs classroom assessment using a sign language communicator (CASC) based on artificial intelligence (AI) techniques. [References].,2023,2023,,"Mouti, Samar

Rihawi, Samer",,"International Journal of e-Collaboration. Vol.19,(1), 2023, ArtID 60.",,,"This research focuses on deaf students in the United Arab Emirates. The proposed classroom assessment using sign language communicator (CASC) for special needs students (SN) in the United Arab Emirates is based on artificial intelligence (AI) tools. This research provides essential services for teaching evaluations, learning outcome assessments, and the development of learning environments. CASC model is composed of two models. The first model converts the speech to a sign language, which contains a speech recognizer, sign language recognizer. The second model converts the sign language to written text. This model generates a report for students' understanding and class evaluation in advance before ending the course based on the sign language recognition and image processing tools. This model will have a significantly positive impact on SN students' success and on effective lecturing and optimizing teaching and learning in the classroom. The accuracy of the model is 92%. The analysis of the student's feedback in real-time provides effective instructional strategies. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: IGI Global
YEAR: 2023",International Journal of e-Collaboration,19,1,,Click here for full text options,SFX,15,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-29001-001
10,Ovid Technologies,APA PsycInfo,2023-10936-251,Learning-based reference-free speech quality assessment for normal hearing and hearing impaired applications.DP  - 2023,,2023,,"Salehi, Haniyeh",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.84,(3-B), 2023, pp. No Pagination Specified.",,Dissertation Abstracts International,"Accurate speech quality measures are highly attractive and beneficial in the design, finetuning, and benchmarking of speech processing algorithms, devices, and communication systems. Switching from narrowband telecommunication to wideband telephony is a change within the telecommunication industry which provides users with better speech quality experience but introduces a number of challenges in speech processing. Noise is the most common distortion on audio signals and as a result there have been a lot of studies on developing high performance noise reduction algorithms. Assistive hearing devices are designed to decrease communication difficulties for people with loss of hearing. As the algorithms within these devices become more advanced, it becomes increasingly crucial to develop accurate and robust quality metrics to assess their performance. Objective speech quality measurements are more attractive compared to subjective assessments as they are cost-effective and subjective variability is eliminated. Although there has been extensive research on objective speech quality evaluation for narrowband speech, those methods are unsuitable for wideband telephony. In the case of hearing-impaired applications, objective quality assessment is challenging as it has to be capable of distinguishing between desired modifications which make signals audible and undesired artifacts. In this thesis a model is proposed that allows extracting two sets of features from the distorted signal only. This approach which is called reference-free (nonintrusive) assessment is attractive as it does not need access to the reference signal. Although this benefit makes nonintrusive assessments suitable for real-time applications, more features need to be extracted and smartly combined to provide comparable accuracy as intrusive metrics. Two feature vectors are proposed to extract information from distorted signals and their performance is examined in three studies. In the first study, both feature vectors are trained on various portions of a noise reduction database for normal hearing applications. In the second study, the same investigation is performed on two sets of databases acquired through several hearing aids. Third study examined the generalizability of the proposed metrics on benchmarking four wireless remote microphones in a variety of environmental conditions. Machine learning techniques are deployed for training the models in the three studies. The studies show that one of the feature sets is robust when trained on different portions of the data from different databases and it also provides good quality prediction accuracy for both normal hearing and hearing-impaired applications. (PsycInfo Database Record (c) 2023 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,84,3-B,No Pagination Specified,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc22&AN=2023-10936-251
11,Ovid Technologies,APA PsycInfo,2022-80152-001,Age-related decline of speech perception. [References].,"Jun 22, 2022",2022,"First Posting: Jun 2022

Accepted: May 2022

First Submitted: Mar 2022.","Hoppe, Ulrich

Hocke, Thomas

Iro, Heinrich","Hoppe, Ulrich: ulrich.hoppe@uk-erlangen.de","Frontiers in Aging Neuroscience. Vol.14, 2022, ArtID 891202.",Jun,,"Hearing loss is one of the most common disorders worldwide. It affects communicative abilities in all age groups. However, it is well known that elderly people suffer more frequently from hearing loss. Two different model approaches were employed: A generalised linear model and a random forest regression model were used to quantify the relationship between pure-tone hearing loss, age, and speech perception. Both models were applied to a large clinical data set of 19,801 ears, covering all degrees of hearing loss. They allow the estimation of age-related decline in speech recognition for different types of audiograms. Our results show that speech scores depend on the specific type of hearing loss and life decade. We found age effects for all degrees of hearing loss. A deterioration in speech recognition of up to 25 percentage points across the whole life span was observed for constant pure-tone thresholds. The largest decrease was 10 percentage points per life decade. This age-related decline in speech recognition cannot be explained by elevated hearing thresholds as measured by pure-tone audiometry. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
HOLDER: Hoppe, Hocke and Iro
YEAR: 2022",Frontiers in Aging Neuroscience,14,,,Click here for full text options,SFX,11,"Frontiers Research Foundation, Switzerland",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.3389%2ffnagi.2022.891202
12,Ovid Technologies,APA PsycInfo,2022-69797-001,Disrupted topological organization of resting-state functional brain networks in age-related hearing loss. [References].,"May 20, 2022",2022,"First Posting: May 2022

Accepted: Apr 2022

First Submitted: Mar 2022.","Yong, Wei

Song, Jiajie

Xing, Chunhua

Xu, Jin-Jing

Xue, Yuan

Yin, Xindao

Wu, Yuanqing

Chen, Yu-Chen","Wu, Yuanqing: cnnxdd@163.com; Chen, Yu-Chen: chenyuchen1989@126.com","Frontiers in Aging Neuroscience. Vol.14, 2022, ArtID 907070.",May,,"Purpose: Age-related hearing loss (ARHL), associated with the function of speech perception decreases characterized by bilateral sensorineural hearing loss at high frequencies, has become an increasingly critical public health problem. This study aimed to investigate the topological features of the brain functional network and structural dysfunction of the central nervous system in ARHL using graph theory. Methods: Forty-six patients with ARHL and forty-five age, sex, and education-matched healthy controls were recruited to undergo a resting-state functional magnetic resonance imaging (fMRI) scan in this study. Graph theory was applied to analyze the topological properties of the functional connectomes by studying the local and global organization of neural networks. Results: Compared with healthy controls, the patient group showed increased local efficiency (Eloc) and clustering coefficient (Cp) of the small-world network. Besides, the degree centrality (Dc) and nodal efficiency (Ne) values of the left inferior occipital gyrus (IOG) in the patient group showed a decrease in contrast with the healthy control group. In addition, the intra-modular interaction of the occipital lobe module and the inter-modular interaction of the parietal occipital module decreased in the patient group, which was positively correlated with Dc and Ne. The intra-modular interaction of the occipital lobe module decreased in the patient group, which was negatively correlated with the Eloc. Conclusion: Based on fMRI and graph theory, we indicate the aberrant small-world network topology in ARHL and dysfunctional interaction of the occipital lobe and parietal lobe, emphasizing the importance of dysfunctional left IOG. These results suggest that early diagnosis and treatment of patients with ARHL is necessary, which can avoid the transformation of brain topology and decreased brain function. (PsycInfo Database Record (c) 2022 APA, all rights reserved)","STATEMENT: This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
HOLDER: Yong, Song, Xing, Xu, Xue, Yin, Wu and Chen
YEAR: 2022",Frontiers in Aging Neuroscience,14,,,Click here for full text options,SFX,9,"Frontiers Research Foundation, Switzerland",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc21&DO=10.3389%2ffnagi.2022.907070
13,Ovid Technologies,APA PsycInfo,2021-26970-001,Assessment of hearing screening programmes across 47 countries or regions I: Provision of newborn hearing screening. [References].,Nov 2021,2021,"Accepted: Feb 2021

Revised: Jan 2021

First Submitted: May 2020.","Busse, Andrea M. L

Mackey, Allison R

Hoeve, Hans L. J

Goedegebure, Andre

Carr, Gwen

Uhlen, Inger M

Simonsz, Huibert J","Busse, Andrea M. L.: a.busse@erasmusmc.nl","International Journal of Audiology. Vol.60,(11), 2021, pp. 821-830.",Nov,,"Objectives: Newborn hearing screening (NHS) varies regarding number and type of tests, location, age, professionals and funding. We compared the provision of existing screening programmes. Design: A questionnaire containing nine domains: demography, administration, existing screening, coverage, tests, diagnosis, treatment, cost and adverse effects, was presented to hearing screening experts. Responses were verified. Clusters were identified based on number of screening steps and use of OAE or aABR, either for all infants or for well and high-risk infants (dual-protocol). Study sample: Fifty-two experts completed the questionnaire sufficiently: 40 European countries, Russia, Malawi, Rwanda, India and China. Results: It took considerable effort to find experts for all countries with sufficient time and knowledge. Data essential for evaluation are often not collected. Infants are first screened in maternity wards in most countries. Human development index and health expenditure were high among countries with dual protocols, three screening steps, including aABR, and low among countries without NHS and countries using OAE for all infants. Nationwide implementation of NHS took 6 years, on average. Conclusion: The extent and complexity of NHS programmes are primarily related to health expenditure and HDI. Data collection should be improved to facilitate comparison of NHS programmes across borders. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: Published by Informa UK Limited, trading as Taylor & Francis Group on behalf of British Society of Audiology, International Society of Audiology, and Nordic Audiological Society. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives License (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited, and is not altered, transformed, or built upon in any way.
HOLDER: The Authors
YEAR: 2021",International Journal of Audiology,60,11,821-830,Click here for full text options,SFX,,"Informa Healthcare, US",EUSREEN Foundation.,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1080%2f14992027.2021.1886350
14,Ovid Technologies,APA PsycInfo,2019-33408-008,Speech development for children with impaired hearing.DP  - 2021,,2021,,"Seal, Brenda C",,"Hull, Raymond H [Ed]. (2021). Introduction to aural rehabilitation: Serving children and adults with hearing loss., 3rd ed. (pp. 161-189). xii, 513pp. San Diego, CA, US: Plural Publishing Inc.; US.",,,"This chapter provides a brief description on speech development for children with impaired hearing. Daniel Ling's Speech and the Hearing-Impaired Child: Theory and Practice (1976) had a strong influence on speech practices of the last quarter of the 20th century. This replacement chapter honors his legacy with many of his insights that remain relevant today and with revised information from the 21st century. In the area of communication, the authors generally report two areas: speech perception and speech production. Audiologists usually document speech perception and speech-language pathologists (SLPs) usually document speech production. Ling also designed two speech production tests to determine a child's speech performance and speech potential. The Phonetic Level Evaluation is a repeat-after-me test divided into (1) vocal quality or suprasegments, with varied duration, intensity, and pitch patterns assessed with consonant-vowel syllables; and then segments, concentrating on (2) vowel and diphthong productions and (3) with three consonants steps, representing a developmental progression of consonants in three steps; and, finally, two stages of consonant blends or clusters: (4) world-initial consonant blends and (5) word-final consonant blends. (PsycInfo Database Record (c) 2022 APA, all rights reserved)",,,,,161-189,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&AN=2019-33408-008
15,Ovid Technologies,APA PsycInfo,2021-11380-001,Mismatched response predicts behavioral speech discrimination outcomes in infants with hearing loss and normal hearing. [References].,Mar-Apr 2021,2021,"Accepted: Dec 2020

First Submitted: Mar 2020.","Uhler, Kristin

Hunter, Sharon

Gilley, Phillip M","Uhler, Kristin: kristin.uhler@cuanschutz.edu","Infancy. Vol.26,(2), 2021, pp. 327-348.",Mar-Apr,,"Children with hearing loss (HL) remain at risk for poorer language abilities than normal hearing (NH) children despite targeted interventions; reasons for these differences remain unclear. In NH children, research suggests speech discrimination is related to language outcomes, yet we know little about it in children with HL under the age of 2 years. We utilized a vowel contrast, /a-i/, and a consonant-vowel contrast, /ba-da/, to examine speech discrimination in 47 NH infants and 40 infants with HL. At Mean age = 3 months, EEG recorded from 11 scalp electrodes was used to compute the time-frequency mismatched response (TF-MMRSE) to the contrasts; at Mean age =9 months, behavioral discrimination was assessed using a head turn task. A machine learning (ML) classifier was used to predict behavioral discrimination when given an arbitrary TF-MMRSE as input, achieving accuracies of 73% for exact classification and 92% for classification within a distance of one class. Linear fits revealed a robust relationship regardless of hearing status or speech contrast. TF-MMRSE responses in the delta (1-3.5 Hz), theta (3.5-8 Hz), and alpha (8-12 Hz) bands explained the most variance in behavioral task performance. Our findings demonstrate the feasibility of using TF-MMRSE to predict later behavioral speech discrimination. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: Published by Wiley Periodicals LLC on behalf of International Congress of Infant Studies. This is an open access article under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial and no modifications or adaptations are made.
HOLDER: The Authors-Infancy
YEAR: 2021",Infancy,26,2,327-348,Click here for full text options,SFX,,"Lawrence Erlbaum, US; Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1111%2finfa.12386
16,Ovid Technologies,APA PsycInfo,2021-35406-001,Audiometric profiles and patterns of benefit: A data-driven analysis of subjective hearing difficulties and handicaps. [References].,"Apr 4, 2021",2021,"Accepted: Mar 2021

Revised: Mar 2021

First Submitted: Apr 2020.","Sanchez-Lopez, Raul

Dau, Torsten

Whitmer, William M",,"International Journal of Audiology. 2021, pp. No Pagination Specified.",Apr,,"Abstract Objective Hearing rehabilitation attempts to compensate for auditory dysfunction, reduce hearing difficulties and minimise participation restrictions that can lead to social isolation. However, there is no systematic approach to assess the quality of the intervention at an individual level that might help to evaluate the need of further hearing rehabilitation in the hearing care clinic. Design A data-driven analysis on subjective data reflecting hearing disabilities and handicap was chosen to explore ""benefit patterns"" as a result of rehabilitation in different audiometric groups. The method was based on (1) dimensionality reduction; (2) stratification; (3) archetypal analysis; (4) clustering; (5) item importance estimation. Study sample 572 hearing-aid users completed questionnaires of hearing difficulties (speech, spatial and qualities hearing scale; SSQ) and hearing handicap (HHQ). Results The data-driven approach revealed four benefit profiles that were different for each audiometric group. The groups with low degree of high-frequency hearing loss (HLHF) showed a priority for rehabilitating hearing handicaps, whereas the groups with HLHF > 50 dB HL showed a priority for improvements in speech understanding. Conclusions The patterns of benefit and the stratification approach might guide the clinical intervention strategy and improve the efficacy and quality of service in the hearing care clinic. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: The Authors
YEAR: 2021",International Journal of Audiology,,,No Pagination Specified,Click here for full text options,SFX,,"Informa Healthcare, US",,First Posting,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc20&DO=10.1080%2f14992027.2021.1905890
17,Ovid Technologies,APA PsycInfo,2020-72284-001,Maximising the ability of stimulus-frequency otoacoustic emissions to predict hearing status and thresholds using machine-learning models. [References].,Apr 2021,2021,"Accepted: Sep 2020

Revised: Sep 2020

First Submitted: Apr 2020.","Liu, Yin

Xu, Runyi

Gong, Qin","Gong, Qin: gongqin@mail.tsinghua.edu.cn","International Journal of Audiology. Vol.60,(4), 2021, pp. 263-273.",Apr,,"Objective: This study aimed to maximise the ability of stimulus-frequency otoacoustic emissions (SFOAEs) to predict hearing status and thresholds based on machine-learning models. Design: SFOAE data and audiometric thresholds were collected at octave frequencies from 0.5 to 8 kHz. Support vector machine, k-nearest neighbour, back propagation neural network, decision tree, and random forest algorithms were used to build classification models for status identification and to develop regression models for threshold prediction. Study sample: About 230 ears with normal hearing and 737 ears with sensorineural hearing loss. Results: All classification models yielded areas under the receiver operating characteristic curve of 0.926-0.994 at 0.5-8 kHz, superior to the previous SFOAE study. The regression models produced lower standard errors (8.1-12.2 dB, mean absolute errors: 5.53-8.97 dB) as compared to those for distortion-product and transient-evoked otoacoustic emissions previously reported (8.6-19.2 dB). Conclusions: SFOAEs using machine-learning approaches offer promising tools for the prediction of hearing capabilities, at least at 0.5-4 kHz. Future research may focus on further improvements in accuracy and reductions in test time to improve clinical utility. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: British Society of Audiology, International Society of Audiology, and Nordic Audiological Society
YEAR: 2020",International Journal of Audiology,60,4,263-273,Click here for full text options,SFX,,"Informa Healthcare, US",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1080%2f14992027.2020.1821252
18,Ovid Technologies,APA PsycInfo,2020-20726-001,"Field test of the Rapid Assessment of Hearing Loss survey protocol in Ntcheu district, Malawi. [References].",Aug 2020,2020,"Accepted: Feb 2020

Revised: Jan 2020

First Submitted: Oct 2019.","Bright, Tess

Mulwafu, Wakisa

Phiri, Mwanaisha

Jiang, Fan

Swanepoel, De Wet

Kuper, Hannah

Mactaggart, Islay

Yip, Jennifer L. Y

Polack, Sarah","Bright, Tess: tess.bright@lshtm.ac.uk","International Journal of Audiology. Vol.59,(8), 2020, pp. 574-582.",Aug,,"Objective: (1) To test the feasibility of the Rapid Assessment of Hearing Loss (RAHL) survey protocol in Malawi (Ntcheu); (2) To estimate the prevalence and probable causes of hearing loss (adults 50 +). Design: Cross-sectional population-based survey. Study sample: Clusters (n = 38) were selected using probability-proportionate-to-size-sampling. Within each cluster, 30 people aged 50 + were selected using compact-segment-sampling. All participants completed smartphone-based audiometry (hearTest). Prevalence was estimated using WHO definitions (PTA of thresholds 0.5, 1, 2, 4 kHz in the better ear of > 25 dB HL (any) and > 40 dB HL (>= moderate)). Otoscopy and questionnaire were used to assess probable causes. Participants with hearing loss and/or ear disease were asked about care-seeking and barriers. Results: Four teams completed the survey in 24 days. 1080 of 1153 (93.7%) participants were examined. The median time to complete the protocol was 24 min/participant. Prevalence of hearing loss was 35.9% (95% CI = 31.6-40.2) (any level); and 10.0% (95% CI = 7.9-12.5) (>= moderate). The majority was classified as probable sensorineural. Nearly one third of people (30.9%) needed diagnostic audiology services and possible hearing aid fitting. Hearing aid coverage was < 1%. Lack of perceived need was a key barrier. Conclusion: The RAHL is simple, fast and provides information about the magnitude and probable causes of hearing loss to plan services. (PsycInfo Database Record (c) 2022 APA, all rights reserved)","HOLDER: British Society of Audiology, International Society of Audiology, and Nordic Audiological Society
YEAR: 2020",International Journal of Audiology,59,8,574-582,Click here for full text options,SFX,,"Informa Healthcare, US",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1080%2f14992027.2020.1739764
19,Ovid Technologies,APA PsycInfo,2020-89373-001,Factors influencing classification of frequency following responses to speech and music stimuli. [References].,Dec 2020,2020,"First Posting: Oct 2020

Accepted: Oct 2020

Revised: Sep 2020

First Submitted: Jun 2019.","Losorelli, Steven

Kaneshiro, Blair

Musacchia, Gabriella A

Blevins, Nikolas H

Fitzgerald, Matthew B","Losorelli, Steven: slosorelli@stanford.edu; Kaneshiro, Blair: blairbo@ccrma.stanford.edu; Musacchia, Gabriella A.: gmusacchia@pacific.edu; Blevins, Nikolas H.: nblevins@stanford.edu; Fitzgerald, Matthew B.: fitzmb@stanford.edu","Hearing Research. Vol.398, 2020, ArtID 108101.",Dec,,"Successful mapping of meaningful labels to sound input requires accurate representation of that sound's acoustic variances in time and spectrum. For some individuals, such as children or those with hearing loss, having an objective measure of the integrity of this representation could be useful. Classification is a promising machine learning approach which can be used to objectively predict a stimulus label from the brain response. This approach has been previously used with auditory evoked potentials (AEP) such as the frequency following response (FFR), but a number of key issues remain unresolved before classification can be translated into clinical practice. Specifically, past efforts at FFR classification have used data from a given subject for both training and testing the classifier. It is also unclear which components of the FFR elicit optimal classification accuracy. To address these issues, we recorded FFRs from 13 adults with normal hearing in response to speech and music stimuli. We compared labeling accuracy of two cross-validation classification approaches using FFR data: (1) a more traditional method combining subject data in both the training and testing set, and (2) a ""leave-one-out"" approach, in which subject data is classified based on a model built exclusively from the data of other individuals. We also examined classification accuracy on decomposed and time-segmented FFRs. Our results indicate that the accuracy of leave-one-subject-out cross validation approaches that obtained in the more conventional cross-validation classifications while allowing a subject's results to be analysed with respect to normative data pooled from a separate population. In addition, we demonstrate that classification accuracy is highest when the entire FFR is used to train the classifier. Taken together, these efforts contribute key steps toward translation of classification-based machine learning approaches into clinical practice. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2020",Hearing Research,398,,,Click here for full text options,SFX,15,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1016%2fj.heares.2020.108101
20,Ovid Technologies,APA PsycInfo,2020-71372-015,Common configurations of real-ear aided response targets prescribed by NAL-NL2 for older adults with mild-to-moderate hearing loss. [References].,Sep 2020,2020,"Accepted: May 2020

Revised: Apr 2020

First Submitted: Feb 2020.","Jensen, Justin

Vyas, Dhruv

Urbanski, Dana

Garudadri, Harinath

Chipara, Octav

Wu, Yu-Hsiang","Jensen, Justin: justin-jensen@uiowa.edu","American Journal of Audiology. Vol.29,(3), 2020, pp. 460-475.",Sep,,"Purpose: This study investigates common real-ear aided response (REAR) configurations prescribed by the NAL-NL2 algorithm for older adults with hearing loss. Method: A data set that is representative of the older adult U.S. population with mild-to-moderate sensorineural hearing loss was constructed from the audiometric data of 934 adults (aged 55-85 years) from the National Health and Nutrition Examination Survey years 1999-2012. Two clustering approaches were implemented to generate common REAR configurations for eight frequencies (0.25, 0.5, 1, 2, 3, 4, 6, and 8 kHz) at three input levels (55, 65, and 75 dB SPL). (a) In the REAR-based clustering approach, the National Health and Nutrition Examination Survey audiograms were first converted to REAR targets and then clustered to generate common REAR configurations. (b) In the audiogram-based clustering approach, the audiograms were first clustered into common hearing loss profiles and then converted to REAR configurations. The trade-off between the number of available REAR configurations and the percentage of the U.S. population whose hearing loss could be fit by at least one of them (i.e., percent coverage) was evaluated. Hearing loss fit was defined as less than +/- 5-dB difference between an individual's REAR targets and those of the clustered REAR configuration. Results: Percent coverage increases with the number of available REAR configurations, with four configurations resulting in 75% population coverage. Overall, REAR-based clustering yielded 5 percentage points better coverage on average compared to audiogram-based clustering. Conclusions: The common REAR configurations can be used for programming the gain frequency responses in preconfigured over-the-counter hearing aids and provide clinically appropriate amplification settings for older adults with mild-to-moderate hearing loss. (PsycInfo Database Record (c) 2022 APA, all rights reserved)","HOLDER: American Speech-Language-Hearing Association
YEAR: 2020",American Journal of Audiology,29,3,460-475,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1044%2f2020_AJA-20-00025
21,Ovid Technologies,APA PsycInfo,2020-20494-007,A novel method for classifying hearing impairment in epidemiological studies of aging: The Wisconsin Age-Related Hearing Impairment Classification Scale. [References].,Mar 2020,2020,"Accepted: Nov 2019

Revised: Oct 2019

First Submitted: Jul 2019.","Cruickshanks, Karen J

Nondahl, David M

Fischer, Mary E

Schubert, Carla R

Tweed, Ted S","Cruickshanks, Karen J.: kjcruick@wisc.edu","American Journal of Audiology. Vol.29,(1), 2020, pp. 59-67.",Mar,,"Purpose: Longitudinal population-based cohort data were used to develop a standardized classification system for age-related hearing impairment using thresholds for frequencies (0.5-8 kHz) typically measured in cohort studies. Method: Audiometric testing data collected in the Epidemiology of Hearing Loss Study from participants (n = 1,369) with four visits (1993-1995, 1998-2000, 2003-2005, and 2009-2010) were included (10,952 audiograms). Cluster analyses (Wald's method) were used to identify audiometric patterns. Maximum allowable threshold values were defined for each cluster to create an ordered scale. Progression was defined as a two-step change. Results: An eight-step scale was developed to capture audiogram shape and severity of hearing impairment. Of the 1,094 participants classified as having normal hearing based on a pure-tone average, only 25% (n = 277) were classified as Level 1 (all thresholds <= 20 dB HL) on the new scale, whereas 17% (n = 182) were Levels 4-6. During the 16-year follow-up, 64.9% of those at Level 1 progressed. There was little regression using this scale. Conclusions: This is the first scale developed from population-based longitudinal cohort data to capture audiogram shape across time. This simple, standardized scale is easy to apply, reduces misclassification of normal hearing, and may be a useful method for identifying risk factors for early, preclinical, age-related changes in hearing. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: American Speech-Language-Hearing Association
YEAR: 2020",American Journal of Audiology,29,1,59-67,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc19&DO=10.1044%2f2019_AJA-19-00021
22,Ovid Technologies,APA PsycInfo,2019-08837-001,Cognitively inspired feature extraction and speech recognition for automated hearing loss testing. [References].,"Aug 15, 2019",2019,"First Posting: Feb 2019

Accepted: Oct 2018

First Submitted: Apr 2018.","Nisar, Shibli

Tariq, Muhammad

Adeel, Ahsan

Gogate, Mandar

Hussain, Amir","Adeel, Ahsan: ahsan.adeel@deepci.org","Cognitive Computation. Vol.11,(4), 2019, pp. 489-502.",Aug,,"Hearing loss, a partial or total inability to hear, is one of the most commonly reported disabilities. A hearing test can be carried out by an audiologist to assess a patient's auditory system. However, the procedure requires an appointment, which can result in delays and practitioner fees. In addition, there are often challenges associated with the unavailability of equipment and qualified practitioners, particularly in remote areas. This paper presents a novel idea that automatically identifies any hearing impairment based on a cognitively inspired feature extraction and speech recognition approach. The proposed system uses an adaptive filter bank with weighted Mel-frequency cepstral coefficients for feature extraction. The adaptive filter bank implementation is inspired by the principle of spectrum sensing in cognitive radio that is aware of its environment and adapts to statistical variations in the input stimuli by learning from the environment. Comparative performance evaluation demonstrates the potential of our automated hearing test method to achieve comparable results to the clinical ground truth, established by the expert audiologist's tests. The overall absolute error of the proposed model when compared with the expert audiologist test is less than 4.9 dB and 4.4 dB for the pure tone and speech audiometry tests, respectively. The overall accuracy achieved is 96.67% with a hidden Markov model (HMM). The proposed method potentially offers a second opinion to audiologists, and serves as a cost-effective pre-screening test to predict hearing loss at an early stage. In future work, authors intend to explore the application of advanced deep learning and optimization approaches to further enhance the performance of the automated testing prototype considering imperfect datasets with real-world background noise. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: Springer Science+Business Media, LLC, part of Springer Nature
YEAR: 2019",Cognitive Computation,11,4,489-502,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc18&DO=10.1007%2fs12559-018-9607-4
23,Ovid Technologies,APA PsycInfo,2019-41279-008,Recovery from sudden sensorineural hearing loss may be linked to chronic stress levels and steroid treatment resistance. [References].,"Jun 10, 2019",2019,"Accepted: Jan 2019

Revised: Nov 2018

First Submitted: Aug 2018.","Ajduk, Jakov

Kosec, Andro

Kelava, Iva

Ries, Mihael

Greguric, Tomislav

Kalogjera, Livije","Kosec, Andro: andro.kosec@yahoo.com","American Journal of Audiology. Vol.28,(2), 2019, pp. 315-321.",Jun,,"Purpose: This article investigates the possible connections between the level of chronic stress and success of steroid therapy in patients with sudden sensorineural hearing loss (SSNHL). Method: A single-center, retrospective, longitudinal cohort study on 55 patients in a tertiary referral otology center was examined. Patients diagnosed with SSNHL between 2014 and 2017 were asked to complete a Measure of Perceived Stress (Brajac, Tkalcic, Dragojevic, & Gruber, 2003) questionnaire. Inclusion criteria were patients > 18 years of age, SSNHL diagnosed within 4 previous weeks, completed steroid treatment, and complete documentation. Results: There were 30 patients (55%) that showed significant improvement in their pure-tone audiogram (PTA) hearing threshold average (>= 15 dB) after steroid treatment. Two-step cluster analysis identified 3 clusters based on average PTA hearing threshold recovery and average Measure of Perceived Stress scores. The difference between pretreatment and posttreatment hearing levels was significantly higher in the cluster with moderate stress compared to clusters with mild and high stress levels (Kruskal-Wallis test, Friedman test, p < .001). There were no significant differences in average PTA hearing threshold recovery after steroid therapy between groups of patients with mild and severe stress. Conclusion: Patients with moderate stress levels show significantly better results after steroid treatment for SSNHL than patients with low or high stress levels. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: American Speech-Language-Hearing Association
YEAR: 2019",American Journal of Audiology,28,2,315-321,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc18&DO=10.1044%2f2019_AJA-18-0127
24,Ovid Technologies,APA PsycInfo,2019-74466-001,Cortical thickness of left Heschl's gyrus correlates with hearing acuity in adults-A surface-based morphometry study. [References].,Dec 2019,2019,"First Posting: Oct 2019

Accepted: Oct 2019

Revised: Oct 2019

First Submitted: Jul 2019.","Neuschwander, Pia

Hanggi, Jurgen

Zekveld, Adriana A

Meyer, Martin","Neuschwander, Pia: pia.neuschwander@psychologie.uzh.ch","Hearing Research. Vol.384, 2019, ArtID 107823.",Dec,,"To date, research examining the relationship between brain structure and hearing acuity is sparse, especially given the context of a broad age range. To investigate this relationship, we applied an automated surface-based morphometry (SBM) approach (FreeSurfer) in this study to re-examine a sample of normal-hearing (n = 17) and hearing-impaired (n = 17) age- and education-matched adults, aged between 20 and 63 years (Alfandari et al., 2018). The SBM approach allows the disentanglement of cortical surface area (CSA) from cortical thickness (CT), the 2 independent constituents of cortical volume (CV). We extend the findings of Alfandari and colleagues by showing several clusters in auditory-related areas as well as in the left and right angular gyrus that showed reduced CT, CSA and CV in hearing-impaired compared to normal-hearing listeners. Nevertheless, none of the clusters found correlated significantly with hearing acuity, measured by pure-tone thresholds, in the 2 groups. An additional vertex-wise correlation analysis between hearing acuity and morphometric parameters over all participants revealed a single significant cluster encompassing the left Heschl's gyrus. Higher hearing thresholds were associated with a thinner cortex within this cluster. Our results imply that hearing impairment is associated with reduced thickness in primary and secondary auditory cortex regions, those regions especially involved in perceiving and processing relevant speech cues. This decrease was observed not only in older but also in younger and middle-aged adults, independent of age-related decline in the cognitive domain and age-dependent whole-brain atrophy. Further, the results show the value added when considering CV, CT and CSA separately, relative to previous studies which have solely relied on voxel-based morphometry to investigate brain structure and hearing acuity across the lifespan. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2019",Hearing Research,384,,,Click here for full text options,SFX,12,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc18&DO=10.1016%2fj.heares.2019.107823
25,Ovid Technologies,APA PsycInfo,2019-23495-090,Improvement of speech perception for hearing-impaired listeners.DP  - 2019,,2019,,"Du, Fang",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.80,(5-B(E)), 2019, pp. No Pagination Specified.",,Dissertation Abstracts International,"Hearing impairment is becoming a prevalent health problem affecting 5% of world adult populations. Hearing aids and cochlear implant already play an essential role in helping patients over decades, but there are still several open problems that prevent them from providing the maximum benefits. Financial and discomfort reasons lead to only one of four patients choose to use hearing aids; Cochlear implant users always have trouble in understanding speech in a noisy environment. In this dissertation, we addressed the hearing aids limitations by proposing a new hearing aid signal processing system named Open-source Self-fitting Hearing Aids System (OS SF hearing aids). The proposed hearing aids system adopted the state-of-art digital signal processing technologies, combined with accurate hearing assessment and machine learning based self-fitting algorithm to further improve the speech perception and comfort for hearing aids users. Informal testing with hearing-impaired listeners showed that the testing results from the proposed system had less than 10 dB (by average) difference when compared with those results obtained from clinical audiometer. In addition, Sixteen-channel filter banks with adaptive differential microphone array provides up to six-dB SNR improvement in the noisy environment. Machine-learning based self-fitting algorithm provides more suitable hearing aids settings. To maximize cochlear implant users' speech understanding in noise, the sequential (S) and parallel (P) coding strategies were proposed by integrating high-rate desynchronized pulse trains (DPT) in the continuous interleaved sampling (CIS) strategy. Ten participants with severe hearing loss participated in the two rounds cochlear implants testing. The testing results showed CIS-DPT-S strategy significantly improved (11%) the speech perception in background noise, while the CIS-DPT-P strategy had a significant improvement in both quiet (7%) and noisy (9%) environment. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,80,5-B(E),No Pagination Specified,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc18&AN=2019-23495-090
26,Ovid Technologies,APA PsycInfo,2018-31046-001,Verbal learning and memory in prelingually deaf children with cochlear implants. [References].,Oct 2018,2018,"Accepted: May 2018

Revised: May 2018

First Submitted: Aug 2017.","Kronenberger, William G

Henning, Shirley C

Ditmars, Allison M

Roman, Adrienne S

Pisoni, David B","Kronenberger, William G.: wkronenb@iupui.edu","International Journal of Audiology. Vol.57,(10), 2018, pp. 746-754.",Oct,,"Objective: Deaf children with cochlear implants (CIs) show poorer verbal working memory compared to normal-hearing (NH) peers, but little is known about their verbal learning and memory (VLM) processes involving multi-trial free recall. Design: Children with CIs were compared to NH peers using the California Verbal Learning Test for Children (CVLT-C). Study sample: Participants were 21 deaf (before age 6 months) children (6-16 years old) implanted prior to age 3 years, and 21 age-IQ matched NH peers. Results: Results revealed no differences between groups in number of words recalled. However, CI users showed a pattern of increasing use of serial clustering strategies across learning trials, whereas NH peers decreased their use of serial clustering strategies. In the CI sample (but not in the NH sample), verbal working memory test scores were related to resistance to the build-up of proactive interference, and sentence recognition was associated with performance on the first exposure to the word list and to the use of recency recall strategies. Conclusions: Children with CIs showed robust evidence of VLM comparable to NH peers. However, their VLM processing (especially recency and proactive interference) was related to speech perception outcomes and verbal WM in different ways from NH peers. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: British Society of Audiology, International Society of Audiology, and Nordic Audiological Society
YEAR: 2018",International Journal of Audiology,57,10,746-754,Click here for full text options,SFX,,"Informa Healthcare, US",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc17&DO=10.1080%2f14992027.2018.1481538
27,Ovid Technologies,APA PsycInfo,2018-09133-026,Improving Pure-Tone Audiometry Using Probabilistic Machine Learning Classification.DP  - 2018,,2018,,"Song, Xinyu",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.79,(3-B(E)), 2018, pp. No Pagination Specified.",,Dissertation Abstracts International,"Hearing loss is a critical public health concern, affecting hundreds millions of people worldwide and dramatically impacting quality of life for affected individuals. While treatment techniques have evolved in recent years, methods for assessing hearing ability have remained relatively unchanged for decades. The standard clinical procedure is the modified Hughson-Westlake procedure, an adaptive pure-tone detection task that is typically performed manually by audiologists, costing millions of collective hours annually among healthcare professionals. In addition to the high burden of labor, the technique provides limited detail about an individual's hearing ability, estimating only detection thresholds at a handful of pre-defined pure-tone frequencies (a threshold audiogram). An efficient technique that produces a detailed estimate of the audiometric function, including threshold and spread, could allow for better characterization of particular hearing pathologies and provide more diagnostic value. Parametric techniques exist to efficiently estimate multidimensional psychometric functions, but are ill-suited for estimation of audiometric functions because these functions cannot be easily parameterized. The Gaussian process is a compelling machine learning technique for inference of nonparametric multidimensional functions using binary data. The work described in this thesis utilizes Gaussian process classification to build an automated framework for efficient, high-resolution estimation of the full audiometric function, which we call the machine learning audiogram (MLAG). This Bayesian technique iteratively computes a posterior distribution describing its current belief about detection probability given the current set of observed pure tones and detection responses. The posterior distribution can be used to provide a current point estimate of the psychometric function as well as to select an informative query point for the next stimulus to be provided to the listener. The Gaussian process covariance function encodes correlations between variables, reflecting prior beliefs on the system; MLAG uses a composite linear/squared exponential covariance function that enforces monotonicity with respect to intensity but only smoothness with respect to frequency for the audiometric function. This framework was initially evaluated in human subjects for threshold audiogram estimation. 2 repetitions of MLAG and 1 repetition of manual clinical audiometry were conducted in each of 21 participants. Results indicated that MLAG both agreed with clinical estimates and exhibited test-retest reliability to within accepted clinical standards, but with significantly fewer tone deliveries required compared to clinical methods while also providing an effectively continuous threshold estimate along frequency. This framework's ability to evaluate full psychometric functions was then evaluated using simulated experiments. As a feasibility check, performance for estimating unidimensional psychometric functions was assessed and directly compared to inference using standard maximum-likelihood probit regression; results indicated that the two methods exhibited near identical performance for estimating threshold and spread. MLAG was then used to estimate 2-dimensional audiometric functions constructed using existing audiogram phenotypes. Results showed that this framework could estimate both threshold and spread of the full audiometric function with high accuracy and reliability given a sufficient sample count; non-active sampling using the Halton set required between 50--100 queries to reach clinical reliability, while active sampling strategies reduced the required number to around 20--30, with Bayesian active leaning by disagreement exhibiting the best performance of the tested methods. Overall, MLAG's accuracy, reliability, and high degree of detail make it a promising... (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,79,3-B(E),No Pagination Specified,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc17&AN=2018-09133-026
28,Ovid Technologies,APA PsycInfo,2018-07642-008,Pure tone hearing profiles in children with otitis media with effusion. [References].,May 2018,2018,"Accepted: Jan 2017

Revised: Jan 2017

First Submitted: Sep 2016.","Cai, Ting

McPherson, Bradley

Li, Caiwei

Yang, Feng","Cai, Ting: caiting13579@gmail.com","Disability and Rehabilitation: An International, Multidisciplinary Journal. Vol.40,(10), 2018, pp. 1166-1175.",May,,"Introduction: Otitis media with effusion (OME) is a common middle ear disease in children. The associated conductive hearing loss is a major concern for hearing health professionals. The aim of the present study was to describe the configuration of pure tone audiograms of children with OME and to design a statistical stratification algorithm to facilitate hearing loss profiling in children with OME. Methods: School age children with OME were recruited. Bone and air conduction thresholds were obtained using standard procedures. Hierarchical cluster analysis was employed to determine audiometric profile groups. The Mandarin Hearing in Noise Test was used to measure sentence perception in children for cluster analysis validity assessment. Results: Ninety-seven children (164 ears) aged between 72 months and 153 months were examined. Air conduction thresholds averaged for 500 Hz, 1000 Hz and 2000 Hz were in the range of 8.3-53.3 dB HL with a mean of 26.8 dB HL. Bone conduction thresholds were found to be influenced by middle ear pathology with a maximal elevation at 2000 Hz of 25 dB HL. Four audiometric profiles were identified. Cluster 1 contained 54 ears (32.9%) with normal or near normal hearing, Clusters 2 contained 37 ears (22.6%) with mild hearing loss, Cluster 3 included 48 ears (29.3%) and Cluster 4 included 25 ears (15.2%) with moderate hearing loss. Stability and validity of the four-cluster profiling procedure was examined and established with satisfactory results. Conclusions: OME in children is associated with pure tone hearing thresholds ranging from normal to moderate hearing loss. The hierarchical clustering algorithm proved useful as a novel means of profiling hearing loss in children with OME and may assist in identifying affected children at greater risk of auditory disadvantage. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: Informa UK Limited, trading as Taylor & Francis Group
YEAR: 2017","Disability and Rehabilitation: An International, Multidisciplinary Journal",40,10,1166-1175,Click here for full text options,SFX,,"Informa Healthcare, US",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc17&DO=10.1080%2f09638288.2017.1290698
29,Ovid Technologies,APA PsycInfo,2018-07720-018,"An exploration of the associations among hearing loss, physical health, and visual memory in adults from west Central Alabama. [References].",Aug 2017,2017,"Accepted: Mar 2017

Revised: Jan 2017

First Submitted: Sep 2016.","Hay-McCutcheon, Marcia J

Hyams, Adriana

Yang, Xin

Parton, Jason

Panasiuk, Brianna

Ondocsin, Sarah

James, Mary Margaret

Scogin, Forrest","Hay-McCutcheon, Marcia J.: mhaymccu@ua.edu","Journal of Speech, Language, and Hearing Research. Vol.60,(8), 2017, pp. 2346-2359.",Aug,Journal of Speech & Hearing Research,"Purpose: The purpose of this preliminary study was to explore the associations among hearing loss, physical health, and visual memory in adults living in rural areas, urban clusters, and an urban city in west Central Alabama. Method: Two hundred ninety-seven adults (182 women, 115 men) from rural areas, urban clusters, and an urban city of west Central Alabama completed a hearing assessment, a physical health questionnaire, a hearing handicap measure, and a visual memory test. Results: A greater number of adults with hearing loss lived in rural areas and urban clusters than in an urban area. In addition, poorer physical health was significantly associated with hearing loss. A greater number of individuals with poor physical health who lived in rural towns and urban clusters had hearing loss compared with the adults with other physical health issues who lived in an urban city. Poorer hearing sensitivity resulted in poorer outcomes on the Emotional and Social subscales of the Hearing Handicap Inventory for Adults. And last, visual memory, a working-memory task, was not associated with hearing loss but was associated with educational level. Conclusions: The outcomes suggest that hearing loss is associated with poor physical and emotional health but not with visual-memory skills. A greater number of adults living in rural areas experienced hearing loss compared with adults living in an urban city, and consequently, further research will be necessary to confirm this relationship and to explore the reasons behind it. Also, further exploration of the relationship between cognition and hearing loss in adults living in rural and urban areas will be needed. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: American Speech-Language-Hearing Association
YEAR: 2017","Journal of Speech, Language, and Hearing Research",60,8,2346-2359,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1044%2f2017_JSLHR-H-16-0369
30,Ovid Technologies,APA PsycInfo,2017-09036-012,"An analysis of current source density profiles activated by local stimulation in the mouse auditory cortex in vitro.DP  - Mar 15, 2017",,2017,"First Posting: Jan 2017

Accepted: Jan 2017

Revised: Jan 2017

First Submitted: Oct 2016.","Yamamura, Daiki

Sano, Ayaka

Tateno, Takashi","Yamamura, Daiki: Yamamura_Daiki@ist.hokudai.ac.jp; Tateno, Takashi: tateno@ist.hokudai.ac.jp","Brain Research. Vol.1659, 2017, pp. 96-112.",Mar,,"To examine local network properties of the mouse auditory cortex in vitro, we recorded extracellular spatiotemporal laminar profiles driven by short electric local stimulation on a planar multielectrode array substrate. The recorded local field potentials were subsequently evaluated using current source density (CSD) analysis to identify sources and sinks. Current sinks are thought to be an indicator of net synaptic current in the small volume of cortex surrounding the recording site. Thus, CSD analysis combined with multielectrode arrays enabled us to compare mean synaptic activity in response to small current stimuli on a layer-by-layer basis. We also used senescence-accelerated mice (SAM), some strains of which show earlier onset of age-related hearing loss, to examine the characteristic spatiotemporal CSD profiles stimulated by electrodes in specific cortical layers. Thus, the CSD patterns were classified into several clusters based on stimulation sites in the cortical layers. We also found some differences in CSD patterns between the two SAM strains in terms of aging according to principle component analysis with dimension reduction. For simultaneous two-site stimulation, we modeled the obtained CSD profiles as a linear superposition of the CSD profiles to individual single-site stimulation. The model analysis indicated the nonlinearity of spatiotemporal integration over stimulus-driven activity in a layer-specific manner. Finally, on the basis of these results, we discuss the auditory cortex local network properties and the effects of aging on these mouse strains. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2017",Brain Research,1659,,96-112,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc16&DO=10.1016%2fj.brainres.2017.01.021
31,Ovid Technologies,APA PsycInfo,2016-22395-016,Disrupted functional brain connectome in unilateral sudden sensorineural hearing loss. [References].,May 2016,2016,"First Posting: Mar 2016

Accepted: Feb 2016

Revised: Feb 2016

First Submitted: Sep 2015.","Xu, Haibo

Fan, Wenliang

Zhao, Xueyan

Li, Jing

Zhang, Wenjuan

Lei, Ping

Liu, Yuan

Wang, Haha

Cheng, Huamao

Shi, Hong","Xu, Haibo: xuhaibo1120@hotmail.com; Fan, Wenliang: fanwenliang168@163.com; Zhao, Xueyan: yaner_323@126.com; Li, Jing: lijing80603@163.com; Zhang, Wenjuan: juan_364@163.com; Lei, Ping: leiping_rosemary@126.com; Liu, Yuan: 309105825@qq.com; Wang, Haha: ahahwang@163.com; Cheng, Huamao: chhmao@aliyun.com; Shi, Hong: shihong5510@163.com","Hearing Research. Vol.335, 2016, pp. 138-148.",May,,"Sudden sensorineural hearing loss (SSNHL) is generally defined as sensorineural hearing loss of 30 dB or greater over at least three contiguous audiometric frequencies and within a three-day period. This hearing loss is usually unilateral and can be associated with tinnitus and vertigo. The pathogenesis of unilateral sudden sensorineural hearing loss is still unknown, and the alterations in the functional connectivity are suspected to involve one possible pathogenesis. Despite scarce findings with respect to alterations in brain functional networks in unilateral sudden sensorineural hearing loss, the alterations of the whole brain functional connectome and whether these alterations were already in existence in the acute period remains unknown. The aim of this study was to investigate the alterations of brain functional connectome in two large samples of unilateral sudden sensorineural hearing loss patients and to investigate the correlation between unilateral sudden sensorineural hearing loss characteristics and changes in the functional network properties. Pure tone audiometry was performed to assess hearing ability. Abnormal changes in the peripheral auditory system were examined using conventional magnetic resonance imaging. The graph theoretical network analysis method was used to detect brain connectome alterations in unilateral sudden sensorineural hearing loss. Compared with the control groups, both groups of unilateral SSNHL patients exhibited a significantly increased clustering coefficient, global efficiency, and local efficiency but a significantly decreased characteristic path length. In addition, the primary increased nodal strength (e.g., nodal betweenness, hubs) was observed in several regions primarily, including the limbic and paralimbic systems, and in the auditory network brain areas. These findings suggest that the alteration of network organization already exists in unilateral sudden sensorineural hearing loss patients within the acute period and that the functional connectome of unilateral SSNHL patients is characterized by a shift toward small-worldization. Additionally, we hope that these findings will help to elucidate unilateral SSNHL through a new research perspective and provide insight for the potential pathophysiology of unilateral SSNHL. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2016",Hearing Research,335,,138-148,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.1016%2fj.heares.2016.02.016
32,Ovid Technologies,APA PsycInfo,2016-07754-001,Linguistic profiles of children with CI as compared with children with hearing or specific language impairment. [References].,Sep-Oct 2016,2016,,"de Hoog, Brigitte E

Langereis, Margreet C

van Weerdenburg, Marjolijn

Knoors, Harry E. T

Verhoeven, Ludo","de Hoog, Brigitte E.: b.dehoog@pwo.ru.nl","International Journal of Language & Communication Disorders. Vol.51,(5), 2016, pp. 518-530.",Sep-Oct,"British Journal of Disorders of Communication, European Journal of Disorders of Communication","Background: The spoken language difficulties of children with moderate or severe to profound hearing loss are mainly related to limited auditory speech perception. However, degraded or filtered auditory input as evidenced in children with cochlear implants (CIs) may result in less efficient or slower language processing as well. To provide insight into the underlying nature of the spoken language difficulties in children with CIs, linguistic profiles of children with CIs are compared with those of hard-of-hearing (HoH) children with conventional hearing aids and children with specific language impairment (SLI). Aims: To examine differences in linguistic abilities and profiles of children with CIs as compared with HoH children and children with SLI, and whether the spoken language difficulties of children with CIs mainly lie in limited auditory perception or in language processing problems. Methods & Procedure: Differences in linguistic abilities and differential linguistic profiles of 47 children with CI, 66 HoH children with moderate to severe hearing loss, and 127 children with SLI are compared, divided into two age cohorts. Standardized Dutch tests were administered. Factor analyses and cluster analyses were conducted to find homogeneous linguistic profiles of the children. Outcomes & Results: The children with CIs were outperformed by their HoH peers and peers with SLI on most linguistic abilities. Concerning the linguistic profiles, the largest group of children with CIs and HoH children shared similar profiles. The profiles observed for most of the children with SLI were different from those of their peers with hearing loss in both age cohorts. Conclusions & Implications: Results suggest that the underlying nature of spoken language problems in most children with CIs manifests in limited auditory perception instead of language processing difficulties. However, there appears to be a subgroup of children with CIs whose linguistic profiles resemble those of children with SLI. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: Royal College of Speech and Language Therapists
YEAR: 2016",International Journal of Language & Communication Disorders,51,5,518-530,Click here for full text options,SFX,,"Informa Healthcare, US; Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.1111%2f1460-6984.12228
33,Ovid Technologies,APA PsycInfo,2015-59073-003,Thin-film micro-electrode stimulation of the cochlea in rats exposed to aminoglycoside induced hearing loss. [References].,Jan 2016,2016,"First Posting: Oct 2015

Accepted: Oct 2015

Revised: Sep 2015

First Submitted: Mar 2015.","Allitt, B. J

Harris, A. R

Morgan, S. J

Clark, G. M

Paolini, A. G","Allitt, B. J.: ben.allitt@monash.edu","Hearing Research. Vol.331, 2016, pp. 13-26.",Jan,,"The multi-channel cochlear implant (CI) provides sound and speech perception to thousands of individuals who would otherwise be deaf. Broad activation of auditory nerve fibres when using a CI results in poor frequency discrimination. The CI also provides users with poor amplitude perception due to elicitation of a narrow dynamic range. Provision of more discrete frequency perception and a greater control over amplitude may allow users to better distinguish speech in noise and to segregate sound sources. In this research, thin-film (TF) high density micro-electrode arrays and conventional platinum ring electrode arrays were used to stimulate the cochlea of rats administered sensorineural hearing loss (SNHL) via ototoxic insult, with neural responses taken at 434 multiunit clusters in the central nucleus of the inferior colliculus (CIC). Threshold, dynamic range and broadness of response were used to compare electrode arrays. A stronger current was required to elicit CIC threshold when using the TF array compared to the platinum ring electrode array. TF stimulation also elicited a narrower dynamic range than the PR counterpart. However, monopolar stimulation using the TF array produced more localised CIC responses than other stimulation strategies. These results suggest that individuals with SNHL could benefit from micro stimulation of the cochlea using a monopolar configuration which may provide discrete frequency perception when using TF electrode arrays. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2015",Hearing Research,331,,13-26,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc15&DO=10.1016%2fj.heares.2015.10.003
34,Ovid Technologies,APA PsycInfo,2015-99020-424,Beyond audiometric phenotype: Toward a differential diagnosis for presbycusis.DP  - 2015,,2015,,"Baiduc, Rachael R",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.75,(7-B(E)), 2015, pp. No Pagination Specified.",,Dissertation Abstracts International,"Age-related hearing loss (ARHL; presbycusis) results from degeneration of neural and/or cochlear structures. A taxonomy distinguishing presbycusis subtypes according to site of lesion was originally proposed by linking audiometric results to histopathological findings. In most cases, the pathology is complex and audiometry and word recognition scores (WRS) are insufficient to identify the location(s) of pathologies along the auditory pathway, often referred to as the site(s) of lesion. Several sophisticated tests of auditory function, with some specifically designed to inspect cochlear or neural status (e.g., distortion product otoacoustic emissions [DPOAEs] and the auditory brainstem response [ABR]) are available today but not in routine use to distinguish between presbycutic subtypes. Because there is no pre-mortem method in place to identify contributing pathologies and their relative dominance in individual cases of presbycusis, the goal of the present study is to improve differential diagnosis in the hope of providing individualized therapeutics for those suffering ARHL. In order to determine candidacy and dosing for these treatments, specific diagnoses will become crucial. This dissertation thus systematically explores an extensive test battery composed of behavioral (audiometry and speech testing) and physiological (ABR, DPOAEs, and electrocochleography) assays of auditory function in presbycutic ears. We compare these responses to data from normal hearing subjects who serve as a reference group. Quadratic (f2-f 1) DPOAEs are incorporated as a potential means of gaining supplementary information regarding cochlear function. As f2-f1 DPOAEs have not been studied extensively, our initial experiments were focused on determining optimal stimulus parameters to elicit them. Results show narrow stimulus frequency ratios (1.14) and moderately high stimulus levels (70 dB SPL) are ideal. We initially set out to uncover a method of diagnosis for ARHL that improves upon the ""gold standard"" (audiometry and WRS). Two analytical strategies (principal component and hierarchical cluster analyses) were used to evaluate various phenotyping strategies. The results provide a potential solution, revealing the feasibility of a much more detailed diagnosis of presbycusis subtypes even in this limited data set. In the future, these phenotyping techniques should be applied on an epidemiological scale and ultimately, might inform appropriate treatment methodologies for each presbycusis subtype. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,75,7-B(E),No Pagination Specified,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&AN=2015-99020-424
35,Ovid Technologies,APA PsycInfo,2015-41162-001,Mental health problems in adolescents with cochlear implants: Peer problems persist after controlling for additional handicaps. [References].,"Jul 15, 2015",2015,,"Huber, Maria

Burger, Thorsten

Illg, Angelika

Kunze, Silke

Giourgas, Alexandros

Braun, Ludwig

Kroger, Stefanie

Nickisch, Andreas

Rasp, Gerhard

Becker, Andreas

Keilmann, Annerose","Huber, Maria: m.huber@salk.at","Frontiers in Psychology. Vol.6, 2015, ArtID 953.",Jul,,"The aims of the present multi-center study were to investigate the extent of mental health problems in adolescents with a hearing loss and cochlear implants (CIs) in comparison to normal hearing (NH) peers and to investigate possible relations between the extent of mental health problems of young CI users and hearing variables, such as age at implantation, or functional gain of CI. The survey included 140 adolescents with CI (mean age = 14.7, SD = 1.5 years) and 140 NH adolescents (mean age = 14.8, SD = 1.4 years), their parents and teachers. Participants were matched by age, gender and social background. Within the CI group, 35 adolescents were identified as ""risk cases"" due to possible and manifest additional handicaps, and 11 adolescents were non-classifiable. Mental health problems were assessed with the Strengths and Difficulties Questionnaire (SDQ) in the versions ""Self,"" ""Parent,"" and ""Teacher."" The CI group showed significantly more ""Peer Problems"" than the NH group. When the CI group was split into a ""risk-group"" (35 ""risk cases"" and 11 non-classifiable persons) and a ""non-risk group"" (n = 94), increased peer problems were perceived in both CI subgroups by adolescents themselves. However, no further differences between the CI non-risk group and the NH group were observed in any rater. The CI risk-group showed significantly more hyperactivity compared to the NH group and more hyperactivity and conduct problems compared to the CI non-risk group. Cluster analyses confirmed that there were significantly more adolescents with high problems in the CI risk-group compared to the CI non-risk group and the NH group. Adolescents with CI, who were able to understand speech in noise had significantly less difficulties compared to constricted CI users. Parents, teachers, and clinicians should be aware that CI users with additionally special needs may have mental health problems. However, peer problems were also experienced by CI adolescents without additional handicaps. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
HOLDER: Huber, Burger, Illg, Kunze, Giourgas, Braun, Kroger, Nickisch, Rasp, Becker and Keilmann
YEAR: 2015",Frontiers in Psychology,6,,,Click here for full text options,SFX,13,"Frontiers Research Foundation, Switzerland",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc14&DO=10.3389%2ffpsyg.2015.00953
36,Ovid Technologies,APA PsycInfo,2014-99040-380,Effects of unilateral and bilateral cochlear implantation on cortical activity measured by an eeg neuroimaging method in children.DP  - 2014,,2014,,"Wong, Daniel Davis Eugene",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.74,(8-B(E)), 2014, pp. No Pagination Specified.",,Dissertation Abstracts International,"Bilateral implantation of a cochlear implant (CI) after a >2 year period of unilateral hearing with a second implant has been shown to result in altered latencies in brainstem responses in children with congenital deafness. In this thesis, a neural source localization method was developed to investigate the effects of unilateral CI use on cortical development after the implantation of a 2nd CI. The electroencephalography (EEG) source localization method is based on the linearly constrained minimum variance (LCMV) vector beamformer and utilizes null constraints to minimize the electrical artifact produced by the CI. The accuracy of the method was assessed and optimized through simulations and comparisons to beamforming with magnetoencephalography (MEG) data. After using cluster analyses to ensure that sources compared across subjects originate from the same neural generators, a study was done to examine the effects of unilateral CI hearing on hemispheric lateralization to monaural responses. It was found that a >2 year period of unilateral hearing results in expanded projections from the 1st implanted ear to the contralateral auditory area that is not reversed by implantation of a 2nd CI. A subsequent study was performed to examine the effects of unilateral CI hearing on the contributions of the 1st and 2nd implanted ears to the binaural response. It was found that in children with > 2 years of unilateral hearing, the binaural response is dominated by the 1st implanted ear. Together, these results suggest that the delay between the 1st and 2 nd CI should be minimized in bilateral implantation to avoid dominance of auditory pathways from the 1st implanted ear. This dominance limits developmental competition from the 2nd CI and potentially contributes to poorer performance in speech detection in noise tasks. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,74,8-B(E),No Pagination Specified,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc13&AN=2014-99040-380
37,Ovid Technologies,APA PsycInfo,2013-00518-012,"Salicylate-induced cochlear impairments, cortical hyperactivity and re-tuning, and tinnitus. [References].",Jan 2013,2013,"First Posting: Nov 2012

Accepted: Nov 2012

Revised: Nov 2012

First Submitted: Jul 2012.","Chen, Guang-Di

Stolzberg, Daniel

Lobarinas, Edward

Sun, Wei

Ding, Dalian

Salvi, Richard","Chen, Guang-Di: gchen7@buffalo.edu","Hearing Research. Vol.295, 2013, pp. 100-113.",Jan,,"High doses of sodium salicylate (SS) have long been known to induce temporary hearing loss and tinnitus, effects attributed to cochlear dysfunction. However, our recent publications reviewed here show that SS can induce profound, permanent, and unexpected changes in the cochlea and central nervous system. Prolonged treatment with SS permanently decreased the cochlear compound action potential (CAP) amplitude in vivo. In vitro, high dose SS resulted in a permanent loss of spiral ganglion neurons and nerve fibers, but did not damage hair cells. Acute treatment with high-dose SS produced a frequency-dependent decrease in the amplitude of distortion product otoacoustic emissions and CAP. Losses were greatest at low and high frequencies, but least at the mid-frequencies (10-20 kHz), the mid-frequency band that corresponds to the tinnitus pitch measured behaviorally. In the auditory cortex, medial geniculate body and amygdala, high-dose SS enhanced sound-evoked neural responses at high stimulus levels, but it suppressed activity at low intensities and elevated response threshold. When SS was applied directly to the auditory cortex or amygdala, it only enhanced sound evoked activity, but did not elevate response threshold. Current source density analysis revealed enhanced current flow into the supragranular layer of auditory cortex following systemic SS treatment. Systemic SS treatment also altered tuning in auditory cortex and amygdala; low frequency and high frequency multiunit clusters up-shifted or down-shifted their characteristic frequency into the 10-20 kHz range thereby altering auditory cortex tonotopy and enhancing neural activity at mid-frequencies corresponding to the tinnitus pitch. These results suggest that SS-induced hyperactivity in auditory cortex originates in the central nervous system, that the amygdala potentiates these effects and that the SS-induced tonotopic shifts in auditory cortex, the putative neural correlate of tinnitus, arises from the interaction between the frequency-dependent losses in the cochlea and hyperactivity in the central nervous system. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B.V.
YEAR: 2012",Hearing Research,295,,100-113,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc12&DO=10.1016%2fj.heares.2012.11.016
38,Ovid Technologies,APA PsycInfo,2012-04714-014,Pseudohypacusis in childhood and adolescence is associated with increased gray matter volume in the medial frontal gyrus and superior temporal gyrus. [References].,Apr 2012,2012,"First Posting: Oct 2010

Accepted: Sep 2010

Revised: Jul 2010

First Submitted: May 2010.","Tomoda, Akemi

Kinoshita, Sumihito

Korenaga, Yuki

Mabe, Hiroyo","Tomoda, Akemi: tomo@kumamoto-u.ac.jp","Cortex: A Journal Devoted to the Study of the Nervous System and Behavior. Vol.48,(4), 2012, pp. 492-503.",Apr,,"Pseudohypacusis is a somatoform disorder characterized by hearing loss with discrepancies between pure-tone audiometry and auditory brainstem response (ABR), but the underlying neuronal mechanisms remain unclear. Using voxel-based morphometry (VBM) with magnetic resonance (MR) imaging for 14 unmedicated, right-handed patients and 35 healthy control subjects, we investigated whether functional hearing loss was associated with discernible changes of brain morphology. Group differences in gray matter volume (GMV) were assessed using high-resolution, T1-weighted, volumetric MR imaging datasets (3T Trio scanner; Siemens AG) and analyzed with covariant factors of age, sex, socioeconomic status (SES), and total GMV, which was increased by 27.9% in the left medial frontal gyrus (MFG) (Brodmann area 10) (p =.001, corrected cluster level) and by 14.4% in the right superior temporal gyrus (STG) and the adjacent middle temporal gyrus (MTG) (BA42 to 21) (p =.009, corrected cluster level) in patients with pseudohypacusis. The GMV in the right STG (BA42) and verbal intelligence quotient (IQ) were correlated significantly with the Wechsler Intelligence Scale for Children-Third Edition (WISC-III) (s =-.57, p <.0001) and level of SES (s =-.55, p <.0001). The present findings suggest that the development of the auditory association cortex involved in language processing is affected, causing insufficient pruning during brain development. We therefore assert that differences in the neuroanatomical substrate of pseudohypacusis subjects result from a developmental disorder in auditory processing. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier Srl.
YEAR: 2010",Cortex: A Journal Devoted to the Study of the Nervous System and Behavior,48,4,492-503,Click here for full text options,SFX,,"Masson Italia, Italy",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc11&DO=10.1016%2fj.cortex.2010.10.001
39,Ovid Technologies,APA PsycInfo,2012-02338-007,Multivariate DPOAE metrics for identifying changes in hearing: Perspectives from ototoxicity monitoring. [References].,Feb 2012,2012,"Accepted: Oct 2011

First Submitted: Oct 2011.","Konrad-Martin, Dawn

Reavis, Kelly M

McMillan, Garnett P

Dille, Marilyn F","Konrad-Martin, Dawn: dawn.martin@va.gov","International Journal of Audiology. Vol.51,(Suppl 1), 2012, pp. S51-S62.",Feb,,"Distortion-product otoacoustic emissions (DPOAEs) provide a window into real-time cochlear mechanical function. Yet, relationships between the changes in DPOAE metrics and auditory sensitivity are still poorly understood. Explicating these relationships might support the use of DPOAEs in hearing conservation programs (HCPs) for detecting early damage leading to noise-induced hearing loss (NIHL) so that mitigating steps might be taken to limit any lasting damage. This report describes the development of DPOAE-based statistical models to assess the risk of hearing loss from cisplatin treatment among cancer patients. Ototoxicity risk assessment (ORA) models were constructed using a machine learning paradigm in which partial least squares and leave-one-out cross-validation were applied, yielding optimal screening algorithms from a set of known risk factors for ototoxicity and DPOAE changes from pre-exposure baseline measures. Single DPOAE metrics alone were poorer indicators of the risk of ototoxic hearing shifts than the best performing multivariate models. This finding suggests that multivariate approaches applied to the use of DPOAEs in a HCP, will improve the ability of DPOAE measures to identify ears with noise-induced mechanical damage and/or hearing loss at each monitoring interval. This prediction must be empirically assessed in noise-exposed subjects. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: British Society of Audiology, International Society of Audiology, and Nordic Audiological Society
YEAR: 2012",International Journal of Audiology,51,Suppl 1,S51-S62,Click here for full text options,SFX,,"Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc11&DO=10.3109%2f14992027.2011.635713
40,Ovid Technologies,APA PsycInfo,2011-04780-046,Multiple effects of childhood deafness on cortical activity in children receiving bilateral cochlear implants simultaneously. [References].,Apr 2011,2011,"First Posting: Nov 2010

Accepted: Oct 2010.","Gordon, K. A

Tanaka, S

Wong, D. D. E

Stockley, T

Ramsden, J. D

Brown, T

Jewell, S

Papsin, B. C","Gordon, K. A.: karen.gordon@utoronto.ca","Clinical Neurophysiology. Vol.122,(4), 2011, pp. 823-833.",Apr,Electroencephalography & Clinical Neurophysiology,"Objective: Auditory development is disrupted without normal hearing but might proceed to some extent depending on the type and onset of deafness. We therefore hypothesized that activity in the auditory cortex would be highly variable in children who are deaf. Methods: To answer this, activity in the deaf brain was evoked by electrical pulses from newly provided bilateral cochlear implants (CIs) in 72 children (n = 144 responses). Results: Responses were categorized by visual inspection into 3 main types which were validated by principal component cluster analyses; 49% had a negative amplitude wave similar to that previously reported in pre-term infants, 26% were dominated by a positive peak typical of responses in young normal hearing children and experienced paediatric CI users, 25% were novel multi-peaked responses. No significant demographic differences, including duration and onset of deafness, were found between response types. However, children with severe biallelic mutations of GJB-2 showed predominately negative peak type responses (79%) as compared with their peers without these mutations who had a more equal distribution between cortical response types. Conclusion: Cortical development in children who are deaf is heterogeneous but can be better predicted when the genotype is known to be a GJB-2 mutation. Significance: Remediation of childhood deafness seeks to restore normal development and function of central auditory functions and thus may need to be tailored to account for effects specific to the aetiology of deafness. (PsycInfo Database Record (c) 2023 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: International Federation of Clinical Neurophysiology
YEAR: 2010",Clinical Neurophysiology,122,4,823-833,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&DO=10.1016%2fj.clinph.2010.10.037
41,Ovid Technologies,APA PsycInfo,2011-30013-004,Randomized trial of a hearing conservation intervention for rural students: Long-term outcomes. [References].,Nov 2011,2011,Accepted: Jul 2011.,"Marlenga, Barbara

Linneman, James G

Pickett, William

Wood, Douglas J

Kirkhorn, Steven R

Broste, Steven K

Knobloch, Mary Jo

Berg, Richard L","Marlenga, Barbara: marlenga.barbara@mcrf.mfldclin.edu","Pediatrics. Vol.128,(5), 2011, pp. e1139-e1146.",Nov,,"Objectives: We had the rare opportunity to conduct a cluster-randomized controlled trial to observe the long-term (16-year) effects of a well-designed hearing conservation intervention for rural high school students. This trial assessed whether the intervention resulted in (1) reduced prevalence of noise-induced hearing loss (NIHL) assessed clinically and/or (2) sustained use of hearing protection devices. Methods: In 1992-1996, 34 rural Wisconsin schools were recruited and 17 were assigned randomly to receive a comprehensive, 3-year, hearing conservation intervention. In 2009 -2010, extensive efforts were made to find and contact all students who completed the original trial. Participants in the 16-year follow-up study completed an exposure history questionnaire and a clinical audiometric examination. Rates of NIHL and use of hearing protection were compared. Results: We recruited 392 participants from the original trial, 200 (53%) from the intervention group and 192 (51%) from the control group. Among participants with exposure to agricultural noise, the intervention group reported significantly greater use of hearing protection compared with the control group (25.9% vs 19.6%; P = .015). The intervention group also reported significantly greater use of hearing protection for shooting guns (56.2% vs 41.6%; P = .029), but the groups reported similar uses of protection in other contexts. There was no significant difference between groups with respect to objective measures of NIHL. Conclusion: This novel trial provides objective evidence that a comprehensive educational intervention by itself may be of limited effectiveness in preventing NIHL in a young rural population. (PsycInfo Database Record (c) 2022 APA, all rights reserved)","HOLDER: American Academy of Pediatrics
YEAR: 2011",Pediatrics,128,5,e1139-e1146,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&DO=10.1542%2fpeds.2011-0770
42,Ovid Technologies,APA PsycInfo,2011-21669-041,Behavioral training enhances cortical temporal processing in neonatally deafened juvenile cats. [References].,Aug 2011,2011,"First Posting: May 2011

Accepted: May 2011

First Submitted: Aug 2010.","Beitel, Ralph E

Vollmer, Maike

Raggio, Marcia W

Schreiner, Christoph E","Beitel, Ralph E.: beitel@keck.ucsf.edu","Journal of Neurophysiology. Vol.106,(2), 2011, pp. 944-959.",Aug,,"Deaf humans implanted with a cochlear prosthesis depend largely on temporal cues for speech recognition because spectral information processing is severely impaired. Training with a cochlear prosthesis is typically required before speech perception shows improvement, suggesting that relevant experience modifies temporal processing in the central auditory system. We tested this hypothesis in neonatally deafened cats by comparing temporal processing in the primary auditory cortex (AI) of cats that received only chronic passive intracochlear electric stimulation (ICES) with cats that were also trained with ICES to detect temporally challenging trains of electric pulses. After months of chronic passive stimulation and several weeks of detection training in behaviorally trained cats, multineuronal AI responses evoked by temporally modulated ICES were recorded in anesthetized animals. The stimulus repetition rates that produced the maximum number of phase-locked spikes (best repetition rate) and 50% cutoff rate were significantly higher in behaviorally trained cats than the corresponding rates in cats that received only chronic passive ICES. Behavioral training restored neuronal temporal following ability to levels comparable with those recorded in naive prior normal-hearing adult deafened animals. Importantly, best repetitition rates and cutoff rates were highest for neuronal clusters activated by the electrode configuration used in behavioral training. These results suggest that neuroplasticity in the AI is induced by behavioral training and perceptual learning in animals deprived of ordinary auditory experience during development and indicate that behavioral training can ameliorate or restore temporal processing in the AI of profoundly deaf animals. (PsycInfo Database Record (c) 2022 APA, all rights reserved)","HOLDER: American Physiological Society
YEAR: 2011",Journal of Neurophysiology,106,2,944-959,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&DO=10.1152%2fjn.00731.2010
43,Ovid Technologies,APA PsycInfo,2011-99080-055,A cochlear stress hormone axis shapes development and function of the auditory periphery.DP  - 2011,,2011,,"Graham, Christine Elizabeth",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.71,(10-B), 2011, pp. 5957.",,Dissertation Abstracts International,"Corticotropin Releasing Factor (CRF) is the stress hormone that activates the hypothalamic-pituitary-adrenal axis to maintain system-wide homeostasis in response to stress. This thesis describes a CRF signaling system contained in the cochlea and explores its role in auditory processing and protection. To investigate the role of CRF signaling in the cochlea, two transgenic mouse strains were used, each lacking one of the CRF receptors expressed in mammals, CRFR1 or CRFR2. Auditory Brainstem Response (ABR) thresholds and Distortion Product Otoacoustic Emission ii (DPOAE) isoresponse thresholds were measured to assess auditory function. CRFR2 null mice exhibit hypersensitive hearing when raised under quiet conditions, but increased susceptibility to noise-induced hearing loss (NIHL). Immunofluorescent labeling of CRFR2 localizes the receptor to the afferent spiral ganglion neurons and support cells lining the cochlear duct. Genetic ablation of CRFR2 elicits changes in both cell types. Using western blot analysis, alterations in glutamate receptor expression were observed in CRFR2 null mice, suggesting a potential regulatory role for CRFR2 in hair cell to spiral ganglion cell glutamatergic transmission. Also, CRFR2 null mice show deficient expression of connexin proteins important for support cell communication. Connexin deficiency in these mice coincides with altered levels of purinergic receptors and potassium channel proteins, suggesting a potential link between connexin deficiency, altered purinergic signaling, and disrupted potassium homeostasis. Such changes may contribute to the hyperacusis in CRFR2 null mice by increasing the endocochlear drive on mechanotransduction. Auditory physiology reveals a decreased sensitivity in CRFR1 null mice, opposite from the hypersensitivity observed in mice lacking CRFR2. Cochlear expression of CRFR1 was assessed using BAC transgenic mice expressing green fluorescent protein (GFP) under the CRFR1 promoter. CRFR1 expression is largely found in various support cells, with little to no expression in sensory cells. Nonetheless, CRFR1 is expressed in support cells directly juxtaposing the inner and outer hair cells, where it may exert indirect effects on hair cell function. The auditory physiology suggests an afferent basis for the hearing impairment in CRFR1 null mice and therefore, support cell-sensory cell interactions were investigated at the afferent synapse. CRFR1 null mice exhibit a significant reduction in glutamine synthetase (GS) levels suggesting impaired glutamate cycling between the presynaptic inner hair cell and its neighboring CRFR1-positive border cell. GS is a glucocorticoid inducible factor, and to determine if glucocorticoid deficiency underlies the reduced GS expression, mice were chronically treated with corticosterone in their drinking water. Corticosterone treatment restored GS levels in CRFR1 null mice but did not rescue the auditory deficit, indicating that reduced GS levels do not cause this deficit. Assessment of afferent synapse structure revealed normal overlay of presynaptic ribbons and postsynaptic glutamate receptor clusters; however, the distribution of these synapses within the inner hair cell was altered as evidenced by three-dimensional image analysis. Labeling of afferent fibers and terminals using antibodies against the a3 subunit of the sodium-potassium ATPase also revealed targeting defects, and together these results demonstrate an important developmental role for CRFR1 activity in the cochlea. We describe for the first time an HPA equivalent signaling system in the cochlea. Immunolabeling experiments demonstrate expression of pro-opiomelanocortin (POMC), adrenocorticotropic hormone (ACTH), and the ACTH receptor, melanocortin receptor 2 (MC2R) in the support cells and sensory cells of the cochlea. The full role of this HPA axis in auditory processing and protection awaits clarification. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,71,10-B,5957,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&AN=2011-99080-055
44,Ovid Technologies,APA PsycInfo,2011-26528-004,WHO Ear and Hearing Disorders Survey in four provinces in China. [References].,Dec 2011,2011,Accepted: Oct 2011.,"Bu, Xingkuan

Liu, Cheng

Xing, Guangqian

Zhou, Ling

Liang, Chuanyu

Zheng, Yun

Meng, Juang

Wang, Youqin

Yang, Chongling

Liu, Yuqing

Du, Baodong

Zhang, Yan

Du, Bo","Bu, Xingkuan: bxkuan@gmail.com","Audiological Medicine. Vol.9,(4), 2011, pp. 141-146.",Dec,"Hearing, Balance and Communication","Objective: To investigate the population based prevalence of ear diseases and hearing impairment in Jiangsu, Sichuan, Guizhou and Jilin Provinces in China, develop strategies to provide scientific data for the global database and to draw up prevention and intervention strategies. Methods: Using the WHO Ear and Hearing Disorders Survey Protocol and the probability proportion to size (PPS) sampling technique, 30,733 residents were targeted for investigation in 150 clusters in four provinces. Every subject had an ear examination and pure tone audiometry. Definitions of disabling hearing loss and the classification of hearing impairment used were in accordance with WHO recommendations. Results: Among 30,733 targeted residents, 29,246 individuals (95.2%) participated in the survey. One thousand, three hundred and sixty individuals (4.4%) were absent; 127 individuals (0.4%) refused. The prevalences of hearing impairment and disabling hearing impairment were 14.2% and 5.2% of investigated individuals, respectively: 9.1% of the sample had a mild hearing loss, 3.8% a moderate degree of hearing loss, 1.1% a severe and 0.3% a profound hearing loss. Using data from the fifth population census in China (2000), we calculated the standardized rates of hearing impairment and hearing disability in our study to be 11.7% and 4.4%, respectively. There was a significant difference in the prevalence between males and females, urban and rural dwellers, as well as for different ages. The prevalence of ear diseases was 6.5% of investigated individuals: the standardized rate was 5.9%; 0.2% of investigated individuals had auricle malformation, 2.2% impacted cerumen, 0.2% otitis externa, 0.3% fungi, 0.1% foreign body, 0.1% acute otitis media, 0.9% chronic suppurative otitis media, 1.8% serous otitis media and 1.3% dry perforation of tympanic membrane. Overall, 8.0% of investigated persons were assessed to be likely to benefit from hearing aids, while 4.0% of persons needed medication, 0.1% language/speech rehabilitation, 1.5% non-urgent surgery and 0.9% other treatment. Conclusions: The high prevalence of hearing impairment and disability is a heavy burden on social development and also hinders normal family life. The government and society as a whole should show more concern about these problems. Strategies for prevention and intervention should be focused on less developed regions, rural areas, aging people and non-infectious conditions. Hearing aids services, medication, professional education and training are particularly important in developing countries. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: Informa Healthcare
YEAR: 2011",Audiological Medicine,9,4,141-146,Click here for full text options,SFX,,"Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc10&DO=10.3109%2f1651386X.2011.631285
45,Ovid Technologies,APA PsycInfo,2011-18908-002,Using cluster analysis to classify audiogram shapes. [References].,Sep 2010,2010,"Accepted: Mar 2010

First Submitted: Sep 2009.","Lee, Cheng-Yung

Hwang, Juen-Haur

Hou, Szu-Jen

Liu, Tien-Chen","Hwang, Juen-Haur: G120796@tzuchi.com.tw","International Journal of Audiology. Vol.49,(9), 2010, pp. 628-633.",Sep,,"The purpose of this study was to design a statistical classification system of audiogram shapes in order to improve and integrate shape recognition across clinical settings. The study included 1633 adult subjects with normal hearing or symmetric sensorineural hearing impairment who underwent pure-tone audiometry between July 2007 and December 2008. K-means cluster analysis was employed to categorize audiometric shapes. Eleven audiogram shapes were identified: rising, flat, peaked 8-kHz dip, 4-kHz dip, 8-kHz dip, mild sloping, severe 8-kHz dip, sloping, abrupt loss, severe sloping, and profound abrupt loss. By using the classification system and nomenclature identified for audiogram shapes as outlined in this study, errors based on personal experiences can be reduced and a consistency can be developed across clinics. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","HOLDER: British Society of Audiology, International Society of Audiology, and Nordic Audiological Society
YEAR: 2010",International Journal of Audiology,49,9,628-633,Click here for full text options,SFX,,"Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc9&DO=10.3109%2f14992021003796887
46,Ovid Technologies,APA PsycInfo,2009-99200-531,"Preschool vitamin a supplementation, middle ear infection, and young adult hearing loss in Nepal.DP  - 2009",,2009,,"Schmitz, Jane",,"Dissertation Abstracts International: Section B: The Sciences and Engineering. Vol.70,(4-B), 2009, pp. 2255.",,Dissertation Abstracts International,"Background. Vitamin A deficiency is associated with risk of chronic otitis media, the leading cause of preventable childhood hearing loss in the world. Despite the co-existence of undernutrition and middle ear infections in many disadvantaged populations, little is known about their association with hearing loss and no studies have assessed the efficacy of vitamin A supplementation on attenuating the risk of hearing loss. Methods. From 2006 to 2008, we assessed 3,628 young adults 16-23 years of age who, as preschool children (1989-1991), participated in a cluster-randomized, double-masked, placebo-controlled vitamin A supplementation trial in southern Nepal. In the original trial, anthropometric measures (height or length, weight, mid-upper arm circumference [MUAC]) and one-week parental morbidity reports, including ear discharge (external ear otorrhea), were collected at the time of dosing every four months over a 16-month period. Household socioeconomic status (SES) variables were also recorded. In the follow-up health survey 17 years later, audiometric, ear health and tympanometry evaluations were performed in addition to nutritional, other health and socioeconomic assessments. Hearing loss was defined as both failing to hear a 30dB screening tone at 0.5, 1, 2, 4 and 8 kHz and exhibiting an average air conduction threshold value greater than 30 dB in the worse ear across the frequencies 0.5, 1, 2 and 4 kHz. Results. The prevalence of hearing loss in this population of older adolescents and young adults was 6.2% (95% confidence interval [CI]: 5.6-6.7%). This prevalence figure suggests that there are approximately 30,840 young people 16 to 23 years of age in rural Nepal with test-based hearing impairment. Those with hearing loss were 6- to 8-fold more likely than their normal hearing peers to report problems in communicating with others. Ear discharge in the preschool years was associated, in a dose-response manner, with hearing loss later in life. The odds ratio (OR) for being hearing impaired as young adults ranged from 1.9 to 19.6 among subjects reporting 1 to 7 weekly episodes of ear discharge in their preschool years compared to individuals reporting no episodes. The OR for hearing loss was 5.14 (95% CI: 3.54-7.46) for any preschool episode of preschool ear discharge compared to being free of apparent ear infection; an increase in risk that was concentrated in subjects with abnormal tympanometry in young adulthood. Preschool supplementation with 200,000 IU of vitamin A every four months was associated with a non-significant 18% reduction in hearing loss relative to controls (OR = 0.82; 95% CI: 0.61-1.09). However, among subjects who had reported any preschool episode of ear discharge, vitamin A supplementation reduced the risk of hearing loss by 37% (OR = 0.63; 95% CI: 0.40-0.98), an effect that persisted after adjusting for age, sex, and childhood SES. Both stunting and wasting, based on indicators less than -2 Z scores, in the preschool years were associated with increased risk of hearing loss. Children who were underweight or wasted, but not stunted, in the preschool years were more likely to have middle ear dysfunction, as measured by tympanometry, in young adulthood. Gender, age and socioeconomic status in early childhood were not associated with young adult hearing loss. Conclusion. Hearing loss is a public health problem among young adults living in rural, southern Nepal. The condition is associated with the frequency of ear infection and the severity of undernutrition in the preschool years. Periodically supplementing children with high-potency vitamin A in the preschool years reduced the risk of permanent hearing loss by early adulthood, particularly among subjects with prospectively documented suppurative ear infections in early childhood. These findings suggest that periodic vitamin A supplementati... (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Dissertation Abstracts International: Section B: The Sciences and Engineering,70,4-B,2255,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&AN=2009-99200-531
47,Ovid Technologies,APA PsycInfo,2009-23598-020,Hearing conservation program for agricultural students: Short-term outcomes from a cluster-randomized trial with planned long-term follow-up. [References].,Dec 2009,2009,First Posting: Oct 2009.,"Berg, Richard L

Pickett, William

Fitz-Randolph, Marcy

Broste, Steven K

Knobloch, Mary Jo

Wood, Douglas J

Kirkhorn, Steven R

Linneman, James G

Marlenga, Barbara","Marlenga, Barbara: marlenga.barbara@mcrf.mfldclin.edu","Preventive Medicine: An International Journal Devoted to Practice and Theory. Vol.49,(6), 2009, pp. 546-552.",Dec,Preventative Medicine: An International Journal Devoted to Practice & Theory,"Objectives : (1) To conduct a contemporary analysis of historical data on short-term efficacy of a 3-year hearing conservation program conducted from 1992 to 1996 in Wisconsin, USA, with 753 high school students actively involved in farm work; (2) to establish procedures for assessment of hearing loss for use in a recently funded follow-up of this same hearing conservation program cohort. Methods : We analyzed a pragmatic cluster-randomized controlled trial, with schools as the unit of randomization. Thirty-four rural schools were recruited and randomized to intervention or control. The intervention included classroom instruction, distribution of hearing protection devices, direct mailings, noise level assessments, and yearly audiometric testing. The control group received the audiometric testing. Results : Students exposed to the hearing conservation program reported more frequent use of hearing protection devices, but there was no evidence of reduced levels of noise-induced hearing loss (NIHL). Conclusion : Our analysis suggests that, since NIHL is cumulative, a 3-year study was likely not long enough to evaluate the efficacy of this intervention. While improvements in reported use of hearing protection devices were noted, the lasting impact of these behaviors is unknown and the finding merits corroboration by longer term objective hearing tests. A follow-up study of the cohort has recently been started. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier Inc.
YEAR: 2009",Preventive Medicine: An International Journal Devoted to Practice and Theory,49,6,546-552,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&DO=10.1016%2fj.ypmed.2009.09.020
48,Ovid Technologies,APA PsycInfo,2009-01630-003,Age-related hearing loss: Aquaporin 4 gene expression changes in the mouse cochlea and auditory midbrain. [References].,Feb 2009,2009,"First Posting: Dec 2008

Accepted: Nov 2008.","Christensen, Nathan

D'Souza, Mary

Zhu, Xiaoxia

Frisina, Robert D","Frisina, Robert D.: Robert_Frisina@urmc.rochester.edu","Brain Research. Vol.1253, 2009, pp. 27-34.",Feb,,"Presbycusis-age-related hearing loss, is the number one communication disorder, and one of the top three chronic medical conditions of our aged population. Aquaporins, particularly aquaporin 4 (Aqp4), are membrane proteins with important roles in water and ion flux across cell membranes, including cells of the inner ear and pathways of the brain used for hearing. To more fully understand the biological bases of presbycusis, 39 CBA mice, a well studied animal model of presbycusis, underwent non-invasive hearing testing as a function of sound frequency (auditory brainstem response-ABR thresholds, and distortion-product otoacoustic emission-DPOAE magnitudes), and were clustered into four groups based on age and hearing ability. Aqp4 gene expression, as determined by genechip microarray analysis and quantitative real-time PCR, was compared to the young adult control group in the three older groups: middle aged with good hearing, old age with mild presbycusis, and old age with severe presbycusis. Linear regression and ANOVA showed statistically significant changes in Aqp4 gene expression and ABR and DPOAE hearing status in the cochlea and auditory midbrain-inferior colliculus. Down-regulation in the cochlea was seen, and an initial down-, then up-regulation was discovered for the inferior colliculus Aqp4 expression. It is theorized that these changes in Aqp4 gene expression represent an age-related disruption of ion flux in the fluids of the cochlea that are responsible for ionic gradients underlying sound transduction in cochlear hair cells necessary for hearing. In regard to central auditory processing at the level of the auditory midbrain, aquaporin gene expression changes may affect neurotransmitter cycling involving supporting cells, thus impairing complex sound neural processing with age. (PsycInfo Database Record (c) 2021 APA, all rights reserved)","STATEMENT: All rights reserved.
HOLDER: Elsevier B. V.
YEAR: 2008",Brain Research,1253,,27-34,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc8&DO=10.1016%2fj.brainres.2008.11.070
49,Ovid Technologies,APA PsycInfo,2009-04156-001,Prevalence of hearing impairment by gender and audiometric configuration: Results from the National Health and Nutrition Examination Survey (1999-2004) and the Keokuk County Rural Health Study (1994-1998). [References].,Oct 2008,2008,,"Ciletti, Lindsay

Flamme, Gregory A","Flamme, Gregory A.: greg.flamme@wmich.edu","Journal of the American Academy of Audiology. Vol.19,(9), 2008, pp. 672-685.",Oct,,"Purpose: This study describes the most common audiometric configurations and the prevalence of these configurations among adults (ages 20 to 69) in the noninstitutionalized population of the United States and in a sample of residents of a rural county in Iowa. Research Design: This was a cross-sectional population-based study. Study Sample: Estimates generalizing to the noninstitutionalized population of the United States were based on National Health and Nutrition Examination Survey (NHANES) data collected from 2819 women and 2525 men between 1999 and 2004. Estimates from the rural county were based on Keokuk County Rural Health Study (KCRHS) data collected from 892 women and 750 men between 1994 and 1998. Data Collection and Analysis: Cluster analyses (k-means) were used to divide participants into groups including maximally similar bilateral air conduction audiograms. Separate cluster analyses were conducted for each gender. For NHANES data, prevalence and error estimates were obtained using sample weights intended to provide data generalizing to the noninstitutionalized population of the United States within this age range. Results: The hierarchical structure of audiometric configurations revealed that approximately 25% of women and 50% of men aged 20 to 69 in the noninstitutionalized population of the United States were best described by a configuration consistent with a marked hearing impairment in at least one frequency. Hearing impairments were more common among participants in the KCRHS. Gently sloping configurations of hearing impairment were dominant among women, while configurations featuring a greater slope were dominant among men. There was a greater variety of audiometric configurations in men than women. Conclusions: In addition to their descriptive value, these data can be used to inform future studies of risk factors and progression of hearing loss, and to improve the generalizability of studies involving rehabilitative options for people with hearing impairment. (PsycInfo Database Record (c) 2022 APA, all rights reserved)",,Journal of the American Academy of Audiology,19,9,672-685,Click here for full text options,SFX,,"Thieme Medical Publishers, Inc., Germany",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc7&DO=10.3766%2fjaaa.19.9.3
50,Ovid Technologies,APA PsycInfo,2008-00143-002,Prevalence of hearing impairment in an adult population in southern Taiwan. [References].,Dec 2007,2007,,"Lin, Cheng-Yu

Yang, Yi-Ching

Guo, Yueliang Leon

Wu, Chih-Hsing

Chang, Chih-Jen

Wu, Jiunn-Liang","Wu, Jiunn-Liang: jiunn@mail.ncku.edu.tw","International Journal of Audiology. Vol.46,(12), 2007, pp. 732-737.",Dec,,"The objective of this study was to estimate the prevalence of hearing impairment in a representative adult population in southern Taiwan and compare the results to those of similar studies in other countries. A stratified systematic cluster sample of 1140 residents, aged >=20 years, of Tainan City was studied from 2001 to 2003. The test battery included otoscopy, pure-tone audiometry, and a questionnaire covering relevant personal, occupational, and family history. The hearing threshold level (HTL) was defined as the better ear pure-tone average (BPTA) (i.e. the average of hearing thresholds at frequencies 500, 1000, 2000, and 4000 Hz). The prevalence of hearing impairment was 21.4% (95% confidence interval: 19.3-23.7%) at BPTA >=25 dB HTL. Middle ear disease was a significant risk factor for hearing impairment in addition to age and gender. The overall prevalence of hearing impairment may be higher in Taiwan (17.1%) than in western populations (11.5%), but differences in the definition of hearing impairment severity and variation in sex distribution among studies may account for this higher prevalence. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,International Journal of Audiology,46,12,732-737,Click here for full text options,SFX,,"Taylor & Francis, United Kingdom",,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc6&DO=10.1080%2f14992020701448986
51,Ovid Technologies,APA PsycInfo,2004-15693-006,Using Visible Speech to Train Perception and Production of Speech for Individuals With Hearing Loss. [References].,Apr 2004,2004,,"Massaro, Dominic W

Light, Joanna","Massaro, Dominic W.: massaro@fuzzy.ucsc.edu","Journal of Speech, Language, and Hearing Research. Vol.47,(2), 2004, pp. 304-320.",Apr,Journal of Speech & Hearing Research,"The main goal of this study was to implement a computer-animated talking head, Baldi, as a language tutor for speech perception and production for individuals with hearing loss. Baldi can speak slowly; illustrate articulation by making the skin transparent to reveal the tongue, teeth, and palate; and show supplementary articulatory features, such as vibration of the neck to show voicing and turbulent airflow to show frication. Seven students with hearing loss between the ages of 8 and 13 were trained for 6 hours across 21 weeks on 8 categories of segments (4 voiced vs. voiceless distinctions, 3 consonant cluster distinctions, and 1 fricative vs. affricate distinction). Training included practice at the segment and the word level. Perception and production improved for each of the 7 children. Speech production also generalized to new words not included in the training lessons. Finally, speech production deteriorated somewhat after 6 weeks without training, indicating that the training method rather than some other experience was responsible for the improvement that was found. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,"Journal of Speech, Language, and Hearing Research",47,2,304-320,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc5&DO=10.1044%2f1092-4388%25282004%2f025%2529
52,Ovid Technologies,APA PsycInfo,1999-00336-003,Modeling the interaction of phonemic intelligibility and lexical structure in audiovisual word recognition.DP  - Oct 1998,,1998,,"Iverson, Paul

Bernstein, Lynne E

Auer, Edward T Jr.",,"Speech Communication. Vol.26,(1-2), 1998, pp. 45-63.",Oct,,"Studies of audiovisual perception of spoken language have mostly modeled phoneme identification in nonsense syllables, but it is doubtful that models or theories of phonetic processing can adequately account for audiovisual word recognition. The present study took a computational approach to examine how lexical structure may additionally constrain word recognition, given the phonetic information available under vocoded audio, visual, and audiovisual stimulus conditions. Adults with normal hearing (18-45 yrs old) made phonemic identification judgments on recordings of spoken nonsense syllables. Deaf Ss participated in a consonant identification task. Hierarchical cluster analysis was used 1st to select classes of perceptually equivalent phonemes for each of the stimulus conditions, and then a machine-readable phonemically transcribed lexicon was re-transcribed in terms of these phonemic equivalence classes. For each of the transcriptions computations were made of percent information extracted, percent words unique, and expected class size. The findings suggest that superadditive levels of audiovisual enhancement are more likely for monosyllabic than for multisyllabic words. (PsycInfo Database Record (c) 2023 APA, all rights reserved)",,Speech Communication,26,1-2,45-63,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc3&DO=10.1016%2fS0167-6393%252898%252900049-1
53,Ovid Technologies,APA PsycInfo,1996-23685-001,"Dispositional optimism, dysphoria, health, and coping with hearing impairment in elderly adults.DP  - Mar-Apr 1995",,1995,,"Andersson, Gerhard

Melin, Lennart

Lindberg, Per

Scott, Berit",,"Audiology. Vol.34,(2), 1995, pp. 76-84.",Mar-Apr,,"Investigated the psychometric validity of and associations among measures of dispositional optimism, dysphoria, health, and coping in a sample of 68 hearing impaired adults (mean age 69.6 yrs), who were recently supplied with hearing aids. Cluster analysis was also attempted to investigate the presence of coping categories, and the characteristics of these obtained subgroups. Measures included the Hearing Coping Assessment, the Hearing Questions (HQ), the Life Orientation Test, the Beck Depression Inventory, and a subscale from the Goteborg Quality of Life. Psychometric analyses revealed high reliability in terms of Cronbach's alpha and split-half r's. Significant intercorrelations were found between several measures, but not with pure-tone audiometry (.5, 1, 2, and 3 kHz). Three clusters were identified interpreted as (1) high copers, (2) copers with moderate psychological and somatic complaints, and (3) low copers. (French abstract) (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Audiology,34,2,76-84,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc3&DO=10.3109%2f00206099509071900
54,Ovid Technologies,APA PsycInfo,1986-27536-001,Vowel perception: Experiments with a single-electrode cochlear implant.DP  - Jun 1986,,1986,,"Doyle, Karen J

Danhauer, Jeffrey L

Edgerton, Bradly J",,"Journal of Speech & Hearing Research. Vol.29,(2), 1986, pp. 179-192.",Jun,"Journal of Speech, Language, and Hearing Research","15 postlingually deaf adults (aged 19-79 yrs) with histories of unsuccessful hearing aid use and a minimum of 6-22 mo experience with a single-electrode cochlear implant were presented with audiorecordings of 11 natural and loudness-matched vowels. Ss rated the dissimilarity of both the naturally spoken and the loudness-matched vowels and performed identification of the latter. Two normal-hearing Ss served as controls for the dissimilarity tasks. Multidimensional scaling, hierarchical clustering, and percent correct identification analyses were used to help determine the perceptual features used by the Ss in their judgments. Data indicate that, in general, normal-hearing Ss took advantage of 2nd formant frequency information. Cochlear-implant Ss relied primarily on fundamental and 1st formant frequency information and demonstrated difficulty in vowel identification. Appendices include audiometric data and descriptive data for the implant Ss, analog unprocessed waveforms of the stimuli, and averaged dissimilarity ratings of the loudness-matched vowels by the Ss. (23 ref) (PsycInfo Database Record (c) 2023 APA, all rights reserved)",,Journal of Speech & Hearing Research,29,2,179-192,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1044%2fjshr.2902.179
55,Ovid Technologies,APA PsycInfo,1979-11190-001,Intonation contour and syntactic structure as predictors of apparent segmentation. [References].,May 1978,1978,,"Geers, Ann E",,"Journal of Experimental Psychology: Human Perception and Performance. Vol.4,(2), 1978, pp. 273-283.",May,,"Segmentation is reflected in the chunking of complex stimuli into cohesive units. In speech this segmentation may be determined by interalized grammatical rules, with boundaries of the units corresponding to major constituent boundaries. On the other hand, this segmentation may also be accomplished by physical characteristics of the speech signal, with the boundaries of the units corresponding to acoustic discontinuities such as changes in vocal pitch, duration, and/or intensity of syllables at the boundary. The present 2 experiments contrasted these 2 types of characteristics to determine their roles in the segmentation of speech. Ss in Exp I were 32 normal-hearing adults; Ss in Exp II were 16 normal-hearing and 16 profoundly deaf adults. Segmentation of spoken sentences appeared to require both prosodic and syntactic cues. The tendency for the perception of interrupting stimuli to cluster was considerably greater at boundaries that were marked by both syntactic and prosodic cues than at those marked by intonation or syntax alone. Although prosodic structure must reinforce syntactic structure to produce maximum segmental effects, it was not essential that these prosodic cues be auditory. Ss with normal hearing appeared to require some auditory cue to intonation boundaries to achieve significant perceptual migration of interrupting stimuli, but deaf Ss were able to use, through vision, durational correlates of the melodic pattern to segment the speech signal. (23 ref) (PsycInfo Database Record (c) 2023 APA, all rights reserved)","HOLDER: American Psychological Association
YEAR: 1978",Journal of Experimental Psychology: Human Perception and Performance,4,2,273-283,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1037%2f0096-1523.4.2.273
56,Ovid Technologies,APA PsycInfo,1984-23609-001,The oral speech intelligibility of hearing-impaired talkers.DP  - Aug 1983,,1983,,"Monsen, Randall B",,"Journal of Speech & Hearing Disorders. Vol.48,(3), 1983, pp. 286-296.",Aug,,"Recordings were made of 10 hearing-impaired adolescents (aged 11 yrs 7 mo to 15 yrs 3 mo) speaking sentences of systematically different phonologic and syntactic structure. Tapes containing these sentences were played to 19 experienced and 25 inexperienced listeners in different conditions: in the absence vs the presence of a verbal context; by auditory vs audiovisual presentation; and with 1 vs 2 presentations of each sentence token. The responses of the listeners were scored and averaged for each S, condition, and type of sentence. Significant differences were observed between (1) simple sentences and those complicated either by consonant clusters, polysyllabic words, or complex syntax; (2) experienced and inexperienced listeners; (3) sentences in and out of context; and (4) sentences heard and seen as opposed to merely heard. The results are discussed with reference to measurement of the intelligibility of the speech of hearing-impaired individuals. (15 ref) (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Journal of Speech & Hearing Disorders,48,3,286-296,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1044%2fjshd.4803.286
57,Ovid Technologies,APA PsycInfo,1981-10732-001,Consonant similarity judgments by normal and hearing-impaired listeners.DP  - Mar 1980,,1980,,"Walden, Brian E

Montgomery, Allen A

Prosek, Robert A

Schwartz, Daniel M",,"Journal of Speech & Hearing Research. Vol.23,(1), 1980, pp. 162-184.",Mar,"Journal of Speech, Language, and Hearing Research","Attempted to identify listener strategies or perceptual modes that might be adopted by hearing-impaired listeners when making similarity judgments among pairs of speech sounds. An attempt was also made to describe the relationship between similarity judgments and auditory confusions for such listeners. 15 21-45 yr old Ss (5 normal hearing, 5 with bilateral acquired hearing loss, and 5 with congenital hearing loss) provided similarity ratings and recognition responses to consonant pairs. Resulting similarity judgments were organized into a variety of similarity matrices and analyzed, using multidimensional scaling, hierarchical clustering, and traditional descriptive and interpretative statistics. The analyses of the similarity ratings between consonants showed that hearing-impaired Ss applied phonemic labels to the stimuli and based their ratings on these labels rather than on the unlabeled acoustic characteristics of the speech sounds. Analysis of the recognition data indicated that those consonants that were most confused were not necessarily the most conceptually similar to the listener. (36 ref) (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Journal of Speech & Hearing Research,23,1,162-184,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1044%2fjshr.2301.162
58,Ovid Technologies,APA PsycInfo,1975-03482-001,A spondee recognition test for young hearing-impaired children.DP  - Aug 1974,,1974,,"Cramer, Kathryn D

Eber, Norman P",,"Journal of Speech & Hearing Disorders. Vol.39,(3), 1974, pp. 304-311.",Aug,,"10 spondaic words recorded on Language Master cards were presented monaurally through insert receivers to 58 5-9 yr old hearing-impaired children to evaluate their ability to recognize familiar speech material. Ss were tested individually until their performance stabilized-which required from 4 to 10 sessions. They indicated their responses by pointing to labeled picture cards. Spondee recognition scores were bimodally distributed, with clusters of scores of 0-65% and 66-100%, respectively. In general, pure-tone averages better than 93 db HTL (hearing-threshold level) were associated with spondee scores from 66 to 100%, while pure-tone averages poorer than 103 db HTL corresponded to spondee scores from 0 to 65%. No close relation between pure-tone thresholds and spondee recognition scores was found for average hearing levels between 93 and 103 db. Recognition scores varied as a function of repeated testing in 3 general ways: stable performance, steadily improving performance, or inconsistent performance. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",,Journal of Speech & Hearing Disorders,39,3,304-311,Click here for full text options,SFX,,,,,https://ovidsp.ovid.com/ovidweb.cgi?T=JS&CSC=Y&NEWS=N&PAGE=fulltext&D=psyc2&DO=10.1044%2fjshd.3903.304