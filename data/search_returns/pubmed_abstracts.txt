1. Cochrane Database Syst Rev. 2017 Jul 7;7(7):CD006396. doi: 
10.1002/14651858.CD006396.pub4.

Interventions to prevent occupational noise-induced hearing loss.

Tikka C(1), Verbeek JH, Kateman E, Morata TC, Dreschler WA, Ferrite S.

Author information:
(1)Cochrane Work Review Group, Finnish Institute of Occupational Health, PO Box 
310, Kuopio, Finland, 70101.

Update of
    Cochrane Database Syst Rev. 2012 Oct 17;10:CD006396.

BACKGROUND: This is the second update of a Cochrane Review originally published 
in 2009. Millions of workers worldwide are exposed to noise levels that increase 
their risk of hearing disorders. There is uncertainty about the effectiveness of 
hearing loss prevention interventions.
OBJECTIVES: To assess the effectiveness of non-pharmaceutical interventions for 
preventing occupational noise exposure or occupational hearing loss compared to 
no intervention or alternative interventions.
SEARCH METHODS: We searched the CENTRAL; PubMed; Embase; CINAHL; Web of Science; 
BIOSIS Previews; Cambridge Scientific Abstracts; and OSH UPDATE to 3 October 
2016.
SELECTION CRITERIA: We included randomised controlled trials (RCT), controlled 
before-after studies (CBA) and interrupted time-series (ITS) of non-clinical 
interventions under field conditions among workers to prevent or reduce noise 
exposure and hearing loss. We also collected uncontrolled case studies of 
engineering controls about the effect on noise exposure.
DATA COLLECTION AND ANALYSIS: Two authors independently assessed study 
eligibility and risk of bias and extracted data. We categorised interventions as 
engineering controls, administrative controls, personal hearing protection 
devices, and hearing surveillance.
MAIN RESULTS: We included 29 studies. One study evaluated legislation to reduce 
noise exposure in a 12-year time-series analysis but there were no controlled 
studies on engineering controls for noise exposure. Eleven studies with 3725 
participants evaluated effects of personal hearing protection devices and 17 
studies with 84,028 participants evaluated effects of hearing loss prevention 
programmes (HLPPs). Effects on noise exposure Engineering interventions 
following legislationOne ITS study found that new legislation in the mining 
industry reduced the median personal noise exposure dose in underground coal 
mining by 27.7 percentage points (95% confidence interval (CI) -36.1 to -19.3 
percentage points) immediately after the implementation of stricter legislation. 
This roughly translates to a 4.5 dB(A) decrease in noise level. The intervention 
was associated with a favourable but statistically non-significant downward 
trend in time of the noise dose of -2.1 percentage points per year (95% CI -4.9 
to 0.7, 4 year follow-up, very low-quality evidence). Engineering intervention 
case studiesWe found 12 studies that described 107 uncontrolled case studies of 
immediate reductions in noise levels of machinery ranging from 11.1 to 19.7 
dB(A) as a result of purchasing new equipment, segregating noise sources or 
installing panels or curtains around sources. However, the studies lacked 
long-term follow-up and dose measurements of workers, and we did not use these 
studies for our conclusions. Hearing protection devicesIn general hearing 
protection devices reduced noise exposure on average by about 20 dB(A) in one 
RCT and three CBAs (57 participants, low-quality evidence). Two RCTs showed 
that, with instructions for insertion, the attenuation of noise by earplugs was 
8.59 dB better (95% CI 6.92 dB to 10.25 dB) compared to no instruction (2 RCTs, 
140 participants, moderate-quality evidence). Administrative controls: 
information and noise exposure feedbackOn-site training sessions did not have an 
effect on personal noise-exposure levels compared to information only in one 
cluster-RCT after four months' follow-up (mean difference (MD) 0.14 dB; 95% CI 
-2.66 to 2.38). Another arm of the same study found that personal noise exposure 
information had no effect on noise levels (MD 0.30 dB(A), 95% CI -2.31 to 2.91) 
compared to no such information (176 participants, low-quality evidence). 
Effects on hearing loss Hearing protection devicesIn two studies the authors 
compared the effect of different devices on temporary threshold shifts at 
short-term follow-up but reported insufficient data for analysis. In two CBA 
studies the authors found no difference in hearing loss from noise exposure 
above 89 dB(A) between muffs and earplugs at long-term follow-up (OR 0.8, 95% CI 
0.63 to 1.03 ), very low-quality evidence). Authors of another CBA study found 
that wearing hearing protection more often resulted in less hearing loss at very 
long-term follow-up (very low-quality evidence). Combination of interventions: 
hearing loss prevention programmesOne cluster-RCT found no difference in hearing 
loss at three- or 16-year follow-up between an intensive HLPP for agricultural 
students and audiometry only. One CBA study found no reduction of the rate of 
hearing loss (MD -0.82 dB per year (95% CI -1.86 to 0.22) for a HLPP that 
provided regular personal noise exposure information compared to a programme 
without this information.There was very-low-quality evidence in four very 
long-term studies, that better use of hearing protection devices as part of a 
HLPP decreased the risk of hearing loss compared to less well used hearing 
protection in HLPPs (OR 0.40, 95% CI 0.23 to 0.69). Other aspects of the HLPP 
such as training and education of workers or engineering controls did not show a 
similar effect.In three long-term CBA studies, workers in a HLPP had a 
statistically non-significant 1.8 dB (95% CI -0.6 to 4.2) greater hearing loss 
at 4 kHz than non-exposed workers and the confidence interval includes the 4.2 
dB which is the level of hearing loss resulting from 5 years of exposure to 85 
dB(A). In addition, of three other CBA studies that could not be included in the 
meta-analysis, two showed an increased risk of hearing loss in spite of the 
protection of a HLPP compared to non-exposed workers and one CBA did not.
AUTHORS' CONCLUSIONS: There is very low-quality evidence that implementation of 
stricter legislation can reduce noise levels in workplaces. Controlled studies 
of other engineering control interventions in the field have not been conducted. 
There is moderate-quality evidence that training of proper insertion of earplugs 
significantly reduces noise exposure at short-term follow-up but long-term 
follow-up is still needed.There is very low-quality evidence that the better use 
of hearing protection devices as part of HLPPs reduces the risk of hearing loss, 
whereas for other programme components of HLPPs we did not find such an effect. 
The absence of conclusive evidence should not be interpreted as evidence of lack 
of effectiveness. Rather, it means that further research is very likely to have 
an important impact.

DOI: 10.1002/14651858.CD006396.pub4
PMCID: PMC6353150
PMID: 28685503 [Indexed for MEDLINE]

Conflict of interest statement: Christina Tikka: None known. Jos Verbeek: None 
known. Erik Kateman: None known. Thais Morata: None known. Wouter Dreschler: 
None known. Silvia Ferrite: None known.


2. Ear Hear. 2019 Jul/Aug;40(4):918-926. doi: 10.1097/AUD.0000000000000669.

Online Machine Learning Audiometry.

Barbour DL(1), Howard RT(1)(2), Song XD(1), Metzger N(1), Sukesan KA(1)(3), 
DiLorenzo JC(1)(3), Snyder BRD(1), Chen JY(1), Degen EA(1), Buchbinder JM(1)(2), 
Heisey KL(1).

Author information:
(1)Laboratory of Sensory Neuroscience and Neuroengineering, Department of 
Biomedical Engineering, Washington University in St. Louis, Missouri, USA.
(2)Program in Audiology and Communication Sciences, Department of 
Otolaryngology, Washington University School of Medicine, St. Louis, Missouri, 
USA.
(3)Department of Computer Science and Engineering, Washington University in St. 
Louis, St. Louis, Missouri, USA.

OBJECTIVES: A confluence of recent developments in cloud computing, real-time 
web audio and machine learning psychometric function estimation has made wide 
dissemination of sophisticated turn-key audiometric assessments possible. The 
authors have combined these capabilities into an online (i.e., web-based) 
pure-tone audiogram estimator intended to empower researchers and clinicians 
with advanced hearing tests without the need for custom programming or special 
hardware. The objective of this study was to assess the accuracy and reliability 
of this new online machine learning audiogram method relative to a commonly used 
hearing threshold estimation technique also implemented online for the first 
time in the same platform.
DESIGN: The authors performed air conduction pure-tone audiometry on 21 
participants between the ages of 19 and 79 years (mean 41, SD 21) exhibiting a 
wide range of hearing abilities. For each ear, two repetitions of online machine 
learning audiogram estimation and two repetitions of online modified 
Hughson-Westlake ascending-descending audiogram estimation were acquired by an 
audiologist using the online software tools. The estimated hearing thresholds of 
these two techniques were compared at standard audiogram frequencies (i.e., 
0.25, 0.5, 1, 2, 4, 8 kHz).
RESULTS: The two threshold estimation methods delivered very similar threshold 
estimates at standard audiogram frequencies. Specifically, the mean absolute 
difference between threshold estimates was 3.24 ± 5.15 dB. The mean absolute 
differences between repeated measurements of the online machine learning 
procedure and between repeated measurements of the Hughson-Westlake procedure 
were 2.85 ± 6.57 dB and 1.88 ± 3.56 dB, respectively. The machine learning 
method generated estimates of both threshold and spread (i.e., the inverse of 
psychometric slope) continuously across the entire frequency range tested from 
fewer samples on average than the modified Hughson-Westlake procedure required 
to estimate six discrete thresholds.
CONCLUSIONS: Online machine learning audiogram estimation in its current form 
provides all the information of conventional threshold audiometry with similar 
accuracy and reliability in less time. More importantly, however, this method 
provides additional audiogram details not provided by other methods. This 
standardized platform can be readily extended to bone conduction, masking, 
spectrotemporal modulation, speech perception, etc., unifying audiometric 
testing into a single comprehensive procedure efficient enough to become part of 
the standard audiologic workup.

DOI: 10.1097/AUD.0000000000000669
PMCID: PMC6476703
PMID: 30358656 [Indexed for MEDLINE]


3. Signal Transduct Target Ther. 2022 Mar 14;7(1):79. doi: 
10.1038/s41392-022-00893-4.

Preventing autosomal-dominant hearing loss in Bth mice with CRISPR/CasRx-based 
RNA editing.

Zheng Z(#)(1)(2)(3), Li G(#)(4)(5), Cui C(#)(1)(2)(3), Wang F(1)(2)(3), Wang 
X(6), Xu Z(1)(2)(3), Guo H(1)(2)(3), Chen Y(1)(2)(3), Tang H(1)(2)(3), Wang 
D(1)(2)(3), Huang M(7)(8), Chen ZY(7)(8), Huang X(9)(10), Li H(1)(2)(3)(11), Li 
GL(12)(13)(14), Hu X(15)(16), Shu Y(17)(18)(19).

Author information:
(1)ENT Institute and Department of Otorhinolaryngology, Eye & ENT Hospital, 
State Key Laboratory of Medical Neurobiology and MOE Frontiers Center for Brain 
Science, Fudan University, Shanghai, 200031, China.
(2)Institutes of Biomedical Sciences, Fudan University, Shanghai, 200032, China.
(3)NHC Key Laboratory of Hearing Medicine (Fudan University), Shanghai, 200032, 
China.
(4)State Key Laboratory of Agrobiotechnology, China Agricultural University, 
Beijing, 100193, China.
(5)College of Biological Sciences, China Agricultural University, Beijing, 
100193, China.
(6)School of Life Science and Technology, Southeast University, Nanjing, 210096, 
China.
(7)Department of Otolaryngology-Head and Neck Surgery, Graduate Program in 
Speech and Hearing Bioscience and Technology and Program in Neuroscience, 
Harvard Medical School, Boston, MA, 02115, USA.
(8)Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston, MA, 
02114, USA.
(9)School of Life Science and Technology, ShanghaiTech University, Shanghai, 
200031, China.
(10)CAS Center for Excellence in Molecular Cell Science, Shanghai Institute of 
Biochemistry and Cell Biology, Chinese Academy of Sciences, University of 
Chinese Academy of Sciences, Shanghai, 200031, China.
(11)Institutes of Brain Science and the Collaborative Innovation Center for 
Brain Science, Fudan University, Shanghai, 200031, China.
(12)ENT Institute and Department of Otorhinolaryngology, Eye & ENT Hospital, 
State Key Laboratory of Medical Neurobiology and MOE Frontiers Center for Brain 
Science, Fudan University, Shanghai, 200031, China. genglin.li@fdeent.org.
(13)Institutes of Biomedical Sciences, Fudan University, Shanghai, 200032, 
China. genglin.li@fdeent.org.
(14)NHC Key Laboratory of Hearing Medicine (Fudan University), Shanghai, 200032, 
China. genglin.li@fdeent.org.
(15)State Key Laboratory of Agrobiotechnology, China Agricultural University, 
Beijing, 100193, China. huxx@cau.edu.cn.
(16)College of Biological Sciences, China Agricultural University, Beijing, 
100193, China. huxx@cau.edu.cn.
(17)ENT Institute and Department of Otorhinolaryngology, Eye & ENT Hospital, 
State Key Laboratory of Medical Neurobiology and MOE Frontiers Center for Brain 
Science, Fudan University, Shanghai, 200031, China. yilai_shu@fudan.edu.cn.
(18)Institutes of Biomedical Sciences, Fudan University, Shanghai, 200032, 
China. yilai_shu@fudan.edu.cn.
(19)NHC Key Laboratory of Hearing Medicine (Fudan University), Shanghai, 200032, 
China. yilai_shu@fudan.edu.cn.
(#)Contributed equally

CRISPR/RfxCas13d (CasRx) editing system can specifically and precisely cleave 
single-strand RNAs, which is a promising treatment for various disorders by 
downregulation of related gene expression. Here, we tested this RNA-editing 
approach on Beethoven (Bth) mice, an animal model for human DFNA36 due to a 
point mutation in Tmc1. We first screened 30 sgRNAs in cell cultures and found 
that CasRx with sgRNA3 reduced the Tmc1Bth transcript by 90.8%, and the Tmc1 
wild type transcript (Tmc1+) by 44.3%. We then injected a newly developed AAV 
vector (AAV-PHP.eB) based CasRx into the inner ears of neonatal Bth mice, and we 
found that Tmc1Bth was reduced by 70.2% in 2 weeks with few off-target effects 
in the whole transcriptome. Consistently, we found improved hair cell survival, 
rescued hair bundle degeneration, and reduced mechanoelectrical transduction 
current. Importantly, the hearing performance, measured in both ABR and DPOAE 
thresholds, was improved significantly in all ages over 8 weeks. We, therefore, 
have validated the CRISPR/CasRx-based RNA editing strategy in treating 
autosomal-dominant hearing loss, paving way for its further application in many 
other hereditary diseases in hearing and beyond.

© 2022. The Author(s).

DOI: 10.1038/s41392-022-00893-4
PMCID: PMC8918553
PMID: 35283480 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


4. J Med Internet Res. 2022 Feb 2;24(2):e32581. doi: 10.2196/32581.

Digital Approaches to Automated and Machine Learning Assessments of Hearing: 
Scoping Review.

Wasmann JW(#)(1), Pragt L(#)(1), Eikelboom R(2)(3)(4), Swanepoel W(2)(3)(4).

Author information:
(1)Department of Otorhinolaryngology, Donders Institute for Brain, Cognition and 
Behaviour, Radboud University Medical Centre, Nijmegen, Netherlands.
(2)Ear Science Institute Australia, Subiaco, Australia.
(3)Ear Sciences Centre, Medical School, The University of Western Australia, 
Perth, Australia.
(4)Department of Speech-Language Pathology and Audiology, University of 
Pretoria, Pretoria, South Africa.
(#)Contributed equally

BACKGROUND: Hearing loss affects 1 in 5 people worldwide and is estimated to 
affect 1 in 4 by 2050. Treatment relies on the accurate diagnosis of hearing 
loss; however, this first step is out of reach for >80% of those affected. 
Increasingly automated approaches are being developed for self-administered 
digital hearing assessments without the direct involvement of professionals.
OBJECTIVE: This study aims to provide an overview of digital approaches in 
automated and machine learning assessments of hearing using pure-tone audiometry 
and to focus on the aspects related to accuracy, reliability, and time 
efficiency. This review is an extension of a 2013 systematic review.
METHODS: A search across the electronic databases of PubMed, IEEE, and Web of 
Science was conducted to identify relevant reports from the peer-reviewed 
literature. Key information about each report's scope and details was collected 
to assess the commonalities among the approaches.
RESULTS: A total of 56 reports from 2012 to June 2021 were included. From this 
selection, 27 unique automated approaches were identified. Machine learning 
approaches require fewer trials than conventional threshold-seeking approaches, 
and personal digital devices make assessments more affordable and accessible. 
Validity can be enhanced using digital technologies for quality surveillance, 
including noise monitoring and detecting inconclusive results.
CONCLUSIONS: In the past 10 years, an increasing number of automated approaches 
have reported similar accuracy, reliability, and time efficiency as manual 
hearing assessments. New developments, including machine learning approaches, 
offer features, versatility, and cost-effectiveness beyond manual audiometry. 
Used within identified limitations, automated assessments using digital devices 
can support task-shifting, self-care, telehealth, and clinical care pathways.

©Jan-Willem Wasmann, Leontien Pragt, Robert Eikelboom, De Wet Swanepoel. 
Originally published in the Journal of Medical Internet Research 
(https://www.jmir.org), 02.02.2022.

DOI: 10.2196/32581
PMCID: PMC8851345
PMID: 34919056 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: DWS has a relationship 
with the hearX Group (Pty) Ltd, which includes equity, consulting, and potential 
royalties. DWS holds a patent for smartphone-based audiometry as an inventor.


5. Neurobiol Aging. 2022 Mar;111:1-13. doi: 10.1016/j.neurobiolaging.2021.09.024. 
Epub 2021 Nov 14.

Cross-modal connectivity effects in age-related hearing loss.

Ponticorvo S(1), Manara R(2), Cassandro E(3), Canna A(4), Scarpa A(3), Troisi 
D(3), Cassandro C(5), Cuoco S(3), Cappiello A(3), Pellecchia MT(3), Salle FD(3), 
Esposito F(6).

Author information:
(1)Department of Medicine, Surgery and Dentistry, Scuola Medica Salernitana, 
University of Salerno, Baronissi, Italy.
(2)Department of Medicine, Surgery and Dentistry, Scuola Medica Salernitana, 
University of Salerno, Baronissi, Italy; Department of Neuroscience, University 
of Padova, Padova, Italy.
(3)Department of Medicine, Surgery and Dentistry, Scuola Medica Salernitana, 
University of Salerno, Baronissi, Italy; University Hospital "San Giovanni di 
Dio e Ruggi D'Aragona", Scuola Medica Salernitana, Salerno, Italy.
(4)Department of Advanced Medical and Surgical Sciences, University of Campania 
"Luigi Vanvitelli", Napoli, Italy.
(5)University Hospital "San Giovanni di Dio e Ruggi D'Aragona", Scuola Medica 
Salernitana, Salerno, Italy.
(6)Department of Advanced Medical and Surgical Sciences, University of Campania 
"Luigi Vanvitelli", Napoli, Italy. Electronic address: 
fabrizio.esposito@unicampania.it.

Age-related sensorineural hearing loss (HL) leads to localized brain changes in 
the primary auditory cortex, long-range functional alterations, and is 
considered a risk factor for dementia. Nonhuman studies have repeatedly 
highlighted cross-modal brain plasticity in sensorial brain networks other than 
those primarily involved in the peripheral damage, thus in this study, the 
possible cortical alterations associated with HL have been analyzed using a 
whole-brain multimodal connectomic approach. Fifty-two HL and 30 normal hearing 
participants were examined in a 3T MRI study along with audiological and 
neurological assessments. Between-regions functional connectivity and 
whole-brain probabilistic tractography were calculated in a connectome-based 
manner and graph theory was used to obtain low-dimensional features for the 
analysis of brain connectivity at global and local levels. The HL condition was 
associated with a different functional organization of the visual subnetwork as 
revealed by a significant increase in global efficiency, density, and clustering 
coefficient. These functional effects were mirrored by similar (but more subtle) 
structural effects suggesting that a functional repurposing of visual cortical 
centers occurs to compensate for age-related loss of hearing abilities.

Copyright © 2021 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neurobiolaging.2021.09.024
PMID: 34915240 [Indexed for MEDLINE]

Conflict of interest statement: Disclosure statement The authors have no actual 
or potential conflicts of interest.


6. Hear Res. 2023 Nov;439:108894. doi: 10.1016/j.heares.2023.108894. Epub 2023 Oct 
5.

Genetic analysis of potential biomarkers and therapeutic targets in age-related 
hearing loss.

Cheng Y(1), Chen W(2), Xu J(1), Liu H(1), Chen T(3), Hu J(4).

Author information:
(1)Department of Neurology, Peking University Shenzhen Hospital, Shenzhen, 
China.
(2)Department of Neurosurgery, Peking University Shenzhen Hospital, Shenzhen, 
China.
(3)Department of Neurology, Shenzhen Second People's Hospital, Shenzhen, China.
(4)Department of Neurology, Peking University Shenzhen Hospital, Shenzhen, 
China. Electronic address: dochj@163.com.

Age-related hearing loss (ARHL) or presbycusis is the phenomenon of hearing loss 
due to the aging of auditory organs with age. It seriously affects the cognitive 
function and quality of life of the elderly. This study is based on 
comprehensive bioinformatic and machine learning methods to identify the 
critical genes of ARHL and explore its therapy targets and pathological 
mechanisms. The ARHL and normal samples were from GSE49543 datasets of the Gene 
Expression Omnibus (GEO) database. Weighted gene co-expression network analysis 
(WGCNA) was applied to obtain significant modules. The Limma R-package was used 
to identify differentially expressed genes (DEGs). The 15 common genes of the 
practical module and DEGs were screened. Functional enrichment analysis 
suggested that these genes were mainly associated with inflammation, immune 
response, and infection. Cytoscape software created the protein-protein 
interaction (PPI) layouts and cytoHubba, support vector machine-recursive 
feature elimination (SVM-RFE), and random forests (RF) algorithms screened hub 
genes. After validating the hub gene expressions in GSE6045 and GSE154833 
datasets, Clec4n, Mpeg1, and Fcgr3 are highly expressed in ARHL and have higher 
diagnostic efficacy for ARHL, so they were identified as hub genes. In 
conclusion, Clec4n, Mpeg1, and Fcgr3 play essential roles in developing ARHL, 
and they might become vital targets in ARHL diagnosis and anti-inflammatory 
therapy.

Copyright © 2023. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2023.108894
PMID: 37844444 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that the research was conducted without any commercial or financial 
relationships that could be construed as a potential conflict of interest.


7. J Acoust Soc Am. 2023 May 1;153(5):2751. doi: 10.1121/10.0019341.

Progress made in the efficacy and viability of deep-learning-based noise 
reduction.

Healy EW(1), Johnson EM(1), Pandey A(2), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, and Center for Cognitive and Brain 
Sciences, The Ohio State University, Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, and Center for Cognitive and 
Brain Sciences, The Ohio State University, Columbus, Ohio 43210, USA.

Recent years have brought considerable advances to our ability to increase 
intelligibility through deep-learning-based noise reduction, especially for 
hearing-impaired (HI) listeners. In this study, intelligibility improvements 
resulting from a current algorithm are assessed. These benefits are compared to 
those resulting from the initial demonstration of deep-learning-based noise 
reduction for HI listeners ten years ago in Healy, Yoho, Wang, and Wang [(2013). 
J. Acoust. Soc. Am. 134, 3029-3038]. The stimuli and procedures were broadly 
similar across studies. However, whereas the initial study involved highly 
matched training and test conditions, as well as non-causal operation, 
preventing its ability to operate in the real world, the current attentive 
recurrent network employed different noise types, talkers, and speech corpora 
for training versus test, as required for generalization, and it was fully 
causal, as required for real-time operation. Significant intelligibility benefit 
was observed in every condition, which averaged 51% points across conditions for 
HI listeners. Further, benefit was comparable to that obtained in the initial 
demonstration, despite the considerable additional demands placed on the current 
algorithm. The retention of large benefit despite the systematic removal of 
various constraints as required for real-world operation reflects the 
substantial advances made to deep-learning-based noise reduction.

© 2023 Acoustical Society of America.

DOI: 10.1121/10.0019341
PMCID: PMC10159658
PMID: 37133814 [Indexed for MEDLINE]


8. EBioMedicine. 2021 Jan;63:103171. doi: 10.1016/j.ebiom.2020.103171. Epub 2021 
Jan 7.

Understanding and treating paediatric hearing impairment.

Wrobel C(1), Zafeiriou MP(2), Moser T(3).

Author information:
(1)Department of Otolaryngology and InnerEarLab, University Medical Center 
Göttingen, 37099 Göttingen, Germany; Multiscale Bioimaging Cluster of Excellence 
(MBExC), University of Göttingen, Germany.
(2)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
Germany; Institute of Pharmacology and Toxicology, University Medical Center, 
37075 Göttingen, Germany.
(3)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
Germany; Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany. Electronic address: tmoser@gwdg.de.

Sensorineural hearing impairment is the most frequent form of hearing impairment 
affecting 1-2 in 1000 newborns and another 1 in 1000 adolescents. More than 50% 
of congenital hearing impairment is of genetic origin and some forms of 
monogenic deafness are likely targets for future gene therapy. Good progress has 
been made in clinical phenotyping, genetic diagnostics, and counselling. Disease 
modelling, e.g. in transgenic mice, has helped elucidate disease mechanisms 
underlying genetic hearing impairment and informed clinical phenotyping in 
recent years. Clinical management of paediatric hearing impairment involves 
hearing aids, cochlear or brainstem implants, signal-to-noise improvement in 
educational settings, speech therapy, and sign language. Cochlear implants, for 
example, have much improved the situation of profoundly hearing impaired and 
deaf children. Nonetheless there remains a major unmet clinical need for 
improving hearing restoration. Preclinical studies promise that we will witness 
clinical trials on gene therapy and a next generation of cochlear implants 
during the coming decade. Moreover, progress in generating sensory hair cells 
and neurons from stem cells spurs disease modelling, drug screening, and 
regenerative approaches. This review briefly summarizes the pathophysiology of 
paediatric hearing impairment and provides an update on the current preclinical 
development of innovative approaches toward improved hearing restoration.

Copyright © 2020 The Author(s). Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ebiom.2020.103171
PMCID: PMC7808910
PMID: 33422987 [Indexed for MEDLINE]

Conflict of interest statement: Tobias Moser is co-founder of OptoGenTech 
company. No conflict of interest for C.W. and M.P.Z.


9. Trends Hear. 2018 Jan-Dec;22:2331216518776817. doi: 10.1177/2331216518776817.

Application of Data Mining to "Big Data" Acquired in Audiology: Principles and 
Potential.

Mellor JC(1), Stone MA(2)(3), Keane J(1)(4).

Author information:
(1)1 School of Computer Science, University of Manchester, UK.
(2)2 Manchester Centre for Audiology and Deafness, University of Manchester, UK.
(3)3 Manchester Academic Health Sciences Centre, University of Manchester, UK.
(4)4 Manchester Institute of Biotechnology, University of Manchester, UK.

Comment in
    10.1177/2331216518773632.

The ubiquity and cheapness of miniature low-power sensors, digital processing, 
and large amounts of storage contained in small packages has heralded the 
ability to acquire large amounts of data about systems during their course of 
operation. The size and complexity of the data sets so generated have 
colloquially been labeled "big data." The computer science field of "data 
mining" has arisen with the purpose of extracting meaning from such data, 
expressly looking for patterns that not only link historic observations but also 
predict future behavior. This overview article considers the process, 
techniques, and interpretation of data mining, with specific focus on its 
application in audiology. Modern hearing instruments contain data-logging 
technology to record data separate from the audio stream, such as the acoustic 
environments in which the device was being used and how the signal processing 
was consequently operating. Combined with details about the patient, such as the 
audiogram, the variety of data generated lends itself to a data mining approach. 
To date, reports of the use and interpretation of these data have been mostly 
constrained to questions such as looking for changes in patterns of daily use, 
or the degree and direction of volume control manipulation as the patient's 
experience with a hearing aid changes. In this, and an accompanying results 
paper, the practical applications of some data mining techniques are described 
as applied to a large data set of examples of real-world device usage, as 
supplied by a hearing aid manufacturer.

DOI: 10.1177/2331216518776817
PMCID: PMC6022814
PMID: 29848183 [Indexed for MEDLINE]


10. Int Arch Occup Environ Health. 2021 Jul;94(5):1097-1111. doi: 
10.1007/s00420-020-01648-w. Epub 2021 Jan 25.

Contributions and limitations of using machine learning to predict noise-induced 
hearing loss.

Chen F(#)(1), Cao Z(#)(2), Grais EM(1), Zhao F(3)(4).

Author information:
(1)Centre for Speech and Language Therapy and Hearing Science, Cardiff School of 
Sport and Health Sciences, Cardiff Metropolitan University, Cardiff, UK.
(2)Center for Rehabilitative Auditory Research, Guizhou Provincial People's 
Hospital, Guiyang, China.
(3)Centre for Speech and Language Therapy and Hearing Science, Cardiff School of 
Sport and Health Sciences, Cardiff Metropolitan University, Cardiff, UK. 
fzhao@cardiffmet.ac.uk.
(4)Department of Hearing and Speech Science, Xinhua College, Sun Yat-Sen 
University, Guangzhou, China. fzhao@cardiffmet.ac.uk.
(#)Contributed equally

PURPOSE: Noise-induced hearing loss (NIHL) is a global issue that impacts 
people's life and health. The current review aims to clarify the contributions 
and limitations of applying machine learning (ML) to predict NIHL by analyzing 
the performance of different ML techniques and the procedure of model 
construction.
METHODS: The authors searched PubMed, EMBASE and Scopus on November 26, 2020.
RESULTS: Eight studies were recruited in the current review following defined 
inclusion and exclusion criteria. Sample size in the selected studies ranged 
between 150 and 10,567. The most popular models were artificial neural networks 
(n = 4), random forests (n = 3) and support vector machines (n = 3). Features 
mostly correlated with NIHL and used in the models were: age (n = 6), duration 
of noise exposure (n = 5) and noise exposure level (n = 4). Five included 
studies used either split-sample validation (n = 3) or ten-fold cross-validation 
(n = 2). Assessment of accuracy ranged in value from 75.3% to 99% with a low 
prediction error/root-mean-square error in 3 studies. Only 2 studies measured 
discrimination risk using the receiver operating characteristic (ROC) curve 
and/or the area under ROC curve.
CONCLUSION: In spite of high accuracy and low prediction error of machine 
learning models, some improvement can be expected from larger sample sizes, 
multiple algorithm use, completed reports of model construction and 
the sufficient evaluation of calibration and discrimination risk.

DOI: 10.1007/s00420-020-01648-w
PMCID: PMC8238747
PMID: 33491101 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no conflict 
of interest.


11. Brain. 2023 Dec 1;146(12):4809-4825. doi: 10.1093/brain/awad255.

Predictive coding and stochastic resonance as fundamental principles of auditory 
phantom perception.

Schilling A(1)(2), Sedley W(3), Gerum R(2)(4), Metzner C(1), Tziridis K(1), 
Maier A(5), Schulze H(1), Zeng FG(6), Friston KJ(7), Krauss P(1)(2)(5).

Author information:
(1)Neuroscience Lab, University Hospital Erlangen, 91054 Erlangen, Germany.
(2)Cognitive Computational Neuroscience Group, University Erlangen-Nürnberg, 
91058 Erlangen, Germany.
(3)Translational and Clinical Research Institute, Newcastle University Medical 
School, Newcastle upon Tyne NE2 4HH, UK.
(4)Department of Physics and Astronomy and Center for Vision Research, York 
University, Toronto, ON M3J 1P3, Canada.
(5)Pattern Recognition Lab, University Erlangen-Nürnberg, 91058 Erlangen, 
Germany.
(6)Center for Hearing Research, Departments of Anatomy and Neurobiology, 
Biomedical Engineering, Cognitive Sciences, Otolaryngology-Head and Neck 
Surgery, University of California Irvine, Irvine, CA 92697, USA.
(7)Wellcome Centre for Human Neuroimaging, Institute of Neurology, University 
College London, London WC1N 3AR, UK.

Mechanistic insight is achieved only when experiments are employed to test 
formal or computational models. Furthermore, in analogy to lesion studies, 
phantom perception may serve as a vehicle to understand the fundamental 
processing principles underlying healthy auditory perception. With a special 
focus on tinnitus-as the prime example of auditory phantom perception-we review 
recent work at the intersection of artificial intelligence, psychology and 
neuroscience. In particular, we discuss why everyone with tinnitus suffers from 
(at least hidden) hearing loss, but not everyone with hearing loss suffers from 
tinnitus. We argue that intrinsic neural noise is generated and amplified along 
the auditory pathway as a compensatory mechanism to restore normal hearing based 
on adaptive stochastic resonance. The neural noise increase can then be 
misinterpreted as auditory input and perceived as tinnitus. This mechanism can 
be formalized in the Bayesian brain framework, where the percept (posterior) 
assimilates a prior prediction (brain's expectations) and likelihood (bottom-up 
neural signal). A higher mean and lower variance (i.e. enhanced precision) of 
the likelihood shifts the posterior, evincing a misinterpretation of sensory 
evidence, which may be further confounded by plastic changes in the brain that 
underwrite prior predictions. Hence, two fundamental processing principles 
provide the most explanatory power for the emergence of auditory phantom 
perceptions: predictive coding as a top-down and adaptive stochastic resonance 
as a complementary bottom-up mechanism. We conclude that both principles also 
play a crucial role in healthy auditory perception. Finally, in the context of 
neuroscience-inspired artificial intelligence, both processing principles may 
serve to improve contemporary machine learning techniques.

© The Author(s) 2023. Published by Oxford University Press on behalf of the 
Guarantors of Brain.

DOI: 10.1093/brain/awad255
PMCID: PMC10690027
PMID: 37503725 [Indexed for MEDLINE]

Conflict of interest statement: The authors report no competing interests.


12. Trends Hear. 2022 Jan-Dec;26:23312165221078707. doi: 10.1177/23312165221078707.

Self-motion with Hearing Impairment and (Directional) Hearing Aids.

Hendrikse MME(1), Eichler T(1), Hohmann V(1), Grimm G(1).

Author information:
(1)Auditory Signal Processing and Cluster of Excellence "Hearing4all", 
Department of Medical Physics and Acoustics, University of Oldenburg, Oldenburg, 
Germany.

When listening to a sound source in everyday situations, typical movement 
behavior is highly individual and may not result in the listener directly facing 
the sound source. Behavioral differences can affect the performance of 
directional algorithms in hearing aids, as was shown in previous work by using 
head movement trajectories of normal-hearing (NH) listeners in acoustic 
simulations for noise-suppression performance predictions. However, the movement 
behavior of hearing-impaired (HI) listeners with or without hearing aids may 
differ, and hearing-aid users might adapt their self-motion to improve the 
performance of directional algorithms. This work investigates the influence of 
hearing impairment on self-motion, and the interaction of hearing aids with 
self-motion. In order to do this, the self-motion of three HI participant 
groups----aided with an adaptive differential microphone (ADM), aided without 
ADM, and unaided-was measured and compared to previously measured self-motion 
data from younger and older NH participants. Self-motion was measured in virtual 
audiovisual environments (VEs) in the laboratory, and the signal-to-noise ratios 
(SNRs) and SNR improvement of the ADM resulting from the head movements of the 
participants were estimated using acoustic simulations. HI participants did 
almost all of the movement with their head and less with their eyes compared to 
NH participants, which led to a 0.3 dB increase in estimated SNR and to 
differences in estimated SNR improvement of the ADM. However, the self-motion of 
the HI participants aided with ADM was similar to that of other HI participants, 
indicating that the ADM did not cause listeners to adapt their self-motion.

DOI: 10.1177/23312165221078707
PMCID: PMC8966140
PMID: 35341403 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
author(s) declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


13. Int J Audiol. 2018 Jun;57(sup3):S1-S2. doi: 10.1080/14992027.2018.1426893. Epub 
2018 Jan 17.

Hearing aid technology: model-based concepts and assessment.

Kollmeier B(1).

Author information:
(1)a Medizinische Physik and Cluster of Excellence "Hearing4All" , Universität 
Oldenburg , Oldenburg , Germany.

DOI: 10.1080/14992027.2018.1426893
PMID: 29338464 [Indexed for MEDLINE]


14. Ear Hear. 2023 Sep-Oct 01;44(5):1240-1250. doi: 10.1097/AUD.0000000000001368. 
Epub 2023 Jun 8.

Prevalence of Childhood Hearing Loss in Rural Alaska.

Emmett SD(1)(2)(3)(4)(5), Platt A(2)(6), Gallo JJ(7)(8), Labrique AB(9), Wang 
NY(8), Inglis-Jenson M(4), Jenson CD(10), Hofstetter P(11), Hicks KL(12), Ross 
AA(1)(3), Egger JR(2), Robler SK(4)(10).

Author information:
(1)Department of Head and Neck Surgery and Communication Science, Duke 
University School of Medicine, Durham, North Carolina, USA.
(2)Duke Global Health Institute, Durham, North Carolina, USA.
(3)Center for Health Policy and Inequalities Research, Duke University, Durham, 
North Carolina, USA.
(4)Department of Otolaryngology-Head & Neck Surgery, University of Arkansas for 
Medical Sciences, Little Rock, Arkansas, USA.
(5)Department of Epidemiology, Fay W. Boozman College of Public Health, 
University of Arkansas for Medical Sciences, Little Rock, Arkansas, USA.
(6)Department of Biostatistics and Bioinformatics, Duke University, Durham, 
North Carolina, USA.
(7)Department of Mental Health, Johns Hopkins Bloomberg School of Public Health, 
Baltimore, Maryland, USA.
(8)Department of Medicine, Johns Hopkins University School of Medicine, 
Baltimore, Maryland, USA.
(9)Department of International Health, Johns Hopkins Bloomberg School of Public 
Health, Baltimore, Maryland, USA.
(10)Department of Audiology, Norton Sound Health Corporation, Nome, Alaska, USA.
(11)Petersburg Medical Center, Petersburg, Alaska, USA.
(12)Department of Otolaryngology-Head and Neck Surgery, University of North 
Carolina - Chapel Hill, Chapel Hill, North Carolina, USA.

OBJECTIVES: Childhood hearing loss has well-known lifelong consequences. Certain 
rural populations are at higher risk for infection-related hearing loss. For 
Alaska Native children, historical data on hearing loss prevalence suggest a 
higher burden of infection-related hearing loss, but updated prevalence data are 
urgently needed in this high-risk population.
DESIGN: Hearing data were collected as part of two school-based 
cluster-randomized trials in 15 communities in rural northwest Alaska over two 
academic years (2017-2019). All enrolled children from preschool to 12th grade 
were eligible. Pure-tone thresholds were obtained using standard audiometry and 
conditioned play when indicated. The analysis included the first available 
audiometric assessment for each child (n = 1634 participants, 3 to 21 years), 
except for the high-frequency analysis, which was limited to year 2 when higher 
frequencies were collected. Multiple imputation was used to quantify the 
prevalence of hearing loss in younger children, where missing data were more 
frequent due to the need for behavioral responses. Hearing loss in either ear 
was evaluated using both the former World Health Organization (WHO) definition 
(pure-tone average [PTA] > 25 dB) and the new WHO definition (PTA ≥ 20 dB), 
which was published after the study. Analyses with the new definition were 
limited to children 7 years and older due to incomplete data obtained on younger 
children at lower thresholds.
RESULTS: The overall prevalence of hearing loss (PTA > 25 dB; 0.5, 1, 2, 4 kHz) 
was 10.5% (95% confidence interval [CI], 8.9 to 12.1). Hearing loss was 
predominately mild (PTA >25 to 40 dB; 8.9%, 95% CI, 7.4 to 10.5). The prevalence 
of unilateral hearing loss was 7.7% (95% CI, 6.3 to 9.0). Conductive hearing 
loss (air-bone gap of ≥ 10 dB) was the most common hearing loss type (9.1%, 95% 
CI, 7.6 to 10.7). Stratified by age, hearing loss (PTA >25 dB) was more common 
in children 3 to 6 years (14.9%, 95% CI, 11.4 to 18.5) compared to children 7 
years and older (8.7%, 95% CI, 7.1 to 10.4). In children 7 years and older, the 
new WHO definition increased the prevalence of hearing loss to 23.4% (95% CI, 
21.0 to 25.8) compared to the former definition (8.7%, 95% CI, 7.1 to 10.4). 
Middle ear disease prevalence was 17.6% (95% CI, 15.7 to 19.4) and was higher in 
younger children (23.6%, 95% CI, 19.7 to 27.6) compared to older children 
(15.2%, 95% CI, 13.2 to 17.3). High-frequency hearing loss (4, 6, 8kHz) was 
present in 20.5% (95% CI, 18.4 to 22.7 [PTA >25 dB]) of all children and 22.8% 
(95% CI, 20.3 to 25.3 [PTA >25 dB]) and 29.7% (95% CI, 27.0 to 32.4 [PTA ≥ 20 
dB]) of children 7 years and older (limited to year 2).
CONCLUSIONS: This analysis represents the first prevalence study on childhood 
hearing loss in Alaska in over 60 years and is the largest cohort with hearing 
data ever collected in rural Alaska. Our results highlight that hearing loss 
continues to be common in rural Alaska Native children, with middle ear disease 
more prevalent in younger children and high-frequency hearing loss more 
prevalent with increasing age. Prevention efforts may benefit from managing 
hearing loss type by age. Lastly, continued research is needed on the impact of 
the new WHO definition of hearing loss on field studies.

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001368
PMCID: PMC10426776
PMID: 37287104 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


15. Trends Hear. 2022 Jan-Dec;26:23312165221143901. doi: 10.1177/23312165221143901.

Spatio-temporal Integration of Speech Reflections in Hearing-Impaired Listeners.

Rennies J(1)(2), Warzybok A(3)(2), Kollmeier B(1)(3)(2), Brand T(3)(2).

Author information:
(1)28439Fraunhofer Institute for Digital Media Technology IDMT, Project Group 
Hearing, Speech and Audio Technology, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)Medical Physics Group, Department für Medizinische Physik und Akustik, 
Oldenburg, Germany.

Speech recognition in rooms requires the temporal integration of reflections 
which arrive with a certain delay after the direct sound. It is commonly assumed 
that there is a certain temporal window of about 50-100 ms, during which 
reflections can be integrated with the direct sound, while later reflections are 
detrimental to speech intelligibility. This concept was challenged in a recent 
study by employing binaural room impulse responses (RIRs) with systematically 
varied interaural phase differences (IPDs) and amplitude of the direct sound and 
a variable number of reflections delayed by up to 200 ms. When amplitude or IPD 
favored late RIR components, normal-hearing (NH) listeners appeared to be 
capable of focusing on these components rather than on the precedent direct 
sound, which contrasted with the common concept of considering early RIR 
components as useful and late components as detrimental. The present study 
investigated speech intelligibility in the same conditions in hearing-impaired 
(HI) listeners. The data indicate that HI listeners were generally less able to 
"ignore" the direct sound than NH listeners, when the most useful information 
was confined to late RIR components. Some HI listeners showed a remarkable 
inability to integrate across multiple reflections and to optimally "shift" 
their temporal integration window, which was quite dissimilar to NH listeners. 
This effect was most pronounced in conditions requiring spatial and temporal 
integration and could provide new challenges for individual prediction models of 
binaural speech intelligibility.

DOI: 10.1177/23312165221143901
PMCID: PMC9772954
PMID: 36537084 [Indexed for MEDLINE]

Conflict of interest statement: The authors declared no potential conflicts of 
interest with respect to the research, authorship, and/or publication of this 
article.


16. Physiol Rev. 2020 Oct 1;100(4):1467-1525. doi: 10.1152/physrev.00035.2019. Epub 
2020 Mar 19.

Emerging Approaches for Restoration of Hearing and Vision.

Kleinlogel S(1), Vogl C(1), Jeschke M(1), Neef J(1), Moser T(1).

Author information:
(1)Institute for Physiology, University of Bern, Bern, Switzerland; 
Pre-Synaptogenesis and Intracellular Transport in Hair Cells Group, Institute 
for Auditory Neuroscience and InnerEarLab, University Medical Center Göttingen, 
Göttingen, Germany; Institute for Auditory Neuroscience and InnerEarLab, 
University Medical Center Göttingen, Göttingen, Germany; Collaborative Research 
Center 889, University of Göttingen, Göttingen, Germany; Cognitive Hearing in 
Primates Group, Auditory Neuroscience and Optogenetics Laboratory, Deutsches 
Primatenzentrum GmbH, Göttingen, Germany; Auditory Neuroscience and Optogenetics 
Laboratory, Deutsches Primatenzentrum GmbH, Göttingen, Germany; and Multiscale 
Bioimaging Cluster of Excellence (MBExC), University of Göttingen, Göttingen, 
Germany.

Impairments of vision and hearing are highly prevalent conditions limiting the 
quality of life and presenting a major socioeconomic burden. For a long time, 
retinal and cochlear disorders have remained intractable for causal therapies, 
with sensory rehabilitation limited to glasses, hearing aids, and electrical 
cochlear or retinal implants. Recently, the application of gene therapy and 
optogenetics to eye and ear has generated hope for a fundamental improvement of 
vision and hearing restoration. To date, one gene therapy for the restoration of 
vision has been approved, and ongoing clinical trials will broaden its 
application including gene replacement, genome editing, and regenerative 
approaches. Moreover, optogenetics, i.e., controlling the activity of cells by 
light, offers a more general alternative strategy. Over little more than a 
decade, optogenetic approaches have been developed and applied to better 
understand the function of biological systems, while protein engineers have 
identified and designed new opsin variants with desired physiological features. 
Considering potential clinical applications of optogenetics, the spotlight is on 
the sensory systems, particularly the eye and ear. Multiple efforts have been 
undertaken to restore lost or hampered function in the eye and ear. Optogenetic 
stimulation promises to overcome fundamental shortcomings of electrical 
stimulation, namely, poor spatial resolution and cellular specificity, and 
accordingly to deliver more detailed sensory information. This review aims to 
provide a comprehensive reference on current gene therapeutic and optogenetic 
research relevant to the restoration of hearing and vision. We will introduce 
gene-therapeutic approaches and discuss the biotechnological and optoelectronic 
aspects of optogenetic hearing and vision restoration.

DOI: 10.1152/physrev.00035.2019
PMID: 32191560 [Indexed for MEDLINE]


17. Ear Hear. 2021 July/Aug;42(4):982-989. doi: 10.1097/AUD.0000000000000993.

Predicting Depression From Hearing Loss Using Machine Learning.

Crowson MG(1)(2), Franck KH(1)(2), Rosella LC(3), Chan TCY(4).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Massachusetts Eye and 
Ear, Boston, Massachusetts, USA.
(2)Department of Otolaryngology-Head and Neck Surgery, Harvard Medical School, 
Boston, Massachusetts, USA.
(3)Dalla Lana School of Public Health, University of Toronto, Ontario, Canada.
(4)Department of Mechanical & Industrial Engineering, University of Toronto, 
Ontario, Canada.

OBJECTIVES: Hearing loss is the most common sensory loss in humans and carries 
an enhanced risk of depression. No prior studies have attempted a contemporary 
machine learning approach to predict depression using subjective and objective 
hearing loss predictors. The objective was to deploy supervised machine learning 
to predict scores on a validated depression scale using subjective and objective 
audiometric variables and other health determinant predictors.
DESIGN: A large predictor set of health determinants from the National Health 
and Nutrition Examination Survey 2015-2016 database was used to predict adults' 
scores on a validated instrument to screen for the presence and severity of 
depression (Patient Health Questionnaire-9 [PHQ-9]). After model training, the 
relative influence of individual predictors on depression scores was stratified 
and analyzed. Model prediction performance was determined by prediction error 
metrics.
RESULTS: The test set mean absolute error was 3.03 (95% confidence interval: 
2.91 to 3.14) and 2.55 (95% confidence interval: 2.48 to 2.62) on datasets with 
audiology-only predictors and all predictors, respectively, on the PHQ-9's 
27-point scale. Participants' self-reported frustration when talking to members 
of family or friends due to hearing loss was the fifth-most influential of all 
predictors. Of the top 10 most influential audiometric predictors, five were 
related to social contexts, two for significant noise exposure, two objective 
audiometric parameters, and one presence of bothersome tinnitus.
CONCLUSIONS: Machine learning algorithms can accurately predict PHQ-9 depression 
scale scores from National Health and Nutrition Examination Survey data. The 
most influential audiometric predictors of higher scores on a validated 
depression scale were social dynamics of hearing loss and not objective 
audiometric testing. Such models could be useful in predicting depression scale 
scores at the point-of-care in conjunction with a standard audiologic 
assessment.

Copyright © 2021 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000000993
PMID: 33577219 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


18. Hear Res. 2017 Jan;343:128-137. doi: 10.1016/j.heares.2016.07.005. Epub 2016 Jul 
26.

Cortical reorganization in postlingually deaf cochlear implant users: 
Intra-modal and cross-modal considerations.

Stropahl M(1), Chen LC(2), Debener S(2).

Author information:
(1)Neuropsychology Lab, Department of Psychology, European Medical School, Carl 
von Ossietzky University Oldenburg, Germany. Electronic address: 
maren.stropahl@uni-oldenburg.de.
(2)Neuropsychology Lab, Department of Psychology, European Medical School, Carl 
von Ossietzky University Oldenburg, Germany; Cluster of Excellence Hearing4all 
Oldenburg, Germany.

With the advances of cochlear implant (CI) technology, many deaf individuals can 
partially regain their hearing ability. However, there is a large variation in 
the level of recovery. Cortical changes induced by hearing deprivation and 
restoration with CIs have been thought to contribute to this variation. The 
current review aims to identify these cortical changes in postlingually deaf CI 
users and discusses their maladaptive or adaptive relationship to the CI 
outcome. Overall, intra-modal and cross-modal reorganization patterns have been 
identified in postlingually deaf CI users in visual and in auditory cortex. Even 
though cross-modal activation in auditory cortex is considered as maladaptive 
for speech recovery in CI users, a similar activation relates positively to lip 
reading skills. Furthermore, cross-modal activation of the visual cortex seems 
to be adaptive for speech recognition. Currently available evidence points to an 
involvement of further brain areas and suggests that a focus on the reversal of 
visual take-over of the auditory cortex may be too limited. Future 
investigations should consider expanded cortical as well as multi-sensory 
processing and capture different hierarchical processing steps. Furthermore, 
prospective longitudinal designs are needed to track the dynamics of cortical 
plasticity that takes place before and after implantation.

Copyright © 2016 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.07.005
PMID: 27473503 [Indexed for MEDLINE]


19. Int J Audiol. 2018 Jun;57(sup3):S3-S28. doi: 10.1080/14992027.2016.1256504. Epub 
2016 Dec 13.

Functionality of hearing aids: state-of-the-art and future model-based 
solutions.

Kollmeier B(1), Kiessling J(2).

Author information:
(1)a Medizinische Physik, Universität Oldenburg and Cluster of Excellence 
Hearing4all, Hörzentrum Oldenburg, HörTech gGmbH and Fraunhofer IDMT/HSA , 
Oldenburg , Germany and.
(2)b Funktionsbereich Audiologie, Justus-Liebig-Universität Gießen , Giessen , 
Germany.

A review about technical and perceptual factors in hearing aid technology, 
research and development is provided, covering current commercial solutions, 
underlying models of hearing loss for usage in hearing devices and emerging 
future technical solutions for hearing aid functionalities. A chain of 
techniques has provided incremental, but steady increases in user benefit, e.g. 
in the fields of hearing aid amplification, feedback suppression, dynamic 
compression, noise reduction and situation adaptation. The models describing the 
perceptual consequences of sensorineural hearing impairment describe the effects 
on the acoustical level, the neurosensory level and the cognitive level and 
provide the framework for compensatory (or even substitutional) functions of 
hearing aids in terms of the attenuation component, the distortion component and 
the neural component of the hearing loss. A major factor is the requirement of a 
strong individualisation of hearing aid solutions calling for an appropriate 
assessment of the different sensorineural components of a hearing loss, 
especially with respect to bilateral and binaural hearing aid solutions.

DOI: 10.1080/14992027.2016.1256504
PMID: 27951738 [Indexed for MEDLINE]


20. EMBO Mol Med. 2020 Apr 7;12(4):e11618. doi: 10.15252/emmm.201911618. Epub 2020 
Mar 30.

Towards the optical cochlear implant: optogenetic approaches for hearing 
restoration.

Dieter A(1)(2), Keppeler D(1), Moser T(1)(3)(4)(5).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Göttingen Graduate School for Neurosciences, Biophysics and Molecular 
Biosciences, University of Göttingen, Göttingen, Germany.
(3)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(4)Auditory Neuroscience Group, Max Planck Institute of Experimental Medicine, 
Göttingen, Germany.
(5)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, Göttingen, 
Germany.

Cochlear implants (CIs) are considered the most successful neuroprosthesis as 
they enable speech comprehension in the majority of half a million CI users 
suffering from sensorineural hearing loss. By electrically stimulating the 
auditory nerve, CIs constitute an interface re-connecting the brain and the 
auditory scene, providing the patient with information regarding the latter. 
However, since electric current is hard to focus in conductive environments such 
as the cochlea, the precision of electrical sound encoding-and thus quality of 
artificial hearing-is limited. Recently, optogenetic stimulation of the cochlea 
has been suggested as an alternative approach for hearing restoration. Cochlear 
optogenetics promises increased spectral selectivity of artificial sound 
encoding, hence improved hearing, as light can conveniently be confined in space 
to activate the auditory nerve within smaller tonotopic ranges. In this review, 
we discuss the latest experimental and technological developments of cochlear 
optogenetics and outline the remaining challenges on the way to clinical 
translation.

© 2020 The Authors. Published under the terms of the CC BY 4.0 license.

DOI: 10.15252/emmm.201911618
PMCID: PMC7136966
PMID: 32227585 [Indexed for MEDLINE]

Conflict of interest statement: D.K. and T.M. are co‐founders of the OptoGenTech 
company.


21. Cereb Cortex. 2023 May 24;33(11):7221-7236. doi: 10.1093/cercor/bhad033.

Brain plasticity and auditory spatial adaptation in patients with unilateral 
hearing loss.

Alzaher M(1)(2), Strelnikov K(2), Marx M(1)(2), Barone P(1).

Author information:
(1)Centre de Recherche Cerveau et Cognition, CNRS, Toulouse, 31300, France.
(2)Service ORL, CHU Toulouse, Toulouse, 31300, France.

Erratum in
    Cereb Cortex. 2023 Apr 25;33(9):5760.

The ability to localize sounds in patients with Unilateral Hearing Loss (UHL) is 
usually disrupted due to alteration in the integration of binaural cues. 
Nonetheless, some patients are able to compensate deficit using adaptive 
strategies. In this study, we explored the neural correlates underlying this 
adaptation. Twenty-one patients with UHL were separated into 3 groups using 
cluster analysis based on their binaural performance. The resulting clusters 
were referred to as better, moderate, and poorer performers cluster (BPC, MPC, 
and PPC). We measured the mismatch negativity (MMN) elicited by deviant sounds 
located at 10°, 20°, and 100° from a standard positioned at 50° ipsilateral to 
the deaf ear. The BPC exhibited significant MMN for all 3 deviants, similar to 
normal hearing (NH) subjects. In contrast, there was no significant MMN for 10° 
and 20° deviants for the PPC and for NH when one ear was plugged and muffed. 
Scalp distribution was maximal over central regions in BPC, while PPC showed 
more frontal MMN distribution. Thus, the BPC exhibited a contralateral 
activation pattern, similar to NH, while the PPC exhibited more symmetrical 
hemispheric activation. MMN can be used as a neural marker to reflect spatial 
adaptation in patients with UHL.

© The Author(s) 2023. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhad033
PMID: 36806394 [Indexed for MEDLINE]


22. Int J Audiol. 2018 Jun;57(sup3):S31-S42. doi: 10.1080/14992027.2018.1425554. 
Epub 2018 Jan 26.

Binaural model-based dynamic-range compression.

Ernst SMA(1), Kortlang S(1), Grimm G(1)(2), Bisitz T(2), Kollmeier B(1)(2), 
Ewert SD(1).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , 
Carl-von-Ossietzky Universität Oldenburg , Oldenburg , Germany and.
(2)b HörTech gGmbH , Oldenburg , Germany.

OBJECTIVE: Binaural cues such as interaural level differences (ILDs) are used to 
organise auditory perception and to segregate sound sources in complex 
acoustical environments. In bilaterally fitted hearing aids, dynamic-range 
compression operating independently at each ear potentially alters these ILDs, 
thus distorting binaural perception and sound source segregation.
DESIGN: A binaurally-linked model-based fast-acting dynamic compression 
algorithm designed to approximate the normal-hearing basilar membrane (BM) 
input-output function in hearing-impaired listeners is suggested. A multi-center 
evaluation in comparison with an alternative binaural and two bilateral fittings 
was performed to assess the effect of binaural synchronisation on (a) speech 
intelligibility and (b) perceived quality in realistic conditions.
STUDY SAMPLE: 30 and 12 hearing impaired (HI) listeners were aided individually 
with the algorithms for both experimental parts, respectively.
RESULTS: A small preference towards the proposed model-based algorithm in the 
direct quality comparison was found. However, no benefit of 
binaural-synchronisation regarding speech intelligibility was found, suggesting 
a dominant role of the better ear in all experimental conditions.
CONCLUSION: The suggested binaural synchronisation of compression algorithms 
showed a limited effect on the tested outcome measures, however, linking could 
be situationally beneficial to preserve a natural binaural perception of the 
acoustical environment.

DOI: 10.1080/14992027.2018.1425554
PMID: 29373937 [Indexed for MEDLINE]


23. Ear Hear. 2020 Nov/Dec;41(6):1692-1702. doi: 10.1097/AUD.0000000000000891.

Dynamically Masked Audiograms With Machine Learning Audiometry.

Heisey KL(1), Walker AM(1)(2), Xie K(1)(3), Abrams JM(1)(2), Barbour DL(1).

Author information:
(1)Department of Biomedical Engineering, Laboratory of Sensory Neuroscience and 
Neuroengineering, Washington University in St. Louis, St. Louis, Missouri, USA.
(2)Program in Audiology and Communication Sciences, Department of 
Otolaryngology, Washington University School of Medicine, St. Louis, Missouri, 
USA.
(3)Department of Computer Science and Engineering, Washington University in St. 
Louis, St. Louis, Missouri, USA.

OBJECTIVES: When one ear of an individual can hear significantly better than the 
other ear, evaluating the worse ear with loud probe tones may require delivering 
masking noise to the better ear to prevent the probe tones from inadvertently 
being heard by the better ear. Current masking protocols are confusing, 
laborious, and time consuming. Adding a standardized masking protocol to an 
active machine learning audiogram procedure could potentially alleviate all of 
these drawbacks by dynamically adapting the masking as needed for each 
individual. The goal of this study is to determine the accuracy and efficiency 
of automated machine learning masking for obtaining true hearing thresholds.
DESIGN: Dynamically masked automated audiograms were collected for 29 
participants between the ages of 21 and 83 (mean 43, SD 20) with a wide range of 
hearing abilities. Normal-hearing listeners were given unmasked and masked 
machine learning audiogram tests. Listeners with hearing loss were given a 
standard audiogram test by an audiologist, with masking stimuli added as 
clinically determined, followed by a masked machine learning audiogram test. The 
hearing thresholds estimated for each pair of techniques were compared at 
standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz).
RESULTS: Masked and unmasked machine learning audiogram threshold estimates 
matched each other well in normal-hearing listeners, with a mean absolute 
difference between threshold estimates of 3.4 dB. Masked machine learning 
audiogram thresholds also matched well the thresholds determined by a 
conventional masking procedure, with a mean absolute difference between 
threshold estimates for listeners with low asymmetry and high asymmetry between 
the ears, respectively, of 4.9 and 2.6 dB. Notably, out of 6200 masked machine 
learning audiogram tone deliveries for this study, no instances of tones 
detected by the nontest ear were documented. The machine learning methods were 
also generally faster than the manual methods, and for some listeners, 
substantially so.
CONCLUSIONS: Dynamically masked audiograms achieve accurate true threshold 
estimates and reduce test time compared with current clinical masking 
procedures. Dynamic masking is a compelling alternative to the methods currently 
used to evaluate individuals with highly asymmetric hearing, yet can also be 
used effectively and efficiently for anyone.

DOI: 10.1097/AUD.0000000000000891
PMCID: PMC7725866
PMID: 33136643 [Indexed for MEDLINE]


24. Hear Res. 2015 Sep;327:102-8. doi: 10.1016/j.heares.2015.04.016. Epub 2015 May 
15.

The application of genome editing in studying hearing loss.

Zou B(1), Mittal R(1), Grati M(1), Lu Z(2), Shu Y(3), Tao Y(4), Feng Y(5), Xie 
D(6), Kong W(7), Yang S(8), Chen ZY(9), Liu X(10).

Author information:
(1)Department of Otolaryngology, University of Miami Miller School of Medicine, 
Miami, FL 33136, USA.
(2)Department of Biology, University of Miami, Miami, FL 33146, USA.
(3)Department of Otology and Laryngology, Harvard Medical School and 
Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston 02114, 
USA; Department of Otology and Skull Base Surgery, Eye, Ear, Nose and Throat 
Hospital, Shanghai Medical College, Fudan University, Shanghai, China.
(4)Department of Otology and Laryngology, Harvard Medical School and 
Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston 02114, 
USA; Department of Otolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan, China.
(5)Department of Otolaryngology, Xiangya Hospital, Central South University, 
Changsha, Hunan, China.
(6)Department of Otolaryngology-Head and Neck Surgery, The Second Xiangya 
Hospital Central South University, Changsha, Hunan, China.
(7)Department of Otolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan, China.
(8)Department of Otolaryngology-Head and Neck Surgery, Chinese PLA General 
Hospital, Beijing, China.
(9)Department of Otology and Laryngology, Harvard Medical School and 
Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston 02114, 
USA. Electronic address: zheng-yi_chen@meei.harvard.edu.
(10)Department of Otolaryngology, University of Miami Miller School of Medicine, 
Miami, FL 33136, USA; Department of Otolaryngology, Xiangya Hospital, Central 
South University, Changsha, Hunan, China; Department of Otolaryngology-Head and 
Neck Surgery, The Second Xiangya Hospital Central South University, Changsha, 
Hunan, China; Department of Otolaryngology-Head and Neck Surgery, Chinese PLA 
General Hospital, Beijing, China. Electronic address: xliu@med.miami.edu.

Targeted genome editing mediated by clustered, regularly interspaced, short 
palindromic repeat (CRISPR)/CRISPR-associated nuclease 9 (Cas9) technology has 
emerged as one of the most powerful tools to study gene functions, and with 
potential to treat genetic disorders. Hearing loss is one of the most common 
sensory disorders, affecting approximately 1 in 500 newborns with no treatment. 
Mutations of inner ear genes contribute to the largest portion of genetic 
deafness. The simplicity and robustness of CRISPR/Cas9-directed genome editing 
in human cells and model organisms such as zebrafish, mice and primates make it 
a promising technology in hearing research. With CRISPR/Cas9 technology, 
functions of inner ear genes can be studied efficiently by the disruption of 
normal gene alleles through non-homologous-end-joining (NHEJ) mechanism. For 
genetic hearing loss, CRISPR/Cas9 has potential to repair gene mutations by 
homology-directed-repair (HDR) or to disrupt dominant mutations by NHEJ, which 
could restore hearing. Our recent work has shown CRISPR/Cas9-mediated genome 
editing can be efficiently performed in the mammalian inner ear in vivo. Thus, 
application of CRISPR/Cas9 in hearing research will open up new avenues for 
understanding the pathology of genetic hearing loss and provide new routes in 
the development of treatment to restore hearing. In this review, we describe 
major methodologies currently used for genome editing. We will highlight 
applications of these technologies in studies of genetic disorders and discuss 
issues pertaining to applications of CRISPR/Cas9 in auditory systems implicated 
in genetic hearing loss.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.04.016
PMCID: PMC4554948
PMID: 25987504 [Indexed for MEDLINE]


25. Sci Rep. 2023 Feb 15;13(1):2719. doi: 10.1038/s41598-023-29871-8.

Restoring speech intelligibility for hearing aid users with deep learning.

Diehl PU(1)(2), Singer Y(3), Zilly H(3), Schönfeld U(4), Meyer-Rachner P(3), 
Berry M(3), Sprekeler H(5)(6)(7), Sprengel E(3), Pudszuhn A(4), Hofmann VM(4).

Author information:
(1)Audatic, Berlin, Friedrichstr. 210, 10117, Berlin, Germany. 
peter.u.diehl@gmail.com.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, 
Charité-Universitätsmedizin Berlin, Freie Universität Berlin, 
Humboldt-Universität zu Berlin, and Berlin Institute of Health, Campus Benjamin 
Franklin, Berlin, Germany. peter.u.diehl@gmail.com.
(3)Audatic, Berlin, Friedrichstr. 210, 10117, Berlin, Germany.
(4)Department of Otorhinolaryngology, Head and Neck Surgery, 
Charité-Universitätsmedizin Berlin, Freie Universität Berlin, 
Humboldt-Universität zu Berlin, and Berlin Institute of Health, Campus Benjamin 
Franklin, Berlin, Germany.
(5)Department for Electrical Engineering and Computer Science, Technische 
Universität Berlin, Berlin, Germany.
(6)Bernstein Center for Computational Neuroscience Berlin, Philippstr. 13, 
10115, Berlin, Germany.
(7)Exzellenzcluster Science of Intelligence, Technische Universität Berlin, 
Marchstr. 23, 10587, Berlin, Germany.

Almost half a billion people world-wide suffer from disabling hearing loss. 
While hearing aids can partially compensate for this, a large proportion of 
users struggle to understand speech in situations with background noise. Here, 
we present a deep learning-based algorithm that selectively suppresses noise 
while maintaining speech signals. The algorithm restores speech intelligibility 
for hearing aid users to the level of control subjects with normal hearing. It 
consists of a deep network that is trained on a large custom database of noisy 
speech signals and is further optimized by a neural architecture search, using a 
novel deep learning-based metric for speech intelligibility. The network 
achieves state-of-the-art denoising on a range of human-graded assessments, 
generalizes across different noise categories and-in contrast to classic 
beamforming approaches-operates on a single microphone. The system runs in real 
time on a laptop, suggesting that large-scale deployment on hearing aid chips 
could be achieved within a few years. Deep learning-based denoising therefore 
holds the potential to improve the quality of life of millions of hearing 
impaired people soon.

© 2023. The Author(s).

DOI: 10.1038/s41598-023-29871-8
PMCID: PMC9932078
PMID: 36792797 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


26. Sensors (Basel). 2022 Apr 1;22(7):2702. doi: 10.3390/s22072702.

Automatic Speech Discrimination Assessment Methods Based on Event-Related 
Potentials (ERP).

Charuthamrong P(1), Israsena P(2), Hemrungrojn S(3), Pan-Ngum S(4).

Author information:
(1)Interdisciplinary Program of Biomedical Engineering, Faculty of Engineering, 
Chulalongkorn University, Pathumwan, Bangkok 10330, Thailand.
(2)National Electronics and Computer Technology Center, 112 Thailand Science 
Park, Klong Luang, Pathumthani 12120, Thailand.
(3)Department of Psychiatry, Faculty of Medicine, Chulalongkorn University, 
Pathumwan, Bangkok 10330, Thailand.
(4)Department of Computer Engineering, Faculty of Engineering, Chulalongkorn 
University, Pathumwan, Bangkok 10330, Thailand.

Speech discrimination is used by audiologists in diagnosing and determining 
treatment for hearing loss patients. Usually, assessing speech discrimination 
requires subjective responses. Using electroencephalography (EEG), a method that 
is based on event-related potentials (ERPs), could provide objective speech 
discrimination. In this work we proposed a visual-ERP-based method to assess 
speech discrimination using pictures that represent word meaning. The proposed 
method was implemented with three strategies, each with different number of 
pictures and test sequences. Machine learning was adopted to classify between 
the task conditions based on features that were extracted from EEG signals. The 
results from the proposed method were compared to that of a similar 
visual-ERP-based method using letters and a method that is based on the auditory 
mismatch negativity (MMN) component. The P3 component and the late positive 
potential (LPP) component were observed in the two visual-ERP-based methods 
while MMN was observed during the MMN-based method. A total of two out of three 
strategies of the proposed method, along with the MMN-based method, achieved 
approximately 80% average classification accuracy by a combination of support 
vector machine (SVM) and common spatial pattern (CSP). Potentially, these 
methods could serve as a pre-screening tool to make speech discrimination 
assessment more accessible, particularly in areas with a shortage of 
audiologists.

DOI: 10.3390/s22072702
PMCID: PMC9002564
PMID: 35408316 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


27. J Acoust Soc Am. 2022 Mar;151(3):1417. doi: 10.1121/10.0009411.

A model of speech recognition for hearing-impaired listeners based on deep 
learning.

Roßbach J(1), Kollmeier B(2), Meyer BT(1).

Author information:
(1)Communication Acoustics and Cluster of Excellence Hearing4all, Carl von 
Ossietzky University, D-26111 Oldenburg, Germany.
(2)Medical Physics and Cluster of Excellence Hearing4all, Carl von Ossietzky 
University, D-26111 Oldenburg, Germany.

Automatic speech recognition (ASR) has made major progress based on deep machine 
learning, which motivated the use of deep neural networks (DNNs) as perception 
models and specifically to predict human speech recognition (HSR). This study 
investigates if a modeling approach based on a DNN that serves as phoneme 
classifier [Spille, Ewert, Kollmeier, and Meyer (2018). Comput. Speech Lang. 48, 
51-66] can predict HSR for subjects with different degrees of hearing loss when 
listening to speech embedded in different complex noises. The eight noise 
signals range from simple stationary noise to a single competing talker and are 
added to matrix sentences, which are presented to 20 hearing-impaired (HI) 
listeners (categorized into three groups with different types of age-related 
hearing loss) to measure their speech recognition threshold (SRT), i.e., the 
signal-to-noise ratio with 50% word recognition rate. These are compared to 
responses obtained from the ASR-based model using degraded feature 
representations that take into account the individual hearing loss of the 
participants captured by a pure-tone audiogram. Additionally, SRTs obtained from 
eight normal-hearing (NH) listeners are analyzed. For NH subjects and three 
groups of HI listeners, the average SRT prediction error is below 2 dB, which is 
lower than the errors of the baseline models.

DOI: 10.1121/10.0009411
PMID: 35364918 [Indexed for MEDLINE]


28. Acta Otolaryngol. 2023 May;143(5):408-415. doi: 10.1080/00016489.2023.2201287. 
Epub 2023 May 2.

Whole-exome sequencing for screening noise-induced hearing loss susceptibility 
genes.

Fan B(1)(2)(3), Wang G(2)(3), Liu G(2)(3), Zhang X(2)(3), Wu W(1)(2)(3).

Author information:
(1)Department of Otorhinolaryngology Head and Neck Surgery, The 306th Hospital 
of PLA-Peking University Teaching Hospital, Beijing, China.
(2)Department of Otorhinolaryngology Head and Neck Surgery, PLA Strategic 
Support Force Characteristic Medical Center, Beijing, China.
(3)Hearing Impairment Laboratory, State Environmental Protection Key Laboratory 
of Environmental Sense Organ Stress and Health, Beijing, China.

BACKGROUND: High-throughput sequencing of genes indicating susceptibility to 
noise-induced hearing loss has not previously been reported.
AIMS/OBJECTIVES: To identify and analyze genes associated with susceptibility to 
noise-induced hearing loss (NIHL) and characterize differences in susceptibility 
to hearing loss by genotype.
MATERIAL AND METHODS: Pure tone audiometry tests were performed on 113 workers 
exposed to high-intensity noise. Whole-exome sequencing (WES) was conducted and 
NIHL susceptibility genes screened for training unsupervised and supervised 
machine learning models. Immunofluorescence staining of mouse cochlea was used 
to observe patterns of NIHL susceptibility gene expression.
RESULTS: Participants were divided into a NIHL and a control group, according to 
the results of audiometry tests. Seventy-three possible NIHL susceptibility 
genes were input into the machine learning model. Two subgroups of NIHL could be 
distinguished by unsupervised machine learning and the classification was 
evaluated by the supervised machine learning algorithm. The VWF gene had the 
highest mutation frequency in the NIHL group and was expressed mainly in the 
spiral ligament.
CONCLUSIONS AND SIGNIFICANCE: NIHL susceptibility genes were screened and NIHL 
subgroups could be distinguished. VWF may be a novel NIHL susceptibility gene.

DOI: 10.1080/00016489.2023.2201287
PMID: 37129226 [Indexed for MEDLINE]


29. Int J Audiol. 2022 Jan;61(1):66-77. doi: 10.1080/14992027.2021.1884909. Epub 
2021 Feb 27.

Robust machine learning method for imputing missing values in audiograms 
collected in children.

Pitathawatchai P(1), Chaichulee S(2), Kirtsreesakul V(1).

Author information:
(1)Department of Otolaryngology Head and Neck Surgery, Faculty of Medicine, 
Prince of Songkla University, Hat Yai, Thailand.
(2)Institute of Biomedical Engineering, Department of Biomedical Sciences and 
Biomedical Engineering, Faculty of Medicine, Prince of Songkla University, Hat 
Yai, Thailand.

OBJECTIVE: To assess the accuracy and reliability of a machine learning (ML) 
algorithm for predicting the full audiograms of hearing-impaired children 
relative to the common approach (CA).
DESIGN: Retrospective study.
STUDY SAMPLE: There were 206 audiograms included from 206 children with 
sensorineural hearing loss. Nested cross-validation was used for evaluating the 
performance of the CA and ML. Six audiogram prediction simulations were 
performed in which either one or two thresholds across 0.5-4 kHz from complete 
audiograms in the dataset were labelled. Missing thresholds at the remaining 
frequencies were then predicted using the CA and ML in each simulation. The 
accuracy of the ML algorithm was determined by comparing the median average 
absolute threshold differences between the CA and ML using Wilcoxon signed-rank 
test. The reliability between runs of the ML was also assessed with Cronbach's 
alphas.
RESULTS: The median average absolute threshold differences in ML (5-8 dBHL) were 
statistically significantly lower than those in CA (6.25-10 dBHL) in all six 
simulations (p value < 0.05). The ML algorithm was also found to be reliable to 
predict the audiograms in all six simulations (α > 0.9).
CONCLUSION: Using the ML to predict the children's audiograms was reliable and 
more accurate than using the CA.

DOI: 10.1080/14992027.2021.1884909
PMID: 33641573 [Indexed for MEDLINE]


30. J Vis Exp. 2022 Apr 21;(182). doi: 10.3791/63874.

Immunolabeling and Counting Ribbon Synapses in Young Adult and Aged Gerbil 
Cochleae.

Steenken F(1), Bovee S(1), Köppl C(2).

Author information:
(1)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg.
(2)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg; christine.koeppl@uol.de.

The loss of ribbon synapses connecting inner hair cells and afferent auditory 
nerve fibers is assumed to be one cause of age-related hearing loss. The most 
common method for detecting the loss of ribbon synapses is immunolabeling 
because it allows for quantitative sampling from several tonotopic locations in 
an individual cochlea. However, the structures of interest are buried deep 
inside the bony cochlea. Gerbils are used as an animal model for age-related 
hearing loss. Here, routine protocols for fixation, immunolabeling gerbil 
cochlear whole mounts, confocal imaging, and quantifying ribbon synapse numbers 
and volumes are described. Furthermore, the particular challenges associated 
with obtaining good material from valuable aging individuals are highlighted. 
Gerbils are euthanized and either perfused cardiovascularly, or their tympanic 
bullae are carefully dissected out of the skull. The cochleae are opened at the 
apex and base and directly transferred to the fixative. Irrespective of the 
initial method, the cochleae are postfixed and subsequently decalcified. The 
tissue is then labeled with primary antibodies against pre- and postsynaptic 
structures and hair cells. Next, the cochleae are incubated with secondary 
fluorescence-tagged antibodies that are specific against their respective 
primary ones. The cochleae of aged gerbils are then treated with an 
autofluorescence quencher to reduce the typically substantial background 
fluorescence of older animals' tissues. Finally, cochleae are dissected into 
6-11 segments. The entire cochlear length is reconstructed such that specific 
cochlear locations can be reliably determined between individuals. Confocal 
image stacks, acquired sequentially, help visualize hair cells and synapses at 
the chosen locations. The confocal stacks are deconvolved, and the synapses are 
either counted manually using ImageJ, or more extensive quantification of 
synaptic structures is carried out with image analysis procedures custom-written 
in Matlab.

DOI: 10.3791/63874
PMID: 35532259 [Indexed for MEDLINE]


31. Neurosci Lett. 2021 Nov 20;765:136250. doi: 10.1016/j.neulet.2021.136250. Epub 
2021 Sep 15.

The emergence of machine learning in auditory neural impairment: A systematic 
review.

Abu Bakar AR(1), Lai KW(2), Hamzaid NA(3).

Author information:
(1)Department of Biomedical Engineering, Faculty of Engineering, Universiti 
Malaya, 50603 Kuala Lumpur, Malaysia. Electronic address: 
abdul.rauf@siswa.um.edu.my.
(2)Department of Biomedical Engineering, Faculty of Engineering, Universiti 
Malaya, 50603 Kuala Lumpur, Malaysia. Electronic address: lai.khinwee@um.edu.my.
(3)Department of Biomedical Engineering, Faculty of Engineering, Universiti 
Malaya, 50603 Kuala Lumpur, Malaysia.

Hearing loss is a common neurodegenerative disease that can start at any stage 
of life. Misalignment of the auditory neural impairment may impose challenges in 
processing incoming auditory stimulus that can be measured using 
electroencephalography (EEG). The electrophysiological behaviour response 
emanated from EEG auditory evoked potential (AEP) requires highly trained 
professionals for analysis and interpretation. Reliable automated methods using 
techniques of machine learning would assist the auditory assessment process for 
informed treatment and practice. It is thus highly required to develop models 
that are more efficient and precise by considering the characteristics of brain 
signals. This study aims to provide a comprehensive review of several 
state-of-the-art techniques of machine learning that adopt EEG evoked response 
for the auditory assessment within the last 13 years. Out of 161 initially 
screened articles, 11 were retained for synthesis. The outcome of the review 
presented that the Support Vector Machine (SVM) classifier outperformed with 
over 80% accuracy metric and was recognized as the best suited model within the 
field of auditory research. This paper discussed the comprehensive iterative 
properties of the proposed computed algorithms and the feasible future direction 
in hearing impaired rehabilitation.

Copyright © 2021 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.neulet.2021.136250
PMID: 34536511 [Indexed for MEDLINE]


32. EMBO Mol Med. 2022 Aug 8;14(8):e15798. doi: 10.15252/emmm.202215798. Epub 2022 
Jul 14.

Is there an unmet medical need for improved hearing restoration?

Wolf BJ(1)(2)(3)(4), Kusch K(1)(5), Hunniford V(1)(6), Vona B(1)(7), Kühler 
R(8), Keppeler D(1)(3), Strenzke N(1)(8)(9), Moser T(1)(2)(3)(4)(9).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(3)Auditory Neuroscience & Synaptic Nanophysiology Group, Max-Planck-Institute 
for Multidisciplinary Sciences, Göttingen, Germany.
(4)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, Göttingen, 
Germany.
(5)Functional Auditory Genomics Group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(6)Sensory and Motor Neuroscience PhD Program, Göttingen Graduate Center for 
Neurosciences, Biophysics, and Molecular Biosciences, Göttingen, Germany.
(7)Institute of Human Genetics, University Medical Center Göttingen, Göttingen, 
Germany.
(8)Department of Otolaryngology, University Medical Center Göttingen, Göttingen, 
Germany.
(9)Collaborative Research Center 889, University of Göttingen, Göttingen, 
Germany.

Hearing impairment, the most prevalent sensory deficit, affects more than 466 
million people worldwide (WHO). We presently lack causative treatment for the 
most common form, sensorineural hearing impairment; hearing aids and cochlear 
implants (CI) remain the only means of hearing restoration. We engaged with CI 
users to learn about their expectations and their willingness to collaborate 
with health care professionals on establishing novel therapies. We summarize 
upcoming CI innovations, gene therapies, and regenerative approaches and 
evaluate the chances for clinical translation of these novel strategies. We 
conclude that there remains an unmet medical need for improving hearing 
restoration and that we are likely to witness the clinical translation of gene 
therapy and major CI innovations within this decade.

© 2022 The Authors. Published under the terms of the CC BY 4.0 license.

DOI: 10.15252/emmm.202215798
PMCID: PMC9358394
PMID: 35833443 [Indexed for MEDLINE]


33. Trends Hear. 2023 Jan-Dec;27:23312165231211437. doi: 10.1177/23312165231211437.

Preferred Strength of Noise Reduction for Normally Hearing and Hearing-Impaired 
Listeners.

Houben R(1), Reinten I(2), Dreschler WA(2), Mathijssen R(3), Dijkstra 
TMH(4)(5)(6).

Author information:
(1)Pento Audiological Centre, Amersfoort, The Netherlands.
(2)Clinical and Experimental Audiology, Amsterdam UMC location AMC, Amsterdam, 
The Netherlands.
(3)Embedded Systems Innovation, TNO, Eindhoven, The Netherlands.
(4)Institute for Computing and Information Sciences, Radboud University 
Nijmegen, Nijmegen, The Netherlands.
(5)Department of Women's Health, University Clinic Tübingen, Tübingen, Germany.
(6)Institute for Translational Bioinformatics, University Clinic Tübingen, 
Tübingen, Germany.

Preference for noise reduction (NR) strength differs between individuals. The 
purpose of this study was (1) to investigate whether hearing loss influences 
this preference, (2) to find the number of distinct settings required to 
classify participants in similar groups based on their preference for NR 
strength, and (3) to estimate the number of paired comparisons needed to predict 
to which preference group a participant belongs. A paired comparison paradigm 
was used in which participants listened to pairs of speech-in-noise stimuli 
processed by NR with 10 different strength settings. Participants indicated 
their preferred sound sample. The 30 participants were divided into three groups 
according to hearing status (normal hearing, mild hearing loss, and moderate 
hearing loss). The results showed that (1) participants with moderate hearing 
loss preferred stronger NR than participants with normal hearing; (2) cluster 
analysis based solely on the preference for NR strength showed that the data 
could be described well by dividing the participants into three preference 
clusters; (3) the appropriate cluster membership could be found with 15 paired 
comparisons. We conclude that on average, a higher hearing loss is related to a 
preference for stronger NR, at least for our NR algorithm and our participants. 
The results show that it might be possible to use a limited set of pre-set NR 
strengths that can be chosen clinically. For our NR one might use three 
settings: no NR, intermediate NR, and strong NR. Paired comparisons might be 
used to find the optimal one of the three settings.

DOI: 10.1177/23312165231211437
PMCID: PMC10666719
PMID: 37990543 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting InterestsThe 
author(s) declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


34. Audiol Neurootol. 2021;26(5):368-377. doi: 10.1159/000513551. Epub 2021 Mar 2.

Association between Speech Recognition in Noise and Risk Factors of 
Cardiovascular Disease.

Goderie T(1), van Wier MF(2), Stam M(2), Lissenberg-Witte BI(3), Merkus P(2), 
Smits C(2), Kramer SE(2).

Author information:
(1)Department of Otolaryngology-Head and Neck surgery, Section Ear and Hearing, 
Amsterdam Public Health Research Institute, Amsterdam UMC, Vrije Universiteit 
Amsterdam, Amsterdam, The Netherlands, t.goderie@amsterdamumc.nl.
(2)Department of Otolaryngology-Head and Neck surgery, Section Ear and Hearing, 
Amsterdam Public Health Research Institute, Amsterdam UMC, Vrije Universiteit 
Amsterdam, Amsterdam, The Netherlands.
(3)Department of Epidemiology and Data Science, Amsterdam UMC, Vrije 
Universiteit Amsterdam, Amsterdam, The Netherlands.

INTRODUCTION: Risk factors for cardiovascular disease (CVD) are associated with 
sensorineural hearing loss. CVD risk factors are known to cluster and interact, 
thereby increasing the cumulative risk for CVD. Previously, using the database 
of the Netherlands Longitudinal Study on Hearing (NL-SH), an association was 
found between a history of smoking and an increased decline in speech 
recognition in noise over 10 years of follow-up. Prospectively limited data are 
available on the association between CVD risk factors, interactions of these 
risk factors, and hearing loss. In this study, data from the NL-SH were used to 
study the association between CVD risk factors and speech recognition in noise 
longitudinally.
METHODS: Baseline, 5-year, and 10-year follow-up data of the NL-SH were 
included. The NL-SH is a web-based prospective cohort study which started in 
2006. Participants were aged 18-70 years at baseline. Speech recognition in 
noise was determined with an online digit-triplet speech-in-noise test. In 
addition, participants completed online questionnaires on demographic, 
lifestyle, and health-related characteristics. The association of the ability to 
recognize speech in noise with CVD risk factors (i.e., obesity, rheumatoid 
arthritis [RA], hypertension, diabetes mellitus, and dyslipidemia) was analyzed 
longitudinally. We also analyzed the interaction between these risk factors 
(including age, sex, and history of smoking) and speech recognition in noise.
RESULTS: None of the CVD risk factors or interactions of 2 CVD risk factors was 
significantly associated with a decline in SRT over time. Obesity (p = 0.016), 
RA (p = 0.027), and hypertension (p = 0.044) were associated with overall higher 
(more unfavorable) SRTs. No overall interactions between CVD risk factors were 
found.
CONCLUSION: Obesity, RA, and hypertension were overall associated with a higher 
SRT, but no longitudinal associations between these or other CVD factors with 
SRTs were found. Also, no interactions between 2 CVD risk factors and SRTs were 
found. Although no longitudinal associations between CVD risk factors and 
decline in SRTs were found, clinicians should be alert about the concurrent 
association between CVD risk factors and hearing loss.

© 2021 The Author(s) Published by S. Karger AG, Basel.

DOI: 10.1159/000513551
PMID: 33652431 [Indexed for MEDLINE]


35. Otol Neurotol. 2022 Jun 1;43(5):e530-e534. doi: 10.1097/MAO.0000000000003539.

Machine Learning for Vestibular Schwannoma Diagnosis Using Audiometrie Data 
Alone.

Carey GE(1), Jacobson CE, Warburton AN, Biddle E, Mannarelli G, Wilson M, 
Stucken EZ.

Author information:
(1)Department of Otolaryngology, University of Michigan Medical School, Ann 
Arbor, Michigan.

OBJECTIVE: The aim of this study is to compare machine learning algorithms and 
established rule-based evaluations in screening audiograms for the purpose of 
diagnosing vestibular schwannomas. A secondary aim is to assess the performance 
of rule-based evaluations for predicting vestibular schwannomas using the 
largest dataset in the literature.
STUDY DESIGN: Retrospective case-control study.
SETTING: Tertiary referral center.
PATIENTS: Seven hundred sixty seven adult patients with confirmed vestibular 
schwannoma and a pretreatment audiogram on file and 2000 randomly selected adult 
controls with audiograms.
INTERVENTIONS: Audiometric data were analyzed using machine learning algorithms 
and standard rule-based criteria for defining asymmetric hearing loss.
MAIN OUTCOME MEASURES: The primary outcome is the ability to identify patients 
with vestibular schwannomas based on audiometric data alone, using machine 
learning algorithms and rule-based formulas. The secondary outcome is the 
application of conventional rule-based formulas to a larger dataset using 
advanced computational techniques.
RESULTS: The machine learning algorithms had mildly improved specificity in some 
fields compared with rule-based evaluations and had similar sensitivity to 
previous rule-based evaluations in diagnosis of vestibular schwannomas.
CONCLUSIONS: Machine learning algorithms perform similarly to rule-based 
evaluations in identifying patients with vestibular schwannomas based on 
audiometric data alone. Performance of established rule-based formulas was 
consistent with earlier performance metrics, when analyzed using a large 
dataset.

Copyright © 2022, Otology & Neurotology, Inc.

DOI: 10.1097/MAO.0000000000003539
PMID: 35617004 [Indexed for MEDLINE]

Conflict of interest statement: The authors disclose no conflicts of interest.


36. Neuroscience. 2020 Mar 1;429:134-142. doi: 10.1016/j.neuroscience.2019.12.046. 
Epub 2020 Jan 11.

Neural Signatures of Working Memory in Age-related Hearing Loss.

Rosemann S(1), Thiel CM(2).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, 26111 Oldenburg, 
Germany; Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany. Electronic address: 
Stephanie.rosemann@uni-oldenburg.de.
(2)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, 26111 Oldenburg, 
Germany; Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany.

Age-related hearing loss affects the ability to hear high frequencies and 
therefore leads to difficulties in understanding speech, particularly under 
adverse listening conditions. This decrease in hearing can be partly compensated 
by the recruitment of executive functions, such as working memory. The 
compensatory effort may, however, lead to a decrease in available neural 
resources compromising cognitive abilities. We here aim to investigate whether 
mild to moderate hearing loss impacts prefrontal functions and related executive 
processes and whether these are related to speech-in-noise perception abilities. 
Nineteen hard of hearing and nineteen age-matched normal-hearing participants 
performed a working memory task to drive prefrontal activity, which was gauged 
with functional magnetic resonance imaging. In addition, speech-in-noise 
understanding, cognitive flexibility and inhibition control were assessed. Our 
results showed no differences in frontoparietal activation patterns and working 
memory performance between normal-hearing and hard of hearing participants. The 
behavioral assessment of further executive functions, however, provided evidence 
of lower cognitive flexibility in hard of hearing participants. Cognitive 
flexibility and hearing abilities further predicted speech-in-noise perception. 
We conclude that neural and behavioral signatures of working memory are intact 
in mild to moderate hearing loss. Moreover, cognitive flexibility seems to be 
closely related to hearing impairment and speech-in-noise perception and should, 
therefore, be investigated in future studies assessing age-related hearing loss 
and its implications on prefrontal functions.

Copyright © 2020 IBRO. Published by Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuroscience.2019.12.046
PMID: 31935488 [Indexed for MEDLINE]


37. Int J Audiol. 2018 May;57(5):335-344. doi: 10.1080/14992027.2017.1423118. Epub 
2018 Jan 9.

Hearing aid noise suppression and working memory function.

Neher T(1)(2), Wagener KC(3), Fischer RL(4).

Author information:
(1)a Medizinische Physik and Cluster of Excellence "Hearing4all" , 
Carl-von-Ossietzky University , Oldenburg , Germany.
(2)b Institute of Clinical Research , University of Southern Denmark , Odense , 
Denmark.
(3)c Hörzentrum Oldenburg GmbH , Oldenburg , Germany , and.
(4)d Sivantos GmbH , Erlangen , Germany.

OBJECTIVE: Research findings concerning the relation between benefit from 
hearing aid (HA) noise suppression and working memory function are inconsistent. 
The current study thus investigated the effects of three noise suppression 
algorithms on auditory working memory and the relation with reading span.
DESIGN: Using a computer simulation of bilaterally fitted HAs, four settings 
were tested: (1) unprocessed, (2) directional microphones, (3) single-channel 
noise reduction, and (4) binaural coherence-based noise reduction. Settings 2-4 
were matched in terms of the speech-weighted signal-to-noise ratio (SNR) 
improvement. Auditory working memory was assessed at +6 dB SNR using listening 
span and N-back paradigms.
STUDY SAMPLE: Twenty experienced HA users aged 55-80 years with large 
differences in reading span.
RESULTS: For the listening span measurements, there was an influence of HA 
setting on sentence-final word recognition and recall, with the directional 
microphones leading to ∼6% better performance than the single-channel noise 
reduction. For the N-back measurements, there was substantial test-retest 
variability and no influence of HA setting. No interactions with reading span 
were found.
CONCLUSION: HA noise suppression may affect the recognition and recall of speech 
at positive SNRs, irrespective of individual reading span. Future work should 
improve the reliability of the auditory working memory measurements.

DOI: 10.1080/14992027.2017.1423118
PMID: 29316819 [Indexed for MEDLINE]


38. Sci Rep. 2021 Mar 16;11(1):5994. doi: 10.1038/s41598-021-85349-5.

Effects of age-related hearing loss and hearing aid experience on sentence 
processing.

Vogelzang M(1)(2)(3), Thiel CM(4)(5), Rosemann S(4)(5), Rieger JW(4)(6), 
Ruigendijk E(7)(4).

Author information:
(1)Institute of Dutch Studies, University of Oldenburg, Ammerländer Heerstraße 
114-116, 26129, Oldenburg, Germany. mv498@cam.ac.uk.
(2)Cluster of Excellence "Hearing4all", University of Oldenburg, Ammerländer 
Heerstraße 114-116, 26129, Oldenburg, Germany. mv498@cam.ac.uk.
(3)Department of Theoretical and Applied Linguistics, University of Cambridge, 
Cambridge, UK. mv498@cam.ac.uk.
(4)Cluster of Excellence "Hearing4all", University of Oldenburg, Ammerländer 
Heerstraße 114-116, 26129, Oldenburg, Germany.
(5)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, University of Oldenburg, Ammerländer Heerstraße 114-116, 26129, 
Oldenburg, Germany.
(6)Applied Neurocognitive Psychology, Department of Psychology, University of 
Oldenburg, Ammerländer Heerstraße 114-116, 26129, Oldenburg, Germany.
(7)Institute of Dutch Studies, University of Oldenburg, Ammerländer Heerstraße 
114-116, 26129, Oldenburg, Germany.

Age-related hearing loss typically affects the hearing of high frequencies in 
older adults. Such hearing loss influences the processing of spoken language, 
including higher-level processing such as that of complex sentences. Hearing 
aids may alleviate some of the speech processing disadvantages associated with 
hearing loss. However, little is known about the relation between hearing loss, 
hearing aid use, and their effects on higher-level language processes. This 
neuroimaging (fMRI) study examined these factors by measuring the comprehension 
and neural processing of simple and complex spoken sentences in hard-of-hearing 
older adults (n = 39). Neither hearing loss severity nor hearing aid experience 
influenced sentence comprehension at the behavioral level. In contrast, hearing 
loss severity was associated with increased activity in left superior frontal 
areas and the left anterior insula, but only when processing specific complex 
sentences (i.e. object-before-subject) compared to simple sentences. Longer 
hearing aid experience in a sub-set of participants (n = 19) was associated with 
recruitment of several areas outside of the core speech processing network in 
the right hemisphere, including the cerebellum, the precentral gyrus, and the 
cingulate cortex, but only when processing complex sentences. Overall, these 
results indicate that brain activation for language processing is affected by 
hearing loss as well as subsequent hearing aid use. Crucially, they show that 
these effects become apparent through investigation of complex but not simple 
sentences.

DOI: 10.1038/s41598-021-85349-5
PMCID: PMC7971046
PMID: 33727628 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


39. Annu Int Conf IEEE Eng Med Biol Soc. 2016 Aug;2016:89-92. doi: 
10.1109/EMBC.2016.7590647.

Difficulty understanding speech in noise by the hearing impaired: underlying 
causes and technological solutions.

Healy EW, Yoho SE.

A primary complaint of hearing-impaired individuals involves poor speech 
understanding when background noise is present. Hearing aids and cochlear 
implants often allow good speech understanding in quiet backgrounds. But 
hearing-impaired individuals are highly noise intolerant, and existing devices 
are not very effective at combating background noise. As a result, speech 
understanding in noise is often quite poor. In accord with the significance of 
the problem, considerable effort has been expended toward understanding and 
remedying this issue. Fortunately, our understanding of the underlying issues is 
reasonably good. In sharp contrast, effective solutions have remained elusive. 
One solution that seems promising involves a single-microphone machine-learning 
algorithm to extract speech from background noise. Data from our group indicate 
that the algorithm is capable of producing vast increases in speech 
understanding by hearing-impaired individuals. This paper will first provide an 
overview of the speech-in-noise problem and outline why hearing-impaired 
individuals are so noise intolerant. An overview of our approach to solving this 
problem will follow.

DOI: 10.1109/EMBC.2016.7590647
PMID: 28268288 [Indexed for MEDLINE]


40. Brain Struct Funct. 2020 Dec;225(9):2689-2700. doi: 10.1007/s00429-020-02148-w. 
Epub 2020 Sep 22.

Neuroanatomical changes associated with age-related hearing loss and listening 
effort.

Rosemann S(1)(2), Thiel CM(3)(4).

Author information:
(1)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany. 
Stephanie.rosemann@uni-oldenburg.de.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany. Stephanie.rosemann@uni-oldenburg.de.
(3)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany.
(4)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany.

Comment in
    Brain Struct Funct. 2021 Jun;226(5):1385.
    Brain Struct Funct. 2021 Jun;226(5):1387-1388.

Age-related hearing loss is associated with a decrease in hearing abilities for 
high frequencies and therefore leads to impairments in understanding speech-in 
particular, under adverse listening conditions. Growing evidence suggests that 
age-related hearing loss is related to various neural changes, for instance, 
affecting auditory and frontal brain regions. How the decreased auditory input 
and the increased listening effort in daily life are associated with structural 
changes is less clear, since previous evidence is scarce and mostly involved low 
sample sizes. Hence, the aim of the current study was to investigate the impact 
of age-related untreated hearing loss and subjectively rated daily life 
listening effort on grey matter and white matter changes in a large sample of 
participants (n = 71). For that aim, we conducted anatomical MRI and diffusion 
tensor imaging (DTI) in elderly hard-of-hearing and age-matched normal-hearing 
participants. Our results showed significantly lower grey matter volume in the 
middle frontal cortex in hard-of-hearing compared to normal-hearing 
participants. Further, higher listening effort was associated with lower grey 
matter volume and cortical thickness in the orbitofrontal cortex and lower grey 
matter volume in the inferior frontal cortex. No significant relations between 
hearing abilities or listening effort were obtained for white matter integrity 
in tracts connecting auditory and prefrontal as well as visual areas. These 
findings provide evidence that hearing impairment as well as daily life 
listening effort seems to be associated with grey matter loss in prefrontal 
brain regions. We further conclude that alterations in cortical thickness seem 
to be linked to the increased listening effort rather than the hearing loss 
itself.

DOI: 10.1007/s00429-020-02148-w
PMCID: PMC7674350
PMID: 32960318 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


41. Otolaryngol Head Neck Surg. 1995 Mar;112(3):383-90. doi: 
10.1016/S0194-59989570271-7.

Database for vertigo.

Kentala E(1), Pyykkö I, Auramo Y, Juhola M.

Author information:
(1)Department of Otolaryngology, University Hospital of Helsinki, Finland.

An interactive database has been developed to assist the diagnostic procedure 
for vertigo and to store the data. The database offers a possibility to split 
and reunite the collected information when needed. It contains detailed 
information about a patient's history, symptoms, and findings in otoneurologic, 
audiologic, and imaging tests. The symptoms are classified into sets of 
questions on vertigo (including postural instability), hearing loss and 
tinnitus, and provoking factors. Confounding disorders are screened. The 
otoneurologic tests involve saccades, smooth pursuit, posturography, and a 
caloric test. In addition, findings from specific antibody tests, clinical 
neurotologic tests, magnetic resonance imaging, brain stem audiometry, and 
electrocochleography are included. The input information can be applied to 
workups for vertigo in an expert system called ONE. The database assists its 
user in that the input of information is easy. If not only can be used for 
diagnostic purposes but is also beneficial for research, and in combination with 
the expert system, it provides a tutorial guide for medical students.

DOI: 10.1016/S0194-59989570271-7
PMID: 7870437 [Indexed for MEDLINE]


42. Ear Hear. 2023 Sep-Oct 01;44(5):1262-1270. doi: 10.1097/AUD.0000000000001380. 
Epub 2023 Jun 15.

A Hybrid Deep Learning Approach to Identify Preventable Childhood Hearing Loss.

Jin FQ(1)(2), Huang O(1)(2), Kleindienst Robler S(3)(4), Morton S(5), Platt 
A(5)(6), Egger JR(5), Emmett SD(5)(7), Palmeri ML(1).

Author information:
(1)Department of Biomedical Engineering, Duke University, Durham, North 
Carolina, USA.
(2)These Authors contributed equally to this work.
(3)Department of Audiology, Norton Sound Health Corporation, Nome, Alaska, USA.
(4)Department of Otolaryngology-Head and Neck Surgery, University of Arkansas 
for Medical Sciences, Little Rock, Arkansas, USA.
(5)Duke Global Health Institute, Durham, North Carolina, USA.
(6)Department of Biostatistics and Bioinformatics, Duke University School of 
Medicine, Durham, North Carolina, USA.
(7)Department of Head and Neck Surgery and Communication Sciences, Duke 
University School of Medicine, Durham, North Carolina, USA.

OBJECTIVE: Childhood hearing loss has well-known, lifelong consequences. 
Infection-related hearing loss disproportionately affects underserved 
communities yet can be prevented with early identification and treatment. This 
study evaluates the utility of machine learning in automating tympanogram 
classifications of the middle ear to facilitate layperson-guided tympanometry in 
resource-constrained communities.
DESIGN: Diagnostic performance of a hybrid deep learning model for classifying 
narrow-band tympanometry tracings was evaluated. Using 10-fold cross-validation, 
a machine learning model was trained and evaluated on 4810 pairs of tympanometry 
tracings acquired by an audiologist and layperson. The model was trained to 
classify tracings into types A (normal), B (effusion or perforation), and C 
(retraction), with the audiologist interpretation serving as reference standard. 
Tympanometry data were collected from 1635 children from October 10, 2017, to 
March 28, 2019, from two previous cluster-randomized hearing screening trials 
(NCT03309553, NCT03662256). Participants were school-aged children from an 
underserved population in rural Alaska with a high prevalence of 
infection-related hearing loss. Two-level classification performance statistics 
were calculated by treating type A as pass and types B and C as refer.
RESULTS: For layperson-acquired data, the machine-learning model achieved a 
sensitivity of 95.2% (93.3, 97.1), specificity of 92.3% (91.5, 93.1), and area 
under curve of 0.968 (0.955, 0.978). The model's sensitivity was greater than 
that of the tympanometer's built-in classifier [79.2% (75.5, 82.8)] and a 
decision tree based on clinically recommended normative values [56.9% (52.4, 
61.3)]. For audiologist-acquired data, the model achieved a higher AUC of 0.987 
(0.980, 0.993), had an equivalent sensitivity of 95.2 (93.3, 97.1), and a higher 
specificity of 97.7 (97.3, 98.2).
CONCLUSIONS: Machine learning can detect middle ear disease with comparable 
performance to an audiologist using tympanograms acquired either by an 
audiologist or a layperson. Automated classification enables the use of 
layperson-guided tympanometry in hearing screening programs in rural and 
underserved communities, where early detection of treatable pathology in 
children is crucial to prevent the lifelong adverse effects of childhood hearing 
loss.

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001380
PMCID: PMC10426782
PMID: 37318215 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
declare.


43. F1000Res. 2021 Apr 22;10:311. doi: 10.12688/f1000research.51784.1. eCollection 
2021.

Thoughts on the potential to compensate a hearing loss in noise.

Schädler MR(1).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, University of 
Oldenburg, Oldenburg, Germany.

Background: The effect of hearing impairment on speech perception was described 
by Plomp (1978) as a sum of a loss of class A, due to signal attenuation, and a 
loss of class D, due to signal distortion. While a loss of class A can be 
compensated by linear amplification, a loss of class D, which severely limits 
the benefit of hearing aids in noisy listening conditions, cannot. The hearing 
loss of class D is assumed to be the main reason why not few users of hearing 
aids keep complaining about the limited benefit of their devices in noisy 
environments. Working compensation strategies against it are unknown. Methods: 
Recently, in an approach to model human speech recognition by means of a 
re-purposed automatic speech recognition (ASR) system, the loss of class D was 
explained by introducing a level uncertainty which reduces the individual 
accuracy of spectro-temporal signal levels. Based on this finding, an 
implementation of a patented dynamic range manipulation scheme (PLATT) is 
proposed which aims to mitigate the effect of increased level uncertainty on 
speech recognition in noise by expanding spectral modulation patterns in the 
range of 2 to 4 ERB. This compensation approach is objectively evaluated 
regarding the benefit in speech recognition thresholds in noise using the 
ASR-based speech recognition model. Recommendations for an evaluation with human 
listeners are derived. Results: The objective evaluation suggests that 
approximately half of the class D loss due to an increased level uncertainty 
might be compensable. To measure the effect with human listeners, an experiment 
needs to be carefully designed to prevent the confusion class A and D loss 
compensations. Conclusions: A working compensation strategy for the class D loss 
could provide previously unexploited potential for relief. Evidence has to be 
provided in experiments with human listeners.

Copyright: © 2021 Schädler MR.

DOI: 10.12688/f1000research.51784.1
PMCID: PMC8524304
PMID: 34721841 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests: The author is the inventor 
of the patented approach which is proposed and used in this contribution: German 
patent DE 10 2017 216 972 B4.


44. Sci Rep. 2023 Dec 11;13(1):21889. doi: 10.1038/s41598-023-48911-x.

Characteristics of brain glucose metabolism and metabolic connectivity in 
noise-induced hearing loss.

Shin S(1), Nam HY(2).

Author information:
(1)Department of Nuclear Medicine, Samsung Changwon Hospital, Sungkyunkwan 
University School of Medicine, Changwon, Republic of Korea.
(2)Department of Nuclear Medicine, Samsung Changwon Hospital, Sungkyunkwan 
University School of Medicine, Changwon, Republic of Korea. 
octobre23@hanmail.net.

The purpose of this study was to evaluate the differences in cerebral glucose 
metabolism and metabolic connectivity between noise-induced hearing loss (NIHL) 
subjects and normal subjects. Eighty-nine subjects who needed close observation 
for NIHL or were diagnosed with NIHL and 89 normal subjects were enrolled. After 
pre-processing of positron emission tomography images including co-registration, 
spatial normalization, and smoothing, a two-sample t-test was conducted to 
compare cerebral glucose metabolism between the two groups. To evaluate 
metabolic connectivity between two groups, BRAPH-BRain Analysis using graPH 
theory, a software package to perform graph theory analysis of the brain 
connectome was used. NIHL subjects showed hypometabolism compared to normal 
subjects in both insulae (x - 38, y - 18, z 4; × 42, y - 12, z 4) and right 
superior temporal gyrus (× 44, y 16, z - 20). No brain regions showed 
hypermetabolism in the NIHL subjects. In metabolic connectivity analysis, NIHL 
subjects showed decreased average strength, global efficiency, local efficiency, 
and mean clustering coefficient when compared with normal subjects. Decreased 
glucose metabolism and metabolic connectivity in NIHL subject might reflect 
decreased auditory function. It might be characteristic of sensorineural hearing 
loss.

© 2023. The Author(s).

DOI: 10.1038/s41598-023-48911-x
PMCID: PMC10713681
PMID: 38081979 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


45. J Speech Lang Hear Res. 2023 Apr 12;66(4):1394-1409. doi: 
10.1044/2022_JSLHR-22-00383. Epub 2023 Mar 1.

Verbal Fluency in Prelingually Deaf, Early Implanted Children and Adolescents 
With Cochlear Implants.

Hasnain F(1), Herran RM(1), Henning SC(1), Ditmars AM(1), Pisoni DB(1)(2), 
Sehgal ST(1), Kronenberger WG(1)(3).

Author information:
(1)Department of Otolaryngology - Head and Neck Surgery, Indiana University 
School of Medicine, Indianapolis.
(2)Department of Psychological and Brain Sciences, Indiana University, 
Bloomington.
(3)Department of Psychiatry, Indiana University School of Medicine, 
Indianapolis.

PURPOSE: Verbal fluency tasks assess the ability to quickly and efficiently 
retrieve words from the mental lexicon by requiring subjects to rapidly generate 
words within a phonological or semantic category. This study investigated 
differences between cochlear implant users and normal-hearing peers in the 
clustering and time course of word retrieval during phonological and semantic 
verbal fluency tasks.
METHOD: Twenty-eight children and adolescents (aged 9-17 years) with cochlear 
implants and 33 normal-hearing peers completed measures of verbal fluency, 
nonverbal intelligence, speech perception, and verbal short-term/working memory. 
Phonological and semantic verbal fluency tests were scored for total words 
generated, words generated in each 10-s interval of the 1-min task, latency to 
first word generated, number of word clusters, average cluster size, and number 
of word/cluster switches.
RESULTS: Children and adolescents with cochlear implants generated fewer words 
than normal-hearing peers throughout the entire 60-s time interval of the 
phonological and semantic fluency tasks. Cochlear implant users also had slower 
start latency times and produced fewer clusters and switches than normal-hearing 
peers during the phonological fluency task. Speech perception and verbal working 
memory scores were more strongly associated with verbal fluency scores in 
children and adolescents with cochlear implants than in normal-hearing peers.
CONCLUSIONS: Cochlear implant users show poorer phonological and semantic verbal 
fluency than normal-hearing peers, and their verbal fluency is significantly 
associated with speech perception and verbal working memory. These findings 
suggest deficits in fluent retrieval of phonological and semantic information 
from long-term lexical memory in cochlear implant users.

DOI: 10.1044/2022_JSLHR-22-00383
PMCID: PMC10457083
PMID: 36857026 [Indexed for MEDLINE]


46. Trends Hear. 2019 Jan-Dec;23:2331216519858311. doi: 10.1177/2331216519858311.

Spatial Speech-in-Noise Performance in Bimodal and Single-Sided Deaf Cochlear 
Implant Users.

Williges B(1), Wesarg T(2), Jung L(2), Geven LI(3), Radeloff A(3), Jürgens 
T(1)(4).

Author information:
(1)1 Medical Physics and Cluster of Excellence "Hearing4all," Carl von Ossietzky 
University of Oldenburg, Germany.
(2)2 Department of Otorhinolaryngology - Head and Neck Surgery, Faculty of 
Medicine, Medical Center - University of Freiburg, University of Freiburg, 
Germany.
(3)3 Department of Otorhinolaryngology, Head and Neck Surgery, Carl von 
Ossietzky University of Oldenburg, Germany.
(4)4 Institute of Acoustics, University of Applied Sciences Lübeck, Germany.

This study compared spatial speech-in-noise performance in two cochlear implant 
(CI) patient groups: bimodal listeners, who use a hearing aid contralaterally to 
support their impaired acoustic hearing, and listeners with contralateral normal 
hearing, i.e., who were single-sided deaf before implantation. Using a 
laboratory setting that controls for head movements and that simulates spatial 
acoustic scenes, speech reception thresholds were measured for frontal 
speech-in-stationary noise from the front, the left, or the right side. Spatial 
release from masking (SRM) was then extracted from speech reception thresholds 
for monaural and binaural listening. SRM was found to be significantly lower in 
bimodal CI than in CI single-sided deaf listeners. Within each listener group, 
the SRM extracted from monaural listening did not differ from the SRM extracted 
from binaural listening. In contrast, a normal-hearing control group showed a 
significant improvement in SRM when using two ears in comparison to one. Neither 
CI group showed a binaural summation effect; that is, their performance was not 
improved by using two devices instead of the best monaural device in each 
spatial scenario. The results confirm a "listening with the better ear" strategy 
in the two CI patient groups, where patients benefited from using two 
ears/devices instead of one by selectively attending to the better one. Which 
one is the better ear, however, depends on the spatial scenario and on the 
individual configuration of hearing loss.

DOI: 10.1177/2331216519858311
PMCID: PMC6669847
PMID: 31364496 [Indexed for MEDLINE]


47. J Acoust Soc Am. 2020 Mar;147(3):1379. doi: 10.1121/10.0000759.

Prediction of individual speech recognition performance in complex listening 
conditions.

Kubiak AM(1), Rennies J(1), Ewert SD(2), Kollmeier B(3).

Author information:
(1)Fraunhofer IDMT, Project Group Hearing, Speech and Audio Technology, Cluster 
of Excellence "Hearing4all," Oldenburg, Germany.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, 26111 Oldenburg, Germany.
(3)Fraunhofer IDMT, Project Group Hearing, Speech and Audio Technology, Cluster 
of Excellence "Hearing4all," Medizinische Physik and Cluster of Excellence 
Hearing4all, Universität Oldenburg, 26111 Oldenburg, Germany.

This study examined how well individual speech recognition thresholds in complex 
listening scenarios could be predicted by a current binaural speech 
intelligibility model. Model predictions were compared with experimental data 
measured for seven normal-hearing and 23 hearing-impaired listeners who differed 
widely in their degree of hearing loss, age, as well as performance in clinical 
speech tests. The experimental conditions included two masker types 
(multi-talker or two-talker maskers), and two spatial conditions (maskers 
co-located with the frontal target or symmetrically separated from the target). 
The results showed that interindividual variability could not be well predicted 
by a model including only individual audiograms. Predictions improved when an 
additional individual "proficiency factor" was derived from one of the 
experimental conditions or a standard speech test. Overall, the current model 
can predict individual performance relatively well (except in conditions high in 
informational masking), but the inclusion of age-related factors may lead to 
even further improvements.

DOI: 10.1121/10.0000759
PMID: 32237817 [Indexed for MEDLINE]


48. Otolaryngol Head Neck Surg. 2020 Oct;163(4):771-777. doi: 
10.1177/0194599820924331. Epub 2020 May 26.

Visual Speech Recognition: Improving Speech Perception in Noise through 
Artificial Intelligence.

Raghavan AM(1), Lipschitz N(2), Breen JT(2), Samy RN(2), Kohlberg GD(2)(3).

Author information:
(1)University of Cincinnati College of Medicine, Cincinnati, Ohio, USA.
(2)Department of Otolaryngology-Head and Neck Surgery, University of 
Cincinnati/Cincinnati Children's Hospital Medical Center, Cincinnati, Ohio, USA.
(3)Department of Otolaryngology-Head and Neck Surgery, University of Washington, 
Seattle, Washington, USA.

OBJECTIVES: To compare speech perception (SP) in noise for normal-hearing (NH) 
individuals and individuals with hearing loss (IWHL) and to demonstrate 
improvements in SP with use of a visual speech recognition program (VSRP).
STUDY DESIGN: Single-institution prospective study.
SETTING: Tertiary referral center.
SUBJECTS AND METHODS: Eleven NH and 9 IWHL participants in a sound-isolated 
booth facing a speaker through a window. In non-VSRP conditions, SP was 
evaluated on 40 Bamford-Kowal-Bench speech-in-noise test (BKB-SIN) sentences 
presented by the speaker at 50 A-weighted decibels (dBA) with multiperson babble 
noise presented from 50 to 75 dBA. SP was defined as the percentage of words 
correctly identified. In VSRP conditions, an infrared camera was used to track 
35 points around the speaker's lips during speech in real time. Lip movement 
data were translated into speech-text via an in-house developed neural 
network-based VSRP. SP was evaluated similarly in the non-VSRP condition on 42 
BKB-SIN sentences, with the addition of the VSRP output presented on a screen to 
the listener.
RESULTS: In high-noise conditions (70-75 dBA) without VSRP, NH listeners 
achieved significantly higher speech perception than IWHL listeners (38.7% vs 
25.0%, P = .02). NH listeners were significantly more accurate with VSRP than 
without VSRP (75.5% vs 38.7%, P < .0001), as were IWHL listeners (70.4% vs 25.0% 
P < .0001). With VSRP, no significant difference in SP was observed between NH 
and IWHL listeners (75.5% vs 70.4%, P = .15).
CONCLUSIONS: The VSRP significantly increased speech perception in high-noise 
conditions for NH and IWHL participants and eliminated the difference in SP 
accuracy between NH and IWHL listeners.

DOI: 10.1177/0194599820924331
PMID: 32453650 [Indexed for MEDLINE]


49. Int J Audiol. 2018 Oct;57(10):746-754. doi: 10.1080/14992027.2018.1481538. Epub 
2018 Jun 22.

Verbal learning and memory in prelingually deaf children with cochlear implants.

Kronenberger WG(1)(2), Henning SC(2), Ditmars AM(2), Roman AS(3), Pisoni 
DB(2)(4).

Author information:
(1)a Department of Psychiatry , Indiana University School of Medicine , 
Indianapolis , IN , USA.
(2)b Department of Otolaryngology-Head and Neck Surgery , DeVault Otologic 
Research Laboratory , Indiana University School of Medicine , Indianapolis , IN 
, USA.
(3)c Department of Hearing and Speech Sciences , Vanderbilt University , 
Nashville , TN , USA.
(4)d Department of Psychological and Brain Sciences , Speech Research Laboratory 
, Indiana University-Bloomington , Bloomington , IN , USA.

OBJECTIVE: Deaf children with cochlear implants (CIs) show poorer verbal working 
memory compared to normal-hearing (NH) peers, but little is known about their 
verbal learning and memory (VLM) processes involving multi-trial free recall.
DESIGN: Children with CIs were compared to NH peers using the California Verbal 
Learning Test for Children (CVLT-C).
STUDY SAMPLE: Participants were 21 deaf (before age 6 months) children 
(6-16 years old) implanted prior to age 3 years, and 21 age-IQ matched NH peers.
RESULTS: Results revealed no differences between groups in number of words 
recalled. However, CI users showed a pattern of increasing use of serial 
clustering strategies across learning trials, whereas NH peers decreased their 
use of serial clustering strategies. In the CI sample (but not in the NH 
sample), verbal working memory test scores were related to resistance to the 
build-up of proactive interference, and sentence recognition was associated with 
performance on the first exposure to the word list and to the use of recency 
recall strategies.
CONCLUSIONS: Children with CIs showed robust evidence of VLM comparable to NH 
peers. However, their VLM processing (especially recency and proactive 
interference) was related to speech perception outcomes and verbal WM in 
different ways from NH peers.

DOI: 10.1080/14992027.2018.1481538
PMCID: PMC6215502
PMID: 29933710 [Indexed for MEDLINE]

Conflict of interest statement: Disclosure statement William Kronenberger is a 
paid consultant for the Indiana Hemophilia and Thrombosis Center and Shire 
Pharmaceuticals. The other authors have no conflicts of interest to declare.


50. Z Gerontol Geriatr. 2023 Jul;56(4):283-289. doi: 10.1007/s00391-023-02179-y. 
Epub 2023 Apr 27.

The future of hearing aid technology : Can technology turn us into superheroes?

[Article in English]

Hohmann V(1)(2)(3).

Author information:
(1)Department of Medical Physics and Acoustics, University of Oldenburg, 26111, 
Oldenburg, Germany. volker.hohmann@uol.de.
(2)Hörzentrum Oldenburg gGmbH, Oldenburg, Germany. volker.hohmann@uol.de.
(3)Cluster of Excellence Hearing4all, Oldenburg, Germany. volker.hohmann@uol.de.

BACKGROUND: Hearing aid technology has proven to be successful in the 
rehabilitation of hearing loss, but its performance is still limited in 
difficult everyday conditions characterized by noise and reverberation.
OBJECTIVE: Introduction to the current state of hearing aid technology and 
presentation of the current state of research and future developments.
METHODS: The current literature was analyzed and several specific new 
developments are presented.
RESULTS: Both objective and subjective data from empirical studies show the 
limitations of the current technology. Examples of current research show the 
potential of machine learning-based algorithms and multimodal signal processing 
for improving speech processing and perception, of using virtual reality for 
improving hearing device fitting and of mobile health technology for improving 
hearing health services.
CONCLUSION: Hearing device technology will remain a key factor in the 
rehabilitation of hearing impairments. New technology, such as machine learning 
and multimodal signal processing, virtual reality and mobile health technology, 
will improve speech enhancement, individual fitting and communication training, 
thus providing better support for all hearing-impaired patients, including older 
patients with disabilities or declining cognitive skills.

Publisher: ZUSAMMENFASSUNG: HINTERGRUND: Die Hörgerätetechnologie hat sich bei 
der Rehabilitation von Hörverlusten als erfolgreich erwiesen, aber ihre Leistung 
ist unter schwierigen Alltagsbedingungen, die durch Lärm und Nachhall 
gekennzeichnet sind, immer noch begrenzt.
ZIELSETZUNG: Einführung in den aktuellen Stand der Hörgerätetechnologie und 
Darstellung des aktuellen Forschungsstandes und der zukünftigen Entwicklung.
METHODEN: Die aktuelle Literatur wird analysiert und mehrere spezifische 
Neuentwicklungen werden vorgestellt.
ERGEBNISSE: Sowohl objektive als auch subjektive Daten aus empirischen Studien 
zeigen die Grenzen der derzeitigen Technologie auf. Beispiele aus der aktuellen 
Forschung belegen das Potenzial von auf maschinellem Lernen basierenden 
Algorithmen und multimodaler Signalverarbeitung zur Verbesserung der 
Sprachverarbeitung und -wahrnehmung, der Nutzung von virtueller Realität zur 
Verbesserung der Hörgeräteanpassung und von mobiler Gesundheitstechnologie zur 
Verbesserung der Hörgesundheitsdienste.
SCHLUSSFOLGERUNG: Die Hörgerätetechnologie wird ein Schlüsselfaktor bei der 
Rehabilitation von Hörschäden bleiben. Neue Technologien wie maschinelles Lernen 
und multimodale Signalverarbeitung, virtuelle Realität und mobile 
Gesundheitstechnologien werden die Sprachverbesserung, die individuelle 
Anpassung und das Kommunikationstraining verbessern.

© 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
ein Teil von Springer Nature.

DOI: 10.1007/s00391-023-02179-y
PMID: 37103645 [Indexed for MEDLINE]


51. J Neurosci. 2024 Apr 17;44(16):e0963222024. doi: 10.1523/JNEUROSCI.0963-22.2024.

Age-Related Deficits in Binaural Hearing: Contribution of Peripheral and Central 
Effects.

Tolnai S(1)(2), Weiß M(3)(4)(5), Beutelmann R(6)(2), Bankstahl JP(4), Bovee 
S(6)(2), Ross TL(4), Berding G(3)(4), Klump GM(1)(2).

Author information:
(1)Animal Physiology and Behavior Group, Department of Neuroscience, School of 
Medicine and Health Sciences, Carl von Ossietzky University of Oldenburg, 
Oldenburg 26111, Germany sandra.tolnai@uol.de georg.klump@uol.de.
(2)Cluster of Excellence "Hearing4all", Oldenburg 26111, Germany.
(3)Cluster of Excellence "Hearing4all", Hannover 30625, Germany.
(4)Department of Nuclear Medicine, Hannover Medical School, Hannover 30625, 
Germany.
(5)The Calcium Signalling Group, Department of Biochemistry and Molecular Cell 
Biology, University Medical Center Hamburg-Eppendorf, Hamburg 20246, Germany.
(6)Animal Physiology and Behavior Group, Department of Neuroscience, School of 
Medicine and Health Sciences, Carl von Ossietzky University of Oldenburg, 
Oldenburg 26111, Germany.

Pure-tone audiograms often poorly predict elderly humans' ability to communicate 
in everyday complex acoustic scenes. Binaural processing is crucial for 
discriminating sound sources in such complex acoustic scenes. The compromised 
perception of communication signals presented above hearing threshold has been 
linked to both peripheral and central age-related changes in the auditory 
system. Investigating young and old Mongolian gerbils of both sexes, an 
established model for human hearing, we demonstrate age-related supra-threshold 
deficits in binaural hearing using behavioral, electrophysiological, anatomical, 
and imaging methods. Binaural processing ability was measured as the binaural 
masking level difference (BMLD), an established measure in human psychophysics. 
We tested gerbils behaviorally with "virtual headphones," recorded single-unit 
responses in the auditory midbrain and evaluated gross midbrain and cortical 
responses using positron emission tomography (PET) imaging. Furthermore, we 
obtained additional measures of auditory function based on auditory brainstem 
responses, auditory-nerve synapse counts, and evidence for central inhibitory 
processing revealed by PET. BMLD deteriorates already in middle-aged animals 
having normal audiometric thresholds and is even worse in old animals with 
hearing loss. The magnitude of auditory brainstem response measures related to 
auditory-nerve function and binaural processing in the auditory brainstem also 
deteriorate. Furthermore, central GABAergic inhibition is affected by age. 
Because the number of synapses in the apical turn of the inner ear was not 
reduced in middle-aged animals, we conclude that peripheral synaptopathy 
contributes little to binaural processing deficits. Exploratory analyses suggest 
increased hearing thresholds, altered binaural processing in the brainstem and 
changed central GABAergic inhibition as potential contributors.

Copyright © 2024 the authors.

DOI: 10.1523/JNEUROSCI.0963-22.2024
PMCID: PMC11026345
PMID: 38395618 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing financial 
interests.


52. J Control Release. 2024 Feb;366:460-478. doi: 10.1016/j.jconrel.2023.12.050. 
Epub 2024 Jan 11.

Extracellular vesicles for developing targeted hearing loss therapy.

Pan X(1), Li Y(2), Huang P(3), Staecker H(4), He M(5).

Author information:
(1)Department of Pharmaceutics, College of Pharmacy, University of Florida, 
Gainesville, Florida 32610, United States.
(2)Department of Medicinal Chemistry, Center for Natural Products, Drug 
Discovery and Development, University of Florida, Gainesville, Florida 32610, 
United States.
(3)Department of Otolaryngology, Head and Neck Surgery, University of Kansas 
School of Medicine, Kansas City, Kansas 66160, United States.
(4)Department of Otolaryngology, Head and Neck Surgery, University of Kansas 
School of Medicine, Kansas City, Kansas 66160, United States. Electronic 
address: hstaecker@kumc.edu.
(5)Department of Pharmaceutics, College of Pharmacy, University of Florida, 
Gainesville, Florida 32610, United States. Electronic address: mhe@cop.ufl.edu.

Substantial efforts have been made for local administration of small molecules 
or biologics in treating hearing loss diseases caused by either trauma, genetic 
mutations, or drug ototoxicity. Recently, extracellular vesicles (EVs) naturally 
secreted from cells have drawn increasing attention on attenuating hearing 
impairment from both preclinical studies and clinical studies. Highly emerging 
field utilizing diverse bioengineering technologies for developing EVs as the 
bioderived therapeutic materials, along with artificial intelligence (AI)-based 
targeting toolkits, shed the light on the unique properties of EVs specific to 
inner ear delivery. This review will illuminate such exciting research field 
from fundamentals of hearing protective functions of EVs to biotechnology 
advancement and potential clinical translation of functionalized EVs. 
Specifically, the advancements in assessing targeting ligands using AI 
algorithms are systematically discussed. The overall translational potential of 
EVs is reviewed in the context of auditory sensing system for developing next 
generation gene therapy.

Copyright © 2023. Published by Elsevier B.V.

DOI: 10.1016/j.jconrel.2023.12.050
PMID: 38182057 [Indexed for MEDLINE]


53. Sci Rep. 2022 Mar 10;12(1):3977. doi: 10.1038/s41598-022-07881-2.

Prediction of hearing recovery in unilateral sudden sensorineural hearing loss 
using artificial intelligence.

Lee MK(#)(1), Jeon ET(#)(2)(3), Baek N(2)(3), Kim JH(1), Rah YC(1), Choi J(4).

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, Korea University 
Ansan Hospital, College of Medicine, Korea University, 123, Jeokgeum-ro 
(Gojan-dong), Danwon-gu, Ansan-si, Gyeonggi-do, 15355, Republic of Korea.
(2)Department of Neurology, Korea University Ansan Hospital, College of 
Medicine, Korea University, Ansan, Republic of Korea.
(3)Medical Science Research Center, Korea University Ansan Hospital, Korea 
University College of Medicine, Ansan, Republic of Korea.
(4)Department of Otorhinolaryngology-Head and Neck Surgery, Korea University 
Ansan Hospital, College of Medicine, Korea University, 123, Jeokgeum-ro 
(Gojan-dong), Danwon-gu, Ansan-si, Gyeonggi-do, 15355, Republic of Korea. 
mednlaw@korea.ac.kr.
(#)Contributed equally

Despite the significance of predicting the prognosis of idiopathic sudden 
sensorineural hearing loss (ISSNHL), no predictive models have been established. 
This study used artificial intelligence to develop prognosis models to predict 
recovery from ISSNHL. We retrospectively reviewed the medical data of 453 
patients with ISSNHL (men, 220; women, 233; mean age, 50.3 years) who underwent 
treatment at a tertiary hospital between January 2021 and December 2019 and were 
followed up after 1 month. According to Siegel's criteria, 203 patients 
recovered in 1 month. Demographic characteristics, clinical and laboratory data, 
and pure-tone audiometry were analyzed. Logistic regression (baseline), a 
support vector machine, extreme gradient boosting, a light gradient boosting 
machine, and multilayer perceptron were used. The outcomes were the area under 
the receiver operating characteristic curve (AUROC) primarily, area under the 
precision-recall curve, Brier score, balanced accuracy, and F1 score. The light 
gradient boosting machine model had the best AUROC and balanced accuracy. 
Together with multilayer perceptron, it was also significantly superior to 
logistic regression in terms of AUROC. Using the SHapley Additive exPlanation 
method, we found that the initial audiogram shape is the most important 
prognostic factor. Machine/deep learning methods were successfully established 
to predict the prognosis of ISSNHL.

© 2022. The Author(s).

DOI: 10.1038/s41598-022-07881-2
PMCID: PMC8913667
PMID: 35273267 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


54. Cortex. 2020 Aug;129:266-280. doi: 10.1016/j.cortex.2020.04.022. Epub 2020 May 
16.

Age-related hearing loss influences functional connectivity of auditory cortex 
for the McGurk illusion.

Rosemann S(1), Smith D(2), Dewenter M(3), Thiel CM(4).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany; 
Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität Oldenburg, 
Oldenburg, Germany. Electronic address: Stephanie.rosemann@uni-oldenburg.de.
(2)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany. 
Electronic address: drsmith@bu.edu.
(3)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany. 
Electronic address: mariemhdw@aol.com.
(4)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany; 
Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität Oldenburg, 
Oldenburg, Germany. Electronic address: Christiane.thiel@uol.de.

Age-related hearing loss affects hearing at high frequencies and is associated 
with difficulties in understanding speech. Increased audio-visual integration 
has recently been found in age-related hearing impairment, the brain mechanisms 
that contribute to this effect are however unclear. We used functional magnetic 
resonance imaging in elderly subjects with normal hearing and mild to moderate 
uncompensated hearing loss. Audio-visual integration was studied using the 
McGurk task. In this task, an illusionary fused percept can occur if incongruent 
auditory and visual syllables are presented. The paradigm included unisensory 
stimuli (auditory only, visual only), congruent audio-visual and incongruent 
(McGurk) audio-visual stimuli. An illusionary precept was reported in over 60% 
of incongruent trials. These McGurk illusion rates were equal in both groups of 
elderly subjects and correlated positively with speech-in-noise perception and 
daily listening effort. Normal-hearing participants showed an increased neural 
response in left pre- and postcentral gyri and right middle frontal gyrus for 
incongruent stimuli (McGurk) compared to congruent audio-visual stimuli. 
Activation patterns were however not different between groups. Task-modulated 
functional connectivity differed between groups showing increased connectivity 
from auditory cortex to visual, parietal and frontal areas in hard of hearing 
participants as compared to normal-hearing participants when comparing 
incongruent stimuli (McGurk) with congruent audio-visual stimuli. These results 
suggest that changes in functional connectivity of auditory cortex rather than 
activation strength during processing of audio-visual McGurk stimuli accompany 
age-related hearing loss.

Copyright © 2020 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2020.04.022
PMID: 32535378 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no competing interests.


55. Disabil Rehabil. 2018 May;40(10):1166-1175. doi: 10.1080/09638288.2017.1290698. 
Epub 2017 Feb 25.

Pure tone hearing profiles in children with otitis media with effusion.

Cai T(1), McPherson B(1), Li C(2), Yang F(3).

Author information:
(1)a Division of Speech and Hearing Sciences, Faculty of Education , The 
University of Hong Kong , Hong Kong , China.
(2)b Department of Otorhinolaryngology , Shenzhen Children's Hospital , Shenzhen 
, China.
(3)c Department of Speech Therapy , Shenzhen Children's Hospital , Shenzhen , 
China.

INTRODUCTION: Otitis media with effusion (OME) is a common middle ear disease in 
children. The associated conductive hearing loss is a major concern for hearing 
health professionals. The aim of the present study was to describe the 
configuration of pure tone audiograms of children with OME and to design a 
statistical stratification algorithm to facilitate hearing loss profiling in 
children with OME.
METHODS: School age children with OME were recruited. Bone and air conduction 
thresholds were obtained using standard procedures. Hierarchical cluster 
analysis was employed to determine audiometric profile groups. The Mandarin 
Hearing in Noise Test was used to measure sentence perception in children for 
cluster analysis validity assessment.
RESULTS: Ninety-seven children (164 ears) aged between 72 months and 153 months 
were examined. Air conduction thresholds averaged for 500 Hz, 1000 Hz and 
2000 Hz were in the range of 8.3-53.3 dB HL with a mean of 26.8 dB HL. Bone 
conduction thresholds were found to be influenced by middle ear pathology with a 
maximal elevation at 2000 Hz of 25 dB HL. Four audiometric profiles were 
identified. Cluster 1 contained 54 ears (32.9%) with normal or near normal 
hearing, Clusters 2 contained 37 ears (22.6%) with mild hearing loss, Cluster 3 
included 48 ears (29.3%) and Cluster 4 included 25 ears (15.2%) with moderate 
hearing loss. Stability and validity of the four-cluster profiling procedure was 
examined and established with satisfactory results.
CONCLUSIONS: OME in children is associated with pure tone hearing thresholds 
ranging from normal to moderate hearing loss. The hierarchical clustering 
algorithm proved useful as a novel means of profiling hearing loss in children 
with OME and may assist in identifying affected children at greater risk of 
auditory disadvantage. Implications for rehabilitation A hierarchical cluster 
analysis method can be used to determine audiometric profiles in children with 
OME. This algorithm assists to identify children at greater risk of auditory 
disadvantage. Cluster groups with more elevated pure tone thresholds may be 
targeted for priority in clinical surveillance and medical/surgical 
intervention.

DOI: 10.1080/09638288.2017.1290698
PMID: 28637148 [Indexed for MEDLINE]


56. J Assoc Res Otolaryngol. 2023 Oct;24(5):499-511. doi: 
10.1007/s10162-023-00909-y. Epub 2023 Nov 13.

Neural Degeneration in Normal-Aging Human Cochleas: Machine-Learning Counts and 
3D Mapping in Archival Sections.

Wu PZ(1)(2), O'Malley JT(3)(4), Liberman MC(3)(4).

Author information:
(1)Eaton-Peabody Laboratories, Massachusetts Eye and Ear Infirmary, 243 Charles 
St., Boston, MA, 02114-3096, USA. Peizhe-Wu@uiowa.edu.
(2)Department of Otolaryngology, Harvard Medical School, Boston, MA, 02115, USA. 
Peizhe-Wu@uiowa.edu.
(3)Eaton-Peabody Laboratories, Massachusetts Eye and Ear Infirmary, 243 Charles 
St., Boston, MA, 02114-3096, USA.
(4)Department of Otolaryngology, Harvard Medical School, Boston, MA, 02115, USA.

Quantifying the survival patterns of spiral ganglion cells (SGCs), the cell 
bodies of auditory-nerve fibers, is critical to studies of sensorineural hearing 
loss, especially in human temporal bones. The classic method of manual counting 
is tedious, and, although stereology approaches can be faster, they can only be 
used to estimate total cell numbers per cochlea. Here, a machine-learning 
algorithm that automatically identifies, counts, and maps the SGCs in digitized 
images of semi-serial human temporal-bone sections not only speeds the analysis, 
with no loss of accuracy, but also allows 3D visualization of the SGCs and 
fine-grained mapping to cochlear frequency. Applying the algorithm to 62 
normal-aging human ears shows significantly faster degeneration of SGCs in the 
basal than the apical half of the cochlea. Comparison to fiber counts in the 
same ears shows that the fraction of surviving SGCs lacking a peripheral axon 
steadily increases with age, reaching more than 50% in the apical cochlea and 
almost 66% in basal regions.

© 2023. The Author(s) under exclusive licence to Association for Research in 
Otolaryngology.

DOI: 10.1007/s10162-023-00909-y
PMCID: PMC10695900
PMID: 37957485 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


57. HNO. 2017 Aug;65(Suppl 2):130-135. doi: 10.1007/s00106-016-0318-4.

Prevalence of hearing loss in Northern and Southern Germany.

[Article in English]

von Gablenz P(1), Hoffmann E(2), Holube I(3).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4All", Oldenburg, Germany. 
petra.vongablenz@jade-hs.de.
(2), Kempten (Allgäu), Germany.
(3)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4All", Oldenburg, Germany.

BACKGROUND: The HÖRSTAT study conducted in Northwest Germany found hearing 
impairment in approximately 16% of adults when applying the World Health 
Organization (WHO) criterion. However, the robustness of extrapolations to 
a national level might be questioned, as the epidemiological data were collected 
on a regional level.
METHODS: Independently from HÖRSTAT, the "Hearing in Germany" study examined 
adult hearing in Aalen, a town located in Southwest Germany. Both 
cross-sectional studies were based on stratified random samples from the general 
population. The average pure-tone threshold shift at 0.5, 1, 2, and 4 kHz 
(PTA4), the prevalence of hearing impairment (WHO criterion: PTA4 in the better 
ear >25), and hearing aid uptake were compared. Data from the Aalen and HÖRSTAT 
studies were pooled (n = 3105) to extrapolate to the prevalence and the degree 
of hearing impairment for the years 2015, 2020, and 2025.
RESULTS: Both studies yielded very similar results for PTA4. Weighted for 
official population statistics, the prevalence of hearing impairment according 
to the WHO criterion is 16.2% in adults, thus affecting 11.1 million persons in 
Germany. Owing to demographic changes, the prevalence is expected to increase in 
the medium term by around 1% per 5‑year period. With a similar degree of hearing 
loss, hearing aid provision differs from place to place.
CONCLUSION: When adjusted for gender and age to the European Standard 
Population, the prevalence of hearing impairment observed both in HÖRSTAT and 
the Aalen sample is considerably lower than reported for international studies. 
Since the analysis refers to cross-sectional data only, possible cohort effects 
are not considered in the prevalence projection.

DOI: 10.1007/s00106-016-0318-4
PMID: 28477091 [Indexed for MEDLINE]


58. Int J Audiol. 2017 Jul;56(7):443-452. doi: 10.1080/14992027.2017.1294767. Epub 
2017 Mar 1.

Social inequalities in pure-tone hearing assessed using occupational 
stratification schemes.

von Gablenz P(1), Holube I(1).

Author information:
(1)a Institute of Hearing Technology and Audiology , Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4All" , Oldenburg , Germany.

OBJECTIVE: The objective of this study is to analyse the performance of two 
occupational stratification approaches and the impact of social position on 
adult hearing.
DESIGN: The prevalence of hearing impairment, pure-tone averages (PTA) and 
prevalence ratios (PR) for relative hearing loss, which focuses on the position 
of one's PTA in the age- and gender-specific distribution, were compared in 
groups defined by ISCO Skill Level and the International Socio-Economic Index 
(ISEI).
STUDY SAMPLE: About 1571 subjects aged 30-89, including 677 highly screened 
adults, from the cross-sectional study HÖRSTAT.
RESULTS: ISCO Skill Level and ISEI yielded qualitatively the same results. The 
prevalence difference between the socially least and most advantaged group 
ranges between 10 and 16%, varying with the scheme applied. Low- and 
high-frequency PTA and PR for relative hearing loss confirm the gradient. 
Screening reduced, but did not negate the social differences. The prevalence 
difference dropped to 6-7% in the otologically normal subsample.
CONCLUSIONS: Social groups defined by hierarchical, occupational measures differ 
in their pure-tone hearing, even if the main risk factors are controlled for. 
This underlines the need for population-based sampling, the relevance of 
reporting the study group's social composition and the importance of advancing 
the discussion on appropriate social measures in hearing research.

DOI: 10.1080/14992027.2017.1294767
PMID: 28635505 [Indexed for MEDLINE]


59. Otolaryngol Head Neck Surg. 2023 Sep;169(3):504-513. doi: 10.1002/ohn.288. Epub 
2023 Feb 9.

Machine Learning Prediction of Objective Hearing Loss With Demographics, 
Clinical Factors, and Subjective Hearing Status.

Gathman TJ(1)(2), Choi JS(3), Vasdev RMS(1)(2), Schoephoerster JA(1), Adams 
ME(3).

Author information:
(1)School of Medicine, University of Minnesota, Minnesota, Minneapolis, USA.
(2)Department of Biomedical Engineering, University of Minnesota, Minneapolis, 
Minnesota, USA.
(3)Department of Otolaryngology, University of Minnesota, Minneapolis, 
Minnesota, USA.

OBJECTIVE: Hearing loss (HL) is highly prevalent, yet underrecognized and 
underdiagnosed. Lack of standardized screening, awareness, cost, and access to 
hearing testing present barriers to HL identification. To facilitate 
prescreening and selection of patients who warrant audiometric evaluation, we 
developed a machine learning (ML) model to predict speech-frequency pure-tone 
average (PTA).
STUDY DESIGN: Cross-sectional study.
SETTING: National Health and Nutrition Examination Survey (NHANES).
METHODS: The cohort included 8918 adults (≥20 years) who completed audiometric 
testing with NHANES (2012-2018). The primary outcome measure was the prediction 
of better hearing ear speech-frequency PTA. Relevant predictors included 
demographics, medical conditions, and subjective assessment of hearing. 
Supervised ML with a tree-based architecture was used. Regression performance 
was determined by the mean absolute error (MAE) with binary classification 
assessed with area under the receiver operating characteristic curve (AUC).
RESULTS: Using the full set of predictors, the test set MAE between the 
ML-predicted and actual PTA was 5.29 dB HL (95% confidence interval [CI]: 
4.97-5.61). The 5 most influential predictors of higher PTA were increased age, 
worse subjective hearing, male gender, increased body mass index, and history of 
smoking. The 5-factor abbreviated model performed comparably to the extended 
feature set with MAE 5.36 (95% CI: 5.03-5.69) and AUC for PTA > 25 dB HL of 0.92 
(95% CI: 0.90-0.94).
CONCLUSION: The ML model was able to predict PTA with patient demographics, 
clinical factors, and subjective hearing status. ML-based prediction may be used 
to identify individuals who could benefit most from audiometric evaluation.

© 2023 The Authors. Otolaryngology-Head and Neck Surgery published by Wiley 
Periodicals LLC on behalf of American Academy of Otolaryngology-Head and Neck 
Surgery Foundation.

DOI: 10.1002/ohn.288
PMID: 36758959 [Indexed for MEDLINE]


60. Neural Plast. 2021 Jun 4;2021:8840452. doi: 10.1155/2021/8840452. eCollection 
2021.

Relationship between Memory Load and Listening Demands in Age-Related Hearing 
Impairment.

Pauquet J(1), Thiel CM(1)(2), Mathys C(3)(4), Rosemann S(1)(2).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität, 26111 Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany.
(3)Institute of Radiology and Neuroradiology, Evangelisches Krankenhaus, Carl 
von Ossietzky Universität Oldenburg, 26122 Oldenburg, Germany.
(4)Research Center Neurosensory Science, Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany.

Age-related hearing loss has been associated with increased recruitment of 
frontal brain areas during speech perception to compensate for the decline in 
auditory input. This additional recruitment may bind resources otherwise needed 
for understanding speech. However, it is unknown how increased demands on 
listening interact with increasing cognitive demands when processing speech in 
age-related hearing loss. The current study used a full-sentence working memory 
task manipulating demands on working memory and listening and studied untreated 
mild to moderate hard of hearing (n = 20) and normal-hearing age-matched 
participants (n = 19) with functional MRI. On the behavioral level, we found a 
significant interaction of memory load and listening condition; this was, 
however, similar for both groups. Under low, but not high memory load, listening 
condition significantly influenced task performance. Similarly, under easy but 
not difficult listening conditions, memory load had a significant effect on task 
performance. On the neural level, as measured by the BOLD response, we found 
increased responses under high compared to low memory load conditions in the 
left supramarginal gyrus, left middle frontal gyrus, and left supplementary 
motor cortex regardless of hearing ability. Furthermore, we found increased 
responses in the bilateral superior temporal gyri under easy compared to 
difficult listening conditions. We found no group differences nor interactions 
of group with memory load or listening condition. This suggests that memory load 
and listening condition interacted on a behavioral level, however, only the 
increased memory load was reflected in increased BOLD responses in frontal and 
parietal brain regions. Hence, when evaluating listening abilities in elderly 
participants, memory load should be considered as it might interfere with the 
assessed performance. We could not find any further evidence that BOLD responses 
for the different memory and listening conditions are affected by mild to 
moderate age-related hearing loss.

Copyright © 2021 Julia Pauquet et al.

DOI: 10.1155/2021/8840452
PMCID: PMC8195652
PMID: 34188676 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


61. Trends Hear. 2018 Jan-Dec;22:2331216518807400. doi: 10.1177/2331216518807400.

Data-Driven Approach for Auditory Profiling and Characterization of Individual 
Hearing Loss.

Sanchez Lopez R(1), Bianchi F(1), Fereczkowski M(1), Santurette S(1)(2), Dau 
T(1).

Author information:
(1)1 Hearing Systems Group, Department of Electrical Engineering, Technical 
University of Denmark, Kongens Lyngby, Denmark.
(2)2 Department of Otorhinolaryngology, Head and Neck Surgery and Audiology, 
Rigshospitalet, Copenhagen, Denmark.

Pure-tone audiometry still represents the main measure to characterize 
individual hearing loss and the basis for hearing-aid fitting. However, the 
perceptual consequences of hearing loss are typically associated not only with a 
loss of sensitivity but also with a loss of clarity that is not captured by the 
audiogram. A detailed characterization of a hearing loss may be complex and 
needs to be simplified to efficiently explore the specific compensation needs of 
the individual listener. Here, it is hypothesized that any listener's hearing 
profile can be characterized along two dimensions of distortion: Type I and Type 
II. While Type I can be linked to factors affecting audibility, Type II reflects 
non-audibility-related distortions. To test this hypothesis, the individual 
performance data from two previous studies were reanalyzed using an 
unsupervised-learning technique to identify extreme patterns in the data, thus 
forming the basis for different auditory profiles. Next, a decision tree was 
determined to classify the listeners into one of the profiles. The analysis 
provides evidence for the existence of four profiles in the data. The most 
significant predictors for profile identification were related to binaural 
processing, auditory nonlinearity, and speech-in-noise perception. This approach 
could be valuable for analyzing other data sets to select the most relevant 
tests for auditory profiling and propose more efficient hearing-deficit 
compensation strategies.

DOI: 10.1177/2331216518807400
PMCID: PMC6236853
PMID: 30384803 [Indexed for MEDLINE]


62. Dement Geriatr Cogn Disord. 2021;50(4):394-400. doi: 10.1159/000519291. Epub 
2021 Sep 30.

Peripheral Hearing Loss and Its Association with Cognition among Ethnic Chinese 
Older Adults.

Nicholas SO(1), Koh EJ(1), Wee SL(1)(2)(3), Eikelboom RH(4)(5)(6), Jayakody 
DMP(4)(5), Lin F(7)(8), Ng TP(1)(9), Heywood RL(4)(5)(10)(11).

Author information:
(1)Geriatric Education and Research Institute (GERI), Singapore, Singapore.
(2)Singapore Institute of Technology, Health and Social Sciences Cluster, 
Singapore, Singapore.
(3)Duke-NUS Medical School, Singapore, Singapore.
(4)Ear Science Institute Australia, Subiaco, Washington, Australia.
(5)Ear Sciences Centre, Medical School, The University of Western Australia, 
Subiaco, Washington, Australia.
(6)Department of Speech Language Pathology and Audiology, University of 
Pretoria, Pretoria, South Africa.
(7)Cochlear Center for Hearing and Public Health, Johns Hopkins Bloomberg School 
of Public Health, Baltimore, Maryland, USA.
(8)Departments of Otolaryngology, Medicine, Mental Health, and Epidemiology, 
Johns Hopkins University, Baltimore, Maryland, USA.
(9)Department of Psychological Medicine, Gerontology Research Program, National 
University of Singapore (NUS), Singapore, Singapore.
(10)Department of Otolaryngology, Ng Teng Fong General Hospital, Singapore, 
Singapore.
(11)Yong Loo Lin School of Medicine, National University of Singapore, 
Singapore, Singapore.

INTRODUCTION: Many studies on hearing loss (HL) and cognition are limited by 
subjective hearing assessments and verbally administered cognition tests, the 
majority of the document findings in Western populations. This study aimed to 
assess the association of HL with cognitive impairment among ethnic Chinese 
Singaporean older adults using visually presented cognitive tests.
METHODS: The hearing of community-dwelling older adults was assessed using pure 
tone audiometry. Cognitive function was assessed using the Computerized 
Cambridge Cognitive Test Battery (CANTAB). Multiple regression analyses examined 
the association between hearing and cognitive function, adjusted for age, 
education, and gender.
RESULTS: HL (pure-tone average [PTA] of thresholds at 0.5, 1, 2, and 4 kHz in 
the better ear, BE4PTA) was associated with reduced performance in delayed 
matching and multitasking tasks (β = -0.25, p = 0.019, and β = 0.02, p = 0.023, 
respectively). Moderate to severe HL was associated with reduced performance in 
delayed matching and verbal recall memory tasks (β = -10.6, p = 0.019, and β = 
-0.28, p = 0.042). High-frequency HL was associated with reduced performance in 
the spatial working memory task (β = 0.004, p = 0.022). All-frequency HL was 
associated with reduced performance in spatial working memory and multitasking 
(β = 0.01, p = 0.040, and β = 0.02, p = 0.048).
CONCLUSION: Similar to Western populations, HL among tonal language-speaking 
ethnic Chinese was associated with worse performance in tasks requiring working 
memory and executive function.

© 2021 The Author(s). Published by S. Karger AG, Basel.

DOI: 10.1159/000519291
PMID: 34592737 [Indexed for MEDLINE]


63. Brain Struct Funct. 2023 Jul;228(6):1511-1534. doi: 10.1007/s00429-023-02669-0. 
Epub 2023 Jun 22.

The neuroanatomical hallmarks of chronic tinnitus in comorbidity with pure-tone 
hearing loss.

Elmer S(#)(1)(2), Schmitt R(#)(3), Giroud N(3)(4)(5), Meyer M(6)(7)(8)(9).

Author information:
(1)Department of Computational Linguistics, Computational Neuroscience of Speech 
& Hearing, University of Zurich, Zurich, Switzerland. stefan.elmer@uzh.ch.
(2)Competence Center Language & Medicine, University of Zurich, Zurich, 
Switzerland. stefan.elmer@uzh.ch.
(3)Department of Computational Linguistics, Computational Neuroscience of Speech 
& Hearing, University of Zurich, Zurich, Switzerland.
(4)Center for Neuroscience Zurich, University and ETH of Zurich, Zurich, 
Switzerland.
(5)Competence Center Language & Medicine, University of Zurich, Zurich, 
Switzerland.
(6)Department of Comparative Language Science, University of Zurich, Zurich, 
Switzerland. martin.meyer@uzh.ch.
(7)Center for Neuroscience Zurich, University and ETH of Zurich, Zurich, 
Switzerland. martin.meyer@uzh.ch.
(8)Center for the Interdisciplinary Study of Language Evolution (ISLE), 
University of Zurich, Zurich, Switzerland. martin.meyer@uzh.ch.
(9)Cognitive Psychology Unit, Alpen-Adria University, Klagenfurt, Austria. 
martin.meyer@uzh.ch.
(#)Contributed equally

Tinnitus is one of the main hearing impairments often associated with pure-tone 
hearing loss, and typically manifested in the perception of phantom sounds. 
Nevertheless, tinnitus has traditionally been studied in isolation without 
necessarily considering auditory ghosting and hearing loss as part of the same 
syndrome. Hence, in the present neuroanatomical study, we attempted to pave the 
way toward a better understanding of the tinnitus syndrome, and compared two 
groups of almost perfectly matched individuals with (TIHL) and without (NTHL) 
pure-tone tinnitus, but both characterized by pure-tone hearing loss. The two 
groups were homogenized in terms of sample size, age, gender, handedness, 
education, and hearing loss. Furthermore, since the assessment of pure-tone 
hearing thresholds alone is not sufficient to describe the full spectrum of 
hearing abilities, the two groups were also harmonized for supra-threshold 
hearing estimates which were collected using temporal compression, frequency 
selectivity und speech-in-noise tasks. Regions-of-interest (ROI) analyses based 
on key brain structures identified in previous neuroimaging studies showed that 
the TIHL group exhibited increased cortical volume (CV) and surface area (CSA) 
of the right supramarginal gyrus and posterior planum temporale (PT) as well as 
CSA of the left middle-anterior part of the superior temporal sulcus (STS). The 
TIHL group also demonstrated larger volumes of the left amygdala and of the left 
head and body of the hippocampus. Notably, vertex-wise multiple linear 
regression analyses additionally brought to light that CSA of a specific 
cluster, which was located in the left middle-anterior part of the STS and 
overlapped with the one found to be significant in the between-group analyses, 
was positively associated with tinnitus distress level. Furthermore, distress 
also positively correlated with CSA of gray matter vertices in the right dorsal 
prefrontal cortex and the right posterior STS, whereas tinnitus duration was 
positively associated with CSA and CV of the right angular gyrus (AG) and 
posterior part of the STS. These results provide new insights into the critical 
gray matter architecture of the tinnitus syndrome matrix responsible for the 
emergence, maintenance and distress of auditory phantom sensations.

© 2023. The Author(s).

DOI: 10.1007/s00429-023-02669-0
PMCID: PMC10335971
PMID: 37349539 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


64. Sci Rep. 2019 Feb 20;9(1):2337. doi: 10.1038/s41598-019-38816-z.

The effect of age-related hearing loss and listening effort on resting state 
connectivity.

Rosemann S(1)(2), Thiel CM(3)(4).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany. 
Stephanie.rosemann@uni-oldenburg.de.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany. Stephanie.rosemann@uni-oldenburg.de.
(3)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany.
(4)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany.

Age-related hearing loss is associated with a decrease in hearing abilities for 
high frequencies. This increases not only the difficulty to understand speech 
but also the experienced listening effort. Task based neuroimaging studies in 
normal-hearing and hearing-impaired participants show an increased frontal 
activation during effortful speech perception in the hearing-impaired. Whether 
the increased effort in everyday listening in hearing-impaired even impacts 
functional brain connectivity at rest is unknown. Nineteen normal-hearing and 
nineteen hearing-impaired participants with mild to moderate hearing loss 
participated in the study. Hearing abilities, listening effort and resting state 
functional connectivity were assessed. Our results indicate no differences in 
functional connectivity between hearing-impaired and normal-hearing 
participants. Increased listening effort, however, was related to significantly 
decreased functional connectivity between the dorsal attention network and the 
precuneus and superior parietal lobule as well as between the auditory and the 
inferior frontal cortex. We conclude that already mild to moderate age-related 
hearing loss can impact resting state functional connectivity. It is however not 
the hearing loss itself but the individually perceived listening effort that 
relates to functional connectivity changes.

DOI: 10.1038/s41598-019-38816-z
PMCID: PMC6382886
PMID: 30787339 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


65. Elife. 2023 May 10;12:e85108. doi: 10.7554/eLife.85108.

Large-scale electrophysiology and deep learning reveal distorted neural signal 
dynamics after hearing loss.

Sabesan S(1), Fragner A(2), Bench C(1), Drakopoulos F(1), Lesica NA(1).

Author information:
(1)Ear Institute, University College London, London, United Kingdom.
(2)Perceptual Technologies, London, United Kingdom.

Update of
    doi: 10.1101/2022.10.04.510811.

Listeners with hearing loss often struggle to understand speech in noise, even 
with a hearing aid. To better understand the auditory processing deficits that 
underlie this problem, we made large-scale brain recordings from gerbils, a 
common animal model for human hearing, while presenting a large database of 
speech and noise sounds. We first used manifold learning to identify the neural 
subspace in which speech is encoded and found that it is low-dimensional and 
that the dynamics within it are profoundly distorted by hearing loss. We then 
trained a deep neural network (DNN) to replicate the neural coding of speech 
with and without hearing loss and analyzed the underlying network dynamics. We 
found that hearing loss primarily impacts spectral processing, creating 
nonlinear distortions in cross-frequency interactions that result in a 
hypersensitivity to background noise that persists even after amplification with 
a hearing aid. Our results identify a new focus for efforts to design improved 
hearing aids and demonstrate the power of DNNs as a tool for the study of 
central brain structures.

© 2023, Sabesan et al.

DOI: 10.7554/eLife.85108
PMCID: PMC10202456
PMID: 37162188 [Indexed for MEDLINE]

Conflict of interest statement: SS, AF, CB, FD No competing interests declared, 
NL is a co-founder of Perceptual Technologies


66. Hear Res. 2014 Oct;316:28-36. doi: 10.1016/j.heares.2014.07.005. Epub 2014 Jul 
28.

Age-related hearing loss increases cross-modal distractibility.

Puschmann S(1), Sandmann P(2), Bendixen A(3), Thiel CM(4).

Author information:
(1)Biological Psychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany. Electronic address: 
sebastian.puschmann@uni-oldenburg.de.
(2)Central Auditory Diagnostics Lab, Department of Neurology, Cluster of 
Excellence "Hearing4all", Hannover Medical School, Hannover, Germany.
(3)Auditory Psychophysiology Lab, Department of Psychology, Cluster of 
Excellence "Hearing4all", European Medical School, Carl von Ossietzky 
Universität Oldenburg, Oldenburg, Germany; Research Center Neurosensory Science, 
Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany.
(4)Biological Psychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, Carl von Ossietzky Universität 
Oldenburg, 26111 Oldenburg, Germany; Research Center Neurosensory Science, Carl 
von Ossietzky Universität Oldenburg, Oldenburg, Germany.

Recent electrophysiological studies have provided evidence that changes in 
multisensory processing in auditory cortex cannot only be observed following 
extensive hearing loss, but also in moderately hearing-impaired subjects. How 
the reduced auditory input affects audio-visual interactions is however largely 
unknown. Here we used a cross-modal distraction paradigm to investigate 
multisensory processing in elderly participants with an age-related 
high-frequency hearing loss as compared to young and elderly subjects with 
normal hearing. During the experiment, participants were simultaneously 
presented with independent streams of auditory and visual input and were asked 
to categorize either the auditory or visual information while ignoring the other 
modality. Unisensory sequences without any cross-modal input served as control 
conditions to assure that all participants were able to perform the task. While 
all groups performed similarly in these unisensory conditions, hearing-impaired 
participants showed significantly increased error rates when confronted with 
distracting cross-modal stimulation. This effect could be observed in both the 
auditory and the visual task. Supporting these findings, an additional 
regression analysis indicted that the degree of high-frequency hearing loss 
significantly modulates cross-modal visual distractibility in the auditory task. 
These findings provide new evidence that already a moderate sub-clinical hearing 
loss, a common phenomenon in the elderly population, affects the processing of 
audio-visual information.

Copyright © 2014 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2014.07.005
PMID: 25080386 [Indexed for MEDLINE]


67. Trends Hear. 2023 Jan-Dec;27:23312165231209913. doi: 10.1177/23312165231209913.

Sixty Years of Frequency-Domain Monaural Speech Enhancement: From Traditional to 
Deep Learning Methods.

Zheng C(1)(2), Zhang H(1)(2), Liu W(1)(2), Luo X(1)(2), Li A(1)(2), Li X(1)(2), 
Moore BCJ(3).

Author information:
(1)Key Laboratory of Noise and Vibration Research, Institute of Acoustics, 
Chinese Academy of Sciences, Beijing, China.
(2)University of Chinese Academy of Sciences, Beijing, China.
(3)Cambridge Hearing Group, Department of Psychology, University of Cambridge, 
Cambridge, UK.

Frequency-domain monaural speech enhancement has been extensively studied for 
over 60 years, and a great number of methods have been proposed and applied to 
many devices. In the last decade, monaural speech enhancement has made 
tremendous progress with the advent and development of deep learning, and 
performance using such methods has been greatly improved relative to traditional 
methods. This survey paper first provides a comprehensive overview of 
traditional and deep-learning methods for monaural speech enhancement in the 
frequency domain. The fundamental assumptions of each approach are then 
summarized and analyzed to clarify their limitations and advantages. A 
comprehensive evaluation of some typical methods was conducted using the WSJ + 
Deep Noise Suppression (DNS) challenge and Voice Bank + DEMAND datasets to give 
an intuitive and unified comparison. The benefits of monaural speech enhancement 
methods using objective metrics relevant for normal-hearing and hearing-impaired 
listeners were evaluated. The objective test results showed that compression of 
the input features was important for simulated normal-hearing listeners but not 
for simulated hearing-impaired listeners. Potential future research and 
development topics in monaural speech enhancement are suggested.

DOI: 10.1177/23312165231209913
PMCID: PMC10658184
PMID: 37956661 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting InterestsThe authors 
declared no potential conflicts of interest with respect to the research, 
authorship, and/or publication of this article.


68. J Assoc Res Otolaryngol. 2017 Apr;18(2):371-385. doi: 10.1007/s10162-016-0596-2. 
Epub 2016 Nov 9.

Longitudinal Changes in Audiometric Phenotypes of Age-Related Hearing Loss.

Vaden KI Jr(1), Matthews LJ(2), Eckert MA(2), Dubno JR(3).

Author information:
(1)Hearing Research Program, Department of Otolaryngology-Head and Neck Surgery, 
Medical University of South Carolina, 135 Rutledge Avenue, MSC 550, Charleston, 
SC, 29425-5500, USA. vaden@musc.edu.
(2)Hearing Research Program, Department of Otolaryngology-Head and Neck Surgery, 
Medical University of South Carolina, 135 Rutledge Avenue, MSC 550, Charleston, 
SC, 29425-5500, USA.
(3)Hearing Research Program, Department of Otolaryngology-Head and Neck Surgery, 
Medical University of South Carolina, 135 Rutledge Avenue, MSC 550, Charleston, 
SC, 29425-5500, USA. dubnojr@musc.edu.

Presbyacusis, or age-related hearing loss, can be characterized in humans as 
metabolic and sensory phenotypes, based on patterns of audiometric thresholds 
that were established in animal models. The metabolic phenotype is thought to 
result from deterioration of the cochlear lateral wall and reduced endocochlear 
potential that decreases cochlear amplification and produces a mild, flat 
hearing loss at lower frequencies coupled with a gradually sloping hearing loss 
at higher frequencies. The sensory phenotype, resulting from environmental 
exposures such as excessive noise or ototoxic drugs, involves damage to sensory 
and non-sensory cells and loss of the cochlear amplifier, which produces a 
50-70 dB threshold shift at higher frequencies. The mixed metabolic + sensory 
phenotype exhibits a mix of lower frequency, sloping hearing loss similar to the 
metabolic phenotype, and steep, higher frequency hearing loss similar to the 
sensory phenotype. The current study examined audiograms collected 
longitudinally from 343 adults 50-93 years old (n = 686 ears) to test the 
hypothesis that metabolic phenotypes increase with increasing age, in contrast 
with the sensory phenotype. A Quadratic Discriminant Analysis (QDA) was used to 
classify audiograms from each of these ears as (1) Older-Normal, (2) Metabolic, 
(3) Sensory, or (4) Metabolic + Sensory phenotypes. Although hearing loss 
increased systematically with increasing age, audiometric phenotypes remained 
stable for the majority of ears (61.5 %) over an average of 5.5 years. Most of 
the participants with stable phenotypes demonstrated matching phenotypes for the 
left and right ears. Audiograms were collected over an average period of 8.2 
years for ears with changing audiometric phenotypes, and the majority of those 
ears transitioned to a Metabolic or Metabolic + Sensory phenotype. These results 
are consistent with the conclusion that the likelihood of metabolic presbyacusis 
increases with increasing age in middle to older adulthood.

DOI: 10.1007/s10162-016-0596-2
PMCID: PMC5352606
PMID: 27830350 [Indexed for MEDLINE]

Conflict of interest statement: The authors state that they have no conflict of 
interest to declare.


69. Eur J Med Genet. 2022 Feb;65(2):104406. doi: 10.1016/j.ejmg.2021.104406. Epub 
2021 Dec 27.

Novel CRISPR/Cas12a-based genetic diagnostic approach for SLC26A4 
mutation-related hereditary hearing loss.

Jin X(1), Zhang L(1), Wang X(2), An L(1), Huang S(3), Dai P(3), Gao H(4), Ma 
X(5).

Author information:
(1)National Research Institute for Family Planning, Beijing, China; National 
Human Genetic Resources Center, Beijing, China.
(2)Shanghai Institute for Advanced Immunochemical Studies, ShanghaiTech 
University, Shanghai, China; School of Life Science and Technology, ShanghaiTech 
University, Shanghai, China.
(3)Department of Otolaryngology, PLA General Hospital, Beijing, China.
(4)National Research Institute for Family Planning, Beijing, China; National 
Human Genetic Resources Center, Beijing, China. Electronic address: 
gaohuafang@nrifp.org.cn.
(5)National Research Institute for Family Planning, Beijing, China; National 
Human Genetic Resources Center, Beijing, China. Electronic address: 
genetic@263.net.cn.

Hereditary hearing loss is a common defect of the auditory nervous system with 
high-incidence, seriously affecting the quality of life of the patients. The 
clinical manifestations of SLC26A4 mutation-related hearing loss are congenital 
sensorineural or mixed deafness. Sensitive and specific SLC26A4 mutation 
detection in the early clinical stage is key for the early indication of 
potential hearing loss in the lack of effective treatment. Using clustered 
regularly interspaced short palindromic repeats (CRISPR)-based nucleic acid 
detection technology, we designed a fast and sensitive detection system for 
SLC26A4 pathogenic mutations (c.919-2A > G, c.2168A > G and c.1229C > T). This 
recombinase-aided amplification-based detection system allows rapid target gene 
amplification and, in combination with the CRISPR-based nucleic acid testing 
(NAT) system, mutation site detection. Moreover, mismatches were introduced in 
CRISPR-derived RNA (crRNA) to increase signal differences between the wild-type 
genes and mutant genes. A total of 64 samples were examined using this approach 
and all results were verified using Sanger sequencing. The detection results 
were consistent with the polymerase chain reaction-Sanger sequencing results. 
Overall, this CRISPR-based NAT technology provides a sensitive and fast new 
approach for the detection of hereditary deafness and provides a crRNA 
optimization strategy for single-nucleotide polymorphism detection, which could 
be helpful for the clinical diagnosis of SLC26A4 mutation-related hereditary 
hearing loss.

Copyright © 2021. Published by Elsevier Masson SAS.

DOI: 10.1016/j.ejmg.2021.104406
PMID: 34968750 [Indexed for MEDLINE]


70. Int J Chron Obstruct Pulmon Dis. 2018 Dec 28;14:149-162. doi: 
10.2147/COPD.S182730. eCollection 2019.

Is COPD associated with alterations in hearing? A systematic review and 
meta-analysis.

Bayat A(1), Saki N(2), Nikakhlagh S(2), Mirmomeni G(3), Raji H(4), Soleimani 
H(1), Rahim F(5).

Author information:
(1)Department of Audiology, Hearing Research Center, Imam Khomeini Hospital, 
Ahvaz Jundishapur University of Medical Sciences, Ahvaz, Iran.
(2)Department of Otorhinolaryngology, Hearing Research Center, Ahvaz Jundishapur 
University of Medical Sciences, Ahvaz Iran.
(3)Department of Biostatistics and Epidemiology, School of Health, Ahvaz 
Jundishapur University of Medical Sciences, Ahvaz, Iran.
(4)Department of Internal Medicine, Air Pollution and Respiratory Diseases 
Research Center, Ahvaz Jundishapur University of Medical Sciences, Ahvaz, Iran.
(5)Department of Molecular Medicine, Health Research Institute, Thalassemia and 
Hemoglobinopathies Research Centre, Ahvaz Jundishapur University of Medical 
Sciences, Ahvaz, Iran, bioinfo2003@gmail.com.

Comment in
    Int J Chron Obstruct Pulmon Dis. 2019 Feb 18;14:457-460.

BACKGROUND AND AIMS: COPD is an irreversible or persistent airflow obstruction, 
which affects up to 600 million people globally. The primary purpose of this 
systematic review was to explore the COPD-based alteration in the auditory 
system function by conducting a quantitative analysis of presently published 
data.
MATERIALS AND METHODS: We systematically searched seven diverse electronic 
databases and manual searching of references to identify relevant studies. Data 
from the selected studies were rated by two investigators independently in a 
blinded fashion. Meta-analysis was done on pooled data using Cochrane's Review 
Manager 5.3.
RESULTS: Sixteen articles received suitable scores and were thus included for 
further processes. Hearing loss (HL) was defined as a change in pure tone 
audiometry (PTA) thresholds, auditory brainstem response (ABR), and auditory 
P300 parameters. ABR wave was significantly elongated in patients with COPD than 
in controls (standardized mean difference [SMD]=0.27, 95% CI: 0.05-0.48, 
P=0.02). PTA was significantly higher in patients with COPD when compared with 
controls (SMD=1.76, 95% CI: 0.43-3.08, P=0.0004). We found that patients with 
COPD had a significantly higher latency than controls (SMD=1.30, 95% CI: 
0.79-1.80, P=0.0001).
CONCLUSION: COPD patients had considerably greater incidence of HL when compared 
with controls. Interestingly, although the mean PTA thresholds at every 
frequency for COPD patients were higher than those for controls, these values 
were still in the slight to mild HL ranges. Prolonged ABR wave latencies in the 
COPD patients suggest retro-cochlear involvement. Thus, COPD most frequently 
clusters with HL, but it is worth noting that alteration in hearing is not 
always recognized by medical experts as a frequent comorbidity associated with 
COPD.

DOI: 10.2147/COPD.S182730
PMCID: PMC6312399
PMID: 30643401 [Indexed for MEDLINE]

Conflict of interest statement: Disclosure The authors report no conflicts of 
interest in this work.


71. Hear Res. 2020 Jul;392:107979. doi: 10.1016/j.heares.2020.107979. Epub 2020 Apr 
29.

The derived-band envelope following response and its sensitivity to 
sensorineural hearing deficits.

Keshishzadeh S(1), Garrett M(2), Vasilkov V(3), Verhulst S(4).

Author information:
(1)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Technologiepark 126, Zwijnaarde, 9052, Belgium. Electronic address: 
sarineh.keshishzadeh@ugent.be.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Department of 
Medical Physics and Acoustics, University of Oldenburg, Carl-von-Ossietzky 
Strasse 9-11, 26120, Oldenburg, Germany. Electronic address: 
markus.garrett@uni-oldenburg.de.
(3)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Technologiepark 126, Zwijnaarde, 9052, Belgium. Electronic address: 
viacheslav.vasilkov@ugent.be.
(4)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Technologiepark 126, Zwijnaarde, 9052, Belgium. Electronic address: 
s.verhulst@ugent.be.

The envelope following response (EFR) has been proposed as a non-invasive marker 
of synaptopathy in animal models. However, its amplitude is affected by the 
spread of basilar-membrane excitation and other coexisting sensorineural hearing 
deficits. This study aims to (i) improve frequency specificity of the EFR by 
introducing a derived-band EFR (DBEFR) technique and (ii) investigate the effect 
of lifetime noise exposure, age and outer-hair-cell (OHC) damage on DBEFR 
magnitudes. Additionally, we adopt a modelling approach to validate the 
frequency-specificity of the DBEFR and test how different aspects of 
sensorineural hearing loss affect peripheral generators. The combined analysis 
of simulations and experimental data proposes that the DBEFRs extracted from the 
[2-6]-kHz frequency band is a sensitive and frequency-specific measure of 
synaptopathy in humans. Individual variability in DBEFR magnitudes among 
listeners with normal audiograms was explained by their self-reported amount of 
experienced lifetime noise-exposure and corresponded to amplitude variability 
predicted by synaptopathy. Older listeners consistently had reduced DBEFR 
magnitudes in comparison to young normal-hearing listeners, in correspondence to 
how age-induced synaptopathy affects EFRs and compromises temporal envelope 
encoding. To a lesser degree, OHC damage was also seen to affect the DBEFR 
magnitude, hence the DBEFR metric should ideally be combined with a sensitive 
marker of OHC damage to offer a differential diagnosis of synaptopathy in 
listeners with impaired audiograms.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2020.107979
PMID: 32447097 [Indexed for MEDLINE]


72. Hear Res. 2019 Mar 1;373:121-129. doi: 10.1016/j.heares.2018.06.001. Epub 2018 
Jun 15.

Contralateral suppression of human hearing sensitivity in single-sided deaf 
cochlear implant users.

Nogueira W(1), Krüger B(2), Büchner A(2), Lopez-Poveda E(3).

Author information:
(1)Medical University Hannover, Cluster of Excellence "Hearing4all", Hannover, 
Germany. Electronic address: nogueiravazquez.waldo@mh-hannover.de.
(2)Medical University Hannover, Cluster of Excellence "Hearing4all", Hannover, 
Germany.
(3)University of Salamanca, Salamanca, Spain.

Cochlear implants (CIs) are being implanted in people with unilateral hearing 
loss because they can improve speech intelligibility and sound source 
localization. Though designed to restore the afferent auditory stimulation, the 
CI possibly restores some efferent effects. The present study aimed at 
investigating this possibility. Five single-sided deaf CI users with less than 
30 dB hearing loss up to 4 kHz in their acoustic ear participated in the study. 
Absolute thresholds for their acoustic ears were measured for pure tones of 500 
and 4000 Hz with durations of 10 and 200 ms in the presence and in the absence 
of contralateral broadband electrical stimulation (CBES) delivered with the CI. 
The electrical stimulus consisted of pulse trains (symmetric biphasic pulses 
with phase duration 36 μs) on all 16 electrodes sequentially stimulated at a 
rate of 843 Hz. Its intensity was set to sound as loud as broadband noise at 50 
or 60 dB SPL in the acoustic ear. Thresholds were measured using a 
three-interval, three-alternative, forced-choice procedure with a two-down, 
one-up adaptive rule to estimate the level for 71% correct in the psychometric 
function. Thresholds measured without the CBES were lower for the longer than 
for the shorter tones, and the difference was larger at 500 than at 4000 Hz. 
CBES equivalent to 50 or 60 dB SPL caused significant threshold elevation only 
for short (10 ms) and low frequency (500 Hz) acoustic tones of 1.2 and 2.2 dB. 
These increases appear smaller than previously reported for normal hearing 
listeners in related experiments. These results support the notion that for 
single-sided deaf CI users, the CI modulates hearing in the acoustic ear. The 
possible mechanisms that may be contributing this effect are discussed.

Copyright © 2018 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2018.06.001
PMID: 29941311 [Indexed for MEDLINE]


73. Int J Audiol. 2022 Nov;61(11):965-974. doi: 10.1080/14992027.2021.1980233. Epub 
2021 Oct 6.

Relation between hearing abilities and preferred playback settings for speech 
perception in complex listening conditions.

Kubiak AM(1), Rennies J(1), Ewert SD(2), Kollmeier B(2).

Author information:
(1)Fraunhofer IDMT, Project Group Hearing, Speech and Audio Technology, Cluster 
of Excellence "Hearing4all", Oldenburg, Germany.
(2)Medizinische Physik, Cluster of Excellence Hearing4all, Carl von Ossietzky 
Universität, Oldenburg, Germany.

OBJECTIVE: This study investigated if individual preferences with respect to the 
trade-off between a good signal-to-noise ratio and a distortion-free speech 
target were stable across different masking conditions and if simple adjustment 
methods could be used to identify subjects as either "noise haters" or 
"distortions haters".
DESIGN: In each masking condition, subjects could adjust the target speech level 
according to their preferences by employing (i) linear gain or gain at the cost 
of (ii) clipping distortions or (iii) compression distortions. The comparison of 
these processing conditions allowed investigating the preferred trade-off 
between distortions and noise disturbance.
STUDY SAMPLE: Thirty subjects differing widely in hearing status (normal-hearing 
to moderately impaired) and age (23-85 years).
RESULTS: High test-retest stability of individual preferences was found for all 
modification schemes. The preference adjustments suggested that subjects could 
be consistently categorised along a scale from "noise haters" to "distortion 
haters", and this preference trait remained stable through all maskers, spatial 
conditions, and types of distortions.
CONCLUSIONS: Employing quick self-adjustment to collect listening preferences in 
complex listening conditions revealed a stable preference trait along the "noise 
vs. distortions" tolerance dimension. This could potentially help in fitting 
modern hearing aid algorithms to the individual user.

DOI: 10.1080/14992027.2021.1980233
PMID: 34612124 [Indexed for MEDLINE]


74. IEEE Trans Biomed Eng. 2023 Dec;70(12):3330-3341. doi: 
10.1109/TBME.2023.3285437. Epub 2023 Nov 21.

Optical Microphone-Based Speech Reconstruction System With Deep Learning for 
Individuals With Hearing Loss.

Lin YM, Han JY, Lin CH, Lai YH.

OBJECTIVE: Although many speech enhancement (SE) algorithms have been proposed 
to promote speech perception in hearing-impaired patients, the conventional SE 
approaches that perform well under quiet and/or stationary noises fail under 
nonstationary noises and/or when the speaker is at a considerable distance. 
Therefore, the objective of this study is to overcome the limitations of the 
conventional speech enhancement approaches.
METHOD: This study proposes a speaker-closed deep learning-based SE method 
together with an optical microphone to acquire and enhance the speech of a 
target speaker.
RESULTS: The objective evaluation scores achieved by the proposed method 
outperformed the baseline methods by a margin of 0.21-0.27 and 0.34-0.64 in 
speech quality (HASQI) and speech comprehension/intelligibility (HASPI), 
respectively, for seven typical hearing loss types.
CONCLUSION: The results suggest that the proposed method can enhance speech 
perception by cutting off noise from speech signals and mitigating interference 
caused by distance.
SIGNIFICANCE: The results of this study show a potential way that can help 
improve the listening experience in enhancing speech quality and speech 
comprehension/intelligibility for hearing-impaired people.

DOI: 10.1109/TBME.2023.3285437
PMID: 37327105 [Indexed for MEDLINE]


75. Ear Hear. 2022 Sep-Oct 01;43(5):1563-1573. doi: 10.1097/AUD.0000000000001217. 
Epub 2022 Mar 29.

Automatic Prediction of Conductive Hearing Loss Using Video Pneumatic Otoscopy 
and Deep Learning Algorithm.

Byun H(1)(2), Park CJ(3)(2), Oh SJ(4), Chung MJ(3)(4)(5), Cho BH(4)(6), Cho 
YS(7).

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, Hanyang University 
College of Medicine, Hanyang University Medical Center, Seoul, South Korea.
(2)These authors contributed equally to this work.
(3)Department of Digital Health, SAIHST, Sungkyunkwan University, Seoul, South 
Korea.
(4)Medical AI Research Center, Samsung Medical Center, Seoul, South Korea.
(5)Department of Radiology, Samsung Medical Center, Sungkyunkwan University 
School of Medicine, Seoul, South Korea.
(6)Department of Medical Device Management and Research, SAIHST, Sungkyunkwan 
University, Seoul, South Korea.
(7)Department of Otorhinolaryngology-Head and Neck Surgery, Sungkyunkwan 
University School of Medicine, Samsung Medical Center, Seoul, South Korea.

OBJECTIVES: Diseases of the middle ear can interfere with normal sound 
transmission, which results in conductive hearing loss. Since video pneumatic 
otoscopy (VPO) findings reveal not only the presence of middle ear effusions but 
also dynamic movements of the tympanic membrane and part of the ossicles, 
analyzing VPO images was expected to be useful in predicting the presence of 
middle ear transmission problems. Using a convolutional neural network (CNN), a 
deep neural network implementing computer vision, this preliminary study aimed 
to create a deep learning model that detects the presence of an air-bone gap, 
conductive component of hearing loss, by analyzing VPO findings.
DESIGN: The medical records of adult patients who underwent VPO tests and 
pure-tone audiometry (PTA) on the same day were reviewed for enrollment. 
Conductive hearing loss was defined as an average air-bone gap of more than 10 
dB at 0.5, 1, 2, and 4 kHz on PTA. Two significant images from the original VPO 
videos, at the most medial position on positive pressure and the most laterally 
displaced position on negative pressure, were used for the analysis. Applying 
multi-column CNN architectures with individual backbones of pretrained CNN 
versions, the performance of each model was evaluated and compared for 
Inception-v3, VGG-16 or ResNet-50. The diagnostic accuracy predicting the 
presence of conductive component of hearing loss of the selected deep learning 
algorithm used was compared with experienced otologists.
RESULTS: The conductive hearing loss group consisted of 57 cases (mean air-bone 
gap = 25 ± 8 dB): 21 ears with effusion, 14 ears with malleus-incus fixation, 15 
ears with stapes fixation including otosclerosis, one ear with a loose 
incus-stapes joint, 3 cases with adhesive otitis media, and 3 ears with middle 
ear masses including congenital cholesteatoma. The control group consisted of 76 
cases with normal hearing thresholds without air-bone gaps. A total of 1130 
original images including repeated measurements were obtained for the analysis. 
Of the various network architectures designed, the best was to feed each of the 
images into the individual backbones of Inception-v3 (three-column architecture) 
and concatenate the feature maps after the last convolutional layer from each 
column. In the selected model, the average performance of 10-fold 
cross-validation in predicting conductive hearing loss was 0.972 mean areas 
under the curve (mAUC), 91.6% sensitivity, 96.0% specificity, 94.4% positive 
predictive value, 93.9% negative predictive value, and 94.1% accuracy, which was 
superior to that of experienced otologists, whose performance had 0.773 mAUC and 
79.0% accuracy on average. The algorithm detected over 85% of cases with stapes 
fixations or ossicular chain problems other than malleus-incus fixations. 
Visualization of the region of interest in the deep learning model revealed that 
the algorithm made decisions generally based on findings in the malleus and 
nearby tympanic membrane.
CONCLUSIONS: In this preliminary study, the deep learning algorithm created to 
analyze VPO images successfully detected the presence of conductive hearing 
losses caused by middle ear effusion, ossicular fixation, otosclerosis, and 
adhesive otitis media. Interpretation of VPO using the deep learning algorithm 
showed promise as a diagnostic tool to differentiate conductive hearing loss 
from sensorineural hearing loss, which would be especially useful for patients 
with poor cooperation.

Copyright © 2022 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001217
PMID: 35344974 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


76. Neurobiol Aging. 2021 Dec;108:133-145. doi: 
10.1016/j.neurobiolaging.2021.08.019. Epub 2021 Sep 4.

Age-related decline in cochlear ribbon synapses and its relation to different 
metrics of auditory-nerve activity.

Steenken F(1), Heeringa AN(1), Beutelmann R(1), Zhang L(1), Bovee S(1), Klump 
GM(1), Köppl C(2).

Author information:
(1)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg Oldenburg, Germany. Electronic address: 
christine.koeppl@uni-oldenburg.de.

Loss of inner hair cell-auditory nerve fiber synapses is considered to be an 
important early stage of neural presbyacusis. Mass potentials, recorded at the 
cochlear round window, can be used to derive the neural index (NI), a sensitive 
measure for pharmacologically-induced synapse loss. Here, we investigate the 
applicability of the NI for measuring age-related auditory synapse loss in 
young-adult, middle-aged, and old Mongolian gerbils. Synapse loss, which was 
progressively evident in the 2 aged groups, correlated weakly with NI when 
measured at a fixed sound level of 60 dB SPL. However, the NI was confounded by 
decreases in single-unit firing rates at 60 dB SPL. NI at 30 dB above threshold, 
when firing rates were similar between age groups, did not correlate with 
synapse loss. Our results show that synapse loss is poorly reflected in the NI 
of aged gerbils, particularly if further peripheral pathologies are present. The 
NI may therefore not be a reliable clinical tool to assess synapse loss in aged 
humans with peripheral hearing loss.

Copyright © 2021 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neurobiolaging.2021.08.019
PMID: 34601244 [Indexed for MEDLINE]


77. Ear Hear. 2023 Nov-Dec 01;44(6):1464-1484. doi: 10.1097/AUD.0000000000001386. 
Epub 2023 Jul 13.

Variability in Cochlear Implantation Outcomes in a Large German Cohort With a 
Genetic Etiology of Hearing Loss.

Tropitzsch A(1)(2)(3)(4), Schade-Mann T(1)(2), Gamerdinger P(1)(2), Dofek S(1), 
Schulte B(5), Schulze M(5), Fehr S(5), Biskup S(5), Haack TB(6), Stöbe P(6), 
Heyd A(1), Harre J(7)(8), Lesinski-Schiedat A(7)(8), Büchner A(7)(8), Lenarz 
T(7)(8), Warnecke A(7)(8), Müller M(1)(4), Vona B(1)(4), Dahlhoff E(1)(4), 
Löwenheim H(1)(4), Holderried M(1)(9).

Author information:
(1)Department of Otolaryngology-Head & Neck Surgery, University of Tübingen 
Medical Center, Tübingen, Germany.
(2)Hearing Center, Department of Otolaryngology-Head & Neck Surgery, University 
of Tübingen Medical Center, Tübingen, Germany.
(3)Center for Rare Hearing Disorders, Centre for Rare Diseases, University of 
Tübingen, Tübingen, Germany.
(4)Neurosensory Center, Departments of Otolaryngology-Head & Neck Surgery and 
Ophthalmology, University of Tübingen Medical Center, Tübingen, Germany.
(5)CeGaT GmbH und Praxis für Humangenetik Tübingen, Tübingen, Germany.
(6)Institute of Medical Genetics and Applied Genomics, University of Tübingen, 
Tübingen, Germany.
(7)Department of Otorhinolaryngology-Head & Neck Surgery, Hannover Medical 
School, Hannover, Germany.
(8)Cluster of Excellence "Hearing4all" of the German Research Foundation, 
Hannover, Germany.
(9)Department of Medical Development and Quality Management, University Hospital 
Tübingen, Tübingen, Germany.

OBJECTIVES: The variability in outcomes of cochlear implantation is largely 
unexplained, and clinical factors are not sufficient for predicting performance. 
Genetic factors have been suggested to impact outcomes, but the clinical and 
genetic heterogeneity of hereditary hearing loss makes it difficult to determine 
and interpret postoperative performance. It is hypothesized that genetic 
mutations that affect the neuronal components of the cochlea and auditory 
pathway, targeted by the cochlear implant (CI), may lead to poor performance. A 
large cohort of CI recipients was studied to verify this hypothesis.
DESIGN: This study included a large German cohort of CI recipients (n = 123 
implanted ears; n = 76 probands) with a definitive genetic etiology of hearing 
loss according to the American College of Medical Genetics (ACMG)/Association 
for Molecular Pathology (AMP) guidelines and documented postoperative 
audiological outcomes. All patients underwent preoperative clinical and 
audiological examinations. Postoperative CI outcome measures were based on at 
least 1 year of postoperative audiological follow-up for patients with 
postlingual hearing loss onset (>6 years) and 5 years for children with 
congenital or pre/perilingual hearing loss onset (≤6 years). Genetic analysis 
was performed based on three different methods that included single-gene 
screening, custom-designed hearing loss gene panel sequencing, targeting known 
syndromic and nonsyndromic hearing loss genes, and whole-genome sequencing.
RESULTS: The genetic diagnosis of the 76 probands in the genetic cohort involved 
35 genes and 61 different clinically relevant (pathogenic, likely pathogenic) 
variants. With regard to implanted ears (n = 123), the six most frequently 
affected genes affecting nearly one-half of implanted ears were GJB2 (21%; n = 
26), TMPRSS3 (7%; n = 9), MYO15A (7%; n = 8), SLC26A4 (5%; n = 6), and LOXHD1 
and USH2A (each 4%; n = 5). CI recipients with pathogenic variants that 
influence the sensory nonneural structures performed at or above the median 
level of speech performance of all ears at 70% [monosyllable word recognition 
score in quiet at 65 decibels sound pressure level (SPL)]. When gene expression 
categories were compared to demographic and clinical categories (total number of 
compared categories: n = 30), mutations in genes expressed in the spiral 
ganglion emerged as a significant factor more negatively affecting cochlear 
implantation outcomes than all clinical parameters. An ANOVA of a reduced set of 
genetic and clinical categories (n = 10) identified five detrimental factors 
leading to poorer performance with highly significant effects ( p < 0.001), 
accounting for a total of 11.8% of the observed variance. The single strongest 
category was neural gene expression accounting for 3.1% of the variance.
CONCLUSIONS: The analysis of the relationship between the molecular genetic 
diagnoses of a hereditary etiology of hearing loss and cochlear implantation 
outcomes in a large German cohort of CI recipients revealed significant 
variabilities. Poor performance was observed with genetic mutations that 
affected the neural components of the cochlea, supporting the "spiral ganglion 
hypothesis."

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001386
PMCID: PMC10583923
PMID: 37438890 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


78. Hear Res. 2016 May;335:138-148. doi: 10.1016/j.heares.2016.02.016. Epub 2016 Mar 
9.

Disrupted functional brain connectome in unilateral sudden sensorineural hearing 
loss.

Xu H(1), Fan W(2), Zhao X(3), Li J(4), Zhang W(5), Lei P(6), Liu Y(7), Wang 
H(8), Cheng H(9), Shi H(10).

Author information:
(1)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China; Department of 
Radiology, Zhongnan Hospital of Wuhan University, Wuhan 430071, China. 
Electronic address: xuhaibo1120@hotmail.com.
(2)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China. Electronic address: 
fanwenliang168@163.com.
(3)Department of Otorhinolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan 430022, China. Electronic 
address: yaner_323@126.com.
(4)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China. Electronic address: 
lijing80603@163.com.
(5)Department of Otorhinolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan 430022, China. Electronic 
address: juan_364@163.com.
(6)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China. Electronic address: 
leiping_rosemary@126.com.
(7)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China. Electronic address: 
309105825@qq.com.
(8)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan 430022, China. Electronic address: 
ahahwang@163.com.
(9)Department of Otorhinolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan 430022, China. Electronic 
address: chhmao@aliyun.com.
(10)Department of Otorhinolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan 430022, China. Electronic 
address: shihong5510@163.com.

Sudden sensorineural hearing loss (SSNHL) is generally defined as sensorineural 
hearing loss of 30 dB or greater over at least three contiguous audiometric 
frequencies and within a three-day period. This hearing loss is usually 
unilateral and can be associated with tinnitus and vertigo. The pathogenesis of 
unilateral sudden sensorineural hearing loss is still unknown, and the 
alterations in the functional connectivity are suspected to involve one possible 
pathogenesis. Despite scarce findings with respect to alterations in brain 
functional networks in unilateral sudden sensorineural hearing loss, the 
alterations of the whole brain functional connectome and whether these 
alterations were already in existence in the acute period remains unknown. The 
aim of this study was to investigate the alterations of brain functional 
connectome in two large samples of unilateral sudden sensorineural hearing loss 
patients and to investigate the correlation between unilateral sudden 
sensorineural hearing loss characteristics and changes in the functional network 
properties. Pure tone audiometry was performed to assess hearing ability. 
Abnormal changes in the peripheral auditory system were examined using 
conventional magnetic resonance imaging. The graph theoretical network analysis 
method was used to detect brain connectome alterations in unilateral sudden 
sensorineural hearing loss. Compared with the control groups, both groups of 
unilateral SSNHL patients exhibited a significantly increased clustering 
coefficient, global efficiency, and local efficiency but a significantly 
decreased characteristic path length. In addition, the primary increased nodal 
strength (e.g., nodal betweenness, hubs) was observed in several regions 
primarily, including the limbic and paralimbic systems, and in the auditory 
network brain areas. These findings suggest that the alteration of network 
organization already exists in unilateral sudden sensorineural hearing loss 
patients within the acute period and that the functional connectome of 
unilateral SSNHL patients is characterized by a shift toward small-worldization. 
Additionally, we hope that these findings will help to elucidate unilateral 
SSNHL through a new research perspective and provide insight for the potential 
pathophysiology of unilateral SSNHL.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.02.016
PMID: 26969260 [Indexed for MEDLINE]


79. Adv Gerontol. 2023;36(2):265-273.

[Analysis of hearing aids application in elderly patients.].

[Article in Russian; Abstract available in Russian from the publisher]

Boboshko MY(1), Garbaruk ES(1), Golovanova LE(2)(3), Maltseva NV(1), Berdnikova 
IP(1), Markelov OA(4), Shpakovskaya II(4), Romanov SA(4), Kaplun DI(4).

Author information:
(1)I.P.Pavlov First Saint-Petersburg State Medical University, 6-8 Lev Tolstoy 
str., St. Petersburg 197022, Russian Federation, e-mail: boboshkom@gmail.com.
(2)I.I.Mechnikov North-Western State Medical University, 41 Kirochnaya str., St. 
Petersburg 191015, Russian Federation.
(3)Saint-Petersburg Geriatric Medico-social Center, Municipal Audiology Center, 
21 Rizhskii av., St. Petersburg 190103, Russian Federation.
(4)Saint-Petersburg Electrotechnical University, Centre for Digital 
Communication Technologies, 5 Professora Popova str., St. Petersburg 197022, 
Russian Federation.

The aim of the study is to evaluate the possibility to implement machine 
learning to create a digital auditory profile for elderly patients and to 
analyze the hearing aid fitting efficacy depending on involvement of the 
peripheral and central auditory pathways in a pathological process. Data 
analysis of 375 people aged 60-93 years is presented. 355 patients with chronic 
bilateral hearing loss (230 of them used hearing aids) were included in the main 
group, and 20 normal hearing elderly people were included in the control group. 
Audiological examination consisted of standard tests (pure tone audiometry, 
impedancemetry, speech audiometry in quiet) and tests to evaluate the central 
auditory processing (binaural fusion, dichotic digits, speech audiometry in 
noise, random gap detection). The Montreal Cognitive Assessment was used to 
detect cognitive impairment. The hearing aid fitting efficiency was evaluated 
with COSI questionnaire and speech audiometry in free field. Processing of the 
results was carried out using Pearson's correlation analysis aimed at creating a 
polynomial model of a patient's hearing on the basis of the limited test 
battery. There were close correlations between the state of cognitive functions 
and age, results of tests to evaluate the central auditory processing, as well 
as patients' satisfaction of hearing aid. The results of the work indicate the 
possibility of using computer technologies of data analysis to develop 
rehabilitation programs for elderly hearing impaired patients.

Publisher: Цель исследования — оценка возможности внедрения методов машинного 
обучения для создания цифрового слухового профиля у пациентов старших возрастных 
групп и анализа эффективности слухопротезирования в зависимости от вовлеченности 
в патологический процесс периферических и центральных отделов слуховой системы. 
Представлены результаты обследования 375 лиц 60–93 лет, из которых в основную 
группу вошли 355 пациентов с хронической двусторонней тугоухостью (230 из них 
использовали слуховые аппараты), а в контрольную — 20 человек пожилого возраста 
с нормальными порогами слуха. Аудиологическое обследование включало базовые 
методики (тональная пороговая и надпороговая аудиометрия, импедансометрия, 
речевая аудиометрия в тишине) и методы оценки состояния центральных отделов 
слуховой системы (тест чередующейся бинаурально речью, дихотический числовой 
тест, речевая аудиометрия в шуме, тест обнаружения паузы). Диагностику состояния 
когнитивных функций осуществляли с использованием Монреальской когнитивной 
шкалы. Эффективность слухопротезирования оценивали посредством анкетирования и 
речевой аудиометрии в свободном звуковом поле. Обработку результатов проводили с 
применением корреляционного анализа Пирсона, направленного на создание 
полиномиальной модели слуха пациента на основе ограниченного набора тестов. 
Выявлены корреляции состояния когнитивных функций и возраста, выполнения ряда 
тестов по оценке центральных отделов слуховой системы, а также успешности 
применения слуховых аппаратов. Результаты работы свидетельствуют о возможности 
использования компьютерных технологий анализа данных для разработки программ 
реабилитации пациентов старших возрастных групп с нарушениями слуха.

PMID: 37356105 [Indexed for MEDLINE]


80. Proc Natl Acad Sci U S A. 2018 Jan 30;115(5):E1022-E1031. doi: 
10.1073/pnas.1717603115. Epub 2018 Jan 16.

Neural preservation underlies speech improvement from auditory deprivation in 
young cochlear implant recipients.

Feng G(1)(2), Ingvalson EM(3)(4), Grieco-Calub TM(5)(6), Roberts MY(5), Ryan 
ME(7)(8), Birmingham P(9)(10), Burrowes D(7)(8), Young NM(4)(6)(11), Wong 
PCM(12)(2)(13).

Author information:
(1)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Hong Kong SAR, China.
(2)Brain and Mind Institute, The Chinese University of Hong Kong, Hong Kong SAR, 
China.
(3)School of Communication Science and Disorders, Florida State University, 
Tallahassee, FL 32301.
(4)Department of Otolaryngology - Head and Neck Surgery, Feinberg School of 
Medicine, Northwestern University, Chicago, IL 60611.
(5)Roxelyn and Richard Pepper Department of Communication Sciences and 
Disorders, Northwestern University, Evanston, IL 60208.
(6)Knowles Hearing Center, School of Communication, Northwestern University, 
Evanston, IL 60208.
(7)Department of Radiology, Feinberg School of Medicine, Northwestern 
University, Chicago, IL 60611.
(8)Department of Medical Imaging, Ann & Robert H. Lurie Children's Hospital of 
Chicago, Chicago, IL 60611.
(9)Department of Anesthesiology, Ann & Robert H. Lurie Children's Hospital of 
Chicago, Chicago, IL 60611.
(10)Department of Anesthesiology, Feinberg School of Medicine, Northwestern 
University, Chicago, IL 60611.
(11)Division of Otolaryngology - Head and Neck Surgery, Ann & Robert H. Lurie 
Children's Hospital of Chicago, Chicago, IL 60611.
(12)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Hong Kong SAR, China; p.wong@cuhk.edu.hk.
(13)Department of Otorhinolaryngology, Head and Neck Surgery, The Chinese 
University of Hong Kong, Hong Kong SAR, China.

Although cochlear implantation enables some children to attain age-appropriate 
speech and language development, communicative delays persist in others, and 
outcomes are quite variable and difficult to predict, even for children 
implanted early in life. To understand the neurobiological basis of this 
variability, we used presurgical neural morphological data obtained from MRI of 
individual pediatric cochlear implant (CI) candidates implanted younger than 3.5 
years to predict variability of their speech-perception improvement after 
surgery. We first compared neuroanatomical density and spatial pattern 
similarity of CI candidates to that of age-matched children with normal hearing, 
which allowed us to detail neuroanatomical networks that were either affected or 
unaffected by auditory deprivation. This information enables us to build 
machine-learning models to predict the individual children's speech development 
following CI. We found that regions of the brain that were unaffected by 
auditory deprivation, in particular the auditory association and cognitive brain 
regions, produced the highest accuracy, specificity, and sensitivity in patient 
classification and the most precise prediction results. These findings suggest 
that brain areas unaffected by auditory deprivation are critical to developing 
closer to typical speech outcomes. Moreover, the findings suggest that 
determination of the type of neural reorganization caused by auditory 
deprivation before implantation is valuable for predicting post-CI language 
outcomes for young children.

DOI: 10.1073/pnas.1717603115
PMCID: PMC5798370
PMID: 29339512 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of interest statement: G.F., N.M.Y., 
P.C.M.W., The Chinese University of Hong Kong, and the Ann & Robert H. Lurie 
Children's Hospital of Chicago disclose potential financial conflict of interest 
related to US patent application filed on December 21, 2017.


81. Int J Audiol. 2024 Feb;63(2):117-126. doi: 10.1080/14992027.2022.2147867. Epub 
2022 Dec 13.

Vehicle noise: comparison of loudness ratings in the field and the laboratory.

Llorach G(1)(2)(3), Oetting D(1)(2), Vormann M(1)(2), Meis M(1)(2), Hohmann 
V(1)(2)(3).

Author information:
(1)Development, Hörzentrum Oldenburg gGmbH, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4All, Department of Medical Physics and 
Acoustics, University of Oldenburg, Oldenburg, Germany.
(3)Auditory Signal Processing, Department of Medical Physics and Acoustics, 
University of Oldenburg, Oldenburg, Germany.

OBJECTIVE: Distorted loudness perception is one of the main complaints of 
hearing aid users. Measuring loudness perception in the clinic as experienced in 
everyday listening situations is important for loudness-based hearing aid 
fitting. Little research has been done comparing loudness perception in the 
field and in the laboratory.
DESIGN: Participants rated the loudness in the field and in the laboratory of 36 
driving actions. The field measurements were recorded with a 360° camera and a 
tetrahedral microphone. The recorded stimuli, which are openly accessible, were 
presented in three conditions in the laboratory: 360° video recordings with a 
head-mounted display, video recordings with a desktop monitor and audio-only.
STUDY SAMPLES: Thirteen normal-hearing participants and 18 hearing-impaired 
participants with hearing aids.
RESULTS: The driving actions were rated as louder in the laboratory than in the 
field for the condition with a desktop monitor and for the audio-only condition. 
The less realistic a laboratory condition was, the more likely it was for a 
participant to rate a driving action as louder. The field-laboratory loudness 
differences were bigger for louder sounds.
CONCLUSION: The results of this experiment indicate the importance of increasing 
realism and immersion when measuring loudness in the clinic.

DOI: 10.1080/14992027.2022.2147867
PMID: 36512479 [Indexed for MEDLINE]


82. J Neurosci. 2016 Mar 30;36(13):3755-64. doi: 10.1523/JNEUROSCI.4460-15.2016.

Auditory Brainstem Response Latency in Noise as a Marker of Cochlear 
Synaptopathy.

Mehraei G(1), Hickox AE(2), Bharadwaj HM(3), Goldberg H(4), Verhulst S(5), 
Liberman MC(6), Shinn-Cunningham BG(7).

Author information:
(1)Program in Speech and Hearing Bioscience and Technology, Harvard 
University/Massachusetts Institute of Technology, Cambridge, Massachusetts 
02139, Center for Computational Neuroscience and Neural Technology, Boston 
University, Boston, Massachusetts 02215, gmehraei@mit.edu.
(2)Program in Speech and Hearing Bioscience and Technology, Harvard 
University/Massachusetts Institute of Technology, Cambridge, Massachusetts 
02139, Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston, 
Massachusetts 02114.
(3)Center for Computational Neuroscience and Neural Technology, Boston 
University, Boston, Massachusetts 02215, Martinos Center for Biomedical Imaging, 
Department of Neurology, Massachusetts General Hospital/Harvard Medical School, 
Charlestown, Massachusetts 02129.
(4)Program in Speech and Hearing Bioscience and Technology, Harvard 
University/Massachusetts Institute of Technology, Cambridge, Massachusetts 
02139.
(5)Center for Computational Neuroscience and Neural Technology, Boston 
University, Boston, Massachusetts 02215, Cluster of Excellence Hearing4All and 
Medical Physics, Department of Medical Physics and Acoustics, Oldenburg 
University, 26129 Oldenburg, Germany.
(6)Program in Speech and Hearing Bioscience and Technology, Harvard 
University/Massachusetts Institute of Technology, Cambridge, Massachusetts 
02139, Eaton-Peabody Laboratory, Massachusetts Eye and Ear Infirmary, Boston, 
Massachusetts 02114, Department of Otology and Laryngology, Harvard Medical 
School, Boston, Massachusetts 02114.
(7)Center for Computational Neuroscience and Neural Technology, Boston 
University, Boston, Massachusetts 02215, Department of Biomedical Engineering, 
Boston University, Boston, Massachusetts 02215.

Evidence from animal and human studies suggests that moderate acoustic exposure, 
causing only transient threshold elevation, can nonetheless cause "hidden 
hearing loss" that interferes with coding of suprathreshold sound. Such noise 
exposure destroys synaptic connections between cochlear hair cells and auditory 
nerve fibers; however, there is no clinical test of this synaptopathy in humans. 
In animals, synaptopathy reduces the amplitude of auditory brainstem response 
(ABR) wave-I. Unfortunately, ABR wave-I is difficult to measure in humans, 
limiting its clinical use. Here, using analogous measurements in humans and 
mice, we show that the effect of masking noise on the latency of the more robust 
ABR wave-V mirrors changes in ABR wave-I amplitude. Furthermore, in our human 
cohort, the effect of noise on wave-V latency predicts perceptual temporal 
sensitivity. Our results suggest that measures of the effects of noise on ABR 
wave-V latency can be used to diagnose cochlear synaptopathy in humans.
SIGNIFICANCE STATEMENT: Although there are suspicions that cochlear synaptopathy 
affects humans with normal hearing thresholds, no one has yet reported a 
clinical measure that is a reliable marker of such loss. By combining human and 
animal data, we demonstrate that the latency of auditory brainstem response 
wave-V in noise reflects auditory nerve loss. This is the first study of human 
listeners with normal hearing thresholds that links individual differences 
observed in behavior and auditory brainstem response timing to cochlear 
synaptopathy. These results can guide development of a clinical test to reveal 
this previously unknown form of noise-induced hearing loss in humans.

Copyright © 2016 the authors 0270-6474/16/363755-10$15.00/0.

DOI: 10.1523/JNEUROSCI.4460-15.2016
PMCID: PMC4812134
PMID: 27030760 [Indexed for MEDLINE]


83. Int J Audiol. 2016;55(2):110-25. doi: 10.3109/14992027.2015.1084054. Epub 2015 
Sep 29.

Hearing threshold distribution and effect of screening in a population-based 
German sample.

von Gablenz P(1), Holube I(1).

Author information:
(1)a Institute of Hearing Technology and Audiology and Cluster of Excellence 
"Hearing4All" , Oldenburg , Germany.

OBJECTIVE: To establish the status of hearing in adults in Germany and the 
effects of screening for noise, tinnitus, ear diseases, and general health on 
the distribution of hearing threshold levels (HTL) DESIGN: A cross-sectional 
epidemiological study conducted between 2010 and 2012 in two middle-sized 
cities.
STUDY SAMPLE: A total of 1903 adults aged 18 to 97 years from a randomized 
sample drawn from the local registration offices and stratified for age and 
gender.
RESULTS: Dispersion and distribution of HTL data observed in the 
population-based sample are well in line with international results. However, 
median HTL tend to be better than in most recent international studies. 
Screening for "otological normality" improves the median HTL overall by 3 dB in 
males and 1 dB in females. This effect is strongly age-dependent in males and 
far less pronounced in females. While by and large HTL medians of females in the 
screened sample meet the values expected by ISO 7029:2000, HTL medians of males 
in middle and higher age cohorts are better than expected, especially in the 
frequencies above 2 kHz.
CONCLUSIONS: This study supports international findings that in males, the 
age-related decrease in hearing sensitivity at high frequencies is smaller than 
described by ISO 7029:2000.

DOI: 10.3109/14992027.2015.1084054
PMID: 26418731 [Indexed for MEDLINE]


84. Pediatrics. 2015 Jul;136(1):141-53. doi: 10.1542/peds.2014-3520. Epub 2015 Jun 
8.

Asymmetric Hearing During Development: The Aural Preference Syndrome and 
Treatment Options.

Gordon K(1), Henkin Y(2), Kral A(3).

Author information:
(1)Archie's Cochlear Implant Laboratory, The Hospital for Sick Children, 
Department of Otolaryngology-Head and Neck Surgery, University of Toronto, 
Toronto, Canada; karen.gordon@utoronto.ca.
(2)Hearing, Speech, and Language Center, Sheba Medical Center, Tel Hashomer, 
Department of Communication Disorders, Sackler Faculty of Medicine, Tel Aviv 
University, Tel Aviv, Israel; and.
(3)Cluster of Excellence Hearing4all, Institute of AudioNeuroTechnology, 
Hannover, Germany; Department of Experimental Otology, ENT Clinics, School of 
Medicine, Hannover Medical University, Hannover, Germany; and School of 
Behavioral and Brain Sciences, The University of Texas at Dallas, Dallas, Texas.

Deafness affects ∼2 in 1000 children and is one of the most common congenital 
impairments. Permanent hearing loss can be treated by fitting hearing aids. More 
severe to profound deafness is an indication for cochlear implantation. Although 
newborn hearing screening programs have increased the identification of 
asymmetric hearing loss, parents and caregivers of children with single-sided 
deafness are often hesitant to pursue therapy for the deaf ear. Delayed 
intervention has consequences for recovery of hearing. It has long been reported 
that asymmetric hearing loss/single-sided deafness compromises speech and 
language development and educational outcomes in children. Recent studies in 
animal models of deafness and in children consistently show evidence of an 
"aural preference syndrome" in which single-sided deafness in early childhood 
reorganizes the developing auditory pathways toward the hearing ear, with weaker 
central representation of the deaf ear. Delayed therapy consequently compromises 
benefit for the deaf ear, with slow rates of improvement measured over time. 
Therefore, asymmetric hearing needs early identification and intervention. 
Providing early effective stimulation in both ears through appropriate fitting 
of auditory prostheses, including hearing aids and cochlear implants, within a 
sensitive period in development has a cardinal role for securing the function of 
the impaired ear and for restoring binaural/spatial hearing. The impacts of 
asymmetric hearing loss on the developing auditory system and on spoken language 
development have often been underestimated. Thus, the traditional minimalist 
approach to clinical management aimed at 1 functional ear should be modified on 
the basis of current evidence.

Copyright © 2015 by the American Academy of Pediatrics.

DOI: 10.1542/peds.2014-3520
PMID: 26055845 [Indexed for MEDLINE]


85. Vet J. 2021 Aug;274:105711. doi: 10.1016/j.tvjl.2021.105711. Epub 2021 Jun 25.

Congenital sensorineural deafness in Australian Cattle dogs in the UK: 
Prevalence and association with phenotype.

Marsh O(1), Freeman J(2), Pollard D(3), De Risio L(4).

Author information:
(1)Southfields Veterinary Specialists, Laindon, Essex, UK. Electronic address: 
oliver.marsh@southfields.co.uk.
(2)Davies Veterinary Specialists, Hitchen, Hertfordshire, UK.
(3)British Horse Society, Kenilworth, Warwickshire, UK.
(4)Linnaeus Veterinary Ltd, Friars Gate, Shirley, UK.

The Australian Cattle dog (ACD) is one of many breeds predisposed to congenital 
sensorineural deafness (CSD). The objective of this study was to estimate CSD 
prevalence and investigate any association with phenotype in the ACD in the UK. 
The database of the authors' institution was searched for ACD puppies undergoing 
brainstem auditory evoked response (BAER) testing for CSD screening (1999-2019). 
Inclusion criteria were BAER performed at 4-10 weeks of age, testing of complete 
litters and available phenotypic data. The age, sex, coat and iris colour, 
presence and location of face and body patches, hearing status and BAER- 
determined parental hearing status of each puppy were recorded. A multivariable 
mixed-effects logistic regression model was used to calculate odds ratios and 
95% confidence intervals to determine whether any of these variables were 
significantly associated with CSD, while adjusting for clustering at litter 
level. Inclusion criteria were met for 524 puppies. Hearing was bilaterally 
normal in 464 puppies (88.6%). The prevalence of unilateral and bilateral CSD 
was 9.7% and 1.7%, respectively. On the basis of multivariable analysis, the 
presence of a pigmented face patch was the only phenotypic variable 
significantly associated with CSD, and was linked to a reduced risk of the 
condition. The prevalence was similar to that reported in an Australian 
population of ACDs. The key findings from this study were that overall CSD 
prevalence in the ACD population in the UK was 11.4%, and puppies with a face 
patch were at reduced risk of the condition.

Copyright © 2021 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.tvjl.2021.105711
PMID: 34182072 [Indexed for MEDLINE]


86. Hear Res. 2017 May;348:112-119. doi: 10.1016/j.heares.2017.03.002. Epub 2017 Mar 
10.

Speech intelligibility and subjective benefit in single-sided deaf adults after 
cochlear implantation.

Finke M(1), Strauß-Schier A(2), Kludt E(3), Büchner A(3), Illg A(2).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Germany; Cluster of 
Excellence "Hearing4all", Germany. Electronic address: 
Finke.Mareike@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Germany.
(3)Department of Otolaryngology, Hannover Medical School, Germany; Cluster of 
Excellence "Hearing4all", Germany.

Treatment with cochlear implants (CIs) in single-sided deaf individuals started 
less than a decade ago. CIs can successfully reduce incapacitating tinnitus on 
the deaf ear and allow, so some extent, the restoration of binaural hearing. 
Until now, systematic evaluations of subjective CI benefit in post-lingually 
single-sided deaf individuals and analyses of speech intelligibility outcome for 
the CI in isolation have been lacking. For the prospective part of this study, 
the Bern Benefit in Single-Sided Deafness Questionnaire (BBSS) was administered 
to 48 single-sided deaf CI users to evaluate the subjectively perceived CI 
benefit across different listening situations. In the retrospective part, speech 
intelligibility outcome with the CI up to 12 month post-activation was compared 
between 100 single-sided deaf CI users and 125 bilaterally implanted CI users 
(2nd implant). The positive median ratings in the BBSS differed significantly 
from zero for all items suggesting that most individuals with single-sided 
deafness rate their CI as beneficial across listening situations. The speech 
perception scores in quiet and noise improved significantly over time in both 
groups of CI users. Speech intelligibility with the CI in isolation was 
significantly better in bilaterally implanted CI users (2nd implant) compared to 
the scores obtained from single-sided deaf CI users. Our results indicate that 
CI users with single-sided deafness can reach open set speech understanding with 
their CI in isolation, encouraging the extension of the CI indication to 
individuals with normal hearing on the contralateral ear. Compared to the 
performance reached with bilateral CI users' second implant, speech reception 
threshold are lower, indicating an aural preference and dominance of the normal 
hearing ear. The results from the BBSS propose good satisfaction with the CI 
across several listening situations.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.03.002
PMID: 28286233 [Indexed for MEDLINE]


87. Stat Med. 2022 Nov 20;41(26):5335-5348. doi: 10.1002/sim.9572. Epub 2022 Sep 20.

Analytical methods for correlated data arising from multicenter hearing studies.

Sheng Y(1), Yang C(2), Curhan S(3)(4), Curhan G(2)(3)(4)(5), Wang M(1)(2)(3)(4).

Author information:
(1)Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
Boston, Massachusetts, USA.
(2)Department of Epidemiology, Harvard T.H. Chan School of Public Health, 
Boston, Massachusetts, USA.
(3)Harvard Medical School, Boston, Massachusetts, USA.
(4)Channing Division of Network Medicine, Department of Medicine, Brigham and 
Women's Hospital, Boston, Massachusetts, USA.
(5)Renal Division, Department of Medicine, Brigham and Women's Hospital, Boston, 
Massachusetts, USA.

In epidemiological hearing studies, estimating the association between exposures 
and hearing loss using audiometrically-assessed hearing measurements is 
challenging due to the complex correlation structure in the clustered data, with 
clusters formed by the two ears of the same individual and the testing site and 
audiologist. We propose a linear mixed-effects model to take into account the 
multilevel correlation structures of the data. Both theoretically and in 
simulation studies, we compare single-ear linear regression models commonly used 
in published hearing loss studies with the proposed both-ears linear mixed 
models properly accounting for the multi-level correlations. Our findings 
include (1) when there are only participant-level covariates, the worse-ear 
linear regression models produce unbiased but typically less efficient 
estimators than the both-ear and average-ear approaches; (2) when there are 
ear-level confounders, the worse-ear method may lead to biased estimators and 
the average-ear method produces unbiased but typically less efficient estimators 
than the both-ear method; (3) the both-ear method may gain efficiency when 
additionally adjusting for testing sites and audiologists. As an illustrative 
example, we applied the single-ear and both-ear methods to assess 
aspirin-hearing association in the Nurses' Health Study II.

© 2022 John Wiley & Sons Ltd.

DOI: 10.1002/sim.9572
PMCID: PMC9588694
PMID: 36125070 [Indexed for MEDLINE]

Conflict of interest statement: CONFLICT OF INTEREST The authors declare no 
potential conflict of interests.


88. Exp Gerontol. 2020 Feb;130:110794. doi: 10.1016/j.exger.2019.110794. Epub 2019 
Nov 30.

Altered verbal fluency processes in older adults with age-related hearing loss.

Loughrey DG(1), Pakhomov SVS(2), Lawlor BA(3).

Author information:
(1)Global Brain Health Institute, Trinity College Dublin, Ireland; Global Brain 
Health Institute, University of California, San Francisco, USA; Trinity College 
Institute of Neuroscience, Trinity College Dublin. Electronic address: 
loughred@tcd.ie.
(2)Institute for Health Informatics, University of Minnesota, Minneapolis, USA.
(3)Global Brain Health Institute, Trinity College Dublin, Ireland; Global Brain 
Health Institute, University of California, San Francisco, USA; Mercer's 
Institute for Successful Ageing, St James Hospital, Dublin, Ireland.

Epidemiological studies have linked age-related hearing loss (ARHL) with an 
increased risk of neurocognitive decline. Difficulties in speech perception with 
subsequent changes in brain morphometry, including regions important for 
lexical-semantic memory, are thought to be a possible mechanism for this 
relationship. This study investigated differences in automatic and executive 
lexical-semantic processes on verbal fluency tasks in individuals with acquired 
hearing loss. The primary outcomes were indices of automatic (clustering/word 
retrieval at start of task) and executive (switching/word retrieval after start 
of the task) processes from semantic and phonemic fluency tasks. To extract 
indices of clustering and switching, we used both manual and computerised 
methods. There were no differences between groups on indices of executive 
fluency processes or on any indices from the semantic fluency task. The hearing 
loss group demonstrated weaker automatic processes on the phonemic fluency task. 
Further research into differences in lexical-semantic processes with ARHL is 
warranted.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.exger.2019.110794
PMID: 31790801 [Indexed for MEDLINE]


89. PLoS One. 2017 Aug 22;12(8):e0183394. doi: 10.1371/journal.pone.0183394. 
eCollection 2017.

Tone perception in Mandarin-speaking school age children with otitis media with 
effusion.

Cai T(1), McPherson B(1), Li C(2), Yang F(3).

Author information:
(1)Division of Speech and Hearing Sciences, Faculty of Education, The University 
of Hong Kong, Hong Kong, China.
(2)Department of Otorhinolaryngology, Shenzhen Children's Hospital, Shenzhen, 
China.
(3)Department of Speech Therapy, Shenzhen Children's Hospital, Shenzhen, China.

OBJECTIVES: The present study explored tone perception ability in school age 
Mandarin-speaking children with otitis media with effusion (OME) in noisy 
listening environments. The study investigated the interaction effects of noise, 
tone type, age, and hearing status on monaural tone perception, and assessed the 
application of a hierarchical clustering algorithm for profiling hearing 
impairment in children with OME.
METHODS: Forty-one children with normal hearing and normal middle ear status and 
84 children with OME with or without hearing loss participated in this study. 
The children with OME were further divided into two subgroups based on their 
severity and pattern of hearing loss using a hierarchical clustering algorithm. 
Monaural tone recognition was measured using a picture-identification test 
format incorporating six sets of monosyllabic words conveying four lexical tones 
under speech spectrum noise, with the signal-to-noise ratio (SNR) conditions 
ranging from -9 to -21 dB.
RESULTS: Linear correlation indicated tone recognition thresholds of children 
with OME were significantly correlated with age and pure tone hearing thresholds 
at every frequency tested. Children with hearing thresholds less affected by OME 
performed similarly to their peers with normal hearing. Tone recognition 
thresholds of children with auditory status more affected by OME were 
significantly inferior to those of children with normal hearing or with minor 
hearing loss. Younger children demonstrated poorer tone recognition performance 
than older children with OME. A mixed design repeated-measure ANCOVA showed 
significant main effects of listening condition, hearing status, and tone type 
on tone recognition. Contrast comparisons revealed that tone recognition scores 
were significantly better under -12 dB SNR than under -15 dB SNR conditions and 
tone recognition scores were significantly worse under -18 dB SNR than those 
obtained under -15 dB SNR conditions. Tone 1 was the easiest tone to identify 
and Tone 3 was the most difficult tone to identify for all participants, when 
considering -12, -15, and -18 dB SNR as within-subject variables. The 
interaction effect between hearing status and tone type indicated that children 
with greater levels of OME-related hearing loss had more impaired tone 
perception of Tone 1 and Tone 2 compared to their peers with lesser levels of 
OME-related hearing loss. However, tone perception of Tone 3 and Tone 4 remained 
similar among all three groups. Tone 2 and Tone 3 were the most perceptually 
difficult tones for children with or without OME-related hearing loss in all 
listening conditions.
CONCLUSIONS: The hierarchical clustering algorithm demonstrated usefulness in 
risk stratification for tone perception deficiency in children with OME-related 
hearing loss. There was marked impairment in tone perception in noise for 
children with greater levels of OME-related hearing loss. Monaural lexical tone 
perception in younger children was more vulnerable to noise and OME-related 
hearing loss than that in older children.

DOI: 10.1371/journal.pone.0183394
PMCID: PMC5568745
PMID: 28829840 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


90. Otolaryngol Head Neck Surg. 2023 Dec;169(6):1573-1581. doi: 10.1002/ohn.422. 
Epub 2023 Jul 7.

A Comparative Study Using Vestibular Mapping in Sudden Sensorineural Hearing 
Loss With and Without Vertigo.

Hong JP(1), Lee JY(1), Kim MB(1).

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, Kangbuk Samsung 
Hospital, Sungkyunkwan University School of Medicine, Seoul, Korea.

OBJECTIVE: To investigate the impairment patterns in peripheral vestibular 
organs in sudden sensorineural hearing loss (SSNHL) with and without vertigo.
STUDY DESIGN: Retrospective study.
SETTING: Single tertiary medical center.
METHODS: Data from 165 SSNHL patients in a tertiary referral center from January 
2017 to December 2022 were retrospectively analyzed. All patients underwent a 
video head impulse test, vestibular evoked myogenic potential test, and 
pure-tone audiometry. Hierarchical cluster analysis was performed to investigate 
vestibular impairment patterns. The prognosis of the hearing was determined 
using American Academy of Otolaryngology-Head and Neck Surgery recommendations.
RESULTS: After excluding patients with vestibular schwannoma and Meniere's 
disease, 152 patients were included in this study. A total of 73 of 152 patients 
were categorized as SSNHL with vertigo (SSNHL_V) and showed an independent merge 
of the posterior semicircular canal (PSCC) in cluster analysis. A total of 79 of 
152 patients were categorized as SSNHL without vertigo (SSNHL_N) and showed an 
independent merge of saccule in cluster analysis. The PSCC (56.2%) and saccule 
(20.3%) were the most frequently impaired vestibular organs in SSNHL_V and 
SSNHL_N, respectively. In terms of prognosis, 106 of 152 patients had partial/no 
recovery and showed an independent merge of the PSCC in cluster analysis. A 
total of 46 of 152 patients had a complete recovery and showed an independent 
merge of the saccule in cluster analysis.
CONCLUSION: A tendency of isolated PSCC dysfunction was seen in SSNHL_V and 
partial/no recovery. A tendency of isolated saccular dysfunction was seen in 
SSNHL_N and complete recovery. Different treatments might be needed in SSNHL 
depending on the presence of vertigo.

© 2023 American Academy of Otolaryngology-Head and Neck Surgery Foundation.

DOI: 10.1002/ohn.422
PMID: 37418229 [Indexed for MEDLINE]


91. J Neurosci Res. 2021 Feb;99(2):699-728. doi: 10.1002/jnr.24754. Epub 2020 Nov 
12.

HCN channels in the mammalian cochlea: Expression pattern, subcellular location, 
and age-dependent changes.

Luque M(1), Schrott-Fischer A(1), Dudas J(1), Pechriggl E(2), Brenner E(2), 
Rask-Andersen H(3), Liu W(3), Glueckert R(1)(4).

Author information:
(1)Department of Otorhinolaryngology, Medical University of Innsbruck, 
Innsbruck, Austria.
(2)Department of Anatomy, Histology & Embryology, Division of Clinical & 
Functional Anatomy, Medical University of Innsbruck, Innsbruck, Austria.
(3)Department of Surgical Sciences, Head and Neck Surgery, Section of 
Otolaryngology, Uppsala University Hospital, Uppsala, Sweden.
(4)Tirol Kliniken, University Clinics Innsbruck, Innsbruck, Austria.

Neuronal diversity in the cochlea is largely determined by ion channels. Among 
voltage-gated channels, hyperpolarization-activated cyclic nucleotide-gated 
(HCN) channels open with hyperpolarization and depolarize the cell until the 
resting membrane potential. The functions for hearing are not well elucidated 
and knowledge about localization is controversial. We created a detailed map of 
subcellular location and co-expression of all four HCN subunits across different 
mammalian species including CBA/J, C57Bl/6N, Ly5.1 mice, guinea pigs, cats, and 
human subjects. We correlated age-related hearing deterioration in CBA/J and 
C57Bl/6N with expression levels of HCN1, -2, and -4 in individual auditory 
neurons from the same cohort. Spatiotemporal expression during murine postnatal 
development exposed HCN2 and HCN4 involvement in a critical phase of hair cell 
innervation. The huge diversity of subunit composition, but lack of relevant 
heteromeric pairing along the perisomatic membrane and axon initial segments, 
highlighted an active role for auditory neurons. Neuron clusters were found to 
be the hot spots of HCN1, -2, and -4 immunostaining. HCN channels were also 
located in afferent and efferent fibers of the sensory epithelium. Age-related 
changes on HCN subtype expression were not uniform among mice and could not be 
directly correlated with audiometric data. The oldest mice groups revealed HCN 
channel up- or downregulation, depending on the mouse strain. The unexpected 
involvement of HCN channels in outer hair cell function where HCN3 overlaps 
prestin location emphasized the importance for auditory function. A better 
understanding may open up new possibilities to tune neuronal responses evoked 
through electrical stimulation by cochlear implants.

© 2020 The Authors. Journal of Neuroscience Research published by Wiley 
Periodicals LLC.

DOI: 10.1002/jnr.24754
PMCID: PMC7839784
PMID: 33181864 [Indexed for MEDLINE]

Conflict of interest statement: There is no conflict of interest to declare.


92. Neuroimage. 2020 Dec;223:117282. doi: 10.1016/j.neuroimage.2020.117282. Epub 
2020 Aug 20.

Brain-informed speech separation (BISS) for enhancement of target speaker in 
multitalker speech perception.

Ceolini E(1), Hjortkjær J(2), Wong DDE(3), O'Sullivan J(4), Raghavan VS(4), 
Herrero J(5), Mehta AD(5), Liu SC(6), Mesgarani N(7).

Author information:
(1)University of Zürich and ETH Zürich, Institute of Neuroinformatics, 
Switzerland. Electronic address: enea.ceolini@ini.uzh.ch.
(2)Department of Health Technology, Danmarks Tekniske Universitet DTU, Kongens 
Lyngby, Denmark; Danish Research Centre for Magnetic Resonance, Copenhagen 
University Hospital Hvidovre, Hvidovre, Denmark.
(3)Laboratoire des Systèmes Perceptifs, CNRS, UMR 8248, Paris, France; 
Département d'Études Cognitives, École Normale Supérieure, PSL Research 
University, Paris, France.
(4)Department of Electrical Engineering, Columbia University, New York, NY, USA; 
Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New 
York, NY, USA.
(5)Department of Neurosurgery, Hofstra-Northwell School of Medicine and 
Feinstein Institute for Medical Research, Manhasset, New York, NY, USA.
(6)University of Zürich and ETH Zürich, Institute of Neuroinformatics, 
Switzerland.
(7)Department of Electrical Engineering, Columbia University, New York, NY, USA; 
Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New 
York, NY, USA. Electronic address: nima@ee.columbia.edu.

Hearing-impaired people often struggle to follow the speech stream of an 
individual talker in noisy environments. Recent studies show that the brain 
tracks attended speech and that the attended talker can be decoded from neural 
data on a single-trial level. This raises the possibility of "neuro-steered" 
hearing devices in which the brain-decoded intention of a hearing-impaired 
listener is used to enhance the voice of the attended speaker from a speech 
separation front-end. So far, methods that use this paradigm have focused on 
optimizing the brain decoding and the acoustic speech separation independently. 
In this work, we propose a novel framework called brain-informed speech 
separation (BISS)1 in which the information about the attended speech, as 
decoded from the subject's brain, is directly used to perform speech separation 
in the front-end. We present a deep learning model that uses neural data to 
extract the clean audio signal that a listener is attending to from a 
multi-talker speech mixture. We show that the framework can be applied 
successfully to the decoded output from either invasive intracranial 
electroencephalography (iEEG) or non-invasive electroencephalography (EEG) 
recordings from hearing-impaired subjects. It also results in improved speech 
separation, even in scenes with background noise. The generalization capability 
of the system renders it a perfect candidate for neuro-steered hearing-assistive 
devices.

Copyright © 2020. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2020.117282
PMCID: PMC8056438
PMID: 32828921 [Indexed for MEDLINE]


93. Neuroimage Clin. 2017 Sep 4;16:514-523. doi: 10.1016/j.nicl.2017.09.001. 
eCollection 2017.

Auditory cross-modal reorganization in cochlear implant users indicates 
audio-visual integration.

Stropahl M(1), Debener S(1)(2).

Author information:
(1)Neuropsychology Lab, Department of Psychology, European Medical School, Carl 
von Ossietzky University Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all Oldenburg, Germany.

There is clear evidence for cross-modal cortical reorganization in the auditory 
system of post-lingually deafened cochlear implant (CI) users. A recent report 
suggests that moderate sensori-neural hearing loss is already sufficient to 
initiate corresponding cortical changes. To what extend these changes are 
deprivation-induced or related to sensory recovery is still debated. Moreover, 
the influence of cross-modal reorganization on CI benefit is also still unclear. 
While reorganization during deafness may impede speech recovery, reorganization 
also has beneficial influences on face recognition and lip-reading. As CI users 
were observed to show differences in multisensory integration, the question 
arises if cross-modal reorganization is related to audio-visual integration 
skills. The current electroencephalography study investigated cortical 
reorganization in experienced post-lingually deafened CI users (n = 18), 
untreated mild to moderately hearing impaired individuals (n = 18) and normal 
hearing controls (n = 17). Cross-modal activation of the auditory cortex by 
means of EEG source localization in response to human faces and audio-visual 
integration, quantified with the McGurk illusion, were measured. CI users 
revealed stronger cross-modal activations compared to age-matched normal hearing 
individuals. Furthermore, CI users showed a relationship between cross-modal 
activation and audio-visual integration strength. This may further support a 
beneficial relationship between cross-modal activation and daily-life 
communication skills that may not be fully captured by laboratory-based speech 
perception tests. Interestingly, hearing impaired individuals showed behavioral 
and neurophysiological results that were numerically between the other two 
groups, and they showed a moderate relationship between cross-modal activation 
and the degree of hearing loss. This further supports the notion that auditory 
deprivation evokes a reorganization of the auditory system even at early stages 
of hearing loss.

DOI: 10.1016/j.nicl.2017.09.001
PMCID: PMC5609862
PMID: 28971005 [Indexed for MEDLINE]


94. Med Lav. 2022 Jun 28;113(3):e2022023. doi: 10.23749/mdl.v113i3.12734.

Predicting and classifying hearing loss in sailors working on speed vessels 
using neural networks: a field study.

Esmaeili R(1), Zare S(2), Ghasemian F(3), Pourtaghi F(4), Saeidnia H(5), 
Pourtaghi G(6).

Author information:
(1)Marine Medicine Research Center, Baqiyatallah University of Medical Sciences, 
Tehran, Iran. rezaesmaeili794@yahoo.com.
(2)Department of Occupational Health Engineering and Safety at Work, Faculty of 
Public Health, Kerman University of Medical Sciences, Kerman, Iran. 
ss_zare87@yahoo.com.
(3)Department of Computer Engineering, Faculty of Engineering, Shahid Bahonar 
University of Kerman, Kerman, Iran. Ghasemianfahime@uk.ac.ir.
(4)School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, 
Iran. dr.f.pourtaghi@gmail.com.
(5)Marine Medicine Research Center, Baqiyatallah University of Medical Sciences, 
Tehran, Iran. hamidsaednia@gmail.com.
(6)Health Research Center, Lifestyle institute, Baqiyatallah University of 
Medical Sciences, Tehran, Iran. pourtaghi@bmsu.ac.ir.

 Noise-induced hearing loss (NIHL) is one of the main risk factors affecting 
people's health and wellbeing in the workplace. Analysing NIHL and consequently 
controlling the causing factors can significantly affect the improvement of 
working environments. Methods: One hundred and twelve male sailors participated 
in this study. They were classified into three groups depending on occupational 
noise exposure: (A) none, i.e., sound pressure level (SPL) lower than 70dBA, (B) 
exposed to SPL in the range of 70-85dBA, and (C) exposed to SPL exceeding 80dBA. 
In a first phase, hearing loss shaping risk factors were identified and 
analysed, including hearing loss in different frequencies, age, work experience, 
sound pressure level (SPL), marital status, and systolic and diastolic blood 
pressure. Then, neural networks were trained to predict the hearing loss changes 
of personnel and used to determine the weight of hearing loss factors. Finally, 
the accuracy of predicting models was calculated relying on Bayesian 
statistics. Results and conclusion: In the present study using neural networks, 
five models were developed. Their accuracy ranged from 92% to 100%. The 
frequencies of 4000Hz and 2000Hz showed the strongest association with the 
hearing loss of the sailors. Also, including systolic and diastolic blood 
pressure did not have any impact on predicted hearing loss, indicating that SPL 
was poorly correlated with extra-auditory effects.

DOI: 10.23749/mdl.v113i3.12734
PMCID: PMC9437656
PMID: 35766647 [Indexed for MEDLINE]


95. Eur Arch Otorhinolaryngol. 2023 Oct;280(10):4433-4444. doi: 
10.1007/s00405-023-07961-7. Epub 2023 Apr 12.

Audiological outcomes of robot-assisted cochlear implant surgery.

Heuninck E(1), Van de Heyning P(2)(3), Van Rompaey V(2)(3), Mertens G(2)(3), 
Topsakal V(4).

Author information:
(1)Department of Otorhinolaryngology Head and Neck Surgery, University Hospital 
Brussels, Vrije Universiteit Brussel, Brussels Health Campus, Brussels, Belgium. 
emilie.heuninck@uzbrussel.be.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, Antwerp University 
Hospital, Antwerp, Belgium.
(3)Experimental Laboratory of Translational Neurosciences and 
Dento-Otolaryngology, Faculty of Medicine and Health Sciences, University of 
Antwerp, Antwerp, Belgium.
(4)Department of Otorhinolaryngology Head and Neck Surgery, University Hospital 
Brussels, Vrije Universiteit Brussel, Brussels Health Campus, Brussels, Belgium.

PURPOSE: The main objective of this study is to evaluate the short-term and 
long-term audiological outcomes in patients who underwent cochlear implantation 
with a robot-assisted system to enable access to the cochlea, and to compare 
outcomes with a matched control group of patients who underwent cochlear 
implantation with conventional access to the cochlea.
METHODS: In total, 23 patients were implanted by robot-assisted cochlear implant 
surgery (RACIS). To evaluate the effectiveness of robotic surgery in terms of 
audiological outcomes, a statistically balanced control group of conventionally 
implanted patients was created. Minimal outcome measures (MOM), consisting of 
pure-tone audiometry, speech understanding in quiet and speech understanding in 
noise were performed pre-operatively and at 3 months, 6 months, 12 months and 
2 years post-activation of the audioprocessor.
RESULTS: There was no statistically significant difference in pure-tone 
audiometry, speech perception in quiet and speech perception in noise between 
robotically implanted and conventionally implanted patients pre-operatively, 
3 months, 6 months, 12 months and 2 years post-activation. A significant 
improvement in pure-tone hearing thresholds, speech understanding in quiet and 
speech understanding in noise with the cochlear implant has been quantified as 
of the first measurements at 3 months and this significant improvement remained 
stable over a time period of 2 years for HEARO implanted patients.
CONCLUSION: Clinical outcomes in robot-assisted cochlear implant surgery are 
comparable to conventional cochlear implantation. CLINICALTRAILS.
GOV TRAIL REGISTRATION NUMBERS: NCT03746613 (date of registration: 19/11/2018), 
NCT04102215 (date of registration: 25/09/2019).

© 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
part of Springer Nature.

DOI: 10.1007/s00405-023-07961-7
PMID: 37043021 [Indexed for MEDLINE]


96. Hear Res. 2019 May;376:111-124. doi: 10.1016/j.heares.2019.02.015. Epub 2019 Mar 
2.

The aging cochlea: Towards unraveling the functional contributions of strial 
dysfunction and synaptopathy.

Heeringa AN(1), Köppl C(2).

Author information:
(1)Cluster of Excellence 'Hearing4all' and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129, Oldenburg, Germany.
(2)Cluster of Excellence 'Hearing4all' and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129, Oldenburg, Germany. Electronic address: 
christine.koeppl@uni-oldenburg.de.

Strial dysfunction is commonly observed as a key consequence of aging in the 
cochlea. A large body of animal research, especially in the quiet-aged Mongolian 
gerbil, shows specific histopathological changes in the cochlear stria 
vascularis and the putatively corresponding effects on endocochlear potential 
and auditory nerve responses. However, recent work suggests that synaptopathy, 
or the loss of inner hair cell-auditory nerve fiber synapses, also presents as a 
consequence of aging. It is now believed that the loss of synapses is the 
earliest age-related degenerative event. The present review aims to integrate 
classic and novel research on age-related pathologies of the inner ear. First, 
we summarize current knowledge on age-related strial dysfunction and 
synaptopathy. We describe how these cochlear pathologies fit into the categories 
for presbyacusis, as first defined by Schuknecht in the '70s. Further, we 
discuss how strial dysfunction and synaptopathy affect sound coding by the 
auditory nerve and how they can be experimentally induced to study their 
specific contributions to age-related hearing deficits. As such, we aim to give 
an overview of the current literature on age-related cochlear pathologies and 
hope to inspire further research on the role of cochlear aging in age-related 
hearing deficits.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.02.015
PMID: 30862414 [Indexed for MEDLINE]


97. Ear Hear. 2016 Sep-Oct;37(5):e276-e290. doi: 10.1097/AUD.0000000000000301.

The Physiological Basis and Clinical Use of the Binaural Interaction Component 
of the Auditory Brainstem Response.

Laumen G(#)(1), Ferber AT(#)(2), Klump GM(1), Tollin DJ(2).

Author information:
(1)Cluster of Excellence Hearing4all, Animal Physiology and Behavior Group, 
Department for Neuroscience, School of Medicine and Health Sciences, Oldenburg 
University, 26111 Oldenburg, Germany.
(2)Department of Physiology and Biophysics, School of Medicine, University of 
Colorado, Aurora, Colorado 80045, USA.
(#)Contributed equally

The auditory brainstem response (ABR) is a sound-evoked noninvasively measured 
electrical potential representing the sum of neuronal activity in the auditory 
brainstem and midbrain. ABR peak amplitudes and latencies are widely used in 
human and animal auditory research and for clinical screening. The binaural 
interaction component (BIC) of the ABR stands for the difference between the sum 
of the monaural ABRs and the ABR obtained with binaural stimulation. The BIC 
comprises a series of distinct waves, the largest of which (DN1) has been used 
for evaluating binaural hearing in both normal hearing and hearing-impaired 
listeners. Based on data from animal and human studies, the authors discuss the 
possible anatomical and physiological bases of the BIC (DN1 in particular). The 
effects of electrode placement and stimulus characteristics on the binaurally 
evoked ABR are evaluated. The authors review how interaural time and intensity 
differences affect the BIC and, analyzing these dependencies, draw conclusion 
about the mechanism underlying the generation of the BIC. Finally, the utility 
of the BIC for clinical diagnoses are summarized.

DOI: 10.1097/AUD.0000000000000301
PMCID: PMC4996694
PMID: 27232077 [Indexed for MEDLINE]


98. Int J Audiol. 2023 Jan;62(1):30-43. doi: 10.1080/14992027.2021.2015633. Epub 
2021 Dec 28.

Spatial speech-in-noise performance in simulated single-sided deaf and bimodal 
cochlear implant users in comparison with real patients.

Jürgens T(1)(2), Wesarg T(3), Oetting D(4), Jung L(3), Williges B(2)(5).

Author information:
(1)Institute of Acoustics, University of Applied Sciences Lübeck, Lübeck, 
Germany.
(2)Medical Physics and Cluster of Excellence "Hearing4all", Carl-von-Ossietzky 
University, Oldenburg, Germany.
(3)Faculty of Medicine, Department of Otorhinolaryngology - Head and Neck 
Surgery, Medical Center, University of Freiburg, Freiburg, Germany.
(4)Hörzentrum Oldenburg gGmbH, Oldenburg, Germany.
(5)SOUND Lab, Cambridge Hearing Group, Department of Clinical Neurosciences, 
University of Cambridge, Cambridge, UK.

OBJECTIVE: Speech reception thresholds (SRTs) in spatial scenarios were measured 
in simulated cochlear implant (CI) listeners with either contralateral normal 
hearing, or aided hearing impairment (bimodal), and compared to SRTs of real 
patients, who were measured using the exact same paradigm, to assess goodness of 
simulation.
DESIGN: CI listening was simulated using a vocoder incorporating actual CI 
signal processing and physiologic details of electric stimulation on one side. 
Unprocessed signals or simulation of aided moderate or profound hearing 
impairment was used contralaterally. Three spatial speech-in-noise scenarios 
were tested using virtual acoustics to assess spatial release from masking (SRM) 
and combined benefit.
STUDY SAMPLE: Eleven normal-hearing listeners participated in the experiment.
RESULTS: For contralateral normal and aided moderately impaired hearing, 
bilaterally assessed SRTs were not statistically different from unilateral SRTs 
of the better ear, indicating "better-ear-listening". Combined benefit was only 
found for contralateral profound impaired hearing. As in patients, SRM was 
highest for contralateral normal hearing and decreased systematically with more 
severe simulated impairment. Comparison to actual patients showed good 
reproduction of SRTs, SRM, and better-ear-listening.
CONCLUSIONS: The simulations reproduced better-ear-listening as in patients and 
suggest that combined benefit in spatial scenes predominantly occurs when both 
ears show poor speech-in-noise performance.

DOI: 10.1080/14992027.2021.2015633
PMID: 34962428 [Indexed for MEDLINE]


99. Hear Res. 2024 Apr;445:108996. doi: 10.1016/j.heares.2024.108996. Epub 2024 Mar 
23.

Noise-induced synaptic loss and its post-exposure recovery in CBA/CaJ vs. 
C57BL/6J mice.

Wu PZ(1), Liberman LD(2), Liberman MC(3).

Author information:
(1)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA 02114, USA; 
Department of Otolaryngology, Harvard Medical School, Boston, MA 02115, USA.
(2)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA 02114, USA.
(3)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA 02114, USA; 
Department of Otolaryngology, Harvard Medical School, Boston, MA 02115, USA. 
Electronic address: Charles_Liberman@meei.harvard.edu.

Acute noise-induced loss of synapses between inner hair cells (IHCs) and 
auditory nerve fibers (ANFs) has been documented in several strains of mice, but 
the extent of post-exposure recovery reportedly varies dramatically. If such 
inter-strain heterogeneity is real, it could be exploited to probe molecular 
pathways mediating neural remodeling in the adult cochlea. Here, we compared 
synaptopathy repair in CBA/CaJ vs. C57BL/6J, which are at opposite ends of the 
reported recovery spectrum. We evaluated C57BL/6J mice 0 h, 24 h, 2 wks or 8 wks 
after exposure for 2 h to octave-band noise (8-16 kHz) at either 90, 94 or 98 dB 
SPL, to compare with analogous post-exposure results in CBA/CaJ at 98 or 101 dB. 
We counted pre- and post-synaptic puncta in immunostained cochleas, using 
machine learning to classify paired (GluA2 and CtBP2) vs. orphan (CtBP2 only) 
puncta, and batch-processing to quantify immunostaining intensity. At 98 dB, 
both strains show ongoing loss of ribbons and synapses between 0 and 24 h, 
followed by partial recovery, however the extent and degree of these changes 
were greater in C57BL/6J. Much of the synaptic recovery is due to transient 
reduction in GluA2 intensity in synaptopathic regions. In contrast, CtBP2 
intensity showed only transient increases (at 2 wks). Neurofilament staining 
revealed transient extension of ANF terminals in C57BL/6J, but not in CBA/CaJ, 
peaking at 24 h and reverting by 2 wks. Thus, although interstrain differences 
in synapse recovery are dominated by reversible changes in GluA2 receptor 
levels, the neurite extension seen in C57BL/6J suggests a qualitative difference 
in regenerative capacity.

Copyright © 2024 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2024.108996
PMCID: PMC11024800
PMID: 38547565 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
have no conflicts of interest or relevant financial relationships to disclose.


100. Int J Audiol. 2022 Apr;61(4):301-310. doi: 10.1080/14992027.2021.1905890. Epub 
2021 Apr 7.

Audiometric profiles and patterns of benefit: a data-driven analysis of 
subjective hearing difficulties and handicaps.

Sanchez-Lopez R(1), Dau T(1), Whitmer WM(2)(3).

Author information:
(1)Hearing Systems Section, Department of Health Technology, Technical 
University of Denmark, Lyngby, Denmark.
(2)Hearing Sciences - Scottish Section, Division of Clinical Neuroscience, 
School of Medicine, University of Nottingham, Glasgow, UK.
(3)Institute of Health and Wellbeing, College of Medical, Veterinary, and Life 
Sciences, University of Glasgow, Glasgow, UK.

OBJECTIVE: Hearing rehabilitation attempts to compensate for auditory 
dysfunction, reduce hearing difficulties and minimise participation restrictions 
that can lead to social isolation. However, there is no systematic approach to 
assess the quality of the intervention at an individual level that might help to 
evaluate the need of further hearing rehabilitation in the hearing care clinic.
DESIGN: A data-driven analysis on subjective data reflecting hearing 
disabilities and handicap was chosen to explore "benefit patterns" as a result 
of rehabilitation in different audiometric groups. The method was based on (1) 
dimensionality reduction; (2) stratification; (3) archetypal analysis; (4) 
clustering; (5) item importance estimation.
STUDY SAMPLE: 572 hearing-aid users completed questionnaires of hearing 
difficulties (speech, spatial and qualities hearing scale; SSQ) and hearing 
handicap (HHQ).
RESULTS: The data-driven approach revealed four benefit profiles that were 
different for each audiometric group. The groups with low degree of 
high-frequency hearing loss (HLHF) showed a priority for rehabilitating hearing 
handicaps, whereas the groups with HLHF > 50 dB HL showed a priority for 
improvements in speech understanding.
CONCLUSIONS: The patterns of benefit and the stratification approach might guide 
the clinical intervention strategy and improve the efficacy and quality of 
service in the hearing care clinic.

DOI: 10.1080/14992027.2021.1905890
PMID: 33825590 [Indexed for MEDLINE]


101. Trends Hear. 2020 Jan-Dec;24:2331216520938929. doi: 10.1177/2331216520938929.

Individual Aided Speech-Recognition Performance and Predictions of Benefit for 
Listeners With Impaired Hearing Employing FADE.

Schädler MR(1), Hülsmeier D(1), Warzybok A(1), Kollmeier B(1).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg.

The benefit in speech-recognition performance due to the compensation of a 
hearing loss can vary between listeners, even if unaided performance and hearing 
thresholds are similar. To accurately predict the individual performance benefit 
due to a specific hearing device, a prediction model is proposed which takes 
into account hearing thresholds and a frequency-dependent suprathreshold 
component of impaired hearing. To test the model, the German matrix sentence 
test was performed in unaided and individually aided conditions in quiet and in 
noise by 18 listeners with different degrees of hearing loss. The outcomes were 
predicted by an individualized automatic speech-recognition system where the 
individualization parameter for the suprathreshold component of hearing loss was 
inferred from tone-in-noise detection thresholds. The suprathreshold component 
was implemented as a frequency-dependent multiplicative noise (mimicking level 
uncertainty) in the feature-extraction stage of the automatic speech-recognition 
system. Its inclusion improved the root-mean-square prediction error of 
individual speech-recognition thresholds (SRTs) from 6.3 dB to 4.2 dB and of 
individual benefits in SRT due to common compensation strategies from 5.1 dB to 
3.4 dB. The outcome predictions are highly correlated with both the 
corresponding observed SRTs (R2 = .94) and the benefits in SRT (R2 = .89) and 
hence might help to better understand-and eventually mitigate-the perceptual 
consequences of as yet unexplained hearing problems, also discussed in the 
context of hidden hearing loss.

DOI: 10.1177/2331216520938929
PMCID: PMC7493243
PMID: 32924797 [Indexed for MEDLINE]


102. Trends Hear. 2021 Jan-Dec;25:2331216520988406. doi: 10.1177/2331216520988406.

Towards Personalized Auditory Models: Predicting Individual Sensorineural 
Hearing-Loss Profiles From Recorded Human Auditory Physiology.

Keshishzadeh S(1), Garrett M(2), Verhulst S(1).

Author information:
(1)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Belgium.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Department of 
Medical Physics and Acoustics, University of Oldenburg, Oldenburg, Germany.

Over the past decades, different types of auditory models have been developed to 
study the functioning of normal and impaired auditory processing. Several models 
can simulate frequency-dependent sensorineural hearing loss (SNHL) and can in 
this way be used to develop personalized audio-signal processing for hearing 
aids. However, to determine individualized SNHL profiles, we rely on indirect 
and noninvasive markers of cochlear and auditory-nerve (AN) damage. Our 
progressive knowledge of the functional aspects of different SNHL subtypes 
stresses the importance of incorporating them into the simulated SNHL profile, 
but has at the same time complicated the task of accomplishing this on the basis 
of noninvasive markers. In particular, different auditory-evoked potential (AEP) 
types can show a different sensitivity to outer-hair-cell (OHC), inner-hair-cell 
(IHC), or AN damage, but it is not clear which AEP-derived metric is best suited 
to develop personalized auditory models. This study investigates how simulated 
and recorded AEPs can be used to derive individual AN- or OHC-damage patterns 
and personalize auditory processing models. First, we individualized the 
cochlear model parameters using common methods of frequency-specific OHC-damage 
quantification, after which we simulated AEPs for different degrees of AN 
damage. Using a classification technique, we determined the recorded AEP metric 
that best predicted the simulated individualized cochlear synaptopathy profiles. 
We cross-validated our method using the data set at hand, but also applied the 
trained classifier to recorded AEPs from a new cohort to illustrate the 
generalizability of the method.

DOI: 10.1177/2331216520988406
PMCID: PMC7871356
PMID: 33526004 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


103. J Am Acad Audiol. 2016 Oct;27(9):732-749. doi: 10.3766/jaaa.15099.

Smartphone-Based System for Learning and Inferring Hearing Aid Settings.

Aldaz G(1), Puria S(2), Leifer LJ(1).

Author information:
(1)Department of Mechanical Engineering, Center for Design Research, Stanford 
University, Stanford, CA.
(2)Mechanics and Computation Division, Department of Mechanical Engineering, 
Stanford University, Stanford, CA.

BACKGROUND: Previous research has shown that hearing aid wearers can 
successfully self-train their instruments' gain-frequency response and 
compression parameters in everyday situations. Combining hearing aids with a 
smartphone introduces additional computing power, memory, and a graphical user 
interface that may enable greater setting personalization. To explore the 
benefits of self-training with a smartphone-based hearing system, a parameter 
space was chosen with four possible combinations of microphone mode 
(omnidirectional and directional) and noise reduction state (active and off). 
The baseline for comparison was the "untrained system," that is, the 
manufacturer's algorithm for automatically selecting microphone mode and noise 
reduction state based on acoustic environment. The "trained system" first 
learned each individual's preferences, self-entered via a smartphone in 
real-world situations, to build a trained model. The system then predicted the 
optimal setting (among available choices) using an inference engine, which 
considered the trained model and current context (e.g., sound environment, 
location, and time).
PURPOSE: To develop a smartphone-based prototype hearing system that can be 
trained to learn preferred user settings. Determine whether user study 
participants showed a preference for trained over untrained system settings.
RESEARCH DESIGN: An experimental within-participants study. Participants used a 
prototype hearing system-comprising two hearing aids, Android smartphone, and 
body-worn gateway device-for ∼6 weeks.
STUDY SAMPLE: Sixteen adults with mild-to-moderate sensorineural hearing loss 
(HL) (ten males, six females; mean age = 55.5 yr). Fifteen had ≥6 mo of 
experience wearing hearing aids, and 14 had previous experience using 
smartphones.
INTERVENTION: Participants were fitted and instructed to perform daily 
comparisons of settings ("listening evaluations") through a smartphone-based 
software application called Hearing Aid Learning and Inference Controller 
(HALIC). In the four-week-long training phase, HALIC recorded individual 
listening preferences along with sensor data from the smartphone-including 
environmental sound classification, sound level, and location-to build trained 
models. In the subsequent two-week-long validation phase, participants performed 
blinded listening evaluations comparing settings predicted by the trained system 
("trained settings") to those suggested by the hearing aids' untrained system 
("untrained settings").
DATA COLLECTION AND ANALYSIS: We analyzed data collected on the smartphone and 
hearing aids during the study. We also obtained audiometric and demographic 
information.
RESULTS: Overall, the 15 participants with valid data significantly preferred 
trained settings to untrained settings (paired-samples t test). Seven 
participants had a significant preference for trained settings, while one had a 
significant preference for untrained settings (binomial test). The remaining 
seven participants had nonsignificant preferences. Pooling data across 
participants, the proportion of times that each setting was chosen in a given 
environmental sound class was on average very similar. However, breaking down 
the data by participant revealed strong and idiosyncratic individual 
preferences. Fourteen participants reported positive feelings of clarity, 
competence, and mastery when training via HALIC.
CONCLUSIONS: The obtained data, as well as subjective participant feedback, 
indicate that smartphones could become viable tools to train hearing aids. 
Individuals who are tech savvy and have milder HL seem well suited to take 
advantages of the benefits offered by training with a smartphone.

American Academy of Audiology

DOI: 10.3766/jaaa.15099
PMCID: PMC5266590
PMID: 27718350 [Indexed for MEDLINE]


104. Ear Hear. 2018 Jul/Aug;39(4):795-809. doi: 10.1097/AUD.0000000000000537.

Deep Learning-Based Noise Reduction Approach to Improve Speech Intelligibility 
for Cochlear Implant Recipients.

Lai YH(1), Tsao Y(2), Lu X(3), Chen F(4), Su YT(5), Chen KC(6)(7), Chen YH(8), 
Chen LC(7), Po-Hung Li L(7)(9), Lee CH(10).

Author information:
(1)Department of Biomedical Engineering, National Yang-Ming University, Taipei, 
Taiwan.
(2)Research Center for Information Technology Innovation, Academia Sinica, 
Taipei, Taiwan.
(3)National Institute of Information and Communications Technology, Japan.
(4)Department of Electrical and Electronic Engineering, Southern University of 
Science and Technology, Shenzhen, China.
(5)Department of Mechatronic Engineering, National Taiwan Normal University, 
Taipei, Taiwan.
(6)Department of Otolaryngology, Far Eastern Memorial Hospital, New Taipei, 
Taiwan.
(7)Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan.
(8)Department of Internal Medicine, Cheng Hsin General Hospital, Taipei, Taiwan.
(9)Faculty of Medicine, School of Medicine, National Yang Ming University, 
Taipei, Taiwan.
(10)School of Electrical and Computer Engineering, Georgia Institute of 
Technology, Georgia, USA.

OBJECTIVE: We investigate the clinical effectiveness of a novel deep 
learning-based noise reduction (NR) approach under noisy conditions with 
challenging noise types at low signal to noise ratio (SNR) levels for 
Mandarin-speaking cochlear implant (CI) recipients.
DESIGN: The deep learning-based NR approach used in this study consists of two 
modules: noise classifier (NC) and deep denoising autoencoder (DDAE), thus 
termed (NC + DDAE). In a series of comprehensive experiments, we conduct 
qualitative and quantitative analyses on the NC module and the overall NC + DDAE 
approach. Moreover, we evaluate the speech recognition performance of the NC + 
DDAE NR and classical single-microphone NR approaches for Mandarin-speaking CI 
recipients under different noisy conditions. The testing set contains Mandarin 
sentences corrupted by two types of maskers, two-talker babble noise, and a 
construction jackhammer noise, at 0 and 5 dB SNR levels. Two conventional NR 
techniques and the proposed deep learning-based approach are used to process the 
noisy utterances. We qualitatively compare the NR approaches by the amplitude 
envelope and spectrogram plots of the processed utterances. Quantitative 
objective measures include (1) normalized covariance measure to test the 
intelligibility of the utterances processed by each of the NR approaches; and 
(2) speech recognition tests conducted by nine Mandarin-speaking CI recipients. 
These nine CI recipients use their own clinical speech processors during 
testing.
RESULTS: The experimental results of objective evaluation and listening test 
indicate that under challenging listening conditions, the proposed NC + DDAE NR 
approach yields higher intelligibility scores than the two compared classical NR 
techniques, under both matched and mismatched training-testing conditions.
CONCLUSIONS: When compared to the two well-known conventional NR techniques 
under challenging listening condition, the proposed NC + DDAE NR approach has 
superior noise suppression capabilities and gives less distortion for the key 
speech envelope information, thus, improving speech recognition more effectively 
for Mandarin CI recipients. The results suggest that the proposed deep 
learning-based NR approach can potentially be integrated into existing CI signal 
processors to overcome the degradation of speech perception caused by noise.

DOI: 10.1097/AUD.0000000000000537
PMID: 29360687 [Indexed for MEDLINE]


105. Auris Nasus Larynx. 2022 Apr;49(2):195-201. doi: 10.1016/j.anl.2021.07.001. Epub 
2021 Jul 23.

Clustering upper airway physicals, otitis media with effusion and auditory 
functions in children.

Aslıer M(1), Aslıer NGY(2), Ercan İ(3), Keskin S(2).

Author information:
(1)Department of Otorhinolaryngology, Sancaktepe Education and Research 
Hospital, Istanbul, Turkey. Electronic address: mustafaaslier@uludag.edu.tr.
(2)Department of Otorhinolaryngology, Sancaktepe Education and Research 
Hospital, Istanbul, Turkey.
(3)Department of Biostatistics, Uludağ University School of Medicine, Bursa, 
Turkey.

OBJECTIVE: Adenoid hypertrophy (AH) has been identified as a cause of otitis 
media with effusion (OME), which is the most common cause of childhood hearing 
loss. Indeed, there may be other upper airway-related predisposing factors such 
as, location of the adenoid, accompanying tonsillar hypertrophy (TH) and nasal 
septal deviation (NSD) for the development of OME. In this study, we aimed to 
evaluate the associations between the upper airway physicals and OME with 
auditory functions.
METHODS: Eighty-six ears of 43 children, aged 3-11 years were included in this 
prospective clinical study. Findings of otolaryngologic examinations were noted. 
Data of pure tone audiometry (PTA), traditional tympanometry (TT) and wideband 
tympanometry (WBT) parameters were collected. Cluster analysis was performed to 
the following variables: age, sex; the adenoid choana percentage (ACP), the 
presences of adenoid around torus tubarius (AATT), TH, NSD and OME; peak 
pressure (PP) values on TT, resonance frequencies (RF) on WBT, ambient pressure 
absorbance ratios (APAR) and PTA hearing thresholds.
RESULTS: Two groups of ears revealed by clustering; cluster-1 (n = 46) and 
cluster-2 (n = 40), at the similarity level of 0.662. The presences of AH, AATT, 
OME and the medians of ACP, PP, RF, WBT APARs at all frequencies except 5656 Hz 
and 8000 Hz, all PTA thresholds were significantly different between two 
clusters (p < 0.05). The lower WBT APARs and higher PTA thresholds were 
associated with higher levels of ACP and higher frequencies of the presence of 
AATT and OME in cluster-1.
CONCLUSION: There are associations between AH, AATT and OME together with 
decline in hearing and SEA. Whereas, TH and NSD are not related to the formation 
of clusters and they are insignificant factors.

Copyright © 2021. Published by Elsevier B.V.

DOI: 10.1016/j.anl.2021.07.001
PMID: 34304942 [Indexed for MEDLINE]

Conflict of interest statement: Declarations of Competing Interest The authors 
have no funding, financial relationships or conflict of interest to disclose.


106. J Int Adv Otol. 2015 Dec;11(3):236-42. doi: 10.5152/iao.2015.1162.

Cortical Evoked Potentials and Hearing Aids in Individuals with Auditory 
Dys-Synchrony.

Yuvaraj P(1), Mannarukrishnaiah J.

Author information:
(1)Department of Speech Pathology and Audiology, National Insitute of Mental 
Health and Neurosciences, Bangalore, India. drmjay16@gmail.com.

OBJECTIVE: The purpose of the present study was to investigate the relationship 
between cortical processing of speech and benefit from hearing aids in 
individuals with auditory dys-synchrony.
MATERIALS AND METHODS: Data were collected from 38 individuals with auditory 
dys-synchrony. Participants were selected based on hearing thresholds, middle 
ear reflexes, otoacoustic emissions, and auditory brain stem responses. 
Cortical-evoked potentials were recorded for click and speech. Participants with 
auditory dys-synchrony were fitted with bilateral multichannel wide dynamic 
range compression hearing aids. Aided and unaided speech identification scores 
for 40 words were obtained for each participant.
RESULTS: Hierarchical cluster analysis using Ward's method clearly showed four 
subgroups of participants with auditory dys-synchrony based on the hearing aid 
benefit score (aided minus unaided speech identification score). The difference 
in the mean aided and unaided speech identification scores was significantly 
different in participants with auditory dys-synchrony. However, the mean unaided 
speech identification scores were not significantly different between the four 
subgroups. The N2 amplitude and P1 latency of the speech-evoked cortical 
potentials were significantly different between the four subgroups formed based 
on hearing aid benefit scores.
CONCLUSION: The results indicated that subgroups of individuals with auditory 
dys-synchrony who benefit from hearing aids exist. Individuals who benefitted 
from hearing aids showed decreased N2 amplitudes compared with those who did 
not. N2 amplitude is associated with greater suppression of background noise 
while processing speech.

DOI: 10.5152/iao.2015.1162
PMID: 26915156 [Indexed for MEDLINE]


107. Trop Med Int Health. 2017 Apr;22(4):485-492. doi: 10.1111/tmi.12840. Epub 2017 
Feb 7.

Prevalence and causes of hearing impairment in Fundong Health District, 
North-West Cameroon.

Ferrite S(1)(2), Mactaggart I(1), Kuper H(1), Oye J(3), Polack S(1).

Author information:
(1)International Centre for Evidence in Disability, London School of Hygiene & 
Tropical Medicine, London, UK.
(2)Department of Hearing and Speech Sciences, Federal University of Bahia, 
Salvador, Brazil.
(3)Sightsavers International, Yaounde, Cameroon.

OBJECTIVE: To estimate the prevalence and causes of hearing impairment in 
Fundong Health District, North-West Cameroon.
METHODS: We selected 51 clusters of 80 people (all ages) through probability 
proportionate to size sampling. Initial hearing screening was undertaken through 
an otoacoustic emission (OAE) test. Participants aged 4+ years who failed this 
test in both ears or for whom an OAE reading could not be taken underwent a 
manual pure-tone audiometry (PTA) screening. Cases of hearing impairment were 
defined as those with pure-tone average ≥41 dBHL in adults and ≥35 dBHL in 
children in the better ear, or children under age 4 who failed the OAE test in 
both ears. Each case with hearing loss was examined by an ear, nose and throat 
nurse who indicated the main likely cause.
RESULTS: We examined 3567 (86.9%) of 4104 eligible people. The overall 
prevalence of hearing impairment was 3.6% (95% confidence interval [CI]: 
2.8-4.6). The prevalence was low in people aged 0-17 (1.1%, 0.7-1.8%) and 18-49 
(1.1%, 0.5-2.6%) and then rose sharply in people aged 50+ (14.8%, 11.7-19.1%). 
Among cases, the majority were classified as moderate (76%), followed by severe 
(15%) and profound (9%). More than one-third of cases of hearing impairment were 
classified as unknown (37%) or conductive (37%) causes, while sensorineural 
causes were less common (26%).
CONCLUSIONS: Prevalence of hearing impairment in North-West Cameroon is in line 
with the WHO estimate for sub-Saharan Africa. The majority of cases with known 
causes are treatable, with impacted wax playing a major role.

© 2017 John Wiley & Sons Ltd.

DOI: 10.1111/tmi.12840
PMID: 28102004 [Indexed for MEDLINE]


108. Neuroimage. 2018 Jul 15;175:425-437. doi: 10.1016/j.neuroimage.2018.04.023. Epub 
2018 Apr 12.

Audio-visual speech processing in age-related hearing loss: Stronger integration 
and increased frontal lobe recruitment.

Rosemann S(1), Thiel CM(2).

Author information:
(1)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany; 
Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität Oldenburg, 
Oldenburg, Germany. Electronic address: Stephanie.rosemann@uni-oldenburg.de.
(2)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany; 
Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität Oldenburg, 
Oldenburg, Germany.

Hearing loss is associated with difficulties in understanding speech, especially 
under adverse listening conditions. In these situations, seeing the speaker 
improves speech intelligibility in hearing-impaired participants. On the 
neuronal level, previous research has shown cross-modal plastic reorganization 
in the auditory cortex following hearing loss leading to altered processing of 
auditory, visual and audio-visual information. However, how reduced auditory 
input effects audio-visual speech perception in hearing-impaired subjects is 
largely unknown. We here investigated the impact of mild to moderate age-related 
hearing loss on processing audio-visual speech using functional magnetic 
resonance imaging. Normal-hearing and hearing-impaired participants performed 
two audio-visual speech integration tasks: a sentence detection task inside the 
scanner and the McGurk illusion outside the scanner. Both tasks consisted of 
congruent and incongruent audio-visual conditions, as well as auditory-only and 
visual-only conditions. We found a significantly stronger McGurk illusion in the 
hearing-impaired participants, which indicates stronger audio-visual 
integration. Neurally, hearing loss was associated with an increased recruitment 
of frontal brain areas when processing incongruent audio-visual, auditory and 
also visual speech stimuli, which may reflect the increased effort to perform 
the task. Hearing loss modulated both the audio-visual integration strength 
measured with the McGurk illusion and brain activation in frontal areas in the 
sentence task, showing stronger integration and higher brain activation with 
increasing hearing loss. Incongruent compared to congruent audio-visual speech 
revealed an opposite brain activation pattern in left ventral postcentral gyrus 
in both groups, with higher activation in hearing-impaired participants in the 
incongruent condition. Our results indicate that already mild to moderate 
hearing loss impacts audio-visual speech processing accompanied by changes in 
brain activation particularly involving frontal areas. These changes are 
modulated by the extent of hearing loss.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.04.023
PMID: 29655940 [Indexed for MEDLINE]


109. Hear Res. 2016 Jan;331:27-40. doi: 10.1016/j.heares.2015.10.004. Epub 2015 Oct 
22.

Suprathreshold auditory processing deficits in noise: Effects of hearing loss 
and age.

Kortlang S(1), Mauermann M(2), Ewert SD(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, D-26111 Oldenburg, Germany. Electronic address: 
steffen.kortlang@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, D-26111 Oldenburg, Germany.

People with sensorineural hearing loss generally suffer from a reduced ability 
to understand speech in complex acoustic listening situations, particularly when 
background noise is present. In addition to the loss of audibility, a mixture of 
suprathreshold processing deficits is possibly involved, like altered basilar 
membrane compression and related changes, as well as a reduced ability of 
temporal coding. A series of 6 monaural psychoacoustic experiments at 0.5, 2, 
and 6 kHz was conducted with 18 subjects, divided equally into groups of young 
normal-hearing, older normal-hearing and older hearing-impaired listeners, 
aiming at disentangling the effects of age and hearing loss on psychoacoustic 
performance in noise. Random frequency modulation detection thresholds (RFMDTs) 
with a low-rate modulator in wide-band noise, and discrimination of a 
phase-jittered Schroeder-phase from a random-phase harmonic tone complex are 
suggested to characterize the individual ability of temporal processing. The 
outcome was compared to thresholds of pure tones and narrow-band noise, loudness 
growth functions, auditory filter bandwidths, and tone-in-noise detection 
thresholds. At 500 Hz, results suggest a contribution of temporal fine structure 
(TFS) to pure-tone detection thresholds. Significant correlation with auditory 
thresholds and filter bandwidths indicated an impact of frequency selectivity on 
TFS usability in wide-band noise. When controlling for the effect of threshold 
sensitivity, the listener's age significantly correlated with tone-in-noise 
detection and RFMDTs in noise at 500 Hz, showing that older listeners were 
particularly affected by background noise at low carrier frequencies.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.10.004
PMID: 26471199 [Indexed for MEDLINE]


110. Int J Audiol. 2020 Aug;59(8):574-582. doi: 10.1080/14992027.2020.1739764. Epub 
2020 Mar 17.

Field test of the Rapid Assessment of Hearing Loss survey protocol in Ntcheu 
district, Malawi.

Bright T(1), Mulwafu W(2), Phiri M(3), Jiang F(4), Swanepoel W(5), Kuper H(1), 
Mactaggart I(1), Yip JLY(1), Polack S(1).

Author information:
(1)International Centre for Evidence in Disability, London School of Hygiene and 
Tropical Medicine, London, UK.
(2)Department of Surgery, College of Medicine, Blantyre, Malawi.
(3)Audiology Department, Queen Elizabeth Central Hospital, Blantyre, Malawi.
(4)School of Public Health, Shandong University, Jinan, China.
(5)Department of Speech-Language Pathology and Audiology, University of 
Pretoria, South Africa.

Objective: (1) To test the feasibility of the Rapid Assessment of Hearing Loss 
(RAHL) survey protocol in Malawi (Ntcheu); (2) To estimate the prevalence and 
probable causes of hearing loss (adults 50+).Design: Cross-sectional 
population-based survey.Study sample: Clusters (n = 38) were selected using 
probability-proportionate-to-size-sampling. Within each cluster, 30 people aged 
50+ were selected using compact-segment-sampling. All participants completed 
smartphone-based audiometry (hearTest). Prevalence was estimated using WHO 
definitions (PTA of thresholds 0.5, 1, 2, 4 kHz in the better ear of >25 dB HL 
(any) and >40 dB HL (≥moderate)). Otoscopy and questionnaire were used to assess 
probable causes. Participants with hearing loss and/or ear disease were asked 
about care-seeking and barriers.Results: Four teams completed the survey in 
24 days. 1080 of 1153 (93.7%) participants were examined. The median time to 
complete the protocol was 24 min/participant. Prevalence of hearing loss was 
35.9% (95% CI = 31.6-40.2) (any level); and 10.0% (95% CI = 7.9-12.5) 
(≥moderate). The majority was classified as probable sensorineural. Nearly one 
third of people (30.9%) needed diagnostic audiology services and possible 
hearing aid fitting. Hearing aid coverage was <1%. Lack of perceived need was a 
key barrier.Conclusion: The RAHL is simple, fast and provides information about 
the magnitude and probable causes of hearing loss to plan services.

DOI: 10.1080/14992027.2020.1739764
PMID: 32180476 [Indexed for MEDLINE]


111. Proc Biol Sci. 2017 Sep 27;284(1863):20171584. doi: 10.1098/rspb.2017.1584.

Barn owls have ageless ears.

Krumm B(1), Klump G(1), Köppl C(1), Langemann U(2).

Author information:
(1)Cluster of Excellence 'Hearing4all', Animal Physiology and Behaviour Group, 
Department of Neuroscience, School of Medicine and Health Sciences, University 
of Oldenburg, 26111 Oldenburg, Germany.
(2)Cluster of Excellence 'Hearing4all', Animal Physiology and Behaviour Group, 
Department of Neuroscience, School of Medicine and Health Sciences, University 
of Oldenburg, 26111 Oldenburg, Germany ulrike.langemann@uni-oldenburg.de.

We measured the auditory sensitivity of the barn owl (Tyto alba), using a 
behavioural Go/NoGo paradigm in two different age groups, one younger than 2 
years (n = 4) and another more than 13 years of age (n = 3). In addition, we 
obtained thresholds from one individual aged 23 years, three times during its 
lifetime. For computing audiograms, we presented test frequencies of between 0.5 
and 12 kHz, covering the hearing range of the barn owl. Average thresholds in 
quiet were below 0 dB sound pressure level (SPL) for frequencies between 1 and 
10 kHz. The lowest mean threshold was -12.6 dB SPL at 8 kHz. Thresholds were the 
highest at 12 kHz, with a mean of 31.7 dB SPL. Test frequency had a significant 
effect on auditory threshold but age group had no significant effect. There was 
no significant interaction between age group and test frequency. Repeated 
threshold estimates over 21 years from a single individual showed only a slight 
increase in thresholds. We discuss the auditory sensitivity of barn owls with 
respect to other species and suggest that birds, which generally show a 
remarkable capacity for regeneration of hair cells in the basilar papilla, are 
naturally protected from presbycusis.

© 2017 The Author(s).

DOI: 10.1098/rspb.2017.1584
PMCID: PMC5627212
PMID: 28931742 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


112. Hear Res. 2021 Sep 15;409:108317. doi: 10.1016/j.heares.2021.108317. Epub 2021 
Jul 22.

A deep learning approach to quantify auditory hair cells.

Cortada M(1), Sauteur L(2), Lanz M(3), Levano S(4), Bodmer D(5).

Author information:
(1)Department of Biomedicine, University of Basel, Hebelstrasse 20, Basel 4031, 
Switzerland. Electronic address: maurizio.cortada@unibas.ch.
(2)Department of Biomedicine, University of Basel, Hebelstrasse 20, Basel 4031, 
Switzerland. Electronic address: loic.sauteur@unibas.ch.
(3)Department of Biomedicine, University of Basel, Hebelstrasse 20, Basel 4031, 
Switzerland. Electronic address: michi.lanz@unibas.ch.
(4)Department of Biomedicine, University of Basel, Hebelstrasse 20, Basel 4031, 
Switzerland. Electronic address: s.levano@unibas.ch.
(5)Department of Biomedicine, University of Basel, Hebelstrasse 20, Basel 4031, 
Switzerland; Clinic for Otorhinolaryngology, Head and Neck Surgery, University 
of Basel Hospital, Petersgraben 4, Basel CH-4031, Switzerland. Electronic 
address: Daniel.Bodmer@usb.ch.

Hearing loss affects millions of people worldwide. Yet, there are still no 
curative therapies for sensorineural hearing loss. Frequent causes of 
sensorineural hearing loss are due to damage or loss of the sensory hair cells, 
the spiral ganglion neurons, or the synapses between them. Culturing the organ 
of Corti allows the study of all these structures in an experimental model, 
which is easy to manipulate. Therefore, the in vitro culture of the neonatal 
mammalian organ of Corti remains a frequently used experimental system, in which 
hair cell survival is routinely assessed. However, the analysis of the surviving 
hair cells is commonly performed via manual counting, which is a time-consuming 
process and the inter-rater reliability can be an issue. Here, we describe a 
deep learning approach to quantify hair cell survival in the murine organ of 
Corti explants. We used StarDist, a publicly available platform and plugin for 
Fiji (Fiji is just ImageJ), to train and apply our own custom deep learning 
model. We successfully validated our model in untreated, cisplatin, and 
gentamicin treated organ of Corti explants. Therefore, deep learning is a 
valuable approach for quantifying hair cell survival in organ of Corti explants. 
Moreover, we also demonstrate how the publicly available Fiji plugin StarDist 
can be efficiently used for this purpose.

Copyright © 2021. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2021.108317
PMID: 34343849 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest None


113. Neuroimage. 2019 Aug 1;196:261-268. doi: 10.1016/j.neuroimage.2019.04.017. Epub 
2019 Apr 9.

Hearing-impaired listeners show increased audiovisual benefit when listening to 
speech in noise.

Puschmann S(1), Daeglau M(2), Stropahl M(3), Mirkovic B(4), Rosemann S(5), Thiel 
CM(6), Debener S(7).

Author information:
(1)Montreal Neurological Institute, McGill University, Montreal, Quebec, H3A 
2B4, Canada; Biological Psychology Lab, Department of Psychology, School of 
Medicine and Health Sciences, Carl von Ossietzky Universität Oldenburg, 26111, 
Oldenburg, Germany; Cluster of Excellence Hearing4All, Carl von Ossietzky 
Universität Oldenburg, 26111, Oldenburg, Germany. Electronic address: 
sebastian.puschmann@mail.mcgill.ca.
(2)Neuropsychology Lab, Department of Psychology, School of Medicine and Health 
Sciences, Carl von Ossietzky Universität Oldenburg, 26111, Oldenburg, Germany; 
Neurocognition and Functional Neurorehabilitation Group, Department of 
Psychology, School of Medicine and Health Sciences, Carl von Ossietzky 
Universität Oldenburg, 26111, Oldenburg, Germany.
(3)Neuropsychology Lab, Department of Psychology, School of Medicine and Health 
Sciences, Carl von Ossietzky Universität Oldenburg, 26111, Oldenburg, Germany.
(4)Cluster of Excellence Hearing4All, Carl von Ossietzky Universität Oldenburg, 
26111, Oldenburg, Germany; Neuropsychology Lab, Department of Psychology, School 
of Medicine and Health Sciences, Carl von Ossietzky Universität Oldenburg, 
26111, Oldenburg, Germany.
(5)Biological Psychology Lab, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, 26111, Oldenburg, 
Germany; Cluster of Excellence Hearing4All, Carl von Ossietzky Universität 
Oldenburg, 26111, Oldenburg, Germany.
(6)Biological Psychology Lab, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, 26111, Oldenburg, 
Germany; Cluster of Excellence Hearing4All, Carl von Ossietzky Universität 
Oldenburg, 26111, Oldenburg, Germany; Research Center Neurosensory Science, Carl 
von Ossietzky Universität Oldenburg, 26111, Oldenburg, Germany.
(7)Cluster of Excellence Hearing4All, Carl von Ossietzky Universität Oldenburg, 
26111, Oldenburg, Germany; Neuropsychology Lab, Department of Psychology, School 
of Medicine and Health Sciences, Carl von Ossietzky Universität Oldenburg, 
26111, Oldenburg, Germany; Research Center Neurosensory Science, Carl von 
Ossietzky Universität Oldenburg, 26111, Oldenburg, Germany.

Recent studies provide evidence for changes in audiovisual perception as well as 
for adaptive cross-modal auditory cortex plasticity in older individuals with 
high-frequency hearing impairments (presbycusis). We here investigated whether 
these changes facilitate the use of visual information, leading to an increased 
audiovisual benefit of hearing-impaired individuals when listening to speech in 
noise. We used a naturalistic design in which older participants with a varying 
degree of high-frequency hearing loss attended to running auditory or 
audiovisual speech in noise and detected rare target words. Passages containing 
only visual speech served as a control condition. Simultaneously acquired scalp 
electroencephalography (EEG) data were used to study cortical speech tracking. 
Target word detection accuracy was significantly increased in the audiovisual as 
compared to the auditory listening condition. The degree of this audiovisual 
enhancement was positively related to individual high-frequency hearing loss and 
subjectively reported listening effort in challenging daily life situations, 
which served as a subjective marker of hearing problems. On the neural level, 
the early cortical tracking of the speech envelope was enhanced in the 
audiovisual condition. Similar to the behavioral findings, individual 
differences in the magnitude of the enhancement were positively associated with 
listening effort ratings. Our results therefore suggest that hearing-impaired 
older individuals make increased use of congruent visual information to 
compensate for the degraded auditory input.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.04.017
PMID: 30978494 [Indexed for MEDLINE]


114. eNeuro. 2021 Dec 8;8(6):ENEURO.0258-21.2021. doi: 10.1523/ENEURO.0258-21.2021. 
Print 2021 Nov-Dec.

Treatment of Age-Related Hearing Loss Alters Audiovisual Integration and 
Resting-State Functional Connectivity: A Randomized Controlled Pilot Trial.

Rosemann S(1)(2), Gieseler A(2)(3), Tahden M(2)(3), Colonius H(2)(3), Thiel 
CM(1)(2).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky Universität Oldenburg, Oldenburg 26111, 
Germany stephanie.rosemann@uni-oldenburg.de christiane.thiel@uni-oldenburg.de.
(2)Cluster of Excellence "Hearing4all," Carl von Ossietzky Universität 
Oldenburg, Oldenburg 26111, Germany.
(3)Cognitive Psychology, Department of Psychology, School of Medicine and Health 
Sciences, Carl von Oldenburg 26111 Universität Oldenburg, Oldenburg 26111, 
Germany.

Untreated age-related hearing loss increases audiovisual integration and impacts 
resting state functional brain connectivity. Further, there is a relation 
between crossmodal plasticity and audiovisual integration strength in cochlear 
implant patients. However, it is currently unclear whether amplification of the 
auditory input by hearing aids influences audiovisual integration and resting 
state functional brain connectivity. We conducted a randomized controlled pilot 
study to investigate how the McGurk illusion, a common measure for audiovisual 
integration, and resting state functional brain connectivity of the auditory 
cortex are altered by six-month hearing aid use. Thirty-two older participants 
with slight-to-moderate, symmetric, age-related hearing loss were allocated to a 
treatment or waiting control group and measured one week before and six months 
after hearing aid fitting with functional magnetic resonance imaging. Our 
results showed a statistical trend for an increased McGurk illusion after six 
months of hearing aid use. We further demonstrated that an increase in McGurk 
susceptibility is related to a decreased hearing aid benefit for auditory speech 
intelligibility in noise. No significant interaction between group and time 
point was obtained in the whole-brain resting state analysis. However, a region 
of interest (ROI)-to-ROI analysis indicated that hearing aid use of six months 
was associated with a decrease in resting state functional connectivity between 
the auditory cortex and the fusiform gyrus and that this decrease was related to 
an increase of perceived McGurk illusions. Our study, therefore, suggests that 
even short-term hearing aid use alters audiovisual integration and functional 
brain connectivity between auditory and visual cortices.

Copyright © 2021 Rosemann et al.

DOI: 10.1523/ENEURO.0258-21.2021
PMCID: PMC8658542
PMID: 34759049 [Indexed for MEDLINE]


115. Am J Audiol. 2020 Jun 8;29(2):199-205. doi: 10.1044/2020_AJA-19-00103. Epub 2020 
Apr 22.

Prevalence of Pre-Existing Hearing Loss Among Patients With Drug-Resistant 
Tuberculosis in South Africa.

Hong H(1)(2), Dowdy DW(3), Dooley KE(4), Francis HW(5), Budhathoki C(1), Han 
HR(1)(6), Farley JE(1)(2).

Author information:
(1)The REACH Initiative, Johns Hopkins University School of Nursing, Baltimore, 
MD.
(2)Johns Hopkins University School of Nursing, Baltimore, MD.
(3)Departments of Epidemiology and International Health, Johns Hopkins Bloomberg 
School of Public Health, Baltimore, MD.
(4)Divisions of Clinical Pharmacology and Infectious Disease, Johns Hopkins 
University School of Medicine, Baltimore, MD.
(5)Division of Head and Neck Surgery and Communication Sciences, Duke University 
School of Medicine, Durham, NC.
(6)Center for Cardiovascular and Chronic Care, The Johns Hopkins University, 
Baltimore, MD.

Purpose Hearing loss, resulting from aminoglycoside ototoxicity, is common among 
patients with drug-resistant tuberculosis (DR-TB). Those with pre-existing 
hearing loss are at particular risk of clinically important hearing loss with 
aminoglycoside-containing treatment than those with normal hearing at baseline. 
This study aimed to identify factors associated with pre-existing hearing loss 
among patients being treated for DR-TB in South Africa. Method Cross-sectional 
analysis nested within a cluster-randomized trial data across 10 South African 
TB hospitals. Patients ≥ 13 years old received clinical and audiological 
evaluations before DR-TB treatment initiation. Results Of 936 patients, average 
age was 35 years. One hundred forty-two (15%) reported pre-existing auditory 
symptoms. Of 482 patients tested by audiometry, 290 (60%) had pre-existing 
hearing loss. The prevalence of pre-existing hearing loss was highest among 
patients ≥ 50 years (adjusted prevalence ratio [aPrR] for symptoms 5.53, 95% 
confidence interval (CI) [3.63, 8.42]; aPrR for audiometric hearing loss 1.63, 
95% CI [1.31, 2.03] compared to age 13-18 years) and among those with a prior 
history of second-line TB treatment (aPrR for symptoms 1.73, 95% CI [1.66, 
1.80]; PrR for audiometric hearing loss 1.33, 95% CI [1.03, 1.73]). Having HIV 
with cluster of differentiation 4 cell count < 200 cells/mm3 and malnutrition 
were risk factors but did not reach statistical significance in adjusted 
analyses. Conclusion Pre-existing hearing loss is common among patients 
presenting for DR-TB treatment in South Africa, and those older than the age of 
50 years or who had prior second-line TB treatment history were at highest risk.

DOI: 10.1044/2020_AJA-19-00103
PMCID: PMC7839025
PMID: 32320639 [Indexed for MEDLINE]


116. Trends Hear. 2016 Sep 7;20:2331216516655794. doi: 10.1177/2331216516655794.

Investigating Differences in Preferred Noise Reduction Strength Among Hearing 
Aid Users.

Neher T(1), Wagener KC(2).

Author information:
(1)Medizinische Physik, Oldenburg University, Oldenburg, Germany Cluster of 
Excellence Hearing4all, Oldenburg, Germany tobias.neher@uni-oldenburg.de.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany Hörzentrum Oldenburg 
GmbH, Oldenburg, Germany.

Even though hearing aid (HA) users can respond very differently to noise 
reduction (NR) processing, knowledge about possible drivers of this variability 
(and thus ways of addressing it in HA fittings) is sparse. The current study 
investigated differences in preferred NR strength among HA users. Participants 
were groups of experienced users with clear preferences ("NR lovers"; N = 14) or 
dislikes ("NR haters"; N = 13) for strong NR processing, as determined in two 
earlier studies. Maximally acceptable background noise levels, detection 
thresholds for speech distortions caused by NR processing, and self-reported 
"sound personality" traits were considered as candidate measures for explaining 
group membership. Participants also adjusted the strength of the (binaural 
coherence-based) NR algorithm to their preferred level. Consistent with previous 
findings, NR lovers favored stronger processing than NR haters, although there 
also was some overlap. While maximally acceptable noise levels and detection 
thresholds for speech distortions tended to be higher for NR lovers than for NR 
haters, group differences were only marginally significant. No clear group 
differences were observed in the self-report data. Taken together, these results 
indicate that preferred NR strength is an individual trait that is fairly stable 
across time and that is not easily captured by psychoacoustic, audiological, or 
self-report measures aimed at indexing susceptibility to background noise and 
processing artifacts. To achieve more personalized NR processing, an effective 
approach may be to let HA users determine the optimal setting themselves during 
the fitting process.

© The Author(s) 2016.

DOI: 10.1177/2331216516655794
PMCID: PMC5017568
PMID: 27604781 [Indexed for MEDLINE]


117. Sensors (Basel). 2022 Aug 12;22(16):6033. doi: 10.3390/s22166033.

Personalization of Hearing Aid Fitting Based on Adaptive Dynamic Range 
Optimization.

Ni A(1), Akbarzadeh S(1), Lobarinas E(2), Kehtarnavaz N(1).

Author information:
(1)Department of Electrical and Computer Engineering, University of Texas at 
Dallas, Richardson, TX 75080-3021, USA.
(2)Callier Center for Communication Disorders, University of Texas at Dallas, 
Richardson, TX 75080-3021, USA.

Adaptive dynamic range optimization (ADRO) is a hearing aid fitting rationale 
which involves adjusting the gains in a number of frequency bands by using a 
series of rules. The rules reflect the comparison of the estimated percentile 
occurrences of the sound levels with the audibility and comfort hearing levels 
of a person suffering from hearing loss. In the study reported in this paper, a 
previously developed machine learning method was utilized to personalize the 
ADRO fitting in order to provide an improved hearing experience as compared to 
the standard ADRO hearing aid fitting. The personalization was carried out based 
on the user preference model within the framework of maximum likelihood inverse 
reinforcement learning. The testing of ten subjects with hearing loss was 
conducted, which indicated that the personalized ADRO was preferred over the 
standard ADRO on average by about 10 times. Furthermore, a word recognition 
experiment was conducted, which showed that the personalized ADRO had no adverse 
impact on speech understanding as compared to the standard ADRO.

DOI: 10.3390/s22166033
PMCID: PMC9414822
PMID: 36015791 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


118. Brain Struct Funct. 2019 Nov;224(8):2661-2676. doi: 10.1007/s00429-019-01922-9. 
Epub 2019 Jul 25.

Age-related hearing loss increases full-brain connectivity while reversing 
directed signaling within the dorsal-ventral pathway for speech.

Bidelman GM(1)(2)(3), Mahmud MS(4), Yeasin M(4), Shen D(5), Arnott SR(5), Alain 
C(5)(6)(7).

Author information:
(1)Institute for Intelligent Systems, University of Memphis, Memphis, TN, USA. 
gmbdlman@memphis.edu.
(2)School of Communication Sciences and Disorders, University of Memphis, 4055 
North Park Loop, Memphis, TN, 38152, USA. gmbdlman@memphis.edu.
(3)Department of Anatomy and Neurobiology, University of Tennessee Health 
Sciences Center, Memphis, TN, USA. gmbdlman@memphis.edu.
(4)Department of Electrical and Computer Engineering, University of Memphis, 
Memphis, TN, USA.
(5)Rotman Research Institute-Baycrest Centre for Geriatric Care, Toronto, ON, 
Canada.
(6)Department of Psychology, University of Toronto, Toronto, ON, Canada.
(7)Institute of Medical Sciences, University of Toronto, Toronto, ON, Canada.

Speech comprehension difficulties are ubiquitous to aging and hearing loss, 
particularly in noisy environments. Older adults' poorer speech-in-noise (SIN) 
comprehension has been related to abnormal neural representations within various 
nodes (regions) of the speech network, but how senescent changes in hearing 
alter the transmission of brain signals remains unspecified. We measured 
electroencephalograms in older adults with and without mild hearing loss during 
a SIN identification task. Using functional connectivity and graph-theoretic 
analyses, we show that hearing-impaired (HI) listeners have more extended (less 
integrated) communication pathways and less efficient information exchange among 
widespread brain regions (larger network eccentricity) than their normal-hearing 
(NH) peers. Parameter optimized support vector machine classifiers applied to 
EEG connectivity data showed hearing status could be decoded (> 85% accuracy) 
solely using network-level descriptions of brain activity, but classification 
was particularly robust using left hemisphere connections. Notably, we found a 
reversal in directed neural signaling in left hemisphere dependent on hearing 
status among specific connections within the dorsal-ventral speech pathways. NH 
listeners showed an overall net "bottom-up" signaling directed from auditory 
cortex (A1) to inferior frontal gyrus (IFG; Broca's area), whereas the HI group 
showed the reverse signal (i.e., "top-down" Broca's → A1). A similar flow 
reversal was noted between left IFG and motor cortex. Our full-brain 
connectivity results demonstrate that even mild forms of hearing loss alter how 
the brain routes information within the auditory-linguistic-motor loop.

DOI: 10.1007/s00429-019-01922-9
PMCID: PMC6778722
PMID: 31346715 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of interest The authors declare they 
have no conflict of interest.


119. Orphanet J Rare Dis. 2021 Aug 5;16(1):349. doi: 10.1186/s13023-021-01969-0.

Auditory cortex hypoperfusion: a metabolic hallmark in Beta Thalassemia.

Manara R(#)(1), Ponticorvo S(#)(2), Perrotta S(3), Barillari MR(4), Costa G(4), 
Brotto D(5), Di Concilio R(6), Ciancio A(7), De Michele E(8), Carafa PA(9), 
Canna A(2), Russo AG(2), Troisi D(2), Caiazza M(10), Ammendola F(10), Roberti 
D(10), Santoro C(10)(11), Picariello S(10), Valentino MS(10), Inserra E(10), 
Carfora R(10), Cirillo M(12), Raimo S(13), Santangelo G(13), di Salle F(2), 
Esposito F(2)(12), Tartaglione I(10).

Author information:
(1)Neuroradiology, Department of Neuroscience, University of Padova, Padua, 
Italy.
(2)Dipartimento di Medicina e Chirurgia, Scuola Medica Salernitana, Università 
di Salerno, Fisciano, Italy.
(3)Dipartimento della Donna, del Bambino e della Chirurgia Generale e 
Specialistica, Università degli Studi della Campania "Luigi Vanvitelli", Via L. 
De Crecchio 4, 80138, Naples, Italy. silverio.perrotta@unicampania.it.
(4)Università degli Studi della Campania, Naples, Italy.
(5)Università di Padova, Padua, Italy.
(6)Dipartimento di Pediatria, Ospedale "Umberto I", Nocera Inferiore, Italy.
(7)Unità Operativa Ematologia - Day Hospital di Talassemia, Ospedale "Madonna 
Delle Grazie", Matera, Italy.
(8)Medicina Trasfusionale AUO "San Giovanni di Dio e Ruggi D'Aragona", Salerno, 
Italy.
(9)Università di Salerno, Fisciano, Italy.
(10)Dipartimento della Donna, del Bambino e della Chirurgia Generale e 
Specialistica, Università degli Studi della Campania "Luigi Vanvitelli", Via L. 
De Crecchio 4, 80138, Naples, Italy.
(11)Clinic of Child and Adolescent Neuropsychiatry, Department of Mental Health, 
Physical and Preventive Medicine, University of Campania "Luigi Vanvitelli", 
Naples, Italy.
(12)Department of Advanced Medical and Surgical Sciences, University of Campania 
"Luigi Vanvitelli", Naples, Italy.
(13)Department of Psychology, University of Campania 'Luigi Vanvitelli', 
Caserta, Italy.
(#)Contributed equally

BACKGROUND: Sensorineural hearing loss in beta-thalassemia is common and it is 
generally associated with iron chelation therapy. However, data are scarce, 
especially on adult populations, and a possible involvement of the central 
auditory areas has not been investigated yet. We performed a multicenter 
cross-sectional audiological and single-center 3Tesla brain perfusion MRI study 
enrolling 77 transfusion-dependent/non transfusion-dependent adult patients and 
56 healthy controls. Pure tone audiometry, demographics, clinical/laboratory and 
cognitive functioning data were recorded.
RESULTS: Half of patients (52%) presented with high-frequency hearing deficit, 
with overt hypoacusia (Pure Tone Average (PTA) > 25 dB) in 35%, irrespective of 
iron chelation or clinical phenotype. Bilateral voxel clusters of significant 
relative hypoperfusion were found in the auditory cortex of beta-thalassemia 
patients, regardless of clinical phenotype. In controls and 
transfusion-dependent (but not in non-transfusion-dependent) patients, the 
relative auditory cortex perfusion values increased linearly with age 
(p < 0.04). Relative auditory cortex perfusion values showed a significant 
U-shaped correlation with PTA values among hearing loss patients, and a linear 
correlation with the full scale intelligence quotient (right side p = 0.01, left 
side p = 0.02) with its domain related to communication skills (right side 
p = 0.04, left side p = 0.07) in controls but not in beta-thalassemia patients. 
Audiometric test results did not correlate to cognitive test scores in any 
subgroup.
CONCLUSIONS: In conclusion, primary auditory cortex perfusion changes are a 
metabolic hallmark of adult beta-thalassemia, thus suggesting complex remodeling 
of the hearing function, that occurs regardless of chelation therapy and before 
clinically manifest hearing loss. The cognitive impact of perfusion changes is 
intriguing but requires further investigations.

© 2021. The Author(s).

DOI: 10.1186/s13023-021-01969-0
PMCID: PMC8340544
PMID: 34353346 [Indexed for MEDLINE]

Conflict of interest statement: None of the authors have a relevant conflict of 
interest to disclose.


120. J Acoust Soc Am. 2016 Feb;139(2):728-39. doi: 10.1121/1.4939896.

Spectral contrast enhancement improves speech intelligibility in noise for 
cochlear implants.

Nogueira W(1), Rode T(2), Büchner A(1).

Author information:
(1)Department of Otolaryngology, Medical University Hannover, Cluster of 
Excellence Hearing4all, Hannover, Germany.
(2)HörSys GmbH, Hannover, Germany.

Spectral smearing causes, at least partially, that cochlear implant (CI) users 
require a higher signal-to-noise ratio to obtain the same speech intelligibility 
as normal hearing listeners. A spectral contrast enhancement (SCE) algorithm has 
been designed and evaluated as an additional feature for a standard CI strategy. 
The algorithm keeps the most prominent peaks within a speech signal constant 
while attenuating valleys in the spectrum. The goal is to partly compensate for 
the spectral smearing produced by the limited number of stimulation electrodes 
and the overlap of electrical fields produced in CIs. Twelve CI users were 
tested for their speech reception threshold (SRT) using the standard CI coding 
strategy with and without SCE. No significant differences in SRT were observed 
between conditions. However, an analysis of the electrical stimulation patterns 
shows a reduction in stimulation current when using SCE. In a second evaluation, 
12 CI users were tested in a similar configuration of the SCE strategy with the 
stimulation being balanced between the SCE and the non-SCE variants such that 
the loudness perception delivered by the strategies was the same. Results show a 
significant improvement in SRT of 0.57 dB (p < 0.0005) for the SCE algorithm.

DOI: 10.1121/1.4939896
PMID: 26936556 [Indexed for MEDLINE]


121. Int J Clin Pract. 2021 Oct;75(10):e14684. doi: 10.1111/ijcp.14684. Epub 2021 Aug 
6.

Investigating tinnitus subgroups based on hearing-related difficulties.

Beukes EW(1)(2), Baguley DM(3)(4)(5), Manchaiah V(1)(6), Andersson G(7)(8), 
Allen PM(2), Kaldo V(7)(9), Jacquemin L(10)(11), Lourenco MPCG(12)(13), Onozuka 
J(14), Stockdale D(15), Maidment DW(16).

Author information:
(1)Department of Speech and Hearing Sciences, Lamar University, Beaumont, TX, 
USA.
(2)Vision and Hearing Sciences Research Group, School of Psychology and Sports 
Sciences, Anglia Ruskin University, Cambridge, UK.
(3)National Institute for Health Research, Nottingham Biomedical Research 
Centre, Ropewalk House, Nottingham, UK.
(4)Hearing Sciences, Division of Clinical Neuroscience, School of Medicine, 
University of Nottingham, Nottingham, UK.
(5)Nottingham Audiology Services, Nottingham University Hospitals, Nottingham, 
UK.
(6)Department of Speech and Hearing, School of Allied Health Sciences, Manipal 
University, Karnataka, India.
(7)Department of Behavioral Sciences and Learning, Linköping University, 
Linköping, Sweden.
(8)Centre for Psychiatry Research, Department of Clinical Neuroscience, 
Karolinska Institutet, & Stockholm Health Care Services, Region Stockholm, 
Sweden.
(9)Department of Psychology, Faculty of Health and Life Sciences, Linnaeus 
University, Växjö, Sweden.
(10)Department of Otorhinolaryngology and Head and Neck Surgery, Antwerp 
University Hospital, Edegem, Belgium.
(11)Department of Translational Neurosciences, Faculty of Medicine and Health 
Sciences, University of Antwerp, Wilrijk, Belgium.
(12)Experimental Health Psychology, Maastricht University, Maastricht, The 
Netherlands.
(13)Research Group Health Psychology, KU Leuven University, Leuven, Belgium.
(14)American Tinnitus Association, Washington, DC, USA.
(15)British Tinnitus Association, Sheffield, UK.
(16)School of Sport, Exercise and Health Sciences, Loughborough University, 
Loughborough, UK.

PURPOSE: Meaningfully grouping individuals with tinnitus who share a common 
characteristics (ie, subgrouping, phenotyping) may help tailor interventions to 
certain tinnitus subgroups and hence reduce outcome variability. The purpose of 
this study was to test if the presence of tinnitus subgroups are discernible 
based on hearing-related comorbidities, and to identify predictors of tinnitus 
severity for each subgroup identified.
METHODS: An exploratory cross-sectional study was used. The study was nested 
within an online survey distributed worldwide to investigate tinnitus 
experiences during the COVID-19 pandemic. The main outcome measure was the 
tinnitus Handicap Inventory- Screening Version.
RESULTS: From the 3400 respondents, 2980 were eligible adults with tinnitus with 
an average age of 58 years (SD = 14.7) and 49% (n = 1457) being female. A 
three-cluster solution identified distinct subgroups, namely, those with 
tinnitus-only (n = 1306; 44%), those presenting with tinnitus, hyperacusis, 
hearing loss and/or misophonia (n = 795; 27%), and those with tinnitus and 
hearing loss (n = 879; 29%). Those with tinnitus and hyperacusis reported the 
highest tinnitus severity (M = 20.3; SD = 10.5) and those with tinnitus and no 
hearing loss had the lowest tinnitus severity (M = 15.7; SD = 10.4). Younger age 
and the presence of mental health problems predicted greater tinnitus severity 
for all groups (β ≤ -0.1, P ≤ .016).
CONCLUSION: Further exploration of these potential subtypes are needed in both 
further research and clinical practice by initially triaging tinnitus patients 
prior to their clinical appointments based on the presence of hearing-related 
comorbidities. Unique management pathways and interventions could be tailored 
for each tinnitus subgroup.

© 2021 John Wiley & Sons Ltd.

DOI: 10.1111/ijcp.14684
PMID: 34331723 [Indexed for MEDLINE]


122. PLoS One. 2021 Dec 31;16(12):e0261433. doi: 10.1371/journal.pone.0261433. 
eCollection 2021.

Predicting speech discrimination scores from pure-tone thresholds-A machine 
learning-based approach using data from 12,697 subjects.

Kim H(1)(2), Park J(3), Choung YH(1)(2), Jang JH(1)(2), Ko J(3).

Author information:
(1)Ajou University Hospital, Suwon, South Korea.
(2)Department of Otolaryngology, School of Medicine, Ajou University, Suwon, 
South Korea.
(3)School of Integrated Technology, College of Engineering, Yonsei University, 
Seoul, South Korea.

Diagnostic tests for hearing impairment not only determines the presence (or 
absence) of hearing loss, but also evaluates its degree and type, and provides 
physicians with essential data for future treatment and rehabilitation. 
Therefore, accurately measuring hearing loss conditions is very important for 
proper patient understanding and treatment. In current-day practice, to quantify 
the level of hearing loss, physicians exploit specialized test scores such as 
the pure-tone audiometry (PTA) thresholds and speech discrimination scores (SDS) 
as quantitative metrics in examining a patient's auditory function. However, 
given that these metrics can be easily affected by various human factors, which 
includes intentional (or accidental) patient intervention, there are needs to 
cross validate the accuracy of each metric. By understanding a "normal" 
relationship between the SDS and PTA, physicians can reveal the need for 
re-testing, additional testing in different dimensions, and also potential 
malingering cases. For this purpose, in this work, we propose a prediction model 
for estimating the SDS of a patient by using PTA thresholds via a Random 
Forest-based machine learning approach to overcome the limitations of the 
conventional statistical (or even manual) methods. For designing and evaluating 
the Random Forest-based prediction model, we collected a large-scale dataset 
from 12,697 subjects, and report a SDS level prediction accuracy of 95.05% and 
96.64% for the left and right ears, respectively. We also present comparisons 
with other widely-used machine learning algorithms (e.g., Support Vector 
Machine, Multi-layer Perceptron) to show the effectiveness of our proposed 
Random Forest-based approach. Results obtained from this study provides 
implications and potential feasibility in providing a practically-applicable 
screening tool for identifying patient-intended malingering in hearing 
loss-related tests.

DOI: 10.1371/journal.pone.0261433
PMCID: PMC8719684
PMID: 34972151 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


123. Stud Health Technol Inform. 2023 Aug 23;306:305-310. doi: 10.3233/SHTI230636.

Exploring Practical Metrics to Support Automatic Speech Recognition Evaluations.

Draffan EA(1), Wald M(1), Ding C(1), Li Y(2).

Author information:
(1)ECS, University of Southampton, UK.
(2)Yunjia Li, Habitat Learn, UK.

Recent studies into the evaluation of automatic speech recognition for its 
quality of output in the form of text have shown that using word error rate to 
see how many mistakes exist in English does not necessarily help the developer 
of automatic transcriptions or captions. Confidence levels as to the type of 
errors being made remain low because mistranslations from speech to text are not 
always captured with a note that details the reason for the error. There have 
been situations in higher education where students requiring captions and 
transcriptions have found that some academic lecture results are littered with 
word errors which means that comprehension levels drop and those with cognitive, 
physical and sensory disabilities are particularly affected. Despite the 
incredible improvements in general understanding of conversational automatic 
speech recognition, academic situations tend to include numerous domain specific 
terms and the lecturers may be non-native speakers, coping with recording 
technology in noisy situations. This paper aims to discuss the way additional 
metrics are used to capture issues and feedback into the machine learning 
process to enable enhanced quality of output and more inclusive practices for 
those using virtual conferencing systems. The process goes beyond what is 
expressed and examines paralinguistic aspects such as timing, intonation, voice 
quality and speech understanding.

DOI: 10.3233/SHTI230636
PMID: 37638929 [Indexed for MEDLINE]


124. G3 (Bethesda). 2016 Oct 13;6(10):3219-3228. doi: 10.1534/g3.116.032516.

The Genetic Architecture of Noise-Induced Hearing Loss: Evidence for a 
Gene-by-Environment Interaction.

Lavinsky J(1), Ge M(2), Crow AL(3), Pan C(4), Wang J(2), Salehi P(2), Myint 
A(2), Eskin E(5), Allayee H(3), Lusis AJ(6), Friedman RA(7).

Author information:
(1)Tina and Rick Caruso Department of Otolaryngology, Zilkha Neurogenetic 
Institute Graduate Program in Surgical Sciences, Federal University of Rio 
Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil.
(2)Tina and Rick Caruso Department of Otolaryngology, Zilkha Neurogenetic 
Institute.
(3)Department of Preventive Medicine and Institute for Genetic Medicine, USC 
Keck School of Medicine, University of Southern California, Los Angeles, 
California 90033.
(4)Department of Human Genetics.
(5)Department of Computer Science.
(6)Department of Microbiology, Immunology, and Molecular Genetics, University of 
California, Los Angeles, California 90024.
(7)Tina and Rick Caruso Department of Otolaryngology, Zilkha Neurogenetic 
Institute rick.friedman@med.usc.edu.

The discovery of environmentally specific genetic effects is crucial to the 
understanding of complex traits, such as susceptibility to noise-induced hearing 
loss (NIHL). We describe the first genome-wide association study (GWAS) for NIHL 
in a large and well-characterized population of inbred mouse strains, known as 
the Hybrid Mouse Diversity Panel (HMDP). We recorded auditory brainstem response 
(ABR) thresholds both pre and post 2-hr exposure to 10-kHz octave band noise at 
108 dB sound pressure level in 5-6-wk-old female mice from the HMDP (4-5 
mice/strain). From the observation that NIHL susceptibility varied among the 
strains, we performed a GWAS with correction for population structure and mapped 
a locus on chromosome 6 that was statistically significantly associated with two 
adjacent frequencies. We then used a "genetical genomics" approach that included 
the analysis of cochlear eQTLs to identify candidate genes within the GWAS QTL. 
In order to validate the gene-by-environment interaction, we compared the 
effects of the postnoise exposure locus with that from the same unexposed 
strains. The most significant SNP at chromosome 6 (rs37517079) was associated 
with noise susceptibility, but was not significant at the same frequencies in 
our unexposed study. These findings demonstrate that the genetic architecture of 
NIHL is distinct from that of unexposed hearing levels and provide strong 
evidence for gene-by-environment interactions in NIHL.

Copyright © 2016 Lavinsky et al.

DOI: 10.1534/g3.116.032516
PMCID: PMC5068943
PMID: 27520957 [Indexed for MEDLINE]


125. Hear Res. 2021 Sep 1;408:108294. doi: 10.1016/j.heares.2021.108294. Epub 2021 
Jun 17.

Speech signal enhancement in cocktail party scenarios by deep learning based 
virtual sensing of head-mounted microphones.

Fischer T(1), Caversaccio M(1), Wimmer W(2).

Author information:
(1)Hearing Research Laboratory, ARTORG Center for Biomedical Engineering 
Research, University of Bern, Bern 3008, Switzerland; Department of ENT, Head 
and Neck Surgery, Inselspital, Bern University Hospital, University of Bern, 
Bern 3008, Switzerland.
(2)Hearing Research Laboratory, ARTORG Center for Biomedical Engineering 
Research, University of Bern, Bern 3008, Switzerland; Department of ENT, Head 
and Neck Surgery, Inselspital, Bern University Hospital, University of Bern, 
Bern 3008, Switzerland. Electronic address: wilhelm.wimmer@artorg.unibe.ch.

The cocktail party effect refers to the human sense of hearing's ability to pay 
attention to a single conversation while filtering out all other background 
noise. To mimic this human hearing ability for people with hearing loss, 
scientists integrate beamforming algorithms into the signal processing path of 
hearing aids or implants' audio processors. Although these algorithms' 
performance strongly depends on the number and spatial arrangement of the 
microphones, most devices are equipped with a small number of microphones 
mounted close to each other on the audio processor housing. We measured and 
evaluated the impact of the number and spatial arrangement of hearing aid or 
head-mounted microphones on the performance of the established Minimum Variance 
Distortionless Response beamformer in cocktail party scenarios. The measurements 
revealed that the optimal microphone placement exploits monaural cues 
(pinna-effect), is close to the target signal, and creates a large distance 
spread due to its spatial arrangement. However, this microphone placement is 
impractical for hearing aid or implant users, as it includes microphone 
positions such as on the forehead. To overcome microphones' placement at 
impractical positions, we propose a deep virtual sensing estimation of the 
corresponding audio signals. The results of objective measures and a subjective 
listening test with 20 participants showed that the virtually sensed microphone 
signals significantly improved the speech quality, especially in cocktail party 
scenarios with low signal-to-noise ratios. Subjective speech quality was 
assessed using a 3-alternative forced choice procedure to determine which of the 
presented speech mixtures was most pleasant to understand. Hearing aid and 
cochlear implant (CI) users might benefit from the presented approach using 
virtually sensed microphone signals, especially in noisy environments.

Copyright © 2021 The Author(s). Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2021.108294
PMID: 34182232 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


126. Sci Rep. 2020 Oct 12;10(1):16987. doi: 10.1038/s41598-020-74012-0.

Reduced resting state functional connectivity with increasing age-related 
hearing loss and McGurk susceptibility.

Schulte A(1), Thiel CM(2)(3), Gieseler A(4)(5), Tahden M(4)(5), Colonius 
H(4)(5), Rosemann S(1)(4).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl-Von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany.
(2)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl-Von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany. 
christiane.thiel@uni-oldenburg.de.
(3)Cluster of Excellence "Hearing4all", Carl Von Ossietzky Universität 
Oldenburg, Oldenburg, Germany. christiane.thiel@uni-oldenburg.de.
(4)Cluster of Excellence "Hearing4all", Carl Von Ossietzky Universität 
Oldenburg, Oldenburg, Germany.
(5)Cognitive Psychology, Department of Psychology, School of Medicine and Health 
Sciences, Carl-Von-Ossietzky Universität Oldenburg, Oldenburg, Germany.

Age-related hearing loss has been related to a compensatory increase in 
audio-visual integration and neural reorganization including alterations in 
functional resting state connectivity. How these two changes are linked in 
elderly listeners is unclear. The current study explored modulatory effects of 
hearing thresholds and audio-visual integration on resting state functional 
connectivity. We analysed a large set of resting state data of 65 elderly 
participants with a widely varying degree of untreated hearing loss. 
Audio-visual integration, as gauged with the McGurk effect, increased with 
progressing hearing thresholds. On the neural level, McGurk illusions were 
negatively related to functional coupling between motor and auditory regions. 
Similarly, connectivity of the dorsal attention network to sensorimotor and 
primary motor cortices was reduced with increasing hearing loss. The same effect 
was obtained for connectivity between the salience network and visual cortex. 
Our findings suggest that with progressing untreated age-related hearing loss, 
functional coupling at rest declines, affecting connectivity of brain networks 
and areas associated with attentional, visual, sensorimotor and motor processes. 
Especially connectivity reductions between auditory and motor areas were related 
to stronger audio-visual integration found with increasing hearing loss.

DOI: 10.1038/s41598-020-74012-0
PMCID: PMC7550565
PMID: 33046800 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


127. J Acoust Soc Am. 2018 Aug;144(2):917. doi: 10.1121/1.5050518.

Physiologically motivated individual loudness model for normal hearing and 
hearing impaired listeners.

Pieper I(1), Mauermann M(1), Oetting D(2), Kollmeier B(1), Ewert SD(1).

Author information:
(1)Medical Physics and Cluster of Excellence Hearing4All, Universität Oldenburg, 
Oldenburg, D-26111, Germany.
(2)HörTech gGmbH and Cluster of Excellence Hearing4all, Oldenburg, Germany.

A loudness model with a central gain is suggested to improve individualized 
predictions of loudness scaling data from normal hearing and hearing impaired 
listeners. The current approach is based on the loudness model of Pieper et al. 
[(2016). J. Acoust. Soc. Am. 139, 2896], which simulated the nonlinear inner ear 
mechanics as transmission-line model in a physical and physiological plausible 
way. Individual hearing thresholds were simulated by a cochlear gain reduction 
in the transmission-line model and linear attenuation (damage of inner hair 
cells) prior to an internal threshold. This and similar approaches of current 
loudness models that characterize the individual hearing loss were shown to be 
insufficient to account for individual loudness perception, in particular at 
high stimulus levels close to the uncomfortable level. An additional parameter, 
termed "post gain," was introduced to improve upon the previous models. The post 
gain parameter amplifies the signal parts above the internal threshold and can 
better account for individual variations in the overall steepness of loudness 
functions and for variations in the uncomfortable level which are independent of 
the hearing loss. The post gain can be interpreted as a central gain occurring 
at higher stages as a result of peripheral deafferentation.

DOI: 10.1121/1.5050518
PMID: 30180690 [Indexed for MEDLINE]


128. Trends Hear. 2020 Jan-Dec;24:2331216520970011. doi: 10.1177/2331216520970011.

Speech Audiometry at Home: Automated Listening Tests via Smart Speakers With 
Normal-Hearing and Hearing-Impaired Listeners.

Ooster J(1)(2), Krueger M(2)(3), Bach JH(2)(3)(4), Wagener KC(2)(3)(4), 
Kollmeier B(2)(3)(4)(5), Meyer BT(1)(2)(3).

Author information:
(1)Communication Acoustics, Carl von Ossietzky Universität, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Germany.
(3)HörTech gGmbH, Oldenburg, Germany.
(4)Hörzentrum GmbH, Oldenburg, Germany.
(5)Medizinische Physik, Carl von Ossietzky Universität, Oldenburg, Germany.

Speech audiometry in noise based on sentence tests is an important diagnostic 
tool to assess listeners' speech recognition threshold (SRT), i.e., the 
signal-to-noise ratio corresponding to 50% intelligibility. The clinical 
standard measurement procedure requires a professional experimenter to record 
and evaluate the response (expert-conducted speech audiometry). The use of 
automatic speech recognition enables self-conducted measurements with an 
easy-to-use speech-based interface. This article compares self-conducted SRT 
measurements using smart speakers with expert-conducted laboratory measurements. 
With smart speakers, there is no control over the absolute presentation level, 
potential errors from the automated response logging, and room acoustics. We 
investigate the differences between highly controlled measurements in the 
laboratory and smart speaker-based tests for young normal-hearing (NH) listeners 
as well as for elderly NH, mildly and moderately hearing-impaired listeners in 
low, medium, and highly reverberant room acoustics. For the smart speaker setup, 
we observe an overall bias in the SRT result that depends on the hearing loss. 
The bias ranges from +0.7 dB for elderly moderately hearing-impaired listeners 
to +2.2 dB for young NH listeners. The intrasubject standard deviation is close 
to the clinical standard deviation (0.57/0.69 dB for the young/elderly NH 
compared with 0.5 dB observed for clinical tests and 0.93/1.09 dB for the 
mild/moderate hearing-impaired listeners compared with 0.9 dB). For detecting a 
clinically elevated SRT, the speech-based test achieves an area under the curve 
value of 0.95 and therefore seems promising for complementing clinical 
measurements.

DOI: 10.1177/2331216520970011
PMCID: PMC7720343
PMID: 33272109 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


129. J Acoust Soc Am. 2017 Mar;141(3):1985. doi: 10.1121/1.4977197.

Auditory inspired machine learning techniques can improve speech intelligibility 
and quality for hearing-impaired listeners.

Monaghan JJ(1), Goehring T(1), Yang X(1), Bolner F(2), Wang S(1), Wright MC(1), 
Bleeck S(1).

Author information:
(1)Institute of Sound and Vibration Research, University of Southampton, 
Southampton, United Kingdom.
(2)ExpORL, Katholieke Universiteit Leuven, Leuven, Belgium.

Machine-learning based approaches to speech enhancement have recently shown 
great promise for improving speech intelligibility for hearing-impaired 
listeners. Here, the performance of three machine-learning algorithms and one 
classical algorithm, Wiener filtering, was compared. Two algorithms based on 
neural networks were examined, one using a previously reported feature set and 
one using a feature set derived from an auditory model. The third 
machine-learning approach was a dictionary-based sparse-coding algorithm. Speech 
intelligibility and quality scores were obtained for participants with 
mild-to-moderate hearing impairments listening to sentences in speech-shaped 
noise and multi-talker babble following processing with the algorithms. 
Intelligibility and quality scores were significantly improved by each of the 
three machine-learning approaches, but not by the classical approach. The 
largest improvements for both speech intelligibility and quality were found by 
implementing a neural network using the feature set based on auditory modeling. 
Furthermore, neural network based techniques appeared more promising than 
dictionary-based, sparse coding in terms of performance and ease of 
implementation.

DOI: 10.1121/1.4977197
PMID: 28372043 [Indexed for MEDLINE]


130. Ear Hear. 2015 Nov-Dec;36 Suppl 1(0 1):24S-37S. doi: 
10.1097/AUD.0000000000000211.

Longitudinal Predictors of Aided Speech Audibility in Infants and Children.

McCreery RW(1), Walker EA, Spratford M, Bentler R, Holte L, Roush P, Oleson J, 
Van Buren J, Moeller MP.

Author information:
(1)1Center for Audiology, Boys Town National Research Hospital, Omaha, Nebraska, 
USA; 2Department of Communication Sciences and Disorders, University of Iowa, 
Iowa City, Iowa, USA; 3Center for Childhood Deafness, Boys Town National 
Research Hospital, Omaha, Nebraska, USA; 4Department of Otolaryngology, 
University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA; 
and 5Department of Biostatistics, University of Iowa, Iowa City, Iowa, USA.

OBJECTIVES: Amplification is a core component of early intervention for children 
who are hard of hearing, but hearing aids (HAs) have unique effects that may be 
independent from other components of the early intervention process, such as 
caregiver training or speech and language intervention. The specific effects of 
amplification are rarely described in studies of developmental outcomes. The 
primary purpose of this article is to quantify aided speech audibility during 
the early childhood years and examine the factors that influence audibility with 
amplification for children in the Outcomes of Children with Hearing Loss study.
DESIGN: Participants were 288 children with permanent hearing loss who were 
followed as part of the Outcomes of Children with Hearing Loss study. All of the 
children in this analysis had bilateral hearing loss and wore air-conduction 
behind-the-ear HAs. At every study visit, hearing thresholds were measured using 
developmentally appropriate behavioral methods. Data were obtained for a total 
of 1043 audiometric evaluations across all subjects for the first four study 
visits. In addition, the aided audibility of speech through the HA was assessed 
using probe microphone measures. Hearing thresholds and aided audibility were 
analyzed. Repeated-measures analyses of variance were conducted to determine 
whether patterns of thresholds and aided audibility were significantly different 
between ears (left versus right) or across the first four study visits. 
Furthermore, a cluster analysis was performed based on the aided audibility at 
entry into the study, aided audibility at the child's final visit, and change in 
aided audibility between these two intervals to determine whether there were 
different patterns of longitudinal aided audibility within the sample.
RESULTS: Eighty-four percent of children in the study had stable audiometric 
thresholds during the study, defined as threshold changes <10 dB for any single 
study visit. There were no significant differences in hearing thresholds, aided 
audibility, or deviation of the HA fitting from prescriptive targets between 
ears or across test intervals for the first four visits. Approximately 35% of 
the children in the study had aided audibility that was below the average for 
the normative range for the Speech Intelligibility Index based on degree of 
hearing loss. The cluster analysis of longitudinal aided audibility revealed 
three distinct groups of children: a group with consistently high aided 
audibility throughout the study, a group with decreasing audibility during the 
study, and a group with consistently low aided audibility.
CONCLUSIONS: The current results indicated that approximately 65% of children in 
the study had adequate aided audibility of speech and stable hearing during the 
study period. Limited audibility was associated with greater degrees of hearing 
loss and larger deviations from prescriptive targets. Studies of developmental 
outcomes will help to determine how aided audibility is necessary to affect 
developmental outcomes in children who are hard of hearing.

DOI: 10.1097/AUD.0000000000000211
PMCID: PMC4704126
PMID: 26731156 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: The authors have no 
conflicts of interest to declare.


131. J Assoc Res Otolaryngol. 2013 Oct;14(5):687-701. doi: 10.1007/s10162-013-0396-x. 
Epub 2013 Jun 6.

Classifying human audiometric phenotypes of age-related hearing loss from animal 
models.

Dubno JR(1), Eckert MA, Lee FS, Matthews LJ, Schmiedt RA.

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Medical University of 
South Carolina, 135 Rutledge Avenue, MSC 550, Charleston, SC, 29425-5500, USA, 
dubnojr@musc.edu.

Age-related hearing loss (presbyacusis) has a complex etiology. Results from 
animal models detailing the effects of specific cochlear injuries on audiometric 
profiles may be used to understand the mechanisms underlying hearing loss in 
older humans and predict cochlear pathologies associated with certain 
audiometric configurations ("audiometric phenotypes"). Patterns of hearing loss 
associated with cochlear pathology in animal models were used to define 
schematic boundaries of human audiograms. Pathologies included evidence for 
metabolic, sensory, and a mixed metabolic + sensory phenotype; an older normal 
phenotype without threshold elevation was also defined. Audiograms from a large 
sample of older adults were then searched by a human expert for "exemplars" 
(best examples) of these phenotypes, without knowledge of the human subject 
demographic information. Mean thresholds and slopes of higher frequency 
thresholds of the audiograms assigned to the four phenotypes were consistent 
with the predefined schematic boundaries and differed significantly from each 
other. Significant differences in age, gender, and noise exposure history 
provided external validity for the four phenotypes. Three supervised machine 
learning classifiers were then used to assess reliability of the exemplar 
training set to estimate the probability that newly obtained audiograms 
exhibited one of the four phenotypes. These procedures classified the exemplars 
with a high degree of accuracy; classifications of the remaining cases were 
consistent with the exemplars with respect to average thresholds and demographic 
information. These results suggest that animal models of age-related hearing 
loss can be used to predict human cochlear pathology by classifying audiograms 
into phenotypic classifications that reflect probable etiologies for hearing 
loss in older humans.

DOI: 10.1007/s10162-013-0396-x
PMCID: PMC3767874
PMID: 23740184 [Indexed for MEDLINE]


132. Neuroscience. 2016 Feb 19;315:228-45. doi: 10.1016/j.neuroscience.2015.12.005. 
Epub 2015 Dec 14.

Noise trauma induced plastic changes in brain regions outside the classical 
auditory pathway.

Chen GD(1), Sheppard A(2), Salvi R(2).

Author information:
(1)Center for Hearing and Deafness, SUNY at Buffalo, Buffalo, NY 14214, USA. 
Electronic address: gchen7@buffalo.edu.
(2)Center for Hearing and Deafness, SUNY at Buffalo, Buffalo, NY 14214, USA.

The effects of intense noise exposure on the classical auditory pathway have 
been extensively investigated; however, little is known about the effects of 
noise-induced hearing loss on non-classical auditory areas in the brain such as 
the lateral amygdala (LA) and striatum (Str). To address this issue, we compared 
the noise-induced changes in spontaneous and tone-evoked responses from 
multiunit clusters (MUC) in the LA and Str with those seen in auditory cortex 
(AC) in rats. High-frequency octave band noise (10-20 kHz) and narrow band noise 
(16-20 kHz) induced permanent threshold shifts at high-frequencies within and 
above the noise band but not at low frequencies. While the noise trauma 
significantly elevated spontaneous discharge rate (SR) in the AC, SRs in the LA 
and Str were only slightly increased across all frequencies. The high-frequency 
noise trauma affected tone-evoked firing rates in frequency and time-dependent 
manner and the changes appeared to be related to the severity of noise trauma. 
In the LA, tone-evoked firing rates were reduced at the high-frequencies (trauma 
area) whereas firing rates were enhanced at the low-frequencies or at the 
edge-frequency dependent on severity of hearing loss at the high frequencies. 
The firing rate temporal profile changed from a broad plateau to one sharp, 
delayed peak. In the AC, tone-evoked firing rates were depressed at high 
frequencies and enhanced at the low frequencies while the firing rate temporal 
profiles became substantially broader. In contrast, firing rates in the Str were 
generally decreased and firing rate temporal profiles become more phasic and 
less prolonged. The altered firing rate and pattern at low frequencies induced 
by high-frequency hearing loss could have perceptual consequences. The 
tone-evoked hyperactivity in low-frequency MUC could manifest as hyperacusis 
whereas the discharge pattern changes could affect temporal resolution and 
integration.

Copyright © 2015 IBRO. Published by Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuroscience.2015.12.005
PMCID: PMC5327920
PMID: 26701290 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing financial 
interests or conflicts of interest.


133. Biometrics. 2024 Jan 29;80(1):ujae013. doi: 10.1093/biomtc/ujae013.

Soft classification and regression analysis of audiometric phenotypes of 
age-related hearing loss.

Yang C(1), Langworthy B(1), Curhan S(2)(3), Vaden KI Jr(4), Curhan 
G(1)(2)(3)(5), Dubno JR(4), Wang M(1)(2)(3)(6).

Author information:
(1)Department of Epidemiology, Harvard T.H. Chan School of Public Health, 
Boston, MA 02115, United States.
(2)Harvard Medical School, Boston, MA 02115, United States.
(3)Channing Division of Network Medicine, Department of Medicine, Brigham and 
Women's Hospital, Boston, MA 02115, United States.
(4)Hearing Research Program, Department of Otolaryngology-Head and Neck Surgery, 
Medical University of South Carolina, Charleston, SC 29425, United States.
(5)Renal Division, Department of Medicine, Brigham and Women's Hospital, Boston, 
MA 02115, United States.
(6)Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
Boston, MA 02115, United States.

Age-related hearing loss has a complex etiology. Researchers have made efforts 
to classify relevant audiometric phenotypes, aiming to enhance medical 
interventions and improve hearing health. We leveraged existing pattern analyses 
of age-related hearing loss and implemented the phenotype classification via 
quadratic discriminant analysis (QDA). We herein propose a method for analyzing 
the exposure effects on the soft classification probabilities of the phenotypes 
via estimating equations. Under reasonable assumptions, the estimating 
equations are unbiased and lead to consistent estimators. The resulting 
estimator had good finite sample performances in simulation studies. As an 
illustrative example, we applied our proposed methods to assess the association 
between a dietary intake pattern, assessed as adherence scores for the dietary 
approaches to stop hypertension diet calculated using validated food-frequency 
questionnaires, and audiometric phenotypes (older-normal, metabolic, sensory, 
and metabolic plus sensory), determined based on data obtained in the Nurses' 
Health Study II Conservation of Hearing Study, the Audiology Assessment Arm. Our 
findings suggested that participants with a more healthful dietary pattern were 
less likely to develop the metabolic plus sensory phenotype of age-related 
hearing loss.

© The Author(s) 2024. Published by Oxford University Press on behalf of The 
International Biometric Society.

DOI: 10.1093/biomtc/ujae013
PMCID: PMC10941322
PMID: 38488465 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no potential conflict of 
interests.


134. Stud Health Technol Inform. 2023 Oct 20;309:170-174. doi: 10.3233/SHTI230768.

A Screening Platform for Hearing Loss and Cognitive Decline: WHISPER (Widespread 
Hearing Impairment Screening and PrEvention of Risk).

Paglialonga A(1), Polo EM(2)(3), Lenatti M(1), Mollura M(3), Barbieri R(3).

Author information:
(1)Cnr-Istituto di Elettronica e di Ingegneria dell'Informazione e delle 
Telecomunicazioni (CNR-IEIIT), 20133 Milan, Italy.
(2)Sapienza University of Rome, DIAG, 00185 Rome, Italy.
(3)Politecnico di Milano, DEIB, 20133 Milan, Italy.

The WHISPER (Widespread Hearing Impairment Screening and PrEvention of Risk) 
platform was recently developed for screening for hearing loss (HL) and 
cognitive decline in adults. It includes a battery of tests (a risk factors (RF) 
questionnaire, a language-independent speech-in-noise test, and cognitive tests) 
and provides a pass/fail outcome based on the analysis of several features. 
Earlier studies demonstrated high accuracy of the speech-in-noise test for 
predicting HL in 350 participants. In this study, preliminary results from the 
RF questionnaire (137 participants) and from the visual digit span test (DST) 
(78 participants) are presented. Despite the relatively small sample size, these 
findings indicate that the RF and DST may provide additional features that could 
be useful to characterize the overall individual profile, providing additional 
knowledge related to short-term memory performance and overall risk of HL and 
cognitive decline. Future research is needed to expand number of subjects 
tested, number of features analyzed, and the range of algorithms (including 
supervised and unsupervised machine learning) used to identify novel measures 
able to predict the individual hearing and cognitive abilities, also including 
components related to the individual risk.

DOI: 10.3233/SHTI230768
PMID: 37869833 [Indexed for MEDLINE]


135. Trends Hear. 2018 Jan-Dec;22:2331216518804945. doi: 10.1177/2331216518804945.

Effect of Hearing Aid Directionality and Remote Microphone on Speech 
Intelligibility in Complex Listening Situations.

Wagener KC(1)(2), Vormann M(1)(2), Latzel M(3), Mülder HE(4).

Author information:
(1)1 Hörzentrum Oldenburg GmbH, Germany.
(2)2 Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)3 Sonova AG, Stäfa, Switzerland.
(4)4 Phonak Communications, Murten, Switzerland.

Remote microphones (RMs) have been developed to support hearing aid (HA) users 
in understanding distant talkers. In traditional clinical applications, a 
drawback of these systems is the deteriorated speech intelligibility in the near 
field. This study investigates advantages and disadvantages of clinical RM usage 
and the effects of different directionality settings of the HAs in complex 
listening situations in the laboratory. Speech intelligibility was investigated 
in 15 experienced severely hearing impaired participants in a noisy environment 
using a dual-task test paradigm where the tasks were presented from either a 
near field or a far field loudspeaker. Primary and secondary tasks were 
presented simultaneously so attention had to be shared on both tasks. In a 
second experiment, two speech intelligibility tests were presented from either 
the near field or the far field loudspeaker. The tests were interleaved to 
simulate a complex listening situation with shifting attention. Directional HA 
microphones yielded better performance than omnidirectional microphones (both 
combined with a RM) in near field when analyzing both tasks of the dual-task 
experiment separately. Furthermore, the integrated dual-task test results showed 
better performance with directional HA microphones compared with the 
omnidirectional setting (both cases in combination with a RM). These findings 
were confirmed by the results of the interleaved speech intelligibility test.

DOI: 10.1177/2331216518804945
PMCID: PMC6194921
PMID: 30322342 [Indexed for MEDLINE]


136. Int J Audiol. 2018 Jun;57(sup3):S71-S80. doi: 10.1080/14992027.2017.1380848. 
Epub 2017 Oct 3.

Loudness summation of equal loud narrowband signals in normal-hearing and 
hearing-impaired listeners.

Ewert SD(1), Oetting D(1)(2).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , Universität 
Oldenburg , Oldenburg , Germany and.
(2)b Project Group Hearing, Speech and Audio Technology of the Fraunhofer IDMT 
and Cluster of Excellence Hearing4all , Oldenburg , Germany.

OBJECTIVE: Loudness perception of binaural broadband signals, e.g. speech shaped 
noise, shows large individual differences using frequency-dependent 
amplification which was adjusted to restore the loudness perception of monaural 
narrowband signals in hearing-impaired (HI) listeners. To better understand and 
quantify this highly individual effect, loudness perception of broadband stimuli 
consisting of a number of spectrally separated narrowband components which where 
individually adjusted to equal loudness is of interest.
DESIGN: Based on categorical loudness scaling, the loudness of an equal 
categorical loudness noise (ECLN) consisting of six third-octave noises was 
assessed. For loudness categories "medium" und "very loud" the required 
narrowband loudness was analysed.
STUDY SAMPLE: Nine normal-hearing (NH) and ten HI listeners.
RESULTS: HI listeners showed lower narrowband loudness values compared to NH 
listeners, indicating an increased spectral loudness summation. More than 50% of 
the HI listeners showed higher binaural spectral loudness summation compared to 
NH listeners. The amount of binaural spectral loudness summation was highly 
correlated (r2 = 0.92) with the loudness level at "very loud" of aided speech 
shaped noise.
CONCLUSIONS: The suggested ECLN measurement is suited to assess individual 
(binaural) broadband loudness in aided conditions, providing valuable 
information for hearing-aid fitting.

DOI: 10.1080/14992027.2017.1380848
PMID: 28971746 [Indexed for MEDLINE]


137. Trends Hear. 2022 Jan-Dec;26:23312165221108259. doi: 10.1177/23312165221108259.

Considerations for Fitting Cochlear Implants Bimodally and to the Single-Sided 
Deaf.

Pieper SH(1)(2), Hamze N(3), Brill S(4), Hochmuth S(5), Exter M(2)(6), Polak 
M(3), Radeloff A(2)(5)(7), Buschermöhle M(8), Dietz M(1)(2)(7).

Author information:
(1)Department of Medical Physics and Acoustic, University of Oldenburg, 
Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, University of Oldenburg, Oldenburg, 
Germany.
(3)MED-EL Medical Electronics GmbH, Innsbruck, Austria.
(4)MED-EL Medical Electronics Germany GmbH, Starnberg, Germany.
(5)Division of Otorhinolaryngology, University of Oldenburg, Oldenburg, Germany.
(6)Hörzentrum Oldenburg gGmbH, Oldenburg, Germany.
(7)Research Center Neurosensory Science, University of Oldenburg, Oldenburg, 
Germany.
(8)KIZMO GmbH, Oldenburg, Germany.

When listening with a cochlear implant through one ear and acoustically through 
the other, binaural benefits and spatial hearing abilities are generally poorer 
than in other bilaterally stimulated configurations. With the working hypothesis 
that binaural neurons require interaurally matched inputs, we review causes for 
mismatch, their perceptual consequences, and experimental methods for mismatch 
measurements. The focus is on the three primary interaural dimensions of 
latency, frequency, and level. Often, the mismatch is not constant, but rather 
highly stimulus-dependent. We report on mismatch compensation strategies, taking 
into consideration the specific needs of the respective patient groups. 
Practical challenges typically faced by audiologists in the proposed fitting 
procedure are discussed. While improvement in certain areas (e.g., speaker 
localization) is definitely achievable, a more comprehensive mismatch 
compensation is a very ambitious endeavor. Even in the hypothetical ideal 
fitting case, performance is not expected to exceed that of a good bilateral 
cochlear implant user.

DOI: 10.1177/23312165221108259
PMCID: PMC9218456
PMID: 35726211 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: NH, SB, 
and MP are employees of cochlear implant manufacturer MED-EL. SP had a 
fixed-term contract with MED-EL during the revision phase of the manuscript. The 
remaining authors declare that the research was conducted in the absence of any 
commercial or financial relationships that could be construed as a potential 
conflict of interest.


138. Otol Neurotol. 2023 Mar 1;44(3):209-215. doi: 10.1097/MAO.0000000000003810. Epub 
2023 Jan 18.

Effect of a CI Programming Fitting Tool with Artificial Intelligence in 
Experienced Cochlear Implant Patients.

Wathour J(1), Govaerts PJ, Lacroix E, Naïma D(1).

Author information:
(1)Cliniques universitaires Saint-Luc, Avenue Hippocrate 100, 1200, Brussels, 
Belgium.

OBJECTIVE: Cochlear implants (CIs) are the treatment of choice for patients with 
severe to profound hearing loss. The hearing results, however, considerably vary 
across patients. This may partly be due to variability in the CI fitting. We 
investigated the effect of FOX, a software tool to program CIs using artificial 
intelligence (AI), on hearing outcomes.
METHODS: Forty-seven experienced CI patients who came to our tertiary CI center 
for their annual follow-up between 2017 and 2020 were recruited for this study. 
They received a new CI map created by the AI software tool. CI parameters and 
auditory outcomes obtained with this new map were compared with those of the 
initial manual map after 15 days of take-home experience. Within-patient 
differences were assessed. At the end of the study, the patients were offered a 
choice to continue using the AI map or to revert to their old manual map.
RESULTS: Several auditory outcomes improved with the AI map, namely, pure tone 
audiometric threshold at 6,000 Hz (median improvement 10 dB, range = -20 to 50 
dB, Z = -2.608, p = 0.008), phonemic discrimination scores (median improvement 
10%, range = 0% to 30%, Z = -4.061, p = 0.001), and soft-intensity (median 
improvement of 10%, range = -20% to 90%, Z = -4.412, p < 0.001) to 
normal-intensity (median improvement of 10%, range = -30% to 60%, Z = -3.35, p < 
0.001) speech audiometric scores.
CONCLUSION: The AI-assisted CI mapping model as a potential assistive tool may 
improve audiological outcomes for experienced CI patients, including 
high-frequency pure tone audiometry and audiometric speech scores at low and 
normal presentation levels.Clinical trial registration: NCT03700268.

Copyright © 2023, Otology & Neurotology, Inc.

DOI: 10.1097/MAO.0000000000003810
PMID: 36728126 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of interest: Authors J.W., E.L., and 
N.D. report no conflict of interest relevant to this article. Author P.G. owns 
intellectual property rights in FOX® and has royalty benefits related to this 
product.


139. Int J Audiol. 2022 Mar;61(3):205-219. doi: 10.1080/14992027.2021.1929515. Epub 
2021 Jun 3.

Inference of the distortion component of hearing impairment from speech 
recognition by predicting the effect of the attenuation component.

Hülsmeier D(1)(2), Buhl M(1)(2), Wardenga N(2)(3), Warzybok A(1)(2), Schädler 
MR(1)(2), Kollmeier B(1)(2).

Author information:
(1)Medical Physics, CvO University Oldenburg, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.

OBJECTIVE: A model-based determination of the average supra-threshold 
("distortion") component of hearing impairment which limits the benefit of 
hearing aid amplification.
DESIGN: Published speech recognition thresholds (SRTs) were predicted with the 
framework for auditory discrimination experiments (FADE), which simulates 
recognition processes, the speech intelligibility index (SII), which exploits 
frequency-dependent signal-to-noise ratios (SNR), and a modified SII with a 
hearing-loss-dependent band importance function (PAV). Their 
attenuation-component-based prediction errors were interpreted as estimates of 
the distortion component.
STUDY SAMPLE: Unaided SRTs of 315 hearing-impaired ears measured with the German 
matrix sentence test in stationary noise.
RESULTS: Overall, the models showed root-mean-square errors (RMSEs) of 7 dB, but 
for steeply sloping hearing loss FADE and PAV were more accurate (RMSE = 9 dB) 
than the SII (RMSE = 23 dB). Prediction errors of FADE and PAV increased 
linearly with the average hearing loss. The consideration of the distortion 
component estimate significantly improved the accuracy of FADE's and PAV's 
predictions.
CONCLUSIONS: The supra-threshold distortion component-estimated by prediction 
errors of FADE and PAV-seems to increase with the average hearing loss. 
Accounting for a distortion component improves the model predictions and implies 
a need for effective compensation strategies for supra-threshold processing 
deficits with increasing audibility loss.

DOI: 10.1080/14992027.2021.1929515
PMID: 34081564 [Indexed for MEDLINE]


140. Clin Neurophysiol. 2018 Jan;129(1):133-142. doi: 10.1016/j.clinph.2017.10.025. 
Epub 2017 Nov 7.

Event-related neuronal responses to acoustic novelty in single-sided deaf 
cochlear implant users: Initial findings.

Bönitz H(1), Kopp B(2), Büchner A(3), Lunner T(4), Lyxell B(5), Finke M(6).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(2)Department of Neurology, Hannover Medical School, Hannover, Germany.
(3)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Hannover, Germany.
(4)Department of Behavioural Sciences and Learning, Linnaeus Centre HEAD, 
Linköping University, Linköping, Sweden; Swedish Institute for Disability 
Research, Linköping University, Linköping, Sweden; Eriksholm Research Centre, 
Oticon A/S, Snekkersten, Denmark.
(5)Department of Behavioural Sciences and Learning, Linnaeus Centre HEAD, 
Linköping University, Linköping, Sweden; Swedish Institute for Disability 
Research, Linköping University, Linköping, Sweden; Department of Behavioral 
Sciences and Learning, Linköping University, Linköping, Sweden.
(6)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Hannover, Germany. Electronic 
address: Finke.Mareike@mh-hannover.de.

OBJECTIVE: A cochlear implant (CI) is an auditory prosthesis restoring profound 
hearing loss. However, CI-transmitted sounds are degraded compared to normal 
acoustic hearing. We investigated cortical responses related to CI-degraded 
against acoustic listening.
METHODS: Event-related potentials (ERPs) were recorded from eight single-sided 
deaf CI users who performed a three-stimulus oddball task, separately with their 
normal hearing ear and CI ear. The oddball tones were occasionally intermitted 
by novel sounds. ERP responses were compared between electric and acoustic 
listening for the auditory (N1) and auditory-cognitive (Novelty P3, Target-P3) 
ERP components.
RESULTS: CI-degraded listening was associated with attenuated sensory processing 
(N1) and with attenuated early cortical responses to acoustic novelty whereas 
the late cortical responses to acoustic novelty and the target-P3 did not differ 
between NH and CI ears.
CONCLUSION: The present study replicates the CI-attenuation of Novelty-P3 
amplitudes in a within-subject comparison. Further, we show that the 
CI-attenuation of Novelty-P3 amplitudes extends to early cortical responses to 
acoustic novelty, but not to late novelty responses.
SIGNIFICANCE: The dissociation into CI-attenuated P3 early Novelty-P3 amplitudes 
and CI-unaffected late Novelty-P3 amplitudes represents a cortical fingerprint 
of CI-degraded listening. It further contributes to general claims of distinct 
auditory Novelty-P3 sub-components.

Copyright © 2017 International Federation of Clinical Neurophysiology. Published 
by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.clinph.2017.10.025
PMID: 29182915 [Indexed for MEDLINE]


141. J Acoust Soc Am. 2015 Sep;138(3):1637-59. doi: 10.1121/1.4928305.

Functional modeling of the human auditory brainstem response to broadband 
stimulation.

Verhulst S(1), Bharadwaj HM(2), Mehraei G(3), Shera CA(4), Shinn-Cunningham 
BG(2).

Author information:
(1)Cluster of Excellence "Hearing4all" and Medizinische Physik, Department of 
Medical Physics and Acoustics, Oldenburg University, Carl-von-Ossietzky Strasse 
9-11, 26129 Oldenburg, Germany.
(2)Center of Computational Neuroscience and Neural Technology, Boston 
University, 677 Beacon Street, Boston, Massachusetts 02215, USA.
(3)Department of Biomedical Engineering, Boston University, 44 Cummington 
Street, Boston, Massachusetts 02215, USA.
(4)Eaton-Peabody Laboratory, 243 Charles Street, Boston, Massachusetts 02114, 
USA.

Population responses such as the auditory brainstem response (ABR) are commonly 
used for hearing screening, but the relationship between single-unit physiology 
and scalp-recorded population responses are not well understood. Computational 
models that integrate physiologically realistic models of single-unit 
auditory-nerve (AN), cochlear nucleus (CN) and inferior colliculus (IC) cells 
with models of broadband peripheral excitation can be used to simulate ABRs and 
thereby link detailed knowledge of animal physiology to human applications. 
Existing functional ABR models fail to capture the empirically observed 1.2-2 ms 
ABR wave-V latency-vs-intensity decrease that is thought to arise from 
level-dependent changes in cochlear excitation and firing synchrony across 
different tonotopic sections. This paper proposes an approach where 
level-dependent cochlear excitation patterns, which reflect human cochlear 
filter tuning parameters, drive AN fibers to yield realistic level-dependent 
properties of the ABR wave-V. The number of free model parameters is minimal, 
producing a model in which various sources of hearing-impairment can easily be 
simulated on an individualized and frequency-dependent basis. The model fits 
latency-vs-intensity functions observed in human ABRs and otoacoustic emissions 
while maintaining rate-level and threshold characteristics of single-unit AN 
fibers. The simulations help to reveal which tonotopic regions dominate ABR 
waveform peaks at different stimulus intensities.

DOI: 10.1121/1.4928305
PMCID: PMC4592442
PMID: 26428802 [Indexed for MEDLINE]


142. Audiol Neurootol. 2022;27(1):83-92. doi: 10.1159/000515489. Epub 2021 Apr 26.

A New Active Osseointegrated Implant System in Patients with Single-Sided 
Deafness.

Willenborg K(1), Avallone E(1), Maier H(1)(2), Lenarz T(1)(2), Busch S(1)(2).

Author information:
(1)Department of Otorhinolaryngology, Medical University Hannover, Hannover, 
Germany.
(2)Cluster of Excellence Hearing4all, Medical University Hannover, Hannover, 
Germany.

OBJECTIVE: The Cochlear™ Osia® System (Osia) is an active transcutaneous bone 
conduction implant system intended for patients with conductive and mixed 
hearing loss but can also be used in cases of single-sided deafness (SSD) for 
the contralateral routing of signal (CROS). The Osia implant is placed 
subcutaneously under the intact skin behind the ear with the piezoelectric 
actuator connected to an osseointegrated BI300 implant - a titanium screw used 
for a 2-stage Baha surgery - on the mastoid. The external processor is 
magnetically attached to the subcutaneous implant receiver coil. As the Osia has 
recently been CE certified and is new on the market, with limited patient 
outcome data for SSD available, the objective of this study was the evaluation 
of surgical procedure, audiological results, and patient satisfaction for the 
Osia in SSD patients.
STUDY DESIGN: In a prospective, monocentric clinical observation study, 6 
patients (18 years of age or older) with SSD and bone conduction thresholds pure 
tone average 0.5, 1, 2, and 4 kHz ≤25 dB HL on the contralateral side were 
implanted with an Osia. Analysis of clinical outcome data with respect to 
surgical technique, adverse events, audiological measurement, and subjective 
benefit for SSD patients was conducted. Audiological measurements performed 
included hearing thresholds, sound field thresholds, word recognition scores 
(WRS; in %) in quiet, and speech recognition thresholds in noise (in dB SNR). 
All tests were performed unaided and aided with the Osia. The subjective benefit 
with the Osia was determined by using 2 questionnaires; the Abbreviated Profile 
of Hearing Aid Benefit (APHAB) and the Bern Benefit in Single-Sided Deafness 
(BBSSD).
RESULTS: Preliminary results indicate a straightforward surgical procedure with 
a low rate of complications and an improvement in speech perception in quiet, 
listening performance in everyday situations and patient satisfaction. However, 
in one of 6 subjects, a revision surgery had to be performed.
CONCLUSION: Provided that SSD patients are open for CROS hearing, they can 
benefit from the Osia by reduced head shadow effects and better speech 
recognition. Special caution should be given to the skin at the site of 
implantation to avoid complications.

© 2021 The Author(s) Published by S. Karger AG, Basel.

DOI: 10.1159/000515489
PMID: 33902037 [Indexed for MEDLINE]


143. Hear Res. 2020 Feb;386:107873. doi: 10.1016/j.heares.2019.107873. Epub 2019 Dec 
18.

Psychoacoustic and electrophysiological electric-acoustic interaction effects in 
cochlear implant users with ipsilateral residual hearing.

Imsiecke M(1), Büchner A(2), Lenarz T(3), Nogueira W(4).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Hanover, Germany. 
Electronic address: imsiecke.marina@mh-hannover.de.
(2)Department of Otorhinolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
buechner.andreas@mh-hannover.de.
(3)Department of Otorhinolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
lenarz.thomas@mh-hannover.de.
(4)Department of Otorhinolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
nogueiravazquez.waldo@mh-hannover.de.

Cochlear implant users with ipsilateral residual hearing combine acoustic and 
electric hearing in one ear, this is called electric-acoustic stimulation (EAS). 
In EAS users, masking can be shown for electric probes in the presence of 
acoustic maskers and vice versa. Masking effects in acoustic hearing are 
generally attributed to nonlinearities of the basilar membrane and hair cell 
adaptation effects. However, similar masking patterns are observed more 
centrally in electric hearing. Consequently, there is no consensus so far on the 
level of interaction between the two modalities. Animal studies have shown that 
electric-acoustic interaction effects can result in reduced physiological 
responses in the cochlear nerve and the inferior colliculus. In CI users with 
residual hearing, it has recently become feasible to record intracochlear 
potentials with a high spatial resolution via the implanted electrode array. An 
investigation of the electrophysiological effects during combined 
electric-acoustic stimulation in humans might be used to assess peripheral 
mechanisms of masking. Seventeen MED-EL Flex electrode users with ipsilateral 
residual hearing participated in both a behavioral and a physiological 
electric-acoustic masking experiment. Psychoacoustic methods were used to 
measure the changes in behavioral thresholds due to the presence of a masker of 
the opposing modality. Subjects were stimulated electrically with unmodulated 
pulse trains using a research interface and acoustically with pure tones 
delivered via headphones. Auditory response telemetry was used to obtain 
objective electrophysiological changes of electrically evoked compound action 
potential and electrocochleography for electric, acoustic and combined 
electric-acoustic presentation in the same subjects. Behavioral thresholds of 
probe tones, either electric or acoustic, were significantly elevated in the 
presence of acoustic or electric maskers, respectively. 15 subjects showed 
significant electric threshold elevation with acoustic masking that did not 
depend on the electric-acoustic frequency difference (EAFD), a measure for the 
proximity of stimulation sites in the cochlea. Electric masking showed 
significant threshold elevation in eleven subjects, which depended significantly 
on EAFD. In the electrophysiological masking experiment, reduced responses to 
electric and acoustic stimulation with additional stimulation of the opposing 
modality were observed. Results showed a similar asymmetry as the psychoacoustic 
masking experiment. Response reduction was smaller than threshold elevation, 
especially for electric masking. Some subjects showed reduced responses to 
acoustic stimulation with electric masking, especially for small EAFD. The 
reduction of electrically evoked responses was significant in some subjects. No 
correlation was observed between psychoacoustic and electrophysiological masking 
results. From present study, it can be concluded that both electric and acoustic 
stimulation mask each other when presented simultaneously. Electrophysiological 
measurements indicate that masking effects are already to some extent present in 
the periphery.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.107873
PMID: 31884220 [Indexed for MEDLINE]


144. J Acoust Soc Am. 2021 Jan;149(1):62. doi: 10.1121/10.0002977.

Sensitivity and specificity of a method for diagnosis of military noise-induced 
hearing loss.

Moore BCJ(1), von Gablenz P(2).

Author information:
(1)Department of Psychology, University of Cambridge, Downing Street, Cambridge, 
CB2 3EB, United Kingdom.
(2)Institute of Hearing Technology and Audiology and Cluster of Excellence 
"Hearing4All", Oldenburg, Germany.

Moore [(2020). J. Acoust. Soc. Am. 148, 884-894] proposed a method for the 
diagnosis of hearing loss produced by noise exposure during military service 
(denoted M-NIHL) based on the audiogram. This letter characterizes the 
sensitivity and specificity of the method, based on 116 ears of men claiming 
compensation for M-NIHL and 244 ears of an age-matched non-noise-exposed control 
group of men screened to match the noise-exposed group in age, absence of 
conductive hearing loss, no history of ear diseases, and asymmetry across ears 
≤10 dB. The sensitivity was 0.97 and the specificity was 0.67, giving a 
discriminability index d' of 2.3.

DOI: 10.1121/10.0002977
PMID: 33514161 [Indexed for MEDLINE]


145. Infancy. 2021 Mar;26(2):327-348. doi: 10.1111/infa.12386. Epub 2021 Jan 22.

Mismatched response predicts behavioral speech discrimination outcomes in 
infants with hearing loss and normal hearing.

Uhler K(1), Hunter S(2), Gilley PM(3).

Author information:
(1)Children's Hospital Colorado, University of Colorado, Anschutz School of 
Medicine, Aurora, CO, USA.
(2)University of Colorado, Anschutz School of Medicine, Aurora, CO, USA.
(3)Institute of Cognitive Science, University of Colorado, Boulder, Boulder, CO, 
USA.

Children with hearing loss (HL) remain at risk for poorer language abilities 
than normal hearing (NH) children despite targeted interventions; reasons for 
these differences remain unclear. In NH children, research suggests speech 
discrimination is related to language outcomes, yet we know little about it in 
children with HL under the age of 2 years. We utilized a vowel contrast, /a-i/, 
and a consonant-vowel contrast, /ba-da/, to examine speech discrimination in 47 
NH infants and 40 infants with HL. At Mean age =3 months, EEG recorded from 11 
scalp electrodes was used to compute the time-frequency mismatched response 
(TF-MMRSE ) to the contrasts; at Mean age =9 months, behavioral discrimination 
was assessed using a head turn task. A machine learning (ML) classifier was used 
to predict behavioral discrimination when given an arbitrary TF-MMRSE as input, 
achieving accuracies of 73% for exact classification and 92% for classification 
within a distance of one class. Linear fits revealed a robust relationship 
regardless of hearing status or speech contrast. TF-MMRSE responses in the delta 
(1-3.5 Hz), theta (3.5-8 Hz), and alpha (8-12 Hz) bands explained the most 
variance in behavioral task performance. Our findings demonstrate the 
feasibility of using TF-MMRSE to predict later behavioral speech discrimination.

© 2021 The Authors. Infancy published by Wiley Periodicals LLC on behalf of 
International Congress of Infant Studies.

DOI: 10.1111/infa.12386
PMCID: PMC7935319
PMID: 33481354 [Indexed for MEDLINE]


146. J Speech Lang Hear Res. 2019 Jan 30;62(1):177-189. doi: 
10.1044/2018_JSLHR-H-18-0064.

Age Effects on Concurrent Speech Segregation by Onset Asynchrony.

Stuckenberg MV(1)(2)(3), Nayak CV(1), Meyer BT(1), Völker C(1), Hohmann V(1), 
Bendixen A(1)(4).

Author information:
(1)Cluster of Excellence "Hearing4all," Carl von Ossietzky University of 
Oldenburg, Germany.
(2)Department of Psychology, University of Leipzig, Germany.
(3)Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, 
Germany.
(4)Faculty of Natural Sciences, Chemnitz University of Technology, Germany.

Purpose For elderly listeners, it is more challenging to listen to 1 voice 
surrounded by other voices than for young listeners. This could be caused by a 
reduced ability to use acoustic cues-such as slight differences in onset 
time-for the segregation of concurrent speech signals. Here, we study whether 
the ability to benefit from onset asynchrony differs between young (18-33 years) 
and elderly (55-74 years) listeners. Method We investigated young (normal 
hearing, N = 20) and elderly (mildly hearing impaired, N = 26) listeners' 
ability to segregate 2 vowels with onset asynchronies ranging from 20 to 100 ms. 
Behavioral measures were complemented by a specific event-related brain 
potential component, the object-related negativity, indicating the perception of 
2 distinct auditory objects. Results Elderly listeners' behavioral performance 
(identification accuracy of the 2 vowels) was considerably poorer than young 
listeners'. However, both age groups showed the same amount of improvement with 
increasing onset asynchrony. Object-related negativity amplitude also increased 
similarly in both age groups. Conclusion Both age groups benefit to a similar 
extent from onset asynchrony as a cue for concurrent speech segregation during 
active (behavioral measurement) and during passive (electroencephalographic 
measurement) listening.

DOI: 10.1044/2018_JSLHR-H-18-0064
PMID: 30534994 [Indexed for MEDLINE]


147. Sci Rep. 2019 Mar 5;9(1):3532. doi: 10.1038/s41598-019-39991-9.

Categorization of everyday sounds by cochlear implanted children.

Berland A(1)(2)(3), Collett E(1)(2), Gaillard P(3), Guidetti M(3), Strelnikov 
K(1)(2)(4), Cochard N(4), Barone P(5)(6), Deguine O(1)(2)(4).

Author information:
(1)UMR 5549, Faculté de Médecine Purpan, Centre National de la Recherche 
Scientifique, Toulouse, France.
(2)Centre de Recherche Cerveau et Cognition, Université de Toulouse, Université 
Paul Sabatier, Toulouse, France.
(3)Unité de Recherche Interdisciplinaire Octogone, EA4156, Laboratoire 
Cognition, Communication et Développement, Université de Toulouse Jean-Jaurès, 
Toulouse, France.
(4)Faculté de Médecine de Purpan, Toulouse, France; Service 
d'Oto-Rhino-Laryngologie et Oto-Neurologie, Hopital Purpan, Toulouse, France.
(5)UMR 5549, Faculté de Médecine Purpan, Centre National de la Recherche 
Scientifique, Toulouse, France. Pascal.barone@cnrs.fr.
(6)Centre de Recherche Cerveau et Cognition, Université de Toulouse, Université 
Paul Sabatier, Toulouse, France. Pascal.barone@cnrs.fr.

Auditory categorization is an important process in the perception and 
understanding of everyday sounds. The use of cochlear implants (CIs) may affect 
auditory categorization and result in poor abilities. The current study was 
designed to compare how children with normal hearing (NH) and children with CIs 
categorize a set of everyday sounds. We tested 24 NH children and 24 children 
with CI on a free-sorting task of 18 everyday sounds corresponding to four a 
priori categories: nonlinguistic human vocalizations, environmental sounds, 
musical sounds, and animal vocalizations. Multiple correspondence analysis 
revealed considerable variation within both groups of child listeners, although 
the human vocalizations and musical sounds were similarly categorized. In 
contrast to NH children, children with CIs categorized some sounds according to 
their acoustic content rather than their associated semantic information. These 
results show that despite identification deficits, children with CIs are able to 
categorize environmental and vocal sounds in a similar way to NH children, and 
are able to use categorization as an adaptive process when dealing with everyday 
sounds.

DOI: 10.1038/s41598-019-39991-9
PMCID: PMC6401047
PMID: 30837546 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


148. Ear Hear. 2022 Sep-Oct 01;43(5):1437-1446. doi: 10.1097/AUD.0000000000001196. 
Epub 2022 Jan 4.

Is Having Hearing Loss Fundamentally Different? Multigroup Structural Equation 
Modeling of the Effect of Cognitive Functioning on Speech Identification.

Marsja E(1)(2), Stenbäck V(1)(2), Moradi S(1)(2)(3), Danielsson H(1)(2), 
Rönnberg J(1)(2).

Author information:
(1)Division of Disability Research, Department of Behavioral Sciences and 
Learning, Linköping University, Linköping, Sweden.
(2)Linnaeus CENTRE HEAD, The Swedish Institute for Disability research, 
Linköping University, Linköping, Sweden.
(3)Faculty of Health and Social Sciences, Department of Health, Social and 
Welfare Studies, University of South-Eastern Norway, Porsgrunn, Norway.

OBJECTIVES: Previous research suggests that there is a robust relationship 
between cognitive functioning and speech-in-noise performance for older adults 
with age-related hearing loss. For normal-hearing adults, on the other hand, the 
research is not entirely clear. Therefore, the current study aimed to examine 
the relationship between cognitive functioning, aging, and speech-in-noise, in a 
group of older normal-hearing persons and older persons with hearing loss who 
wear hearing aids.
DESIGN: We analyzed data from 199 older normal-hearing individuals (mean age = 
61.2) and 200 older individuals with hearing loss (mean age = 60.9) using 
multigroup structural equation modeling. Four cognitively related tasks were 
used to create a cognitive functioning construct: the reading span task, a 
visuospatial working memory task, the semantic word-pairs task, and Raven's 
progressive matrices. Speech-in-noise, on the other hand, was measured using 
Hagerman sentences. The Hagerman sentences were presented via an experimental 
hearing aid to both normal hearing and hearing-impaired groups. Furthermore, the 
sentences were presented with one of the two background noise conditions: the 
Hagerman original speech-shaped noise or four-talker babble. Each noise 
condition was also presented with three different hearing processing settings: 
linear processing, fast compression, and noise reduction.
RESULTS: Cognitive functioning was significantly related to speech-in-noise 
identification. Moreover, aging had a significant effect on both speech-in-noise 
and cognitive functioning. With regression weights constrained to be equal for 
the two groups, the final model had the best fit to the data. Importantly, the 
results showed that the relationship between cognitive functioning and 
speech-in-noise was not different for the two groups. Furthermore, the same 
pattern was evident for aging: the effects of aging on cognitive functioning and 
aging on speech-in-noise were not different between groups.
CONCLUSION: Our findings revealed similar cognitive functioning and aging 
effects on speech-in-noise performance in older normal-hearing and aided 
hearing-impaired listeners. In conclusion, the findings support the Ease of 
Language Understanding model as cognitive processes play a critical role in 
speech-in-noise independent from the hearing status of elderly individuals.

Copyright © 2022 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001196
PMID: 34983896 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest 
relevant to this article to disclose.


149. PLoS One. 2020 Apr 23;15(4):e0231632. doi: 10.1371/journal.pone.0231632. 
eCollection 2020.

Gender-specific hearing loss in German adults aged 18 to 84 years compared to 
US-American and current European studies.

von Gablenz P(1), Hoffmann E(2), Holube I(1).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4all", Oldenburg, Germany.
(2)Department of Audiology, Aalen University of Applied Sciences, Aalen, 
Germany.

INTRODUCTION: From an epidemiological point of view, the increase of pure-tone 
hearing thresholds as one aspect of biological ageing is moderated by societal 
factors. Since health policies refer to empirical findings, it is reasonable to 
replicate population-based hearing surveys and to compare estimates for 
different birth cohorts from the same regions or, conversely, for the same birth 
cohorts from different regions.
METHODS: We pooled data from two independent cross-sectional German studies 
conducted between 2008 and 2012 and including 3105 adults. The increase of 
thresholds, the prevalence and risk of hearing impairment (HI) by age and gender 
were compared to results reported for European and US-American studies that were 
carried out at about the same time. Since these studies differed with regard to 
the age limits, the statistical approaches and, importantly, their definitions 
of HI, data adjustments were performed to enable the comparison.
RESULTS: Overall, 15.5% of the participants in the German studies showed a 
pure-tone average at 0.5, 1, 2, and 4 kHz in the better ear (PTA) greater than 
25 dB HL and 8.6% had a PTA of at least 35 dB HL. Based on one-to-one 
comparisons, the German estimates demonstrated a good agreement to a large Dutch 
study and with some reservations to a Swedish study, but considerable 
differences to US-American results. Comprehensive comparisons of the 
within-study gender differences showed that age-related HI was less and the 
gender gap was markedly smaller in Europe compared to the US due to the lower HI 
in males found in the European studies.
CONCLUSION: Discrepancies in measurement procedures, conditions, and equipment 
that complicate the comparison of absolute HI estimates across studies play no 
or only a marginal role when comparing relative estimates. Hence, the gender gap 
differences reviewed in this analysis possibly stem from societal conditions 
that distinguish societies commonly labeled modern industrialized western 
countries.

DOI: 10.1371/journal.pone.0231632
PMCID: PMC7179866
PMID: 32324766 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


150. Int J Pediatr Otorhinolaryngol. 2015 Apr;79(4):487-92. doi: 
10.1016/j.ijporl.2015.01.004. Epub 2015 Jan 19.

CHARGE syndrome and Cochlear implantation: difficulties and outcomes in the 
paediatric population.

Birman CS(1), Brew JA(2), Gibson WP(3), Elliott EJ(4).

Author information:
(1)Discipline of Paediatrics and Child Health, Sydney Medical School, University 
of Sydney, Sydney, Australia; Sydney Children's Hospital Network (Children's 
Hospital at Westmead), Hawkesbury Road, Westmead 2145, NSW, Australia; The 
Sydney Cochlear Implant Centre, Royal Institute for Deaf and Blind Children, PO 
Box 188, Gladesville 1675, NSW, Australia; Department of Linguistics, Faculty of 
Human Sciences, Macquarie University, North Ryde, Australia. Electronic address: 
Catherine.birman@gmail.com.
(2)The Sydney Cochlear Implant Centre, Royal Institute for Deaf and Blind 
Children, PO Box 188, Gladesville 1675, NSW, Australia.
(3)Sydney Children's Hospital Network (Children's Hospital at Westmead), 
Hawkesbury Road, Westmead 2145, NSW, Australia; The Sydney Cochlear Implant 
Centre, Royal Institute for Deaf and Blind Children, PO Box 188, Gladesville 
1675, NSW, Australia; Emeritus Professor, Sydney Medical School, University of 
Sydney, Sydney, Australia.
(4)Discipline of Paediatrics and Child Health, Sydney Medical School, University 
of Sydney, Sydney, Australia; Sydney Children's Hospital Network (Children's 
Hospital at Westmead), Hawkesbury Road, Westmead 2145, NSW, Australia.

OBJECTIVES: CHARGE syndrome is a complex cluster of congenital abnormalities, 
these children may have absent or hypoplastic auditory nerves. Our objective was 
to assess preoperative factors and outcomes for paediatric cochlear implant 
recipients with CHARGE syndrome, to enable better surgical preparation and 
family counselling.
METHODS: The Sydney Cochlear Implant Centre database was searched for children 
with CHARGE syndrome who had received a cochlear implant at ages 16 and less. 
Data were collected regarding clinical history; hearing assessments; MRI and CT 
scan findings; preoperative transtympanic electrical Auditory Brainstem Response 
(ABR); intraoperative findings and intraoperative electrical ABR and Neural 
Response Telemetry; and language outcomes in terms of main language used and 
Categories of Auditory Performance scores (0-7 ranking).
RESULTS: Ten children were identified. All seven prelingual profoundly deaf 
children with CHARGE syndrome had hypoplastic or absent auditory nerves 
bilaterally on MRI scans. Middle ear anatomy was often abnormal, affecting 
surgical landmarks and making identification of the cochlea very difficult in 
some cases. Three cases required repeated surgery to obtain successful cochlear 
implant insertion, one under CT scan image guided technique. All seven children 
used sign language, or simpler gestures, as their main mode of communication. 
Two children of of these children, who were implanted early, also attained some 
spoken language. CAP scores ranged from 0 to 6. The three children with CHARGE 
syndrome and progressive sensorineural hearing loss had a normal auditory nerve 
in at least one ear on MRI scans. All had preoperative verbal language, with CAP 
scores of 6, and continued with CAP scores of 6 following receipt of the 
cochlear implant.
CONCLUSION: Children with CHARGE and congenital profound hearing loss all had 
hypoplasia or absent auditory nerves, affecting their outcomes with cochlear 
implants. They often had markedly abnormal middle ear anatomy and CT image 
guided surgery can be helpful. These children should be offered a bilingual 
early intervention approach, using sign language and verbal language, to ensure 
best language outcomes. Children with CHARGE syndrome and progressive profound 
hearing loss did well with cochlear implants and continue to be able to use 
verbal language.

Copyright © 2015 Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.ijporl.2015.01.004
PMID: 25649713 [Indexed for MEDLINE]


151. Laryngoscope. 2024 Feb;134(2):926-936. doi: 10.1002/lary.30894. Epub 2023 Jul 
14.

Predicting Acoustic Hearing Preservation Following Cochlear Implant Surgery 
Using Machine Learning.

Zeitler DM(1)(2), Buchlak QD(3)(4), Ramasundara S(3), Farrokhi F(1)(5), Esmaili 
N(3)(6).

Author information:
(1)Neuroscience Institute, Virginia Mason Franciscan Health, Seattle, 
Washington, USA.
(2)Department of Otolaryngology-Head Neck Surgery, Section of 
Otology/Neurotology, Virginia Mason Franciscan Health, Seattle, Washington, USA.
(3)School of Medicine, University of Notre Dame Australia, Sydney, New South 
Wales, Australia.
(4)Department of Neurosurgery, Monash Health, Melbourne, Victoria, Australia.
(5)Department of Neurosurgery, Virginia Mason Franciscan Health, Seattle, 
Washington, USA.
(6)Faculty of Engineering and Information Technology, University of Technology 
Sydney, Sydney, New South Wales, Australia.

OBJECTIVES: The aim of the study was to train and test supervised 
machine-learning classifiers to predict acoustic hearing preservation after CI 
using preoperative clinical data.
STUDY DESIGN: Retrospective predictive modeling study of prospectively collected 
single-institution CI dataset.
METHODS: One hundred and seventy-five patients from a REDCap database including 
761 patients >18 years who underwent CI and had audiometric testing 
preoperatively and one month after surgery were included. The primary outcome 
variable was the lowest quartile change in acoustic hearing at one month after 
CI using various formulae (standard pure tone average, SPTA; low-frequency PTA, 
LFPTA). Analysis involved applying multivariate logistic regression to detect 
statistical associations and training and testing supervised learning 
classifiers. Classifier performance was assessed with numerous metrics including 
area under the receiver operating characteristic curve (AUC) and Matthews 
correlation coefficient (MCC).
RESULTS: Lowest quartile change (indicating hearing preservation) in SPTA was 
positively associated with a history of meningitis, preoperative LFPTA, and 
preoperative SPTA. Lowest quartile change in SPTA was negatively associated with 
sudden hearing loss, noise exposure, aural fullness, and abnormal anatomy. 
Lowest quartile change in LFPTA was positively associated with preoperative 
LFPTA. Lowest quartile change in LFPTA was negatively associated with tobacco 
use. Random forest demonstrated the highest mean classification performance on 
the validation dataset when predicting each of the outcome variables.
CONCLUSIONS: Machine learning demonstrated utility for predicting preservation 
of residual acoustic hearing in patients undergoing CI surgery, and the detected 
associations facilitated the interpretation of our machine-learning models. The 
models and statistical associations together may be used to facilitate 
improvements in shared clinical decision-making and patient outcomes.
LEVEL OF EVIDENCE: 3 Laryngoscope, 134:926-936, 2024.

© 2023 The American Laryngological, Rhinological and Otological Society, Inc.

DOI: 10.1002/lary.30894
PMID: 37449725 [Indexed for MEDLINE]


152. Ear Hear. 2022 May/Jun;43(3):993-1002. doi: 10.1097/AUD.0000000000001155.

Preoperative Visual Measures of Verbal Learning and Memory and their Relations 
to Speech Recognition After Cochlear Implantation.

Ray C(1), Pisoni DB(2), Lu E(1), Kronenberger WG(2)(3), Moberly AC(1).

Author information:
(1)Department of Otolaryngology, The Ohio State University, Columbus, OH.
(2)Department of Psychological and Brain Sciences, Indiana University, 
Bloomington, IN.
(3)Department of Psychiatry, Indiana University School of Medicine, 
Indianapolis, IN.

OBJECTIVES: This study examined the performance of a group of adult cochlear 
implant (CI) candidates (CIC) on visual tasks of verbal learning and memory. 
Preoperative verbal learning and memory abilities of the CIC group were compared 
with a group of older normal-hearing (ONH) control participants. Relations 
between preoperative verbal learning and memory measures and speech recognition 
outcomes after 6 mo of CI use were also investigated for a subgroup of the CICs.
DESIGN: A group of 80 older adult participants completed a visually presented 
multitrial free recall task. Measures of word recall, repetition learning, and 
the use of self-generated organizational strategies were collected from a group 
of 49 CICs, before cochlear implantation, and a group of 31 ONH controls. Speech 
recognition outcomes were also collected from a subgroup of 32 of the CIC 
participants who returned for testing 6 mo after CI activation.
RESULTS: CICs demonstrated poorer verbal learning performance compared with the 
group of ONH control participants. Among the preoperative verbal learning and 
memory measures, repetition learning slope and measures of self-generated 
organizational clustering strategies were the strongest predictors of post-CI 
speech recognition outcomes.
CONCLUSIONS: Older adult CI candidates present with verbal learning and memory 
deficits compared with older adults without hearing loss, even on visual tasks 
that are independent from the direct effects of audibility. Preoperative verbal 
learning and memory processes reflecting repetition learning and self-generated 
organizational strategies in free recall were associated with speech recognition 
outcomes 6 months after implantation. The pattern of results suggests that 
visual measures of verbal learning may be a useful predictor of outcomes in 
postlingual adult CICs.

Copyright © 2022 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000001155
PMCID: PMC9010345
PMID: 35319518 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflicts of interest. 
All authors contributed to the conceptualization and completion of this research 
project. A.C.M. supervised the data collection; C.R. and D.B.P. wrote the 
initial draft of the article; A.C.M., E.L., and W.G.K. provided edits and 
revisions. All authors discussed the results and implications and commented on 
the article in various stages of preparation.


153. Int J Audiol. 2020 Oct;59(10):763-771. doi: 10.1080/14992027.2020.1741704. Epub 
2020 Mar 18.

The Finnish simplified matrix sentence test for the assessment of speech 
intelligibility in the elderly.

Willberg T(1)(2), Kärtevä K(1), Zokoll M(3)(4), Buschermöhle M(5), Sivonen V(6), 
Aarnisalo A(6), Löppönen H(1)(7), Kollmeier B(3)(8), Dietz A(7).

Author information:
(1)Institute of Clinical Medicine, University of Eastern Finland, Kuopio, 
Finland.
(2)Department of Otorhinolaryngology, Turku University Hospital, Turku, Finland.
(3)Medizinische Physik and Cluster of Excellence Hearing4all, Carl von Ossietzky 
University, Oldenburg, Germany.
(4)Hörzentrum Oldenburg GmbH, Oldenburg, Germany.
(5)Klinisches Innovationszentrum für Medizintechnik Oldenburg, Oldenburg, 
Germany.
(6)Department of Otorhinolaryngology, Helsinki University Hospital, Finland.
(7)Department of Otorhinolaryngology, Kuopio University Hospital, Finland.
(8)HörTech gGmbH, Oldenburg, Germany.

Objective: A simplified version of the Finnish matrix sentence test (FMST) was 
developed to improve the reliability of hearing diagnostic for children and for 
patients with limited working memory capacity and/or vocabulary.Design: Study 1 
evaluated the word matrix of the Finnish simplified matrix sentence test 
(FINSIMAT) to rule out systematic differences between the new FINSIMAT test 
lists, and to provide reference values for normal-hearing (NH) young adults 
(YA). In Study 2, the FINSIMAT and the FMST were evaluated in elderly listeners 
with mild-to-moderate hearing impairment (HI).Study sample: Twenty NH YAs 
participated in Study 1, and 16 elderly HI adults participated in Study 
2.Results: For NH YAs, the reference speech reception threshold (SRT50) estimate 
and the slope for the FINSIMAT were -11.2 ± 1.0 dB signal-to-noise ratio (SNR) 
and 19.4 ± 1.9%/dB SNR. For the elderly HI listeners, the mean SRT50 estimates 
for the FINSIMAT and FMST were -4.1 and -3.6 dB SNR, respectively. The 
correlation between the FMST and FINSIMAT results was strong (r2 = 0.78, 
p < 0.001).Conclusion: The FINSIMAT showed comparable characteristics to the 
FMST and proved feasible for measurements in elderly HI listeners.

DOI: 10.1080/14992027.2020.1741704
PMID: 32186403 [Indexed for MEDLINE]


154. Ear Hear. 2014 May-Jun;35(3):e52-62. doi: 10.1097/AUD.0000000000000003.

Do hearing loss and cognitive function modulate benefit from different binaural 
noise-reduction settings?

Neher T(1), Grimm G, Hohmann V, Kollmeier B.

Author information:
(1)Cluster of Excellence "Hearing4all," Medical Physics Section, Department of 
Medical Physics and Acoustics, Carl-von-Ossietzky University, Oldenburg, 
Germany.

OBJECTIVES: Although previous research indicates that cognitive skills influence 
benefit from different types of hearing aid algorithms, comparatively little is 
known about the role of, and potential interaction with, hearing loss. This 
holds true especially for noise reduction (NR) processing. The purpose of the 
present study was thus to explore whether degree of hearing loss and cognitive 
function modulate benefit from different binaural NR settings based on measures 
of speech intelligibility, listening effort, and overall preference.
DESIGN: Forty elderly listeners with symmetrical sensorineural hearing losses in 
the mild to severe range participated. They were stratified into four 
age-matched groups (with n = 10 per group) based on their pure-tone average 
hearing losses and their performance on a visual measure of working memory (WM) 
capacity. The algorithm under consideration was a binaural coherence-based NR 
scheme that suppressed reverberant signal components as well as diffuse 
background noise at mid to high frequencies. The strength of the applied 
processing was varied from inactive to strong, and testing was carried out 
across a range of fixed signal-to-noise ratios (SNRs). Potential benefit was 
assessed using a dual-task paradigm combining speech recognition with a visual 
reaction time (VRT) task indexing listening effort. Pairwise preference 
judgments were also collected. All measurements were made using headphone 
simulations of a frontal speech target in a busy cafeteria. Test-retest data 
were gathered for all outcome measures.
RESULTS: Analysis of the test-retest data showed all data sets to be reliable. 
Analysis of the speech scores showed that, for all groups, speech recognition 
was unaffected by moderate NR processing, whereas strong NR processing reduced 
intelligibility by about 5%. Analysis of the VRT scores revealed a similar data 
pattern. That is, while moderate NR did not affect VRT performance, strong NR 
impaired the performance of all groups slightly. Analysis of the preference 
scores collapsed across SNR showed that all groups preferred some over no NR 
processing. Furthermore, the two groups with smaller WM capacity preferred 
strong over moderate NR processing; for the two groups with larger WM capacity, 
preference did not differ significantly between the moderate and strong 
settings.
CONCLUSIONS: The present study demonstrates that, for the algorithm and the 
measures of speech recognition and listening effort used here, the effects of 
different NR settings interact with neither degree of hearing loss nor WM 
capacity. However, preferred NR strength was found to be associated with smaller 
WM capacity, suggesting that hearing aid users with poorer cognitive function 
may prefer greater noise attenuation even at the expense of poorer speech 
intelligibility. Further research is required to enable a more detailed 
(SNR-dependent) analysis of this effect and to test its wider applicability.

DOI: 10.1097/AUD.0000000000000003
PMID: 24351610 [Indexed for MEDLINE]


155. Artif Intell Med. 2016 Jun;70:12-30. doi: 10.1016/j.artmed.2016.05.001. Epub 
2016 May 24.

Classification of auditory brainstem responses through symbolic pattern 
discovery.

Molina ME(1), Perez A(2), Valente JP(3).

Author information:
(1)Department of Languages, Information Systems and Software Engineering, School 
of Computer Engineering, Technical University of Madrid, Campus de Montegancedo, 
s/n, Boadilla del Monte, Madrid 28660, Spain. Electronic address: 
me.molina@alumnos.upm.es.
(2)Department of Languages, Information Systems and Software Engineering, School 
of Computer Engineering, Technical University of Madrid, Campus de Montegancedo, 
s/n, Boadilla del Monte, Madrid 28660, Spain. Electronic address: 
aurora@fi.upm.es.
(3)Department of Languages, Information Systems and Software Engineering, School 
of Computer Engineering, Technical University of Madrid, Campus de Montegancedo, 
s/n, Boadilla del Monte, Madrid 28660, Spain. Electronic address: 
jpvalente@fi.upm.es.

INTRODUCTION: Numeric time series are present in a very wide range of domains, 
including many branches of medicine. Data mining techniques have proved to be 
useful for knowledge discovery in this type of data and for supporting 
decision-making processes.
OBJECTIVES: The overall objective is to classify time series based on the 
discovery of frequent patterns. These patterns will be discovered in symbolic 
sequences obtained from the time series data by means of a temporal abstraction 
process.
METHODS: Firstly, we transform numeric time series into symbolic time sequences, 
where the symbols aim to represent the relevant domain concepts. These symbols 
can be defined using either public or expert domain knowledge. Then we apply a 
symbolic pattern discovery technique to the output symbolic sequences. This 
technique identifies the subsequences frequently found in a population group. 
These subsequences (patterns) are representative of population groups. Finally, 
we employ a classification technique based on the identified patterns in order 
to classify new individuals. Thanks to the inclusion of domain knowledge, the 
classification results can be explained using domain terminology. This makes the 
results easier to interpret for the domain specialist (physician).
RESULTS: This method has been applied to brainstem auditory evoked potentials 
(BAEPs) time series. Preliminary experiments were carried out to analyse several 
aspects of the method including the best configuration of the pattern discovery 
technique parameters. We then applied the method to the BAEPs of 83 individuals 
belonging to four classes (healthy, conductive hearing loss, vestibular 
schwannoma-brainstem involvement and vestibular schwannoma-8th-nerve 
involvement). According to the results of the cross-validation, overall accuracy 
was 99.4%, sensitivity (recall) was 97.6% and specificity was 100% (no false 
positives).
CONCLUSION: The proposed method effectively reduces dimensionality. 
Additionally, if the symbolic transformation includes the right domain 
knowledge, the method arguably outputs a data representation that denotes the 
relevant domain concepts more clearly. The method is capable of finding patterns 
in BAEPs time series and is very accurate at correctly predicting whether or not 
new patients have an auditory-related disorder.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.artmed.2016.05.001
PMID: 27431034 [Indexed for MEDLINE]


156. Brain Cogn. 1995 Apr;27(3):398-438. doi: 10.1006/brcg.1995.1028.

Multiresolution analysis of event-related potentials by wavelet decomposition.

Samar VJ(1), Swartz KP, Raghuveer MR.

Author information:
(1)Communication Research Department, National Technical Institute for the Deaf 
at Rochester Institute of Technology, NY 14623-0887, USA.

Wavelet analysis is presented as a new tool for analyzing event-related 
potentials (ERPs). The wavelet transform expands ERPs into a time-scale 
representation, which allows the analyst to zoom in on the small scale, fine 
structure details of an ERP or zoom out to examine the large scale, global 
waveshape. The time-scale representation is closely related to the more familiar 
time-frequency representation used in spectrograms of time-varying signals. 
However, time-scale representations have special properties that make them 
attractive for many ERP applications. In particular, time-scale representations 
permit theoretically unlimited time resolution for the detection of short-lived 
peaks and permit a flexible choice of wavelet basis functions for analyzing 
different types of ERPs. Generally, time-scale representations offer a formal 
basis for designing new, specialized filters for various ERP applications. Among 
recently explored applications of wavelet analysis to ERPs are (a) the precise 
identification of the time of occurrence of overlapping peaks in the auditory 
brainstem evoked response; (b) the extraction of single-trial ERPs from 
background EEG noise; (c) the decomposition of averaged ERP waveforms into 
orthogonal detail functions that isolate the waveform's experimental behavior in 
distinct, orthogonal frequency bands; and (d) the use of wavelet transform 
coefficients to concisely extract important information from ERPs that predicts 
human signal detection performance. In this tutorial we present an intuitive 
introduction to wavelets and the wavelet transform, concentrating on the 
multiresolution approach to wavelet analysis of ERP data. We then illustrate 
this approach with real data. Finally, we offer some speculations on future 
applications of wavelet analysis to ERP data.

DOI: 10.1006/brcg.1995.1028
PMID: 7626282 [Indexed for MEDLINE]


157. S Afr J Commun Disord. 2020 Mar 3;67(2):e1-e11. doi: 10.4102/sajcd.v67i2.675.

Recent advances in hearing conservation programmes: A systematic review.

Moroe NF(1), Khoza-Shangase K.

Author information:
(1)Department of Speech Pathology and Audiology, Faculty of Humanities, 
University of the Witwatersrand, Johannesburg. nomfundo.moroe@wits.ac.za.

BACKGROUND: Current evidence from low- and middle-income (LAMI) countries, such 
as South Africa, indicates that occupational noise-induced hearing loss (ONIHL) 
continues to be a health and safety challenge for the mining industry. There is 
also evidence of hearing conservation programmes (HCPs) being implemented with 
limited success.
OBJECTIVES: The aim of this study was to explore and document current evidence 
reflecting recent advances in HCPs in order to identify gaps within the South 
African HCPs.
METHOD: A systematic literature review was conducted in line with the Preferred 
Reporting Items for Systematic Reviews and Meta-Analysis. Electronic databases 
including Sage, Science Direct, PubMed, Scopus MEDLINE, ProQuest and Google 
Scholar were searched for potential studies published in English between 2010 
and 2019 reporting on recent advances in HCPs within the mining industry.
RESULTS: The study findings revealed a number of important recent advances 
internationally, which require deliberation for possible implementation within 
the South African HCPs context. These advances have been presented under seven 
themes: (1) the use of metrics, (2) pharmacological interventions and hair cell 
regeneration, (3) artificial neural network, (4) audiology assessment measures, 
(5) noise monitoring advances, (6) conceptual approaches to HCPs and (7) buying 
quiet.
CONCLUSION: The study findings raise important advances that may have 
significant implications for HCPs in LAMI countries where ONIHL remains a highly 
prevalent occupational health challenge. Establishing feasibility and efficacy 
of these advances in these contexts to ensure contextual relevance and 
responsiveness is one of the recommendations to facilitate the success of HCPs 
targets.

DOI: 10.4102/sajcd.v67i2.675
PMCID: PMC7136823
PMID: 32129659 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no financial 
or personal relationships which may have inappropriately influenced them in 
writing this article.


158. Hear Res. 2017 Feb;344:183-194. doi: 10.1016/j.heares.2016.11.012. Epub 2016 Nov 
30.

Speech enhancement based on neural networks improves speech intelligibility in 
noise for cochlear implant users.

Goehring T(1), Bolner F(2), Monaghan JJ(3), van Dijk B(4), Zarowski A(5), Bleeck 
S(3).

Author information:
(1)ISVR, University of Southampton, University Rd, Southampton SO17 1BJ, United 
Kingdom. Electronic address: goehring.tobias@gmail.com.
(2)ExpORL, KU Leuven, O&N II Herestraat 49, 3000 Leuven, Belgium; Cochlear 
Technology Centre, Schaliënhoevedreef 20 I, 2800 Mechelen, Belgium.
(3)ISVR, University of Southampton, University Rd, Southampton SO17 1BJ, United 
Kingdom.
(4)Cochlear Technology Centre, Schaliënhoevedreef 20 I, 2800 Mechelen, Belgium.
(5)European Institute for ORL-HNS, Sint Augustinus Hospital, Oosterveldlaan 24, 
2610 Wilrijk, Belgium.

Speech understanding in noisy environments is still one of the major challenges 
for cochlear implant (CI) users in everyday life. We evaluated a speech 
enhancement algorithm based on neural networks (NNSE) for improving speech 
intelligibility in noise for CI users. The algorithm decomposes the noisy speech 
signal into time-frequency units, extracts a set of auditory-inspired features 
and feeds them to the neural network to produce an estimation of which frequency 
channels contain more perceptually important information (higher signal-to-noise 
ratio, SNR). This estimate is used to attenuate noise-dominated and retain 
speech-dominated CI channels for electrical stimulation, as in traditional 
n-of-m CI coding strategies. The proposed algorithm was evaluated by measuring 
the speech-in-noise performance of 14 CI users using three types of background 
noise. Two NNSE algorithms were compared: a speaker-dependent algorithm, that 
was trained on the target speaker used for testing, and a speaker-independent 
algorithm, that was trained on different speakers. Significant improvements in 
the intelligibility of speech in stationary and fluctuating noises were found 
relative to the unprocessed condition for the speaker-dependent algorithm in all 
noise types and for the speaker-independent algorithm in 2 out of 3 noise types. 
The NNSE algorithms used noise-specific neural networks that generalized to 
novel segments of the same noise type and worked over a range of SNRs. The 
proposed algorithm has the potential to improve the intelligibility of speech in 
noise for CI users while meeting the requirements of low computational 
complexity and processing delay for application in CI devices.

Copyright © 2016 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.11.012
PMCID: PMC5256482
PMID: 27913315 [Indexed for MEDLINE]


159. Am J Audiol. 2017 Oct 12;26(3S):369-372. doi: 10.1044/2017_AJA-16-0138.

Diagnosing and Screening in a Minority Language: A Validation Study.

Zokoll MA(1)(2)(3), Wagener KC(2)(3), Kollmeier B(1)(2)(3)(4).

Author information:
(1)Medical Physics, Carl von Ossietzky University Oldenburg, Germany.
(2)Hörzentrum Oldenburg GmbH, Germany.
(3)Cluster of Excellence "Hearing4all," Oldenburg, Germany.
(4)HörTech gGmbH, Oldenburg, Germany.

PURPOSE: The Turkish Digit Triplet Test for hearing self-screening purposes and 
the Turkish Matrix Test (TURMatrix) for follow-up hearing diagnostics offer an 
automated closed-set response format where patients respond by choosing from 
response alternatives. Their applicability for testing Turkish-speaking patients 
in their native language by German audiologists with different Turkish language 
skills was investigated.
METHOD: Tests were composed of spoken numbers (Turkish Digit Triplet Test) or 
sentences (TURMatrix). For 49 participants differing in hearing ability, speech 
reception thresholds (SRTs) in noise and quiet were obtained, for the TURMatrix 
with either the open- or closed-set response format, by audiologists with and 
without Turkish language skills, respectively.
RESULTS: SRTs of both tests correlate closely with each other as well as with 
hearing ability, but not as closely as individual SRTs in quiet with hearing 
ability. SRTs in noise of listeners with normal hearing were about 0.7 dB lower 
for the closed-set than for the open-set response format.
CONCLUSIONS: The 2 tests yield comparable results and are applicable to 
professionals without suitable language skills. For the closed-set response 
format of the TURMatrix, literacy is crucial and supplemental (visual) cues 
improve performance. Speech audiometry in noise should assess suprathreshold 
processing deficits independently from language proficiency in the majority 
language.

DOI: 10.1044/2017_AJA-16-0138
PMID: 29049620 [Indexed for MEDLINE]


160. Trends Hear. 2023 Jan-Dec;27:23312165231213191. doi: 10.1177/23312165231213191.

The Relative Contribution of Cochlear Synaptopathy and Reduced Inhibition to 
Age-Related Hearing Impairment for People With Normal Audiograms.

Gómez-Álvarez M(1)(2), Johannesen PT(1)(2), Coelho-de-Sousa SL(1)(2), Klump 
GM(3), Lopez-Poveda EA(1)(2)(4).

Author information:
(1)Instituto de Neurociencias de Castilla y León, Universidad de Salamanca, 
Salamanca, Spain.
(2)Instituto de Investigación Biomédica de Salamanca, Universidad de Salamanca, 
Salamanca, Spain.
(3)Department of Neuroscience and Cluster of Excellence "Hearing4all", Carl von 
Ossietzky University of Oldenburg, Oldenburg, Germany.
(4)Departamento de Cirugía, Facultad de Medicina, Universidad de Salamanca, 
Salamanca, Spain.

Older people often show auditory temporal processing deficits and 
speech-in-noise intelligibility difficulties even when their audiogram is 
clinically normal. The causes of such problems remain unclear. Some studies have 
suggested that for people with normal audiograms, age-related hearing 
impairments may be due to a cognitive decline, while others have suggested that 
they may be caused by cochlear synaptopathy. Here, we explore an alternative 
hypothesis, namely that age-related hearing deficits are associated with 
decreased inhibition. For human adults (N = 30) selected to cover a reasonably 
wide age range (25-59 years), with normal audiograms and normal cognitive 
function, we measured speech reception thresholds in noise (SRTNs) for 
disyllabic words, gap detection thresholds (GDTs), and frequency modulation 
detection thresholds (FMDTs). We also measured the rate of growth (slope) of 
auditory brainstem response wave-I amplitude with increasing level as an 
indirect indicator of cochlear synaptopathy, and the interference inhibition 
score in the Stroop color and word test (SCWT) as a proxy for inhibition. As 
expected, performance in the auditory tasks worsened (SRTNs, GDTs, and FMDTs 
increased), and wave-I slope and SCWT inhibition scores decreased with ageing. 
Importantly, SRTNs, GDTs, and FMDTs were not related to wave-I slope but 
worsened with decreasing SCWT inhibition. Furthermore, after partialling out the 
effect of SCWT inhibition, age was no longer related to SRTNs or GDTs and became 
less strongly related to FMDTs. Altogether, results suggest that for people with 
normal audiograms, age-related deficits in auditory temporal processing and 
speech-in-noise intelligibility are mediated by decreased inhibition rather than 
cochlear synaptopathy.

DOI: 10.1177/23312165231213191
PMCID: PMC10644751
PMID: 37956654 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting InterestsThe authors 
declared no potential conflicts of interest with respect to the research, 
authorship, and/or publication of this article.


161. Sci Adv. 2019 May 15;5(5):eaav6134. doi: 10.1126/sciadv.aav6134. eCollection 
2019 May.

Speaker-independent auditory attention decoding without access to clean speech 
sources.

Han C(1)(2), O'Sullivan J(1)(2), Luo Y(1)(2), Herrero J(3), Mehta AD(3), 
Mesgarani N(1)(2).

Author information:
(1)Department of Electrical Engineering, Columbia University, New York, NY, USA.
(2)Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, 
USA.
(3)Department of Neurosurgery, Hofstra-Northwell School of Medicine and 
Feinstein Institute for Medical Research, Manhasset, New York, NY, USA.

Speech perception in crowded environments is challenging for hearing-impaired 
listeners. Assistive hearing devices cannot lower interfering speakers without 
knowing which speaker the listener is focusing on. One possible solution is 
auditory attention decoding in which the brainwaves of listeners are compared 
with sound sources to determine the attended source, which can then be amplified 
to facilitate hearing. In realistic situations, however, only mixed audio is 
available. We utilize a novel speech separation algorithm to automatically 
separate speakers in mixed audio, with no need for the speakers to have prior 
training. Our results show that auditory attention decoding with automatically 
separated speakers is as accurate and fast as using clean speech sounds. The 
proposed method significantly improves the subjective and objective quality of 
the attended speaker. Our study addresses a major obstacle in actualization of 
auditory attention decoding that can assist hearing-impaired listeners and 
reduce listening effort for normal-hearing subjects.

DOI: 10.1126/sciadv.aav6134
PMCID: PMC6520028
PMID: 31106271 [Indexed for MEDLINE]


162. Sensors (Basel). 2022 Oct 20;22(20):8031. doi: 10.3390/s22208031.

Automatic User Preferences Selection of Smart Hearing Aid Using BioAid.

Siddiqui HUR(1), Saleem AA(1), Raza MA(1), Zafar K(1), Russo R(2), Dudley S(3).

Author information:
(1)Institute of Computer Science, Khawaja Fareed University of Engineering and 
Information Technology, Rahim Yar Khan 64200, Pakistan.
(2)Department of Brain and Behavioral Sciences, University of Pavia, 27100 
Pavia, Italy.
(3)School of Engineering, London South Bank University, London SE1 0AA, UK.

Noisy environments, changes and variations in the volume of speech, and 
non-face-to-face conversations impair the user experience with hearing aids. 
Generally, a hearing aid amplifies sounds so that a hearing-impaired person can 
listen, converse, and actively engage in daily activities. Presently, there are 
some sophisticated hearing aid algorithms available that operate on numerous 
frequency bands to not only amplify but also provide tuning and noise filtering 
to minimize background distractions. One of those is the BioAid assistive 
hearing system, which is an open-source, freely available downloadable app with 
twenty-four tuning settings. Critically, with this device, a person suffering 
with hearing loss must manually alter the settings/tuning of their hearing 
device when their surroundings and scene changes in order to attain a 
comfortable level of hearing. However, this manual switching among multiple 
tuning settings is inconvenient and cumbersome since the user is forced to 
switch to the state that best matches the scene every time the auditory 
environment changes. The goal of this study is to eliminate this manual 
switching and automate the BioAid with a scene classification algorithm so that 
the system automatically identifies the user-selected preferences based on 
adequate training. The aim of acoustic scene classification is to recognize the 
audio signature of one of the predefined scene classes that best represent the 
environment in which it was recorded. BioAid, an open-source biological inspired 
hearing aid algorithm, is used after conversion to Python. The proposed method 
consists of two main parts: classification of auditory scenes and selection of 
hearing aid tuning settings based on user experiences. The DCASE2017 dataset is 
utilized for scene classification. Among the many classifiers that were trained 
and tested, random forests have the highest accuracy of 99.7%. In the second 
part, clean speech audios from the LJ speech dataset are combined with scenes, 
and the user is asked to listen to the resulting audios and adjust the presets 
and subsets. A CSV file stores the selection of presets and subsets at which the 
user can hear clearly against the scenes. Various classifiers are trained on the 
dataset of user preferences. After training, clean speech audio was convolved 
with the scene and fed as input to the scene classifier that predicts the scene. 
The predicted scene was then fed as input to the preset classifier that predicts 
the user's choice for preset and subset. The BioAid is automatically tuned to 
the predicted selection. The accuracy of random forest in the prediction of 
presets and subsets was 100%. This proposed approach has great potential to 
eliminate the tedious manual switching of hearing assistive device parameters by 
allowing hearing-impaired individuals to actively participate in daily life by 
automatically adjusting hearing aid settings based on the acoustic scene.

DOI: 10.3390/s22208031
PMCID: PMC9610183
PMID: 36298382 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


163. Ear Hear. 2019 Jul/Aug;40(4):938-950. doi: 10.1097/AUD.0000000000000675.

A New Speech, Spatial, and Qualities of Hearing Scale Short-Form: Factor, 
Cluster, and Comparative Analyses.

Moulin A(1)(2), Vergne J(1)(2), Gallego S(3)(4)(5), Micheyl C(6)(7)(8).

Author information:
(1)INSERM U1028, CNRS UMR 5292, Lyon Neuroscience Research Center, Brain 
Dynamics and Cognition Team, University of Lyon, Lyon, France.
(2)Université C. Bernard Lyon 1, Lyon Neuroscience Research Center, Brain 
Dynamics and Cognition Team, University of Lyon, Lyon, France.
(3)Institut des Sciences et Technologies de Réadaptation (ISTR), University of 
Lyon, Lyon, France.
(4)Audition Conseil, Lyon, France.
(5)Laboratory of Integrative and Adaptive Neurosciences (LNIA) UMR 7260, 
Aix-Marseille University-CNRS, Marseille, France.
(6)Starkey Hearing Technologies, Créteil, France.
(7)Starkey Hearing Research Center, Berkeley, California, USA.
(8)INSERM U1028, CNRS UMR 5292, Cognition and Auditory Perception Team (CAP), 
Lyon Neuroscience Research Center, University of Lyon, Lyon, France.

OBJECTIVES: The objective of this work was to build a 15-item short-form of the 
Speech Spatial and Qualities of Hearing Scale (SSQ) that maintains the 
three-factor structure of the full form, using a data-driven approach consistent 
with internationally recognized procedures for short-form building. This 
included the validation of the new short-form on an independent sample and an 
in-depth, comparative analysis of all existing, full and short SSQ forms.
DESIGN: Data from a previous study involving 98 normal-hearing (NH) individuals 
and 196 people with hearing impairments (HI), non hearing aid wearers, along 
with results from several other published SSQ studies, were used for developing 
the short-form. Data from a new and independent sample of 35 NH and 88 HI 
hearing aid wearers were used to validate the new short-form. Factor and 
hierarchical cluster analyses were used to check the factor structure and 
internal consistency of the new short-form. In addition, the new short-form was 
compared with all other SSQ forms, including the full SSQ, the German SSQ15, the 
SSQ12, and the SSQ5. Construct validity was further assessed by testing 
statistical relationships between scores and audiometric factors, including 
pure-tone threshold averages (PTAs) and left/right PTA asymmetry. 
Receiver-operating characteristic analyses were used to compare the ability of 
different SSQ forms to discriminate between NH and HI (HI non hearing aid 
wearers and HI hearing aid wearers) individuals.
RESULTS: Compared all other SSQ forms, including the full SSQ, the new 
short-form showed negligible cross-loading across the three main subscales and 
greater discriminatory power between NH and HI subjects (as indicated by a 
larger area under the receiver-operating characteristic curve), as well as 
between the main subscales (especially Speech and Qualities). Moreover, the new, 
5-item Spatial subscale showed increased sensitivity to left/right PTA 
asymmetry. Very good internal consistency and homogeneity and high correlations 
with the SSQ were obtained for all short-forms.
CONCLUSIONS: While maintaining the three-factor structure of the full SSQ, and 
exceeding the latter in terms of construct validity and sensitivity to 
audiometric variables, the new 15-item SSQ affords a substantial reduction in 
the number of items and, thus, in test time. Based on overall scores, Speech 
subscores, or Spatial subscores, but not Qualities subscores, the 15-item SSQ 
appears to be more sensitive to differences in self-evaluated hearing abilities 
between NH and HI subjects than the full SSQ.

DOI: 10.1097/AUD.0000000000000675
PMID: 30461444 [Indexed for MEDLINE]


164. Ear Hear. 2019 May/Jun;40(3):690-699. doi: 10.1097/AUD.0000000000000649.

Machine Learning Models for the Hearing Impairment Prediction in Workers Exposed 
to Complex Industrial Noise: A Pilot Study.

Zhao Y(1), Li J(1), Zhang M(2), Lu Y(1), Xie H(2), Tian Y(1), Qiu W(3).

Author information:
(1)Key Laboratory for Biomedical Engineering of Ministry of Education, 
Collaborative Innovation Center for Diagnosis and Treatment of Infectious 
Diseases, College of Biomedical Engineering and Instrument Science, Zhejiang 
University, Hangzhou, China.
(2)Institute of Environmental and Occupational Health, Zhejiang Provincial 
Center for Disease Control and Prevention, Hangzhou, China.
(3)Auditory Research Laboratory, State University of New York at Plattsburgh, 
New York, USA.

OBJECTIVES: To demonstrate the feasibility of developing machine learning models 
for the prediction of hearing impairment in humans exposed to complex 
non-Gaussian industrial noise.
DESIGN: Audiometric and noise exposure data were collected on a population of 
screened workers (N = 1,113) from 17 factories located in Zhejiang province, 
China. All the subjects were exposed to complex noise. Each subject was given an 
otologic examination to determine their pure-tone hearing threshold levels and 
had their personal full-shift noise recorded. For each subject, the hearing loss 
was evaluated according to the hearing impairment definition of the National 
Institute for Occupational Safety and Health. Age, exposure duration, equivalent 
A-weighted SPL (LAeq), and median kurtosis were used as the input for four 
machine learning algorithms, that is, support vector machine, neural network 
multilayer perceptron, random forest, and adaptive boosting. Both classification 
and regression models were developed to predict noise-induced hearing loss 
applying these four machine learning algorithms. Two indexes, area under the 
curve and prediction accuracy, were used to assess the performances of the 
classification models for predicting hearing impairment of workers. Root mean 
square error was used to quantify the prediction performance of the regression 
models.
RESULTS: A prediction accuracy between 78.6 and 80.1% indicated that the four 
classification models could be useful tools to assess noise-induced hearing 
impairment of workers exposed to various complex occupational noises. A 
comprehensive evaluation using both the area under the curve and prediction 
accuracy showed that the support vector machine model achieved the best score 
and thus should be selected as the tool with the highest potential for 
predicting hearing impairment from the occupational noise exposures in this 
study. The root mean square error performance indicated that the four regression 
models could be used to predict noise-induced hearing loss quantitatively and 
the multilayer perceptron regression model had the best performance.
CONCLUSIONS: This pilot study demonstrated that machine learning algorithms are 
potential tools for the evaluation and prediction of noise-induced hearing 
impairment in workers exposed to diverse complex industrial noises.

DOI: 10.1097/AUD.0000000000000649
PMCID: PMC6493679
PMID: 30142102 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


165. Ear Hear. 2023 Jan-Feb 01;44(1):118-134. doi: 10.1097/AUD.0000000000001259. Epub 
2022 Jul 27.

Summating Potential as Marker of Intracochlear Position in Bipolar 
Electrocochleography.

Baumhoff P(1), Rahbar Nikoukar L(1), de Andrade JSC(1)(2)(3), Lenarz T(1)(4), 
Kral A(1)(4)(5).

Author information:
(1)Department of Experimental Otology & Institute of AudioNeuroTechnology 
(VIANNA), ENT Clinics, Hannover Medical School, Hannover, Germany.
(2)Department of Otorhinolaryngology and Head and Neck Surgery, Federal 
University of São Paulo (UNIFESP), São Paulo, Brazil.
(3)Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES 
Foundation), Brasília, Brazil.
(4)Cluster of Excellence "Hearing4all", Hannover, Germany.
(5)Department of Biomedical Sciences, School of Medicine and Health Sciences, 
Macquarie University, Sydney, Australia.

OBJECTIVES: Cochlear implantation criteria include subjects with residual 
low-frequency hearing. To minimize implantation trauma and to avoid unwanted 
interactions of electric- and acoustic stimuli, it is often recommended to stop 
cochlear implantation before the cochlear implant (CI) reaches the cochlear 
partition with residual hearing, as determined by an audiogram. For this 
purpose, the implant can be used to record acoustically evoked signals during 
implantation, including cochlear compound action potentials (CAP), cochlear 
microphonics (CMs), and summating potentials (SPs). The former two have 
previously been used to monitor residual hearing in clinical settings.
DESIGN: In the present study we investigated the use of intracochlear, bipolar 
SP recordings to determine the exact cochlear position of the contacts of 
implanted CIs in guinea pig cochleae (n = 13). Polarity reversals of SPs were 
used as a functional marker of intracochlear position. Micro computed tomography 
(µCT) imaging and a modified Greenwood function were used to determine the 
cochleotopic positions of the contacts in the cochlea. These anatomical 
reconstructions were used to validate the SP-based position estimates.
RESULTS: The precision of the SP-based position estimation was on average within 
± 0.37 octaves and was not impaired by moderate hearing loss caused by noise 
exposure after implantation. It is important to note that acute hearing 
impairment did not reduce the precision of the method. The cochleotopic position 
of CI accounted for ~70% of the variability of SP polarity reversals. Outliers 
in the dataset were associated with lateral CI positions. Last, we propose a 
simplified method to avoid implantation in functioning parts of the cochlea by 
approaching a predefined frequency region using bipolar SP recordings through a 
CI.
CONCLUSIONS: Bipolar SP recordings provide reliable information on electrode 
position in the cochlea. The position estimate remains reliable after moderate 
hearing loss. The technique presented here could be applied during CI surgery to 
monitor the CI approach to a predefined frequency region.

Copyright © 2022 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001259
PMID: 35894668 [Indexed for MEDLINE]


166. Ear Hear. 2023 Nov-Dec 01;44(6):1514-1525. doi: 10.1097/AUD.0000000000001393. 
Epub 2023 Jun 9.

Exploring Factors That Contribute to the Success of Rehabilitation With Hearing 
Aids.

Lansbergen SE(1), Versfeld N(2), Dreschler WA(1).

Author information:
(1)Department(s), Clinical and Experimental Audiology, Amsterdam UMC, University 
of Amsterdam, Amsterdam, The Netherlands.
(2)Otolaryngology Head and Neck Surgery, Ear and Hearing, Amsterdam UMC, Vrije 
Universiteit Amsterdam, Amsterdam Public Health Research Institute, Amsterdam, 
Boelelaan, The Netherlands.

OBJECTIVES: Hearing aids are an essential and important part of hearing 
rehabilitation. The combination of technical data on hearing aids and individual 
rehabilitation needs can give insight into the factors that contribute to the 
success of rehabilitation. This study sets out to investigate if different 
subgroups of (comparable) hearing aids lead to differences in the success of 
rehabilitation, and whether these differences vary between different domains of 
auditory functioning.
DESIGN: This study explored the advantages of including patient-reported outcome 
measures (PROMs) in the process of purchasing new hearing aids in a large sample 
of successful hearing aid users. Subject data were obtained from 64 (commercial) 
hearing aid dispensers and 10 (noncommercial) audiological centers in the 
Netherlands. The PROM was a 32-item questionnaire and was used to determine the 
success of rehabilitation using hearing aids by measuring auditory disability 
over time. The items were mapped on six domains of auditory functioning: 
detection, discrimination, localization, speech in quiet, speech in noise, and 
noise tolerance, encompassing a variety of daily-life listening situations. 
Hearing aids were grouped by means of cluster analysis, resulting in nine 
subgroups. In total, 1149 subjects were included in this study. A general linear 
model was used to model the final PROM results. Model results were analyzed via 
a multifactor Analysis of Variance. Post hoc analyses provided detailed 
information on model variables.
RESULTS: Results showed a strong statistically significant effect of hearing 
aids on self-perceived auditory functioning in general. Clinically relevant 
differences were found for auditory domains including detection, speech in 
quiet, speech in noise, and localization. There was only a small, but 
significant, effect of the different subgroups of hearing aids on the final PROM 
results, where no differences were found between the auditory domains. Minor 
differences were found between results obtained in commercial and noncommercial 
settings, or between novice and experienced users. Severity of Hearing loss, 
age, gender, and hearing aid style (i.e., behind-the-ear versus 
receiver-in-canal type) did not have a clinically relevant effect on the final 
PROM results.
CONCLUSIONS: The use of hearing aids has a large positive effect on 
self-perceived auditory functioning. There was however no salient effect of the 
different subgroups of hearing aids on the final PROM results, indicating that 
technical properties of hearing aids only play a limited role in this respect. 
This study challenges the belief that premium devices outperform basic ones, 
highlighting the need for personalized rehabilitation strategies and the 
importance of evaluating factors contributing to successful rehabilitation for 
clinical practice.

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001393
PMCID: PMC10583950
PMID: 37792897 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflicts of interest.


167. Physiol Meas. 2021 May 13;42(4). doi: 10.1088/1361-6579/abcdf2.

Towards effective assessment of normal hearing function from ABR using a 
time-variant sweep-tone stimulus approach.

Jiang Y(1)(2)(3), Samuel OW(1)(3), Zhang H(1)(2)(3), Chen S(1)(2)(3), Li 
G(1)(2)(3).

Author information:
(1)CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen 
Institutes of Advanced Technology (SIAT), Chinese Academy of Sciences (CAS), and 
the SIAT Branch, Shenzhen Institute of Artificial Intelligence and Robotics for 
Society, Shenzhen, People's Republic of China.
(2)Shenzhen College of Advanced Technology, University of Chinese Academy of 
Sciences, Shenzhen, People's Republic of China.
(3)Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine 
Intelligence-Synergy Systems, Shenzhen, People's Republic of China.

Objective. The auditory brainstem response (ABR) audiometry is a means of 
assessing the functional status of the auditory neural pathway in the clinic. 
The conventional click ABR test lacks good neural synchrony and it mainly 
evaluates high-frequency hearing while the common tone-burst ABR test only 
detects hearing loss of a certain frequency at a time. Additionally, the 
existing chirp stimuli are designed based on average data of cochlear 
characteristics, ignoring individual differences amongst subjects.Approach. 
Therefore, this study designed a new stimulus approach based on a sweep-tone 
concept with a time variant and spectrum characteristics that could be 
customized based on an individual's cochlear characteristics. To validate the 
efficiency of the proposed method, we compared its performance with the click 
and tone-bursts using ABR recordings from 11 normal-hearing adults.Main results. 
Experimental results showed that the proposed sweep-tone ABR achieved a higher 
amplitude compared with those elicited by the click and tone-bursts. When the 
stimulus level or rate was varied, the sweep-tone ABR consistently elicited a 
larger response than the corresponding click ABR. Moreover, the sweep-tone ABR 
appeared earlier than the click ABR under the same conditions. Specifically, the 
mean wave V peak-to-peak amplitude of the sweep-tone ABR was 1.3 times that of 
the click ABR at 70 dB nHL (normal hearing level) and a rate of 20 s-1, in which 
the former saved 40% of test time.Significance. In summary, the proposed 
sweep-tone approach is found to be more efficient than the traditional click and 
tone-burst in eliciting ABR.

© 2021 Institute of Physics and Engineering in Medicine.

DOI: 10.1088/1361-6579/abcdf2
PMID: 33238252 [Indexed for MEDLINE]


168. Annu Int Conf IEEE Eng Med Biol Soc. 2018 Jul;2018:404-408. doi: 
10.1109/EMBC.2018.8512277.

Improving the performance of hearing aids in noisy environments based on deep 
learning technology.

Lai YH, Zheng WZ, Tang ST, Fang SH, Liao WH, Tsao Y.

The performance of a deep-learning-based speech enhancement (SE) technology for 
hearing aid users, called a deep denoising autoencoder (DDAE), was investigated. 
The hearing-aid speech perception index (HASPI) and the hearing- aid sound 
quality index (HASQI), which are two well-known evaluation metrics for speech 
intelligibility and quality, were used to evaluate the performance of the DDAE 
SE approach in two typical high-frequency hearing loss (HFHL) audiograms. Our 
experimental results show that the DDAE SE approach yields higher 
intelligibility and quality scores than two classical SE approaches. These 
results suggest that a deep-learning-based SE method could be used to improve 
speech intelligibility and quality for hearing aid users in noisy environments.

DOI: 10.1109/EMBC.2018.8512277
PMID: 30440419 [Indexed for MEDLINE]


169. Cochlear Implants Int. 2020 Jan;21(1):1-8. doi: 10.1080/14670100.2019.1661567. 
Epub 2019 Oct 7.

Speech understanding and listening effort in cochlear implant users - microphone 
beamformers lead to significant improvements in noisy environments.

Büchner A(1), Schwebs M(1), Lenarz T(1).

Author information:
(1)Department of Otolaryngology and Cluster of Excellence 'Hearing4all', Medical 
University of Hannover, Hannover, Germany.

Objectives: To evaluate the effect of microphone directionality, i.e. 
beamforming, on speech understanding in noise with the SONNET audio 
processor.Methods: Speech reception thresholds (SRTs) were tested in three 
different microphone settings (omnidirectional, adaptive, and fixed beamformer 
(natural)) and assessed via the Oldenburg Sentence Test and the Just 
Understanding Speech Test. Subjects rated the listening effort needed to 
understand speech in different signal-to-noise ratios (-10, -5, 0, 5, 10, 15 dB 
SNR) via a Visual Analogue Scale. For all test methods, speech was presented at 
0° azimuth while fixed and uncorrelated masking noise was presented 
simultaneously from five loudspeakers positioned at ±70°, ±135°, and 180° 
azimuth.Results: Compared to the omnidirectional mode, significant improvements 
(p<0.001) were shown in mean SRTs for both the natural (3.3 dB SNR) and adaptive 
(5.2 dB SNR) settings. Using the natural or the adaptive setting required 
significantly less listening effort than using the omnidirectional setting for 
the SNR conditions -5 dB SNR (p=0.002) and 0 dB SNR (p<0.001).Discussion: The 
beamformer settings significantly improved speech understanding in noise over 
the omnidirectional setting. Due our multi-speaker test setup, we conclude that 
beamforming should yield significantly better and less stressful speech 
understanding in demanding real-life listening situations.

DOI: 10.1080/14670100.2019.1661567
PMID: 31590612 [Indexed for MEDLINE]


170. J Acoust Soc Am. 2021 Aug;150(2):1067. doi: 10.1121/10.0005820.

A deep neural-network classifier for photograph-based estimation of hearing 
protection attenuation and fit.

Smalt CJ(1), Ciccarelli GA(1), Rodriguez AR(1), Murphy WJ(2).

Author information:
(1)Human Health & Performance Systems Group, MIT Lincoln Laboratory, Lexington, 
Massachusetts 02421, USA.
(2)DFSE/EPHB/Noise & Bioacoustics Team, National Institute for Occupational 
Safety and Health, Cincinnati, Ohio 45226, USA.

Occupational and recreational acoustic noise exposure is known to cause 
permanent hearing damage and reduced quality of life, which indicates the 
importance of noise controls including hearing protection devices (HPDs) in 
situations where high noise levels exist. While HPDs can provide adequate 
protection for many noise exposures, it is often a challenge to properly train 
HPD users and maintain compliance with usage guidelines. HPD fit-testing systems 
are commercially available to ensure proper attenuation is achieved, but they 
often require specific facilities designed for hearing testing (e.g., a quiet 
room or an audiometric booth) or special equipment (e.g., modified HPDs designed 
specifically for fit testing). In this study, we explored using visual 
information from a photograph of an HPD inserted into the ear to estimate 
hearing protector attenuation. Our dataset consists of 960 unique photographs 
from four types of hearing protectors across 160 individuals. We achieved 73% 
classification accuracy in predicting if the fit was greater or less than the 
median measured attenuation (29 dB at 1 kHz) using a deep neural network. 
Ultimately, the fit-test technique developed in this research could be used for 
training as well as for automated compliance monitoring in noisy environments to 
prevent hearing loss.

DOI: 10.1121/10.0005820
PMCID: PMC8689361
PMID: 34470332 [Indexed for MEDLINE]


171. Ear Hear. 2008 Jun;29(3):326-35. doi: 10.1097/AUD.0b013e3181662c42.

Lexical tone recognition with an artificial neural network.

Zhou N(1), Zhang W, Lee CY, Xu L.

Author information:
(1)School of Hearing, Speech and Language Sciences, Ohio University, Athens, 
Ohio 45701, USA.

OBJECTIVES: Tone production is particularly important for communicating in tone 
languages such as Mandarin Chinese. In the present study, an artificial neural 
network was used to recognize tones produced by adult native speakers. The 
purposes of the study were (1) to test the sensitivity of the neural network to 
speaker variation typically in adult speaker groups, (2) to evaluate two 
normalization procedures to overcome the effects of speaker variation, and (3) 
to compare tone recognition performance of the neural network with that of the 
human listeners.
DESIGN: A feedforward multilayer neural network was used. Twenty-nine adult 
native Mandarin Chinese speakers were recruited to record tone samples. The F0 
contours of the vowel part of the 1044 monosyllabic words recorded were 
extracted using an autocorrelation method. Samples from the F0 contours were 
used as inputs to the neural network. The efficacy of the neural network was 
first tested by varying the number of inputs and the number of neurons in the 
hidden layer from 1 to 16. The sensitivity of the neural network to speaker 
variation was tested by (1) using the raw F0 data from speech tokens of a number 
of randomly drawn speakers that varied from 1 to 29, (2) using the raw F0 data 
from speech tokens of either male-only or female-only speakers, and (3) using 
two sets of normalized F0 data (i.e., tone 1-based normalization and first-order 
derivative) from speech tokens from a number of randomly drawn speakers that 
varied from 1 to 29. The recognition performance of the neural network under 
several experimental conditions was compared with the corresponding recognition 
performance of 10 normal-hearing, native Mandarin Chinese speaking adult 
listeners.
RESULTS: Three inputs and four hidden neurons were found to be sufficient for 
the neural network to perform at about 85% correct using speech samples without 
normalization. The performance of the neural network was affected by variation 
across speakers particularly between genders. Using the tone 1-based 
normalization procedure, the performance of the neural network improved 
significantly. The recognition accuracy of the neural network as a whole or for 
each tone was comparable with that of the human listeners.
CONCLUSIONS: The neural network can be used to evaluate the tone production of 
Mandarin Chinese speaking adults with human listener-like recognition accuracy. 
The tone 1-based normalization procedure improves the performance of the neural 
network to human listener-like accuracy. The success of our neural network in 
recognizing tones from multiple speakers supports its utility for evaluating 
tone production. Further testing of the neural network with hearing-impaired 
speakers might reveal its potential use for clinical evaluation of tone 
production.

DOI: 10.1097/AUD.0b013e3181662c42
PMCID: PMC2562432
PMID: 18453884 [Indexed for MEDLINE]


172. Front Public Health. 2022 May 27;10:898355. doi: 10.3389/fpubh.2022.898355. 
eCollection 2022.

Convolutional Neural Network Based Real Time Arabic Speech Recognition to Arabic 
Braille for Hearing and Visually Impaired.

Bhatia S(1), Devi A(2), Alsuwailem RI(1), Mashat A(3).

Author information:
(1)Department of Information Systems, College of Computer Sciences and 
Information Technology, King Faisal University, Al Hasa, Saudi Arabia.
(2)Research Head, AP3 Solutions, Chennai, India.
(3)Faculty of Computing and Information Technology, King Abdulaziz University, 
Rabigh, Saudi Arabia.

Natural Language Processing (NLP) is a group of theoretically inspired computer 
structures for analyzing and modeling clearly going on texts at one or extra 
degrees of linguistic evaluation to acquire human-like language processing for 
quite a few activities and applications. Hearing and visually impaired people 
are unable to see entirely or have very low vision, as well as being unable to 
hear completely or having a hard time hearing. It is difficult to get 
information since both hearing and vision, which are crucial organs for 
receiving information, are harmed. Hearing and visually impaired people are 
considered to have a substantial information deficit, as opposed to people who 
just have one handicap, such as blindness or deafness. Visually and 
hearing-impaired people who are unable to communicate with the outside world may 
experience emotional loneliness, which can lead to stress and, in extreme cases, 
serious mental illness. As a result, overcoming information handicap is a 
critical issue for visually and hearing-impaired people who want to live active, 
independent lives in society. The major objective of this study is to recognize 
Arabic speech in real time and convert it to Arabic text using Convolutional 
Neural Network-based algorithms before saving it to an SD card. The Arabic text 
is then translated into Arabic Braille characters, which are then used to 
control the Braille pattern via a Braille display with a solenoid drive. The 
Braille lettering triggered on the finger was deciphered by visually and hearing 
challenged participants who were proficient in Braille reading. The CNN, in 
combination with the ReLU model learning parameters, is fine-tuned for 
optimization, resulting in a model training accuracy of 90%. The tuned 
parameters model's testing results show that adding the ReLU activation function 
to the CNN model improves recognition accuracy by 84 % when speaking Arabic 
digits.

Copyright © 2022 Bhatia, Devi, Alsuwailem and Mashat.

DOI: 10.3389/fpubh.2022.898355
PMCID: PMC9197259
PMID: 35712297 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


173. J Am Acad Audiol. 2016 Sep;27(8):628-46. doi: 10.3766/jaaa.15062.

Directional Processing and Noise Reduction in Hearing Aids: Individual and 
Situational Influences on Preferred Setting.

Neher T(1)(2), Wagener KC(3)(2), Fischer RL(4).

Author information:
(1)Medizinische Physik, Oldenburg University, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)Hörzentrum Oldenburg GmbH, Oldenburg, Germany.
(4)Sivantos GmbH, Erlangen, Germany.

BACKGROUND: A better understanding of individual differences in hearing aid (HA) 
outcome is a prerequisite for more personalized HA fittings. Currently, 
knowledge of how different user factors relate to response to directional 
processing (DIR) and noise reduction (NR) is sparse.
PURPOSE: To extend a recent study linking preference for DIR and NR to pure-tone 
average hearing thresholds (PTA) and cognitive factors by investigating if (1) 
equivalent links exist for different types of DIR and NR, (2) self-reported 
noise sensitivity and personality can account for additional variability in 
preferred DIR and NR settings, and (3) spatial target speech configuration 
interacts with individual DIR preference.
RESEARCH DESIGN: Using a correlational study design, overall preference for 
different combinations of DIR and NR programmed into a commercial HA was 
assessed in a complex speech-in-noise situation and related to PTA, cognitive 
function, and different personality traits.
STUDY SAMPLE: Sixty experienced HA users aged 60-82 yr with controlled variation 
in PTA and working memory capacity took part in this study. All of them had 
participated in the earlier study, as part of which they were tested on a 
measure of "executive control" tapping into cognitive functions such as working 
memory, mental flexibility, and selective attention.
DATA COLLECTION AND ANALYSIS: Six HA settings based on unilateral 
(within-device) or bilateral (across-device) DIR combined with inactive, 
moderate, or strong single-microphone NR were programmed into a pair of 
behind-the-ear HAs together with individually prescribed amplification. Overall 
preference was assessed using a free-field simulation of a busy cafeteria 
situation with either a single frontal talker or two talkers at ±30° azimuth as 
the target speech. In addition, two questionnaires targeting noise sensitivity 
and the "Big Five" personality traits were administered. Data were analyzed 
using multiple regression analyses and repeated-measures analyses of variance 
with a focus on potential interactions between the HA settings and user factors.
RESULTS: Consistent with the earlier study, preferred HA setting was related to 
PTA and executive control. However, effects were weaker this time. Noise 
sensitivity and personality did not interact with HA settings. As expected, 
spatial target speech configuration influenced preference, with bilateral and 
unilateral DIR "winning" in the single- and two-talker scenario, respectively. 
In general, participants with higher PTA tended to more strongly prefer 
bilateral DIR than participants with lower PTA.
CONCLUSIONS: Although the current study lends some support to the view that PTA 
and cognitive factors affect preferred DIR and NR setting, it also indicates 
that these effects can vary across noise management technologies. To facilitate 
more personalized HA fittings, future research should investigate the source of 
this variability.

American Academy of Audiology.

DOI: 10.3766/jaaa.15062
PMID: 27564441 [Indexed for MEDLINE]


174. Trends Hear. 2021 Jan-Dec;25:2331216521990288. doi: 10.1177/2331216521990288.

Individual Hearing Aid Benefit in Real Life Evaluated Using Ecological Momentary 
Assessment.

von Gablenz P(1), Kowalk U(1), Bitzer J(1), Meis M(2), Holube I(1).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4all," Oldenburg, Germany.
(2)Hörzentrum Oldenburg GmbH, Oldenburg, Germany.

Ecological momentary assessment (EMA) was used in 24 adults with 
mild-to-moderate hearing loss who were seeking first hearing-aid (HA) fitting or 
HA renewal. At two stages in the aural rehabilitation process, just before HA 
fitting and after an average 3-month HA adjustment period, the participants used 
a smartphone-based EMA system for 3 to 4 days. A questionnaire app allowed for 
the description of the environmental context as well as assessments of various 
hearing-related dimensions and of well-being. In total, 2,042 surveys were 
collected. The main objectives of the analysis were threefold: First, describing 
the "auditory reality" of future and experienced HA users; second, examining the 
effects of HA fitting for individual participants, as well as for the subgroup 
of first-time HA-users; and third, reviewing whether the EMA data collected in 
the unaided condition predicted who ultimately decided for or against permanent 
HA use. The participants reported hearing-related disabilities across the full 
range of daily listening tasks, but communication events took the largest share. 
The effect of the HA intervention was small in experienced HA users. Generally, 
much larger changes and larger interindividual differences were observed in 
first-time compared with experienced HA users in all hearing-related dimensions. 
Changes were not correlated with hearing loss or with the duration of the HA 
adjustment period. EMA data collected in the unaided condition did not predict 
the cancelation of HA fitting. The study showed that EMA is feasible in a 
general population of HA candidates for establishing individual and 
multidimensional profiles of real-life hearing experiences.

DOI: 10.1177/2331216521990288
PMCID: PMC8020740
PMID: 33787404 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


175. Int J Audiol. 2021 Nov;60(11):821-830. doi: 10.1080/14992027.2021.1886350. Epub 
2021 Mar 10.

Assessment of hearing screening programmes across 47 countries or regions I: 
provision of newborn hearing screening.

Bussé AML(1), Mackey AR(2), Hoeve HLJ(1), Goedegebure A(1), Carr G(3), Uhlén 
IM(2), Simonsz HJ(1); EUS€REEN Foundation.

Author information:
(1)Department of Otorhinolaryngology and Head, Neck Surgery and Department of 
Ophthalmology, Erasmus University Medical Center, Rotterdam, The Netherlands.
(2)CLINTEC, Karolinska Institutet, Stockholm, Sweden.
(3)Independent consultant in Early Hearing Detection, Intervention and Family 
Centered Practice, London, UK.

OBJECTIVES: Newborn hearing screening (NHS) varies regarding number and type of 
tests, location, age, professionals and funding. We compared the provision of 
existing screening programmes.
DESIGN: A questionnaire containing nine domains: demography, administration, 
existing screening, coverage, tests, diagnosis, treatment, cost and adverse 
effects, was presented to hearing screening experts. Responses were verified. 
Clusters were identified based on number of screening steps and use of OAE or 
aABR, either for all infants or for well and high-risk infants (dual-protocol).
STUDY SAMPLE: Fifty-two experts completed the questionnaire sufficiently: 40 
European countries, Russia, Malawi, Rwanda, India and China.
RESULTS: It took considerable effort to find experts for all countries with 
sufficient time and knowledge. Data essential for evaluation are often not 
collected. Infants are first screened in maternity wards in most countries. 
Human development index and health expenditure were high among countries with 
dual protocols, three screening steps, including aABR, and low among countries 
without NHS and countries using OAE for all infants. Nationwide implementation 
of NHS took 6 years, on average.
CONCLUSION: The extent and complexity of NHS programmes are primarily related to 
health expenditure and HDI. Data collection should be improved to facilitate 
comparison of NHS programmes across borders.

DOI: 10.1080/14992027.2021.1886350
PMID: 33688794 [Indexed for MEDLINE]


176. Acta Otolaryngol. 2016 Oct;136(10):1035-40. doi: 10.1080/00016489.2016.1175662. 
Epub 2016 Apr 28.

The development and evaluation of the Finnish digit triplet test.

Willberg T(1)(2), Buschermöhle M(3)(4), Sivonen V(5), Aarnisalo AA(5), Löppönen 
H(1)(2), Kollmeier B(3)(4)(6), Dietz A(1)(2).

Author information:
(1)a Department of Otorhinolaryngology , Kuopio University Hospital , Kuopio , 
Finland ;
(2)b Institute of Clinical Medicine, University of Eastern Finland , Kuopio , 
Finland ;
(3)c HörTech gGmbH , Oldenburg , Germany ;
(4)d Cluster of Excellence, 'Hearing4all' , Oldenburg , Germany ;
(5)e Department of Otorhinolaryngology , Helsinki University Central Hospital , 
Helsinki , Finland ;
(6)f Department for Medical Physics and Acoustics , Carl Von Ossietzky 
Universität Oldenburg , Oldenburg , Germany.

OBJECTIVES: The aim of the study was to develop a reliable and easily accessible 
screening test for primary detection of hearing impairment.
METHODS: Digits 0-9 were used to form quasirandom digit triplets. First, digit 
specific intelligibility functions and speech recognition thresholds (SRTs) were 
determined. To homogenize the test material digits with steep intelligibility 
function slopes were chosen and level correction up to ±2 dB were applied to the 
digits as needed. Evaluation measurements were performed to check for systematic 
differences in intelligibility between the test lists and to obtain normative 
reference function for normal-hearing listeners.
RESULTS: The mean SRT and the final slope of the test lists were -10.8 ± 0.1 dB 
signal-to-noise ratio (SNR) and 21.7 ± 1.8%/dB, respectively (measurements at 
constant level; inter-list variability). The mean SRT and slope of the test 
subjects were -10.8 ± 0.5 dB SNR and 23.4 ± 5.2%/dB (measurements at constant 
level; inter-subject variability). The mean SRT for normal-hearing young adults 
for a single adaptive measurement is -9.8 ± 0.9 dB SNR.
CONCLUSION: The Finnish digit triplet test is the first self-screening hearing 
test in the Finnish language. It was developed according to current standards, 
and it provides reliable and internationally comparable speech intelligibility 
measurements.

DOI: 10.1080/00016489.2016.1175662
PMID: 27121373 [Indexed for MEDLINE]


177. J Acoust Soc Am. 2021 Apr;149(4):2367. doi: 10.1121/10.0003954.

Analysis of correlation between window duration for kurtosis computation and 
accuracy of noise-induced hearing loss prediction.

Tian Y(1), Ding W(1), Zhang M(2), Zhou T(1), Li J(1), Qiu W(3).

Author information:
(1)Engineering Research Center of EMR and Intelligent Expert System, Ministry of 
Education, College of Biomedical Engineering and Instrument Science, Zhejiang 
University, Hangzhou, China.
(2)Institute of Environmental and Occupational Health, Zhejiang Provincial 
Center for Disease Control and Prevention, Hangzhou, China.
(3)Auditory Research Laboratory, State University of New York at Plattsburgh, 
Plattsburgh, New York 12901, USA.

Kurtosis is considered an important metric for evaluating noise-induced hearing 
loss (NIHL). However, how to select window duration to calculate kurtosis 
remains unsolved. In this study, two algorithms were designed to investigate the 
correlation between window duration for kurtosis computation and the accuracy of 
NIHL prediction using a Chinese industrial database. Pure-tone hearing threshold 
levels (HTLs) and full-shift noise were recorded from each subject. In the 
statistical comparison, subjects were divided into high- and low-kurtosis groups 
based on kurtosis values computed over different window durations. Mann-Whitney 
U test was used to compare the difference in group HTLs to find the optimal 
window duration to best distinguish these two groups. In the support vector 
machine NIHL prediction model, kurtosis obtained from different window durations 
was used as a feature of the model for NIHL evaluation. The area under the curve 
was used to evaluate the performances of models. Fourteen window durations were 
tested for each algorithm. Results showed that 60 s was an optimal window 
duration that allows for both efficient computation and high accuracy for NIHL 
evaluation at test frequencies of 3, 4 and 6 kHz, and the geometric mean of 
kurtosis sequence was the best metric in NIHL evaluation.

DOI: 10.1121/10.0003954
PMID: 33940921 [Indexed for MEDLINE]


178. Sci Rep. 2020 Apr 21;10(1):6704. doi: 10.1038/s41598-020-63515-5.

Data-driven segmentation of audiometric phenotypes across a large clinical 
cohort.

Parthasarathy A(1)(2), Romero Pinto S(3), Lewis RM(3)(4), Goedicke W(3), Polley 
DB(3)(5).

Author information:
(1)Eaton-Peabody Laboratories, Department of Otolaryngology - Head and Neck 
Surgery, Massachusetts Eye and Ear, Boston, MA, 02114, USA. 
Aravindakshan_Parthasarathy@meei.harvard.edu.
(2)Department of Otolaryngology - Head and Neck Surgery, Harvard Medical School, 
Boston, MA, 02114, USA. Aravindakshan_Parthasarathy@meei.harvard.edu.
(3)Eaton-Peabody Laboratories, Department of Otolaryngology - Head and Neck 
Surgery, Massachusetts Eye and Ear, Boston, MA, 02114, USA.
(4)National Military Audiology and Speech Pathology Center, Walter Reed National 
Military Medical Center, Bethesda, MD, 20889, USA.
(5)Department of Otolaryngology - Head and Neck Surgery, Harvard Medical School, 
Boston, MA, 02114, USA.

Pure tone audiograms are used to assess the degree and underlying source of 
hearing loss. Audiograms are typically categorized into a few canonical types, 
each thought to reflect distinct pathologies of the ear. Here, we analyzed 
116,400 patient records from our clinic collected over a 24-year period and 
found that standard categorization left 46% of patient records unclassified. To 
better account for the full spectrum of hearing loss profiles, we used a 
Gaussian Mixture Model (GMM) to segment audiograms without any assumptions about 
frequency relationships, interaural symmetry or etiology. The GMM converged on 
ten types, featuring varying degrees of high-frequency hearing loss, flat loss, 
mixed loss, and notched profiles, with predictable relationships to patient age 
and sex. A separate GMM clustering of 15,380 audiograms from the National Health 
and Nutrition Examination Survey (NHANES) identified six similar types, that 
only lacked the more extreme hearing loss configurations observed in our patient 
cohort. Whereas traditional approaches distill hearing loss configurations down 
to a few canonical types by disregarding much of the underlying variability, an 
objective probabilistic model that accounted for all of the data identified an 
organized, but more heterogenous set of audiogram types that was consistent 
across two large clinical databases.

DOI: 10.1038/s41598-020-63515-5
PMCID: PMC7174357
PMID: 32317648 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


179. Am J Audiol. 2022 Sep 21;31(3S):961-979. doi: 10.1044/2022_AJA-21-00194. Epub 
2022 Jul 25.

Evaluation of Machine Learning Algorithms and Explainability Techniques to 
Detect Hearing Loss From a Speech-in-Noise Screening Test.

Lenatti M(1), Moreno-Sánchez PA(2)(3), Polo EM(4), Mollura M(5), Barbieri R(5), 
Paglialonga A(1).

Author information:
(1)Institute of Electronics, Information Engineering and Telecommunications, 
National Research Council of Italy, Milan.
(2)School of Health Care and Social Work, Seinäjoki University of Applied 
Sciences, Finland.
(3)Faculty of Medicine and Health Technology, Tampere University, Seinäjoki, 
Finland.
(4)Department of Computer, Control, and Management Engineering, Sapienza 
University of Rome, Italy.
(5)Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di 
Milano, Milan, Italy.

PURPOSE: The aim of this study was to analyze the performance of multivariate 
machine learning (ML) models applied to a speech-in-noise hearing screening test 
and investigate the contribution of the measured features toward hearing loss 
detection using explainability techniques.
METHOD: Seven different ML techniques, including transparent (i.e., decision 
tree and logistic regression) and opaque (e.g., random forest) models, were 
trained and evaluated on a data set including 215 tested ears (99 with hearing 
loss of mild degree or higher and 116 with no hearing loss). Post hoc 
explainability techniques were applied to highlight the role of each feature in 
predicting hearing loss.
RESULTS: Random forest (accuracy = .85, sensitivity = .86, specificity = .85, 
precision = .84) performed, on average, better than decision tree (accuracy = 
.82, sensitivity = .84, specificity = .80, precision = .79). Support vector 
machine, logistic regression, and gradient boosting had similar performance as 
random forest. According to post hoc explainability analysis on models generated 
using random forest, the features with the highest relevance in predicting 
hearing loss were age, number and percentage of correct responses, and average 
reaction time, whereas the total test time had the lowest relevance.
CONCLUSIONS: This study demonstrates that a multivariate approach can help 
detect hearing loss with satisfactory performance. Further research on a bigger 
sample and using more complex ML algorithms and explainability techniques is 
needed to fully investigate the role of input features (including additional 
features such as risk factors and individual responses to low-/high-frequency 
stimuli) in predicting hearing loss.

DOI: 10.1044/2022_AJA-21-00194
PMID: 35877954 [Indexed for MEDLINE]


180. Int J Audiol. 2023 Feb;62(2):159-171. doi: 10.1080/14992027.2022.2028022. Epub 
2022 Jan 25.

Evaluation of a semi-supervised self-adjustment fine-tuning procedure for 
hearing aids.

Gößwein JA(1), Rennies J(1), Huber R(1), Bruns T(1), Hildebrandt A(2), Kollmeier 
B(1)(3).

Author information:
(1)Fraunhofer Institute for Digital Media Technology (IDMT), Oldenburg Branch 
for Hearing, Speech and Audio Technology (HSA) and Cluster of Excellence 
"Hearing4all", Oldenburg, Germany.
(2)Department of Psychology, Carl von Ossietzky University of Oldenburg, and 
Cluster of Excellence "Hearing4all", Oldenburg, Germany.
(3)Department of Medical Physics and Acoustics, Carl von Ossietzky University of 
Oldenburg, Oldenburg, Germany.

OBJECTIVE: This study investigated the effects of different adjustment criteria 
and sound scenes on self-adjusted hearing-aid gain settings. Self-adjusted 
settings were evaluated for speech recognition in noise, perceived listening 
effort, and preference.
DESIGN: This study evaluated a semi-supervised self-adjustment fine-tuning 
procedure that presents realistic everyday sound scenes in a laboratory 
environment, using a two-dimensional user interface, and enabling simultaneous 
changes in amplitude and spectral slope. While exploring the two-dimensional 
space of parameter settings, the hearing-aid users were instructed to optimise 
either listening comfort or speech understanding.
STUDY SAMPLE: Twenty experienced hearing aid users (median age 69.5 years) were 
invited to participate in this study.
RESULTS: Adjustment criterion and sound scenes had a significant effect on 
preferred gain settings. No differences in signal-to-noise ratios required for 
50% speech intelligibility or in the perceived listening effort were observed 
between the adjusted settings of the two adjustment criteria. There was a 
preference for the self-adjusted settings over the prescriptive first fit.
CONCLUSIONS: Listeners could reliably select their preferred gains to the two 
adjustment criteria and for different speech stimuli.

DOI: 10.1080/14992027.2022.2028022
PMID: 35076330 [Indexed for MEDLINE]


181. Trends Hear. 2016 Oct 3;20:2331216516667734. doi: 10.1177/2331216516667734.

Subjective Listening Effort and Electrodermal Activity in Listening Situations 
with Reverberation and Noise.

Holube I(1), Haeder K(2), Imbery C(2), Weber R(3).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany Cluster of Excellence "Hearing4All", Oldenburg, 
Germany inga.holube@jade-hs.de.
(2)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.
(3)Department of Medical Physics and Acoustics, University of Oldenburg, 
Oldenburg, Germany.

Disturbing factors like reverberation or ambient noise can impair speech 
recognition and raise the listening effort needed for successful communication 
in daily life. Situations with high listening effort are thought to result in 
increased stress for the listener. The aim of this study was to explore possible 
measures to determine listening effort in situations with varying background 
noise and reverberation. For this purpose, subjective ratings of listening 
effort, speech recognition, and stress level, together with the electrodermal 
activity as a measure of the autonomic stress reaction, were investigated. It 
was expected that the electrodermal activity would show different stress levels 
in different acoustic situations and might serve as an alternative to subjective 
ratings. Ten young normal-hearing and 17 elderly hearing-impaired subjects 
listened to sentences from the Oldenburg sentence test either with stationary 
background noise or with reverberation. Four listening situations were 
generated, an easy and a hard one for each of the two disturbing factors, which 
were related to each other by the Speech Transmission Index. The easy situation 
resulted in 100% and the hard situation resulted in 30 to 80% speech 
recognition. The results of the subjective ratings showed significant 
differences between the easy and the hard listening situations in both subject 
groups. Two methods of analyzing the electrodermal activity values revealed 
similar, but nonsignificant trends. Significant correlations between subjective 
ratings and physiological electrodermal activity data were observed for 
normal-hearing subjects in the noise situation.

© The Author(s) 2016.

DOI: 10.1177/2331216516667734
PMCID: PMC5051672
PMID: 27698257 [Indexed for MEDLINE]


182. Int J Audiol. 2021 Apr;60(4):263-273. doi: 10.1080/14992027.2020.1821252. Epub 
2020 Sep 22.

Maximising the ability of stimulus-frequency otoacoustic emissions to predict 
hearing status and thresholds using machine-learning models.

Liu Y(1), Xu R(1), Gong Q(1)(2).

Author information:
(1)Department of Biomedical Engineering, School of Medicine, Tsinghua 
University, Beijing, China.
(2)School of Medicine, Shanghai University, Shanghai, China.

OBJECTIVE: This study aimed to maximise the ability of stimulus-frequency 
otoacoustic emissions (SFOAEs) to predict hearing status and thresholds based on 
machine-learning models.
DESIGN: SFOAE data and audiometric thresholds were collected at octave 
frequencies from 0.5 to 8 kHz. Support vector machine, k-nearest neighbour, back 
propagation neural network, decision tree, and random forest algorithms were 
used to build classification models for status identification and to develop 
regression models for threshold prediction.
STUDY SAMPLE: About 230 ears with normal hearing and 737 ears with sensorineural 
hearing loss.
RESULTS: All classification models yielded areas under the receiver operating 
characteristic curve of 0.926-0.994 at 0.5-8 kHz, superior to the previous SFOAE 
study. The regression models produced lower standard errors (8.1-12.2 dB, mean 
absolute errors: 5.53-8.97 dB) as compared to those for distortion-product and 
transient-evoked otoacoustic emissions previously reported (8.6-19.2 dB).
CONCLUSIONS: SFOAEs using machine-learning approaches offer promising tools for 
the prediction of hearing capabilities, at least at 0.5-4 kHz. Future research 
may focus on further improvements in accuracy and reductions in test time to 
improve clinical utility.

DOI: 10.1080/14992027.2020.1821252
PMID: 32959697 [Indexed for MEDLINE]


183. Acta Otolaryngol. 2020 Mar;140(3):230-235. doi: 10.1080/00016489.2019.1704865. 
Epub 2020 Jan 31.

Transient-evoked otoacoustic emission signals predicting outcomes of acute 
sensorineural hearing loss in patients with Ménière's disease.

Liu YW(1), Kao SL(1), Wu HT(2), Liu TC(1), Fang TY(3)(4), Wang PC(3)(4).

Author information:
(1)Department of Electrical Engineering, National Tsing Hua University, Hsinchu, 
Taiwan.
(2)Department of Mathematics and Department of Statistical Science, Duke 
University, Durham, NC, USA.
(3)Department of Otolaryngology, Cathay General Hospital, Taipei, Taiwan.
(4)School of Medicine, Fu Jen Catholic University, Taipei, Taiwan.

Background: Fluctuating hearing loss is characteristic of Ménière's disease (MD) 
during acute episodes. However, no reliable audiometric hallmarks are available 
for counselling the hearing recovery possibility.Aims/objectives: To find 
parameters for predicting MD hearing outcomes.Material and methods: We applied 
machine learning techniques to analyse transient-evoked otoacoustic emission 
(TEOAE) signals recorded from patients with MD. Thirty unilateral MD patients 
were recruited prospectively after onset of acute cochleo-vestibular symptoms. 
Serial TEOAE and pure-tone audiogram (PTA) data were recorded longitudinally. 
Denoised TEOAE signals were projected onto the three most prominent principal 
directions through a linear transformation. Binary classification was performed 
using a support vector machine (SVM). TEOAE signal parameters, including signal 
energy and group delay, were compared between improved (PTA improvement: ≥15 dB) 
and nonimproved groups using Welch's t-test.Results: Signal energy did not 
differ (p = .64) but a significant difference in 1-kHz (p = .045) group delay 
was recorded between improved and nonimproved groups. The SVM achieved a 
cross-validated accuracy of >80% in predicting hearing outcomes.Conclusions and 
significance: This study revealed that baseline TEOAE parameters obtained during 
acute MD episodes, when processed through machine learning technology, may 
provide information on outer hair cell function to predict hearing recovery.

DOI: 10.1080/00016489.2019.1704865
PMID: 32003266 [Indexed for MEDLINE]


184. J Acoust Soc Am. 2020 Jul;148(1):389. doi: 10.1121/10.0001600.

Efficient two-microphone speech enhancement using basic recurrent neural network 
cell for hearing and hearing aids.

Shankar N(1), Bhat GS(1), Panahi IMS(1).

Author information:
(1)Department of Electrical and Computer Engineering, The University of Texas at 
Dallas, Richardson, Texas 75080, USA.

This work presents a two-microphone speech enhancement (SE) framework based on 
basic recurrent neural network (RNN) cell. The proposed method operates in 
real-time, improving the speech quality and intelligibility in noisy 
environments. The RNN model trained using a simple feature set-real and 
imaginary parts of the short-time Fourier transform (STFT) are computationally 
efficient with a minimal input-output processing delay. The proposed algorithm 
can be used in any stand-alone platform such as a smartphone using its two 
inbuilt microphones. The detailed operation of the real-time implementation on 
the smartphone is presented. The developed application works as an assistive 
tool for hearing aid devices (HADs). Speech quality and intelligibility test 
results are used to compare the proposed algorithm to existing conventional and 
neural network-based SE methods. Subjective and objective scores show the 
superior performance of the developed method over several conventional methods 
in different noise conditions and low signal to noise ratios (SNRs).

DOI: 10.1121/10.0001600
PMCID: PMC7928060
PMID: 32752751 [Indexed for MEDLINE]


185. PLoS One. 2022 Feb 8;17(2):e0263516. doi: 10.1371/journal.pone.0263516. 
eCollection 2022.

Sound source localization patterns and bilateral cochlear implants: Age at onset 
of deafness effects.

Anderson SR(1), Jocewicz R(2), Kan A(3), Zhu J(4), Tzeng S(5), Litovsky RY(1).

Author information:
(1)Waisman Center, University of Wisconsin-Madison, Madison, Wisconsin, United 
States of America.
(2)Department of Audiology, Stanford University, Stanford, California, United 
States of America.
(3)School of Engineering, Macquarie University, New South Wales, Australia.
(4)Department of Statistics, University of Wisconsin-Madison, Madison, 
Wisconsin, United States of America.
(5)Department of Mathematics, National Sun Yat-sen University, Kaohsiung, 
Taiwan.

The ability to determine a sound's location is critical in everyday life. 
However, sound source localization is severely compromised for patients with 
hearing loss who receive bilateral cochlear implants (BiCIs). Several patient 
factors relate to poorer performance in listeners with BiCIs, associated with 
auditory deprivation, experience, and age. Critically, characteristic errors are 
made by patients with BiCIs (e.g., medial responses at lateral target 
locations), and the relationship between patient factors and the type of errors 
made by patients has seldom been investigated across individuals. In the present 
study, several different types of analysis were used to understand localization 
errors and their relationship with patient-dependent factors (selected based on 
their robustness of prediction). Binaural hearing experience is required for 
developing accurate localization skills, auditory deprivation is associated with 
degradation of the auditory periphery, and aging leads to poorer temporal 
resolution. Therefore, it was hypothesized that earlier onsets of deafness would 
be associated with poorer localization acuity and longer periods without BiCI 
stimulation or older age would lead to greater amounts of variability in 
localization responses. A novel machine learning approach was introduced to 
characterize the types of errors made by listeners with BiCIs, making them 
simple to interpret and generalizable to everyday experience. Sound localization 
performance was measured in 48 listeners with BiCIs using pink noise trains 
presented in free-field. Our results suggest that older age at testing and 
earlier onset of deafness are associated with greater average error, 
particularly for sound sources near the center of the head, consistent with 
previous research. The machine learning analysis revealed that variability of 
localization responses tended to be greater for individuals with earlier 
compared to later onsets of deafness. These results suggest that early bilateral 
hearing is essential for best sound source localization outcomes in listeners 
with BiCIs.

DOI: 10.1371/journal.pone.0263516
PMCID: PMC8824335
PMID: 35134072 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


186. Int J Audiol. 2018 Jun;57(sup3):S139-S145. doi: 10.1080/14992027.2016.1257163. 
Epub 2016 Nov 22.

Hearing aid fitting and fine-tuning based on estimated individual traits.

Völker C(1)(2), Ernst SMA(1)(2), Kollmeier B(1)(2).

Author information:
(1)a Abteilung Medizinische Physik , Carl von Ossietzky Universität Oldenburg , 
Oldenburg , Germany and.
(2)b Cluster of Excellence 'Hearing4all' , Oldenburg , Germany.

OBJECTIVE: A generalised concept for hearing aid fitting and fine-tuning based 
on estimated individual traits is presented along first implementations in this 
report.
DESIGN: To estimate the individual traits, a set of auditory model-based 
performance measures is used to generate promising candidates within the 
algorithm's parameter space for a subsequent subjective rating. For the 
subjective assessment, a fast and intuitive multi-stimulus test denoted as 
combined discrimination and classification (CoDiCl) is presented to capture user 
preferences for an optimised setting.
STUDY SAMPLE: The estimation of individual traits is shown in an exemplary 
manner for a multidimensional coherence-based noise reduction algorithm. The 
dimensionality reduction was performed using differently weighted combinations 
of speech intelligibility index (SII) and perceived similarity measure (PSM).
RESULTS: Nine reasonable alternative algorithm setting candidates were extracted 
from a model-optimised exploration path (MOEP) for a subsequent subjective 
rating to potentially differentiate between listeners with different attitudes 
towards noise suppression and introduced distortions (i.e. "noise haters" and 
"distortion haters").
CONCLUSIONS: By iteratively improving the agreement between subjective and 
objective assessment, an objective estimation of subjective traits using 
appropriate weightings of objective measures may become possible. This will 
potentially help to efficiently fit modern multidimensional hearing aid 
algorithms to the individual user.

DOI: 10.1080/14992027.2016.1257163
PMID: 27873543 [Indexed for MEDLINE]


187. Ear Hear. 2019 Jan/Feb;40(1):204-212. doi: 10.1097/AUD.0000000000000599.

Prevalence of Hearing Impairment in Mahabubnagar District, Telangana State, 
India.

Bright T(1), Mactaggart I(1), Kuper H(1), Murthy GV(1)(2), Polack S(1).

Author information:
(1)International Centre for Evidence in Disability, London School of Hygiene & 
Tropical Medicine, London, United Kingdom.
(2)South Asia Centre for Disability Inclusive Development and Research, Indian 
Institute of Public Health Hyderabad, Public Health Foundation of India, 
Hyderabad, India.

OBJECTIVES: To estimate the prevalence of hearing impairment in Mahabubnagar 
district, Telangana state, India.
METHODS: A population-based prevalence survey of hearing impairment was 
undertaken in 2014. Fifty-one clusters of 80 people aged 6 months and older were 
selected using probability-proportionate-to-size sampling. A two-stage hearing 
screening was conducted using otoacoustic emissions on all participants followed 
by pure-tone audiometry on those aged 4 years and older who failed otoacoustic 
emissions. Cases of hearing impairment were defined using the World Health 
Organization definition of disabling hearing impairment: a pure-tone average of 
thresholds at 500, 1000, 2000, and 4000 Hz of ≥41 dB HL for adults and ≥31 dB HL 
for children based on the better ear. Possible causes of hearing impairment were 
ascertained by a certified audiologist. Reported hearing difficulties were also 
measured in this survey and compared with audiometry results.
RESULTS: Three thousand five hundred seventy-three people were examined 
(response rate 87%), of whom 52% were female. The prevalence of disabling 
hearing impairment was 4.5% [95% confidence interval (CI) = 3.8 to 5.3). 
Disabling hearing impairment prevalence increased with age from 0.4% in those 
aged 4 to 17 years (95% CI = 0.2 to 1.1) to 34.7% (95% CI = 28.7 to 41.1) in 
those aged older than 65 years. No difference in prevalence was seen by sex. Ear 
examination suggested that the possible cause of disabling hearing impairment 
was chronic suppurative otitis media for 6.9% of cases and dry perforation for 
5.6% cases. For the vast majority of people with disabling hearing impairment, a 
possible cause could not be established. The overall prevalence of reported or 
proxy reported hearing impairment was 2.6% (95% CI = 2.0 to 3.4), and this 
ranged from 0.6% (95% CI = 0.08 to 4.4) in those aged 0 to 3 years to 14.4% (95% 
CI = 9.8 to 20.7) in those aged older than 65 years.
CONCLUSIONS: Disabling hearing impairment in Telangana State is common, 
affecting approximately 1 in 23 people overall and a third of people aged older 
than 65 years. These findings suggest that there are a substantial number of 
individuals with hearing impairment who could potentially benefit from improved 
access to low-cost interventions.

DOI: 10.1097/AUD.0000000000000599
PMID: 29782444 [Indexed for MEDLINE]


188. Hear Res. 2024 Apr;445:108989. doi: 10.1016/j.heares.2024.108989. Epub 2024 Mar 
11.

The crucial role of diverse animal models to investigate cochlear aging and 
hearing loss.

Castaño-González K(1), Köppl C(2), Pyott SJ(3).

Author information:
(1)Department of Otorhinolaryngology, Head & Neck Surgery, University Medical 
Center Groningen; The Research School of Behavioural and Cognitive 
Neurosciences, University of Groningen, Groningen, The Netherlands.
(2)Cluster of Excellence "Hearing4All", Department of Neuroscience, School of 
Medicine and Health Sciences, Carl von Ossietzky Universität; Research Center 
Neurosensory Science, Carl von Ossietzky Universität, Oldenburg, Germany.
(3)Department of Otorhinolaryngology, Head & Neck Surgery, University Medical 
Center Groningen; The Research School of Behavioural and Cognitive 
Neurosciences, University of Groningen, Groningen, The Netherlands. Electronic 
address: s.pyott@umcg.nl.

Age-related hearing loss affects a large and growing segment of the population, 
with profound impacts on quality of life. Age-related pathology of the 
cochlea-the mammalian hearing organ-underlies age-related hearing loss. Because 
investigating age-related changes in the cochlea in humans is challenging and 
often impossible, animal models are indispensable to investigate these 
mechanisms as well as the complex consequences of age-related hearing loss on 
the brain and behavior. In this review, we advocate for a comparative and 
interdisciplinary approach while also addressing the challenges of comparing 
age-related hearing loss across species with varying lifespans. We describe the 
experimental advantages and limitations as well as areas for future research in 
well-established models of age-related hearing loss, including mice, rats, 
gerbils, chinchillas, and birds. We also indicate the need to expand 
characterization of age-related hearing loss in other established animal models, 
especially guinea pigs, cats, and non-human primates, in which auditory function 
is well characterized but age-related cochlear pathology is understudied. 
Finally, we highlight the potential of emerging animal models for advancing our 
understanding of age-related hearing loss, including deer mice, with their 
notably extended lifespans and preserved hearing, naked mole rats, with their 
exceptional longevity and extensive vocal communications, as well as zebrafish, 
which offer genetic tractability and suitability for drug screening. Ultimately, 
a comparative and interdisciplinary approach in auditory research, combining 
insights from various animal models with human studies, is key to robust and 
reliable research outcomes that better advance our understanding and treatment 
of age-related hearing loss.

Copyright © 2024 The Author(s). Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2024.108989
PMID: 38518394 [Indexed for MEDLINE]


189. Int J Audiol. 2018 Jun;57(sup3):S43-S54. doi: 10.1080/14992027.2017.1300695. 
Epub 2017 Mar 30.

Evaluation of combined dynamic compression and single channel noise reduction 
for hearing aid applications.

Kortlang S(1), Chen Z(1), Gerkmann T(2), Kollmeier B(1), Hohmann V(1), Ewert 
SD(1).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , Universität 
Oldenburg , Oldenburg , Germany and.
(2)b Speech Signal Processing and Cluster of Excellence Hearing4all , 
Universität Oldenburg , Oldenburg , Germany.

OBJECTIVE: Single-channel noise reduction (SCNR) and dynamic range compression 
(DRC) are important elements in hearing aids. Only relatively few studies have 
addressed interaction effects and typically used real hearing aids with limited 
knowledge about the integrated algorithms. Here the potential benefit of 
different combinations and integration of SCNR and DRC was systematically 
assessed.
DESIGN: Ten different systems combining SCNR and DRC were implemented, including 
five serial arrangements, a parallel and two multiplicative approaches. In an 
instrumental evaluation, signal-to-noise ratio (SNR) improvement and spectral 
contrast enhancement (SCE) were assessed. Quality ratings at 0 and +6 dB SNR, 
and speech reception thresholds (SRTs) in noise were measured using stationary 
and babble noise.
STUDY SAMPLE: Thirteen young normal-hearing (NH) listeners and 12 
hearing-impaired (HI) listeners participated.
RESULTS: In line with an increased segmental SNR and spectral contrast compared 
to a serial concatenation, the parallel approach significantly reduced the 
perceived noise annoyance for both subject groups. The proposed multiplicative 
approaches could partly counteract increased speech distortions introduced by 
DRC and achieved the best overall quality for the HI listeners.
CONCLUSIONS: For high SNRs well above the individual SRT, the specific 
combination of SCNR and DRC is perceptually relevant and the integrative 
approaches were preferred.

DOI: 10.1080/14992027.2017.1300695
PMID: 28355947 [Indexed for MEDLINE]


190. Ear Hear. 2024 Mar-Apr 01;45(2):465-475. doi: 10.1097/AUD.0000000000001443. Epub 
2023 Nov 22.

Deep Learning Models for Predicting Hearing Thresholds Based on Swept-Tone 
Stimulus-Frequency Otoacoustic Emissions.

Liu Y(1), Gong Q(1)(2).

Author information:
(1)Department of Biomedical Engineering, School of Medicine, Tsinghua 
University, Beijing, China.
(2)School of Medicine, Shanghai University, Shanghai, China.

OBJECTIVES: This study aims to develop deep learning (DL) models for the 
quantitative prediction of hearing thresholds based on stimulus-frequency 
otoacoustic emissions (SFOAEs) evoked by swept tones.
DESIGN: A total of 174 ears with normal hearing and 388 ears with sensorineural 
hearing loss were studied. SFOAEs in the 0.3 to 4.3 kHz frequency range were 
recorded using linearly swept tones at a rate of 2 Hz/msec, with stimulus level 
changing from 40 to 60 dB SPL in 10 dB steps. Four DL models were used to 
predict hearing thresholds at octave frequencies from 0.5 to 4 kHz. The models-a 
conventional convolutional neural network (CNN), a hybrid CNN-k-nearest neighbor 
(KNN), a hybrid CNN-support vector machine (SVM), and a hybrid CNN-random forest 
(RF)-were individually built for each frequency. The input to the DL models was 
the measured raw SFOAE amplitude spectra and their corresponding signal to noise 
ratio spectra. All DL models shared a CNN-based feature self-extractor. They 
differed in that the conventional CNN utilized a fully connected layer to make 
the final regression decision, whereas the hybrid CNN-KNN, CNN-SVM, and CNN-RF 
models were designed by replacing the last fully connected layer of CNN model 
with a traditional machine learning (ML) regressor, that is, KNN, SVM, and RF, 
respectively. The model performance was evaluated using mean absolute error and 
SE averaged over 20 repetitions of 5 × 5 fold nested cross-validation. The 
performance of the proposed DL models was compared with two types of traditional 
ML models.
RESULTS: The proposed SFOAE-based DL models resulted in an optimal mean absolute 
error of 5.98, 5.22, 5.51, and 6.06 dB at 0.5, 1, 2, and 4 kHz, respectively, 
superior to that obtained by the traditional ML models. The produced SEs were 
8.55, 7.27, 7.58, and 7.95 dB at 0.5, 1, 2, and 4 kHz, respectively. All the DL 
models outperformed any of the traditional ML models.
CONCLUSIONS: The proposed swept-tone SFOAE-based DL models were capable of 
quantitatively predicting hearing thresholds with satisfactory performance. With 
DL techniques, the underlying relationship between SFOAEs and hearing thresholds 
at disparate frequencies was explored and captured, potentially improving the 
diagnostic value of SFOAEs.

Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000001443
PMID: 37990395 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


191. Neuropsychologia. 2016 Jul 1;87:169-181. doi: 
10.1016/j.neuropsychologia.2016.05.019. Epub 2016 May 19.

On the relationship between auditory cognition and speech intelligibility in 
cochlear implant users: An ERP study.

Finke M(1), Büchner A(2), Ruigendijk E(3), Meyer M(4), Sandmann P(5).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Germany; Cluster of 
Excellence "Hearing4all", Germany. Electronic address: 
Finke.Mareike@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Germany; Cluster of 
Excellence "Hearing4all", Germany.
(3)Cluster of Excellence "Hearing4all", Germany; Department of Dutch, University 
of Oldenburg, Germany.
(4)Neuroplasticity and Learning in the Healthy Aging Brain, Psychological 
Institute, University of Zurich, Switzerland; Cognitive Psychology Unit (CPU), 
University of Klagenfurt, Austria.
(5)Cluster of Excellence "Hearing4all", Germany; Department of Neurology, 
Hannover Medical School, Germany; Department of Otorhinolaryngology, University 
of Cologne, Germany.

There is a high degree of variability in speech intelligibility outcomes across 
cochlear-implant (CI) users. To better understand how auditory cognition affects 
speech intelligibility with the CI, we performed an electroencephalography study 
in which we examined the relationship between central auditory processing, 
cognitive abilities, and speech intelligibility. Postlingually deafened CI users 
(N=13) and matched normal-hearing (NH) listeners (N=13) performed an oddball 
task with words presented in different background conditions (quiet, stationary 
noise, modulated noise). Participants had to categorize words as living 
(targets) or non-living entities (standards). We also assessed participants' 
working memory (WM) capacity and verbal abilities. For the oddball task, we 
found lower hit rates and prolonged response times in CI users when compared 
with NH listeners. Noise-related prolongation of the N1 amplitude was found for 
all participants. Further, we observed group-specific modulation effects of 
event-related potentials (ERPs) as a function of background noise. While NH 
listeners showed stronger noise-related modulation of the N1 latency, CI users 
revealed enhanced modulation effects of the N2/N4 latency. In general, 
higher-order processing (N2/N4, P3) was prolonged in CI users in all background 
conditions when compared with NH listeners. Longer N2/N4 latency in CI users 
suggests that these individuals have difficulties to map acoustic-phonetic 
features to lexical representations. These difficulties seem to be increased for 
speech-in-noise conditions when compared with speech in quiet background. 
Correlation analyses showed that shorter ERP latencies were related to enhanced 
speech intelligibility (N1, N2/N4), better lexical fluency (N1), and lower 
ratings of listening effort (N2/N4) in CI users. In sum, our findings suggest 
that CI users and NH listeners differ with regards to both the sensory and the 
higher-order processing of speech in quiet as well as in noisy background 
conditions. Our results also revealed that verbal abilities are related to 
speech processing and speech intelligibility in CI users, confirming the view 
that auditory cognition plays an important role for CI outcome. We conclude that 
differences in auditory-cognitive processing contribute to the variability in 
speech performance outcomes observed in CI users.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2016.05.019
PMID: 27212057 [Indexed for MEDLINE]


192. Hear Res. 2019 Feb;372:80-87. doi: 10.1016/j.heares.2017.10.010. Epub 2017 Oct 
31.

The Optimal inter-implant interval in pediatric sequential bilateral 
implantation.

Illg A(1), Sandner C(2), Büchner A(3), Lenarz T(2), Kral A(2), Lesinski-Schiedat 
A(2).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany. Electronic address: illg@hoerzentrum-hannover.de.
(2)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(3)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence, Hearing4All, Hannover Medical School, Hannover, 
Germany.

An increasing number of children receive bilateral cochlear implants (CIs) 
sequentially. Outcomes of bilateral implantation show high variability. This 
retrospective analysis investigates the optimal inter-implant interval. For this 
purpose, speech comprehension results of 250 children who underwent sequential 
bilateral cochlear implantation were evaluated. All individuals underwent 
periodic speech perception testing in quiet and noise. The most recent 
unilateral data for each side were statistically analyzed. Speech test outcomes 
were evaluated with reference to age at first implantation and interval between 
implantations. A statistically significant difference for speech test 
performance was obtained between the first-implanted ear and the 
second-implanted ear for all children (expressed as a mean). These outcomes were 
dependent on the inter-implant interval. There was a significant correlation 
(r = - 0.497; p = 0.000) between speech test results and the inter-implant 
interval. Nevertheless, one subgroup of 27 children had the same or better 
results for the second side as compared with the first. In conclusion, the 
evaluation of the inter-implant interval and age groups at first implantation 
showed a preferred interval of up to four years in children under the age of 
4 at first implantation. The older the children were at first implantation, the 
shorter the inter-implant interval had to be. It is as a direct consequence of 
this interval that children for whom it was longer were also older.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.10.010
PMID: 29133013 [Indexed for MEDLINE]


193. Am J Audiol. 2019 Jun 10;28(2):315-321. doi: 10.1044/2019_AJA-18-0127. Epub 2019 
May 14.

Recovery From Sudden Sensorineural Hearing Loss May Be Linked to Chronic Stress 
Levels and Steroid Treatment Resistance.

Ajduk J(1), Košec A(2), Kelava I(2), Ries M(1), Gregurić T(3), Kalogjera L(1).

Author information:
(1)School of Medicine, University of Zagreb, Croatia.
(2)Department of Otorhinolaryngology and Head and Neck Surgery, University 
Hospital Center Sestre milosrdnice, Zagreb, Croatia.
(3)Department of Radiology, University Hospital Center Sestre milosrdnice, 
Zagreb, Croatia.

Purpose This article investigates the possible connections between the level of 
chronic stress and success of steroid therapy in patients with sudden 
sensorineural hearing loss (SSNHL). Method A single-center, retrospective, 
longitudinal cohort study on 55 patients in a tertiary referral otology center 
was examined. Patients diagnosed with SSNHL between 2014 and 2017 were asked to 
complete a Measure of Perceived Stress (Brajac, Tkalcic, Dragojević, & Gruber, 
2003 ) questionnaire. Inclusion criteria were patients > 18 years of age, SSNHL 
diagnosed within 4 previous weeks, completed steroid treatment, and complete 
documentation. Results There were 30 patients (55%) that showed significant 
improvement in their pure-tone audiogram (PTA) hearing threshold average (≥ 15 
dB) after steroid treatment. Two-step cluster analysis identified 3 clusters 
based on average PTA hearing threshold recovery and average Measure of Perceived 
Stress scores. The difference between pretreatment and posttreatment hearing 
levels was significantly higher in the cluster with moderate stress compared to 
clusters with mild and high stress levels (Kruskal-Wallis test, Friedman test, p 
< .001). There were no significant differences in average PTA hearing threshold 
recovery after steroid therapy between groups of patients with mild and severe 
stress. Conclusion Patients with moderate stress levels show significantly 
better results after steroid treatment for SSNHL than patients with low or high 
stress levels.

DOI: 10.1044/2019_AJA-18-0127
PMID: 31084569 [Indexed for MEDLINE]


194. Int J Audiol. 2021 Nov;60(11):917-926. doi: 10.1080/14992027.2021.1931487. Epub 
2021 Jun 13.

Hearing aid acquisition and ownership: what can we learn from online consumer 
reviews?

Bennett RJ(1)(2), Swanepoel W(1)(2)(3), Ratinaud P(4), Bailey A(5), Pennebaker 
JW(6), Manchaiah V(7)(8).

Author information:
(1)Ear Science Institute Australia, Subiaco, Australia.
(2)Ear Sciences Centre, School of Surgery, The University of Western Australia, 
Nedlands, Australia.
(3)Department of Speech-Language Pathology and Audiology, University of 
Pretoria, Gauteng, South Africa.
(4)LERASS Laboratory, University of Toulouse, Toulouse, France.
(5)Hearing Tracker Inc., Austin, TX, USA.
(6)Department of Psychology, University of Texas at Austin, Austin, TX, USA.
(7)Department of Speech and Hearing Sciences, Lamar University, Beaumont, TX, 
USA.
(8)Department of Speech and Hearing, School of Allied Health Sciences, Manipal 
University, Manipal, India.

OBJECTIVE: To explore the publicised opinions of consumers actively 
participating in online hearing aid reviews.
DESIGN: A retrospective design examining data generated from an online consumer 
review website (www.HearingTracker.com). Qualitative data (open text responses) 
were analysed using the open source automated topic modelling software IRaMuTeQ 
(http://www.iramuteq.org/) to identify themes. Outputs were compared with 
quantitative data from the consumer reviews (short response questions exploring 
hearing aid performance and benefit, and some meta-data such as hearing aid 
brand and years of hearing aid ownership).
STUDY SAMPLE: 1378 online consumer hearing aid reviews.
RESULTS: Six clusters within two domains were identified. The domain Device 
Acquisition included three clusters: Finding the right provider, device and 
price-point; Selecting a hearing aid to suit the hearing loss; Attaining 
physical fit and device management skills. The domain Device Use included three 
clusters: Smartphone streaming to hearing aids; Hearing aid adjustment using 
smartphone; and Hearing in noise.
CONCLUSIONS: Although online hearing aid consumers indicate positive performance 
on multiple-choice questions relating to hearing aid performance and benefit, 
their online reviews describe a number of barriers limiting their success. 
Hearing healthcare clinicians must employ a personalised approach to 
audiological rehabilitation to ensure individual clients' needs are met.

DOI: 10.1080/14992027.2021.1931487
PMID: 34120557 [Indexed for MEDLINE]


195. Trends Hear. 2021 Jan-Dec;25:23312165211041475. doi: 10.1177/23312165211041475.

Transient Noise Reduction Using a Deep Recurrent Neural Network: Effects on 
Subjective Speech Intelligibility and Listening Comfort.

Keshavarzi M(1)(2)(3), Reichenbach T(1)(4), Moore BCJ(3).

Author information:
(1)Department of Bioengineering and Centre for Neurotechnology, 4615Imperial 
College London, London, UK.
(2)Centre for Neuroscience in Education, Department of Psychology, 
2152University of Cambridge, Cambridge, UK.
(3)Cambridge Hearing Group, Department of Psychology, 2152University of 
Cambridge, Cambridge, UK.
(4)Department Artificial Intelligence in Biomedical Engineering, 
Friedrich-Alexander-University Erlangen- Nuremberg, Erlangen, Germany.

A deep recurrent neural network (RNN) for reducing transient sounds was 
developed and its effects on subjective speech intelligibility and listening 
comfort were investigated. The RNN was trained using sentences spoken with 
different accents and corrupted by transient sounds, using the clean speech as 
the target. It was tested using sentences spoken by unseen talkers and corrupted 
by unseen transient sounds. A paired-comparison procedure was used to compare 
all possible combinations of three conditions for subjective speech 
intelligibility and listening comfort for two relative levels of the transients. 
The conditions were: no processing (NP); processing using the RNN; and 
processing using a multi-channel transient reduction method (MCTR). Ten 
participants with normal hearing and ten with mild-to-moderate hearing loss 
participated. For the latter, frequency-dependent linear amplification was 
applied to all stimuli to compensate for individual audibility losses. For the 
normal-hearing participants, processing using the RNN was significantly 
preferred over that for NP for subjective intelligibility and comfort, 
processing using the RNN was significantly preferred over that for MCTR for 
subjective intelligibility, and processing using the MCTR was significantly 
preferred over that for NP for comfort for the higher transient level only. For 
the hearing-impaired participants, processing using the RNN was significantly 
preferred over that for NP for both subjective intelligibility and comfort, 
processing using the RNN was significantly preferred over that for MCTR for 
comfort, and processing using the MCTR was significantly preferred over that for 
NP for comfort.

DOI: 10.1177/23312165211041475
PMCID: PMC8642050
PMID: 34606381 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


196. Proc Natl Acad Sci U S A. 2021 May 4;118(18):e2014472118. doi: 
10.1073/pnas.2014472118.

Multiscale photonic imaging of the native and implanted cochlea.

Keppeler D(1)(2), Kampshoff CA(1)(2)(3), Thirumalai A(1)(2), Duque-Afonso 
CJ(1)(2), Schaeper JJ(4), Quilitz T(1)(2), Töpperwien M(4), Vogl C(1)(2), 
Hessler R(5), Meyer A(2)(3), Salditt T(4)(6), Moser T(7)(2)(3)(6)(8).

Author information:
(1)Institute for Auditory Neuroscience, University Medical Center Göttingen, 
37075 Göttingen, Germany.
(2)InnerEarLab, University Medical Center Göttingen, 37075 Göttingen, Germany.
(3)Department of Otolaryngology, University Medical Center Göttingen, 37075 
Göttingen, Germany.
(4)Institute for X-ray Physics, University of Göttingen, 37075 Göttingen, 
Germany.
(5)MED-EL, 6020 Innsbruck, Austria.
(6)Cluster of Excellence "Multiscale Bioimaging: From Molecular Machines to 
Networks of Excitable Cells," University of Göttingen, 37075 Göttingen, Germany.
(7)Institute for Auditory Neuroscience, University Medical Center Göttingen, 
37075 Göttingen, Germany; tmoser@gwdg.de.
(8)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
37075 Göttingen, Germany.

The cochlea of our auditory system is an intricate structure deeply embedded in 
the temporal bone. Compared with other sensory organs such as the eye, the 
cochlea has remained poorly accessible for investigation, for example, by 
imaging. This limitation also concerns the further development of technology for 
restoring hearing in the case of cochlear dysfunction, which requires 
quantitative information on spatial dimensions and the sensorineural status of 
the cochlea. Here, we employed X-ray phase-contrast tomography and light-sheet 
fluorescence microscopy and their combination for multiscale and multimodal 
imaging of cochlear morphology in species that serve as established animal 
models for auditory research. We provide a systematic reference for 
morphological parameters relevant for cochlear implant development for rodent 
and nonhuman primate models. We simulate the spread of light from the emitters 
of the optical implants within the reconstructed nonhuman primate cochlea, which 
indicates a spatially narrow optogenetic excitation of spiral ganglion neurons.

DOI: 10.1073/pnas.2014472118
PMCID: PMC8106341
PMID: 33903231 [Indexed for MEDLINE]

Conflict of interest statement: Competing interest statement: T.M. and D.K. are 
co-founders of OptoGenTech company.


197. Hear Res. 2016 May;335:179-192. doi: 10.1016/j.heares.2016.03.010. Epub 2016 Mar 
19.

Spectral and binaural loudness summation for hearing-impaired listeners.

Oetting D(1), Hohmann V(2), Appell JE(3), Kollmeier B(4), Ewert SD(2).

Author information:
(1)Project Group Hearing, Speech and Audio Technology of the Fraunhofer IDMT and 
Cluster of Excellence Hearing4all, Oldenburg, Germany; Medizinische Physik and 
Cluster of Excellence Hearing4all, Universität Oldenburg, 26111 Oldenburg, 
Germany. Electronic address: dirk.oetting@idmt.fraunhofer.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, 26111 Oldenburg, Germany.
(3)Project Group Hearing, Speech and Audio Technology of the Fraunhofer IDMT and 
Cluster of Excellence Hearing4all, Oldenburg, Germany.
(4)Project Group Hearing, Speech and Audio Technology of the Fraunhofer IDMT and 
Cluster of Excellence Hearing4all, Oldenburg, Germany; Medizinische Physik and 
Cluster of Excellence Hearing4all, Universität Oldenburg, 26111 Oldenburg, 
Germany.

Sensorineural hearing loss typically results in a steepened loudness function 
and a reduced dynamic range from elevated thresholds to uncomfortably loud 
levels for narrowband and broadband signals. Restoring narrowband loudness 
perception for hearing-impaired (HI) listeners can lead to overly loud 
perception of broadband signals and it is unclear how binaural presentation 
affects loudness perception in this case. Here, loudness perception quantified 
by categorical loudness scaling for nine normal-hearing (NH) and ten HI 
listeners was compared for signals with different bandwidth and different 
spectral shape in monaural and in binaural conditions. For the HI listeners, 
frequency- and level-dependent amplification was used to match the narrowband 
monaural loudness functions of the NH listeners. The average loudness functions 
for NH and HI listeners showed good agreement for monaural broadband signals. 
However, HI listeners showed substantially greater loudness for binaural 
broadband signals than NH listeners: on average a 14.1 dB lower level was 
required to reach "very loud" (range 30.8 to -3.7 dB). Overall, with narrowband 
loudness compensation, a given binaural loudness for broadband signals above 
"medium loud" was reached at systematically lower levels for HI than for NH 
listeners. Such increased binaural loudness summation was not found for loudness 
categories below "medium loud" or for narrowband signals. Large individual 
variations in the increased loudness summation were observed and could not be 
explained by the audiogram or the narrowband loudness functions.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.03.010
PMID: 27006003 [Indexed for MEDLINE]


198. Hear Res. 2018 Dec;370:113-119. doi: 10.1016/j.heares.2018.10.006. Epub 2018 Oct 
13.

Use of non-invasive measures to predict cochlear synapse counts.

Bramhall NF(1), McMillan GP(2), Kujawa SG(3), Konrad-Martin D(2).

Author information:
(1)VA RR&D National Center for Rehabilitative Auditory Research (NCRAR), VA 
Portland Health Care System, Portland, OR, 97239, USA; Department of 
Otolaryngology/Head & Neck Surgery, Oregon Health & Science University, 
Portland, OR, 97239, USA. Electronic address: naomi.bramhall@va.gov.
(2)VA RR&D National Center for Rehabilitative Auditory Research (NCRAR), VA 
Portland Health Care System, Portland, OR, 97239, USA; Department of 
Otolaryngology/Head & Neck Surgery, Oregon Health & Science University, 
Portland, OR, 97239, USA.
(3)Eaton-Peabody Laboratories, Massachusetts Eye & Ear Infirmary, Boston, MA, 
02114, USA; Department of Otolaryngology, Harvard Medical School, Boston, MA, 
02115, USA.

Cochlear synaptopathy, the loss of synaptic connections between inner hair cells 
(IHCs) and auditory nerve fibers, has been documented in animal models of aging, 
noise, and ototoxic drug exposure, three common causes of acquired sensorineural 
hearing loss in humans. In each of these models, synaptopathy begins prior to 
changes in threshold sensitivity or loss of hair cells; thus, this underlying 
injury can be hidden behind a normal threshold audiogram. Since cochlear 
synaptic loss cannot be directly confirmed in living humans, non-invasive assays 
will be required for diagnosis. In animals with normal auditory thresholds, the 
amplitude of wave 1 of the auditory brainstem response (ABR) is highly 
correlated with synapse counts. However, synaptopathy can also co-occur with 
threshold elevation, complicating the use of the ABR alone as a diagnostic 
measure. Using an age-graded series of mice and a partial least squares 
regression approach to model structure-function relationships, this study shows 
that the combination of a small number of ABR and distortion product otoacoustic 
emission (DPOAE) measurements can predict synaptic ribbon counts at various 
cochlear frequencies to within 1-2 synapses per IHC of their true value. In 
contrast, the model, trained using the age-graded series of mice, overpredicted 
synapse counts in a small sample of young noise-exposed mice, perhaps due to 
differences in the underlying pattern of damage between aging and noise-exposed 
mice. These results provide partial validation of a noninvasive approach to 
identify synaptic/neuronal loss in humans using ABRs and DPOAEs.

Published by Elsevier B.V.

DOI: 10.1016/j.heares.2018.10.006
PMCID: PMC7161203
PMID: 30366194 [Indexed for MEDLINE]

Conflict of interest statement: Declarations of interest None.


199. Trends Hear. 2023 Jan-Dec;27:23312165221148022. doi: 10.1177/23312165221148022.

Optimization of Sound Coding Strategies to Make Singing Music More Accessible 
for Cochlear Implant Users.

Tahmasebi S(1)(2), Segovia-Martinez M(3), Nogueira W(1)(2).

Author information:
(1)Department of Otolaryngology, 9177Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence Hearing4all, Hannover, Germany.
(3)438962Oticon Medical, Vallauris, France.

Cochlear implants (CIs) are implantable medical devices that can partially 
restore hearing to people suffering from profound sensorineural hearing loss. 
While these devices provide good speech understanding in quiet, many CI users 
face difficulties when listening to music. Reasons include poor spatial 
specificity of electric stimulation, limited transmission of spectral and 
temporal fine structure of acoustic signals, and restrictions in the dynamic 
range that can be conveyed via electric stimulation of the auditory nerve. The 
coding strategies currently used in CIs are typically designed for speech rather 
than music. This work investigates the optimization of CI coding strategies to 
make singing music more accessible to CI users. The aim is to reduce the 
spectral complexity of music by selecting fewer bands for stimulation, 
attenuating the background instruments by strengthening a noise reduction 
algorithm, and optimizing the electric dynamic range through a back-end 
compressor. The optimizations were evaluated through both objective and 
perceptual measures of speech understanding and melody identification of singing 
voice with and without background instruments, as well as music appreciation 
questionnaires. Consistent with the objective measures, results gathered from 
the perceptual evaluations indicated that reducing the number of selected bands 
and optimizing the electric dynamic range significantly improved speech 
understanding in music. Moreover, results obtained from questionnaires show that 
the new music back-end compressor significantly improved music enjoyment. These 
results have potential as a new CI program for improved singing music 
perception.

DOI: 10.1177/23312165221148022
PMCID: PMC9837293
PMID: 36628453 [Indexed for MEDLINE]

Conflict of interest statement: The authors declared no potential conflicts of 
interest with respect to the research, authorship, and/or publication of this 
article.


200. Hear Res. 2021 May;404:108217. doi: 10.1016/j.heares.2021.108217. Epub 2021 Feb 
22.

DARF: A data-reduced FADE version for simulations of speech recognition 
thresholds with real hearing aids.

Hülsmeier D(1), Schädler MR(2), Kollmeier B(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität 
Oldenburg, Oldenburg 26129, Germany. Electronic address: 
david.huelsmeier@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität 
Oldenburg, Oldenburg 26129, Germany.

Developing and selecting hearing aids is a time consuming process which is 
simplified by using objective models. Previously, the framework for auditory 
discrimination experiments (FADE) accurately simulated benefits of hearing aid 
algorithms with root mean squared prediction errors below 3 dB. One FADE 
simulation requires several hours of (un)processed signals, which is obstructive 
when the signals have to be recorded. We propose and evaluate a data-reduced 
FADE version (DARF) which facilitates simulations with signals that cannot be 
processed digitally, but that can only be recorded in real-time. DARF simulates 
one speech recognition threshold (SRT) with about 30 min of recorded and 
processed signals of the (German) matrix sentence test. Benchmark experiments 
were carried out to compare DARF and standard FADE exhibiting small differences 
for stationary maskers (1 dB), but larger differences with strongly fluctuating 
maskers (5 dB). Hearing impairment and hearing aid algorithms seemed to reduce 
the differences. Hearing aid benefits were simulated in terms of speech 
recognition with three pairs of real hearing aids in silence (≥8 dB), in 
stationary and fluctuating maskers in co-located (stat. 2 dB; fluct. 6 dB), and 
spatially separated speech and noise signals (stat. ≥8 dB; fluct. 8 dB). The 
simulations were plausible in comparison to data from literature, but a 
comparison with empirical data is still open. DARF facilitates objective SRT 
simulations with real devices with unknown signal processing in real 
environments. Yet, a validation of DARF for devices with unknown signal 
processing is still pending since it was only tested with three similar devices. 
Nonetheless, DARF could be used for improving as well as for developing or 
model-based fitting of hearing aids.

Copyright © 2021 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2021.108217
PMID: 33706223 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The Authors 
declare that there is no conflict of interest.


201. J Speech Lang Hear Res. 2021 Jan 14;64(1):250-262. doi: 
10.1044/2020_JSLHR-20-00262. Epub 2021 Jan 5.

When Hearing Does Not Mean Understanding: On the Neural Processing of 
Syntactically Complex Sentences by Listeners With Hearing Loss.

Vogelzang M(1)(2), Thiel CM(2)(3), Rosemann S(2)(3), Rieger JW(2)(4), Ruigendijk 
E(1)(2).

Author information:
(1)Institute of Dutch Studies, Carl von Ossietzky University of Oldenburg, 
Germany.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky University of 
Oldenburg, Germany.
(3)Biological Psychology Lab, Department of Psychology, Faculty of Medicine and 
Health Sciences, Carl von Ossietzky University of Oldenburg, Germany.
(4)Applied Neurocognitive Psychology Lab, Department of Psychology, Carl von 
Ossietzky University of Oldenburg, Germany.

Purpose Adults with mild-to-moderate age-related hearing loss typically exhibit 
issues with speech understanding, but their processing of syntactically complex 
sentences is not well understood. We test the hypothesis that listeners with 
hearing loss' difficulties with comprehension and processing of syntactically 
complex sentences are due to the processing of degraded input interfering with 
the successful processing of complex sentences. Method We performed a 
neuroimaging study with a sentence comprehension task, varying sentence 
complexity (through subject-object order and verb-arguments order) and cognitive 
demands (presence or absence of a secondary task) within subjects. Groups of 
older subjects with hearing loss (n = 20) and age-matched normal-hearing 
controls (n = 20) were tested. Results The comprehension data show effects of 
syntactic complexity and hearing ability, with normal-hearing controls 
outperforming listeners with hearing loss, seemingly more so on syntactically 
complex sentences. The secondary task did not influence off-line comprehension. 
The imaging data show effects of group, sentence complexity, and task, with 
listeners with hearing loss showing decreased activation in typical speech 
processing areas, such as the inferior frontal gyrus and superior temporal 
gyrus. No interactions between group, sentence complexity, and task were found 
in the neuroimaging data. Conclusions The results suggest that listeners with 
hearing loss process speech differently from their normal-hearing peers, 
possibly due to the increased demands of processing degraded auditory input. 
Increased cognitive demands by means of a secondary visual shape processing task 
influence neural sentence processing, but no evidence was found that it does so 
in a different way for listeners with hearing loss and normal-hearing listeners.

DOI: 10.1044/2020_JSLHR-20-00262
PMID: 33400550 [Indexed for MEDLINE]


202. eNeuro. 2020 May 8;7(3):ENEURO.0511-19.2020. doi: 10.1523/ENEURO.0511-19.2020. 
Print 2020 May/Jun.

Aging But Not Age-Related Hearing Loss Dominates the Decrease of Parvalbumin 
Immunoreactivity in the Primary Auditory Cortex of Mice.

Rogalla MM(1), Hildebrandt KJ(2).

Author information:
(1)Department of Neuroscience, Division of Auditory Neuroscience, and Cluster of 
Excellence, Hearing4all, Carl von Ossietzky University, Oldenburg 26129, Germany 
meike.rogalla@uni-oldenburg.de.
(2)Department of Neuroscience, Division of Auditory Neuroscience, and Cluster of 
Excellence, Hearing4all, Carl von Ossietzky University, Oldenburg 26129, 
Germany.

Alterations in inhibitory circuits of the primary auditory cortex (pAC) have 
been shown to be an aspect of aging and age-related hearing loss (AHL). Several 
studies reported a decline in parvalbumin (PV) immunoreactivity in aged rodent 
pAC of animals displaying AHL and conclude a relationship between reduced 
sensitivity and declined PV immunoreactivity. However, it remains elusive 
whether AHL or a general molecular aging is causative for decreased PV 
immunoreactivity. In this study, we aimed to disentangle the effects of AHL and 
general aging on PV immunoreactivity patterns in inhibitory interneurons of 
mouse pAC. We compared young and old animals of a mouse line with AHL (C57BL/6) 
and a mutant (C57B6.CAST-Cdh23Ahl+ ) that is not vulnerable to AHL according to 
their hearing status by measuring auditory brainstem responses (ABRs) and by an 
immunohistochemical evaluation of the PV immunoreactivity patterns in two 
dimensions (rostro-caudal and layer) in the pAC. Although AHL could be confirmed 
by ABR measurements for the C57BL/6 mice, both aged strains showed a similar 
reduction of PV+ positive interneurons in both, number and density. The pattern 
of reduction across the rostro-caudal axis and across cortical layers was 
similar for both aged lines. Our results demonstrate that a reduced PV 
immunoreactivity is a sign of general, molecular aging and not related to AHL.

Copyright © 2020 Rogalla and Hildebrandt.

DOI: 10.1523/ENEURO.0511-19.2020
PMCID: PMC7210488
PMID: 32327469 [Indexed for MEDLINE]


203. Eur Arch Otorhinolaryngol. 2015 Nov;272(11):3157-62. doi: 
10.1007/s00405-014-3337-3. Epub 2014 Oct 17.

Use of data mining to predict significant factors and benefits of bilateral 
cochlear implantation.

Ramos-Miguel A(1)(2), Perez-Zaballos T(3)(4), Perez D(3)(4), Falconb JC(3)(4), 
Ramosb A(3)(4).

Author information:
(1)University of Las Palmas of Gran Canaria, Gran Canaria, Spain. 
aramos.gcc@gmail.com.
(2)Hearing Loss Unit, University Hospital Insular De Gran Canaria, Gran Canaria, 
Spain. aramos.gcc@gmail.com.
(3)University of Las Palmas of Gran Canaria, Gran Canaria, Spain.
(4)Hearing Loss Unit, University Hospital Insular De Gran Canaria, Gran Canaria, 
Spain.

Data mining (DM) is a technique used to discover pattern and knowledge from a 
big amount of data. It uses artificial intelligence, automatic learning, 
statistics, databases, etc. In this study, DM was successfully used as a 
predictive tool to assess disyllabic speech test performance in bilateral 
implanted patients with a success rate above 90%. 60 bilateral sequentially 
implanted adult patients were included in the study. The DM algorithms developed 
found correlations between unilateral medical records and Audiological test 
results and bilateral performance by establishing relevant variables based on 
two DM techniques: the classifier and the estimation. The nearest neighbor 
algorithm was implemented in the first case, and the linear regression in the 
second. The results showed that patients with unilateral disyllabic test results 
below 70% benefited the most from a bilateral implantation. Finally, it was 
observed that its benefits decrease as the inter-implant time increases.

DOI: 10.1007/s00405-014-3337-3
PMID: 25323153 [Indexed for MEDLINE]


204. S Afr J Commun Disord. 2017 Mar 28;64(1):e1-e12. doi: 10.4102/sajcd.v64i1.185.

Perceptions of public primary school teachers regarding noise-induced hearing 
loss in South Africa.

Ehlert K(1).

Author information:
(1)Department Speech-Language Pathology and Audiology, Sefako Makgatho Health 
Sciences University. katerina.ehlert@smu.ac.za.

BACKGROUND: Noise-induced hearing loss (NIHL) is an increasingly growing problem 
in young children. This is attributed to recreational noise being the most 
common cause of this problem. In young children, hearing problems can delay 
language development and reduce academic achievements. South Africa, in 
particular, has limited information and protective measures regarding the 
conservation of hearing in school-aged children.
OBJECTIVES: The main aim of the study was to determine the perception of primary 
school teachers regarding NIHL. The study also aimed to determine if any hearing 
conservation programmes are being implemented in schools and the need for 
training of primary school teachers regarding NIHL.
METHOD: A survey was conducted. In order to cover the population of interest, 
the sampled schools in Pretoria were clustered into urban, semi-urban and rural 
areas.
RESULTS: The majority of the teachers included in this study are aware of NIHL 
and its effects. They, however, lack the necessary resources and knowledge to 
effectively use this information. Most (67.5%) of the teachers indicated that 
they have never been exposed to children with NIHL in a school setting. It was 
also found that the majority (84%) of the schools included in the study do not 
implement hearing screening and conservation programmes.
CONCLUSION: Although the sample size was limited, the results correlate with 
other research in this field indicating a need for planning and implementation 
of hearing conservation programmes in schools, including training of teachers in 
order for these programmes to be effective.

DOI: 10.4102/sajcd.v64i1.185
PMCID: PMC5843150
PMID: 28397520 [Indexed for MEDLINE]

Conflict of interest statement: The author declares that she has no financial or 
personal relationships that may have inappropriately influenced her in writing 
this article.


205. PLoS One. 2021 Dec 13;16(12):e0261295. doi: 10.1371/journal.pone.0261295. 
eCollection 2021.

Assessing the relationship between neural health measures and speech performance 
with simultaneous electric stimulation in cochlear implant listeners.

Langner F(1), Arenberg JG(2), Büchner A(1), Nogueira W(1).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School and Cluster of 
Excellence Hearing4all, Hanover, Germany.
(2)Department of Otolaryngology, Massachusetts Eye and Ear, Harvard Medical 
School, Boston, MA, United States of America.

OBJECTIVES: The relationship between electrode-nerve interface (ENI) estimates 
and inter-subject differences in speech performance with sequential and 
simultaneous channel stimulation in adult cochlear implant listeners were 
explored. We investigated the hypothesis that individuals with good ENIs would 
perform better with simultaneous compared to sequential channel stimulation 
speech processing strategies than those estimated to have poor ENIs.
METHODS: Fourteen postlingually deaf implanted cochlear implant users 
participated in the study. Speech understanding was assessed with a sentence 
test at signal-to-noise ratios that resulted in 50% performance for each user 
with the baseline strategy F120 Sequential. Two simultaneous stimulation 
strategies with either two (Paired) or three sets of virtual channels (Triplet) 
were tested at the same signal-to-noise ratio. ENI measures were estimated 
through: (I) voltage spread with electrical field imaging, (II) behavioral 
detection thresholds with focused stimulation, and (III) slope (IPG slope 
effect) and 50%-point differences (dB offset effect) of amplitude growth 
functions from electrically evoked compound action potentials with two 
interphase gaps.
RESULTS: A significant effect of strategy on speech understanding performance 
was found, with Triplets showing a trend towards worse speech understanding 
performance than sequential stimulation. Focused thresholds correlated 
positively with the difference required to reach most comfortable level (MCL) 
between Sequential and Triplet strategies, an indirect measure of channel 
interaction. A significant offset effect (difference in dB between 50%-point for 
higher eCAP growth function slopes with two IPGs) was observed. No significant 
correlation was observed between the slopes for the two IPGs tested. None of the 
measures used in this study correlated with the differences in speech 
understanding scores between strategies.
CONCLUSIONS: The ENI measure based on behavioral focused thresholds could 
explain some of the difference in MCLs, but none of the ENI measures could 
explain the decrease in speech understanding with increasing pairs of 
simultaneously stimulated electrodes in processing strategies.

DOI: 10.1371/journal.pone.0261295
PMCID: PMC8668108
PMID: 34898654 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


206. Otol Neurotol. 2021 Aug 1;42(7):e849-e857. doi: 10.1097/MAO.0000000000003120.

Improved Speech Intelligibility in Subjects With Stable Sensorineural Hearing 
Loss Following Intratympanic Dosing of FX-322 in a Phase 1b Study.

McLean WJ(1)(2), Hinton AS(1), Herby JTJ(1), Salt AN(3), Hartsock JJ(3), Wilson 
S(1), Lucchino DL(1), Lenarz T(4), Warnecke A(4), Prenzler N(4), Schmitt H(4), 
King S(5), Jackson LE(6), Rosenbloom J(7), Atiee G(8), Bear M(9), Runge CL(10), 
Gifford RH(11), Rauch SD(12), Lee DJ(12), Langer R(13), Karp JM(14)(15)(16)(17), 
Loose C(1), LeBel C(1).

Author information:
(1)Frequency Therapeutics, Woburn, MA & Farmington, CT.
(2)Department of Surgery, University of Connecticut School of Medicine, 
Farmington, CT.
(3)Department of Otolaryngology, Central Institute for the Deaf, Fay and Carl 
Simons Center for Hearing and Deafness, Washington University School of 
Medicine, Saint Louis, MO.
(4)Department of Otolaryngology and Cluster of Excellence of the German Research 
Foundation "Hearing4all", Hannover Medical School, Hannover, Germany.
(5)Ear Medical Group.
(6)Ear Institute of Texas, San Antonio, TX.
(7)Alamo ENT Associates, San Antonio, TX.
(8)Worldwide Clinical Trials, San Antonio, TX.
(9)Forsythe and Bear LLC, Woodland Hills, CA.
(10)Department of Otolaryngology and Communication Sciences, Medical College of 
Wisconsin, Milwaukee, WI.
(11)Department of Hearing and Speech Sciences, Vanderbilt University Medical 
Center, Nashville, TN.
(12)Department of Otolaryngology, Harvard Medical School and Massachusetts Eye 
and Ear, Boston.
(13)Department of Biological Engineering, Massachusetts Institute of Technology, 
Cambridge, MA.
(14)Center for Nanomedicine, Department of Anesthesiology, Perioperative and 
Pain Medicine, Brigham and Women's Hospital, Harvard Medical School Boston MA.
(15)Harvard-MIT Division of Health Science and Technology.
(16)Harvard Stem Cell Institute, Harvard University, Cambridge, MA, USA.
(17)Broad Institute of MIT and Harvard, Cambridge, MA.

OBJECTIVES: There are no approved pharmacologic therapies for chronic 
sensorineural hearing loss (SNHL). The combination of CHIR99021+valproic acid 
(CV, FX-322) has been shown to regenerate mammalian cochlear hair cells ex vivo. 
The objectives were to characterize the cochlear pharmacokinetic profile of CV 
in guinea pigs, then measure FX-322 in human perilymph samples, and finally 
assess safety and audiometric effects of FX-322 in humans with chronic SNHL.
STUDY DESIGNS: Middle ear residence, cochlear distribution, and elimination 
profiles of FX-322 were assessed in guinea pigs. Human perilymph sampling 
following intratympanic FX-322 dosing was performed in an open-label study in 
cochlear implant subjects. Unilateral intratympanic FX-322 was assessed in a 
Phase 1b prospective, randomized, double-blinded, placebo-controlled clinical 
trial.
SETTING: Three private otolaryngology practices in the US.
PATIENTS: Individuals diagnosed with mild to moderately severe chronic SNHL 
(≤70 dB standard pure-tone average) in one or both ears that was stable for 
≥6 months, medical histories consistent with noise-induced or idiopathic sudden 
SNHL, and no significant vestibular symptoms.
INTERVENTIONS: Intratympanic FX-322.
MAIN OUTCOME MEASURES: Pharmacokinetics of FX-322 in perilymph and safety and 
audiometric effects.
RESULTS: After intratympanic delivery in guinea pigs and humans, FX-322 levels 
in the cochlear extended high-frequency region were observed and projected to be 
pharmacologically active in humans. A single dose of FX-322 in SNHL subjects was 
well tolerated with mild, transient treatment-related adverse events (n = 15 
FX-322 vs 8 placebo). Of the six patients treated with FX-322 who had baseline 
word recognition in quiet scores below 90%, four showed clinically meaningful 
improvements (absolute word recognition improved 18-42%, exceeding the 95% 
confidence interval determined by previously published criteria). No significant 
changes in placebo-injected ears were observed. At the group level, FX-322 
subjects outperformed placebo group in word recognition in quiet when averaged 
across all time points, with a mean improvement from baseline of 18.9% 
(p = 0.029). For words in noise, the treated group showed a mean 1.3 dB 
signal-to-noise ratio improvement (p = 0.012) relative to their baseline scores 
while placebo-treated subjects did not (-0.21 dB, p = 0.71).
CONCLUSIONS: Delivery of FX-322 to the extended high-frequency region of the 
cochlea is well tolerated and enhances speech recognition performance in 
multiple subjects with stable chronic hearing loss.

Copyright © 2021 The Author(s). Published by Wolters Kluwer Health, Inc. on 
behalf of Otology & Neurotology, Inc.

DOI: 10.1097/MAO.0000000000003120
PMCID: PMC8279894
PMID: 33617194 [Indexed for MEDLINE]

Conflict of interest statement: No other authors have conflicts of interest.


207. Eur J Neurosci. 2023 Mar;57(6):981-1002. doi: 10.1111/ejn.15922. Epub 2023 Feb 
20.

Different neuroanatomical correlates for temporal and spectral supra-threshold 
auditory tasks and speech in noise recognition in older adults with hearing 
impairment.

Neuschwander P(1), Schmitt R(2), Jagoda L(1), Kurthen I(3), Giroud N(2), Meyer 
M(4)(5)(6).

Author information:
(1)Division of Neuropsychology, Department of Psychology, University of Zurich, 
Zurich, Switzerland.
(2)Neuroscience of Speech & Hearing, Department of Computational Linguistics, 
University of Zurich, Zurich, Switzerland.
(3)Developmental Psychology: Infancy and Childhood, Department of Psychology, 
University of Zurich, Zurich, Switzerland.
(4)Evolutionary Neuroscience of Language, Department of Comparative Language 
Science, University of Zurich, Zurich, Switzerland.
(5)Center for the Interdisciplinary Study of Language Evolution (ISLE), 
University of Zurich, Zurich, Switzerland.
(6)Cognitive Psychology Unit, Alpen-Adria University of Klagenfurt, Klagenfurt, 
Austria.

Varying degrees of pure-tone hearing loss in older adults are differentially 
associated with cortical volume (CV) and thickness (CT) within and outside of 
the auditory pathway. This study addressed the question to what degree 
supra-threshold auditory performance (i.e., temporal compression and frequency 
selectivity) as well as speech in noise (SiN) recognition are associated with 
neurostructural correlates in a sample of 59 healthy older adults with mild to 
moderate pure-tone hearing loss. Using surface-based morphometry on T1-weighted 
MRI images, CT, CV, and surface area (CSA) of several regions-of-interest were 
obtained. The results showed distinct neurostructural patterns for the different 
tasks in terms of involved regions as well as morphometric parameters. While 
pure-tone averages (PTAs) positively correlated with CT in a right hemisphere 
superior temporal sulcus and gyrus cluster, supra-threshold auditory perception 
additionally extended significantly to CV and CT in left and right superior 
temporal clusters including Heschl's gyrus and sulcus, the planum polare and 
temporale. For SiN recognition, we found significant correlations with an 
auditory-related CT cluster and furthermore with language-related areas in the 
prefrontal cortex. Taken together, our results show that different auditory 
abilities are differently associated with cortical morphology in older adults 
with hearing impairment. Still, a common pattern is that greater PTAs and poorer 
supra-threshold auditory performance as well as poorer SiN recognition are all 
related to cortical thinning and volume loss but not to changes in CSA. These 
results support the hypothesis that mostly CT undergoes alterations in the 
context of auditory decline, while CSA remains stable.

© 2023 University of Zurich and The Authors. European Journal of Neuroscience 
published by Federation of European Neuroscience Societies and John Wiley & Sons 
Ltd.

DOI: 10.1111/ejn.15922
PMID: 36683390 [Indexed for MEDLINE]


208. Int J Audiol. 2016 Dec;55(12):738-747. doi: 10.1080/14992027.2016.1219774. Epub 
2016 Sep 14.

Perceived listening effort and speech intelligibility in reverberation and noise 
for hearing-impaired listeners.

Schepker H(1)(2), Haeder K(2)(3), Rennies J(2)(4), Holube I(2)(3).

Author information:
(1)a Signal Processing Group, Department of Medical Physics and Acoustics , 
University of Oldenburg , Oldenburg , Germany.
(2)b Cluster of Excellence "Hearing4All" , Oldenburg , Germany.
(3)c Institute of Hearing Technology and Audiology , Jade University of Applied 
Sciences , Oldenburg , Germany , and.
(4)d Project Group Hearing, Speech and Audio Technology , Fraunhofer Institute 
for Digital Media Technology IDMT , Oldenburg , Germany.

OBJECTIVE: The purpose of this study was to assess perceived listening effort 
and speech intelligibility in reverberant and noisy conditions for 
hearing-impaired listeners for conditions that are similar according to the 
speech transmission index (STI).
DESIGN: Scaled listening effort was measured in four different conditions at 
five different STI generated using various relative contributions of noise and 
reverberant interferences. Intelligibility was measured for a subset of 
conditions.
STUDY SAMPLE: Twenty mildly to moderately hearing-impaired listeners.
RESULTS: In general, listening effort decreased and speech intelligibility 
increased with increasing STI. For simulated impulse responses consisting of 
white Gaussian noise exponentially decaying in time, a good agreement between 
conditions of different relative contributions of noise and reverberation was 
found. For real impulse responses, the STI slightly overestimated the effect of 
reverberation on the perceived listening effort and underestimated its effect on 
speech intelligibility. Including the average hearing loss in the calculation of 
the STI led to a better agreement between STI predictions and subjective data.
CONCLUSION: Speech intelligibility and listening effort provide complementary 
tools to evaluate speech perception over a broad range of acoustic scenarios. In 
addition, when incorporating hearing loss information the STI provides a rough 
prediction of listening effort in these acoustic scenarios.

DOI: 10.1080/14992027.2016.1219774
PMID: 27627181 [Indexed for MEDLINE]


209. Clin Neurophysiol. 2015 Mar;126(3):594-607. doi: 10.1016/j.clinph.2014.06.029. 
Epub 2014 Jul 3.

Rapid bilateral improvement in auditory cortex activity in postlingually 
deafened adults following cochlear implantation.

Sandmann P(1), Plotz K(2), Hauthal N(3), de Vos M(4), Schönfeld R(2), Debener 
S(5).

Author information:
(1)Central Auditory Diagnostics Lab, Department of Neurology, Cluster of 
Excellence "Hearing4all", Hannover Medical School, 30625 Hannover, Germany; 
Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, University of Oldenburg, 26111 
Oldenburg, Germany. Electronic address: Sandmann.Pascale@mh-hannover.de.
(2)ENT Centre, Evangelical Hospital Oldenburg, 26122 Oldenburg, Germany.
(3)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, University of Oldenburg, 26111 
Oldenburg, Germany.
(4)Methods in Neurocognitive Psychology, Department of Psychology, Cluster of 
Excellence "Hearing4all", European Medical School, University of Oldenburg, 
26111 Oldenburg, Germany.
(5)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, University of Oldenburg, 26111 
Oldenburg, Germany; Research Center Neurosensory Science, University of 
Oldenburg, 26111 Oldenburg, Germany.

OBJECTIVE: Cochlear implants (CIs) can partially restore hearing, but the 
cortical changes underlying auditory rehabilitation are not well understood.
METHODS: This prospective longitudinal study used electroencephalography (EEG) 
to examine the temporal dynamics of changes in the auditory cortex contralateral 
and ipsilateral to the CI. Postlingually deafened CI recipients (N=11; mean: 
59years) performed an auditory frequency discrimination task after <1week, 
8weeks, 15weeks, and 59weeks of CI use.
RESULTS: The CI users revealed a remarkable improvement in auditory 
discrimination ability which was most pronounced over the first eight weeks of 
CI experience. At the same time, CI users developed N1 auditory event-related 
potentials (AEP) with significantly enhanced amplitude and decreased latency, 
both in the auditory cortex contralateral and ipsilateral to the CI. A 
relationship was found between the duration of deafness and the ipsilateral AEP 
latency.
CONCLUSIONS: Postlingually deafened adult CI users show rapid adaptation of the 
bilateral auditory cortex. Cortical plasticity is limited after long duration of 
auditory deprivation.
SIGNIFICANCE: The finding of rapid and limited cortical changes in adult CI 
recipients may be of clinical relevance and can help estimate the role of 
plasticity for therapeutic gain.

Copyright © 2014 International Federation of Clinical Neurophysiology. Published 
by Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.clinph.2014.06.029
PMID: 25065298 [Indexed for MEDLINE]


210. Int J Audiol. 2020 Dec;59(12):930-940. doi: 10.1080/14992027.2020.1806368. Epub 
2020 Aug 20.

Clinical validation of the Russian Matrix test - effect of hearing loss, age, 
and noise level.

Warzybok A(1), Zhilinskaya E(2), Goykhburg M(3), Tavartkiladze G(3), Kollmeier 
B(1)(4), Boboshko M(2)(5).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Carl-von-Ossietzky 
Universität Oldenburg, Oldenburg, Germany.
(2)Pavlov First St. Petersburg State Medical University, Saint-Petersburg, 
Russia.
(3)National Research Centre for Audiology and Hearing Rehabilitation, Moscow, 
Russia.
(4)HörTech gGmbH, Oldenburg, Germany.
(5)Northwest State Medical University named after Mechnikov, Saint-Petersburg, 
Russia.

OBJECTIVE: To validate the Russian matrix sentence test (RUMatrix) for the 
assessment of speech recognition in quiet and in noise in clinical praxis. The 
effect of hearing impairment, age, and masking-noise level on speech recognition 
was examined.
DESIGN: All participants underwent pure tone audiometry, a monosyllabic speech 
test in quiet, and speech recognition measurements with RUMatrix in quiet (SRTQ) 
and in noise (SRTN).
STUDY SAMPLE: One hundred and forty-two listeners divided into four groups: 1. 
Young normal-hearing listeners, 2. Older normal-hearing listeners, 3. Young 
hearing-impaired listeners, and 4. Older hearing-impaired listeners.
RESULTS: Significant differences between groups of listeners were found in the 
SRTQ and SRTN. A strong correlation between hearing threshold and SRTQ (R2=0.88, 
p < 0.001) indicates a strong link between speech recognition in quiet and 
audibility. The pure-tone average explained less variance in SRTN (R2=0.67, 
p < 0.001), pointing out an additional influence of suprathreshold distortion. A 
high test sensitivity of 0.99 was found for SRTN and SRTQ. The monosyllabic test 
had a low sensitivity (0.21), indicating that the test is not suitable for 
separating normal-hearing and hearing-impaired listeners.
CONCLUSIONS: RuMatrix is a reliable speech recognition assessment tool with a 
high sensitivity and validity for the main aspects of hearing impairment.

DOI: 10.1080/14992027.2020.1806368
PMID: 32815756 [Indexed for MEDLINE]


211. Artif Intell Med. 2007 May;40(1):1-14. doi: 10.1016/j.artmed.2006.07.001. Epub 
2006 Aug 22.

Auditory brainstem response classification: a hybrid model using time and 
frequency features.

Davey R(1), McCullagh P, Lightbody G, McAllister G.

Author information:
(1)Department of Language and Communication Science, City University, 
Northampton Square, London EC1V 0HB, UK.

OBJECTIVE: The auditory brainstem response (ABR) is an evoked response obtained 
from brain electrical activity when an auditory stimulus is applied to the ear. 
An audiologist can determine the threshold level of hearing by applying stimuli 
at reducing levels of intensity, and can also diagnose various otological, 
audiological, and neurological abnormalities by examining the morphology of the 
waveform and the latencies of the individual waves. This is a subjective process 
requiring considerable expertise. The aim of this research was to develop 
software classification models to assist the audiologist with an automated 
detection of the ABR waveform and also to provide objectivity and consistency in 
this detection.
MATERIALS AND METHODS: The dataset used in this study consisted of 550 waveforms 
derived from tests using a range of stimulus levels applied to 85 subjects 
ranging in hearing ability. Each waveform had been classified by a human expert 
as 'response=Yes' or 'response=No'. Individual software classification models 
were generated using time, frequency and cross-correlation measures. 
Classification employed both artificial neural networks (NNs) and the C5.0 
decision tree algorithm. Accuracies were validated using six-fold 
cross-validation, and by randomising training, validation and test datasets.
RESULTS: The result was a two stage classification process whereby strong 
responses were classified to an accuracy of 95.6% in the first stage. This used 
a ratio of post-stimulus to pre-stimulus power in the time domain, with power 
measures at 200, 500 and 900Hz in the frequency domain. In the second stage, 
outputs from time, frequency and cross-correlation classifiers were combined 
using the Dempster-Shafer method to produce a hybrid model with an accuracy of 
85% (126 repeat waveforms).
CONCLUSION: By combining the different approaches a hybrid system has been 
created that emulates the approach used by an audiologist in analysing an ABR 
waveform. Interpretation did not rely on one particular feature but brought 
together power and frequency analysis as well as consistency of subaverages. 
This provided a system that enhanced robustness to artefacts while maintaining 
classification accuracy.

DOI: 10.1016/j.artmed.2006.07.001
PMID: 16930965 [Indexed for MEDLINE]


212. BMC Med Genet. 2018 Sep 14;19(1):168. doi: 10.1186/s12881-018-0676-8.

Notch polymorphisms associated with sensitivity of noise induced hearing loss 
among Chinese textile factory workers.

Ding E(1), Liu J(2), Shen H(3), Gong W(1), Zhang H(1), Song H(2), Zhu B(4).

Author information:
(1)Institute of Occupational Disease Prevention, Jiangsu Provincial Center for 
Disease Prevention and Control, No.172 Jiangsu Road, Nanjing, Jiangsu Province, 
210009, People's Republic of China.
(2)Nanjing Prevention and Treatment Center for Occupational Disease, Nanjing, 
Jiangsu Province, China.
(3)Kunshan Centers for Disease Prevention and Control, Kunshan, Jiangsu 
Province, China.
(4)Institute of Occupational Disease Prevention, Jiangsu Provincial Center for 
Disease Prevention and Control, No.172 Jiangsu Road, Nanjing, Jiangsu Province, 
210009, People's Republic of China. zhubljscdc@126.com.

BACKGROUND: Noise induced hearing loss (NIHL) is a polygenic disease involving 
both genetic and environmental factors, and is one of the most important 
occupational health hazards worldwide. To date, the influence of Notch1 variants 
on the risk to develop NIHL has not been illuminated. This study was conducted 
to explore the effects of Notch1 polymorphisms on individual susceptibility to 
NIHL.
METHODS: A total of 2689 industrial workers from one textile factory in east 
China were recruited to participate in the current study. Venous blood was 
collected, basic clinical data was obtained by questionnaires and pure-tone 
audiometry (PTA) tests were conducted by specialist physicians. Next we 
performed genotyping of three selected SNPs (rs3124594, rs3124599 and rs3124603) 
in the Notch1 gene in 535 NIHL patients and 535 controls. Subsequently, the main 
effects of the genotypes and their interactions were evaluated.
RESULTS: Our results revealed that individuals with a GG of rs3124594, TT of 
rs3124603 (OR = 4.70 and 1.59 respectively) and the haplotype AAC 
(rs3124594-rs3124599-rs3124603) (OR = 14.95) were associated with an increased 
risk of NIHL in our study cohort. Stratified analysis showed that an increased 
NIHL risk was found in individuals exposed to work related noise for ≤16 years 
that also had the rs3124594 GG or rs3124603 CT/TT genotype with an OR of 4.20 
and 1.73 respectively. Multifactor dimensionality reduction analysis indicated 
that rs3124594, rs3124599 and rs3124603 interacted with each other and were 
related to an increased risk to develop NIHL (OR = 3.60).
CONCLUSIONS: The genetic polymorphisms rs3124594 and rs3124603 within the Notch1 
gene are associated with an increased risk of NIHL in a Chinese population and 
could potentially be used as biomarkers for NIHL in noise exposed workers.

DOI: 10.1186/s12881-018-0676-8
PMCID: PMC6137875
PMID: 30217173 [Indexed for MEDLINE]

Conflict of interest statement: ETHICS APPROVAL AND CONSENT TO PARTICIPATE: 
Institutional Review Board of the Jiangsu Provincial Center for Disease 
Prevention and Control granted ethical clearance for the study. Informed consent 
was obtained from all individual participants. CONSENT FOR PUBLICATION: Not 
applicable. COMPETING INTERESTS: The authors declare that they have no competing 
interests. PUBLISHER’S NOTE: Springer Nature remains neutral with regard to 
jurisdictional claims in published maps and institutional affiliations.


213. J Physiol Paris. 2006 Jul-Sep;100(1-3):133-41. doi: 
10.1016/j.jphysparis.2006.09.006. Epub 2006 Oct 31.

Experimental-neuromodeling framework for understanding auditory object 
processing: integrating data across multiple scales.

Husain FT(1), Horwitz B.

Author information:
(1)Brain Imaging and Modeling Section, National Institute on Deafness and Other 
Communication Disorders, National Institutes of Health, Building 10, Rm 8S235-D, 
9000 Rockville Pike, Bethesda, MD 20892, USA. husainf@mail.nih.gov

In this article, we review a combined experimental-neuromodeling framework for 
understanding brain function with a specific application to auditory object 
processing. Within this framework, a model is constructed using the best 
available experimental data and is used to make predictions. The predictions are 
verified by conducting specific or directed experiments and the resulting data 
are matched with the simulated data. The model is refined or tested on new data 
and generates new predictions. The predictions in turn lead to better-focused 
experiments. The auditory object processing model was constructed using 
available neurophysiological and neuroanatomical data from mammalian studies of 
auditory object processing in the cortex. Auditory objects are brief sounds such 
as syllables, words, melodic fragments, etc. The model can simultaneously 
simulate neuronal activity at a columnar level and neuroimaging activity at a 
systems level while processing frequency-modulated tones in a 
delayed-match-to-sample task. The simulated neuroimaging activity was 
quantitatively matched with neuroimaging data obtained from experiments; both 
the simulations and the experiments used similar tasks, sounds, and other 
experimental parameters. We then used the model to investigate the neural bases 
of the auditory continuity illusion, a type of perceptual grouping phenomenon, 
without changing any of its parameters. Perceptual grouping enables the auditory 
system to integrate brief, disparate sounds into cohesive perceptual units. The 
neural mechanisms underlying auditory continuity illusion have not been studied 
extensively with conventional neuroimaging or electrophysiological techniques. 
Our modeling results agree with behavioral studies in humans and an 
electrophysiological study in cats. The results predict a particular set of 
bottom-up cortical processing mechanisms that implement perceptual grouping, and 
also attest to the robustness of our model.

DOI: 10.1016/j.jphysparis.2006.09.006
PMCID: PMC1941673
PMID: 17079121 [Indexed for MEDLINE]


214. Hear Res. 2024 Mar 1;443:108953. doi: 10.1016/j.heares.2024.108953. Epub 2024 
Jan 19.

Tripolar configuration and pulse shape in cochlear implants reduce channel 
interactions in the temporal domain.

Quass GL(1), Kral A(2).

Author information:
(1)Institute for AudioNeuroTechnology (VIANNA) & Department of Experimental 
Otology, Otolaryngology Clinics, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence "Hearing4All" (EXC 2177), Germany. Electronic address: 
gquass@med.umich.edu.
(2)Institute for AudioNeuroTechnology (VIANNA) & Department of Experimental 
Otology, Otolaryngology Clinics, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence "Hearing4All" (EXC 2177), Germany; Australian Hearing Hub, 
School of Medicine and Health Sciences, Macquarie University, Sydney, Australia.

The present study investigates effects of current focusing and pulse shape on 
threshold, dynamic range, spread of excitation and channel interaction in the 
time domain using cochlear implant stimulation. The study was performed on 20 
adult guinea pigs using a 6-channel animal cochlear implant, recording was 
performed in the auditory midbrain using a multielectrode array. After 
determining the best frequencies for individual recording contacts with acoustic 
stimulation, the ear was deafened and a cochlear implant was inserted into the 
cochlea. The position of the implant was controlled by x-ray. Stimulation with 
biphasic, pseudomonophasic and monophasic stimuli was performed with monopolar, 
monopolar with common ground, bipolar and tripolar configuration in two sets of 
experiments, allowing comparison of the effects of the different stimulation 
strategies on threshold, dynamic range, spread of excitation and channel 
interaction. Channel interaction was studied in the temporal domain, where two 
electrodes were activated with pulse trains and phase locking to these pulse 
trains in the midbrain was quantified. The results documented multifactorial 
influences on the response properties, with significant interaction between 
factors. Thresholds increased with increasing current focusing, but decreased 
with pseudomonophasic and monophasic pulse shapes. The results documented that 
current focusing, particularly tripolar configuration, effectively reduces 
channel interaction, but that also pseudomonophasic and monophasic stimulation 
and phase duration intensity coding reduce channel interactions.

Copyright © 2024 The Author(s). Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2024.108953
PMID: 38277881 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest Research CIs 
were supplied by Oticon medical. Authors have nothing to declare.


215. Int J Mol Sci. 2022 Dec 24;24(1):291. doi: 10.3390/ijms24010291.

Prevention of Noise-Induced Hearing Loss In Vivo: Continuous Application of 
Insulin-like Growth Factor 1 and Its Effect on Inner Ear Synapses, Auditory 
Function and Perilymph Proteins.

Malfeld K(1)(2), Armbrecht N(1), Pich A(3), Volk HA(2), Lenarz T(1)(4), Scheper 
V(1)(4).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625 Hannover, Germany.
(2)Department of Small Animal Medicine and Surgery, University of Veterinary 
Medicine Hannover, Foundation, 30559 Hannover, Germany.
(3)Core Facility Proteomics, Hannover Medical School, Carl-Neuberg-Str. 1, 30625 
Hannover, Germany.
(4)Cluster of Excellence "Hearing4all", German Research Foundation (DFG; 
"Deutsche Forschungsgemeinschaft"), Hannover Medical School, Carl-Neuberg-Str. 
1, 30625 Hannover, Germany.

As noise-induced hearing loss (NIHL) is a leading cause of occupational 
diseases, there is an urgent need for the development of preventive and 
therapeutic interventions. To avoid user-compliance-based problems occurring 
with conventional protection devices, the pharmacological prevention is 
currently in the focus of hearing research. Noise exposure leads to an increase 
in reactive oxygen species (ROS) in the cochlea. This way antioxidant agents are 
a promising option for pharmacological interventions. Previous animal studies 
reported preventive as well as therapeutic effects of Insulin-like growth factor 
1 (IGF-1) in the context of NIHL. Unfortunately, in patients the time point of 
the noise trauma cannot always be predicted, and additive effects may occur. 
Therefore, continuous prevention seems to be beneficial. The present study aimed 
to investigate the preventive potential of continuous administration of low 
concentrations of IGF-1 to the inner ear in an animal model of NIHL. Guinea pigs 
were unilaterally implanted with an osmotic minipump. One week after surgery 
they received noise trauma, inducing a temporary threshold shift. Continuous 
IGF-1 delivery lasted for seven more days. It did not lead to significantly 
improved hearing thresholds compared to control animals. Quite the contrary, 
there is a hint for a higher noise susceptibility. Nevertheless, changes in the 
perilymph proteome indicate a reduced damage and better repair mechanisms 
through the IGF-1 treatment. Thus, future studies should investigate delivery 
methods enabling continuous prevention but reducing the risk of an overdosage.

DOI: 10.3390/ijms24010291
PMCID: PMC9820558
PMID: 36613734 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest. The 
funders had no role in the design of the study; in the collection, analyses, or 
interpretation of data; in the writing of the manuscript; or in the decision to 
publish the results.


216. BMJ Open. 2019 Jan 15;9(1):e023078. doi: 10.1136/bmjopen-2018-023078.

Hearing Norton Sound: a community randomised trial protocol to address childhood 
hearing loss in rural Alaska.

Emmett SD(1)(2), Robler SK(3), Wang NY(4)(5), Labrique A(6), Gallo JJ(7), 
Hofstetter P(8).

Author information:
(1)Department of Surgery, Duke University School of Medicine, Durham, North 
Carolina, USA.
(2)Duke Global Health Institute, Durham, North Carolina, USA.
(3)Department of Audiology, Norton Sound Health Corporation, Nome, Alaska, USA.
(4)Department of Medicine, Johns Hopkins University School of Medicine, 
Baltimore, Maryland, USA.
(5)Departments of Biostatistics and Epidemiology, Johns Hopkins Bloomberg School 
of Public Health, Baltimore, Maryland, USA.
(6)Departments of International Health and Epidemiology, Johns Hopkins 
University Bloomberg School of Public Health, Baltimore, Maryland, USA.
(7)Department of Mental Health, Johns Hopkins Bloomberg School of Public Health, 
Baltimore, Maryland, USA.
(8)Norton Sound Health Corporation, Nome, Alaska, USA.

INTRODUCTION: The population in rural Alaska experiences a disproprionately high 
burden of infection-mediated hearing loss. While the state mandates school 
hearing screening, many children with hearing loss are not identified or are 
lost to follow-up before ever receiving treatment. A robust, tribally owned 
healthcare system exists in Alaska, but children with hearing loss must first be 
identified and referred for existing infrastructure to be used. This trial will 
evaluate a new school hearing screening and referral process in rural Alaska, 
with the goal of improving timely identification and treatment of childhood 
hearing loss.
METHODS AND ANALYSIS: Comparative effectiveness community randomised trial 
testing digital innovations to improve school hearing screening and referral in 
15 communities in the Norton Sound region of northwest Alaska, with data 
collection from October 2017 to February 2020. All children (K-12) attending 
school in Bering Strait School District with parental informed consent and child 
assent will be eligible (target recruitment n=1500). Participating children will 
undergo both the current school hearing screen and new mobile health (mHealth) 
screen, with screening test validity evaluated against an audiometric 
assessment. Communities will be cluster randomised to continue the current 
primary care referral process or receive telemedicine referral for follow-up 
diagnosis and treatment. The primary outcome will be time to International 
Statistical Classification of Diseases, 10th Revision, ear/hearing diagnosis 
from screening date, measured in days. Secondary outcomes will include: 
sensitivity and specificity of current school and mHealth screening protocols 
measured against a benchmark audiometric assessment (air and bone conduction 
audiometry, tympanometry and digital otoscopy); hearing loss prevalence; 
hearing-related quality of life; and school performance (AIMSweb). 
Intention-to-treat analysis will be used.
ETHICS AND DISSEMINATION: This study has been approved by the Institutional 
Review Boards of Alaska Area, Norton Sound and Duke University and is registered 
on clinicaltrials.gov. Results will be distributed with equal emphasis on 
scientific and community dissemination.
TRIAL REGISTRATION NUMBER: NCT03309553; Pre-results.

© Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No 
commercial re-use. See rights and permissions. Published by BMJ.

DOI: 10.1136/bmjopen-2018-023078
PMCID: PMC6340015
PMID: 30782695 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests: None declared.


217. J Acoust Soc Am. 2022 Nov;152(5):2720. doi: 10.1121/10.0014955.

A convolutional neural network-based framework for analysis and assessment of 
non-linguistic sound classification and enhancement for normal hearing and 
cochlear implant listeners.

Shekar RCMC(1), Hansen JHL(1).

Author information:
(1)Cochlear Implant Processing Laboratory-Center for Robust Speech Systems 
(CRSS-CILab), University of Texas at Dallas, Richardson, Texas 75080, USA.

Naturalistic sounds encode salient acoustic content that provides situational 
context or subject/system properties essential for acoustic awareness, autonomy, 
safety, and improved quality of life for individuals with sensorineural hearing 
loss. Cochlear implants (CIs) are an assistive hearing device that restores 
auditory function in hearing impaired individuals. Most CI research advancements 
have focused on improving speech recognition in noisy, reverberant, or 
time-varying diverse environments. Relatively few studies have explored 
non-linguistic sound (NLS) perception among CIs, and those that have carried out 
such studies generally reported poor perception, suggesting a clear deficit in 
current CI sound processing systems. In this study, a convolutional neural 
network (CNN)-based NLS classification model is used as a framework to compare 
unprocessed and CI-simulated NLS classification and evaluate NLS perception 
targeted algorithms among CI listeners. Additionally, a NLS enhancement 
algorithm that focuses on improving identifiability and perception among CI 
listeners is proposed. The proposed NLS enhancement algorithm is evaluated based 
on identifiability performance using the CI-simulated NLS classification model. 
The proposed NLS classification framework was able to achieve near human-level 
performance with no significant effect of classification modality (model vs 
human subject) and achieved mean classification scores of 85.86% for NH 
(p = 0.3758) and 65.25% for CI (p = 0.1725). Among the four different 
feature-based methods of the proposed NLS enhancement algorithm, the 
"harmonicity"-based one achieved highest mean classification accuracy of 63.75%, 
when compared to baseline, and demonstrated significant improvement in 
performance (p = 0.0403). The resulting proposed comparative NLS classification 
framework contributes toward (i) advancement of NLS recognition studies, (ii) 
mitigation of CI user recruitment constraints and listener evaluation with NH 
listeners, (iii) development of a community shared testbed for comparative NLS 
studies, and (iv) advancement of NLS enhancement studies (identifiability and 
perceptual factors) among CI listeners.

DOI: 10.1121/10.0014955
PMCID: PMC9637023
PMID: 36456299 [Indexed for MEDLINE]


218. Trends Hear. 2015 Dec 30;19:2331216515618609. doi: 10.1177/2331216515618609.

Comparing Binaural Pre-processing Strategies III: Speech Intelligibility of 
Normal-Hearing and Hearing-Impaired Listeners.

Völker C(1), Warzybok A(2), Ernst SM(2).

Author information:
(1)Abteilung Medizinische Physik, Carl von Ossietzky Universität Oldenburg, 
Germany Cluster of Excellence "Hearing4all," Oldenburg, Germany 
christoph.voelker@uni-oldenburg.de.
(2)Abteilung Medizinische Physik, Carl von Ossietzky Universität Oldenburg, 
Germany Cluster of Excellence "Hearing4all," Oldenburg, Germany.

A comprehensive evaluation of eight signal pre-processing strategies, including 
directional microphones, coherence filters, single-channel noise reduction, 
binaural beamformers, and their combinations, was undertaken with normal-hearing 
(NH) and hearing-impaired (HI) listeners. Speech reception thresholds (SRTs) 
were measured in three noise scenarios (multitalker babble, cafeteria noise, and 
single competing talker). Predictions of three common instrumental measures were 
compared with the general perceptual benefit caused by the algorithms. The 
individual SRTs measured without pre-processing and individual benefits were 
objectively estimated using the binaural speech intelligibility model. Ten 
listeners with NH and 12 HI listeners participated. The participants varied in 
age and pure-tone threshold levels. Although HI listeners required a better 
signal-to-noise ratio to obtain 50% intelligibility than listeners with NH, no 
differences in SRT benefit from the different algorithms were found between the 
two groups. With the exception of single-channel noise reduction, all algorithms 
showed an improvement in SRT of between 2.1 dB (in cafeteria noise) and 4.8 dB 
(in single competing talker condition). Model predictions with binaural speech 
intelligibility model explained 83% of the measured variance of the individual 
SRTs in the no pre-processing condition. Regarding the benefit from the 
algorithms, the instrumental measures were not able to predict the perceptual 
data in all tested noise conditions. The comparable benefit observed for both 
groups suggests a possible application of noise reduction schemes for listeners 
with different hearing status. Although the model can predict the individual 
SRTs without pre-processing, further development is necessary to predict the 
benefits obtained from the algorithms at an individual level.

© The Author(s) 2015.

DOI: 10.1177/2331216515618609
PMCID: PMC4771033
PMID: 26721922 [Indexed for MEDLINE]


219. Laryngoscope. 2011 Aug;121(8):1810-7. doi: 10.1002/lary.21844.

Cluster analysis of auditory and vestibular test results in definite Menière's 
disease.

Montes-Jovellar L(1), Guillen-Grima F, Perez-Fernandez N.

Author information:
(1)Department of Otorhinolaryngology, Clínica Universidad de Navarra, University 
Hospital and Medical School, University of Navarra, Navarra, Spain.

OBJECTIVES/HYPOTHESIS: To determine whether patients with Menière's disease can 
be grouped into distinct subtypes based on a cluster analysis of distinct 
disease parameters.
STUDY DESIGN: Prospective study at a tertiary center associated with a 
university hospital.
METHODS: The study included 153 patients diagnosed with unilateral definite 
Menière's disease. The main variables employed were taken from auditory, 
vestibular, posturographic, and disability assessments.
RESULTS: A four-cluster solution best fitted the data. Each cluster represented 
a distinct patient profile. Cluster 1 patients (13.1%) were the eldest, with the 
worst hearing bilaterally and good vestibular function but with a significant 
postural impact and a low level of disability. Cluster 2 patients (41.2%) were 
the least affected in all the parameters that were close to normal. Cluster 3 
patients (34.6%) were the most affected, experiencing frequent and intense 
vertigo attacks, and they were visually dependent. Cluster 4 patients (11.1%) 
had strong asymmetric hearing between both ears and the most uncompensated 
vestibular deficit; they were moderately disabled.
CONCLUSIONS: We have identified four distinct profiles of patients with definite 
Menière's disease that we consider as "mildly active elderly," "mildly active 
young," "active compensated," and "active uncompensated." We have demonstrated 
that only in a restricted population of patients can the American Academy of 
Otolaryngology-Head and Neck Surgery staging system provide analysis of subtypes 
of the disease.

Copyright © 2011 The American Laryngological, Rhinological, and Otological 
Society, Inc.

DOI: 10.1002/lary.21844
PMID: 21792974 [Indexed for MEDLINE]


220. Hear Res. 2016 Mar;333:77-86. doi: 10.1016/j.heares.2016.01.006. Epub 2016 Jan 
15.

Prevalence and audiological profiles of GJB2 mutations in a large collective of 
hearing impaired patients.

Burke WF(1), Warnecke A(2), Schöner-Heinisch A(3), Lesinski-Schiedat A(4), Maier 
H(2), Lenarz T(2).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence, Hearing4All, Germany. Electronic address: 
burke.william@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence, Hearing4All, Germany.
(3)Institute for Human Genetics, Hannover Medical School, Hannover, Germany.
(4)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.

Mutations in the GJB2 gene are known to represent the commonest cause of 
hereditary and congenital hearing loss. In this study, a complete sequencing of 
the GJB2 gene in a cohort of 506 patients from a single, large cochlear implant 
program in Europe was performed. Audiological testing for those patients who 
could actively participate was performed using pure tone audiometry (PTA). Those 
unable to undergo PTA were measured using click-auditory brainstem response 
(ABR). Data analysis was performed to determine genotype-phenotype correlations 
of the mutational status vs. audiological profiles and vs. age at the time of 
presentation. An overall prevalence of biallelic mutations of 13.4% was found 
for the total collective. When subsets of younger patients were examined, the 
prevalence increased to 27% of those up to age 18 and 35% of those up to age 
5 at the time of testing, respectively. This increase was found to be highly 
significant (p < 0.001). Analysis of the mean PTA thresholds revealed a strong 
correlation between allele combination status and mean PTA (p = 0.021). The 
prevalence of simple heterozygotes was found to be approximately 10.1%, which is 
around 3.3 times the value expected in the general population. As GJB2 follows a 
recessive pattern of inheritance, the question arises as to why such a large 
fraction of simple heterozygotes was observed among the hearing impaired 
patients included in this study.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.01.006
PMID: 26778469 [Indexed for MEDLINE]


221. Int J Audiol. 2022 Dec;61(12):1003-1017. doi: 10.1080/14992027.2021.2009923. 
Epub 2021 Dec 9.

Premium versus entry-level hearing aids: using group concept mapping to 
investigate the drivers of preference.

Saleh HK(1)(2), Folkeard P(2), Van Eeckhoutte M(2)(3)(4), Scollie S(2)(5).

Author information:
(1)Health & Rehabilitation Sciences, Western University, London, Ontario, 
Canada.
(2)National Centre for Audiology, Western University, London, Ontario, Canada.
(3)Hearing Systems, Department of Health Technology, Technical University of 
Denmark, Kongens, Lyngby.
(4)Ear, Nose, Throat (ENT) & Audiology Clinic, Rigshospitalet, Copenhagen 
University Hospital, Denmark.
(5)Communication Sciences and Disorders, Faculty of Health Sciences, Western 
University, London, Ontario, Canada.

OBJECTIVES: To investigate the difference in outcome measures and drivers of 
user preference between premium and entry-level hearing aids using group concept 
mapping.
DESIGN: A single-blind crossover trial was conducted. Aided behavioural outcomes 
measured were loudness rating, speech/consonant recognition, and speech quality. 
Preference between hearing aids was measured with a 7-point Likert scale. Group 
concept mapping was utilised to investigate preference results. Participants 
generated statements based on what influenced their preferences. These were 
sorted into categories with underlying themes. Participants rated each statement 
on a 5-point Likert scale of importance.
STUDY SAMPLE: Twenty-three adult participants (mean: 62.4 years; range: 24-78) 
with mild to moderately severe bilateral SNHL (PTA500-4000 Hz > 20 dB HL).
RESULTS: A total of 83 unique statements and nine distinct clusters, with 
underlying themes driving preference, were generated. Clusters that differed 
significantly in importance between entry-level and premium hearing aid choosers 
were: Having access to smartphone application-based user-controlled settings, 
the ability to stream calls and music, and convenience features such as 
accessory compatibility.
CONCLUSION: This study has identified non-signal-processing factors which 
significantly influenced preference for a premium hearing aid over an 
entry-level hearing aid, indicating the importance of these features as drivers 
of user preference.

DOI: 10.1080/14992027.2021.2009923
PMID: 34883040 [Indexed for MEDLINE]


222. Otol Neurotol. 2020 Jul;41(6):736-744. doi: 10.1097/MAO.0000000000002633.

Single-Sided Deafness-Outcomes of Three Interventions for Profound Unilateral 
Sensorineural Hearing Loss: A Randomized Clinical Trial.

Fogels J(1)(2)(3), Jönsson R(4), Sadeghi A(1)(2)(3), Flynn M(5), Flynn T(6).

Author information:
(1)Division of Audiology, Department of Health and Rehabilitation, Institute of 
Neuroscience and Physiology, Sahlgrenska Academy, University of Gothenburg, 
Sweden.
(2)Region Västra Götaland, Habilitation & Health, Hearing Organisation, 
Gothenburg, Sweden.
(3)Division of Audiology, Department of Health and Rehabilitation, Institute of 
Neuroscience and Physiology, Sahlgrenska Academy, University of Gothenburg.
(4)Department of Otorhinolaryngology, Institute of Clinical Science, Sahlgrenska 
Academy, University of Gothenburg, Gothenburg, Sweden.
(5)Better Health, Healthcare and Treatment Global Impact Cluster, Research and 
Innovation, University of Newcastle, Callaghan, Australia.
(6)School of Humanities and Social Science, Faculty of Education and Arts, 
University of New Castle, Australia.

OBJECTIVE: A comparison of three interventions for profound unilateral 
sensorineural hearing loss.
STUDY DESIGN: Prospective, crossover randomized clinical trial.
PARTICIPANTS: Fifteen participants with profound unilateral sensorineural 
hearing loss.
INTERVENTIONS: Three potential technical interventions were compared: Bone 
Conduction Device on softband, Contralateral Routing of Signal (CROS), and 
Remote Microphone . Each intervention was randomly trialed for a period of 3 
weeks, separated by a 1 week washout period.
OUTCOME MEASURES: Speech in noise recognition test performed under four 
conditions (lateral noise poorer ear, lateral noise better ear, speech poorer 
ear, speech better ear). Standardized questionnaires (Abbreviated Profile of 
Hearing Aid Benefit, Bern Benefit in Single Sided Deafness Questionnaire, and 
Speech, Spatial, and Other Qualities 12) were used to evaluate amplification 
benefit at baseline and following each intervention.
RESULTS: The use of remote microphone provided the best results in the speech 
recognition in noise test. A benefit in some signal-to-noise ratios was 
presented of the CROS over bone conduction device on softband in the Speech Poor 
Ear condition. On questionnaires of benefit, participants did not rate a 
particular intervention as significantly better than any other. Following the 
study, CROS was the intervention preferred by the 8 of 15 participants (53%). 
The majority of participants (80%) chose to continue with an intervention rather 
than no treatment.
CONCLUSION: The use of all interventions resulted in increased performance in 
speech recognition in noise and rated higher on subjective benefits in 
comparison with baseline. People with SSD are a heterogeneous population when 
considering perceived difficulties. Future research should focus on segmenting 
the population of SSD depending on factors such as etiology, high frequency loss 
in the better ear, and age of acquired loss for the poorer ear. This 
stratification may possibly increase the benefit for the patient in terms of 
more individual-based clinical routines.

DOI: 10.1097/MAO.0000000000002633
PMID: 32574478 [Indexed for MEDLINE]


223. Int J Audiol. 2015;54 Suppl 2:80-7. doi: 10.3109/14992027.2015.1070309. Epub 
2015 Aug 28.

Characteristics and international comparability of the Finnish matrix sentence 
test in cochlear implant recipients.

Dietz A(1), Buschermöhle M(2)(3), Sivonen V(4), Willberg T(1), Aarnisalo AA(4), 
Lenarz T(3)(5), Kollmeier B(2)(3)(6).

Author information:
(1)a * Department of Otorhinolaryngology , Kuopio University Hospital , Kuopio , 
Finland.
(2)b HörTech gGmbH , Oldenburg , Germany.
(3)c Cluster of Excellence, 'Hearing4all' , Oldenburg & Hannover , Germany.
(4)d Department of Otorhinolaryngology , Helsinki University Central Hospital , 
Helsinki , Finland.
(5)e Department of Otorhinolaryngology , Head & Neck Surgery , Medizinische 
Hochschule Hannover , Germany.
(6)f Carl von Ossietzky Universität Oldenburg, Medizinische Physik , Oldenburg , 
Germany.

OBJECTIVES: The first Finnish sentence-based speech test in noise--the Finnish 
matrix sentence test--was recently developed. The aim of this study was to 
determine the characteristics of the new test with respect to test-retest 
reliability, speech recognition curve, and international comparability in 
Finnish cochlear implant (CI) recipients.
DESIGN: The speech reception thresholds (SRT) were measured by means of an 
adaptive test procedure and compared with the results of the traditional Finnish 
word test. Additional measurements for concurrent slope and SRT estimation were 
conducted to determine the speech recognition curve and to check the test-retest 
reliability.
STUDY SAMPLE: The measurements were performed on 78 Finnish CI recipients. In a 
subset of 25 patients, additional measurements for test-retest reliability and 
slope determination were performed.
RESULTS: The mean SRT was -3.5 ± 1.7 dB SNR, with only a weak correlation with 
the Finnish word test. Test-retest reliability was within ± 1 dB and the mean 
slope of the speech recognition curve was 14.6 ± 3.6 %/dB. The rehabilitation 
results were similar to the results published for the German matrix test.
CONCLUSIONS: The Finnish matrix test was found to be suitable and efficient in 
CI recipients with similar characteristics as the German matrix test.

DOI: 10.3109/14992027.2015.1070309
PMID: 26364512 [Indexed for MEDLINE]


224. Audiol Neurootol. 2020;25(3):164-172. doi: 10.1159/000506067. Epub 2020 Feb 25.

Audiological Results with the SAMBA Audio Processor in Comparison to the Amadé 
for the Vibrant Soundbridge.

Zimmermann D(1), Busch S(1)(2), Lenarz T(1)(2), Maier H(3)(4).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence EXC 1077/1 "Hearing4all", Hannover, Germany.
(3)Department of Otolaryngology, Hannover Medical School, Hannover, Germany, 
Maier.Hannes@MH-Hannover.de.
(4)Cluster of Excellence EXC 1077/1 "Hearing4all", Hannover, Germany, 
Maier.Hannes@MH-Hannover.de.

BACKGROUND: Since its introduction in 1996, the Vibrant Soundbridge (VSB) has 
been upgraded with several improved generations of processors. As all systems 
are compatible, implanted patients can benefit from new technologies by 
upgrading to the newest processor type available.
OBJECTIVES: The aim of this study was to compare the performance of the new 
(current) SAMBA processor with the previous Amadé processor.
METHODS: Twenty subjects monaurally implanted with a VSB and the Amadé processor 
tested the new SAMBA processor for a trial period of 4 weeks. We measured air 
conduction and bone conduction thresholds, unaided thresholds, and aided free 
field thresholds with both devices. Speech performance in quiet using the 
Freiburg monosyllabic test at 65 dB SPL (S0) was compared. The speech 
intelligibility in noise was determined using the Oldenburg sentence test 
measured in different listening conditions (S0NVSB/S0Ncontra) and microphone 
settings (omni/directional vs. adaptive directivity).
RESULTS: Word recognition scores in quiet with the SAMBA were still 
significantly lower than with the Amadé after the 4 weeks trial period but 
improved over the following year. Speech intelligibility with the SAMBA was 
significantly better than with the Amadé in omnidirectional mode and comparable 
with the Amadé in directional mode. Hence, the adaptive directionality provides 
an advantage in difficult hearing situations such as noisy environments. The 
subjective benefit was evaluated using the Abbreviated Profile of Hearing Aid 
Benefit and the Speech, Spatial and Qualities-C questionnaire. Results of the 
questionnaires demonstrate an overall higher level of satisfaction with the new 
SAMBA speech processor than with the older processor.
CONCLUSION: The SAMBA enables similar speech perception in quiet but more 
flexible adaptation in acoustically challenging environments compared to the 
previous Amadé processor.

© 2020 S. Karger AG, Basel.

DOI: 10.1159/000506067
PMID: 32097930 [Indexed for MEDLINE]


225. Int J Pediatr Otorhinolaryngol. 2012 Sep;76(9):1332-8. doi: 
10.1016/j.ijporl.2012.06.001. Epub 2012 Jul 15.

Speech perception and cortical auditory evoked potentials in cochlear implant 
users with auditory neuropathy spectrum disorders.

Alvarenga KF(1), Amorim RB, Agostinho-Pesse RS, Costa OA, Nascimento LT, 
Bevilacqua MC.

Author information:
(1)Department of Audiology and Speech Pathology at the School of Dentistry, 
University of São Paulo, Bauru Campus, Brazil. katialv@fob.usp.br

OBJECTIVE: To characterize the P(1) component of long latency auditory evoked 
potentials (LLAEPs) in cochlear implant users with auditory neuropathy spectrum 
disorder (ANSD) and determine firstly whether they correlate with speech 
perception performance and secondly whether they correlate with other variables 
related to cochlear implant use.
METHODS: This study was conducted at the Center for Audiological Research at the 
University of São Paulo. The sample included 14 pediatric (4-11 years of age) 
cochlear implant users with ANSD, of both sexes, with profound prelingual 
hearing loss. Patients with hypoplasia or agenesis of the auditory nerve were 
excluded from the study. LLAEPs produced in response to speech stimuli were 
recorded using a Smart EP USB Jr. system. The subjects' speech perception was 
evaluated using tests 5 and 6 of the Glendonald Auditory Screening Procedure 
(GASP).
RESULTS: The P(1) component was detected in 12/14 (85.7%) children with ANSD. 
Latency of the P(1) component correlated with duration of sensorial hearing 
deprivation (*p=0.007, r=0.7278), but not with duration of cochlear implant use. 
An analysis of groups assigned according to GASP performance (k-means 
clustering) revealed that aspects of prior central auditory system development 
reflected in the P(1) component are related to behavioral auditory skills.
CONCLUSIONS: In children with ANSD using cochlear implants, the P(1) component 
can serve as a marker of central auditory cortical development and a predictor 
of the implanted child's speech perception performance.

Copyright © 2012 Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.ijporl.2012.06.001
PMID: 22796193 [Indexed for MEDLINE]


226. Trends Hear. 2016 Jul 26;20:2331216516658239. doi: 10.1177/2331216516658239.

Selecting Appropriate Tests to Assess the Benefits of Bilateral Amplification 
With Hearing Aids.

van Schoonhoven J(1), Schulte M(2), Boymans M(3), Wagener KC(2), Dreschler 
WA(3), Kollmeier B(4).

Author information:
(1)Department of Clinical and Experimental Audiology, Academic Medical Centre, 
Amsterdam, The Netherlands jvanschoonhoven@amc.nl.
(2)Hörzentrum Oldenburg GmbH, Oldenburg, Germany Cluster of Excellence 
Hearing4all, Oldenburg, Germany.
(3)Department of Clinical and Experimental Audiology, Academic Medical Centre, 
Amsterdam, The Netherlands.
(4)Hörzentrum Oldenburg GmbH, Oldenburg, Germany Cluster of Excellence 
Hearing4all, Oldenburg, Germany Medizinische Physik, Carl-von-Ossietzky 
Universität Oldenburg, Germany.

The aim of this study was to investigate the effect of bilateral hearing aids 
(HA) in subjects with mild and moderate-to-severe hearing loss. This study was 
designed as a within-subject feasibility study. Bilateral HA use was assessed 
using different laboratory tests on speech reception, listening effort, noise 
tolerance, and localization. All data were evaluated with bilateral and 
unilateral HA fittings. Forty experienced bilateral HA users were included with 
hearing impairment ranging from mild to moderate-to-severe. Subjects were 
stratified into two groups based on the degree of hearing loss. Speech reception 
in noise, listening effort, and localization tests showed a bilateral benefit 
for the moderate-to-severely hearing-impaired subjects. A bilateral benefit was 
also observed for listening effort in the mildly hearing-impaired group. The 
assessment of listening effort shows promise as a measure of bilateral HA 
benefit for mild hearing impairment. Localization and speech reception in noise 
tests provide additional value for larger losses. The next step is to compare 
experienced unilateral with bilateral HA users.

© The Author(s) 2016.

DOI: 10.1177/2331216516658239
PMCID: PMC4964154
PMID: 27460871 [Indexed for MEDLINE]


227. Biosci Biotechnol Biochem. 2022 Jul 22;86(8):1085-1094. doi: 
10.1093/bbb/zbac092.

Garland chrysanthemum consumption ameliorates age-related hearing loss in 
C57BL/6 mouse; model system to explore hearing loss prevention foods in a short 
period.

Oike H(1)(2), Tomita S(1), Koyano H(2), Azami K(1).

Author information:
(1)Food Research Institute, National Agriculture and Food Research Organization 
(NARO), 2-1-12 Kannondai, Tsukuba, Ibaraki, Japan.
(2)Research Center for Agricultural Information Technology, National Agriculture 
and Food Research Organization (NARO), 3-1-1 Kannondai, Tsukuba, Ibaraki, Japan.

Garland chrysanthemum (Glebionis coronaria L.) is an antioxidant-rich leafy 
vegetable. We found that garland chrysanthemum consumption ameliorated 
age-related hearing loss (AHL) in C57BL/6J mice, an early onset model. We also 
found that AHL progression was significantly ameliorated by three of ten 
products. Metabolome analysis of the 10 products using nuclear magnetic 
resonance (NMR) spectroscopy indicated that phytosterols may be involved in the 
amelioration of AHL. However, the direct inhibitory effect of phytosterol 
mixture on mouse AHL progression was not identified. These results suggest that 
garland chrysanthemum consumption delays AHL development in mice and its 
efficiency varies depending on the source of the product. Our findings also 
suggest that phytosterol content in garland chrysanthemum functions as an 
evaluation marker for the efficiency. Furthermore, to accelerate the search for 
foods that prevent AHL, we have used these data to develop an automatic 
threshold determination method for auditory brainstem response using machine 
learning.

© The Author(s) 2022. Published by Oxford University Press on behalf of Japan 
Society for Bioscience, Biotechnology, and Agrochemistry.

DOI: 10.1093/bbb/zbac092
PMID: 35687003 [Indexed for MEDLINE]


228. J Acoust Soc Am. 2018 Apr;143(4):2128. doi: 10.1121/1.5030918.

Better-ear glimpsing with symmetrically-placed interferers in bilateral cochlear 
implant users.

Hu H(1), Dietz M(1), Williges B(1), Ewert SD(1).

Author information:
(1)Medizinische Physik, Carl von Ossietzky Universität Oldenburg and Cluster of 
Excellence "Hearing4all," Küpkersweg 74, 26129, Oldenburg, Germany.

For a frontal target in spatially symmetrically placed interferers, normal 
hearing (NH) listeners can use "better-ear glimpsing" to select time-frequency 
segments with favorable signal-to-noise ratio in either ear. With an ideal 
monaural better-ear mask (IMBM) processing, some studies showed that NH 
listeners can reach similar performance as in the natural binaural listening 
condition, although interaural phase differences at low frequencies can further 
improve performance. In principle, bilateral cochlear implant (BiCI) listeners 
could use the same better-ear glimpsing, albeit without exploiting interaural 
phase differences. Speech reception thresholds of NH and BiCI listeners were 
measured in three interferers (speech-shaped stationary noise, nonsense speech, 
or single talker) either co-located with the target, symmetrically placed at 
±60°, or independently presented to each ear, with and without IMBM processing. 
Furthermore, a bilateral noise vocoder based on the BiCI electrodogram was used 
in the same NH listeners. Headphone presentation and direct stimulation with 
head-related transfer functions for spatialization were used in NH and BiCI 
listeners, respectively. Compared to NH listeners, both NH listeners with 
vocoder and BiCI listeners showed strongly reduced binaural benefit from spatial 
separation. However, both groups greatly benefited from IMBM processing as part 
of the stimulation strategy.

DOI: 10.1121/1.5030918
PMID: 29716260 [Indexed for MEDLINE]


229. J Acoust Soc Am. 2019 Mar;145(3):1378. doi: 10.1121/1.5093547.

A deep learning algorithm to increase intelligibility for hearing-impaired 
listeners in the presence of a competing talker and reverberation.

Healy EW(1), Delfarah M(2), Johnson EM(1), Wang D(3).

Author information:
(1)Department of Speech and Hearing Science, and Center for Cognitive and Brain 
Sciences, The Ohio State University, Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.
(3)Department of Computer Science and Engineering, and Center for Cognitive and 
Brain Sciences, The Ohio State University, Columbus, Ohio 43210, USA.

For deep learning based speech segregation to have translational significance as 
a noise-reduction tool, it must perform in a wide variety of acoustic 
environments. In the current study, performance was examined when target speech 
was subjected to interference from a single talker and room reverberation. 
Conditions were compared in which an algorithm was trained to remove both 
reverberation and interfering speech, or only interfering speech. A recurrent 
neural network incorporating bidirectional long short-term memory was trained to 
estimate the ideal ratio mask corresponding to target speech. Substantial 
intelligibility improvements were found for hearing-impaired (HI) and 
normal-hearing (NH) listeners across a range of target-to-interferer ratios 
(TIRs). HI listeners performed better with reverberation removed, whereas NH 
listeners demonstrated no difference. Algorithm benefit averaged 56 percentage 
points for the HI listeners at the least-favorable TIR, allowing these listeners 
to perform numerically better than young NH listeners without processing. The 
current study highlights the difficulty associated with perceiving speech in 
reverberant-noisy environments, and it extends the range of environments in 
which deep learning based speech segregation can be effectively applied. This 
increasingly wide array of environments includes not only a variety of 
background noises and interfering speech, but also room reverberation.

DOI: 10.1121/1.5093547
PMCID: PMC6420339
PMID: 31067936 [Indexed for MEDLINE]


230. J Proteome Res. 2017 May 5;16(5):1911-1923. doi: 10.1021/acs.jproteome.6b00986. 
Epub 2017 Apr 13.

Proteome Analysis of Human Perilymph Using an Intraoperative Sampling Method.

Schmitt HA(1)(2), Pich A(3), Schröder A(3), Scheper V(1)(2), Lilli G(1)(2), 
Reuter G(1)(2), Lenarz T(1)(2).

Author information:
(1)Department of Otolaryngology, Hannover Medical School , Carl-Neuberg-Str. 1, 
30625 Hannover, Germany.
(2)Cluster of Excellence of the German Research Foundation (DFG; "Deutsche 
Forschungsgemeinschaft") "Hearing4all", Hannover Medical School , 
Carl-Neuberg-Str. 1, 30625 Hannover, Germany.
(3)Core Facility Proteomics, Hannover Medical School , Carl-Neuberg-Str. 1, 
30625 Hannover, Germany.

The knowledge about the etiology and pathophysiology of sensorineural hearing 
loss (SNHL) is still very limited. This study aims at the improvement of 
understanding different types of SNHL by proteome analysis of human perilymph. 
Sampling of perilymph was established during inner ear surgeries (cochlear 
implantation, vestibular schwannoma surgeries), and safety of the sampling 
method was determined by checking hearing threshold with pure-tone audiometry 
postoperatively. An in-depth shot-gun proteomics approach was performed to 
identify cochlear proteins and the individual proteome in perilymph of patients. 
This method enables the identification and quantification of protein composition 
of perilymph. The proteome of 41 collected perilymph samples with volumes of 
1-12 μL was analyzed by data-dependent acquisition, resulting in overall 878 
detected protein groups. At least 203 protein groups were solely identified in 
perilymph, not in reference samples (serum, cerebrospinal fluid), displaying a 
specific protein pattern for perilymph. Samples were grouped by patient's age 
and surgery type, leading to the identification of some proteins specific to 
particular subgroups. Proteins with different abundances between different 
sample groups were subjected to classification by gene ontology annotations. The 
identified proteins might serve as biomarkers to develop tools for noninvasive 
inner ear diagnostics and to elucidate molecular profiles of SNHL.

DOI: 10.1021/acs.jproteome.6b00986
PMID: 28282143 [Indexed for MEDLINE]


231. Trends Hear. 2016 Nov 11;20:2331216516672186. doi: 10.1177/2331216516672186.

Individual Differences in Auditory Brainstem Response Wave Characteristics: 
Relations to Different Aspects of Peripheral Hearing Loss.

Verhulst S(1)(2), Jagadeesh A(3), Mauermann M(3), Ernst F(3).

Author information:
(1)Cluster of Excellence Hearing4all and Medizinische Physik, Department of 
Medical Physics and Acoustics, Oldenburg University, Oldenburg, Germany 
s.verhulst@ugent.be.
(2)Department of Information Technology, Ghent University, Technologiepark, 
Zwijnaarde, Belgium.
(3)Cluster of Excellence Hearing4all and Medizinische Physik, Department of 
Medical Physics and Acoustics, Oldenburg University, Oldenburg, Germany.

Little is known about how outer hair cell loss interacts with noise-induced and 
age-related auditory nerve degradation (i.e., cochlear synaptopathy) to affect 
auditory brainstem response (ABR) wave characteristics. Given that listeners 
with impaired audiograms likely suffer from mixtures of these hearing deficits 
and that ABR amplitudes have successfully been used to isolate synaptopathy in 
listeners with normal audiograms, an improved understanding of how different 
hearing pathologies affect the ABR source generators will improve their 
sensitivity in hearing diagnostics. We employed a functional model for human 
ABRs in which different combinations of hearing deficits were simulated and show 
that high-frequency cochlear gain loss steepens the slope of the ABR Wave-V 
latency versus intensity and amplitude versus intensity curves. We propose that 
grouping listeners according to a ratio of these slope metrics (i.e., the ABR 
growth ratio) might offer a way to factor out the outer hair cell loss deficit 
and maximally relate individual differences for constant ratios to other 
peripheral hearing deficits such as cochlear synaptopathy. We compared the model 
predictions to recorded click-ABRs from 30 participants with normal or 
high-frequency sloping audiograms and confirm the predicted relationship between 
the ABR latency growth curve and audiogram slope. Experimental ABR amplitude 
growth showed large individual differences and was compared with the Wave-I 
amplitude, Wave-V/I ratio, or the interwaveI-W latency in the same listeners. 
The model simulations along with the ABR recordings suggest that a hearing loss 
profile depicting the ABR growth ratio versus the Wave-I amplitude or Wave-V/I 
ratio might be able to differentiate outer hair cell deficits from cochlear 
synaptopathy in listeners with mixed pathologies.

© The Author(s) 2016.

DOI: 10.1177/2331216516672186
PMCID: PMC5117250
PMID: 27837052 [Indexed for MEDLINE]


232. J Acoust Soc Am. 2021 Jun;149(6):3943. doi: 10.1121/10.0005089.

An effectively causal deep learning algorithm to increase intelligibility in 
untrained noises for hearing-impaired listeners.

Healy EW(1), Tan K(2), Johnson EM(1), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, The Ohio State University, 
Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.

Real-time operation is critical for noise reduction in hearing technology. The 
essential requirement of real-time operation is causality-that an algorithm does 
not use future time-frame information and, instead, completes its operation by 
the end of the current time frame. This requirement is extended currently 
through the concept of "effectively causal," in which future time-frame 
information within the brief delay tolerance of the human speech-perception 
mechanism is used. Effectively causal deep learning was used to separate speech 
from background noise and improve intelligibility for hearing-impaired 
listeners. A single-microphone, gated convolutional recurrent network was used 
to perform complex spectral mapping. By estimating both the real and imaginary 
parts of the noise-free speech, both the magnitude and phase of the estimated 
noise-free speech were obtained. The deep neural network was trained using a 
large set of noises and tested using complex noises not employed during 
training. Significant algorithm benefit was observed in every condition, which 
was largest for those with the greatest hearing loss. Allowable delays across 
different communication settings are reviewed and assessed. The current work 
demonstrates that effectively causal deep learning can significantly improve 
intelligibility for one of the largest populations of need in challenging 
conditions involving untrained background noises.

DOI: 10.1121/10.0005089
PMCID: PMC8186949
PMID: 34241481 [Indexed for MEDLINE]


233. J Int Adv Otol. 2021 Sep;17(5):380-386. doi: 10.5152/iao.2021.9337.

Cross-Modal Cortical Activity in the Brain Can Predict Cochlear Implantation 
Outcome in Adults: A Machine Learning Study.

Kyong JS(1), Suh MW(2), Han JJ(3), Park MK(2), Noh TS(2), Oh SH(2), Lee JH(2).

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University, Seoul, Korea; Audiology Institute, Hallym University of Graduate 
Studies, Seoul, Korea.
(2)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University, Seoul, Korea.
(3)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University, Seoul, Korea; Department of Otorhinolaryngology-Head and Neck 
Surgery, Soonchunhyang University Hospital, Seoul, Korea.

OBJECTIVES: Prediction of cochlear implantation (CI) outcome is often difficult 
because outcomes vary among patients. Though the brain plasticity across 
modalities during deafness is associated with individual CI outcomes, 
longitudinal observations in multiple patients are scarce. Therefore, we sought 
a prediction system based on cross-modal plasticity in a longitudinal study with 
multiple patients.
METHODS: Classification of CI outcomes between excellent or poor was tested 
based on the features of brain cross-modal plasticity, measured using 
event-related responses and their corresponding electromagnetic sources. A 
machine learning estimation model was applied to 13 datasets from 3 patients 
based on linear supervised training. Classification efficiency was evaluated 
comparing prediction accuracy, sensitivity/specificity, total mis-classification 
cost, and training time among feature set conditions.
RESULTS: Combined feature sets with the sensor and source levels dramatically 
improved classification accuracy between excellent and poor outcomes. 
Specifically, the tactile feature set best explained CI outcome (accuracy, 98.83 
± 2.57%; sensitivity, 98.00 ± 0.01%; specificity, 98.15 ± 4.26%; total 
misclassification cost, 0.17 ± 0.38; training time, 0.51 ± 0.09 sec), followed 
by the visual feature (accuracy, 93.50 ± 4.89%; sensitivity, 89.17 ± 8.16%; 
specificity, 98.00 ± 0.01%; total misclassification cost, 0.65 ± 0.49; training 
time, 0.38 ± 0.50 sec).
CONCLUSION: Individual tactile and visual processing in the brain best 
classified the current status when classified by combined sensor-source level 
features. Our results suggest that cross-modal brain plasticity due to deafness 
may provide a basis for classifying the status. We expect this novel method to 
contribute to the evaluation and prediction of CI outcomes.

DOI: 10.5152/iao.2021.9337
PMCID: PMC8975390
PMID: 34617886 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of Interest: The authors have no 
conflict of interest to declare.


234. Int J Numer Method Biomed Eng. 2022 May;38(5):e3582. doi: 10.1002/cnm.3582. Epub 
2022 Feb 21.

The effects of noise-induced hair cell lesions on cochlear electromechanical 
responses: A computational approach using a biophysical model.

Saremi A(1), Stenfelt S(2).

Author information:
(1)Department of Applied Physics and Electronics, Umeå University, Umeå, Sweden.
(2)Department of Biomedical and Clinical Sciences, Linköping University, 
Linköping, Sweden.

A biophysically inspired signal processing model of the human cochlea is 
deployed to simulate the effects of specific noise-induced inner hair cell (IHC) 
and outer hair cell (OHC) lesions on hearing thresholds, cochlear compression, 
and the spectral and temporal features of the auditory nerve (AN) coding. The 
model predictions were evaluated by comparison with corresponding data from 
animal studies as well as human clinical observations. The hearing thresholds 
were simulated for specific OHC and IHC damages and the cochlear nonlinearity 
was assessed at 0.5 and 4 kHz. The tuning curves were estimated at 1 kHz and the 
contributions of the OHC and IHC pathologies to the tuning curve were 
distinguished by the model. Furthermore, the phase locking of AN spikes were 
simulated in quiet and in presence of noise. The model predicts that the phase 
locking drastically deteriorates in noise indicating the disturbing effect of 
background noise on the temporal coding in case of hearing impairment. Moreover, 
the paper presents an example wherein the model is inversely configured for 
diagnostic purposes using a machine learning optimization technique (Nelder-Mead 
method). Accordingly, the model finds a specific pattern of OHC lesions that 
gives the audiometric hearing loss measured in a group of noise-induced hearing 
impaired humans.

© 2022 The Authors. International Journal for Numerical Methods in Biomedical 
Engineering published by John Wiley & Sons Ltd.

DOI: 10.1002/cnm.3582
PMCID: PMC9286811
PMID: 35150464 [Indexed for MEDLINE]


235. Int J Audiol. 2018 Jun;57(sup3):S92-S104. doi: 10.1080/14992027.2016.1220680. 
Epub 2016 Sep 6.

Modifications of the MUlti stimulus test with Hidden Reference and Anchor 
(MUSHRA) for use in audiology.

Völker C(1)(2), Bisitz T(3), Huber R(3), Kollmeier B(1)(2), Ernst SMA(1)(2).

Author information:
(1)a Abteilung Medizinische Physik , Carl von Ossietzky Universität Oldenburg , 
Oldenburg , Germany.
(2)b Cluster of Excellence 'Hearing4all' , Oldenburg , Germany , and.
(3)c Centre of Competence HörTech gGmbH , Oldenburg , Germany.

OBJECTIVE: Two modifications of the standardised MUlti Stimulus test with Hidden 
Reference and Anchor (MUSHRA), namely MUSHRA simple and MUSHRA drag&drop, were 
implemented and evaluated together with the original test method. The 
modifications were designed to maximise the accessibility of MUSHRA for elderly 
and technically non-experienced listeners, who constitute the typical target 
group in hearing aid evaluation.
DESIGN: Three MUSHRA variants were assessed based on subjective and objective 
measures, e.g. test-retest reliability, discrimination ability, time exposure 
and overall preference. With each method, participants repeated the task to rate 
the quality of several hearing aid algorithms four times.
STUDY SAMPLE: Fifty listeners grouped into five subject classes were tested, 
including elderly and technically non-experienced participants with normal and 
impaired hearing. Normal-hearing, technically experienced students served as 
controls.
RESULTS: Both modifications can be used to obtain compatible rating results. 
Both were preferred over the classical MUSHRA procedure. Technically experienced 
listeners performed best with the modification MUSHRA drag&drop.
CONCLUSIONS: The comprehensive comparison of the MUSHRA variants demonstrates 
that the intuitive modification MUSHRA drag&drop can be generally recommended. 
However, considering e.g. specific evaluation demands, we suggest a 
differentiated and careful application of listening test methods.

DOI: 10.1080/14992027.2016.1220680
PMID: 27598985 [Indexed for MEDLINE]


236. Trends Hear. 2019 Jan-Dec;23:2331216519833567. doi: 10.1177/2331216519833567.

Monitoring of the Inner Ear Function During and After Cochlear Implant Insertion 
Using Electrocochleography.

Haumann S(1)(2), Imsiecke M(1), Bauernfeind G(1)(2), Büchner A(1)(2), 
Helmstaedter V(1)(2), Lenarz T(1)(2), Salcher RB(1)(2).

Author information:
(1)1 Department of Otolaryngology, Hannover Medical School, Germany.
(2)2 Cluster of Excellence Hearing4All, Hannover, Germany.

To preserve residual hearing during cochlear implant (CI) surgery, it is 
desirable to use intraoperative monitoring of inner ear function (cochlear 
monitoring), especially during electrode insertion. A promising method is 
electrocochleography (ECochG). Within this project, the relations between 
ongoing responses (ORs), recorded extra- and intracochlearly (EC and IC), and 
preservation of residual hearing were investigated. Before, during, and after 
insertion of hearing preservation electrodes, intraoperative ECochG recordings 
were performed EC using a cotton wick electrode and after insertion also IC 
using the CI electrode (MED-EL) and a research software tool. The stimulation 
was delivered acoustically using low frequency tone bursts. The recordings were 
conducted in 10 adult CI recipients. The amplitudes of IC ORs were detected to 
be larger than EC ORs. Intraoperative EC thresholds correlated highly to 
preoperative audiometric thresholds at 1000 Hz, IC thresholds highly at 250 Hz 
and 500 Hz. The correlations of both intraoperative ECochG recordings to 
postoperative pure tone thresholds were low. When measured postoperatively at 
the same appointments, IC OR thresholds correlated highly to audiometric pure 
tone thresholds. For all patients, it was possible to record ORs during or 
directly after electrode insertion. Consequently, we conclude that we did not 
observe any cases with severe IC trauma. Delayed hearing loss could not be 
predicted with our method. Nevertheless, intraoperative ECochG recordings are a 
promising tool to gain further insight into mechanisms impacting residual 
hearing. Postoperatively recorded IC OR thresholds seem to be a reliable tool 
for frequency specific hearing threshold estimation.

DOI: 10.1177/2331216519833567
PMCID: PMC6435875
PMID: 30909815 [Indexed for MEDLINE]


237. Int J Audiol. 2018 Jun;57(sup3):S130-S138. doi: 10.1080/14992027.2017.1378931. 
Epub 2017 Sep 25.

Analysis of compressive properties of the BioAid hearing aid algorithm.

Clark NR(1), Lecluyse W(2), Jürgens T(3).

Author information:
(1)a Mimi Hearing Technologies GmbH , Berlin , Germany.
(2)b Department of Children, Young People and Education , University Campus 
Suffolk , Ipswich , UK , and.
(3)c Medizinische Physik, Forschungszentrum Neurosensorik, and Cluster of 
Excellence "Hearing4all" , Carl-von-Ossietzky Universität Oldenburg , Oldenburg 
, Germany.

OBJECTIVE: This technical paper describes a biologically inspired hearing aid 
algorithm based on a computer model of the peripheral auditory system simulating 
basilar membrane compression, reflexive efferent feedback and its resulting 
properties.
DESIGN: Two evaluations were conducted on the core part of the algorithm, which 
is an instantaneous compression sandwiched between the attenuation and envelope 
extraction processes of a relatively slow feedback compressor.
STUDY SAMPLE: The algorithm's input/output (I/O) function was analysed for 
different stationary (ambient) sound levels, and the algorithm's response to 
transient sinusoidal tone complexes was analysed and contrasted to that of a 
reference dynamic compressor.
RESULTS: The algorithm's emergent properties are: (1) the I/O function adapts to 
the average sound level such that processing is linear for levels close to the 
ambient sound level and (2) onsets of transient signals are marked across time 
and frequency.
CONCLUSION: Adaptive linearisation and onset marking, as inherent compressive 
features of the algorithm, provide potentially beneficial features to 
hearing-impaired listeners with a relatively simple circuit. The algorithm 
offers a new, biological perspective on hearing aid amplification.

DOI: 10.1080/14992027.2017.1378931
PMID: 28942716 [Indexed for MEDLINE]


238. Ear Hear. 2010 Apr;31(2):202-12. doi: 10.1097/AUD.0b013e3181c62263.

Slight-mild sensorineural hearing loss in children: audiometric, clinical, and 
risk factor profiles.

Cone BK(1), Wake M, Tobin S, Poulakis Z, Rickards FW.

Author information:
(1)Department of Speech, Language and Hearing Sciences, University of Arizona, 
Tucson, Arizona, USA. conewess@u.arizona.edu

OBJECTIVES: Slight or mild hearing loss has been posited as a factor affecting 
speech, language, learning, and academic outcomes, but the risk factors for 
slight-mild sensorineural hearing loss (SNHL) have not been ascertained. The two 
specific aims for this research were (1) to describe the audiometric and 
clinical characteristics of children identified with slight-mild bilateral SNHL 
and (2) to compare children with slight-mild SNHL with those with normal hearing 
(NH) with respect to potential risk factors for congenital or acquired for 
hearing loss.
DESIGN: A cross-sectional cluster sample survey of 6581 children enrolled in 
years 1 and 5 of Australian elementary school was completed. Children were 
screened for slight-mild SNHL, defined as a low- and/or high-frequency pure-tone 
average of 16 to 40 dB HL in the better ear, with air-bone gaps <10 dB. Children 
who did not pass the screen received air and bone conduction threshold and 
tympanometry tests to determine the type and degree of hearing loss. The parents 
of every child who participated in this study completed a questionnaire, before 
the hearing screening, to ascertain possible risk indicators. The questionnaire 
included items regarding the family's demographics, hearing status of family 
members, the presence of risk factors, and parental concern regarding the 
child's hearing.
RESULTS: Fifty-five children with slight-mild SNHL and 5490 with NH were 
identified. Of the group with SNHL, 39 children had a slight loss (16 to 25 dB 
HL) and 16 had a mild loss (26 to 40 dB HL). The majority of the losses were 
bilateral and symmetrical, and the mean pure-tone average for the better ear for 
all 55 children was 22.4 dB HL (SD, 5.2). The most prevalent risk factor was 
"neonatal intensive care unit/special care nursery admission," which was 
reported for 12.5% of the SNHL and 8.4% of the NH group. Reported use of 
personal stereos was a significant risk factor with an odds ratio of 1.7 (95% 
confidence interval = 1.0 to 3.0, p = 0.05). The questions relating to parental 
concern for their child's hearing had low sensitivity (<30%) and very low 
positive predictive values (<3%) for detecting slight-mild SNHL.
CONCLUSIONS: Slight-mild SNHL had a prevalence of 0.88% among the school-aged 
population sampled, with the majority of these children exhibiting bilateral, 
symmetrical audiometric configurations. Conventional risk factors for hearing 
loss were not strongly predictive of slight-mild SNHL nor were parental concerns 
about the child's hearing ability. The association between slight-mild SNHL and 
the parent report of personal stereo use suggests that this type of noise 
exposure may be a risk factor for acquired hearing loss. This seems to be the 
first documentation of such an association in a large sample of young children.

DOI: 10.1097/AUD.0b013e3181c62263
PMID: 20054279 [Indexed for MEDLINE]


239. Elife. 2019 Jan 18;8:e40946. doi: 10.7554/eLife.40946.

Cellular cartography of the organ of Corti based on optical tissue clearing and 
machine learning.

Urata S(1)(2), Iida T(1), Yamamoto M(3), Mizushima Y(2), Fujimoto C(2), 
Matsumoto Y(2), Yamasoba T(2), Okabe S(1).

Author information:
(1)Department of Cellular Neurobiology, Graduate School of Medicine, The 
University of Tokyo, Tokyo, Japan.
(2)Department of Otolaryngology, Graduate School of Medicine, The University of 
Tokyo, Tokyo, Japan.
(3)Department of Nephrology, Graduate School of Medicine, Kyoto University, 
Kyoto, Japan.

The highly organized spatial arrangement of sensory hair cells in the organ of 
Corti is essential for inner ear function. Here, we report a new analytical 
pipeline, based on optical clearing of tissue, for the construction of a 
single-cell resolution map of the organ of Corti. A sorbitol-based optical 
clearing method enabled imaging of the entire cochlea at subcellular resolution. 
High-fidelity detection and analysis of all hair cell positions along the entire 
longitudinal axis of the organ of Corti were performed automatically by machine 
learning-based pattern recognition. Application of this method to samples from 
young, adult, and noise-exposed mice extracted essential information regarding 
cellular pathology, including longitudinal and radial spatial characteristics of 
cell loss, implying that multiple mechanisms underlie clustered cell loss. Our 
method of cellular mapping is effective for system-level phenotyping of the 
organ of Corti under both physiological and pathological conditions.

© 2019, Urata et al.

DOI: 10.7554/eLife.40946
PMCID: PMC6338463
PMID: 30657453 [Indexed for MEDLINE]

Conflict of interest statement: SU, TI, MY, YM, CF, YM, TY, SO No competing 
interests declared


240. J Acoust Soc Am. 2016 May;139(5):2604. doi: 10.1121/1.4948445.

Large-scale training to increase speech intelligibility for hearing-impaired 
listeners in novel noises.

Chen J(1), Wang Y(1), Yoho SE(2), Wang D(1), Healy EW(2).

Author information:
(1)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.
(2)Department of Speech and Hearing Science, The Ohio State University, 
Columbus, Ohio 43210, USA.

Supervised speech segregation has been recently shown to improve human speech 
intelligibility in noise, when trained and tested on similar noises. However, a 
major challenge involves the ability to generalize to entirely novel noises. 
Such generalization would enable hearing aid and cochlear implant users to 
improve speech intelligibility in unknown noisy environments. This challenge is 
addressed in the current study through large-scale training. Specifically, a 
deep neural network (DNN) was trained on 10 000 noises to estimate the ideal 
ratio mask, and then employed to separate sentences from completely new noises 
(cafeteria and babble) at several signal-to-noise ratios (SNRs). Although the 
DNN was trained at the fixed SNR of - 2 dB, testing using hearing-impaired 
listeners demonstrated that speech intelligibility increased substantially 
following speech segregation using the novel noises and unmatched SNR conditions 
of 0 dB and 5 dB. Sentence intelligibility benefit was also observed for 
normal-hearing listeners in most noisy conditions. The results indicate that 
DNN-based supervised speech segregation with large-scale training is a very 
promising approach for generalization to new acoustic environments.

DOI: 10.1121/1.4948445
PMCID: PMC5392064
PMID: 27250154 [Indexed for MEDLINE]


241. J Acoust Soc Am. 2013 Dec;134(6):4458. doi: 10.1121/1.4824700.

Integrating cognitive and peripheral factors in predicting hearing-aid 
processing effectiveness.

Kates JM(1), Arehart KH(1), Souza PE(2).

Author information:
(1)Department of Speech Language and Hearing Sciences, University of Colorado, 
Boulder, Colorado 80309.
(2)Department of Communication Sciences and Disorders and Knowles Hearing 
Center, Northwestern University, Evanston, Illinois 60201.

Individual factors beyond the audiogram, such as age and cognitive abilities, 
can influence speech intelligibility and speech quality judgments. This paper 
develops a neural network framework for combining multiple subject factors into 
a single model that predicts speech intelligibility and quality for a nonlinear 
hearing-aid processing strategy. The nonlinear processing approach used in the 
paper is frequency compression, which is intended to improve the audibility of 
high-frequency speech sounds by shifting them to lower frequency regions where 
listeners with high-frequency loss have better hearing thresholds. An ensemble 
averaging approach is used for the neural network to avoid the problems 
associated with overfitting. Models are developed for two subject groups, one 
having nearly normal hearing and the other mild-to-moderate sloping losses.

DOI: 10.1121/1.4824700
PMCID: PMC3874061
PMID: 25669257 [Indexed for MEDLINE]


242. Int J Audiol. 2017 Jun;56(6):417-423. doi: 10.1080/14992027.2017.1296595. Epub 
2017 Mar 5.

Cochlear implant effectiveness in postlingual single-sided deaf individuals: 
what's the point?

Finke M(1)(2), Bönitz H(1), Lyxell B(3)(4)(5), Illg A(1).

Author information:
(1)a Department of Otolaryngology , Hannover Medical School , Hannover , 
Germany.
(2)b Cluster of Excellence "Hearing4all" , Oldenburg & Hannover , Germany.
(3)c Linnaeus Centre HEAD , Linköping University , Linköping , Sweden.
(4)d Department of Behavioral Sciences and Learning , Linköping University , 
Linköping , Sweden , and.
(5)e The Swedish Institute for Disability Research , Linköping University , 
Linköping , Sweden.

OBJECTIVES: By extending the indication criteria for cochlear implants (CI), the 
population of CI candidates increased in age, as well as range and type of 
hearing loss. This qualitative study identified factors that contributed to seek 
CI treatment in single-sided deaf individuals and gained insights how 
single-sided deafness (SSD) and hearing with a CI affect their lives.
DESIGN: An open-ended questionnaire and a standardised inventory (IOI-HA) were 
used. Qualitative data reflecting the reasons to seek CI treatment and the 
individual experiences after CI switch-on were collected.
STUDY SAMPLE: A total of 19 postlingually deafened single-sided deaf CI users.
RESULTS: Participants use their CI daily and stated that their life satisfaction 
increased since CI activation. The analysis of the qualitative data revealed 
four core categories: sound localisation, tinnitus and noise sensitivity, fear 
to lose the second ear and quality of life.
CONCLUSIONS: Our results show how strongly and diversely quality of hearing and 
quality of life is affected by acquired SSD and improved after CI activation. 
Our data suggest that the fear of hearing loss (HL) on the normal hearing (NH) 
ear is an important but so far neglected reason to seek treatment with a CI in 
individuals with postlingual SSD.

DOI: 10.1080/14992027.2017.1296595
PMID: 28635507 [Indexed for MEDLINE]


243. Int J Mol Sci. 2023 Dec 7;24(24):17240. doi: 10.3390/ijms242417240.

Predicting the Impact of OTOF Gene Missense Variants on Auditory Neuropathy 
Spectrum Disorder.

Dmitriev DA(1), Shilov BV(1), Polunin MM(2), Zadorozhny AD(1), Lagunin AA(1)(3).

Author information:
(1)Department of Bioinformatics, Medico-Biological Faculty, Pirogov Russian 
National Research Medical University, Moscow 117997, Russia.
(2)Department of Otorhinolaryngology, Faculty of Pediatrics, Pirogov Russian 
National Research Medical University, Moscow 117997, Russia.
(3)Department of Bioinformatics, Institute of Biomedical Chemistry, Moscow 
119121, Russia.

Auditory neuropathy spectrum disorder (ANSD) associated with mutations of the 
OTOF gene is one of the common types of sensorineural hearing loss of a 
hereditary nature. Due to its high genetic heterogeneity, ANSD is considered one 
of the most difficult hearing disorders to diagnose. The dataset from 270 known 
annotated single amino acid substitutions (SAV) related to ANSD was created. It 
was used to estimate the accuracy of pathogenicity prediction using the known 
(from dbNSFP4.4) method and a new one. The new method (ConStruct) for the 
creation of the protein-centric classification model is based on the use of 
Random Forest for the analysis of missense variants in exons of the OTOF gene. A 
system of predictor variables was developed based on the modern understanding of 
the structure and function of the otoferlin protein and reflecting the location 
of changes in the tertiary structure of the protein due to mutations in the OTOF 
gene. The conservation values of nucleotide substitutions in genomes of 100 
vertebrates and 30 primates were also used as variables. The average prediction 
of balanced accuracy and the AUC value calculated by the 5-fold cross-validation 
procedure were 0.866 and 0.903, respectively. The model shows good results for 
interpreting data from the targeted sequencing of the OTOF gene and can be 
implemented as an auxiliary tool for the diagnosis of ANSD in the early stages 
of ontogenesis. The created model, together with the results of the 
pathogenicity prediction of SAVs via other known accurate methods, were used for 
the evaluation of a manually created set of 1302 VUS related to ANSD. Based on 
the analysis of predicted results, 16 SAVs were selected as the new most 
probable pathogenic variants.

DOI: 10.3390/ijms242417240
PMCID: PMC10743402
PMID: 38139069 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


244. Neuroreport. 2021 Jun 9;32(9):776-782. doi: 10.1097/WNR.0000000000001651.

Transplantation of adipose-derived stromal cells protects functional and 
morphological auditory nerve integrity in a model of cochlear implantation.

Radeloff A(1)(2)(3), Nada N(4), El Mahallawi T(4), Kolkaila E(4), Vollmer M(5), 
Rak K(6), Hagen R(6), Schendzielorz P(6).

Author information:
(1)Division of Oto-Rhino-Laryngology, Head and Neck Surgery, Carl von 
Ossietzky-University.
(2)Cluster of excellence "Hearing 4 All".
(3)Research Center Neurosensory Science, Oldenburg, Germany.
(4)Department of Oto-Rhino-Laryngology, Head and Neck Surgery, Tanta University 
Hospitals, Tanta, Egypt.
(5)Department of Otol-Rhino-Laryngology, Head and Neck Surgery, University 
Magdeburg and Leibniz Institute for Neurobiology, Magdeburg.
(6)Department of Oto-Rhino-Laryngology, Plastic, Aesthetic and Reconstructive 
Head and Neck Surgery, University of Würzburg, Germany.

Cochlear implants are considered the gold standard therapy for subjects with 
severe hearing loss and deafness. Cochlear implants bypass the damaged hair 
cells and directly stimulate spiral ganglion neurons (SGNs) of the auditory 
nerve. Hence, the presence of functional SGNs is crucial for speech perception 
in electric hearing with a cochlear implant. In deaf individuals, SGNs 
progressively degenerate due to the lack of neurotrophic support, normally 
provided by sensory cells of the inner ear. Adipose-derived stromal cells (ASCs) 
are known to produce neurotrophic factors. In a guinea pig model of sensory 
hearing loss and cochlear implantation, ASCs were autologously transplanted into 
the scala tympani prior to insertion of a cochlear implant on one side. 
Electrically evoked auditory brain stem responses (eABR) were recorded 8 weeks 
after cochlear implantation. At conclusion of the experiment, the cochleae were 
histologically evaluated. Compared to untreated control animals, transplantation 
of ASCs resulted in an increased number of SGNs and their peripheral neurites. 
In ASC-transplanted animals, mean eABR thresholds were lower and suprathreshold 
amplitudes larger, suggesting a larger population of intact auditory nerve 
fibers. Moreover, when compared to controls, amplitude-level functions of eABRs 
in ASC transplanted animals demonstrated steeper slopes in response to 
increasing interphase gaps (IPGs), indicative of better functionality of the 
auditory nerve. In summary, results suggest that transplantation of autologous 
ASCs into the deaf inner ear may have protective effects on the survival of SGNs 
and their peripheral processes and may thus contribute to long-term benefits in 
speech discrimination performance in cochlear implant subjects.

Copyright © 2021 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/WNR.0000000000001651
PMID: 33994529 [Indexed for MEDLINE]


245. Trends Hear. 2018 Jan-Dec;22:2331216518784837. doi: 10.1177/2331216518784837.

Adjusting Expectations: Hearing Abilities in a Population-Based Sample Using an 
SSQ Short Form.

von Gablenz P(1)(2), Otto-Sobotka F(3), Holube I(1)(2).

Author information:
(1)1 Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.
(2)2 Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)3 Division of Epidemiology and Biometry, School for Medicine and Health 
Sciences, Carl von Ossietzky University, Oldenburg, Germany.

The German short form of the Speech, Spatial, and Qualities of Hearing Scale 
(SSQ) was administered in a cross-sectional study based on stratified random 
samples complemented by audiometric tests and a general interview. Data from 
1,711 unaided adults aged 18 to 97 years were analyzed in order to determine a 
distribution of hearing abilities considered as normal and the main factors that 
impact self-assessments. An innovative mathematical approach was used to 
overcome the constraints of statistics based on the mean. Quantile regression 
analysis yielded a benchmark distribution of SSQ scores that might support 
audiologists in setting realistic SSQ score targets and estimated how the effect 
of auditory and nonauditory factors changes across the distribution of SSQ 
scores. Regression models showed significant effects for nonauditory factors on 
SSQ ratings when controlled for pure-tone hearing and interaural asymmetry. 
Self-reporting of hearing difficulties, when asked in general terms, was 
substantially related to SSQ ratings. This effect was observed in both high and 
low scoring participants and led to a considerable score decrease in all SSQ 
subscales. Gender, educational level, and self-reporting of health issues also 
were significantly related to SSQ ratings, but the corresponding effects were 
regularly unbalanced across the score distribution and particularly large at 
lower quantiles. The estimated effects of age, however, were mostly small in 
size, inconsistent regarding the direction, and failed significance for all SSQ 
items. Overall, the results suggest that nonauditory factors and cumulative 
effects must be considered when evaluating rehabilitative interventions against 
an ideal outcome.

DOI: 10.1177/2331216518784837
PMCID: PMC6053860
PMID: 30022731 [Indexed for MEDLINE]


246. J Acoust Soc Am. 2004 May;115(5 Pt 1):2207-20. doi: 10.1121/1.1689961.

Noise-induced hair-cell loss and total exposure energy: analysis of a large data 
set.

Harding GW(1), Bohne BA.

Author information:
(1)Department of Otolaryngology, Washington University School of Medicine, St. 
Louis, Missouri 63110, USA. hardingg@wustl.edu

The relation between total noise-exposure energy, recovery time, or rest during 
the exposure and amount of hair-cell loss was examined in 416 chinchillas. The 
exposures were octave bands of noise (OBN) with a center frequency of either 4 
kHz at 47-108 dB sound pressure level (SPL) for 0.5 h to 36 d, or 0.5 kHz at 
65-128 dB SPL for 3.5 h to 432 d. Recovery times varied from 0 to 365 d. With 
both OBNs, some animals were exposed on interrupted schedules. Hair-cell loss as 
a function of age in nonexposed animals (N = 117) was used to correct for 
sensory-cell loss due to aging. For both OBNs, the ears (N = 607) were separated 
into three subsets to characterize the primary hair-cell loss from noise and the 
secondary post-exposure loss and to determine if rest during the exposure 
decreased loss. Cluster and regression analyses were performed on data from the 
basal and apical halves of the cochlea to determine the specific rates for these 
three factors. It was found that: (1) when the OBN was above a critical level, 
there was no relation between total energy and hair-cell loss; (2) below a 
critical level, there were highly significant log-linear relations between total 
energy and hair-cell loss, but not at rates predicted by the equal-energy 
hypothesis; (3) rest periods during either OBN exposure reduced hair-cell loss; 
more so for the 4 kHz OBN than the 0.5 kHz OBN; (4) except for the highest 
exposure levels, the majority of outer hair cell loss from the 4 kHz OBN 
occurred after the exposure had terminated, while that from the 0.5 kHz OBN 
occurred during the exposure; and (5) a majority of the inner hair cell loss 
from both OBNs occurred post-exposure.

DOI: 10.1121/1.1689961
PMID: 15139632 [Indexed for MEDLINE]


247. PLoS One. 2019 Jun 3;14(6):e0217790. doi: 10.1371/journal.pone.0217790. 
eCollection 2019.

Predicting cochlear dead regions in patients with hearing loss through a machine 
learning-based approach: A preliminary study.

Chang YS(1)(2), Park H(3), Hong SH(4), Chung WH(5), Cho YS(5), Moon IJ(5).

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, Korea University 
College of Medicine, Korea University Ansan Hospital, Ansan, Republic of Korea.
(2)Department of Digital Health, SAIHST, Sungkyunkwan University, Seoul, 
Republic of Korea.
(3)Hearing Research Laboratory, Samsung Medical Center, Seoul, Republic of 
Korea.
(4)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Changwon 
Hospital, Sungkyunkwan University School of Medicine, Changwon, Republic of 
Korea.
(5)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Medical 
Center, Sungkyunkwan University School of Medicine, Seoul, Republic of Korea.

We propose a machine learning (ML)-based model for predicting cochlear dead 
regions (DRs) in patients with hearing loss of various etiologies. Five hundred 
and fifty-five ears from 380 patients (3,770 test samples) diagnosed with 
sensorineural hearing loss (SNHL) were analyzed. A threshold-equalizing noise 
(TEN) test was applied to detect the presence of DRs. Data were collected on 
sex, age, side of the affected ear, hearing loss etiology, word recognition 
scores (WRS), and pure-tone thresholds at each frequency. According to the cause 
of hearing loss as diagnosed by the physician, we categorized the patients into 
six groups: 1) SNHL with unknown etiology; 2) sudden sensorineural hearing loss 
(SSNHL); 3) vestibular schwannoma (VS); 4) Meniere's disease (MD); 5) 
noise-induced hearing loss (NIHL); or 6) presbycusis or age-related hearing loss 
(ARHL). To develop a predictive model, we performed recursive partitioning and 
regression for classification, logistic regression, and random forest. The 
overall prevalence of one or more DRs in test ears was 20.36% (113 ears). Among 
the 3,770 test samples, the overall frequency-specific prevalence of DR was 
6.7%. WRS, pure-tone thresholds at each frequency, disease type (VS or MD), and 
frequency information were useful for predicting DRs. Sex and age were not 
associated with detecting DRs. Based on these results, we suggest possible 
predictive factors for determining the presence of DRs. To improve the 
predictive power of the model, a more flexible model or more clinical features, 
such as the duration of hearing loss or risk factors for developing DRs, may be 
needed.

DOI: 10.1371/journal.pone.0217790
PMCID: PMC6546232
PMID: 31158267 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


248. Sci Rep. 2017 Aug 31;7(1):10106. doi: 10.1038/s41598-017-10680-9.

Association of leukocyte telomere length and the risk of age-related hearing 
impairment in Chinese Hans.

Liu H(1), Luo H(2), Yang T(3)(4)(5), Wu H(6)(7)(8), Chen D(9).

Author information:
(1)Ministry of Education and Shanghai Key Laboratory of Children's Environmental 
Health, Xin Hua Hospital Affiliated to Shanghai Jiao Tong University School of 
Medicine, Shanghai, China.
(2)Department of Otolaryngology, Renji Hospital Affiliated to Shanghai Jiao Tong 
University School of Medicine, Shanghai, China.
(3)Department of Otolaryngology-Head and Neck Surgery, Xinhua Hospital 
Affiliated to Shanghai Jiao Tong University School of Medicine, Shanghai, China. 
yangtfxl@sina.com.
(4)Ear Institute, Shanghai Jiaotong University School of Medicine, Shanghai, 
China. yangtfxl@sina.com.
(5)Shanghai Key Laboratory of Translational Medicine on Ear and Nose Diseases, 
Shanghai, China. yangtfxl@sina.com.
(6)Department of Otorhinolaryngology-Head and Neck Surgery, Shanghai Ninth 
People's Hospital Affiliated to Shanghai Jiaotong University School of Medicine, 
Shanghai, China. wuhao622@sina.cn.
(7)Ear Institute, Shanghai Jiaotong University School of Medicine, Shanghai, 
China. wuhao622@sina.cn.
(8)Shanghai Key Laboratory of Translational Medicine on Ear and Nose Diseases, 
Shanghai, China. wuhao622@sina.cn.
(9)Ministry of Education and Shanghai Key Laboratory of Children's Environmental 
Health, Xin Hua Hospital Affiliated to Shanghai Jiao Tong University School of 
Medicine, Shanghai, China. simpledandan1981@163.com.

Age-related hearing loss (ARHI) is the most common sensory disorder in the 
elderly. Although telomere attrition has been shown as a determinant in the 
pathobiology of various age-related diseases, it remains unknown whether 
telomere length is associated with ARHI. We hypothesized that decreased 
leukocyte telomere length (LTL) increased the risk of ARHI. Thus, we measured 
LTL of 666 ARHI and 43 controls by an established quantitative PCR technique. 
Four audiogram shape subtypes of ARHI, including "flat shape (FL)", "2-4 kHz 
abrupt loss (AL) shape", "8 kHz dip (8D) shape" and "sloping shape (SL)" could 
be identified among the cases using K-means cluster analysis. Longer LTL was 
associated with the reduced incidence of ARHI (adjusted OR = 0.550, 95% CI: 
0.420-0.721, P < 0.0001 for all the ARHI; 0.498, 0.318-0.780, P = 0.0023 for FL 
subgroup; 0.428, 0.292-0.628, P < 0.0001 for AL subgroup; 0.552, 0.399-0.764, 
P = 0.0003 for mSL subgroup). Subjects in the highest tertile of LTL were at 
less risk for ARHI than those in the lowest and middle tertiles (OR for ARHI: 
0.327, 95% CI 0.170-0.629, P = 0.0008). There was a descending trend of LTL as 
the degree of pure tone threshold average (PTA) aggravated. These results 
suggest that telomere attrition may be involved in the progression of ARHI.

DOI: 10.1038/s41598-017-10680-9
PMCID: PMC5578975
PMID: 28860610 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


249. Indian J Public Health. 2011 Apr-Jun;55(2):132-4. doi: 10.4103/0019-557X.85251.

Prevalence of hearing impairement in the district of Lucknow, India.

Mishra A(1), Verma V, Shukla GK, Mishra SC, Dwivedi R.

Author information:
(1)Department of Otolaryngology, King George's Medical College, Lucknow, India. 
anupampenn@yahoo.com

A multi-cluster study (survey) was carried out by department of ENT KG Medical 
University, Lucknow from July 2003 to August 2004 in rural and urban population 
of Lucknow district to estimate prevalence and causes of hearing impairment in 
the community. Data included audiological profile and basic ear examination that 
was analysed through EARFORM software program of WHO. Overall hearing impairment 
was seen in 15.14% of rural as opposed to 5.9% of urban population. A higher 
prevalence of disabling hearing impairment (DHI) in elderly and deafness in 0-10 
years age group was seen. The prevalence of sensorineural deafness necessitating 
hearing aids was 20% in rural and 50% in urban areas respectively. The presence 
of DHI was seen in 1/2 urban subjects and 1/3rd of rural counterparts. The 
incidence of cerumen / debris was very common in both types of population and 
the need of surgery was much more amongst rural subjects indicating more 
advanced / dangerous ear disease.

DOI: 10.4103/0019-557X.85251
PMID: 21941050 [Indexed for MEDLINE]


250. Trends Hear. 2020 Jan-Dec;24:2331216520945826. doi: 10.1177/2331216520945826.

Can You Hear Out the Melody? Testing Musical Scene Perception in Young 
Normal-Hearing and Older Hearing-Impaired Listeners.

Siedenburg K(1), Röttges S(1), Wagener KC(2), Hohmann V(1)(2).

Author information:
(1)Department of Medical Physics and Acoustics and Cluster of Excellence 
Hearing4all, Carl von Ossietzky University of Oldenburg.
(2)Hörzentrum Oldenburg GmbH & Hörtech gGmbH, Oldenburg, Germany.

It is well known that hearing loss compromises auditory scene analysis 
abilities, as is usually manifested in difficulties of understanding speech in 
noise. Remarkably little is known about auditory scene analysis of 
hearing-impaired (HI) listeners when it comes to musical sounds. Specifically, 
it is unclear to which extent HI listeners are able to hear out a melody or an 
instrument from a musical mixture. Here, we tested a group of younger 
normal-hearing (yNH) and older HI (oHI) listeners with moderate hearing loss in 
their ability to match short melodies and instruments presented as part of 
mixtures. Four-tone sequences were used in conjunction with a simple musical 
accompaniment that acted as a masker (cello/piano dyads or spectrally matched 
noise). In each trial, a signal-masker mixture was presented, followed by two 
different versions of the signal alone. Listeners indicated which signal version 
was part of the mixture. Signal versions differed either in terms of the 
sequential order of the pitch sequence or in terms of timbre (flute vs. 
trumpet). Signal-to-masker thresholds were measured by varying the signal 
presentation level in an adaptive two-down/one-up procedure. We observed that 
thresholds of oHI listeners were elevated by on average 10 dB compared with that 
of yNH listeners. In contrast to yNH listeners, oHI listeners did not show 
evidence of listening in dips of the masker. Musical training of participants 
was associated with a lowering of thresholds. These results may indicate 
detrimental effects of hearing loss on central aspects of musical scene 
perception.

DOI: 10.1177/2331216520945826
PMCID: PMC7502688
PMID: 32895034 [Indexed for MEDLINE]


251. Dev Neurosci. 2021;43(6):358-375. doi: 10.1159/000518130. Epub 2021 Jul 19.

Prenatal Exposure to Tobacco and Alcohol Alters Development of the Neonatal 
Auditory System.

Sininger YS(1)(2), Condon CG(3), Gimenez LA(3), Shuffrey LC(3)(4), Myers 
MM(3)(4)(5), Elliott AJ(6)(7), Thai T(3), Nugent JD(3)(4), Pini N(3)(4), Sania 
A(4), Odendaal HJ(8), Angal J(6)(7), Tobacco D(6)(7), Hoffman HJ(9), Simmons 
DD(10), Fifer WP(3)(4)(5).

Author information:
(1)Department of Head & Neck Surgery, University of California, Los Angeles, 
California, USA.
(2)C&Y Consultants, Santa Fe, New Mexico, USA.
(3)Division of Developmental Neuroscience, New York State Psychiatric Institute, 
New York, New York, USA.
(4)Department of Psychiatry, Columbia University Irving Medical Center, New 
York, New York, USA.
(5)Department of Pediatrics, Columbia University Irving Medical Center, New 
York, New York, USA.
(6)Center for Pediatric & Community Research, Avera Research Institute, Sioux 
Falls, South Dakota, USA.
(7)Department of Pediatrics, University of South Dakota School of Medicine, 
Sioux Falls, South Dakota, USA.
(8)Department of Obstetrics and Gynaecology, Faculty of Medicine and Health 
Science, Stellenbosch University, Cape Town, South Africa.
(9)Epidemiology and Statistics Program, National Institute on Deafness and Other 
Communication Disorders (NIDCD), National Institutes of Health (NIH), Bethesda, 
Maryland, USA.
(10)Department of Biology, Baylor University, Waco, Texas, USA.

Prenatal exposures to alcohol (PAE) and tobacco (PTE) are known to produce 
adverse neonatal and childhood outcomes including damage to the developing 
auditory system. Knowledge of the timing, extent, and combinations of these 
exposures on effects on the developing system is limited. As part of the 
physiological measurements from the Safe Passage Study, Auditory Brainstem 
Responses (ABRs) and Transient Otoacoustic Emissions (TEOAEs) were acquired on 
infants at birth and one-month of age. Research sites were in South Africa and 
the Northern Plains of the U.S. Prenatal information on alcohol and tobacco 
exposure was gathered prospectively on mother/infant dyads. Cluster analysis was 
used to characterize three levels of PAE and three levels of PTE. 
Repeated-measures ANOVAs were conducted for newborn and one-month-old infants 
for ABR peak latencies and amplitudes and TEOAE levels and signal-to-noise 
ratios. Analyses controlled for hours of life at test, gestational age at birth, 
sex, site, and other exposure. Significant main effects of PTE included reduced 
newborn ABR latencies from both ears. PTE also resulted in a significant 
reduction of ABR peak amplitudes elicited in infants at 1-month of age. PAE led 
to a reduction of TEOAE amplitude for 1-month-old infants but only in the left 
ear. Results indicate that PAE and PTE lead to early disruption of peripheral, 
brainstem, and cortical development and neuronal pathways of the auditory 
system, including the olivocochlear pathway.

© 2021 S. Karger AG, Basel.

DOI: 10.1159/000518130
PMID: 34348289 [Indexed for MEDLINE]


252. Nat Neurosci. 2008 Oct;11(10):1217-22. doi: 10.1038/nn.2193. Epub 2008 Sep 14.

Speech motor learning in profoundly deaf adults.

Nasir SM(1), Ostry DJ.

Author information:
(1)Department of Psychology, McGill University, 1205 Dr. Penfield Avenue, 
Montreal, Quebec H3A1B1, Canada.

Speech production, like other sensorimotor behaviors, relies on multiple sensory 
inputs--audition, proprioceptive inputs from muscle spindles and cutaneous 
inputs from mechanoreceptors in the skin and soft tissues of the vocal tract. 
However, the capacity for intelligible speech by deaf speakers suggests that 
somatosensory input alone may contribute to speech motor control and perhaps 
even to speech learning. We assessed speech motor learning in cochlear implant 
recipients who were tested with their implants turned off. A robotic device was 
used to alter somatosensory feedback by displacing the jaw during speech. We 
found that implant subjects progressively adapted to the mechanical perturbation 
with training. Moreover, the corrections that we observed were for movement 
deviations that were exceedingly small, on the order of millimeters, indicating 
that speakers have precise somatosensory expectations. Speech motor learning is 
substantially dependent on somatosensory input.

DOI: 10.1038/nn.2193
PMCID: PMC2601702
PMID: 18794839 [Indexed for MEDLINE]


253. Int J Audiol. 2021;60(sup2):71-79. doi: 10.1080/14992027.2020.1858237. Epub 2021 
Jan 17.

Self-reported hearing handicap in adults aged 55 to 81 years is modulated by 
hearing abilities, frailty, mental health, and willingness to use hearing aids.

Nuesse T(1)(2), Schlueter A(1)(2), Lemke U(3), Holube I(1)(2).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4All", Oldenburg, Germany.
(3)Sonova AG, Stäfa, Switzerland.

OBJECTIVE: The aim of this study was to predict outcomes of the HHI 
questionnaire (Hearing Handicap Inventory) using individual variables beyond 
pure-tone hearing thresholds.
DESIGN: An extensive health-related test battery was applied including a general 
anamnesis, questionnaires, audiological measures, examination of visual acuity, 
balance, and cognition, as well as tactile- and motor skills. Based on the 
self-assessment of health variables and different sensory and cognitive 
performance measures, a frailty index was calculated to describe the health 
status of the participants. A stepwise linear regression analysis was conducted 
to predict HHI scores.
STUDY SAMPLE: A mixed sample (N = 212) of 55- to 81-year-old, participants with 
different hearing and aiding status completed the test battery.
RESULTS: The regression analysis showed statistically significant contributions 
of pure-tone hearing thresholds, speech recognition in noise, age, frailty, 
mental health, and the willingness to use hearing aids on HHIE outcomes.
CONCLUSIONS: Self-reported hearing handicap assessed with the HHI questionnaire 
reflects various individual variables additionally to pure-tone hearing loss and 
speech recognition in noise. It is necessary to be aware of the influences of 
age and health-related variables on HHI scores when using it in research as well 
as in clinical settings.

DOI: 10.1080/14992027.2020.1858237
PMID: 33459099 [Indexed for MEDLINE]


254. Hear Res. 2021 Dec;412:108380. doi: 10.1016/j.heares.2021.108380. Epub 2021 Oct 
23.

Age-related changes in event related potentials, steady state responses and 
temporal processing in the auditory cortex of mice with severe or mild hearing 
loss.

Rumschlag JA(1), Razak KA(2).

Author information:
(1)Graduate Neuroscience Program, Riverside, United States.
(2)Graduate Neuroscience Program, Riverside, United States; Psychology 
Department, University of California, Riverside, United States. Electronic 
address: khaleel@ucr.edu.

Age-related changes in auditory processing affect the quality of life of older 
adults with and without hearing loss. To distinguish between the effects of 
sensorineural hearing loss and aging on cortical processing, the main goal of 
the present study was to compare cortical responses using the same stimulus 
paradigms and recording conditions in two strains of mice (C57BL/6J and FVB) 
that differ in the degree of age-related hearing loss. Electroencephalogram 
(EEG) recordings were obtained from freely moving young and old mice using 
epidural screw electrodes. We measured event related potentials (ERP) and 40 Hz 
auditory steady-state responses (ASSR). We used a novel stimulus, termed the 
gap-ASSR stimulus, which elicits an ASSR by rapidly presenting short gaps in 
continuous noise. By varying the gap widths and modulation depths, we probed the 
limits of temporal processing in young and old mice. Temporal fidelity of ASSR 
and gap-ASSR responses were measured as phase consistency across trials 
(inter-trial phase clustering; ITPC). The old C57 mice, which show severe 
hearing loss, produced larger ERP amplitudes compared to young mice. Despite 
robust ERPs, the old C57 mice showed significantly diminished ITPC in the ASSR 
and gap-ASSR responses, even with 100% modulation depth. The FVB mice, which 
show mild hearing loss with age, generated similar ERP amplitudes and ASSR ITPC 
across the age groups tested. However, the old FVB mice showed decreased 
gap-ASSR responses compared to young mice, particularly for modulation depths 
<100%. The C57 mice data suggest that severe presbycusis leads to increased gain 
in the auditory cortex, but with reduced temporal fidelity. The FVB mice data 
suggest that with mild hearing loss, age-related changes in temporal processing 
become apparent only when tested with more challenging sounds (shorter gaps and 
shallower modulation).

Copyright © 2021. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2021.108380
PMID: 34758398 [Indexed for MEDLINE]

Conflict of interest statement: Declarations of Competing Interest None.


255. Brain Res. 2009 Feb 9;1253:27-34. doi: 10.1016/j.brainres.2008.11.070. Epub 2008 
Dec 3.

Age-related hearing loss: aquaporin 4 gene expression changes in the mouse 
cochlea and auditory midbrain.

Christensen N(1), D'Souza M, Zhu X, Frisina RD.

Author information:
(1)Otolaryngology Department, University of Rochester Medical School, Rochester, 
NY 14642-8629, USA.

Presbycusis -- age-related hearing loss, is the number one communication 
disorder, and one of the top three chronic medical conditions of our aged 
population. Aquaporins, particularly aquaporin 4 (Aqp4), are membrane proteins 
with important roles in water and ion flux across cell membranes, including 
cells of the inner ear and pathways of the brain used for hearing. To more fully 
understand the biological bases of presbycusis, 39 CBA mice, a well-studied 
animal model of presbycusis, underwent non-invasive hearing testing as a 
function of sound frequency (auditory brainstem response -- ABR thresholds, and 
distortion-product otoacoustic emission -- DPOAE magnitudes), and were clustered 
into four groups based on age and hearing ability. Aqp4 gene expression, as 
determined by genechip microarray analysis and quantitative real-time PCR, was 
compared to the young adult control group in the three older groups: middle aged 
with good hearing, old age with mild presbycusis, and old age with severe 
presbycusis. Linear regression and ANOVA showed statistically significant 
changes in Aqp4 gene expression and ABR and DPOAE hearing status in the cochlea 
and auditory midbrain -- inferior colliculus. Down-regulation in the cochlea was 
seen, and an initial down-, then up-regulation was discovered for the inferior 
colliculus Aqp4 expression. It is theorized that these changes in Aqp4 gene 
expression represent an age-related disruption of ion flux in the fluids of the 
cochlea that are responsible for ionic gradients underlying sound transduction 
in cochlear hair cells necessary for hearing. In regard to central auditory 
processing at the level of the auditory midbrain, aquaporin gene expression 
changes may affect neurotransmitter cycling involving supporting cells, thus 
impairing complex sound neural processing with age.

DOI: 10.1016/j.brainres.2008.11.070
PMCID: PMC2670229
PMID: 19070604 [Indexed for MEDLINE]


256. Otol Neurotol. 2019 Mar;40(3):e326-e335. doi: 10.1097/MAO.0000000000002127.

Individual Hearing Preservation Cochlear Implantation Using the Concept of 
Partial Insertion.

Lenarz T(1), Timm ME, Salcher R, Büchner A.

Author information:
(1)Cluster of Excellence Hearing4all, Department of Otorhinolaryngology, 
Hannover Medical School, Hannover, Germany.

OBJECTIVE: Aim of this study was to evaluate the method of partial insertion of 
flexible lateral wall electrodes in patients with residual hearing and potential 
electric-acoustic stimulation (EAS) users.
PATIENTS AND INTERVENTION: N = 6 patients with a high-frequency hearing loss 
were treated with a partial insertion using atraumatic lateral wall electrodes. 
In three cases, a electrode of 24 mm length was inserted with the aim to achieve 
a 16 mm insertion depth and in three cases a electrode of 28 mm length to 
achieve a 20 mm insertion depth.
MAIN OUTCOME MEASURE: Differences between the pre- and postoperative unaided 
air-conducted pure tone thresholds in low frequencies (125 Hz-1.5 kHz) were 
analyzed. Freiburg monosyllables (FBM) at 65 dB and Hochmair-Desoyer sentence 
test in noise (10 dB SNR) were performed. The pre- and postoperative cochlea 
images were analyzed.
RESULTS: Residual hearing could be preserved in all patients (n = 6) and is 
stable up to 6 months follow-up. All patients could use EAS with an average 
speech understanding score of 65% in monosyllables (FBM) and 76% in sentences in 
noise. All patients benefit significantly compared to the preoperative best 
aided situation.
CONCLUSION: First results of patients treated with partially inserted atraumatic 
lateral wall electrodes show good hearing preservation rates and very good 
speech perception results in EAS. Partial insertion appears to be a method for 
an individualized cochlea implantation. In case of postoperative hearing loss 
the electrode can be further inserted, so the patients can benefit from deeper 
insertion using electric stimulation only equivalent to larger electrodes.

DOI: 10.1097/MAO.0000000000002127
PMID: 30741914 [Indexed for MEDLINE]


257. J Acoust Soc Am. 2016 Jul;140(1):121. doi: 10.1121/1.4955078.

Interactions between amplitude modulation and frequency modulation processing: 
Effects of age and hearing loss.

Paraouty N(1), Ewert SD(2), Wallaert N(1), Lorenzi C(1).

Author information:
(1)Laboratoire des Systèmes Perceptifs (CNRS UMR 8248), Institut d'Etude de la 
Cognition, Ecole normale supérieure, Paris Sciences et Lettres Research 
University, 29 rue d'Ulm, 75005 Paris, France.
(2)Medizinische Physik and Cluster of Excellence Hearing4All, Universität 
Oldenburg, 26111 Oldenburg, Germany.

Frequency modulation (FM) and amplitude modulation (AM) detection thresholds 
were measured for a 500-Hz carrier frequency and a 5-Hz modulation rate. For AM 
detection, FM at the same rate as the AM was superimposed with varying FM depth. 
For FM detection, AM at the same rate was superimposed with varying AM depth. 
The target stimuli always contained both amplitude and frequency modulations, 
while the standard stimuli only contained the interfering modulation. Young and 
older normal-hearing listeners, as well as older listeners with mild-to-moderate 
sensorineural hearing loss were tested. For all groups, AM and FM detection 
thresholds were degraded in the presence of the interfering modulation. AM 
detection with and without interfering FM was hardly affected by either age or 
hearing loss. While aging had an overall detrimental effect on FM detection with 
and without interfering AM, there was a trend that hearing loss further impaired 
FM detection in the presence of AM. Several models using optimal combination of 
temporal-envelope cues at the outputs of off-frequency filters were tested. The 
interfering effects could only be predicted for hearing-impaired listeners. This 
indirectly supports the idea that, in addition to envelope cues resulting from 
FM-to-AM conversion, normal-hearing listeners use temporal fine-structure cues 
for FM detection.

DOI: 10.1121/1.4955078
PMID: 27475138 [Indexed for MEDLINE]


258. Trends Hear. 2015 Dec 30;19:2331216515617916. doi: 10.1177/2331216515617916.

Comparing Binaural Pre-processing Strategies I: Instrumental Evaluation.

Baumgärtel RM(1), Krawczyk-Becker M(2), Marquardt D(3), Völker C(4), Hu H(4), 
Herzke T(5), Coleman G(5), Adiloğlu K(5), Ernst SM(4), Gerkmann T(2), Doclo 
S(3), Kollmeier B(4), Hohmann V(6), Dietz M(4).

Author information:
(1)Medical Physics Group, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany Cluster of Excellence "Hearing4all," Oldenburg, Germany 
Regina.Baumgaertel@uni-oldenburg.de.
(2)Cluster of Excellence "Hearing4all," Oldenburg, Germany Speech Signal 
Processing Group, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany.
(3)Cluster of Excellence "Hearing4all," Oldenburg, Germany Signal Processing 
Group, Carl von Ossietzky Universität Oldenburg, Oldenburg, Germany.
(4)Medical Physics Group, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany Cluster of Excellence "Hearing4all," Oldenburg, Germany.
(5)Cluster of Excellence "Hearing4all," Oldenburg, Germany HörTech gGmbH, 
Oldenburg, Germany.
(6)Medical Physics Group, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany Cluster of Excellence "Hearing4all," Oldenburg, Germany HörTech gGmbH, 
Oldenburg, Germany.

In a collaborative research project, several monaural and binaural noise 
reduction algorithms have been comprehensively evaluated. In this article, eight 
selected noise reduction algorithms were assessed using instrumental measures, 
with a focus on the instrumental evaluation of speech intelligibility. Four 
distinct, reverberant scenarios were created to reflect everyday listening 
situations: a stationary speech-shaped noise, a multitalker babble noise, a 
single interfering talker, and a realistic cafeteria noise. Three instrumental 
measures were employed to assess predicted speech intelligibility and predicted 
sound quality: the intelligibility-weighted signal-to-noise ratio, the 
short-time objective intelligibility measure, and the perceptual evaluation of 
speech quality. The results show substantial improvements in predicted speech 
intelligibility as well as sound quality for the proposed algorithms. The 
evaluated coherence-based noise reduction algorithm was able to provide 
improvements in predicted audio signal quality. For the tested single-channel 
noise reduction algorithm, improvements in intelligibility-weighted 
signal-to-noise ratio were observed in all but the nonstationary cafeteria 
ambient noise scenario. Binaural minimum variance distortionless response 
beamforming algorithms performed particularly well in all noise scenarios.

© The Author(s) 2015.

DOI: 10.1177/2331216515617916
PMCID: PMC4771044
PMID: 26721920 [Indexed for MEDLINE]


259. Sci Rep. 2024 Mar 28;14(1):7357. doi: 10.1038/s41598-024-57312-7.

Improved tactile speech robustness to background noise with a dual-path 
recurrent neural network noise-reduction method.

Fletcher MD(1)(2), Perry SW(3)(4), Thoidis I(5), Verschuur CA(3), Goehring T(6).

Author information:
(1)University of Southampton Auditory Implant Service, University of 
Southampton, University Road, Southampton, SO17 1BJ, UK. 
M.D.Fletcher@soton.ac.uk.
(2)Institute of Sound and Vibration Research, University of Southampton, 
University Road, Southampton, SO17 1BJ, UK. M.D.Fletcher@soton.ac.uk.
(3)University of Southampton Auditory Implant Service, University of 
Southampton, University Road, Southampton, SO17 1BJ, UK.
(4)Institute of Sound and Vibration Research, University of Southampton, 
University Road, Southampton, SO17 1BJ, UK.
(5)School of Electrical and Computer Engineering, Aristotle University of 
Thessaloniki, 54124, Thessaloniki, Greece.
(6)MRC Cognition and Brain Sciences Unit, University of Cambridge, 15 Chaucer 
Road, Cambridge, CB2 7EF, UK.

Many people with hearing loss struggle to understand speech in noisy 
environments, making noise robustness critical for hearing-assistive devices. 
Recently developed haptic hearing aids, which convert audio to vibration, can 
improve speech-in-noise performance for cochlear implant (CI) users and assist 
those unable to access hearing-assistive devices. They are typically body-worn 
rather than head-mounted, allowing additional space for batteries and 
microprocessors, and so can deploy more sophisticated noise-reduction 
techniques. The current study assessed whether a real-time-feasible dual-path 
recurrent neural network (DPRNN) can improve tactile speech-in-noise 
performance. Audio was converted to vibration on the wrist using a vocoder 
method, either with or without noise reduction. Performance was tested for 
speech in a multi-talker noise (recorded at a party) with a 2.5-dB 
signal-to-noise ratio. An objective assessment showed the DPRNN improved the 
scale-invariant signal-to-distortion ratio by 8.6 dB and substantially 
outperformed traditional noise-reduction (log-MMSE). A behavioural assessment in 
16 participants showed the DPRNN improved tactile-only sentence identification 
in noise by 8.2%. This suggests that advanced techniques like the DPRNN could 
substantially improve outcomes with haptic hearing aids. Low-cost haptic devices 
could soon be an important supplement to hearing-assistive devices such as CIs 
or offer an alternative for people who cannot access CI technology.

© 2024. The Author(s).

DOI: 10.1038/s41598-024-57312-7
PMCID: PMC10978864
PMID: 38548750 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


260. Hear Res. 2019 Sep 1;380:150-165. doi: 10.1016/j.heares.2019.07.001. Epub 2019 
Jul 2.

Applicability of subcortical EEG metrics of synaptopathy to older listeners with 
impaired audiograms.

Garrett M(1), Verhulst S(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all", Department of 
Medical Physics and Acoustics, University of Oldenburg, Oldenburg, Germany. 
Electronic address: markus.garrett@uol.de.
(2)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Ghent, Belgium; Medizinische Physik and Cluster of Excellence 
"Hearing4all", Department of Medical Physics and Acoustics, University of 
Oldenburg, Oldenburg, Germany. Electronic address: s.verhulst@ugent.be.

Emerging evidence suggests that cochlear synaptopathy is a common feature of 
sensorineural hearing loss, but it is not known to what extent 
electrophysiological metrics targeting synaptopathy in animals can be applied to 
people, such as those with impaired audiograms. This study investigates the 
applicability of subcortical electrophysiological measures associated with 
synaptopathy, i.e., auditory brainstem responses (ABRs) and envelope following 
responses (EFRs), to older participants with high-frequency sloping audiograms. 
The outcomes of this study are important for the development of reliable and 
sensitive synaptopathy diagnostics in people with normal or impaired 
outer-hair-cell function. Click-ABRs at different sound pressure levels and EFRs 
to amplitude-modulated stimuli were recorded, as well as relative EFR and ABR 
metrics which reduce the influence of individual factors such as head size and 
noise floor level on the measures. Most tested metrics showed significant 
differences between the groups and did not always follow the trends expected 
from synaptopathy. Age was not a reliable predictor for the electrophysiological 
metrics in the older hearing-impaired group or young normal-hearing control 
group. This study contributes to a better understanding of how 
electrophysiological synaptopathy metrics differ in ears with healthy and 
impaired audiograms, which is an important first step towards unravelling the 
perceptual consequences of synaptopathy.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.07.001
PMID: 31306930 [Indexed for MEDLINE]


261. J Neural Eng. 2020 Jun 12;17(3):036013. doi: 10.1088/1741-2552/ab92b2.

Auditory attention tracking states in a cocktail party environment can be 
decoded by deep convolutional neural networks.

Tian Y, Ma L.

OBJECTIVE: A deep convolutional neural network (CNN) is a method for deep 
learning (DL). It has a powerful ability to automatically extract features and 
is widely used in classification tasks with scalp electroencephalogram (EEG) 
signals. However, the small number of samples and low signal-to-noise ratio 
involved in scalp EEG with low spatial resolution constitute a limitation that 
might restrict potential brain-computer interface (BCI) applications that are 
based on the CNN model. In the present study, a novel CNN model with 
source-spatial feature images (SSFIs) as the input is proposed to decode 
auditory attention tracking states in a cocktail party environment.
APPROACH: We first extract SSFIs using rhythm entropy and weighted minimum norm 
estimation. Next, we develop a CNN model with three convolutional layers. 
Furthermore, we estimate the performance of the proposed model via generalized 
performance, alternative models that deleted or replaced a model's component, 
and loss curves. Finally, we use a deep transfer model with fine-tuning for a 
low (poor) behavioral performance group (L-group).
MAIN RESULTS: Based on cortical activity reconstructions from the scalp EEGs, 
the classification accuracy (CA) of the proposed model is 80.4% (chance level: 
52.5%), which is superior to that achieved by scalp EEG. Additionally, the 
performance of the proposed model is more stable when compared to alternative 
models that delete or replace specific model components. The proposed model 
identifies the difference between two auditory attention tracking states 
(successful versus unsuccessful) at an early stage with a short time window (250 
ms after target offset). Furthermore, we propose a deep transfer learning model 
to improve the classification for the L-group. With this model, the CA of the 
L-group significantly increase by 5.3%.
SIGNIFICANCE: Our proposed model improves the performance of a decoder for 
auditory attention tracking, which could be suitable for relieving the 
difficulty with the attentional modulation of individual's neural responses. It 
provides a novel communication channel with auditory cognitive BCI for patients 
with attention and hearing impairment.

DOI: 10.1088/1741-2552/ab92b2
PMID: 32403093 [Indexed for MEDLINE]


262. HNO. 2016 Mar;64 Suppl 1:S1-6. doi: 10.1007/s00106-015-0089-3.

A software tool for pure‑tone audiometry. Classification of audiograms for 
inclusion of patients in clinical trials. English version.

Rahne T(1), Buthut F(2), Plößl S(2), Plontke SK(2).

Author information:
(1)Department of Otorhinolaryngology, University Hospital Halle (Saale), 
Ernst-Grube-Str. 40, 06120, Halle (Saale), Germany. torsten.rahne@uk-halle.de.
(2)Department of Otorhinolaryngology, University Hospital Halle (Saale), 
Ernst-Grube-Str. 40, 06120, Halle (Saale), Germany.

OBJECTIVE: Selecting subjects for clinical trials on hearing loss therapies 
relies on the patient meeting the audiological inclusion criteria. In studies on 
the treatment of idiopathic sudden sensorineural hearing loss, the patient's 
acute audiogram is usually compared with a previous audiogram, the audiogram of 
the non-affected ear, or a normal audiogram according to an ISO standard. 
Generally, many more patients are screened than actually fulfill the particular 
inclusion criteria. The inclusion criteria often require a calculation of 
pure-tone averages, selection of the most affected frequencies, and calculation 
of hearing loss differences.
MATERIALS AND METHODS: A software tool was developed to simplify and accelerate 
this inclusion procedure for investigators to estimate the possible recruitment 
rate during the planning phase of a clinical trial and during the actual study. 
This tool is Microsoft Excel-based and easy to modify to meet the particular 
inclusion criteria of a specific clinical trial. The tool was retrospectively 
evaluated on 100 patients with acute hearing loss comparing the times for 
classifying automatically and manually. The study sample comprised 100 patients 
with idiopathic sudden sensorineural hearing loss.
RESULTS AND CONCLUSION: The age- and sex-related normative audiogram was 
calculated automatically by the tool and the hearing impairment was graded. The 
estimated recruitment rate of our sample was quickly calculated. Information 
about meeting the inclusion criteria was provided instantaneously. A significant 
reduction of 30 % in the time required for classifying (30 s per patient) was 
observed.

DOI: 10.1007/s00106-015-0089-3
PMCID: PMC4819485
PMID: 26607156 [Indexed for MEDLINE]


263. Prog Brain Res. 2007;166:125-40. doi: 10.1016/S0079-6123(07)66011-7.

Neural network models of tinnitus.

Husain FT(1).

Author information:
(1)Brain Imaging and Modeling Section, National Institute on Deafness and Other 
Communication Disorders, NIH, Bethesda, MD 20892, USA. husainf@nidcd.nih.gov

In this chapter we review the relatively recent effort on the part of 
neuroscientists to use computational neural network modeling to investigate the 
neural basis of subjective tinnitus. There are advantages and challenges in 
using a modeling framework to understand this complex auditory disorder. The 
foremost challenge to modeling a subjective condition such as tinnitus is the 
evaluation of the occurrence of tinnitus in the model. We propose comparing 
measures of the model's activities (simulated neuronal activity, behavioral 
activity, or neuroimaging activity) with experimental data obtained from studies 
of tinnitus in humans and animals; strong agreement with experimental data will 
provide support for the validity of the simulation of tinnitus in a particular 
model. A major advantage of neural network modeling is that it allows 
experimentation not possible in animals. Models make it possible to evaluate the 
contribution of different neural mechanisms affecting tinnitus in a principled 
manner. A model makes predictions that can be tested by experiments thus leading 
to the designing of focused experiments. We review several neural models of 
tinnitus and discuss published findings from simulations using these models. We 
conclude with a proposed scheme for investigating tinnitus that combines neural 
network modeling with brain imaging experiments.

DOI: 10.1016/S0079-6123(07)66011-7
PMID: 17956777 [Indexed for MEDLINE]


264. Neural Plast. 2016;2016:4382656. doi: 10.1155/2016/4382656. Epub 2015 Dec 27.

Cross-Modal Functional Reorganization of Visual and Auditory Cortex in Adult 
Cochlear Implant Users Identified with fNIRS.

Chen LC(1), Sandmann P(2), Thorne JD(1), Bleichner MG(3), Debener S(4).

Author information:
(1)Neuropsychology Lab, Department of Psychology, European Medical School, 
Carl-von-Ossietzky University Oldenburg, 26129 Oldenburg, Germany.
(2)Department of Neurology, Hannover Medical School, 30625 Hannover, Germany; 
Cluster of Excellence Hearing4all, 26129 Oldenburg, Germany.
(3)Neuropsychology Lab, Department of Psychology, European Medical School, 
Carl-von-Ossietzky University Oldenburg, 26129 Oldenburg, Germany; Cluster of 
Excellence Hearing4all, 26129 Oldenburg, Germany.
(4)Neuropsychology Lab, Department of Psychology, European Medical School, 
Carl-von-Ossietzky University Oldenburg, 26129 Oldenburg, Germany; Cluster of 
Excellence Hearing4all, 26129 Oldenburg, Germany; Research Center Neurosensory 
Science, University of Oldenburg, 26129 Oldenburg, Germany.

Cochlear implant (CI) users show higher auditory-evoked activations in visual 
cortex and higher visual-evoked activation in auditory cortex compared to normal 
hearing (NH) controls, reflecting functional reorganization of both visual and 
auditory modalities. Visual-evoked activation in auditory cortex is a 
maladaptive functional reorganization whereas auditory-evoked activation in 
visual cortex is beneficial for speech recognition in CI users. We investigated 
their joint influence on CI users' speech recognition, by testing 20 
postlingually deafened CI users and 20 NH controls with functional near-infrared 
spectroscopy (fNIRS). Optodes were placed over occipital and temporal areas to 
measure visual and auditory responses when presenting visual checkerboard and 
auditory word stimuli. Higher cross-modal activations were confirmed in both 
auditory and visual cortex for CI users compared to NH controls, demonstrating 
that functional reorganization of both auditory and visual cortex can be 
identified with fNIRS. Additionally, the combined reorganization of auditory and 
visual cortex was found to be associated with speech recognition performance. 
Speech performance was good as long as the beneficial auditory-evoked activation 
in visual cortex was higher than the visual-evoked activation in the auditory 
cortex. These results indicate the importance of considering cross-modal 
activations in both visual and auditory cortex for potential clinical outcome 
estimation.

DOI: 10.1155/2016/4382656
PMCID: PMC4706950
PMID: 26819766 [Indexed for MEDLINE]


265. Otol Neurotol. 2018 Oct;39(9):1147-1152. doi: 10.1097/MAO.0000000000001954.

Direct Acoustic Cochlear Implants Lead to an Improved Speech Perception Gap 
Compared to Conventional Hearing Aid.

Maier H(1), Lenarz T(1), Dolležal LV(2), Busch S(1).

Author information:
(1)Department of Otorhinolaryngology and Cluster of Excellence "Hearing4all," 
Hannover Medical School.
(2)Cochlear Deutschland GmbH & Co. KG, Hannover, Germany.

OBJECTIVES: The objectives of this study was to evaluate the aided speech 
perception in quiet of direct acoustic cochlear implant (DACI) patients and the 
speech perception gap in comparison with hearing aid users.
STUDY DESIGN: Retrospective comparative study.
SETTING: Tertiary referral center.
PATIENTS: Adults with moderate-to-severe mixed hearing loss who have been 
implanted with a DACI and fitted with a processor for at least 6 months.
INTERVENTION(S): Comparison of aided monosyllabic word scores and speech 
perception gap of 59 DACI-implanted ears speech perception gap with published 
data on 208 ears aided with a conventional hearing aid (HA) divided into four 
different hearing loss groups between 35 and 75 dB HL.
MAIN OUTCOME MEASURE(S): Aided monosyllabic word score, predicted maximum 
monosyllabic word recognition score (PBmax) and speech perception gap.
RESULTS: In terms of aided speech perception, DACI patients with cochlear 
reserves between 45 and 65 dB HL have a significant advantage compared with 
conventional HA users. A speech perception gap of 11% points for DACI and 21% 
points for conventional HAs were determined and an approximation of PBmax is 
achieved by 52% of the DACI patients compared with only 36% of the HA users.
CONCLUSIONS: For patients with moderate-to-severe inner ear hearing loss between 
45 and 65 dB HL, better speech perception in quiet is obtained with the DACI 
system. Compared with conventional hearing aids, speech performance with the 
DACI is closer to the maximally possibly score PBmax.

DOI: 10.1097/MAO.0000000000001954
PMID: 30106855 [Indexed for MEDLINE]


266. Audiol Neurootol. 2020;25(3):133-142. doi: 10.1159/000504285. Epub 2020 Jan 31.

Hearing Aid Treatment for Patients with Mixed Hearing Loss. Part II: Speech 
Recognition in Comparison to Direct Acoustic Cochlear Stimulation.

Wardenga N(1)(2), Snik AFM(3), Kludt E(4)(5), Waldmann B(6), Lenarz T(4)(5), 
Maier H(4)(5).

Author information:
(1)Cluster of Excellence Hearing4all, Hannover, Germany, 
wardenga.nina@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Hannover, Germany, 
wardenga.nina@mh-hannover.de.
(3)Department of Biophysics, Radboud University, Nijmegen, The Netherlands.
(4)Cluster of Excellence Hearing4all, Hannover, Germany.
(5)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(6)Cochlear Deutschland GmbH and Co. KG, Hannover, Germany.

BACKGROUND: The conventional therapy for severe mixed hearing loss is middle ear 
surgery combined with a power hearing aid. However, a substantial group of 
patients with severe mixed hearing loss cannot be treated adequately with 
today's state-of-the-art (SOTA) power hearing aids, as predicted by the 
accompanying part I of this publication, where we compared the available maximum 
power output (MPO) and gain from technical specifications to requirements for 
optimum benefit using a common fitting rule. Here, we intended to validate the 
theoretical assumptions from part I experimentally in a mixed hearing loss 
cohort fitted with SOTA power hearing aids. Additionally, we compared the 
results with an implantable hearing device that circumvents the impaired middle 
ear, directly stimulating the cochlea, as this might be a better option.
OBJECTIVES: Speech recognition outcomes obtained from patients with severe mixed 
hearing loss supplied acutely with a SOTA hearing aid were studied to validate 
the outcome predictions as described in part I. Further, the results obtained 
with hearing aids were compared to those in direct acoustic cochlear implant 
(DACI) users.
MATERIALS AND METHODS: Twenty patients (37 ears with mixed hearing loss) were 
provided and fitted with a SOTA power hearing aid. Before and after an 
acclimatization period of at least 4 weeks, word recognition scores (WRS) in 
quiet and in noise were studied, as well as the speech reception threshold in 
noise (SRT). The outcomes were compared retrospectively to a second group of 45 
patients (47 ears) using the DACI device. Based on the severity of the mixed 
hearing loss and the available gain and MPO of the SOTA hearing aid, the hearing 
aid and DACI users were subdivided into groups with prediction of sufficient, 
partially insufficient, or very insufficient hearing aid performance.
RESULTS: The patients with predicted adequate SOTA hearing aid performance 
indeed showed the best WRS in quiet and in noise when compared to patients with 
predicted inferior outcomes. Insufficient hearing aid performance at one or more 
frequencies led to a gradual decrease in hearing aid benefit, validating the 
criteria used here and in the accompanying paper. All DACI patients showed 
outcomes at the same level as the adequate hearing aid performance group, being 
significantly better than those of the groups with inadequate hearing aid 
performance. Whereas WRS in quiet and noise were sensitive to insufficient gain 
or output, showing significant differences between the SOTA hearing aid and DACI 
groups, the SRT in noise was less sensitive.
CONCLUSIONS: Limitations of outcomes in mixed hearing loss individuals due to 
insufficient hearing aid performance can be accurately predicted by applying a 
commonly used fitting rule and the 35-dB dynamic range rule on the hearing aid 
specifications. Evidently, when outcomes in patients with mixed hearing loss 
using the most powerful hearing aids are insufficient, bypassing the middle ear 
with a powerful active middle ear implant or direct acoustic implant can be a 
promising alternative treatment.

The Author(s). Published by S. Karger AG, Basel.

DOI: 10.1159/000504285
PMCID: PMC7265759
PMID: 32007992 [Indexed for MEDLINE]

Conflict of interest statement: This work is part of the doctoral thesis of N.W. 
and was supported by a project grant from Cochlear Ltd. and the DFG Cluster of 
Excellence EXC1077/1 “Hearing4all.” All authors received travel support from 
Cochlear Ltd. for meetings. B. Waldmann is an employee of Cochlear Ltd., which 
provided the declared support.


267. Technol Health Care. 2021;29(S1):141-152. doi: 10.3233/THC-218015.

A method for enhancing speech and warning signals based on parallel 
convolutional neural networks in a noisy environment.

Kang HL(1)(1), Na SD(2)(1), Kim MN(3).

Author information:
(1)Department of Medical & Biological Engineering, Graduate School, Kyungpook 
National University, Daegu 700-422, Korea.
(2)Department of Biomedical Engineering, Kyungpook National University Hospital, 
Daegu 700-422, Korea.
(3)Department of Biomedical Engineering, School of Medicine, Kyungpook National 
University, Daegu 700-422, Korea.

BACKGROUND: Digital hearing aids are based on technology that amplifies sound 
and removes noise according to the frequency of hearing loss in hearing loss 
patients. However, within the noise removed is a warning sound that alert the 
listener; the listener may be exposed to danger because the warning sound is not 
recognized.
OBJECTIVE: In this paper, a deep learning model was used to improve these limits 
and propose a method to distinguish the warning sound in speech signals mixed 
with noise. In addition, the improved speech and warning sound were derived by 
removing noise present in the classification sound signals.
METHODS: To classify the sound dataset, an adaptive convolution filter that 
changes according to two signals is proposed. The proposed convolution filter is 
applied to the PCNNs model to analyze the characteristics of the time and 
frequency domains of the dataset and classify the presence or absence of warning 
sound. In addition, the CEDN model was used to improve the intelligibility of 
the warning and the speech in the signal based on the warning sound 
classification from the proposed PCNNs model.
RESULTS: Experimental results show that the PCNNs model using the proposed 
multiplicative filters is efficient for analyzing sound signals with complex 
frequencies. In addition, the CEDN model was used to improve the intelligibility 
of the warning and the speech in the signal based on the warning sound 
classification from the proposed PCNNs model.
CONVLUSION: We confirmed that the PCNN model with the proposed filter showed the 
highest training rate, lowest error rate, and the most stable results. In 
addition, the CEDN model confirmed that speech and warning sounds were 
recognized, but it was confirmed that there was a limitation in clearly 
recognizing speech as the noise ratio increased.

DOI: 10.3233/THC-218015
PMCID: PMC8150607
PMID: 33682754 [Indexed for MEDLINE]

Conflict of interest statement: None to report.


268. Int J Speech Lang Pathol. 2014 Feb;16(1):69-81. doi: 
10.3109/17549507.2013.808698. Epub 2013 Sep 3.

Typical consonant cluster acquisition in auditory-verbal children with 
early-identified severe/profound hearing loss.

Fulcher A(1), Baker E, Purcell A, Munro N.

Author information:
(1)The University of Sydney , Sydney , Australia.

Early-identified severe/profound hearing loss (HL) following universal newborn 
hearing screening (UNHS) has been associated with improved speech and language 
outcomes. However, speech outcome reports have typically been based on broad 
measures of speech intelligibility and/or singleton consonant accuracy, with 
little known about production of consonant clusters. Using a prospective design, 
the range and accuracy of consonant clusters produced by a homogenous cohort of 
12 children early-identified with severe/profound HL aged 3- and 4-years were 
examined. All children demonstrated bilateral aided thresholds within a range of 
15-25 dB HL across all frequencies, were optimally amplified with cochlear 
implants (11/12) or hearing aids (1/12), and attended auditory-verbal (AV) early 
intervention. Standardized speech and language assessments were administered. 
Consonant clusters were strategically sampled in single-word and conversational 
speech contexts. All standard scores for speech, receptive, and expressive 
language were within normal limits. All children produced consonant clusters 
commensurate with expectations for typically-developing hearing peers at 3- and 
4- years-of-age. Children's production of phonetically complex morphophonemes 
(final consonant clusters marking grammatical morphemes) was also in keeping 
with developmental expectations. Factors which contributed to these encouraging 
outcomes require further investigation.

DOI: 10.3109/17549507.2013.808698
PMID: 24001172 [Indexed for MEDLINE]


269. Hear Res. 2020 Dec;398:108101. doi: 10.1016/j.heares.2020.108101. Epub 2020 Oct 
22.

Factors influencing classification of frequency following responses to speech 
and music stimuli.

Losorelli S(1), Kaneshiro B(2), Musacchia GA(3), Blevins NH(4), Fitzgerald 
MB(5).

Author information:
(1)Department of Otolaryngology Head and Neck Surgery, Stanford University 
School of Medicine, Palo Alto, CA, USA. Electronic address: 
slosorelli@stanford.edu.
(2)Department of Otolaryngology Head and Neck Surgery, Stanford University 
School of Medicine, Palo Alto, CA, USA. Electronic address: 
blairbo@ccrma.stanford.edu.
(3)Department of Otolaryngology Head and Neck Surgery, Stanford University 
School of Medicine, Palo Alto, CA, USA; Department of Audiology, University of 
the Pacific, San Francisco, CA, USA. Electronic address: gmusacchia@pacific.edu.
(4)Department of Otolaryngology Head and Neck Surgery, Stanford University 
School of Medicine, Palo Alto, CA, USA. Electronic address: 
nblevins@stanford.edu.
(5)Department of Otolaryngology Head and Neck Surgery, Stanford University 
School of Medicine, Palo Alto, CA, USA. Electronic address: fitzmb@stanford.edu.

Successful mapping of meaningful labels to sound input requires accurate 
representation of that sound's acoustic variances in time and spectrum. For some 
individuals, such as children or those with hearing loss, having an objective 
measure of the integrity of this representation could be useful. Classification 
is a promising machine learning approach which can be used to objectively 
predict a stimulus label from the brain response. This approach has been 
previously used with auditory evoked potentials (AEP) such as the frequency 
following response (FFR), but a number of key issues remain unresolved before 
classification can be translated into clinical practice. Specifically, past 
efforts at FFR classification have used data from a given subject for both 
training and testing the classifier. It is also unclear which components of the 
FFR elicit optimal classification accuracy. To address these issues, we recorded 
FFRs from 13 adults with normal hearing in response to speech and music stimuli. 
We compared labeling accuracy of two cross-validation classification approaches 
using FFR data: (1) a more traditional method combining subject data in both the 
training and testing set, and (2) a "leave-one-out" approach, in which subject 
data is classified based on a model built exclusively from the data of other 
individuals. We also examined classification accuracy on decomposed and 
time-segmented FFRs. Our results indicate that the accuracy of 
leave-one-subject-out cross validation approaches that obtained in the more 
conventional cross-validation classifications while allowing a subject's results 
to be analysed with respect to normative data pooled from a separate population. 
In addition, we demonstrate that classification accuracy is highest when the 
entire FFR is used to train the classifier. Taken together, these efforts 
contribute key steps toward translation of classification-based machine learning 
approaches into clinical practice.

Copyright © 2020. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2020.108101
PMID: 33142106 [Indexed for MEDLINE]


270. Int J Audiol. 2018 Jun;57(sup3):S81-S91. doi: 10.1080/14992027.2017.1308564. 
Epub 2017 Apr 10.

Acoustic and perceptual effects of magnifying interaural difference cues in a 
simulated "binaural" hearing aid.

de Taillez T(1), Grimm G(1), Kollmeier B(1), Neher T(1).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , Universität 
Oldenburg , Oldenburg , Germany.

OBJECTIVE: To investigate the influence of an algorithm designed to enhance or 
magnify interaural difference cues on speech signals in noisy, spatially complex 
conditions using both technical and perceptual measurements. To also investigate 
the combination of interaural magnification (IM), monaural microphone 
directionality (DIR), and binaural coherence-based noise reduction (BC).
DESIGN: Speech-in-noise stimuli were generated using virtual acoustics. A 
computational model of binaural hearing was used to analyse the spatial effects 
of IM. Predicted speech quality changes and signal-to-noise-ratio (SNR) 
improvements were also considered. Additionally, a listening test was carried 
out to assess speech intelligibility and quality.
STUDY SAMPLE: Listeners aged 65-79 years with and without sensorineural hearing 
loss (N = 10 each).
RESULTS: IM increased the horizontal separation of concurrent directional sound 
sources without introducing any major artefacts. In situations with diffuse 
noise, however, the interaural difference cues were distorted. Preprocessing the 
binaural input signals with DIR reduced distortion. IM influenced neither speech 
intelligibility nor speech quality.
CONCLUSIONS: The IM algorithm tested here failed to improve speech perception in 
noise, probably because of the dispersion and inconsistent magnification of 
interaural difference cues in complex environments.

DOI: 10.1080/14992027.2017.1308564
PMID: 28395561 [Indexed for MEDLINE]


271. Hear Res. 2006 Feb;212(1-2):128-39. doi: 10.1016/j.heares.2005.11.006. Epub 2006 
Jan 19.

Mapping quantitative trait loci for hearing loss in Black Swiss mice.

Drayton M(1), Noben-Trauth K.

Author information:
(1)Section on Neurogenetics, Laboratory of Molecular Biology, National Institute 
on Deafness and Other Communication Disorders, National Institutes of Health, 5 
Research Court, Rockville, MD 20850, USA.

In common inbred mouse strains, hearing loss is a highly prevalent quantitative 
trait, which is mainly controlled by the Cdh23(753A) variant and alleles at 
numerous other strain-specific loci. Here, we investigated the genetic basis of 
hearing loss in non-inbred strains. Mice of Swiss Webster, CF-1, NIH Swiss, ICR, 
and Black Swiss strains exhibited hearing profiles characteristic of 
progressive, sensorineural hearing impairment. In particular, CF-1, Black Swiss, 
and NIH Swiss mice showed early-onset hearing impairment, ICR and Swiss Webster 
mice expressed a delayed-onset hearing loss, and NMRI mice had normal hearing. 
By quantitative trait locus (QTL) mapping, two significant QTLs were identified 
underlying hearing loss in Black Swiss mice: one QTL mapped to chromosome (chr) 
10 (named ahl5, LOD 8.9, peak association 35-42 cM) and a second QTL localized 
to chr 18 (ahl6, LOD 3.8, 38-44 cM). Ahl5 and ahl6 account for 61% and 32% of 
the variation in the backcross, respectively. Cadherin 23 (Cdh23) and 
protocadherin 15 (Pcdh15), mapping within the 95% confidence interval of ahl5, 
bear nucleotide polymorphisms in coding exons, but these appear to be unrelated 
to the hearing phenotype. Haplotype analyses across the Cdh23 locus demonstrated 
the phylogenetic relationship between Black Swiss and common inbred strains.

DOI: 10.1016/j.heares.2005.11.006
PMID: 16426780 [Indexed for MEDLINE]


272. Hear Res. 2016 Mar;333:136-149. doi: 10.1016/j.heares.2016.01.005. Epub 2016 Jan 
14.

A neural-based vocoder implementation for evaluating cochlear implant coding 
strategies.

El Boghdady N(1), Kegel A(2), Lai WK(2), Dillier N(2).

Author information:
(1)Institute for Neuroinformatics (INI), Universität Zürich (UZH)/ ETH Zürich 
(ETHZ), Zürich, Switzerland. Electronic address: n.el.boghdady@umcg.nl.
(2)Laboratory of Experimental Audiology, ENT Department, Universitätsspital 
Zürich (USZ), Zürich, Switzerland.

Most simulations of cochlear implant (CI) coding strategies rely on standard 
vocoders that are based on purely signal processing techniques. However, these 
models neither account for various biophysical phenomena, such as neural 
stochasticity and refractoriness, nor for effects of electrical stimulation, 
such as spectral smearing as a function of stimulus intensity. In this paper, a 
neural model that accounts for stochastic firing, parasitic spread of excitation 
across neuron populations, and neuronal refractoriness, was developed and 
augmented as a preprocessing stage for a standard 22-channel noise-band vocoder. 
This model was used to subjectively and objectively assess consonant 
discrimination in commercial and experimental coding strategies. Stimuli 
consisting of consonant-vowel (CV) and vowel-consonant-vowel (VCV) tokens were 
processed by either the Advanced Combination Encoder (ACE) or the Excitability 
Controlled Coding (ECC) strategies, and later resynthesized to audio using the 
aforementioned vocoder model. Baseline performance was measured using 
unprocessed versions of the speech tokens. Behavioural responses were collected 
from seven normal hearing (NH) volunteers, while EEG data were recorded from 
five NH participants. Psychophysical results indicate that while there may be a 
difference in consonant perception between the two tested coding strategies, 
mismatch negativity (MMN) waveforms do not show any marked trends in CV or VCV 
contrast discrimination.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.01.005
PMID: 26775182 [Indexed for MEDLINE]


273. Hear Res. 2001 May;155(1-2):82-90. doi: 10.1016/s0378-5955(01)00250-7.

Genetic basis for susceptibility to noise-induced hearing loss in mice.

Davis RR(1), Newlander JK, Ling X, Cortopassi GA, Krieg EF, Erway LC.

Author information:
(1)Hearing Loss Prevention Section, Division of Applied Research and Technology, 
National Institute for Occupational Safety and Health Centers for Disease 
Control and Prevention, Mailstop C-27, 4676 Columbia Parkway, Cincinnati OH 
45226, USA. rrdl@cdc.gov

The C57BL/6J (B6) and DBA/2J (D2) inbred strains of mice exhibit an age-related 
hearing loss (AHL) due to a recessive gene (Ahl) that maps to Chromosome 10. The 
Ahl gene is also implicated in the susceptibility to noise-induced hearing loss 
(NIHL). The B6 mice (Ahl/Ahl) are more susceptible to NIHL than the CBA/CaJ (CB) 
mice (+(Ahl)). The B6xD2.F(1) hybrid mice (Ahl/Ahl) are more susceptible to NIHL 
than the CBxB6.F(1) mice (+/Ahl) [Erway et al., 1996. Hear. Res. 93, 181-187]. 
These genetic effects implicate the Ahl gene as contributing to NIHL 
susceptibility. The present study demonstrates segregation for the putative Ahl 
gene and mapping of such a gene to Chromosome 10, consistent with other 
independent mapping of Ahl for AHL in 10 strains of mice [Johnson et al., 2000. 
Genomics 70, 171-180]. The present study was based on a conventional cross 
between two inbred strains, CBxB6.F(1) backcrossed to B6 with segregation for 
the putative +/Ahl:Ahl/Ahl. These backcross progeny were exposed to 110 dB SPL 
noise for 8 h. All of the progeny were tested for auditory evoked brainstem 
responses and analyzed for any significant permanent threshold shift of NIHL. 
Cluster analyses were used to distinguish the two putative genotypes, the least 
affected with NIHL (+/Ahl) and most affected with PTS (Ahl/Ahl). Approximately 
1/2 of the backcross progeny exhibited PTS, particularly at 16 kHz. These mice 
were genotyped for two D10Mit markers. Quantitative trait loci analyses (log of 
the odds=15) indicated association of the genetic factor within a few 
centiMorgan of the best evidence for Ahl [Johnson et al., 2000. Genomics 70, 
171-180]. All of the available evidence supports a role for the Ahl gene in both 
AHL and NIHL among these strains of mice.

DOI: 10.1016/s0378-5955(01)00250-7
PMID: 11335078 [Indexed for MEDLINE]


274. J Am Acad Audiol. 2019 Jun;30(6):516-532. doi: 10.3766/jaaa.17129. Epub 2019 Mar 
7.

How do Hearing Aid Owners Acquire Hearing Aid Management Skills?

Bennett RJ(1)(2), Meyer CJ(3), Eikelboom RH(1)(2)(4).

Author information:
(1)Ear Science Institute Australia, Subiaco, Australia.
(2)Ear Sciences Centre, The University of Western Australia, Nedlands, 
Australia.
(3)School of Health and Rehabilitation Sciences, University of Queensland, St. 
Lucia, Australia.
(4)Department of Speech-Language Pathology and Audiology, University of 
Pretoria, Pretoria, South Africa.

BACKGROUND: Clinical studies have found up to 90% of hearing aid owners 
demonstrate difficulty with basic hearing aid management tasks and almost 50% of 
hearing aid owners self-report not receiving enough practical help from their 
clinician regarding how to use their hearing aid. Although studies have 
highlighted the overwhelming amount of information and training required to 
learn how to use a hearing aid appropriately, a gap remains in the literature 
regarding the range of methods by which hearing aid owners acquire the knowledge 
and skills for hearing aid use, and whether these approaches are considered 
beneficial.
PURPOSE: To gain insight into how both hearing aid owners and hearing health 
clinicians view the acquisition of hearing aid management skills and the 
efficacy of currently used methods of hearing aid training.
RESEARCH DESIGN: Concept mapping techniques were used to identify key themes, 
wherein participants generated, sorted, and rated the importance of statements 
in response to the question "How do hearing aid owners learn the skills required 
to use, handle, manage, maintain, and care for their hearing aids?"
STUDY SAMPLE: Twenty-four hearing aid owners (aged 56-91 years; 54.2% male) and 
22 clinicians (aged 32-69 years; 9.1% male).
DATA COLLECTION AND ANALYSIS: Participant perspectives were collected via group 
concept mapping sessions in October 2015. Hierarchical cluster analysis was used 
to identify themes and develop a framework for understanding how skill 
acquisition occurs. Participants rated each method of hearing aid skill 
acquisition as to how beneficial it was and how often it was used.
RESULTS: Participants identified 75 unique items describing how hearing aid 
management skills are acquired within six concepts: (1) Relationship with the 
clinician, (2) clinician as a source of knowledge and support, (3) hands-on 
experience, (4) seeking additional information, (5) asking support people for 
help, and (6) external resources.
CONCLUSIONS: The results of this study highlight the diverse methods and sources 
by which hearing aid owners learn the skills necessary to use, manage, and 
maintain their hearing aids. Significant emphasis was placed on the role of the 
hearing health clinician to provide training, support, and an ongoing 
professional relationship, with lesser roles played by family, friends, and 
other health professionals.

American Academy of Audiology.

DOI: 10.3766/jaaa.17129
PMID: 30969909 [Indexed for MEDLINE]


275. Brain Struct Funct. 2021 Jun;226(5):1387-1388. doi: 10.1007/s00429-021-02263-2. 
Epub 2021 Apr 12.

Rebuttal to: Neuroanatomical changes associated with age-related hearing loss 
and listening effort.

Rosemann S(1)(2), Thiel C(3)(4).

Author information:
(1)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Ammerländer Heerstraße 114-118, 26111, Oldenburg, Germany.
(3)Biological Psychology, Department of Psychology, Department for Medicine and 
Health Sciences, Carl-von-Ossietzky Universität Oldenburg, Ammerländer 
Heerstraße 114-118, 26111, Oldenburg, Germany. 
christiane.thiel@uni-oldenburg.de.
(4)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, Ammerländer Heerstraße 114-118, 26111, Oldenburg, Germany. 
christiane.thiel@uni-oldenburg.de.

Comment on
    Brain Struct Funct. 2020 Dec;225(9):2689-2700.

DOI: 10.1007/s00429-021-02263-2
PMCID: PMC8096735
PMID: 33844051 [Indexed for MEDLINE]


276. J Neurosci. 2020 Jan 8;40(2):343-354. doi: 10.1523/JNEUROSCI.2784-18.2019. Epub 
2019 Nov 12.

Temporal Coding of Single Auditory Nerve Fibers Is Not Degraded in Aging 
Gerbils.

Heeringa AN(1), Zhang L(1), Ashida G(1), Beutelmann R(1), Steenken F(1), Köppl 
C(2).

Author information:
(1)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129 Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129 Oldenburg, Germany 
christine.koeppl@uni-oldenburg.de.

People suffering from age-related hearing loss typically present with deficits 
in temporal processing tasks. Temporal processing deficits have also been shown 
in single-unit studies at the level of the auditory brainstem, midbrain, and 
cortex of aged animals. In this study, we explored whether temporal coding is 
already affected at the level of the input to the central auditory system. 
Single-unit auditory nerve fiber recordings were obtained from 41 Mongolian 
gerbils of either sex, divided between young, middle-aged, and old gerbils. 
Temporal coding quality was evaluated as vector strength in response to tones at 
best frequency, and by constructing shuffled and cross-stimulus 
autocorrelograms, and reverse correlations, from responses to 1 s noise bursts 
at 10-30 dB sensation level (dB above threshold). At comparable sensation 
levels, all measures showed that temporal coding was not altered in auditory 
nerve fibers of aging gerbils. Furthermore, both temporal fine structure and 
envelope coding remained unaffected. However, spontaneous rates were decreased 
in aging gerbils. Importantly, despite elevated pure tone thresholds, the 
frequency tuning of auditory nerve fibers was not affected. These results 
suggest that age-related temporal coding deficits arise more centrally, possibly 
due to a loss of auditory nerve fibers (or their peripheral synapses) but not 
due to qualitative changes in the responses of remaining auditory nerve fibers. 
The reduced spontaneous rate and elevated thresholds, but normal frequency 
tuning, of aged auditory nerve fibers can be explained by the well known 
reduction of endocochlear potential due to strial dysfunction in aged 
gerbils.SIGNIFICANCE STATEMENT As our society ages, age-related hearing deficits 
become ever more prevalent. Apart from decreased hearing sensitivity, elderly 
people often suffer from a reduced ability to communicate in daily settings, 
which is thought to be caused by known age-related deficits in auditory temporal 
processing. The current study demonstrated, using several different stimuli and 
analysis techniques, that these putative temporal processing deficits are not 
apparent in responses of single-unit auditory nerve fibers of quiet-aged 
gerbils. This suggests that age-related temporal processing deficits may develop 
more central to the auditory nerve, possibly due to a reduced population of 
active auditory nerve fibers, which will be of importance for the development of 
treatments for age-related hearing disorders.

Copyright © 2020 the authors.

DOI: 10.1523/JNEUROSCI.2784-18.2019
PMCID: PMC6948943
PMID: 31719164 [Indexed for MEDLINE]


277. Ear Hear. 2015 Nov-Dec;36(6):e326-35. doi: 10.1097/AUD.0000000000000186.

Fast, Continuous Audiogram Estimation Using Machine Learning.

Song XD(1), Wallace BM, Gardner JR, Ledbetter NM, Weinberger KQ, Barbour DL.

Author information:
(1)1Laboratory of Sensory Neuroscience and Neuroengineering, Department of 
Biomedical Engineering, Washington University in St. Louis, St. Louis, Missouri, 
USA; 2Program in Audiology and Communication Sciences, Washington University in 
St. Louis, St. Louis, Missouri, USA; and 3Department of Computer Science & 
Engineering, Washington University in St. Louis, St. Louis, Missouri, USA.

OBJECTIVES: Pure-tone audiometry has been a staple of hearing assessments for 
decades. Many different procedures have been proposed for measuring thresholds 
with pure tones by systematically manipulating intensity one frequency at a time 
until a discrete threshold function is determined. The authors have developed a 
novel nonparametric approach for estimating a continuous threshold audiogram 
using Bayesian estimation and machine learning classification. The objective of 
this study was to assess the accuracy and reliability of this new method 
relative to a commonly used threshold measurement technique.
DESIGN: The authors performed air conduction pure-tone audiometry on 21 
participants between the ages of 18 and 90 years with varying degrees of hearing 
ability. Two repetitions of automated machine learning audiogram estimation and 
one repetition of conventional modified Hughson-Westlake ascending-descending 
audiogram estimation were acquired by an audiologist. The estimated hearing 
thresholds of these two techniques were compared at standard audiogram 
frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz).
RESULTS: The two threshold estimate methods delivered very similar estimates at 
standard audiogram frequencies. Specifically, the mean absolute difference 
between estimates was 4.16 ± 3.76 dB HL. The mean absolute difference between 
repeated measurements of the new machine learning procedure was 4.51 ± 4.45 dB 
HL. These values compare favorably with those of other threshold audiogram 
estimation procedures. Furthermore, the machine learning method generated 
threshold estimates from significantly fewer samples than the modified 
Hughson-Westlake procedure while returning a continuous threshold estimate as a 
function of frequency.
CONCLUSIONS: The new machine learning audiogram estimation technique produces 
continuous threshold audiogram estimates accurately, reliably, and efficiently, 
making it a strong candidate for widespread application in clinical and research 
audiometry.

DOI: 10.1097/AUD.0000000000000186
PMCID: PMC4709018
PMID: 26258575 [Indexed for MEDLINE]


278. Int J Audiol. 2016;55(5):285-94. doi: 10.3109/14992027.2015.1120892. Epub 2016 
Feb 15.

Predicting three-month and 12-month post-fitting real-world hearing-aid outcome 
using pre-fitting acceptable noise level (ANL).

Wu YH(1), Ho HC(2)(3), Hsiao SH(2)(3), Brummet RB(4), Chipara O(4).

Author information:
(1)a Department of Communication Sciences and Disorders , The University of Iowa 
, Iowa City , USA .
(2)b Department of Otolaryngology , Buddhist Dalin Tzu-Chi General Hospital , 
Chiayi , Taiwan .
(3)c School of Medicine, Tzu-Chi University , Hualien , Taiwan , and.
(4)d Department of Computer Science , The University of Iowa , Iowa City , USA.

OBJECTIVE: Determine the extent to which pre-fitting acceptable noise level 
(ANL), with or without other predictors such as hearing-aid experience, can 
predict real-world hearing-aid outcomes at three and 12 months post-fitting.
DESIGN: ANLs were measured before hearing-aid fitting. Post-fitting outcome was 
assessed using the international outcome inventory for hearing aids (IOI-HA) and 
a hearing-aid use questionnaire. Models that predicted outcomes (successful vs. 
unsuccessful) were built using logistic regression and several machine learning 
algorithms, and were evaluated using the cross-validation technique.
STUDY SAMPLE: A total of 132 adults with hearing impairment.
RESULTS: The prediction accuracy of the models ranged from 61% to 68% (IOI-HA) 
and from 55% to 61% (hearing-aid use questionnaire). The models performed more 
poorly in predicting 12-month than three-month outcomes. The ANL cutoff between 
successful and unsuccessful users was higher for experienced (∼18 dB) than 
first-time hearing-aid users (∼10 dB), indicating that most experienced users 
will be predicted as successful users regardless of their ANLs.
CONCLUSIONS: Pre-fitting ANL is more useful in predicting short-term (three 
months) hearing-aid outcomes for first-time users, as measured by the IOI-HA. 
The prediction accuracy was lower than the accuracy reported by some previous 
research that used a cross-sectional design.

DOI: 10.3109/14992027.2015.1120892
PMCID: PMC4823154
PMID: 26878163 [Indexed for MEDLINE]

Conflict of interest statement: DECLARATION OF INTEREST The authors report no 
conflicts of interest. The authors alone are responsible for the content and 
writing of the paper.


279. J Vet Intern Med. 2006 Nov-Dec;20(6):1355-62. doi: 
10.1892/0891-6640(2006)20[1355:pouabd]2.0.co;2.

Prevalence of unilateral and bilateral deafness in border collies and 
association with phenotype.

Platt S(1), Freeman J, di Stefani A, Wieczorek L, Henley W.

Author information:
(1)Centre for Small Animal Studies, Animal Health Trust, Lanwades Park, 
Kentford, Newmar- ket, Suffolk CB8 7UU, UK. Simon.platt@aht.org.uk

BACKGROUND: Congenital sensorineural deafness (CSD) occurs in Border Collies, 
but its prevalence and inheritance are unknown. This study estimated the 
prevalence of CSD in Border Collies and investigated its association with 
phenotypic attributes linked to the merle gene, including coat pigmentation and 
iris color.
HYPOTHESIS: Deafness in Border Collies is associated with pigmentation patterns 
linked to the merle gene.
ANIMALS: A total of 2597 Border Collies from the United Kingdom.
METHODS: A retrospective study of Border Collies tested, during 1994-2002, by 
using brainstem auditory evoked responses. Associations between deafness and 
phenotypic attributes were assessed by using generalized logistic regression.
RESULTS: The prevalence of CSD in puppies was estimated as 2.8%. The 
corresponding rates of unilateral and bilateral CSD were 2.3 and 0.5%, 
respectively. Adjustment for clustering of hearing status by litter reduced the 
overall prevalence estimate to 1.6%. There was no association between CSD and 
sex (P = .2). Deaf Border Collies had higher rates of merle coat pigmentation, 
blue iris pigment, and excess white on the head than normal hearing Border 
Collies (all P < .001). The odds of deafness were increased by a factor of 14 
for Border Collies with deaf dams, relative to the odds for dogs with normal 
dams (P = .007), after adjustment for phenotypic attributes.
CONCLUSIONS AND CLINICAL IMPORTANCE: Associations between CSD and pigmentation 
patterns linked to the merle gene were demonstrated for Border Collies. Evidence 
for an inherited component to CSD in Border Collies supports selective breeding 
from only tested and normal parents to reduce the prevalence of this disease.

DOI: 10.1892/0891-6640(2006)20[1355:pouabd]2.0.co;2
PMID: 17186850 [Indexed for MEDLINE]


280. Hear Res. 2016 Jan;331:13-26. doi: 10.1016/j.heares.2015.10.003. Epub 2015 Oct 
22.

Thin-film micro-electrode stimulation of the cochlea in rats exposed to 
aminoglycoside induced hearing loss.

Allitt BJ(1), Harris AR(2), Morgan SJ(3), Clark GM(4), Paolini AG(5).

Author information:
(1)School of Psychological Science, La Trobe University, Bundoora, Victoria, 
3086, Australia; ARC Centre of Excellence for Electromaterials Science, 
Australia; Department of Physiology, Monash University, Clayton, 3800, 
Australia. Electronic address: ben.allitt@monash.edu.
(2)School of Psychological Science, La Trobe University, Bundoora, Victoria, 
3086, Australia; ARC Centre of Excellence for Electromaterials Science, 
Australia.
(3)School of Psychological Science, La Trobe University, Bundoora, Victoria, 
3086, Australia.
(4)School of Psychological Science, La Trobe University, Bundoora, Victoria, 
3086, Australia; ARC Centre of Excellence for Electromaterials Science, 
Australia; Centre for Neural Engineering, University of Melbourne, Australia.
(5)School of Psychological Science, La Trobe University, Bundoora, Victoria, 
3086, Australia; ARC Centre of Excellence for Electromaterials Science, 
Australia; School of Health Sciences, College of Science Engineering & Health, 
RMIT University, Bundoora, Australia.

The multi-channel cochlear implant (CI) provides sound and speech perception to 
thousands of individuals who would otherwise be deaf. Broad activation of 
auditory nerve fibres when using a CI results in poor frequency discrimination. 
The CI also provides users with poor amplitude perception due to elicitation of 
a narrow dynamic range. Provision of more discrete frequency perception and a 
greater control over amplitude may allow users to better distinguish speech in 
noise and to segregate sound sources. In this research, thin-film (TF) high 
density micro-electrode arrays and conventional platinum ring electrode arrays 
were used to stimulate the cochlea of rats administered sensorineural hearing 
loss (SNHL) via ototoxic insult, with neural responses taken at 434 multiunit 
clusters in the central nucleus of the inferior colliculus (CIC). Threshold, 
dynamic range and broadness of response were used to compare electrode arrays. A 
stronger current was required to elicit CIC threshold when using the TF array 
compared to the platinum ring electrode array. TF stimulation also elicited a 
narrower dynamic range than the PR counterpart. However, monopolar stimulation 
using the TF array produced more localised CIC responses than other stimulation 
strategies. These results suggest that individuals with SNHL could benefit from 
micro stimulation of the cochlea using a monopolar configuration which may 
provide discrete frequency perception when using TF electrode arrays.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.10.003
PMID: 26471198 [Indexed for MEDLINE]


281. Ear Nose Throat J. 2018 Jul;97(7):E36-E40. doi: 10.1177/014556131809700706.

Analysis of the audiogram shape in patients with idiopathic sudden sensorineural 
hearing loss using a cluster analysis.

Watanabe T(1), Suzuki M.

Author information:
(1)Department of Otolaryngology, Head and Neck Surgery, Oita University Faculty 
of Medicine, 1-1, Idaigoka, Hasama-machi, Yufu-city, Oita 879-5593, Japan. 
twatanab@med.oita-u.ac.jp.

We performed a cluster analysis to classify the audiogram shape in patients with 
idiopathic sudden sensorineural hearing loss (ISSNHL). We also investigated 
whether the audiogram shape is a prognostic indicator in the management of 
ISSNHL. A total of 115 inpatients with ISSNHL treated between 2001 and 2010 were 
analyzed. The data collected included age, sex, duration of hearing loss at the 
time of treatment, and the presence or absence of tinnitus, vertigo, diabetes, 
nystagmus, and canal paresis. A hierarchical cluster analysis was performed 
using the hearing threshold for each frequency on audiograms as variables. A 
logistic regression model was used for the prognostic analysis. The audiogram 
shape was classified into four clusters: (1) crossing horizontally pattern of 
all tones; (2) up-sloping pattern of low-tone loss; (3) deaf pattern; and (4) 
down-sloping pattern of high-tone loss. The age of the patient, presence of 
canal paresis, and audiogram shape showed statistically significant 
relationships with hearing improvement. The audiogram shape based on the cluster 
analysis demonstrated a significant relationship with hearing improvement in 
patients with ISSNHL. Further studies are needed to elucidate the underlying 
etiology of each audiogram shape.

DOI: 10.1177/014556131809700706
PMID: 30036445 [Indexed for MEDLINE]


282. Hear Res. 2018 Jul;364:25-37. doi: 10.1016/j.heares.2018.04.003. Epub 2018 Apr 
9.

Electric-acoustic forward masking in cochlear implant users with ipsilateral 
residual hearing.

Imsiecke M(1), Krüger B(2), Büchner A(3), Lenarz T(4), Nogueira W(5).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hanover, Germany. 
Electronic address: Imsiecke.Marina@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
Krueger.Benjamin@mh-hannover.de.
(3)Department of Otolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
Buechner.Andreas@mh-hannover.de.
(4)Department of Otolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
Lenarz.Thomas@mh-hannover.de.
(5)Department of Otolaryngology, Hannover Medical School, Hanover, Germany; 
Cluster of Excellence 'Hearing4All', Hanover, Germany. Electronic address: 
NogueiraVazquez.Waldo@mh-hannover.de.

In order to investigate the temporal mechanisms of the auditory system, 
psychophysical forward masking experiments were conducted in cochlear implant 
users who had preserved acoustic hearing in the ipsilateral ear. This unique 
electric-acoustic stimulation (EAS) population allowed the measurement of 
threshold recovery functions for acoustic or electric probes in the presence of 
electric or acoustic maskers, respectively. In the electric masking experiment, 
the forward masked threshold elevation of acoustic probes was measured as a 
function of the time interval after the offset of the electric masker, i.e. the 
masker-to-probe interval (MPI). In the acoustic masking experiment, the forward 
masked threshold elevation of electric probe stimuli was investigated under the 
influence of a preceding acoustic masker. Since electric pulse trains directly 
stimulate the auditory nerve, this novel experimental setup allowed the acoustic 
adaptation properties (attributed to the physiology of the hair cells) to be 
differentiated from the subsequent processing by more central mechanisms along 
the auditory pathway. For instance, forward electric masking patterns should 
result more from the auditory-nerve response to electrical stimulation, while 
forward acoustic masking patterns should primarily be the result of the recovery 
from adaptation at the hair-cell neuron interface. Electric masking showed 
prolonged threshold elevation of acoustic probes, which depended significantly 
on the masker-to-probe interval. Additionally, threshold elevation was 
significantly dependent on the similarity between acoustic stimulus frequency 
and electric place frequency, the electric-acoustic frequency difference (EAFD). 
Acoustic masking showed a reduced, but statistically significant effect of 
electric threshold elevation, which did not significantly depend on MPI. Lastly, 
acoustic masking showed longer decay times than electric masking and a reduced 
dependency on EAFD. In conclusion, the forward masking patterns observed for 
combined electric-acoustic stimulation provide further insights into the 
temporal mechanisms of the auditory system. For instance, the asymmetry in the 
amount of threshold elevation, the dependency on EAFD and the time constants for 
the recovery functions of acoustic and electric masking all indicate that there 
must be several processes with different latencies (e.g. neural adaptation, 
depression of spontaneous activity, efferent systems) that are involved in 
forward masking recovery functions.

Copyright © 2018 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2018.04.003
PMID: 29673567 [Indexed for MEDLINE]


283. J Acoust Soc Am. 2017 Apr;141(4):2526. doi: 10.1121/1.4979591.

Extension and evaluation of a near-end listening enhancement algorithm for 
listeners with normal and impaired hearing.

Rennies J(1), Drefs J(1), Hülsmeier D(1), Schepker H(2), Doclo S(2).

Author information:
(1)Project Group Hearing, Speech and Audio Technology, Fraunhofer Institute for 
Digital Media Technology IDMT and Cluster of Excellence Hearing4All, D-26129 
Oldenburg, Germany.
(2)Signal Processing Group, Department of Medical Physics and Acoustics and 
Cluster of Excellence Hearing4All, University of Oldenburg, D-26111 Oldenburg, 
Germany.

In many applications in which speech is played back via a sound reinforcement 
system such as public address systems and mobile phones, speech intelligibility 
is degraded by additive environmental noise. A possible solution to maintain 
high intelligibility in noise is to pre-process the speech signal based on the 
estimated noise power at the position of the listener. The previously proposed 
AdaptDRC algorithm [Schepker, Rennies, and Doclo (2015). J. Acoust. Soc. Am. 
138, 2692-2706] applies both frequency shaping and dynamic range compression 
under an equal-power constraint, where the processing is adaptively controlled 
by short-term estimates of the speech intelligibility index. Previous 
evaluations of the algorithm have focused on normal-hearing listeners. In this 
study, the algorithm was extended with an adaptive gain stage under an 
equal-peak-power constraint, and evaluated with eleven normal-hearing and ten 
mildly to moderately hearing-impaired listeners. For normal-hearing listeners, 
average improvements in speech reception thresholds of about 4 and 8 dB compared 
to the unprocessed reference condition were measured for the original algorithm 
and its extension, respectively. For hearing-impaired listeners, the average 
improvements were about 2 and 6 dB, indicating that the relative improvement due 
to the proposed adaptive gain stage was larger for these listeners than the 
benefit of the original processing stages.

DOI: 10.1121/1.4979591
PMID: 28464693 [Indexed for MEDLINE]


284. Int Arch Occup Environ Health. 2015 Aug;88(6):779-87. doi: 
10.1007/s00420-014-1004-z. Epub 2014 Nov 29.

Prediction of hearing loss among the noise-exposed workers in a steel factory 
using artificial intelligence approach.

Aliabadi M(1), Farhadian M, Darvishi E.

Author information:
(1)Department of Occupational Health, School of Public Health, Hamadan 
University of Medical Science, Hamadan, Iran, mohsen.aliabadi@umsha.ac.ir.

PURPOSE: Prediction of hearing loss in noisy workplaces is considered to be an 
important aspect of hearing conservation program. Artificial intelligence, as a 
new approach, can be used to predict the complex phenomenon such as hearing 
loss. Using artificial neural networks, this study aims to present an empirical 
model for the prediction of the hearing loss threshold among noise-exposed 
workers.
METHODS: Two hundred and ten workers employed in a steel factory were chosen, 
and their occupational exposure histories were collected. To determine the 
hearing loss threshold, the audiometric test was carried out using a calibrated 
audiometer. The personal noise exposure was also measured using a noise 
dosimeter in the workstations of workers. Finally, data obtained five variables, 
which can influence the hearing loss, were used for the development of the 
prediction model. Multilayer feed-forward neural networks with different 
structures were developed using MATLAB software. Neural network structures had 
one hidden layer with the number of neurons being approximately between 5 and 15 
neurons.
RESULTS: The best developed neural networks with one hidden layer and ten 
neurons could accurately predict the hearing loss threshold with RMSE = 2.6 dB 
and R(2) = 0.89. The results also confirmed that neural networks could provide 
more accurate predictions than multiple regressions.
CONCLUSIONS: Since occupational hearing loss is frequently non-curable, results 
of accurate prediction can be used by occupational health experts to modify and 
improve noise exposure conditions.

DOI: 10.1007/s00420-014-1004-z
PMID: 25432298 [Indexed for MEDLINE]


285. Int J Audiol. 2018 Jun;57(sup3):S62-S70. doi: 10.1080/14992027.2017.1294768. 
Epub 2017 Mar 1.

An individualised acoustically transparent earpiece for hearing devices.

Denk F(1), Hiipakka M(1), Kollmeier B(1), Ernst SMA(1).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , University of 
Oldenburg , Oldenburg , Germany.

OBJECTIVE: An important and often still unresolved problem of hearing devices 
such as assistive listening devices and hearing aids is limited user acceptance 
- a primary reason is poor conservation quality of the acoustic environment. 
Approaching a possible solution to this problem, an earpiece prototype is 
presented and evaluated. The prototype is individually and automatically 
calibrated in situ to provide acoustical transparency, i.e., achieving an audio 
perception alike to the open ear.
DESIGN: A comprehensive evaluation was performed, comprising technical 
measurements on an advanced dummy head and listening tests, in which listeners 
directly compared sound perception through the prototype and a simulated open 
ear canal reference.
STUDY SAMPLE: Ten normal hearing subjects, including five expert listeners, 
participated in the listening test.
RESULTS: The technical evaluation verified good achievement of acoustical 
transparency. The psychoacoustic results showed that a reliable distinction 
between the two conditions presented was not possible for relevant communication 
sounds.
CONCLUSION: The prototype can be described as an initial realisation of an 
acoustically transparent hearing system, i.e. a device that does not disturb the 
perception of external sounds. In further developments, the device can be 
considered as the basis for systems integrating high sound quality, hearing 
support and other desired modifications.

DOI: 10.1080/14992027.2017.1294768
PMID: 28635506 [Indexed for MEDLINE]


286. J Int Adv Otol. 2016 Apr;12(1):1-7. doi: 10.5152/iao.2016.510.

Cochlear Implant Evaluation: Prognosis Estimation by Data Mining System.

Guerra-Jiménez G(1), Ramos De Miguel Á, Falcón González JC, Borkoski Barreiro 
SA, Pérez Plasencia D, Ramos Macías Á.

Author information:
(1)Department of Ear Nose Throat, Complejo Hospitalario Insular Materno 
Infantil, Las Palmas de GC, Spain. gloriaguerraj@gmail.com.

OBJECTIVE: Prediction of speech recognition (SR) and quality of life (QoL) 
outcomes after cochlear implantation is one of the most important challenges for 
otologists. By sifting through very large amounts of data, data mining reveals 
trends, patterns, and relationships that might otherwise have remained 
undetected. There are identifiable pre-implantational factors that condition the 
cochlear implantation outcome. Our objective is to design a data mining system 
to predict and classify cochlear implant (CI) predictable benefits in terms of 
SR and QoL in each patient.
MATERIALS AND METHODS: This is an observational study of CI users for at least 
one year. Audiological benefits and its relation to QoL are analyzed using the 
Glasgow Benefit Inventory (GBI) and the Specific Questionnaire (SQ). 
Sociodemographic and medical variables are processed in SPSS Statistics 19.0, 
MatLab® and Weka®. Classifiers are designed using the nearest neighbour and 
decision tree algorithms. Estimators are created by linear logistic regression.
RESULTS: A total of 29 patients (mean age, 55.3 years; 52% female and 48% male) 
including 48% unilateral CI users and 51% bimodal CI users were included in the 
study. GBI improved by 36 points and SQ by 1.7 (p<0.05). Using Nearest Neighbour 
(IB1) algorithm for classifiers, interesting attributes were identified for SR 
and SQ result classification (success rate: 80.7%). Decision tree algorithm 
(J48) showed influencing variables for GBI (success rate: 81%). Estimators by 
linear logistic regression analysis disclosed a precision of 85%, 68%, and 71% 
for SR, GBI, and SQ, respectively.
CONCLUSION: Our study proposes a systematized system to classify and estimate SR 
and QoL improvement based on our initial evaluation to complement decision 
making and patients' information.

DOI: 10.5152/iao.2016.510
PMID: 27340975 [Indexed for MEDLINE]


287. Ear Hear. 2021 Jan/Feb;42(1):163-172. doi: 10.1097/AUD.0000000000000914.

Do Impedance Changes Correlate With a Delayed Hearing Loss After Hybrid L24 
Implantation?

Konrad S(1), Framke T(2), Kludt E(1), Büchner A(1)(3), Lenarz T(1)(3), Paasche 
G(1)(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Institute for Biostatistics, Hannover Medical School, Hannover, Germany.
(3)Hearing4all Cluster of Excellence, Hannover Medical School, Hannover, 
Germany.

OBJECTIVES: Preservation of residual hearing is one of the main goals in present 
cochlear implantation surgery. Especially for this purpose, smaller and softer 
electrode carriers were developed that are to be inserted through the round 
window membrane to minimize trauma. By using these electrodes and insertion 
technique, residual hearing can be preserved in a large number of patients. 
Unfortunately, some of these patients with initially preserved residual hearing 
after cochlear implantation lose it later on. The reason for this is unknown but 
it is speculated about a correlation with an increase in impedance, since 
increased impedance values are linked to intracochlear inflammation and tissue 
reaction. Our hypothesis for this study design was that an increase in impedance 
predicts changes in residual hearing under clinical conditions.
DESIGN: Data of all adult patients (N = 122) receiving a Hybrid-L24 cochlear 
implant at our center between 2005 and early 2015 were retrospectively 
evaluated. Impedance values in Common Ground mode as measured during clinical 
routine and referring audiological test data (audiometric thresholds under 
headphones) were collected. Changes between consecutive measurements were 
calculated for impedance values and hearing thresholds for each patient. 
Correlations between changes in impedances and acoustic hearing thresholds were 
calculated. Average values were compared as well as patients with largest 
impedance changes within the observation period were evaluated separately.
RESULTS: Group mean values of impedances were between 5 and 7 kΩ and stable over 
time with higher values on basal electrode contacts compared with apical 
contacts. Average hearing thresholds at the time of initial fitting were between 
40 to 50 dB (250 Hz) and 90 dB (1 kHz) with a loss of about 10 dB compared with 
preoperative values. Correlation between impedance changes and threshold changes 
was found, but too inconsistently to imply a true relationship. When evaluating 
the 20 patients with the largest impedance changes during the observation period 
(all >1 kΩ from one appointment to the next one), some patients were found where 
hearing loss is timely connected and highly correlated with an unusual impedance 
change. But large impedance changes were also observed without affecting hearing 
thresholds and hearing loss was found without impedance change.
CONCLUSIONS: Changes in impedance as measured during clinical routine cannot be 
taken as an indicator for a late acoustic hearing loss.

Copyright © 2020 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000000914
PMID: 32769433 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


288. Hear Res. 2017 Sep;353:185-196. doi: 10.1016/j.heares.2017.06.014. Epub 2017 Jun 
30.

Simultaneous masking between electric and acoustic stimulation in cochlear 
implant users with residual low-frequency hearing.

Krüger B(1), Büchner A(2), Nogueira W(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Cluster of Excellence 
Hearing4all, Hannover, Germany. Electronic address: 
Krueger.benjamin@mh-hannover.de.
(2)Department of Otolaryngology, Hannover Medical School, Cluster of Excellence 
Hearing4all, Hannover, Germany. Electronic address: 
Buechner.Andreas@mh-hannover.de.
(3)Department of Otolaryngology, Hannover Medical School, Cluster of Excellence 
Hearing4all, Hannover, Germany. Electronic address: 
NogueiraVazquez.Waldo@mh-hannover.de.

Ipsilateral electric-acoustic stimulation (EAS) is becoming increasingly 
important in cochlear implant (CI) treatment. Improvements in electrode designs 
and surgical techniques have contributed to improved hearing preservation during 
implantation. Consequently, CI implantation criteria have been expanded toward 
people with significant residual low-frequency hearing, who may benefit from the 
combined use of both the electric and acoustic stimulation in the same ear. 
However, only few studies have investigated the mutual interaction between 
electric and acoustic stimulation modalities. This work characterizes the 
interaction between both stimulation modalities using psychophysical masking 
experiments and cone beam computer tomography (CBCT). Two psychophysical 
experiments for electric and acoustic masking were performed to measure the 
hearing threshold elevation of a probe stimulus in the presence of a masker 
stimulus. For electric masking, the probe stimulus was an acoustic tone while 
the masker stimulus was an electric pulse train. For acoustic masking, the probe 
stimulus was an electric pulse train and the masker stimulus was an acoustic 
tone. Five EAS users, implanted with a CI and ipsilateral residual low-frequency 
hearing, participated in the study. Masking was determined at different 
electrodes and different acoustic frequencies. CBCT scans were used to determine 
the individual place-pitch frequencies of the intracochlear electrode contacts 
by using the Stakhovskaya place-to-frequency transformation. This allows the 
characterization of masking as a function of the difference between electric and 
acoustic stimulation sites, which we term the electric-acoustic frequency 
difference (EAFD). The results demonstrate a significant elevation of detection 
thresholds for both experiments. In electric masking, acoustic-tone thresholds 
increased exponentially with decreasing EAFD. In contrast, for the acoustic 
masking experiment, threshold elevations were present regardless of the tested 
EAFDs. Based on the present findings, we conclude that there is an asymmetry 
between the electric and the acoustic masker modalities. These observations have 
implications for the design and fitting of EAS sound-coding strategies.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.06.014
PMID: 28688755 [Indexed for MEDLINE]


289. Am J Audiol. 2020 Mar 5;29(1):59-67. doi: 10.1044/2019_AJA-19-00021. Epub 2020 
Feb 3.

A Novel Method for Classifying Hearing Impairment in Epidemiological Studies of 
Aging: The Wisconsin Age-Related Hearing Impairment Classification Scale.

Cruickshanks KJ(1)(2), Nondahl DM(1), Fischer ME(1), Schubert CR(1), Tweed 
TS(1)(3).

Author information:
(1)Department of Ophthalmology and Visual Sciences, School of Medicine and 
Public Health, University of Wisconsin-Madison.
(2)Department of Population Health Sciences, School of Medicine and Public 
Health, University of Wisconsin-Madison.
(3)Department of Communication Sciences and Disorders, University of 
Wisconsin-Madison.

Purpose Longitudinal population-based cohort data were used to develop a 
standardized classification system for age-related hearing impairment using 
thresholds for frequencies (0.5-8 kHz) typically measured in cohort studies. 
Method Audiometric testing data collected in the Epidemiology of Hearing Loss 
Study from participants (n = 1,369) with four visits (1993-1995, 1998-2000, 
2003-2005, and 2009-2010) were included (10,952 audiograms). Cluster analyses 
(Wald's method) were used to identify audiometric patterns. Maximum allowable 
threshold values were defined for each cluster to create an ordered scale. 
Progression was defined as a two-step change. Results An eight-step scale was 
developed to capture audiogram shape and severity of hearing impairment. Of the 
1,094 participants classified as having normal hearing based on a pure-tone 
average, only 25% (n = 277) were classified as Level 1 (all thresholds ≤ 20 dB 
HL) on the new scale, whereas 17% (n = 182) were Levels 4-6. During the 16-year 
follow-up, 64.9% of those at Level 1 progressed. There was little regression 
using this scale. Conclusions This is the first scale developed from 
population-based longitudinal cohort data to capture audiogram shape across 
time. This simple, standardized scale is easy to apply, reduces 
misclassification of normal hearing, and may be a useful method for identifying 
risk factors for early, preclinical, age-related changes in hearing.

DOI: 10.1044/2019_AJA-19-00021
PMCID: PMC7229775
PMID: 32011900 [Indexed for MEDLINE]


290. J Acoust Soc Am. 2020 Jun;147(6):4106. doi: 10.1121/10.0001441.

A talker-independent deep learning algorithm to increase intelligibility for 
hearing-impaired listeners in reverberant competing talker conditions.

Healy EW(1), Johnson EM(1), Delfarah M(2), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, and Center for Cognitive and Brain 
Sciences, The Ohio State University, Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.

Deep learning based speech separation or noise reduction needs to generalize to 
voices not encountered during training and to operate under multiple 
corruptions. The current study provides such a demonstration for 
hearing-impaired (HI) listeners. Sentence intelligibility was assessed under 
conditions of a single interfering talker and substantial amounts of room 
reverberation. A talker-independent deep computational auditory scene analysis 
(CASA) algorithm was employed, in which talkers were separated and 
dereverberated in each time frame (simultaneous grouping stage), then the 
separated frames were organized to form two streams (sequential grouping stage). 
The deep neural networks consisted of specialized convolutional neural networks, 
one based on U-Net and the other a temporal convolutional network. It was found 
that every HI (and normal-hearing, NH) listener received algorithm benefit in 
every condition. Benefit averaged across all conditions ranged from 52 to 76 
percentage points for individual HI listeners and averaged 65 points. Further, 
processed HI intelligibility significantly exceeded unprocessed NH 
intelligibility. Although the current utterance-based model was not implemented 
as a real-time system, a perspective on this important issue is provided. It is 
concluded that deep CASA represents a powerful framework capable of producing 
large increases in HI intelligibility for potentially any two voices.

DOI: 10.1121/10.0001441
PMCID: PMC7314568
PMID: 32611178 [Indexed for MEDLINE]


291. PLoS Comput Biol. 2021 Dec 8;17(12):e1008664. doi: 10.1371/journal.pcbi.1008664. 
eCollection 2021 Dec.

Tinnitus-like "hallucinations" elicited by sensory deprivation in an entropy 
maximization recurrent neural network.

Dotan A(1)(2), Shriki O(1)(3)(2).

Author information:
(1)Department of Cognitive and Brain Sciences, Ben-Gurion University of the 
Negev, Beer-Sheva, Israel.
(2)Zlotowski Center for Neuroscience, Ben-Gurion University of the Negev, 
Beer-Sheva, Israel.
(3)Department of Computer Science, Ben-Gurion University of the Negev, 
Beer-Sheva, Israel.

Sensory deprivation has long been known to cause hallucinations or "phantom" 
sensations, the most common of which is tinnitus induced by hearing loss, 
affecting 10-20% of the population. An observable hearing loss, causing auditory 
sensory deprivation over a band of frequencies, is present in over 90% of people 
with tinnitus. Existing plasticity-based computational models for tinnitus are 
usually driven by homeostatic mechanisms, modeled to fit phenomenological 
findings. Here, we use an objective-driven learning algorithm to model an early 
auditory processing neuronal network, e.g., in the dorsal cochlear nucleus. The 
learning algorithm maximizes the network's output entropy by learning the 
feed-forward and recurrent interactions in the model. We show that the 
connectivity patterns and responses learned by the model display several 
hallmarks of early auditory neuronal networks. We further demonstrate that 
attenuation of peripheral inputs drives the recurrent network towards its 
critical point and transition into a tinnitus-like state. In this state, the 
network activity resembles responses to genuine inputs even in the absence of 
external stimulation, namely, it "hallucinates" auditory responses. These 
findings demonstrate how objective-driven plasticity mechanisms that normally 
act to optimize the network's input representation can also elicit pathologies 
such as tinnitus as a result of sensory deprivation.

DOI: 10.1371/journal.pcbi.1008664
PMCID: PMC8687580
PMID: 34879061 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


292. PLoS One. 2017 Dec 21;12(12):e0188950. doi: 10.1371/journal.pone.0188950. 
eCollection 2017.

Prevalence of paediatric chronic suppurative otitis media and hearing impairment 
in rural Malawi: A cross-sectional survey.

Hunt L(1), Mulwafu W(2), Knott V(3), Ndamala CB(4), Naunje AW(4), Dewhurst S(5), 
Hall A(6), Mortimer K(1).

Author information:
(1)Liverpool School of Tropical Medicine, Liverpool, United Kingdom.
(2)College of Medicine, Blantyre, Malawi.
(3)Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, United Kingdom.
(4)Malawi-Liverpool-Wellcome Trust Clinical Research Program, Blantyre, Malawi.
(5)University Hospitals Leicester NHS Foundation Trust, Leicester, United 
Kingdom.
(6)Independent Scholar, Sheffield, United Kingdom.

OBJECTIVE: To estimate the prevalence of World Health Organization-defined 
chronic suppurative otitis media (CSOM) and mild hearing impairment in a 
population representative sample of school-entry age children in rural Malawi. A 
secondary objective was to explore factors associated with CSOM in this 
population.
METHODS: We performed a community-based cross-sectional study of children aged 
4-6 years in Chikhwawa District, Southern Malawi, utilising a village-level 
cluster design. Participants underwent a structured clinical assessment, 
including video-otoscopy and screening audiometry. Diagnoses were made remotely 
by two otolaryngologists who independently reviewed clinical data and images 
collected in the field. Hearing impairment was classified as failure to hear a 
pure tone of 25dB or greater at 1, 2 or 4kHz.
RESULTS: We recruited 281 children across 10 clusters. The prevalence estimates 
of CSOM, unilateral hearing impairment and bilateral hearing impairment were 
5.4% (95%CI 2.2-8.6), 24.5% (95%CI 16.3-30.0), and 12.5% (95%CI 6.2-16.9) 
respectively. Middle ear disease was seen in 46.9% of children with hearing 
impairment. A trend towards increased risk of CSOM was observed with sleeping in 
a house with >2 other children.
INTERPRETATION: We found a high burden of middle ear disease and preventable 
hearing impairment in our sample of school-entry age children in rural Malawi. 
There are important public health implications of these findings as CSOM and 
hearing impairment can affect educational outcomes, and may impact subsequent 
development. The identification and management of middle ear disease and hearing 
impairment represent major unmet needs in this population.

DOI: 10.1371/journal.pone.0188950
PMCID: PMC5739401
PMID: 29267304 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


293. Trends Hear. 2019 Jan-Dec;23:2331216519872362. doi: 10.1177/2331216519872362.

Movement and Gaze Behavior in Virtual Audiovisual Listening Environments 
Resembling Everyday Life.

Hendrikse MME(1), Llorach G(1)(2), Hohmann V(1)(2), Grimm G(1).

Author information:
(1)Medizinische Physik and Cluster of Excellence 'Hearing4all', Universität 
Oldenburg, Germany.
(2)Hörzentrum Oldenburg GmbH, Germany.

Recent achievements in hearing aid development, such as visually guided hearing 
aids, make it increasingly important to study movement behavior in everyday 
situations in order to develop test methods and evaluate hearing aid 
performance. In this work, audiovisual virtual environments (VEs) were designed 
for communication conditions in a living room, a lecture hall, a cafeteria, a 
train station, and a street environment. Movement behavior (head movement, gaze 
direction, and torso rotation) and electroencephalography signals were measured 
in these VEs in the laboratory for 22 younger normal-hearing participants and 19 
older normal-hearing participants. These data establish a reference for future 
studies that will investigate the movement behavior of hearing-impaired 
listeners and hearing aid users for comparison. Questionnaires were used to 
evaluate the subjective experience in the VEs. A test-retest comparison showed 
that the measured movement behavior is reproducible and that the measures of 
movement behavior used in this study are reliable. Moreover, evaluation of the 
questionnaires indicated that the VEs are sufficiently realistic. The 
participants rated the experienced acoustic realism of the VEs positively, and 
although the rating of the experienced visual realism was lower, the 
participants felt to some extent present and involved in the VEs. Analysis of 
the movement data showed that movement behavior depends on the VE and the age of 
the subject and is predictable in multitalker conversations and for moving 
distractors. The VEs and a database of the collected data are publicly 
available.

DOI: 10.1177/2331216519872362
PMCID: PMC6732870
PMID: 32516060 [Indexed for MEDLINE]


294. Adv Exp Med Biol. 2016;894:467-475. doi: 10.1007/978-3-319-25474-6_49.

On the Interplay Between Cochlear Gain Loss and Temporal Envelope Coding 
Deficits.

Verhulst S(1), Piktel P(2), Jagadeesh A(2), Mauermann M(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Department of 
Medical Physics and Acoustics, Oldenburg University, Carl-von-Ossietzky Strasse 
9-11, 26129, Oldenburg, Germany. Sarah.verhulst@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Department of 
Medical Physics and Acoustics, Oldenburg University, Carl-von-Ossietzky Strasse 
9-11, 26129, Oldenburg, Germany.

Hearing impairment is characterized by two potentially coexisting sensorineural 
components: (i) cochlear gain loss that yields wider auditory filters, elevated 
hearing thresholds and compression loss, and (ii) cochlear neuropathy, a 
noise-induced component of hearing loss that may impact temporal coding fidelity 
of supra-threshold sound. This study uses a psychoacoustic amplitude modulation 
(AM) detection task in quiet and multiple noise backgrounds to test whether 
these aspects of hearing loss can be isolated in listeners with normal to mildly 
impaired hearing ability. Psychoacoustic results were compared to 
distortion-product otoacoustic emission (DPOAE) thresholds and 
envelope-following response (EFR) measures. AM thresholds to pure-tone carriers 
(4 kHz) in normal-hearing listeners depended on temporal coding fidelity. AM 
thresholds in hearing-impaired listeners were normal, indicating that reduced 
cochlear gain may counteract how reduced temporal coding fidelity degrades AM 
thresholds. The amount with which a 1-octave wide masking noise worsened AM 
detection was inversely correlated to DPOAE thresholds. The narrowband noise 
masker was shown to impact the hearing-impaired listeners more so than the 
normal hearing listeners, suggesting that this masker may be targeting a 
temporal coding deficit. This study offers a window into how psychoacoustic 
difference measures can be adopted in the differential diagnostics of hearing 
deficits in listeners with mixed forms of sensorineural hearing loss.

DOI: 10.1007/978-3-319-25474-6_49
PMID: 27080688 [Indexed for MEDLINE]


295. J Acoust Soc Am. 2018 Jun;143(6):3602. doi: 10.1121/1.5042056.

Deep learning models to remix music for cochlear implant users.

Gajęcki T(1), Nogueira W(1).

Author information:
(1)Department of Otolaryngology, Medical University Hannover and Cluster of 
Excellence Hearing4all, Hannover, 30625, Germany.

The severe hearing loss problems that some people suffer can be treated by 
providing them with a surgically implanted electrical device called cochlear 
implant (CI). CI users struggle to perceive complex audio signals such as music; 
however, previous studies show that CI recipients find music more enjoyable when 
the vocals are enhanced with respect to the background music. In this manuscript 
source separation (SS) algorithms are used to remix pop songs by applying gain 
to the lead singing voice. This work uses deep convolutional auto-encoders, a 
deep recurrent neural network, a multilayer perceptron (MLP), and non-negative 
matrix factorization to be evaluated objectively and subjectively through two 
different perceptual experiments which involve normal hearing subjects and CI 
recipients. The evaluation assesses the relevance of the artifacts introduced by 
the SS algorithms considering their computation time, as this study aims at 
proposing one of the algorithms for real-time implementation. Results show that 
the MLP performs in a robust way throughout the tested data while providing 
levels of distortions and artifacts which are not perceived by CI users. Thus, 
an MLP is proposed to be implemented for real-time monaural audio SS to remix 
music for CI users.

DOI: 10.1121/1.5042056
PMID: 29960485 [Indexed for MEDLINE]


296. J Acoust Soc Am. 2017 Aug;142(2):812. doi: 10.1121/1.4996859.

Towards a joint reflection-distortion otoacoustic emission profile: Results in 
normal and impaired ears.

Abdala C(1), Kalluri R(1).

Author information:
(1)Caruso Department of Otolaryngology, Auditory Research Center, University of 
Southern California, 1640 Marengo Street, Suite 326, Los Angeles, California 
90033, USA.

Otoacoustic emissions (OAEs) provide salient information about cochlear function 
and dysfunction. Two broad classes of emissions, linear reflection and nonlinear 
distortion, arise via distinct cochlear processes and hence, appear to provide 
independent information about cochlear health and hearing. Considered in 
combination, these two OAE types may characterize sensory hearing loss most 
effectively. In this study, the level-dependent growth of stimulus-frequency 
OAEs (a reflection-type emission) and distortion-product OAEs (a distortion-type 
emission) were measured in ten normal-hearing ears and eight ears with 
slight-to-moderate sensorineural hearing loss. Metrics of OAE strength and 
compression were derived from OAE input/output functions and then considered in 
a combined fashion. Results indicate that SFOAEs and DPOAEs differ significantly 
in their strength and compression features. When SFOAE and DPOAE metrics are 
displayed together on a two-dimensional plot, relatively well-defined data 
clusters describe their normative relationship. In hearing-impaired ears, this 
relationship is disrupted but not in a uniform way across ears; ears with 
similar audiograms showed differently altered joint-OAE profiles. Hearing loss 
sometimes affected only one OAE or one more than the other. Results suggest a 
joint-OAE profile is promising and warrants study in a large group of subjects 
with sensory hearing loss of varied etiologies.

DOI: 10.1121/1.4996859
PMCID: PMC5552396
PMID: 28863614 [Indexed for MEDLINE]


297. B-ENT. 2013;Suppl 21:3-8.

Universal neonatal hearing screening in Flanders reveals socio-demographic risk 
factors for hearing impairment.

Van Kerschaver E(1).

Author information:
(1)Kind en Gezin (Child and Family), Brussels, Belgium. 
erwin.vankerschaver@scarlet.be

INTRODUCTION: Permanent congenital hearing impairment (CHI) occurs in 
approximately 1.4 per 1,000 newborns. Early treatment and rehabilitation is 
essential to prevent the delayed development of speech and language. This paper 
describes the special collaborative approach of the Flemish screening programme. 
It also discusses the results and the new insights into socio-demographic risk 
factors for CHI.
METHODS: In the period 1999-2008, the entire population of 628,337 newborns in 
Flanders was tested using an AABR hearing screener. Positive results were 
referred for confirmation of the CHI diagnosis to specialised referral centres. 
Socio-demographic factors were investigated to study any relationship with CHI.
RESULTS: The referral rate after two screenings was 2.7-7.2 per thousand of 
screened babies depending on the screener used. All children were referred to 
specialised centres and there was almost no loss to follow-up. The diagnosis of 
hearing loss was confirmed in 77-82% of the babies referred. The 
socio-demographic factors of gender, birth order and birth length, initial 
feeding type, level of education and origin of the mother were found to be 
independent predictors of CHI. Most of these risk factors can be linked to 
poverty. The observation that 50% of babies with CHI have no risk factors from 
the classic AAP list may be partly explained by the non-inclusion of 
socio-demographic risk factors.
CONCLUSIONS: This integrated programme opens up new perspectives for 
hearing-impaired babies. The social impact of the screening programme is 
considerable. A cluster of socio-demographic risk factors for CHI can be added 
to the classic AAP list.

PMID: 24383217 [Indexed for MEDLINE]


298. Hear Res. 2017 Feb;344:50-61. doi: 10.1016/j.heares.2016.10.023. Epub 2016 Nov 
9.

A physiologically-inspired model reproducing the speech intelligibility benefit 
in cochlear implant listeners with residual acoustic hearing.

Zamaninezhad L(1), Hohmann V(2), Büchner A(3), Schädler MR(4), Jürgens T(5).

Author information:
(1)Medizinische Physik, Cluster of Excellence "Hearing4all", and 
Forschungszentrum Neurosensorik, Carl-von-Ossietzky Universität Oldenburg, 
Germany. Electronic address: ladan.zamaninezhad@uni-oldenburg.de.
(2)Medizinische Physik, Cluster of Excellence "Hearing4all", and 
Forschungszentrum Neurosensorik, Carl-von-Ossietzky Universität Oldenburg, 
Germany. Electronic address: volker.hohmann@uni-oldenburg.de.
(3)Deutsches Hörzentrum der Medizinischen Hochschule Hannover and Cluster of 
Excellence "Hearing4all", D-30625, Germany. Electronic address: 
Buechner@hoerzentrum-hannover.de.
(4)Medizinische Physik, Cluster of Excellence "Hearing4all", and 
Forschungszentrum Neurosensorik, Carl-von-Ossietzky Universität Oldenburg, 
Germany. Electronic address: marc.r.schaedler@uni-oldenburg.de.
(5)Medizinische Physik, Cluster of Excellence "Hearing4all", and 
Forschungszentrum Neurosensorik, Carl-von-Ossietzky Universität Oldenburg, 
Germany. Electronic address: tim.juergens@uni-oldenburg.de.

This study introduces a speech intelligibility model for cochlear implant users 
with ipsilateral preserved acoustic hearing that aims at simulating the observed 
speech-in-noise intelligibility benefit when receiving simultaneous electric and 
acoustic stimulation (EA-benefit). The model simulates the auditory nerve 
spiking in response to electric and/or acoustic stimulation. The temporally and 
spatially integrated spiking patterns were used as the final internal 
representation of noisy speech. Speech reception thresholds (SRTs) in stationary 
noise were predicted for a sentence test using an automatic speech recognition 
framework. The model was employed to systematically investigate the effect of 
three physiologically relevant model factors on simulated SRTs: (1) the spatial 
spread of the electric field which co-varies with the number of electrically 
stimulated auditory nerves, (2) the "internal" noise simulating the deprivation 
of auditory system, and (3) the upper bound frequency limit of acoustic hearing. 
The model results show that the simulated SRTs increase monotonically with 
increasing spatial spread for fixed internal noise, and also increase with 
increasing the internal noise strength for a fixed spatial spread. The predicted 
EA-benefit does not follow such a systematic trend and depends on the specific 
combination of the model parameters. Beyond 300 Hz, the upper bound limit for 
preserved acoustic hearing is less influential on speech intelligibility of 
EA-listeners in stationary noise. The proposed model-predicted EA-benefits are 
within the range of EA-benefits shown by 18 out of 21 actual cochlear implant 
listeners with preserved acoustic hearing.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.10.023
PMID: 27838372 [Indexed for MEDLINE]


299. Sci Rep. 2018 Dec 20;8(1):18004. doi: 10.1038/s41598-018-36404-1.

Cochlear Implantation in Postlingually Deaf Adults is Time-sensitive Towards 
Positive Outcome: Prediction using Advanced Machine Learning Techniques.

Kim H(1), Kang WS(2), Park HJ(3), Lee JY(2), Park JW(2), Kim Y(2), Seo JW(2), 
Kwak MY(2), Kang BC(4), Yang CJ(5), Duffy BA(1), Cho YS(6), Lee SY(7), Suh 
MW(7), Moon IJ(6), Ahn JH(2), Cho YS(6), Oh SH(7), Chung JW(2).

Author information:
(1)Department of Neurology, USC Stevens Neuroimaging and Informatics Institute, 
Keck School of Medicine, University of Southern California, Los Angeles, USA.
(2)Department of Otolaryngology, Asan Medical Center, University of Ulsan 
College of Medicine, Seoul, South Korea.
(3)Department of Otolaryngology, Asan Medical Center, University of Ulsan 
College of Medicine, Seoul, South Korea. dzness@amc.seoul.kr.
(4)Department of Otorhinolaryngology-Head and Neck Surgery, Ulsan University 
Hospital, University of Ulsan College of Medicine, Ulsan, Korea.
(5)Department of Otolaryngology, Hanil General Hospital, Seoul, South Korea.
(6)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Medical 
Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.
(7)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University Hospital, Seoul National University College of Medicine, Seoul, South 
Korea.

Given our aging society and the prevalence of age-related hearing loss that 
often develops during adulthood, hearing loss is a common public health issue 
affecting almost all older adults. Moderate-to-moderately severe hearing loss 
can usually be corrected with hearing aids; however, severe-to-profound hearing 
loss often requires a cochlear implant (CI). However, post-operative CI results 
vary, and the performance of the previous prediction models is limited, 
indicating that a new approach is needed. For postlingually deaf adults 
(n de120) who received CI with full insertion, we predicted CI outcomes using a 
Random-Forest Regression (RFR) model and investigated the effect of preoperative 
factors on CI outcomes. Postoperative word recognition scores (WRS) served as 
the dependent variable to predict. Predictors included duration of deafness 
(DoD), age at CI operation (ageCI), duration of hearing-aid use (DoHA), 
preoperative hearing threshold and sentence recognition score. Prediction 
accuracy was evaluated using mean absolute error (MAE) and Pearson's correlation 
coefficient r between the true WRS and predicted WRS. The fitting using a linear 
model resulted in prediction of WRS with r = 0.7 and MAE = 15.6 ± 9. RFR 
outperformed the linear model (r = 0.96, MAE = 6.1 ± 4.7, p < 0.00001). 
Cross-hospital data validation showed reliable performance using RFR (r = 0.91, 
MAE = 9.6 ± 5.2). The contribution of DoD to prediction was the highest (MAE 
increase when omitted: 14.8), followed by ageCI (8.9) and DoHA (7.5). After CI, 
patients with DoD < 10 years presented better WRSs and smaller variations 
(p < 0.01) than those with longer DoD. Better WRS was also explained by younger 
age at CI and longer-term DoHA. Machine learning demonstrated a robust 
prediction performance for CI outcomes in postlingually deaf adults across 
different institutes, providing a reference value for counseling patients 
considering CI. Health care providers should be aware that the patients with 
severe-to-profound hearing loss who cannot have benefit from hearing aids need 
to proceed with CI as soon as possible and should continue using hearing aids 
until after CI operation.

DOI: 10.1038/s41598-018-36404-1
PMCID: PMC6301958
PMID: 30573747 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


300. Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi. 2021 May 20;39(5):354-358. doi: 
10.3760/cma.j.cn121094-20200413-00185.

[Relationship between binaural high-frequency mean hearing threshold and 
hypertension in female worker exposed to noise].

[Article in Chinese; Abstract available in Chinese from the publisher]

Guo JY(1), Dong GH(2), Rong X(3), Luo HC(4), Liu YM(3).

Author information:
(1)School of Public Health, Sun Yat-sen University, Guangzhou 510080, China 
Guangzhou Occupational Disease Prevention and Treatment Hospital, Guangzhou 
510620, China.
(2)School of Public Health, Sun Yat-sen University, Guangzhou 510080, China.
(3)Guangzhou Occupational Disease Prevention and Treatment Hospital, Guangzhou 
510620, China.
(4)Guangzhou Emergency Management Bureau, Guangzhou 510060, China.

Objective: To explore the relationship between the binaural high-frequency mean 
hearing threshold and the hypertension of female workers exposed to noise, and 
to understand the application significance of the binaural high-frequency mean 
hearing threshold as an internal effect indicator of the risk of hypertension in 
female workers exposed to noise. Methods: From January to December 2018, a total 
of 20882 female workers exposed to noise in Guangzhou were selected by cluster 
sampling. Pure tone audiometry, blood pressure, age and length of service were 
collected. Trend test was used to evaluate the effects of exposure to noise and 
binaural high-frequency mean hearing threshold on blood pressure. Binary 
logistic regression model was used to evaluate the risk of hypertension 
associated with exposure to noise and binaural high-frequency mean hearing 
threshold. Results: The detection rate of normal hearing threshold, mild hearing 
loss and severe hearing loss was 80.73% (16858/20882) , 16.21% (3384/20882) and 
3.06% (640/20882) respectively. The prevalence of hypertension was 6.04% 
(1018/16858) in normal hearing group, 10.28% (348/3384) in patients with high 
frequency mild hearing loss, and 11.25% (72/640) in patients with high frequency 
severe hearing loss. There was a linear relationship between the increase of 
working age and high-frequency mean hearing threshold and the increase of 
systolic and diastolic blood pressure (P< 0.05) . Compared with those exposed to 
noise for less than 1 year, the risk of hypertension in female workers with 7-9 
years and more than 9 years was decreased (OR= 0.79, 0.75, P<0.05) . Compared 
with normal hearing group, the risk of hypertension in high frequency mild 
hearing loss group was increased (OR=1.31, P<0.05) . Conclusion: The increase in 
the binaural high-frequency mean hearing threshold of female workers exposed to 
noise can increase the blood pressure level and the risk of hypertension, and 
attention should be paid to female workers with high-frequency mild hearing 
loss.

Publisher: 目的： 探讨双耳高频平均听阈与噪声作业女工高血压的关系，了解双耳高频平均听阈作为噪声作业女工发生高血压风险内效应指标的应用意义。 方法： 
于2018年1至12月，采取整群抽样的方法，将广州市的20 
882名在岗噪声作业女工纳入研究，收集其纯音测听值、血压、年龄及工龄等信息。运用趋势χ(2)检验评估接触噪声工龄和双耳高频平均听阈对血压的影响，运用二元logistic回归模型评估接触噪声工龄和双耳高频平均听阈相关的高血压风险。 
结果： 噪声作业女工双耳高频平均听阈正常听力检出率为80.73%（16 858/20 882）,高频轻度听力损失检出率为16.21%（3 384/20 
882），高频重度听力损失检出率为3.06%（640/20 882）。正常听力组中高血压患病率为6.04%（1 018/16 
858）,高频轻度听力损失患者中高血压患病率为10.28%（348/3 
384）,高频重度听力损失患者中高血压患病率为11.25%（72/640）。随着接触噪声工龄和双耳高频平均听阈增加，收缩压和舒张压呈升高趋势（P<0.05）。与接触噪声工龄<1年组比较，7~9年和≥9年组女工发生高血压风险均下降（OR=0.79、0.75，P<0.05）；与正常听力组比较，高频轻度听力损失组发生高血压风险增加（OR=1.31，P<0.05）。 
结论： 噪声作业女工双耳高频平均听阈增加可能导致血压水平和高血压风险增加，应重点关注高频轻度听力损失女工。.

DOI: 10.3760/cma.j.cn121094-20200413-00185
PMID: 34074080 [Indexed for MEDLINE]


301. Trends Hear. 2019 Jan-Dec;23:2331216519847413. doi: 10.1177/2331216519847413.

Perceptual Effects of Adjusting Hearing-Aid Gain by Means of a Machine-Learning 
Approach Based on Individual User Preference.

Søgaard Jensen N(1), Hau O(1), Bagger Nielsen JB(1), Bundgaard Nielsen T(2), 
Vase Legarth S(2).

Author information:
(1)1 Widex A/S, Lynge, Denmark.
(2)2 SenseLab, FORCE Technology, Hørsholm, Denmark.

This study investigated a method to adjust hearing-aid gain by use of a 
machine-learning algorithm that estimates the optimal setting of gain parameters 
based on user preference indicated in an iterative paired-comparison procedure. 
Twenty hearing-impaired participants completed this procedure for 12 different 
sound scenarios. During the adjustment procedure, their task was to indicate a 
preference based on one of three sound attributes: Basic Audio Quality, 
Listening Comfort, or Speech Clarity. In a double-blind comparison of recordings 
of the processed scenarios, and using the same attributes as criteria, the 
adjusted gain settings were subsequently compared with two prescribed settings 
of the same hearing aid (with and without activation of an automatic 
sound-classification system). The results showed that the adjustment method 
provided a general improvement of Basic Audio Quality, an improvement of 
Listening Comfort in a traffic-noise scenario but not in three scenarios with 
speech babble, and no significant improvement of Speech Clarity. A large 
variation in gain adjustments was observed across participants, both among those 
who did benefit and among those who did not benefit from the adjustment. There 
was no clear connection between the gain adjustments and the perceived benefit, 
which indicates that the preferred gain settings for a given sound scenario and 
a given listening intention are highly individual and difficult to predict.

DOI: 10.1177/2331216519847413
PMCID: PMC6535733
PMID: 31104581 [Indexed for MEDLINE]


302. Neural Plast. 2021 May 29;2021:9979157. doi: 10.1155/2021/9979157. eCollection 
2021.

Deletion of Clusterin Protects Cochlear Hair Cells against Hair Cell Aging and 
Ototoxicity.

Zhao X(1), Henderson HJ(2), Wang T(1), Liu B(1)(3), Li Y(1).

Author information:
(1)Department of Otorhinolaryngology Head and Neck Surgery, Beijing Tongren 
Hospital, Capital Medical University, Beijing, China.
(2)Department of Biomedical Sciences, Creighton University School of Medicine, 
Omaha, Nebraska 68178, USA.
(3)Beijing Institute of Otolaryngology, Key Laboratory of Otolaryngology Head 
and Neck Surgery (Capital Medical University), Ministry of Education, Beijing, 
China.

Hearing loss is a debilitating disease that affects 10% of adults worldwide. 
Most sensorineural hearing loss is caused by the loss of mechanosensitive hair 
cells in the cochlea, often due to aging, noise, and ototoxic drugs. The 
identification of genes that can be targeted to slow aging and reduce the 
vulnerability of hair cells to insults is critical for the prevention of 
sensorineural hearing loss. Our previous cell-specific transcriptome analysis of 
adult cochlear hair cells and supporting cells showed that Clu, encoding a 
secreted chaperone that is involved in several basic biological events, such as 
cell death, tumor progression, and neurodegenerative disorders, is expressed in 
hair cells and supporting cells. We generated Clu-null mice (C57BL/6) to 
investigate its role in the organ of Corti, the sensory epithelium responsible 
for hearing in the mammalian cochlea. We showed that the deletion of Clu did not 
affect the development of hair cells and supporting cells; hair cells and 
supporting cells appeared normal at 1 month of age. Auditory function tests 
showed that Clu-null mice had hearing thresholds comparable to those of 
wild-type littermates before 3 months of age. Interestingly, Clu-null mice 
displayed less hair cell and hearing loss compared to their wildtype littermates 
after 3 months. Furthermore, the deletion of Clu is protected against 
aminoglycoside-induced hair cell loss in both in vivo and in vitro models. Our 
findings suggested that the inhibition of Clu expression could represent a 
potential therapeutic strategy for the alleviation of age-related and ototoxic 
drug-induced hearing loss.

Copyright © 2021 Xiaochang Zhao et al.

DOI: 10.1155/2021/9979157
PMCID: PMC8181089
PMID: 34194490 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


303. J Int Adv Otol. 2019 Apr;15(1):87-93. doi: 10.5152/iao.2019.4553.

A Novel Approach for Classifying Native Chinese and Malay Speaking Persons 
According to Cortical Auditory Evoked Responses.

Ibrahim IA(1), Ting HN(1), Moghavvemi M(2).

Author information:
(1)Department of Electrical Engineering, University of Malaya School of 
Engineering, Kuala Lumpur, Malaysia;Department of Biomedical Engineering, 
University of Malaya School of Engineering, Kuala Lumpur, Malaysia.
(2)Center of Research in Applied Electronics (CRAE), University of Malaya School 
of Engineering, Kuala Lumpur, Malaysia;University of Science and Culture, 
Tehran, Iran.

OBJECTIVES: This study uses a new approach for classifying the human ethnicity 
according to the auditory brain responses (electroencephalography [EEG] signals) 
with a high level of accuracy. Moreover, the study presents three different 
algorithms used to classify the human ethnicity using auditory brain responses. 
The algorithms were tested on Malays and Chinese as a case study.
MATERIALS AND METHODS: The EEG signal was used as a brain response signal, which 
was evoked by two auditory stimuli (Tones and Consonant Vowels stimulus). The 
study was carried out on Malaysians (Malay and Chinese) with normal hearing and 
with hearing loss. A ranking process for the subjects' EEG data and the 
nonlinear features was used to obtain the maximum classification accuracy.
RESULTS: The study formulated the classification of Normal Hearing Ethnicity 
Index and Sensorineural Hearing Loss Ethnicity Index. These indices classified 
the human ethnicity according to brain auditory responses by using numerical 
values of response signal features. Three classification algorithms were used to 
verify the human ethnicity. Support Vector Machine (SVM) classified the human 
ethnicity with an accuracy of 90% in the cases of normal hearing and 
sensorineural hearing loss (SNHL); the SVM classified with an accuracy of 84%.
CONCLUSION: The classification indices categorized or separated the human 
ethnicity in both hearing cases of normal hearing and SNHL with high accuracy. 
The SVM classifier provided a good accuracy in the classification of the 
auditory brain responses. The proposed indices might constitute valuable tools 
for the classification of the brain responses according to the human ethnicity.

DOI: 10.5152/iao.2019.4553
PMCID: PMC6483426
PMID: 30924771 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of Interest: The authors have no 
conflicts of interest to declare.


304. Clin Interv Aging. 2016 May 12;11:603-13. doi: 10.2147/CIA.S100255. eCollection 
2016.

Neurocognitive testing and cochlear implantation: insights into performance in 
older adults.

Cosetti MK(1), Pinkston JB(2), Flores JM(3), Friedmann DR(4), Jones CB(2), 
Roland JT Jr(5), Waltzman SB(4).

Author information:
(1)Department of Otolaryngology - Head and Neck Surgery, Louisiana State 
University Health Sciences Center, Shreveport, LA, USA; Department of 
Neurosurgery, Louisiana State University Health Sciences Center, Shreveport, LA, 
USA.
(2)Department of Neurology, Louisiana State University Health Sciences Center, 
Shreveport, LA, USA.
(3)Department of Epidemiology, Johns Hopkins Bloomberg School of Public Health, 
Baltimore, MA, USA.
(4)Department of Otolaryngology, New York University School of Medicine, New 
York, NY, USA.
(5)Department of Otolaryngology, New York University School of Medicine, New 
York, NY, USA; Department of Neurosurgery, New York University School of 
Medicine, New York, NY, USA.

OBJECTIVE: The aim of this case series was to assess the impact of auditory 
rehabilitation with cochlear implantation on the cognitive function of elderly 
patients over time.
DESIGN: This is a longitudinal case series of prospective data assessing 
neurocognitive function and speech perception in an elderly cohort pre- and 
post-implantation.
SETTING: University cochlear implant center.
PARTICIPANTS: The patients were post-lingually deafened elderly female (mean, 
73.6 years; SD, 5.82; range, 67-81 years) cochlear implant recipients (n=7).
MEASUREMENTS: A neurocognitive battery of 20 tests assessing intellectual 
function, learning, short- and long-term memory, verbal fluency, attention, 
mental flexibility, and processing speed was performed prior to and 2-4.1 years 
(mean, 3.7) after cochlear implant (CI). Speech perception testing using 
Consonant-Nucleus-Consonant words was performed prior to implantation and at 
regular intervals postoperatively. Individual and aggregate differences in 
cognitive function pre- and post-CI were estimated. Logistic regression with 
cluster adjustment was used to estimate the association (%improvement or 
%decline) between speech understanding and years from implantation at 1 year, 2 
years, and 3 years post-CI.
RESULTS: Improvements after CI were observed in 14 (70%) of all subtests 
administered. Declines occurred in five (25%) subtests. In 55 individual tests 
(43%), post-CI performance improved compared to a patient's own performance 
before implantation. Of these, nine (45%) showed moderate or pronounced 
improvement. Overall, improvements were largest in the verbal and memory 
domains. Logistic regression demonstrated a significant relationship between 
speech perception and cognitive function over time. Five neurocognitive tests 
were predictive of improved speech perception following implantation.
CONCLUSION: Comprehensive neurocognitive testing of elderly women demonstrated 
areas of improvement in cognitive function and auditory perception following 
cochlear implantation. Multiple neurocognitive tests were strongly associated 
with current speech perception measures. While these data shed light on the 
complex relationship between hearing and cognition by showing that CI may slow 
the expected age-related cognitive decline, further research is needed to 
examine the impact of hearing rehabilitation on cognitive decline.

DOI: 10.2147/CIA.S100255
PMCID: PMC4869653
PMID: 27274210 [Indexed for MEDLINE]


305. J Neurosci. 2015 Feb 4;35(5):2161-72. doi: 10.1523/JNEUROSCI.3915-14.2015.

Individual differences reveal correlates of hidden hearing deficits.

Bharadwaj HM(1), Masud S(2), Mehraei G(3), Verhulst S(4), Shinn-Cunningham 
BG(2).

Author information:
(1)Center for Computational Neuroscience and Neural Technology and Department of 
Biomedical Engineering, Boston University, Boston, Massachusetts 02215, 
hari@nmr.mgh.harvard.edu.
(2)Center for Computational Neuroscience and Neural Technology and Department of 
Biomedical Engineering, Boston University, Boston, Massachusetts 02215.
(3)Center for Computational Neuroscience and Neural Technology and Program in 
Speech and Hearing Biosciences and Technology, Harvard University-Massachusetts 
Institute of Technology, Cambridge, Massachusetts 02139, and.
(4)Center for Computational Neuroscience and Neural Technology and Cluster of 
Excellence Hearing4all and Medizinische Physik, Department of Medical Physics 
and Acoustics, Oldenburg University, D-26111 Oldenburg, Germany.

Clinical audiometry has long focused on determining the detection thresholds for 
pure tones, which depend on intact cochlear mechanics and hair cell function. 
Yet many listeners with normal hearing thresholds complain of communication 
difficulties, and the causes for such problems are not well understood. Here, we 
explore whether normal-hearing listeners exhibit such suprathreshold deficits, 
affecting the fidelity with which subcortical areas encode the temporal 
structure of clearly audible sound. Using an array of measures, we evaluated a 
cohort of young adults with thresholds in the normal range to assess both 
cochlear mechanical function and temporal coding of suprathreshold sounds. 
Listeners differed widely in both electrophysiological and behavioral measures 
of temporal coding fidelity. These measures correlated significantly with each 
other. Conversely, these differences were unrelated to the modest variation in 
otoacoustic emissions, cochlear tuning, or the residual differences in hearing 
threshold present in our cohort. Electroencephalography revealed that listeners 
with poor subcortical encoding had poor cortical sensitivity to changes in 
interaural time differences, which are critical for localizing sound sources and 
analyzing complex scenes. These listeners also performed poorly when asked to 
direct selective attention to one of two competing speech streams, a task that 
mimics the challenges of many everyday listening environments. Together with 
previous animal and computational models, our results suggest that hidden 
hearing deficits, likely originating at the level of the cochlear nerve, are 
part of "normal hearing."

Copyright © 2015 the authors 0270-6474/15/352161-12$15.00/0.

DOI: 10.1523/JNEUROSCI.3915-14.2015
PMCID: PMC4402332
PMID: 25653371 [Indexed for MEDLINE]


306. Environ Sci Pollut Res Int. 2019 Mar;26(7):6481-6491. doi: 
10.1007/s11356-018-04106-w. Epub 2019 Jan 8.

Performance of machine-learning algorithms to pattern recognition and 
classification of hearing impairment in Brazilian farmers exposed to pesticide 
and/or cigarette smoke.

Tomiazzi JS(1), Pereira DR(1), Judai MA(2), Antunes PA(1), Favareto APA(3).

Author information:
(1)Graduate Program in Environment and Regional Development, University of 
Western São Paulo - UNOESTE, Presidente Prudente, SP, Brazil.
(2)Faculty of Health Sciences, University of Western São Paulo - UNOESTE, 
Presidente Prudente, SP, Brazil.
(3)Graduate Program in Environment and Regional Development, University of 
Western São Paulo - UNOESTE, Presidente Prudente, SP, Brazil. 
anafavareto@unoeste.br.

The use of pesticides has been increasing in agriculture, leading to a public 
health problem. The aim of this study was to evaluate ototoxic effects in 
farmers who were exposed to cigarette smoke and/or pesticides and to identify 
possible classification patterns in the exposure groups. The sample included 127 
participants of both sexes aged between 18 and 39, who were divided into the 
following four groups: control group (CG), smoking group (SG), pesticide group 
(PG), and smoking + pesticide group (SPG). Meatoscopy, pure tone audiometry, 
logoaudiometry, high-frequency thresholds, and immittance testing were 
performed. Data were evaluated by artificial neural network (ANN), K-nearest 
neighbors (K-NN), and support vector machine (SVM). There was symmetry between 
the right and left ears, an increase in the incidence of hearing loss at high 
frequency and of downward sloping audiometric curve configuration, and 
alteration of stapedial reflex in the three exposed groups. The machine-learning 
classifiers achieved good classification performance (control and exposed). The 
best classification results occur in high type (I and II) datasets (about 90% 
accuracy) in k-NN test. It is concluded that both xenobiotic substances have 
ototoxic potential; however, their combined use does not present additive or 
potentiating effects recognizable by the algorithms.

DOI: 10.1007/s11356-018-04106-w
PMID: 30623325 [Indexed for MEDLINE]


307. J Acoust Soc Am. 2019 Mar;145(3):1493. doi: 10.1121/1.5094765.

Comparison of effects on subjective intelligibility and quality of speech in 
babble for two algorithms: A deep recurrent neural network and spectral 
subtraction.

Keshavarzi M(1), Goehring T(2), Turner RE(3), Moore BCJ(1).

Author information:
(1)Department of Psychology, University of Cambridge, Cambridge, United Kingdom.
(2)MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, 
United Kingdom.
(3)Department of Engineering, University of Cambridge, Cambridge, United 
Kingdom.

The effects on speech intelligibility and sound quality of two noise-reduction 
algorithms were compared: a deep recurrent neural network (RNN) and spectral 
subtraction (SS). The RNN was trained using sentences spoken by a large number 
of talkers with a variety of accents, presented in babble. Different talkers 
were used for testing. Participants with mild-to-moderate hearing loss were 
tested. Stimuli were given frequency-dependent linear amplification to 
compensate for the individual hearing losses. A paired-comparison procedure was 
used to compare all possible combinations of three conditions. The conditions 
were: speech in babble with no processing (NP) or processed using the RNN or SS. 
In each trial, the same sentence was played twice using two different 
conditions. The participants indicated which one was better and by how much in 
terms of speech intelligibility and (in separate blocks) sound quality. 
Processing using the RNN was significantly preferred over NP and over SS 
processing for both subjective intelligibility and sound quality, although the 
magnitude of the preferences was small. SS processing was not significantly 
preferred over NP for either subjective intelligibility or sound quality. 
Objective computational measures of speech intelligibility predicted better 
intelligibility for RNN than for SS or NP.

DOI: 10.1121/1.5094765
PMID: 31067946 [Indexed for MEDLINE]


308. Sci Rep. 2018 Feb 23;8(1):3569. doi: 10.1038/s41598-018-21811-1.

A mouse model of miR-96, miR-182 and miR-183 misexpression implicates miRNAs in 
cochlear cell fate and homeostasis.

Weston MD(1), Tarang S(2), Pierce ML(3), Pyakurel U(2), Rocha-Sanchez SM(2), 
McGee J(4), Walsh EJ(4), Soukup GA(5).

Author information:
(1)Department of Oral Biology, School of Dentistry, Creighton University, 780729 
California Plaza, Omaha, NE 68178-0729, USA. michaelweston@creighton.edu.
(2)Department of Oral Biology, School of Dentistry, Creighton University, 780729 
California Plaza, Omaha, NE 68178-0729, USA.
(3)Department of Pharmacology, School of Medicine, Creighton University, 2500 
California Plaza, Omaha, NE 68178, USA.
(4)Developmental Auditory Physiology Laboratory, Boys Town National Research 
Hospital, 555 North 30th Street, Omaha, NE 68131, USA.
(5)Department of Biomedical Sciences, School of Medicine, Creighton University, 
2500 California Plaza, Omaha, NE 68178, USA.

Germline mutations in Mir96, one of three co-expressed polycistronic miRNA genes 
(Mir96, Mir182, Mir183), cause hereditary hearing loss in humans and mice. 
Transgenic FVB/NCrl- Tg(GFAP-Mir183,Mir96,Mir182)MDW1 mice (Tg1MDW), which 
overexpress this neurosensory-specific miRNA cluster in the inner ear, were 
developed as a model system to identify, in the aggregate, target genes and 
biologic processes regulated by the miR-183 cluster. Histological assessments 
demonstrate Tg1MDW/1MDW homozygotes have a modest increase in cochlear inner 
hair cells (IHCs). Affymetrix mRNA microarray data analysis revealed that 
downregulated genes in P5 Tg1MDW/1MDW cochlea are statistically enriched for 
evolutionarily conserved predicted miR-96, miR-182 or miR-183 target sites. ABR 
and DPOAE tests from 18 days to 3 months of age revealed that Tg1MDW/1MDW 
homozygotes develop progressive neurosensory hearing loss that correlates with 
histologic assessments showing massive losses of both IHCs and outer hair cells 
(OHCs). This mammalian miRNA misexpression model demonstrates a potency and 
specificity of cochlear homeostasis for one of the dozens of endogenously 
co-expressed, evolutionally conserved, small non-protein coding miRNA families. 
It should be a valuable tool to predict and elucidate miRNA-regulated genes and 
integrated functional gene expression networks that significantly influence 
neurosensory cell differentiation, maturation and homeostasis.

DOI: 10.1038/s41598-018-21811-1
PMCID: PMC5824881
PMID: 29476110 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


309. Hear Res. 2019 Jun;377:260-270. doi: 10.1016/j.heares.2019.04.005. Epub 2019 Apr 
11.

Effects of directional sound processing and listener's motivation on EEG 
responses to continuous noisy speech: Do normal-hearing and aided 
hearing-impaired listeners differ?

Mirkovic B(1), Debener S(2), Schmidt J(3), Jaeger M(4), Neher T(5).

Author information:
(1)Department of Psychology, University of Oldenburg, Ammerländer Heerstraße 
114, 26129, Oldenburg, Germany; Cluster of Excellence "Hearing4all", Oldenburg, 
Germany. Electronic address: bojana.mirkovic@uni-oldenburg.de.
(2)Department of Psychology, University of Oldenburg, Ammerländer Heerstraße 
114, 26129, Oldenburg, Germany; Cluster of Excellence "Hearing4all", Oldenburg, 
Germany. Electronic address: stefan.debener@uni-oldenburg.de.
(3)Department of Psychology, University of Oldenburg, Ammerländer Heerstraße 
114, 26129, Oldenburg, Germany. Electronic address: 
julia.schmidt@uni-oldenburg.de.
(4)Department of Psychology, University of Oldenburg, Ammerländer Heerstraße 
114, 26129, Oldenburg, Germany. Electronic address: 
manuela.jaeger@uni-oldenburg.de.
(5)Institute of Clinical Research, University of Southern Denmark, Campusvej 55, 
5230, Odense M, Denmark. Electronic address: tneher@health.sdu.dk.

OBJECTIVE: It has been suggested that the next major advancement in hearing aid 
(HA) technology needs to include cognitive feedback from the user to control HA 
functionality. In order to enable automatic brainwave-steered HA adjustments, 
attentional processes underlying speech-in-noise perception in aided 
hearing-impaired individuals need to be better understood. Here, we addressed 
the influence of two important factors for the listening performance of HA users 
- hearing aid processing and motivation - by analysing ongoing neural responses 
during long-term listening to continuous noisy speech.
METHODS: Sixteen normal-hearing (NH) and 15 linearly aided hearing-impaired 
(aHI) participants listened to an audiobook recording embedded in realistic 
speech babble noise at individually adjusted signal-to-noise ratios (SNRs). A HA 
simulator was used for simulating a directional microphone setting as well as 
for providing individual amplification. To assess listening performance 
behaviourally, participants answered questions about the contents of the 
audiobook. We manipulated (1) the participants' motivation by offering a 
monetary reward for good listening performance in one half of the measurements 
and (2) the SNR by engaging/disengaging the directional microphone setting. 
During the speech-in-noise task, electroencephalography (EEG) signals were 
recorded using wireless, mobile hardware. EEG correlates of listening 
performance were investigated using EEG impulse responses, as estimated using 
the cross-correlation between the recorded EEG signal and the temporal envelope 
of the audiobook at the output of the HA simulator.
RESULTS: At the behavioural level, we observed better performance for the NH 
listeners than for the aHI listeners. Furthermore, the directional microphone 
setting led to better performance for both participant groups, and when the 
directional microphone setting was disengaged motivation also improved the 
performance of the aHI participants. Analysis of the EEG impulse responses 
showed faster N1P2 responses for both groups and larger N2 peak amplitudes for 
the aHI group when the directional microphone setting was activated, but no 
physiological correlates of motivation.
SIGNIFICANCE: The results of this study indicate that motivation plays an 
important role for speech understanding in noise. In terms of neuro-steered HAs, 
our results suggest that the latency of attentional processes is influenced by 
HA-induced stimulus changes, which can potentially be used for inferring benefit 
from noise suppression processing automatically. Further research is necessary 
to identify the neural correlates of motivation as an exclusive top-down process 
and to combine such features with HA-driven ones for online HA adjustments.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.04.005
PMID: 31003037 [Indexed for MEDLINE]


310. Otol Neurotol. 2021 Jun 1;42(5):671-677. doi: 10.1097/MAO.0000000000003028.

Predictive Sensitivity and Concordance of Machine-learning Tools for Diagnosing 
DFNA9 in a Large Series of p.Pro51Ser Variant Carriers in the COCH-gene.

Salah M(1)(2), de Varebeke SJ(1)(3), Fransen E(4)(5), Topsakal V(2)(3), Van Camp 
G(5), Van Rompaey V(2)(3).

Author information:
(1)Department Otorhinolaryngology and Head and Neck Surgery, Jessa Hospital, 
Hasselt.
(2)Department of Otorhinolaryngology, University Hospital Antwerp.
(3)Department of Translational Neurosciences, Faculty of Medicine and Health 
Sciences.
(4)StatUa Center for Statistics.
(5)Center for medical genetics, University of Antwerp, Edegem, Belgium.

OBJECTIVE: In this study we aimed to evaluate the predictive cross-sectional 
sensitivity and longitudinal concordance of a machine-learning algorithm in a 
series of genetically confirmed p.(Pro51Ser) variant carriers (DFNA9).
STUDY DESIGN: Cross-sectional study.
SETTING: Tertiary and secondary referral center.
PATIENTS: Audiograms of 111 subjects with the p.(Pro51Ser) mutation in the 
COCH-gene were analyzed cross-sectionally. A subset of 17 subjects with repeated 
audiograms were used for longitudinal analysis.
INTERVENTIONS: All audiological thresholds were run through the web-based 
AudioGene v4.0 software.
MAIN OUTCOME MEASURES: Sensitivity for accurate prediction of DFNA9 for 
cross-sectional data and concordance of correct prediction for longitudinal 
auditory data.
RESULTS: DFNA9 was predicted with a sensitivity of 93.7% in a series of 222 
cross-sectionally collected audiological thresholds (76.1% as first gene locus). 
When using the hearing thresholds of the best ear, the sensitivity was 94.6%. 
The sensitivity was significantly higher in DFNA9 patients aged younger than 40 
and aged 60 years or older, compared to the age group of 40 to 59 years, with 
resp. 97.6% (p < 0.0001) and 98.8% (p < 0.0001) accurate predictions. An average 
concordance of 91.6% was found to show the same response in all successive 
longitudinal audiometric data per patient.
CONCLUSIONS: Audioprofiling software can accurately predict DFNA9 in an area 
with a high prevalence of confirmed carriers of the p.(Pro51Ser) variant in the 
COCH-gene. This algorithm yields high promises for helping clinicians in 
directing genetic testing in case of a strong family history of progressive 
hearing loss, especially for very young and old carriers.

Copyright © 2021, Otology & Neurotology, Inc.

DOI: 10.1097/MAO.0000000000003028
PMID: 33492061 [Indexed for MEDLINE]

Conflict of interest statement: The authors disclose no conflicts of interest.


311. J Acoust Soc Am. 2017 Jun;141(6):4230. doi: 10.1121/1.4984271.

An algorithm to increase intelligibility for hearing-impaired listeners in the 
presence of a competing talker.

Healy EW(1), Delfarah M(2), Vasko JL(1), Carter BL(1), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, The Ohio State University, 
Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.

Individuals with hearing impairment have particular difficulty perceptually 
segregating concurrent voices and understanding a talker in the presence of a 
competing voice. In contrast, individuals with normal hearing perform this task 
quite well. This listening situation represents a very different problem for 
both the human and machine listener, when compared to perceiving speech in other 
types of background noise. A machine learning algorithm is introduced here to 
address this listening situation. A deep neural network was trained to estimate 
the ideal ratio mask for a male target talker in the presence of a female 
competing talker. The monaural algorithm was found to produce 
sentence-intelligibility increases for hearing-impaired (HI) and normal-hearing 
(NH) listeners at various signal-to-noise ratios (SNRs). This benefit was 
largest for the HI listeners and averaged 59%-points at the least-favorable SNR, 
with a maximum of 87%-points. The mean intelligibility achieved by the HI 
listeners using the algorithm was equivalent to that of young NH listeners 
without processing, under conditions of identical interference. Possible reasons 
for the limited ability of HI listeners to perceptually segregate concurrent 
voices are reviewed as are possible implementation considerations for algorithms 
like the current one.

DOI: 10.1121/1.4984271
PMCID: PMC5464956
PMID: 28618817 [Indexed for MEDLINE]


312. Hear Res. 2017 Feb;344:223-234. doi: 10.1016/j.heares.2016.11.017. Epub 2016 Dec 
7.

Loudness and pitch perception using Dynamically Compensated Virtual Channels.

Nogueira W(1), Litvak LM(2), Landsberger DM(3), Büchner A(4).

Author information:
(1)Medical University Hannover, Cluster of Excellence "Hearing4all", Hannover, 
Germany. Electronic address: nogueiravazquez.waldo@mh-hannover.de.
(2)Advanced Bionics LLC, Valencia, CA, USA.
(3)New York University School of Medicine, New York, NY, USA.
(4)Medical University Hannover, Cluster of Excellence "Hearing4all", Hannover, 
Germany.

Reducing power consumption is important for the development of smaller cochlear 
implant (CI) speech processors. Simultaneous electrode stimulation may improve 
power efficiency by minimizing the required current applied to a given 
electrode. Simultaneous in-phase stimulation on adjacent electrodes (i.e. 
virtual channels) can be used to elicit pitch percepts intermediate to the ones 
provided by each of the physical electrodes in isolation. Virtual channels are 
typically implemented in monopolar stimulation mode, producing broad excitation 
patterns. Focused stimulation may reduce the excitation patterns, but is 
inefficient in terms of power consumption. To create a more power efficient 
virtual channel, we developed the Dynamically Compensated Virtual Channel 
(DC-VC) using four adjacent electrodes. The two central electrodes are current 
steered using the coefficient α (0<α<1 ) whereas the two flanking electrodes are 
used to focus/unfocus the stimulation with the coefficient σ (-1<σ<1). With 
increasing values of σ, power can be saved at the potential expense of 
generating broader electric fields. Additionally, reshaping the electric fields 
might also alter place pitch coding. The goal of the present study is to 
investigate the tradeoff between place pitch encoding and power savings using 
simultaneous electrode stimulation in the DC-VC configuration. A computational 
model and psychophysical experiments in CI users have been used for that 
purpose. Results from 10 adult Advanced Bionics CI users have been collected. 
Results show that the required current to produce comfortable levels is 
significantly reduced with increasing σ as predicted by the computational model. 
Moreover, no significant differences in the estimated number of discriminable 
steps were detected for the different values of σ. From these results, we 
conclude that DC-VCs can reduce power consumption without decreasing the number 
of discriminable place pitch steps.

Copyright © 2016. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2016.11.017
PMCID: PMC5421637
PMID: 27939418 [Indexed for MEDLINE]


313. Cochlear Implants Int. 2018 May;19(3):142-146. doi: 
10.1080/14670100.2018.1425274. Epub 2018 Jan 19.

Pilot study on the use of data mining to identify cochlear implant candidates.

Grisel JJ(1), Schafer E(2), Lam A(3), Griffin T(4).

Author information:
(1)a Head & Neck Surgical Associates , 1 Burnside Dr., Wichita Falls , TX 76310 
, USA.
(2)b University of North Texas , 1155 Union Circle #305010 Denton , TX 76203 , 
USA.
(3)c Auditory Implant Initiative , 1 Burnside Dr., Wichita Falls , TX 76310 , 
USA.
(4)d Midwestern State University , 3410 Taft Blvd., Wichita Falls , TX 76308 , 
USA.

OBJECTIVES: The goal of this pilot study was to determine the clinical utility 
of data-mining software that screens for cochlear implant (CI) candidacy.
METHODS: The Auditory Implant Initiative developed a software module that 
screens for CI candidates via integration with a software system (Noah 4) that 
serves as a depository for hearing test data. To identify candidates, patient 
audiograms from one practice were exported into the screening module. Candidates 
were tracked to determine if any eventually underwent implantation.
RESULTS: After loading 4836 audiograms from the Noah 4 system, the screening 
module identified 558 potential CI candidates. After reviewing the data for the 
potential candidates, 117 were targeted and invited to an educational event. 
Following the event, a total of six candidates were evaluated, and two were 
implanted.
DISCUSSION: This objective approach to identifying candidates has the potential 
to address the gross underutilization of CIs by removing any bias or lack of 
knowledge regarding the management of severe to profound sensorineural hearing 
loss with CIs.
CONCLUSION: The screening module was an effective tool for identifying potential 
CI candidates at one ENT practice. On a larger scale, the screening module has 
the potential to impact thousands of CI candidates worldwide.

DOI: 10.1080/14670100.2018.1425274
PMID: 29347892 [Indexed for MEDLINE]


314. Rev Panam Salud Publica. 2007 Jun;21(6):381-7. doi: 
10.1590/s1020-49892007000500006.

Hearing impairment and socioeconomic factors: a population-based survey of an 
urban locality in southern Brazil.

Béria JU(1), Raymann BC, Gigante LP, Figueiredo AC, Jotz G, Roithman R, Selaimen 
da Costa S, Garcez V, Scherer C, Smith A.

Author information:
(1)Graduate School of Public Health, Medical School, Lutheran University of 
Brazil, Canoas, Rio Grande do Sul, Brazil.

OBJECTIVE: To provide the first population-based data on deafness and hearing 
impairment in Brazil.
METHODS: In 2003, a cross-sectional household survey was conducted of 2,427 
persons 4 years old and over. The study population was composed of 1,040 
systematically chosen households in 40 randomly selected census tracts (dwelling 
clusters) in the city of Canoas, which is in the state of Rio Grande do Sul, in 
southern Brazil. Hearing function was evaluated in all subjects by both 
pure-tone audiometry and physical examination, using the World Health 
Organization Ear and Hearing Disorders Survey Protocol and definitions of 
hearing levels. The socioeconomic data that were gathered included the amount of 
schooling of all individuals tested and the income of the head of the household.
RESULTS: It was found that 26.1% of the population studied showed some level of 
hearing impairment, and 6.8% (95% confidence interval (CI) = 5.5%-8.1%) were 
classified in the disabling hearing impairment group. The prevalence of moderate 
hearing loss was 5.4% (95% CI = 4.4%-6.4%); for severe hearing loss, 1.2% (95% 
CI = 0.7%-1.7%); and for profound hearing loss, 0.2% (95% CI = 0.03%-0.33%). The 
groups at higher risk for hearing loss were men (odds ratio (OR) = 1.54; 95% CI 
= 1.06-2.23); participants 60 years of age and over (OR = 12.55; 95% CI = 
8.38-18.79); those with fewer years of formal schooling (OR = 3.92; 95% CI = 
2.14-7.16); and those with lower income (OR = 1.56; 95% CI = 1.06-2.27).
CONCLUSIONS: These results support advocacy by health policy planners and care 
providers for the prevention of deafness and hearing impairment. The findings 
could help build awareness in the community, in universities, and in government 
agencies of the health care needs that hearing problems create.

DOI: 10.1590/s1020-49892007000500006
PMID: 17761050 [Indexed for MEDLINE]


315. Cochlear Implants Int. 2017 Jul;18(4):198-206. doi: 
10.1080/14670100.2017.1325093. Epub 2017 May 12.

Computer-assisted CI fitting: Is the learning capacity of the intelligent agent 
FOX beneficial for speech understanding?

Meeuws M(1), Pascoal D(1), Bermejo I(1), Artaso M(1), De Ceulaer G(1), Govaerts 
PJ(1).

Author information:
(1)a The Eargroup , Herentalsebaan 75, 2100 Antwerp-Deurne, Belgium.

OBJECTIVE: The software application FOX ('Fitting to Outcome eXpert') is an 
intelligent agent to assist in the programing of cochlear implant (CI) 
processors. The current version utilizes a mixture of deterministic and 
probabilistic logic which is able to improve over time through a learning 
effect. This study aimed at assessing whether this learning capacity yields 
measurable improvements in speech understanding.
METHODS: A retrospective study was performed on 25 consecutive CI recipients 
with a median CI use experience of 10 years who came for their annual CI 
follow-up fitting session. All subjects were assessed by means of speech 
audiometry with open set monosyllables at 40, 55, 70, and 85 dB SPL in quiet 
with their home MAP. Other psychoacoustic tests were executed depending on the 
audiologist's clinical judgment. The home MAP and the corresponding test results 
were entered into FOX. If FOX suggested to make MAP changes, they were 
implemented and another speech audiometry was performed with the new MAP.
RESULTS: FOX suggested MAP changes in 21 subjects (84%). The within-subject 
comparison showed a significant median improvement of 10, 3, 1, and 7% at 40, 
55, 70, and 85 dB SPL, respectively. All but two subjects showed an 
instantaneous improvement in their mean speech audiometric score.
DISCUSSION: Persons with long-term CI use, who received a FOX-assisted CI 
fitting at least 6 months ago, display improved speech understanding after MAP 
modifications, as recommended by the current version of FOX. This can be 
explained only by intrinsic improvements in FOX's algorithms, as they have 
resulted from learning. This learning is an inherent feature of artificial 
intelligence and it may yield measurable benefit in speech understanding even in 
long-term CI recipients.

DOI: 10.1080/14670100.2017.1325093
PMID: 28498083 [Indexed for MEDLINE]


316. J Acoust Soc Am. 2008 Nov;124(5):3191-202. doi: 10.1121/1.2987427.

Perception and production of /r/ allophones improve with hearing from a cochlear 
implant.

Matthies ML(1), Guenther FH, Denny M, Perkell JS, Burton E, Vick J, Lane H, 
Tiede M, Zandipour M.

Author information:
(1)Department of Speech Language and Hearing Sciences, Boston University, 
Boston, MA 02215, USA.

Tongue shape can vary greatly for allophones of /r/ produced in different 
phonetic contexts but the primary acoustic cue used by listeners, lowered F3, 
remains stable. For the current study, it was hypothesized that auditory 
feedback maintains the speech motor control mechanisms that are constraining 
acoustic variability of F3 in /r/; thus the listener's percept remains /r/ 
despite the range of articulatory configurations employed by the speaker. Given 
the potential importance of auditory feedback, postlingually deafened speakers 
should show larger acoustic variation in /r/ allophones than hearing controls, 
and auditory feedback from a cochlear implant could reduce that variation over 
time. To test these hypotheses, measures were made of phoneme perception and of 
production of tokens containing /r/, stop consonants, and /r/+stop clusters in 
hearing controls and in eight postlingually deafened adults pre- and 
postimplant. Postimplant, seven of the eight implant speakers did not differ 
from the control mean. It was also found that implant users' production of stop 
and stop+/r/ blend improved with time but the measured acoustic contrast between 
these was still better in the control speakers than for the implant group even 
after the implant users had experienced a year of improved auditory feedback.

DOI: 10.1121/1.2987427
PMCID: PMC2677359
PMID: 19045803 [Indexed for MEDLINE]


317. Ear Hear. 2020 Nov/Dec;41(6):1619-1634. doi: 10.1097/AUD.0000000000000410.

Classification of Hearing Aids Into Feature Profiles Using Hierarchical Latent 
Class Analysis Applied to a Large Dataset of Hearing Aids.

Lansbergen S(1), Dreschler WA.

Author information:
(1)Department of Clinical and Experimental Audiology, Amsterdam University 
Medical Center, University of Amsterdam, Amsterdam, the Netherlands.

OBJECTIVES: We developed a framework for objectively comparing hearing aids, 
independent of brand, type, or product family. This was done using a large 
dataset of commercially available hearing aids. To achieve this, we investigated 
which hearing aid features are suitable for comparison, and are also relevant 
for the rehabilitation of hearing impairment. To compare hearing aids 
objectively, we distinguished populations of hearing aids based on a set of key 
hearing aid features. Finally, we describe these hearing aid subpopulations so 
that these could potentially be used as a supporting tool for the selection of 
an appropriate hearing aid.
DESIGN: In this study, we used technical (meta-)data from 3911 hearing aids 
(available on the Dutch market in March 2018). The dataset contained about 50 of 
the most important characteristics of a hearing aid. After cleaning and handling 
the data via a well-defined knowledge discovery in database procedure, a total 
3083 hearing aids were included. Subsequently, a set of well-defined key hearing 
aid features were used as input for further analysis. The data were split into 
an in-the-ear style hearing aid subset and a behind-the-ear style subset, for 
separate analyses. The knowledge discovery in databases procedure was also used 
as an objective guiding tool for applying an exploratory cluster analysis to 
expose subpopulations of hearing aids within the dataset. The latter was done 
using Latent Class Tree Analysis, which is an extension to the better-known 
Latent Class Analysis clustering method: with the important addition of a 
hierarchical structure.
RESULTS: A total of 10 hearing aid features were identified as relevant for 
audiological rehabilitation: compression, sound processing, noise reduction 
(NR), expansion, wind NR, impulse (noise) reduction, active feedback management, 
directionality, NR environments, and ear-to-ear communication. These features 
had the greatest impact on results yielded by the Latent Class Tree cluster 
analysis. At the first level in the hierarchical cluster model, the two 
subpopulations of hearing aids could be divided into 3 main branches, mainly 
distinguishable by the overall availability or technology level of hearing aid 
features. Higher-level results of the cluster analysis yielded a set of mutually 
exclusive hearing aid populations, called modalities. In total, nine 
behind-the-ear and seven in-the-ear modalities were found. These modalities were 
characterized by particular profiles of (complex) interplay between the selected 
key features. A technical comparison of features (e.g., implementation) is 
beyond the scope of this research.
CONCLUSIONS: Combining a large dataset of hearing aids with a probabilistic 
hierarchical clustering method enables analysis of hearing aid characteristics 
which extends beyond product families and manufacturers. Furthermore, this study 
found that the resulting hearing aid modalities can be thought of as a generic 
alternative to the manufacturer-dependent proprietary "concepts," and could 
potentially aid the selection of an appropriate hearing aid for technical 
rehabilitation. This study is in line with a growing need for justification of 
hearing aid selection and the increasing demand for evidence-based practice.

DOI: 10.1097/AUD.0000000000000410
PMCID: PMC7722464
PMID: 33136637 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


318. Trends Hear. 2021 Jan-Dec;25:23312165211066174. doi: 10.1177/23312165211066174.

Predictive models for cochlear implant outcomes: Performance, generalizability, 
and the impact of cohort size.

Shafieibavani E(1), Goudey B(1)(2), Kiral I(1), Zhong P(1), Jimeno-Yepes A(1), 
Swan A(1), Gambhir M(1), Buechner A(3), Kludt E(3), Eikelboom RH(4)(5)(6), 
Sucher C(4)(5), Gifford RH(7), Rottier R(8), Plant K(8), Anjomshoa H(1)(9).

Author information:
(1)127113IBM Research Australia, Southbank, Victoria, Australia.
(2)School of Computing and Information Systems, University of Melbourne, 
Parkville, Victoria, Australia.
(3)9177Medizinische Hochschule Hannover, Hannover, Niedersachsen, Germany.
(4)104182Ear Science Institute Australia, Subiaco, Western Australia, Australia.
(5)Ear Sciences Centre, The University of Western Australia, Nedlands, Western 
Australia, Australia.
(6)Department of Speech Language Pathology and Audiology, University of 
Pretoria, South Africa.
(7)Department of Hearing and Speech Sciences, Vanderbilt University Medical 
Center, Nashville, TN, United States of America.
(8)104148Cochlear Limited, New South Wales, Australia.
(9)School of Mathematics and Statistics, University of Melbourne, Parkville, 
Victoria, Australia.

While cochlear implants have helped hundreds of thousands of individuals, it 
remains difficult to predict the extent to which an individual's hearing will 
benefit from implantation. Several publications indicate that machine learning 
may improve predictive accuracy of cochlear implant outcomes compared to 
classical statistical methods. However, existing studies are limited in terms of 
model validation and evaluating factors like sample size on predictive 
performance. We conduct a thorough examination of machine learning approaches to 
predict word recognition scores (WRS) measured approximately 12 months after 
implantation in adults with post-lingual hearing loss. This is the largest 
retrospective study of cochlear implant outcomes to date, evaluating 2,489 
cochlear implant recipients from three clinics. We demonstrate that while 
machine learning models significantly outperform linear models in prediction of 
WRS, their overall accuracy remains limited (mean absolute error: 17.9-21.8). 
The models are robust across clinical cohorts, with predictive error increasing 
by at most 16% when evaluated on a clinic excluded from the training set. We 
show that predictive improvement is unlikely to be improved by increasing sample 
size alone, with doubling of sample size estimated to only increasing 
performance by 3% on the combined dataset. Finally, we demonstrate how the 
current models could support clinical decision making, highlighting that subsets 
of individuals can be identified that have a 94% chance of improving WRS by at 
least 10% points after implantation, which is likely to be clinically 
meaningful. We discuss several implications of this analysis, focusing on the 
need to improve and standardize data collection.

DOI: 10.1177/23312165211066174
PMCID: PMC8764462
PMID: 34903103 [Indexed for MEDLINE]


319. Eur Arch Otorhinolaryngol. 2023 Oct;280(10):4381-4389. doi: 
10.1007/s00405-023-07927-9. Epub 2023 Mar 31.

Surgical and audiological outcomes with a new transcutaneous bone conduction 
device with reduced transducer thickness in children.

Willenborg K(1)(2), Lenarz T(3)(4), Busch S(3)(4).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany. willenborg.kerstin@mh-hannover.de.
(2)Cluster of Excellence H4A, Hannover, Germany. 
willenborg.kerstin@mh-hannover.de.
(3)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany.
(4)Cluster of Excellence H4A, Hannover, Germany.

PURPOSE: Due to smaller bone thickness, young children with conductive or mixed 
hearing loss or single-sided deafness were previously most commonly treated with 
a percutaneous osseointegrated bone-anchored hearing aid (BAHA) or an active 
middle-ear implant. While the BAHA increases the risk of implant infections, 
skin infection, overgrowth of the screw or involvement of the implant in head 
trauma, middle-ear implant surgery involves manipulation of the ossicles with 
possible risk of surgical trauma. These complications can be omitted with 
transcutaneous bone conduction implant systems like the MED-EL Bonebridge 
system. The purpose of this study was to analyze whether the second generation 
of the Bonebridge (BCI 602) that features a decreased implant thickness with a 
reduced surgical drilling depth can be implanted safely in young children with 
good postoperative hearing performance.
METHODS: In this study, 14 patients under 12 years were implanted with the 
second generation of the Bonebridge. Preoperative workup comprised a CT scan, an 
MRI scan, pure tone audiometry, or alternatively a BERA (bone conduction, air 
conduction). Since children under 12 years often have a lower bone thickness, 
the CT was performed to determine the suitability of the temporal bone for 
optimal implant placement using the Otoplan software.
RESULTS: All patients (including three under the age of five) were successfully 
implanted and showed a good postoperative hearing performance.
CONCLUSION: With adequate preoperative workup, this device can be safely 
implanted in children and even children under 5 years of age and allows for an 
extension of indication criteria toward younger children.

© 2023. The Author(s).

DOI: 10.1007/s00405-023-07927-9
PMCID: PMC10477095
PMID: 37000276 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


320. J Speech Lang Hear Res. 2017 May 24;60(5):1362-1377. doi: 
10.1044/2016_JSLHR-H-16-0162.

Auditory Environment Across the Life Span of Cochlear Implant Users: Insights 
From Data Logging.

Busch T(1), Vanpoucke F(2), van Wieringen A(3).

Author information:
(1)KU Leuven, BelgiumCochlear Technology Centre, Mechelen, Belgium.
(2)Cochlear Technology Centre, Mechelen, Belgium.
(3)KU Leuven, Belgium.

PURPOSE: We describe the natural auditory environment of people with cochlear 
implants (CIs), how it changes across the life span, and how it varies between 
individuals.
METHOD: We performed a retrospective cross-sectional analysis of Cochlear 
Nucleus 6 CI sound-processor data logs. The logs were obtained from 1,501 people 
with CIs (ages 0-96 years). They covered over 2.4 million hr of implant use and 
indicated how much time the CI users had spent in various acoustical 
environments. We investigated exposure to spoken language, noise, music, and 
quiet, and analyzed variation between age groups, users, and countries.
RESULTS: CI users spent a substantial part of their daily life in noisy 
environments. As a consequence, most speech was presented in background noise. 
We found significant differences between age groups for all auditory scenes. Yet 
even within the same age group and country, variability between individuals was 
substantial.
CONCLUSIONS: Regardless of their age, people with CIs face challenging 
acoustical environments in their daily life. Our results underline the 
importance of supporting them with assistive listening technology. Moreover, we 
found large differences between individuals' auditory diets that might 
contribute to differences in rehabilitation outcomes. Their causes and effects 
should be investigated further.

DOI: 10.1044/2016_JSLHR-H-16-0162
PMID: 28418532 [Indexed for MEDLINE]


321. J Acoust Soc Am. 2014 Mar;135(3):1506-17. doi: 10.1121/1.4864293.

Prediction of consonant recognition in quiet for listeners with normal and 
impaired hearing using an auditory model.

Jürgens T(1), Ewert SD(1), Kollmeier B(1), Brand T(1).

Author information:
(1)Cluster of Excellence "Hearing4all," Department für Medizinische Physik und 
Akustik, Carl-von-Ossietzky Universität Oldenburg, Carl-von Ossietzky-Strasse 
9-11, D-26111 Oldenburg, Germany.

Consonant recognition was assessed in normal-hearing (NH) and hearing-impaired 
(HI) listeners in quiet as a function of speech level using a nonsense logatome 
test. Average recognition scores were analyzed and compared to recognition 
scores of a speech recognition model. In contrast to commonly used spectral 
speech recognition models operating on long-term spectra, a "microscopic" model 
operating in the time domain was used. Variations of the model (accounting for 
hearing impairment) and different model parameters (reflecting cochlear 
compression) were tested. Using these model variations this study examined 
whether speech recognition performance in quiet is affected by changes in 
cochlear compression, namely, a linearization, which is often observed in HI 
listeners. Consonant recognition scores for HI listeners were poorer than for NH 
listeners. The model accurately predicted the speech reception thresholds of the 
NH and most HI listeners. A partial linearization of the cochlear compression in 
the auditory model, while keeping audibility constant, produced higher 
recognition scores and improved the prediction accuracy. However, including 
listener-specific information about the exact form of the cochlear compression 
did not improve the prediction further.

DOI: 10.1121/1.4864293
PMID: 24606286 [Indexed for MEDLINE]


322. Artif Intell Med. 2004 Jul;31(3):221-9. doi: 10.1016/j.artmed.2004.03.004.

Automatic analysis of auditory nerve electrically evoked compound action 
potential with an artificial neural network.

Charasse B(1), Thai-Van H, Chanal JM, Berger-Vachon C, Collet L.

Author information:
(1)UMR CNRS 5020, Laboratoire Neurosciences & Systèmes Sensoriels, 50 avenue 
Tony Garnier, 69366 Lyon Cedex, France. bcharass@olfac.uni-lyon1.fr

The auditory nerve's electrically evoked compound action potential is recorded 
in deaf patients equipped with the Nucleus 24 cochlear implant using a reverse 
telemetry system (NRT). Since the threshold of the NRT response (NRT-T) is 
thought to reflect the psychophysics needed for programming cochlear implants, 
efforts have been made by specialized management teams to develop its use. This 
study aimed at developing a valid tool, based on artificial neural networks 
(ANN) technology, for automatic estimation of NRT-T. The ANN used was a single 
layer perceptron, trained with 120 NRT traces. Learning traces differed from 
data used for the validation. A total of 550 NRT traces from 11 cochlear implant 
subjects were analyzed separately by the system and by a group of physicians 
with expertise in NRT analysis. Both worked to determine 37 NRT-T values, using 
the response amplitude growth function (AGF) (linear regression of response 
amplitudes obtained at decreasing stimulus intensity levels). The validity of 
the system was assessed by comparing the NRT-T values automatically determined 
by the system with those determined by the physicians. A strong correlation was 
found between automatic and physician-obtained NRT-T values (Pearson r 
correlation coefficient >0.9). ANOVA statistics confirmed that automatic NRT-Ts 
did not differ from physician-obtained values (F = 0.08999, P = 0.03). Moreover, 
the average error between NRT-Ts predicted by the system and NRT-Ts measured by 
the physicians (3.6 stimulation units) did not differ significantly from the 
average error between NRT-Ts measured by each of the three physicians (4.2 
stimulation units). In conclusion, the automatic system developed in this study 
was found to be as efficient as human experts for fitting the amplitude growth 
function and estimating NRT-T, with the advantage of considerable time-saving.

DOI: 10.1016/j.artmed.2004.03.004
PMID: 15302088 [Indexed for MEDLINE]


323. Int J Audiol. 2016;55(6):346-57. doi: 10.3109/14992027.2015.1135352. Epub 2016 
Feb 26.

Exploration of a physiologically-inspired hearing-aid algorithm using a computer 
model mimicking impaired hearing.

Jürgens T(1)(2), Clark NR(2)(3), Lecluyse W(2)(4), Meddis R(2).

Author information:
(1)a Medizinische Physik, Forschungszentrum Neurosensorik and Cluster of 
Excellence 'Hearing4all', Carl-von-Ossietzky Universität Oldenburg , Oldenburg , 
Germany .
(2)b Department of Psychology , University of Essex , Colchester , UK .
(3)c Mimi Hearing Technologies GmbH , Berlin , Germany .
(4)d Department of Children, Young People and Education , University Campus 
Suffolk , Ipswich , UK.

OBJECTIVE: To use a computer model of impaired hearing to explore the effects of 
a physiologically-inspired hearing-aid algorithm on a range of psychoacoustic 
measures.
DESIGN: A computer model of a hypothetical impaired listener's hearing was 
constructed by adjusting parameters of a computer model of normal hearing. 
Absolute thresholds, estimates of compression, and frequency selectivity 
(summarized to a hearing profile) were assessed using this model with and 
without pre-processing the stimuli by a hearing-aid algorithm. The influence of 
different settings of the algorithm on the impaired profile was investigated. To 
validate the model predictions, the effect of the algorithm on hearing profiles 
of human impaired listeners was measured.
STUDY SAMPLE: A computer model simulating impaired hearing (total absence of 
basilar membrane compression) was used, and three hearing-impaired listeners 
participated.
RESULTS: The hearing profiles of the model and the listeners showed substantial 
changes when the test stimuli were pre-processed by the hearing-aid algorithm. 
These changes consisted of lower absolute thresholds, steeper temporal masking 
curves, and sharper psychophysical tuning curves.
CONCLUSION: The hearing-aid algorithm affected the impaired hearing profile of 
the model to approximate a normal hearing profile. Qualitatively similar results 
were found with the impaired listeners' hearing profiles.

DOI: 10.3109/14992027.2015.1135352
PMID: 26918797 [Indexed for MEDLINE]


324. Ear Hear. 2018 Mar/Apr;39(2):293-304. doi: 10.1097/AUD.0000000000000486.

Characteristics of Real-World Signal to Noise Ratios and Speech Listening 
Situations of Older Adults With Mild to Moderate Hearing Loss.

Wu YH(1), Stangl E(1), Chipara O(1), Hasan SS(1), Welhaven A(1), Oleson J(1).

Author information:
(1)Department of Communication Sciences and Disorders, The University of Iowa, 
Iowa City, Iowa, USA.

OBJECTIVES: The first objective was to determine the relationship between speech 
level, noise level, and signal to noise ratio (SNR), as well as the distribution 
of SNR, in real-world situations wherein older adults with hearing loss are 
listening to speech. The second objective was to develop a set of prototype 
listening situations (PLSs) that describe the speech level, noise level, SNR, 
availability of visual cues, and locations of speech and noise sources of 
typical speech listening situations experienced by these individuals.
DESIGN: Twenty older adults with mild to moderate hearing loss carried digital 
recorders for 5 to 6 weeks to record sounds for 10 hours per day. They also 
repeatedly completed in situ surveys on smartphones several times per day to 
report the characteristics of their current environments, including the 
locations of the primary talker (if they were listening to speech) and noise 
source (if it was noisy) and the availability of visual cues. For surveys where 
speech listening was indicated, the corresponding audio recording was examined. 
Speech-plus-noise and noise-only segments were extracted, and the SNR was 
estimated using a power subtraction technique. SNRs and the associated survey 
data were subjected to cluster analysis to develop PLSs.
RESULTS: The speech level, noise level, and SNR of 894 listening situations were 
analyzed to address the first objective. Results suggested that as noise levels 
increased from 40 to 74 dBA, speech levels systematically increased from 60 to 
74 dBA, and SNR decreased from 20 to 0 dB. Most SNRs (62.9%) of the collected 
recordings were between 2 and 14 dB. Very noisy situations that had SNRs below 0 
dB comprised 7.5% of the listening situations. To address the second objective, 
recordings and survey data from 718 observations were analyzed. Cluster analysis 
suggested that the participants' daily listening situations could be grouped 
into 12 clusters (i.e., 12 PLSs). The most frequently occurring PLSs were 
characterized as having the talker in front of the listener with visual cues 
available, either in quiet or in diffuse noise. The mean speech level of the 
PLSs that described quiet situations was 62.8 dBA, and the mean SNR of the PLSs 
that represented noisy environments was 7.4 dB (speech = 67.9 dBA). A subset of 
observations (n = 280), which was obtained by excluding the data collected from 
quiet environments, was further used to develop PLSs that represent noisier 
situations. From this subset, two PLSs were identified. These two PLSs had lower 
SNRs (mean = 4.2 dB), but the most frequent situations still involved speech 
from in front of the listener in diffuse noise with visual cues available.
CONCLUSIONS: The present study indicated that visual cues and diffuse noise were 
exceedingly common in real-world speech listening situations, while environments 
with negative SNRs were relatively rare. The characteristics of speech level, 
noise level, and SNR, together with the PLS information reported by the present 
study, can be useful for researchers aiming to design ecologically valid 
assessment procedures to estimate real-world speech communicative functions for 
older adults with hearing loss.

DOI: 10.1097/AUD.0000000000000486
PMCID: PMC5824438
PMID: 29466265 [Indexed for MEDLINE]


325. Int J Audiol. 2010 Sep;49(9):628-33. doi: 10.3109/14992021003796887.

Using cluster analysis to classify audiogram shapes.

Lee CY(1), Hwang JH, Hou SJ, Liu TC.

Author information:
(1)Department of Otolaryngology, Buddhist Dalin Tzu Chi General Hospital, 
Chiayi, Taiwan.

The purpose of this study was to design a statistical classification system of 
audiogram shapes in order to improve and integrate shape recognition across 
clinical settings. The study included 1633 adult subjects with normal hearing or 
symmetric sensorineural hearing impairment who underwent pure-tone audiometry 
between July 2007 and December 2008. K-means cluster analysis was employed to 
categorize audiometric shapes. Eleven audiogram shapes were identified: rising, 
flat, peaked 8-kHz dip, 4-kHz dip, 8-kHz dip, mild sloping, severe 8-kHz dip, 
sloping, abrupt loss, severe sloping, and profound abrupt loss. By using the 
classification system and nomenclature identified for audiogram shapes as 
outlined in this study, errors based on personal experiences can be reduced and 
a consistency can be developed across clinics.

DOI: 10.3109/14992021003796887
PMID: 20553102 [Indexed for MEDLINE]


326. Hear Res. 2020 Sep 15;395:107995. doi: 10.1016/j.heares.2020.107995. Epub 2020 
Jul 8.

Simulations with FADE of the effect of impaired hearing on speech recognition 
performance cast doubt on the role of spectral resolution.

Hülsmeier D(1), Warzybok A(2), Kollmeier B(2), Schädler MR(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität 
Oldenburg, 26129, Oldenburg, Germany. Electronic address: 
david.huelsmeier@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität 
Oldenburg, 26129, Oldenburg, Germany.

Listeners with hearing impairment show sub-optimal processing of acoustic 
signals which affects their ability to recognize speech. In this contribution, 
three effective signal processing deficits are proposed to simulate 
sensorineural hearing impairment and their effect on simulated speech 
recognition performance is studied. Psychoacoustic and speech recognition 
experiments were simulated with the framework for auditory discrimination 
experiments (FADE). Loss in absolute hearing threshold was modeled as lower 
level limit, supra-threshold loss in envelope amplitude resolution as 
multiplicative noise, and reduced spectral resolution was simulated with an 
increase of the analysis bandwidth. Their effects on the speech recognition 
performance with the German matrix test in quiet and noise, the audiogram, and 
tone in (notched) noise detection experiments were systematically examined. The 
simulations indicate that each psychoacoustic experiment relates to at least one 
signal processing deficit. This indicates the possibility to determine 
individual model parameters from the outcome of psychoacoustic experiments. 
Moreover, absolute hearing thresholds yield the highest effects on simulated 
speech recognition thresholds, followed by supra-threshold loss in envelope 
amplitude resolution, and-to a much smaller degree-spectral resolution. A 
reduced spectral resolution only affected recognition performance in fluctuating 
masker for normal hearing thresholds, indicating its potential relevance for 
more complex listening conditions. In contrast to popular interpretations in the 
literature, the simulations reveal that reduced spectral resolution plays a 
minor role compared to a reduced envelope amplitude resolution in characterizing 
supra-threshold hearing loss at least in stationary noise.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2020.107995
PMID: 32702612 [Indexed for MEDLINE]


327. Hum Mutat. 2013 Apr;34(4):539-45. doi: 10.1002/humu.22268. Epub 2013 Feb 19.

AudioGene: predicting hearing loss genotypes from phenotypes to guide genetic 
screening.

Taylor KR(1), Deluca AP, Shearer AE, Hildebrand MS, Black-Ziegelbein EA, Anand 
VN, Sloan CM, Eppsteiner RW, Scheetz TE, Huygen PL, Smith RJ, Braun TA, Casavant 
TL.

Author information:
(1)Department of Electrical and Computer Engineering, University of Iowa, Iowa 
City, IA, USA.

Autosomal dominant nonsyndromic hearing loss (ADNSHL) is a common and often 
progressive sensory deficit. ADNSHL displays a high degree of genetic 
heterogeneity and varying rates of progression. Accurate, comprehensive, and 
cost-effective genetic testing facilitates genetic counseling and provides 
valuable prognostic information to affected individuals. In this article, we 
describe the algorithm underlying AudioGene, a software system employing 
machine-learning techniques that utilizes phenotypic information derived from 
audiograms to predict the genetic cause of hearing loss in persons segregating 
ADNSHL. Our data show that AudioGene has an accuracy of 68% in predicting the 
causative gene within its top three predictions, as compared with 44% for a 
majority classifier. We also show that AudioGene remains effective for 
audiograms with high levels of clinical measurement noise. We identify 
audiometric outliers for each genetic locus and hypothesize that outliers may 
reflect modifying genetic effects. As personalized genomic medicine becomes more 
common, AudioGene will be increasingly useful as a phenotypic filter to assess 
pathogenicity of variants identified by massively parallel sequencing.

© 2012 Wiley Periodicals, Inc.

DOI: 10.1002/humu.22268
PMCID: PMC3753227
PMID: 23280582 [Indexed for MEDLINE]


328. J Acoust Soc Am. 2021 Oct;150(4):2526. doi: 10.1121/10.0006565.

Deep learning based speaker separation and dereverberation can generalize across 
different languages to improve intelligibility.

Healy EW(1), Johnson EM(1), Delfarah M(2), Krishnagiri DS(1), Sevich VA(1), 
Taherian H(2), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, The Ohio State University, 
Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.

The practical efficacy of deep learning based speaker separation and/or 
dereverberation hinges on its ability to generalize to conditions not employed 
during neural network training. The current study was designed to assess the 
ability to generalize across extremely different training versus test 
environments. Training and testing were performed using different languages 
having no known common ancestry and correspondingly large linguistic 
differences-English for training and Mandarin for testing. Additional 
generalizations included untrained speech corpus/recording channel, 
target-to-interferer energy ratios, reverberation room impulse responses, and 
test talkers. A deep computational auditory scene analysis algorithm, employing 
complex time-frequency masking to estimate both magnitude and phase, was used to 
segregate two concurrent talkers and simultaneously remove large amounts of room 
reverberation to increase the intelligibility of a target talker. Significant 
intelligibility improvements were observed for the normal-hearing listeners in 
every condition. Benefit averaged 43.5% points across conditions and was 
comparable to that obtained when training and testing were performed both in 
English. Benefit is projected to be considerably larger for individuals with 
hearing impairment. It is concluded that a properly designed and trained deep 
speaker separation/dereverberation network can be capable of generalization 
across vastly different acoustic environments that include different languages.

DOI: 10.1121/10.0006565
PMCID: PMC8637753
PMID: 34717521 [Indexed for MEDLINE]


329. J Acoust Soc Am. 2015 Sep;138(3):1660-9. doi: 10.1121/1.4929493.

An algorithm to increase speech intelligibility for hearing-impaired listeners 
in novel segments of the same noise type.

Healy EW(1), Yoho SE(1), Chen J(2), Wang Y(2), Wang D(3).

Author information:
(1)Department of Speech and Hearing Science, Center for Cognitive and Brain 
Sciences, The Ohio State University, Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.
(3)Department of Computer Science and Engineering, Center for Cognitive and 
Brain Sciences, The Ohio State University, Columbus, Ohio 43210, USA.

Machine learning algorithms to segregate speech from background noise hold 
considerable promise for alleviating limitations associated with hearing 
impairment. One of the most important considerations for implementing these 
algorithms into devices such as hearing aids and cochlear implants involves 
their ability to generalize to conditions not employed during the training 
stage. A major challenge involves the generalization to novel noise segments. In 
the current study, sentences were segregated from multi-talker babble and from 
cafeteria noise using an algorithm that employs deep neural networks to estimate 
the ideal ratio mask. Importantly, the algorithm was trained on segments of 
noise and tested using entirely novel segments of the same nonstationary noise 
type. Substantial sentence-intelligibility benefit was observed for 
hearing-impaired listeners in both noise types, despite the use of unseen noise 
segments during the test stage. Interestingly, normal-hearing listeners 
displayed benefit in babble but not in cafeteria noise. This result highlights 
the importance of evaluating these algorithms not only in human subjects, but in 
members of the actual target population.

DOI: 10.1121/1.4929493
PMCID: PMC4592427
PMID: 26428803 [Indexed for MEDLINE]


330. Scand Audiol. 1999;28(2):85-90. doi: 10.1080/010503999424806.

Slope analysis of Auditory Brainstem Responses in children at risk of central 
auditory processing disorders.

Gopal KV(1), Kowalski J.

Author information:
(1)Department of Speech and Hearing Sciences, University of North Texas, Denton 
76203-5010, USA. gopal@unt.edu

The method of slope vectors was used to quantify Auditory Brainstem Responses 
(ABR) obtained from nine normal children and nine children at risk for central 
auditory processing disorders (CAPD) with language impairment, for monaural and 
binaural stimulation conditions. Slopes thus obtained were subjected to K-Means 
Cluster Analysis. Distinction between the two groups was obtained only for 
binaural stimulation conditions, wherein all normal children were grouped under 
cluster 1 with higher slope values and 6 out of 9 CAPD children were grouped 
under cluster 2 with lower slopes. The results suggest that there may be several 
subcategories among children who are found to be at risk for CAPD. One of the 
subcategories may comprise children who exhibit poor ABR morphology, especially 
during binaural stimulation conditions, which could be due to binaural 
interference.

DOI: 10.1080/010503999424806
PMID: 10384895 [Indexed for MEDLINE]


331. J Acoust Soc Am. 2024 Mar 1;155(3):1694-1703. doi: 10.1121/10.0025057.

Enhancing music recognition using deep learning-powered source separation 
technology for cochlear implant users.

Chang YJ(1), Han JY(1), Chu WC(1), Li LP(2)(3)(4)(5), Lai YH(1)(6).

Author information:
(1)Department of Biomedical Engineering, National Yang Ming Chiao Tung 
University, Taipei, Taiwan.
(2)Faculty of Medicine, School of Medicine, National Yang Ming Chiao Tung 
University, Taipei, Taiwan.
(3)Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan.
(4)Department of Medical Research, China Medical University Hospital, China 
Medical University, Taichung, Taiwan.
(5)Institute of Brain Science, School of Medicine, National Yang Ming Chiao Tung 
University, Taipei, Taiwan.
(6)Medical Device Innovation Translation Center, National Yang Ming Chiao Tung 
University, Taipei, Taiwan.

Cochlear implant (CI) is currently the vital technological device for assisting 
deaf patients in hearing sounds and greatly enhances their sound listening 
appreciation. Unfortunately, it performs poorly for music listening because of 
the insufficient number of electrodes and inaccurate identification of music 
features. Therefore, this study applied source separation technology with a 
self-adjustment function to enhance the music listening benefits for CI users. 
In the objective analysis method, this study showed that the results of the 
source-to-distortion, source-to-interference, and source-to-artifact ratios were 
4.88, 5.92, and 15.28 dB, respectively, and significantly better than the Demucs 
baseline model. For the subjective analysis method, it scored higher than the 
traditional baseline method VIR6 (vocal to instrument ratio, 6 dB) by 
approximately 28.1 and 26.4 (out of 100) in the multi-stimulus test with hidden 
reference and anchor test, respectively. The experimental results showed that 
the proposed method can benefit CI users in identifying music in a live concert, 
and the personal self-fitting signal separation method had better results than 
any other default baselines (vocal to instrument ratio of 6 dB or vocal to 
instrument ratio of 0 dB) did. This finding suggests that the proposed system is 
a potential method for enhancing the music listening benefits for CI users.

© 2024 Acoustical Society of America.

DOI: 10.1121/10.0025057
PMID: 38426839 [Indexed for MEDLINE]


332. Front Med. 2019 Dec;13(6):690-704. doi: 10.1007/s11684-018-0638-8. Epub 2018 Aug 
30.

Tprn is essential for the integrity of stereociliary rootlet in cochlear hair 
cells in mice.

Men Y(1), Li X(2), Tu H(1), Zhang A(1), Fu X(1), Wang Z(1), Jin Y(1), Hou C(3), 
Zhang T(1), Zhang S(1), Zhou Y(1), Li B(4)(5), Li J(6), Sun X(7), Wang H(8), Gao 
J(9).

Author information:
(1)School of Life Science, Shandong University, Jinan, 250100, China.
(2)Rizhao Polytechnic, Rizhao, 276826, China.
(3)The Second Hospital of Shandong University, Jinan, 250033, China.
(4)Electron Microscopy Laboratory, Shandong Institute of Otolaryngology, Jinan, 
250022, China.
(5)Laboratory of Electron Microscopy, Jinan WEI-YA Biotech Company, Jinan, 
250100, China.
(6)Department of Otolaryngology-Head and Neck Surgery, Provincial Hospital 
Affiliated to Shandong University, Jinan, 250021, China.
(7)School of Life Science, Shandong University, Jinan, 250100, China. 
sunxy70@sdu.edu.cn.
(8)Department of Otolaryngology-Head and Neck Surgery, Provincial Hospital 
Affiliated to Shandong University, Jinan, 250021, China. 
wang.hb7585@hotmail.com.
(9)School of Life Science, Shandong University, Jinan, 250100, China. 
jggao@sdu.edu.cn.

Tprn encodes the taperin protein, which is concentrated in the tapered region of 
hair cell stereocilia in the inner ear. In humans, TPRN mutations cause 
autosomal recessive nonsyndromic deafness (DFNB79) by an unknown mechanism. To 
determine the role of Tprn in hearing, we generated Tprn-null mice by clustered 
regularly interspaced short palindromic repeat/Cas9 genome-editing technology 
from a CBA/CaJ background. We observed significant hearing loss and progressive 
degeneration of stereocilia in the outer hair cells of Tprn-null mice starting 
from postnatal day 30. Transmission electron microscopy images of stereociliary 
bundles in the mutant mice showed some stereociliary rootlets with curved 
shafts. The central cores of the stereociliary rootlets possessed hollow 
structures with surrounding loose peripheral dense rings. Radixin, a protein 
expressed at stereocilia tapering, was abnormally dispersed along the 
stereocilia shafts in Tprn-null mice. The expression levels of radixin and 
β-actin significantly decreased.We propose that Tprn is critical to the 
retention of the integrity of the stereociliary rootlet. Loss of Tprn in 
Tprn-null mice caused the disruption of the stereociliary rootlet, which 
resulted in damage to stereociliary bundles and hearing impairments. The 
generated Tprn-null mice are ideal models of human hereditary deafness DFNB79.

DOI: 10.1007/s11684-018-0638-8
PMID: 30159668 [Indexed for MEDLINE]


333. S Afr J Commun Disord. 2018 Jul 5;65(1):e1-e9. doi: 10.4102/sajcd.v65i1.582.

Assessing the efficacy of asynchronous telehealth-based hearing screening and 
diagnostic services using automated audiometry in a rural South African school.

Govender SM(1), Mars M.

Author information:
(1)Department of Telehealth, University of KwaZulu-Natal. 
samantha.govender@smu.ac.za.

 Asynchronous automated telehealth-based hearing screening and diagnostic 
testing can be used within the rural school context to identify and confirm 
hearing loss. Objective: The aims of the study were to evaluate the efficacy of 
an asynchronous telehealth-based service delivery model using automated 
technology for screening and diagnostic testing as well as to describe the 
prevalence, type and degree of hearing loss. Method: A comparative 
within-subject design was used. Frequency distributions, sensitivity, 
specificity scores as well as the positive and negative predictive values were 
calculated. Testing was conducted in a non-sound-treated classroom within a 
school environment on 73 participants (146 ears). The sensitivity and 
specificity rates were 65.2% and 100%, respectively. Diagnostic accuracy was 
91.7% and the negative predictive values (NPV) and positive predictive values 
(PPV) were 93.8% and 100%, respectively. Results: Results revealed that 23 ears 
of 20 participants (16%) presented with hearing loss. Twelve per cent of ears 
presented with unilateral hearing impairment and 4% with bilateral hearing loss. 
Mild hearing loss was identified as most prevalent (8% of ears). Eight ears 
obtained false-negative results and presented with mild low- to mid-frequency 
hearing loss. The sensitivity rate for the study was low and was attributed to 
plausible reasons relating to test accuracy, child-related variables and mild 
low-frequency sensory-neural hearing loss. Conclusion: The study demonstrates 
that asynchronous telehealth-based automated hearing testing within the school 
context can be used to facilitate early identification of hearing loss; however, 
further research and development into protocol formulation, ongoing device 
monitoring and facilitator training is required to improve test sensitivity and 
ensure accuracy of results.

DOI: 10.4102/sajcd.v65i1.582
PMCID: PMC6111388
PMID: 30035608 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no financial 
or personal relationship(s) that may have inappropriately influenced them in 
writing this article.


334. J Otolaryngol Head Neck Surg. 2008 Dec;37(6):753-8.

Cross-sectional survey of hearing impairment and ear disease in Uganda.

Westerberg BD(1), Lee PK, Lukwago L, Zaramba S, Bubikere S, Stewart I.

Author information:
(1)Division of Otolaryngology, University of British Columbia, Vancouver, 
British Columbia.

OBJECTIVE: To determine the prevalence and causes of disabling hearing loss in 
adults and children in Uganda.
STUDY DESIGN: Cross-sectional survey of ear disease and hearing impairment.
SETTING: A random cluster sample design of the population from the Masindi 
district of Uganda following the World Health Organization (WHO) guidelines, 
using a modified version of the WHO Ear Disease Survey Protocol.
MAIN OUTCOME MEASURE: The prevalence of disabling hearing impairment using the 
WHO definitions (excluding 0.5 kHz owing to high background noise levels).
RESULTS: In the study, 6041 participants were enrolled and underwent audiometric 
evaluation and an ear examination. The prevalence of disabling hearing 
impairment was 11.7% in adults and 10.2% in children. A further 2.3% of children 
in whom thresholds could not be measured were deemed to have significant hearing 
loss based on screening questions and/or sound-field stimuli. Correctable causes 
such as dry perforations, cerumen impaction, and chronic suppurative otitis 
media resulted in disabling hearing loss in 17% of adult subjects and 41% of 
children. Preventable hearing loss, such as meningitis and noise-induced hearing 
loss, was present in a further significant percentage of subjects.
CONCLUSIONS: Ear disease and hearing impairment were found to be important 
health problems in the Ugandan population. Preventable ear disease is a major 
cause of hearing loss in the population. It is hoped that the findings of this 
study will draw attention to the problem in Uganda and will lead to proper 
allocation of resources for the prevention and treatment of hearing loss and ear 
disease.

PMID: 19128699 [Indexed for MEDLINE]


335. Hear Res. 2017 Sep;353:36-48. doi: 10.1016/j.heares.2017.07.014. Epub 2017 Jul 
29.

Speech reception with different bilateral directional processing schemes: 
Influence of binaural hearing, audiometric asymmetry, and acoustic scenario.

Neher T(1), Wagener KC(2), Latzel M(3).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all", Dept. of Medical 
Physics and Acoustics, Carl-von-Ossietzky University, D-26111 Oldenburg, 
Germany. Electronic address: tneher@health.sdu.dk.
(2)Hörzentrum Oldenburg GmbH, Marie-Curie-Str. 2, D-26129 Oldenburg, Germany. 
Electronic address: k.wagener@hoerzentrum-oldenburg.de.
(3)Phonak AG, Laubisrütistrasse 28, CH-8712 Stäfa, Switzerland. Electronic 
address: matthias.latzel@phonak.com.

Hearing aid (HA) users can differ markedly in their benefit from directional 
processing (or beamforming) algorithms. The current study therefore investigated 
candidacy for different bilateral directional processing schemes. Groups of 
elderly listeners with symmetric (N = 20) or asymmetric (N = 19) hearing 
thresholds for frequencies below 2 kHz, a large spread in the binaural 
intelligibility level difference (BILD), and no difference in age, overall 
degree of hearing loss, or performance on a measure of selective attention took 
part. Aided speech reception was measured using virtual acoustics together with 
a simulation of a linked pair of completely occluding behind-the-ear HAs. Five 
processing schemes and three acoustic scenarios were used. The processing 
schemes differed in the tradeoff between signal-to-noise ratio (SNR) improvement 
and binaural cue preservation. The acoustic scenarios consisted of a frontal 
target talker presented against two speech maskers from ±60° azimuth or 
spatially diffuse cafeteria noise. For both groups, a significant interaction 
between BILD, processing scheme, and acoustic scenario was found. This 
interaction implied that, in situations with lateral speech maskers, HA users 
with BILDs larger than about 2 dB profited more from preserved low-frequency 
binaural cues than from greater SNR improvement, whereas for smaller BILDs the 
opposite was true. Audiometric asymmetry reduced the influence of binaural 
hearing. In spatially diffuse noise, the maximal SNR improvement was generally 
beneficial. N0Sπ detection performance at 500 Hz predicted the benefit from 
low-frequency binaural cues. Together, these findings provide a basis for 
adapting bilateral directional processing to individual and situational 
influences. Further research is needed to investigate their generalizability to 
more realistic HA conditions (e.g., with low-frequency vent-transmitted sound).

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.07.014
PMID: 28783570 [Indexed for MEDLINE]


336. Biomed Res Int. 2019 Jan 6;2019:4346325. doi: 10.1155/2019/4346325. eCollection 
2019.

Middle Ear Transducer: Long Term Stability of the Latest Generation T2.

Prenzler NK(1)(2), Kludt E(2), Giere T(2), Salcher R(1)(2), Lenarz T(1)(2), 
Maier H(1)(2).

Author information:
(1)Cluster of Excellence Hearing4all, Germany.
(2)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.

OBJECTIVES/HYPOTHESIS: Comparing long term stability of the Middle Ear 
Transducers (MET) of the 1st generation T1 (Otologics LLC) with the current 
generation T2 (Cochlear Ltd.) in all our clinical cases with standard incus 
coupling.
STUDY DESIGN: Retrospective chart review.
METHODS: 52 ears implanted with a MET device between 2008 and 2016 were analyzed 
retrospectively. All patients suffered from sensorineural hearing loss and the 
actuator was coupled to the body of the incus (standard coupling). 23 ears were 
implanted with the transducer T1 (Otologics LLC) between 2008 and 2011 and 29 
ears were implanted with the current transducer T2 since 2011 (Otologics 
LLC/Cochlear Ltd.). Latest available in situ and bone conduction (BC) thresholds 
were exploited for a follow-up period of up to 7 years after first fitting. Long 
term stability of coupling and actuator performance was evaluated by tracking 
differences between in situ and BC thresholds.
RESULTS: In the T1 group, 9 out of 23 implants were still used by the patients 
at their last follow-up visit (average observation time 3.7 yrs.; min 1.0 yrs., 
max 7.4 yrs.). In 9 patients a technical failure identified by a decrease of in 
situ threshold of more than 15 dB compared to BC thresholds [Δ (in situ - BC)] 
lead to non-usage of the implant and 7 explantations. Five other explantations 
occurred due to medical reasons such as BC threshold decrease, infection, or 
insufficient speech intelligibility with the device. In the T2 group, 23 out of 
29 implants were still used at the most current follow-up visit (average 
observation time 3.3 yrs.; min 1.0 yrs., max 4.8 yrs.). No technical failures 
were observed up to more than 4 years after implantation. Five T2 patients 
discontinued using the device due to insufficient benefit; two of these patients 
were explanted. One patient had to be explanted before the activation of the 
device due to disorders of wound healing. Nevertheless, a small but significant 
decrease of hearing loss corrected coupling efficiency [Δ (in situ - BC)] was 
seen in the T2 group.
CONCLUSIONS: In contrast to the T1 transducers of the earlier generation of MET 
systems where technical failures occurred frequently, no technical failures were 
detected after 29 implantations with the current T2 transducers. However, a 
small but significant decline of transmission efficiency was observable even in 
the T2 implanted group.

DOI: 10.1155/2019/4346325
PMCID: PMC6339725
PMID: 30723738 [Indexed for MEDLINE]


337. Int J Audiol. 2021 Apr;60(sup1):S13-S22. doi: 10.1080/14992027.2020.1795281. 
Epub 2020 Aug 4.

An examination of clinical uptake factors for remote hearing aid support: a 
concept mapping study with audiologists.

Glista D(1)(2), O'Hagan R(2), Moodie S(1)(2), Scollie S(1)(2).

Author information:
(1)The School of Communication Sciences and Disorders, Faculty of Health 
Sciences, The University of Western Ontario, London, Canada.
(2)The National Centre for Audiology, The University of Western Ontario, London, 
Canada.

OBJECTIVE: To develop a conceptual framework around the factors that influence 
audiologists in the clinical uptake of remote follow-up hearing aid support 
services.
DESIGN: A purposive sample of 42 audiologists, stratified according to 
client-focus of either paediatric or adult, were recruited from professional 
associations in Ontario, Canada, as members of the six-step, participatory-based 
concept mapping process. Analyses included multidimensional scaling and 
hierarchical cluster analysis.
RESULTS: Six main themes emerged from this research according to overall level 
of importance: (1) technology and infrastructure; (2) audiologist-centred 
considerations; (3) hearing healthcare regulations; (4) client-centred 
considerations; (5) clinical implementation considerations; and (6) financial 
considerations. Subthemes were identified at the group-level and by subgroup. 
These highlight the importance of TECH factors (accessible Technology, Easy to 
use, robust Connection, and Help available), as well as the multi-faceted nature 
of the perceived attitudes/aptitudes across stakeholders.
CONCLUSION: Findings can be utilised in tailored planning and development 
efforts to support future research, knowledge dissemination, best-practice 
protocol/guideline development, and related training to assist in the clinical 
uptake of remote follow-up hearing aid support services, across variable 
practice contexts.

DOI: 10.1080/14992027.2020.1795281
PMID: 32749182 [Indexed for MEDLINE]


338. S Afr J Commun Disord. 2002;49:28-39.

Predicting hearing loss from otoacoustic emissions using an artificial neural 
network.

de Waal R(1), Hugo R, Soer M, Krüger JJ.

Author information:
(1)Department of Communication Pathology & Electronic Engineering, University of 
Pretoria.

Normal and impaired pure tone thresholds (PTTs) were predicted from distortion 
product otoacoustic emissions (DPOAEs) using a feed-forward artificial neural 
network (ANN) with a back-propagation training algorithm. The ANN used a map of 
present and absent DPOAEs from eight DPgrams, (2f1-f2 = 406-4031 Hz) to predict 
PTTs at 0.5, 1, 2 and 4 kHz. With normal hearing as < 25 dB HL, prediction 
accuracy of normal hearing was 94% at 500, 88% at 1000, 88% at 2000 and 93% at 
4000 Hz. Prediction of hearing-impaired categories was less accurate, due to 
insufficient data for the ANN to train on. This research indicates the 
possibility of accurately predicting hearing ability within 10 dB in normal 
hearing individuals and in hearing-impaired listeners with DPOAEs and ANNs from 
500-4000 Hz.

PMID: 14968700 [Indexed for MEDLINE]


339. Hum Genet. 2002 May;110(5):389-94. doi: 10.1007/s00439-002-0719-1. Epub 2002 Apr 
9.

Mutations in the WFS1 gene that cause low-frequency sensorineural hearing loss 
are small non-inactivating mutations.

Cryns K(1), Pfister M, Pennings RJ, Bom SJ, Flothmann K, Caethoven G, Kremer H, 
Schatteman I, Köln KA, Tóth T, Kupka S, Blin N, Nürnberg P, Thiele H, van de 
Heyning PH, Reardon W, Stephens D, Cremers CW, Smith RJ, Van Camp G.

Author information:
(1)Department of Medical Genetics, University of Antwerp, Universiteitsplein 1, 
B-2610 Antwerp, Belgium.

Hereditary hearing impairment is an extremely heterogeneous trait, with more 
than 70 identified loci. Only two of these loci are associated with an auditory 
phenotype that predominantly affects the low frequencies (DFNA1 and DFNA6/14). 
In this study, we have completed mutation screening of the WFS1 gene in eight 
autosomal dominant families and twelve sporadic cases in which affected persons 
have low-frequency sensorineural hearing impairment (LFSNHI). Mutations in this 
gene are known to be responsible for Wolfram syndrome or DIDMOAD (diabetes 
insipidus, diabetes mellitus, optic atrophy, and deafness), which is an 
autosomal recessive trait. We have identified seven missense mutations and a 
single amino acid deletion affecting conserved amino acids in six families and 
one sporadic case, indicating that mutations in WFS1 are a major cause of 
inherited but not sporadic low-frequency hearing impairment. Among the ten WFS1 
mutations reported in LFSNHI, none is expected to lead to premature protein 
truncation, and nine cluster in the C-terminal protein domain. In contrast, 64% 
of the Wolfram syndrome mutations are inactivating. Our results indicate that 
only non-inactivating mutations in WFS1 are responsible for non-syndromic 
low-frequency hearing impairment.

DOI: 10.1007/s00439-002-0719-1
PMID: 12073007 [Indexed for MEDLINE]


340. Audiol Neurootol. 2016;21(6):347-355. doi: 10.1159/000453354. Epub 2017 Jan 10.

Comparison of Alternative Coupling Methods of the Vibrant Soundbridge Floating 
Mass Transducer.

Busch S(1), Lenarz T, Maier H.

Author information:
(1)Department of Otorhinolaryngology and Cluster of Excellence "Hearing4all," 
Hannover Medical School, Hannover, Germany.

The active middle ear implant Vibrant Soundbridge© provides a variety of 
coupling modalities of the floating mass transducer (FMT) to various structures 
of the ossicular chain and the round window. A retrospective analysis was 
performed on 125 subjects (n = 137 ears) (1) to compare the efficacy of the 
different FMT coupling modalities with increasing degree of hearing loss, (2) to 
compare the performance in speech outcome and the effective gain between the 
coupling types, and (3) to evaluate the risk of additional hearing loss of each 
coupling procedure. The patients were grouped according to their type of FMT 
coupling into incus vibroplasty (incus group, n = 59), round window vibroplasty 
with coupler (RWC group, n = 23), round window vibroplasty without coupler (RW 
group, n = 22), and oval window vibroplasty with coupler (OWC group, n = 33). 
For each coupling group, pre- and postoperative thresholds, the results of the 
Freiburg monosyllable test at 65 dB SPL, and the effective gain across 
frequencies (0.5-6 kHz) were evaluated. A logistic regression function was used 
to describe the relationship between word recognition scores (WRS, in % correct) 
and the mean bone conduction (BC) hearing loss. The surgical procedure had no 
clinically relevant effect on BC thresholds of patients in each coupling group. 
The BC pure tone average (PTA4) for 50% WRS predicted by the model function was 
similar for the incus (48.2 dB nHL), RW (47.8 dB nHL), and OWC (49.0 dB nHL) 
groups, but higher for the RWC group (67.9 dB nHL). However, the median WRS was 
80% or better with no significant differences in speech perception between 
coupling types (Kruskal-Wallis test, p = 0.229). The effective gain shows an 
advantage for the incus coupling between 0.5 and 2 kHz over the other coupling 
types. The performance of the FMT coupling modalities is equally good for 
patients with a mild-to-moderate hearing loss, but the efficacy of coupling 
types differs for patients with greater hearing loss (>48 dB BC HL).

© 2017 S. Karger AG, Basel.

DOI: 10.1159/000453354
PMID: 28068651 [Indexed for MEDLINE]


341. Mol Med Rep. 2020 Dec;22(6):5053-5068. doi: 10.3892/mmr.2020.11631. Epub 2020 
Oct 23.

Identifying the mechanisms underlying the protective effect of 
tetramethylpyrazine against cisplatin‑induced in vitro ototoxicity in HEI‑OC1 
auditory cells using gene expression profiling.

Guan G(1), He X(2), Chen J(2), Bin L(2), Tang X(2).

Author information:
(1)Department of Otolaryngology, The Second Hospital of Jilin University, 
Changchun, Jilin 130041, P.R. China.
(2)Department of Otolaryngology, The First Affiliated Hospital of Zhejiang 
Traditional Chinese Medical University, Hangzhou, Zhejiang 310006, P.R. China.

Sensorineural hearing loss is prevalent in patients receiving cisplatin therapy. 
Tetramethylpyrazine (Tet) and tanshinone IIA (Tan IIA) have protective roles 
against hearing impairment or ototoxicity. The present study aimed to 
investigate the molecular mechanisms underlying cisplatin‑induced ototoxicity 
and the protective effect of Tet and Tan IIA against it. House Ear 
Institute‑Organ of Corti 1 auditory cells were treated with titrating doses of 
Tan IIA, Tet, and cisplatin. In a cell viability assay, cisplatin, Tan IIA and 
Tet had IC50 values of 42.89 µM, 151.80 and 1.04x103 mg/l, respectively. Tan IIA 
augmented cisplatin‑induced cytotoxicity. However, Tet concentrations <75 mg/l 
attenuated cisplatin‑induced cytotoxicity and apoptosis. Moreover, RNA 
sequencing analysis was carried out on auditory cells treated for 30 h with 
30 µM cisplatin alone for 48 h or combined with 37.5 mg/l Tet for 30 h. 
Differentially expressed genes (DEGs) induced in these conditions were 
identified and examined using Gene Ontology and Kyoto Encyclopedia of Genes and 
Genomes pathway analysis. Cisplatin increased the expression of genes related to 
the p53 and FoxO pathways, such as Fas, p21/CDKN1A, and Bcl‑2 binding component 
3, but decreased the expression of insulin‑like growth factor 1 (IGF1), as well 
as genes in the histone (Hist)1 and Hist2 clusters. Treatment with Tet 
downregulated FOXO3 and Bcl‑2 binding component 3, and increased the expression 
of IGF1. Moreover, Tet upregulated genes associated with Wnt signaling, but not 
p53‑related genes. Thus, the otoprotective properties of Tet might be mediated 
by activation of Wnt and IGF1 signaling, and inhibition of FoxO signaling.

DOI: 10.3892/mmr.2020.11631
PMCID: PMC7646960
PMID: 33174043 [Indexed for MEDLINE]


342. J Speech Lang Hear Res. 2017 Aug 16;60(8):2346-2359. doi: 
10.1044/2017_JSLHR-H-16-0369.

An Exploration of the Associations Among Hearing Loss, Physical Health, and 
Visual Memory in Adults From West Central Alabama.

Hay-McCutcheon MJ(1), Hyams A(2), Yang X(3), Parton J(3), Panasiuk B(1), 
Ondocsin S(1), James MM(1), Scogin F(2).

Author information:
(1)Department of Communicative Disorders, University of Alabama, Tuscaloosa.
(2)Department of Psychology, University of Alabama, Tuscaloosa.
(3)Information Systems, Statistics, Management Science, University of Alabama, 
Tuscaloosa.

PURPOSE: The purpose of this preliminary study was to explore the associations 
among hearing loss, physical health, and visual memory in adults living in rural 
areas, urban clusters, and an urban city in west Central Alabama.
METHOD: Two hundred ninety-seven adults (182 women, 115 men) from rural areas, 
urban clusters, and an urban city of west Central Alabama completed a hearing 
assessment, a physical health questionnaire, a hearing handicap measure, and a 
visual memory test.
RESULTS: A greater number of adults with hearing loss lived in rural areas and 
urban clusters than in an urban area. In addition, poorer physical health was 
significantly associated with hearing loss. A greater number of individuals with 
poor physical health who lived in rural towns and urban clusters had hearing 
loss compared with the adults with other physical health issues who lived in an 
urban city. Poorer hearing sensitivity resulted in poorer outcomes on the 
Emotional and Social subscales of the Hearing Handicap Inventory for Adults. And 
last, visual memory, a working-memory task, was not associated with hearing loss 
but was associated with educational level.
CONCLUSIONS: The outcomes suggest that hearing loss is associated with poor 
physical and emotional health but not with visual-memory skills. A greater 
number of adults living in rural areas experienced hearing loss compared with 
adults living in an urban city, and consequently, further research will be 
necessary to confirm this relationship and to explore the reasons behind it. 
Also, further exploration of the relationship between cognition and hearing loss 
in adults living in rural and urban areas will be needed.

DOI: 10.1044/2017_JSLHR-H-16-0369
PMID: 28793136 [Indexed for MEDLINE]


343. Trends Hear. 2018 Jan-Dec;22:2331216518768954. doi: 10.1177/2331216518768954.

Objective Prediction of Hearing Aid Benefit Across Listener Groups Using Machine 
Learning: Speech Recognition Performance With Binaural Noise-Reduction 
Algorithms.

Schädler MR(1), Warzybok A(1), Kollmeier B(1).

Author information:
(1)1 Medizinische Physik and Cluster of Excellence "Hearing4all," Carl von 
Ossietzky Universität Oldenburg, Germany.

The simulation framework for auditory discrimination experiments (FADE) was 
adopted and validated to predict the individual speech-in-noise recognition 
performance of listeners with normal and impaired hearing with and without a 
given hearing-aid algorithm. FADE uses a simple automatic speech recognizer 
(ASR) to estimate the lowest achievable speech reception thresholds (SRTs) from 
simulated speech recognition experiments in an objective way, independent from 
any empirical reference data. Empirical data from the literature were used to 
evaluate the model in terms of predicted SRTs and benefits in SRT with the 
German matrix sentence recognition test when using eight single- and 
multichannel binaural noise-reduction algorithms. To allow individual 
predictions of SRTs in binaural conditions, the model was extended with a simple 
better ear approach and individualized by taking audiograms into account. In a 
realistic binaural cafeteria condition, FADE explained about 90% of the variance 
of the empirical SRTs for a group of normal-hearing listeners and predicted the 
corresponding benefits with a root-mean-square prediction error of 0.6 dB. This 
highlights the potential of the approach for the objective assessment of 
benefits in SRT without prior knowledge about the empirical data. The 
predictions for the group of listeners with impaired hearing explained 75% of 
the empirical variance, while the individual predictions explained less than 
25%. Possibly, additional individual factors should be considered for more 
accurate predictions with impaired hearing. A competing talker condition clearly 
showed one limitation of current ASR technology, as the empirical performance 
with SRTs lower than -20 dB could not be predicted.

DOI: 10.1177/2331216518768954
PMCID: PMC5949929
PMID: 29692200 [Indexed for MEDLINE]


344. Trends Hear. 2018 Jan-Dec;22:2331216518770964. doi: 10.1177/2331216518770964.

Use of a Deep Recurrent Neural Network to Reduce Wind Noise: Effects on Judged 
Speech Intelligibility and Sound Quality.

Keshavarzi M(1), Goehring T(2), Zakis J(3), Turner RE(4), Moore BCJ(1).

Author information:
(1)1 Department of Psychology, University of Cambridge, Cambridge, UK.
(2)2 MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, 
UK.
(3)3 Blamey and Saunders Hearing Pty Ltd, East Melbourne, Victoria, Australia.
(4)4 Department of Engineering, University of Cambridge, Cambridge, UK.

Despite great advances in hearing-aid technology, users still experience 
problems with noise in windy environments. The potential benefits of using a 
deep recurrent neural network (RNN) for reducing wind noise were assessed. The 
RNN was trained using recordings of the output of the two microphones of a 
behind-the-ear hearing aid in response to male and female speech at various 
azimuths in the presence of noise produced by wind from various azimuths with a 
velocity of 3 m/s, using the "clean" speech as a reference. A paired-comparison 
procedure was used to compare all possible combinations of three conditions for 
subjective intelligibility and for sound quality or comfort. The conditions were 
unprocessed noisy speech, noisy speech processed using the RNN, and noisy speech 
that was high-pass filtered (which also reduced wind noise). Eighteen native 
English-speaking participants were tested, nine with normal hearing and nine 
with mild-to-moderate hearing impairment. Frequency-dependent linear 
amplification was provided for the latter. Processing using the RNN was 
significantly preferred over no processing by both subject groups for both 
subjective intelligibility and sound quality, although the magnitude of the 
preferences was small. High-pass filtering (HPF) was not significantly preferred 
over no processing. Although RNN was significantly preferred over HPF only for 
sound quality for the hearing-impaired participants, for the results as a whole, 
there was a preference for RNN over HPF. Overall, the results suggest that 
reduction of wind noise using an RNN is possible and might have beneficial 
effects when used in hearing aids.

DOI: 10.1177/2331216518770964
PMCID: PMC5949931
PMID: 29708061 [Indexed for MEDLINE]


345. J Comp Neurol. 1993 Mar 15;329(3):402-11. doi: 10.1002/cne.903290310.

Plasticity of auditory cortex associated with sensorineural hearing loss in 
adult C57BL/6J mice.

Willott JF(1), Aitkin LM, McFadden SL.

Author information:
(1)Department of Psychology, Northern Illinois University, DeKalb 60115.

The representation of frequency was mapped in the primary auditory cortex (AI) 
of C57BL/6J (C57) mice during young adulthood (1.5-2 months) when hearing is 
optimal, and at 3, 6, and 12 months of age, a period during which progressive, 
high frequency, sensorineural hearing loss occurs in this strain. Maps were also 
obtained from CBA/CaJ mice which retain good hearing as they age. In AI of young 
adult C57 mice and CBA mice, characteristic frequencies (CFs) of multiple-unit 
clusters were easily identified with extracellular recordings, and a general 
tonotopic organization was observed from dorsal (high frequency) to ventral and 
caudal (low frequency). In individual cases there appeared to be deviations from 
the above tonotopic organization, despite the fact that inbred mice are 
genetically invariant. As progressive loss of high frequency sensitivity ensued 
peripherally, a substantially increased representation of middle frequencies was 
observed in AI. There was no apparent change in the surface area of the auditory 
cortex despite the elimination of high frequencies, and virtually the entire 
auditory cortex became devoted to the middle frequencies (especially 10-13 kHz) 
for which sensitivity remained high. Similar age-related changes were not 
observed in normal-hearing CBA mice. These findings indicate that plasticity in 
the representation of frequency in AI is associated with high frequency hearing 
loss in C57 mice.

DOI: 10.1002/cne.903290310
PMID: 8459051 [Indexed for MEDLINE]


346. J Soc Bras Fonoaudiol. 2012;24(4):335-41.

Determinants of communication skills development in children with hearing 
impairment.

[Article in English, Portuguese]

Novaes BC(1), Versolatto-Cavanaugh MC, Figueiredo Rde S, Mendes Bde C.

Author information:
(1)Graduate Program in Speech-Language Pathology and Audiology, Pontifícia 
Universidade Católica de São Paulo, São Paulo, SP, Brazil. 
beatriznovaes@pucsp.br

PURPOSE: To establish relationships between age at onset of individual hearing 
aid use, functional hearing, communication skills, family involvement and family 
expectations regarding language development of children diagnosed with hearing 
loss during the first three years of life.
METHODS: Thirty-five babies diagnosed with moderate to severe hearing loss who 
were receiving treatment at the Children's Hearing Center/Derdic (CeAC) were 
evaluated during a period of 24 months. Assessments were carried out every six 
months and included: VRA--Visual reinforcement audiometry (with and without 
amplification); IT-MAIS; MUSS; and satisfaction of family regarding child 
development.
RESULTS: Cluster analysis was performed among the subjects. Consistent use of 
hearing aids was the only variable that exhibited a strong relationship with 
hearing and language skills. Children whose parents were not satisfied exhibited 
severe hearing loss and limited auditory capacity even with the use of hearing 
aid, and, consequently, poor auditory skills and speech production.
CONCLUSION: Datalogging monitoring can guide the knowledge of speech-language 
pathologists and audiologists and it can also be used on strategic planning. 
Family involvement, quality of parental participation in the intervention 
program as well as expectations about the future are also important aspects to 
consider as these can aid therapists and researchers on the assessment of deaf 
babies intervention effectiveness.

PMID: 23306683 [Indexed for MEDLINE]


347. Trends Hear. 2016 Sep 7;20:2331216516655795. doi: 10.1177/2331216516655795.

Sentence Recognition Prediction for Hearing-impaired Listeners in Stationary and 
Fluctuation Noise With FADE: Empowering the Attenuation and Distortion Concept 
by Plomp With a Quantitative Processing Model.

Kollmeier B(1), Schädler MR(2), Warzybok A(2), Meyer BT(2), Brand T(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, Germany birger.kollmeier@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, Germany.

To characterize the individual patient's hearing impairment as obtained with the 
matrix sentence recognition test, a simulation Framework for Auditory 
Discrimination Experiments (FADE) is extended here using the Attenuation and 
Distortion (A+D) approach by Plomp as a blueprint for setting the individual 
processing parameters. FADE has been shown to predict the outcome of both speech 
recognition tests and psychoacoustic experiments based on simulations using an 
automatic speech recognition system requiring only few assumptions. It builds on 
the closed-set matrix sentence recognition test which is advantageous for 
testing individual speech recognition in a way comparable across languages. 
Individual predictions of speech recognition thresholds in stationary and in 
fluctuating noise were derived using the audiogram and an estimate of the 
internal level uncertainty for modeling the individual Plomp curves fitted to 
the data with the Attenuation (A-) and Distortion (D-) parameters of the Plomp 
approach. The "typical" audiogram shapes from Bisgaard et al with or without a 
"typical" level uncertainty and the individual data were used for individual 
predictions. As a result, the individualization of the level uncertainty was 
found to be more important than the exact shape of the individual audiogram to 
accurately model the outcome of the German Matrix test in stationary or 
fluctuating noise for listeners with hearing impairment. The prediction accuracy 
of the individualized approach also outperforms the (modified) Speech 
Intelligibility Index approach which is based on the individual threshold data 
only.

© The Author(s) 2016.

DOI: 10.1177/2331216516655795
PMCID: PMC5017573
PMID: 27604782 [Indexed for MEDLINE]


348. J Speech Hear Res. 1994 Jun;37(3):510-21. doi: 10.1044/jshr.3703.510.

Physiological assessment of speech and voice production of adults with hearing 
loss.

Higgins MB(1), Carney AE, Schulte L.

Author information:
(1)Boys Town National Research Hospital, Omaha, NE.

The purpose of this investigation was to study the impact of hearing loss on 
phonatory, velopharyngeal, and articulatory functioning using a comprehensive 
physiological approach. Electroglottograph (EGG), nasal/oral air flow, and 
intraoral air pressure signals were recorded simultaneously from adults with 
impaired and normal hearing as they produced syllables and words of varying 
physiological difficulty. The individuals with moderate-to-profound hearing loss 
had good to excellent oral communication skills. Intraoral pressure, nasal air 
flow, durations of lip, velum, and vocal fold articulations, estimated 
subglottal pressure, mean phonatory air flow, fundamental frequency, and EGG 
abduction quotient were compared between the two subject groups. Data from the 
subjects with hearing loss also were compared across aided and unaided 
conditions to investigate the influence of auditory feedback on speech motor 
control. The speakers with hearing loss had significantly higher intraoral 
pressures, subglottal pressures, laryngeal resistances, and fundamental 
frequencies than those with normal hearing. There was notable between-subject 
variability. All of the individuals with profound hearing loss had at least one 
speech/voice physiology measure that fell outside of the normal range, and most 
of the subjects demonstrated unique clusters of abnormal behaviors. Abnormal 
behaviors were more evident in the phonatory than articulatory or velopharyngeal 
systems and were generally consistent with vocal fold hyperconstriction. There 
was evidence from individual data that vocal fold posturing influenced 
articulatory timing. The results did not support the idea that the speech 
production skills of adults with moderate-to-profound hearing loss who are good 
oral communicators deteriorate when there are increased motoric demands on the 
velopharyngeal and phonatory mechanism. Although no significant differences were 
found between the aided and unaided conditions, 7 of 10 subjects showed the same 
direction of change for subglottal pressure, intraoral pressure, nasal air flow, 
and the duration of lip and vocal fold articulations. We conclude that 
physiological assessments provide important information about the speech/voice 
production abilities of individuals with moderate-to-profound hearing loss and 
are a valuable addition to standard assessment batteries.

DOI: 10.1044/jshr.3703.510
PMID: 8084183 [Indexed for MEDLINE]


349. Eur J Neurosci. 2020 Mar;51(5):1265-1278. doi: 10.1111/ejn.13846. Epub 2018 Feb 
12.

A two-path model of auditory modulation detection using temporal fine structure 
and envelope cues.

Ewert SD(1), Paraouty N(2), Lorenzi C(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4All, Universität 
Oldenburg, 26111, Oldenburg, Germany.
(2)Laboratoire des systèmes perceptifs, Département d'études cognitives, École 
normale supérieure, CNRS, PSL Research University, Paris, France.

A model using temporal-envelope cues was previously developed to explain 
perceptual interference effects between amplitude modulation and frequency 
modulation (FM). As that model could not accurately predict FM sensitivity and 
the interference effects, temporal fine structure (TFS) cues were added to the 
model. Thus, following the initial stage of the model consisting of a linear 
filter bank simulating cochlear filtering, processing was split into an 
'envelope path' based on envelope power cues and a 'TFS path' based on a measure 
of the distribution of time intervals between successive zero-crossings. This 
yielded independent detectability indices for envelope and TFS cues, which were 
optimally combined to produce a single decision statistic. Independent internal 
noises in the envelope and TFS paths were adjusted to match the data. 
Simulations indicate that TFS cues are required to account for FM data for young 
normal-hearing listeners and that TFS processing is impaired for both older 
normal-hearing and hearing-impaired listeners. The role of TFS was further 
assessed by relating the monaural FM sensitivity to measures of interaural phase 
difference, commonly assumed to rely on binaural TFS sensitivity. The model 
demonstrates that binaural TFS sensitivity is considerably lower than monaural 
TFS sensitivity. Similar to FM thresholds, interaural phase difference 
sensitivity declined with age and hearing loss, although higher degradations 
were observed in binaural temporal processing compared to monaural processing. 
Overall, this model provides a novel tool to explore the mechanisms involved in 
FM processing in the normal auditory system and the degradations in FM 
sensitivity with ageing and hearing loss.

© 2018 Federation of European Neuroscience Societies and John Wiley & Sons Ltd.

DOI: 10.1111/ejn.13846
PMID: 29368797 [Indexed for MEDLINE]


350. PLoS One. 2015 Mar 25;10(3):e0120148. doi: 10.1371/journal.pone.0120148. 
eCollection 2015.

Design and evaluation of a cochlear implant strategy based on a "Phantom" 
channel.

Nogueira W(1), Litvak LM(2), Saoji AA(2), Büchner A(1).

Author information:
(1)Department of Otolaryngology, Medical University Hannover, Cluster of 
Excellence "Hearing4all", Hannover, Germany.
(2)Research and Technology Group, Advanced Bionics LLC, Valencia CA, USA.

Unbalanced bipolar stimulation, delivered using charge balanced pulses, was used 
to produce "Phantom stimulation", stimulation beyond the most apical contact of 
a cochlear implant's electrode array. The Phantom channel was allocated audio 
frequencies below 300 Hz in a speech coding strategy, conveying energy some two 
octaves lower than the clinical strategy and hence delivering the fundamental 
frequency of speech and of many musical tones. A group of 12 Advanced Bionics 
cochlear implant recipients took part in a chronic study investigating the 
fitting of the Phantom strategy and speech and music perception when using 
Phantom. The evaluation of speech in noise was performed immediately after 
fitting Phantom for the first time (Session 1) and after one month of take-home 
experience (Session 2). A repeated measures of analysis of variance (ANOVA) 
within factors strategy (Clinical, Phantom) and interaction time (Session 1, 
Session 2) revealed a significant effect for the interaction time and strategy. 
Phantom obtained a significant improvement in speech intelligibility after one 
month of use. Furthermore, a trend towards a better performance with Phantom 
(48%) with respect to F120 (37%) after 1 month of use failed to reach 
significance after type 1 error correction. Questionnaire results show a 
preference for Phantom when listening to music, likely driven by an improved 
balance between high and low frequencies.

DOI: 10.1371/journal.pone.0120148
PMCID: PMC4373925
PMID: 25806818 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: We would like to mention 
the following conflicts of interest: Leonid M. Litvak and Aniket A. Saoji are 
employees of the cochlear implant manufacturer Advanced Bionics LLC. Waldo 
Nogueira is a former employee of the same company. This does not alter the 
authors’ adherence to PLOS ONE policies on sharing data and materials.


351. Int J Audiol. 2018 Jun;57(sup3):S55-S61. doi: 10.1080/14992027.2017.1279758. 
Epub 2017 Jan 23.

Comparison of single-microphone noise reduction schemes: can hearing impaired 
listeners tell the difference?

Huber R(1), Bisitz T(1), Gerkmann T(2), Kiessling J(3), Meister H(4), Kollmeier 
B(2).

Author information:
(1)a HörTech gGmbH and Cluster of Excellence Hearing4All , Oldenburg , Germany.
(2)b Department of Medical Physics and Acoustics , University of Oldenburg, and 
Cluster of Excellence Hearing4All , Oldenburg , Germany.
(3)c Funktionsbereich Audiologie , Justus-Liebig University Giessen , Giessen , 
Germany , and.
(4)d Jean Uhrmacher Institute for Clinical ENT-Research , University of Cologne 
, Cologne , Germany.

OBJECTIVE: The perceived qualities of nine different single-microphone noise 
reduction (SMNR) algorithms were to be evaluated and compared in subjective 
listening tests with normal hearing and hearing impaired (HI) listeners.
DESIGN: Speech samples added with traffic noise or with party noise were 
processed by the SMNR algorithms. Subjects rated the amount of speech 
distortions, intrusiveness of background noise, listening effort and overall 
quality, using a simplified MUSHRA (ITU-R, 2003 ) assessment method.
STUDY SAMPLE: 18 normal hearing and 18 moderately HI subjects participated in 
the study.
RESULTS: Significant differences between the rating behaviours of the two 
subject groups were observed: While normal hearing subjects clearly 
differentiated between different SMNR algorithms, HI subjects rated all 
processed signals very similarly. Moreover, HI subjects rated speech distortions 
of the unprocessed, noisier signals as being more severe than the distortions of 
the processed signals, in contrast to normal hearing subjects.
CONCLUSIONS: It seems harder for HI listeners to distinguish between additive 
noise and speech distortions or/and they might have a different understanding of 
the term "speech distortion" than normal hearing listeners have. The findings 
confirm that the evaluation of SMNR schemes for hearing aids should always 
involve HI listeners.

DOI: 10.1080/14992027.2017.1279758
PMID: 28112001 [Indexed for MEDLINE]


352. Audiol Neurootol. 2021;26(5):361-367. doi: 10.1159/000513509. Epub 2021 Apr 26.

The Use of a Robot to Insert an Electrode Array of Cochlear Implants in the 
Cochlea: A Feasibility Study and Preliminary Results.

Barriat S(1), Peigneux N(1), Duran U(2), Camby S(1), Lefebvre PP(1).

Author information:
(1)Department of Otorhinolaryngology, Liège University, CHU de Liège, Liège, 
Belgium.
(2)Department of Radiology, Liège University, CHU de Liège, Liège, Belgium.

INTRODUCTION: Cochlear implants (CIs) are commonly used for the rehabilitation 
of profound bilateral hearing loss. However, patients with substantial residual 
acoustic hearing are potential CI candidates. Because of both improvements in 
technology and advancements in surgical techniques, it may be possible to 
preserve hearing to some extent. For more than a decade, it has been suggested 
that robots are used to perform middle ear surgery. We evaluated the use of the 
RobOtol® otologic robot specifically to insert CI electrodes into the inner ear.
METHODS: CI surgery with the conventional approach was performed under general 
anesthesia. The MED-El Flex 24-electrode array was inserted using RobOtol®. 
Video recordings were used to calculate the speed of insertion. The positions of 
the electrodes were evaluated using a cone beam CT. All subjects underwent 
pure-tone audiometry tests before and after surgery, and the pure-tone average 
(PTA) was calculated from 250 to 4,000 Hz.
RESULTS: The robot inserted implants in 5 patients, and complete insertion of 
the electrode array was achieved. The speed of insertion of the electrode array 
was 0.88 ± 0.12 mm/s. The mean loss of the PTA for 5 frequencies (250, 500, 
1,000, 2,000, and 4,000 Hz) was 13.60 ± 7.70 dB. Only 1 patient showed a loss of 
the PTA by >20 dB. For these 5 patients, the cone beam CT findings showed that 
all the electrode arrays were in the tympanic ramp and had a grade of 0. The 
results were compared with those obtained from a cohort of 17 patients who 
underwent manual implantation of a MED-El Flex 24-electrode array.
CONCLUSION: To minimize disturbance to the cochlea while atraumatic electrode 
arrays are inserted, electrodes can be inserted at a constant, slow speed in the 
inner ear with the assistance of the RobOtol® robot in a normal clinical 
surgical setting.

© 2021 S. Karger AG, Basel.

DOI: 10.1159/000513509
PMID: 33902040 [Indexed for MEDLINE]


353. J Neurophysiol. 2000 Apr;83(4):2145-62. doi: 10.1152/jn.2000.83.4.2145.

Electrical cochlear stimulation in the deaf cat: comparisons between 
psychophysical and central auditory neuronal thresholds.

Beitel RE(1), Snyder RL, Schreiner CE, Raggio MW, Leake PA.

Author information:
(1)Department of Otolaryngology, University of California, San Francisco, 
California 94143-0732, USA.

Cochlear prostheses for electrical stimulation of the auditory nerve 
("electrical hearing") can provide auditory capacity for profoundly deaf adults 
and children, including in many cases a restored ability to perceive speech 
without visual cues. A fundamental challenge in auditory neuroscience is to 
understand the neural and perceptual mechanisms that make rehabilitation of 
hearing possible in these deaf humans. We have developed a feline behavioral 
model that allows us to study behavioral and physiological variables in the same 
deaf animals. Cats deafened by injection of ototoxic antibiotics were implanted 
with either a monopolar round window electrode or a multichannel scala tympani 
electrode array. To evaluate the effects of perceptually significant electrical 
stimulation of the auditory nerve on the central auditory system, an animal was 
trained to avoid a mild electrocutaneous shock when biphasic current pulses (0.2 
ms/phase) were delivered to its implanted cochlea. Psychophysical detection 
thresholds and electrical auditory brain stem response (EABR) thresholds were 
estimated in each cat. At the conclusion of behavioral testing, acute 
physiological experiments were conducted, and threshold responses were recorded 
for single neurons and multineuronal clusters in the central nucleus of the 
inferior colliculus (ICC) and the primary auditory cortex (A1). Behavioral and 
neurophysiological thresholds were evaluated with reference to cochlear 
histopathology in the same deaf cats. The results of the present study include: 
1) in the cats implanted with a scala tympani electrode array, the lowest ICC 
and A1 neural thresholds were virtually identical to the behavioral thresholds 
for intracochlear bipolar stimulation; 2) behavioral thresholds were lower than 
ICC and A1 neural thresholds in each of the cats implanted with a monopolar 
round window electrode; 3) EABR thresholds were higher than behavioral 
thresholds in all of the cats (mean difference = 6.5 dB); and 4) the cumulative 
number of action potentials for a sample of ICC neurons increased monotonically 
as a function of the amplitude and the number of stimulating biphasic pulses. 
This physiological result suggests that the output from the ICC may be 
integrated spatially across neurons and temporally integrated across pulses when 
the auditory nerve array is stimulated with a train of biphasic current pulses. 
Because behavioral thresholds were lower and reaction times were faster at a 
pulse rate of 30 pps compared with a pulse rate of 2 pps, spatial-temporal 
integration in the central auditory system was presumably reflected in 
psychophysical performance.

DOI: 10.1152/jn.2000.83.4.2145
PMID: 10758124 [Indexed for MEDLINE]


354. CMAJ. 2003 May 27;168(11):1421-3.

Enteroviruses and sudden deafness.

Schattner A(1), Halperin D, Wolf D, Zimhony O.

Author information:
(1)Hebrew University and Hadassah Medical School, Jerusalem, Israel. 
amiMD@clalit.org.il

A young, healthy man presented with sudden severe sensorineural hearing loss and 
tinnitus. The results of the workup and neuroimaging were normal, as were the 
auditory brain stem responses. Methylprednisolone pulse therapy was associated 
with significant hearing improvement within 10 days. A history of a short 
self-limited febrile illness preceding admission (with headache, photophobia, 
myalgia and fatigue), a raised serum C-reactive protein level and transient 
leukopenia suggested an infectious cause. Lumbar puncture revealed a mononuclear 
pleocytosis of the cerebrospinal fluid, with negative cultures but positive 
polymerase chain reaction test results for enterovirus, which was later cultured 
from the patient's stool. The patient's wife and baby had had a similar febrile 
illness without hearing loss 10 days earlier, and an outbreak of enterovirus 
meningitis was identified in the area, which was associated with familial 
clustering and echovirus serotype 4 infection. The varied causes of sudden 
sensorineural hearing loss, which should include enterovirus, are reviewed here.

PMCID: PMC155958
PMID: 12771071 [Indexed for MEDLINE]


355. Int J Audiol. 2019 Apr;58(4):231-245. doi: 10.1080/14992027.2018.1554912.

Common Audiological Functional Parameters (CAFPAs): statistical and compact 
representation of rehabilitative audiological classification based on expert 
knowledge.

Buhl M(1)(2), Warzybok A(1)(2), Schädler MR(1)(2), Lenarz T(2)(3), Majdani 
O(2)(3)(4), Kollmeier B(1)(2)(5)(6).

Author information:
(1)a Medizinische Physik , Universität Oldenburg , Oldenburg , Germany.
(2)b Cluster of Excellence Hearing4all, Universität Oldenburg , Oldenburg , 
Germany.
(3)c Clinic and Policlinic for Otolaryngology , Hanover Medical School , 
Hannover , Germany.
(4)d Clinic for Otolaryngology , Städt. Klinikum Wolfsburg , Wolfsburg , 
Germany.
(5)e HörTech gGmbH , Oldenburg , Germany.
(6)f Hearing Speech and Audio Technology , Fraunhofer IDMT , Oldenburg , 
Germany.

OBJECTIVE: As a step towards objectifying audiological rehabilitation and 
providing comparability between different test batteries and clinics, the Common 
Audiological Functional Parameters (CAFPAs) were introduced as a common and 
abstract representation of audiological knowledge obtained from diagnostic 
tests.
DESIGN: Relationships between CAFPAs as an intermediate representation between 
diagnostic tests and audiological findings, diagnoses and treatment 
recommendations (summarised as "diagnostic cases") were established by means of 
an expert survey. Expert knowledge was collected for 14 given categories 
covering different diagnostic cases. For each case, the experts were asked to 
indicate expected ranges of diagnostic test outcomes, as well as traffic 
light-encoded CAFPAs.
STUDY SAMPLE: Eleven German experts in the field of audiological rehabilitation 
from Hanover and Oldenburg participated in the survey.
RESULTS: Audiological findings or treatment recommendations could be 
distinguished by a statistical model derived from the experts' answers for 
CAFPAs as well as audiological tests.
CONCLUSIONS: The CAFPAs serve as an abstract, comprehensive representation of 
audiological knowledge. If more detailed information on certain functional 
aspects of the auditory system is required, the CAFPAs indicate which 
information is missing. The statistical graphical representations for CAFPAs and 
audiological tests are suitable for audiological teaching material; they are 
universally applicable for real clinical databases.

DOI: 10.1080/14992027.2018.1554912
PMID: 30900518 [Indexed for MEDLINE]


356. J Acoust Soc Am. 2021 Nov;150(5):3976. doi: 10.1121/10.0007134.

A causal and talker-independent speaker separation/dereverberation deep learning 
algorithm: Cost associated with conversion to real-time capable operation.

Healy EW(1), Taherian H(2), Johnson EM(1), Wang D(2).

Author information:
(1)Department of Speech and Hearing Science, The Ohio State University, 
Columbus, Ohio 43210, USA.
(2)Department of Computer Science and Engineering, The Ohio State University, 
Columbus, Ohio 43210, USA.

The fundamental requirement for real-time operation of a speech-processing 
algorithm is causality-that it operate without utilizing future time frames. In 
the present study, the performance of a fully causal deep computational auditory 
scene analysis algorithm was assessed. Target sentences were isolated from 
complex interference consisting of an interfering talker and concurrent room 
reverberation. The talker- and corpus/channel-independent model used Dense-UNet 
and temporal convolutional networks and estimated both magnitude and phase of 
the target speech. It was found that mean algorithm benefit was significant in 
every condition. Mean benefit for hearing-impaired (HI) listeners across all 
conditions was 46.4 percentage points. The cost of converting the algorithm to 
causal processing was also assessed by comparing to a prior non-causal version. 
Intelligibility decrements for HI and normal-hearing listeners from non-causal 
to causal processing were present in most but not all conditions, and these 
decrements were statistically significant in half of the conditions tested-those 
representing the greater levels of complex interference. Although a cost 
associated with causal processing was present in most conditions, it may be 
considered modest relative to the overall level of benefit.

DOI: 10.1121/10.0007134
PMCID: PMC8612765
PMID: 34852625 [Indexed for MEDLINE]


357. Hear Res. 2022 Dec;426:108609. doi: 10.1016/j.heares.2022.108609. Epub 2022 Sep 
20.

How much individualization is required to predict the individual effect of 
suprathreshold processing deficits? Assessing Plomp's distortion component with 
psychoacoustic detection thresholds and FADE.

Hülsmeier D(1), Kollmeier B(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität, 
Oldenburg, 26111, Oldenburg, Germany.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, CvO Universität, 
Oldenburg, 26111, Oldenburg, Germany. Electronic address: 
birger.kollmeier@uol.de.

Plomp introduced an empirical separation of the increased speech recognition 
thresholds (SRT) in listeners with a sensorineural hearing loss into an 
Attenuation (A) component (which can be compensated by amplification) and a 
non-compensable Distortion (D) component. Previous own research backed up this 
notion by speech recognition models that derive their SRT prediction from the 
individual audiogram with or without a psychoacoustic measure of suprathreshold 
processing deficits. To determine the precision in separating the A and D 
component for the individual listener with various individual measures and 
individualized models, SRTs with 40 listeners with a variation in hearing 
impairment were obtained in quiet, stationary noise, and fluctuating noise (ICRA 
5-250 and babble). Both the clinical audiogram and an adaptive, precise sweep 
audiogram were obtained as well as tone-in-noise detection thresholds at four 
frequencies to characterize the individual hearing impairment. For predicting 
the SRT, the FADE-model (which is based on machine learning) was used with 
either of the two audiogram procedures and optionally the individual 
tone-in-noise detection thresholds. The results indicate that the precisely 
measured swept tone audiogram allows for a more precise prediction of the 
individual SRT in comparison to the clinical audiogram (RMS error of 4.3 dB vs. 
6.4 dB, respectively). While an estimation from the precise audiogram and FADE 
performed equally well in predicting the individual A and D component, the 
further refinement of including the tone-in-noise detection threshold with FADE 
led to a slight improvement of prediction accuracy (RMS error of 3.3 dB, 4.6 dB 
and 1.4 dB, for SRT, A and D component, respectively). Hence, applying FADE is 
advantageous for scientific purposes where a consistent modeling of different 
psychoacoustical effects in the same listener with a minimum amount of 
assumptions is desirable. For clinical purposes, however, a precisely measured 
audiogram and an estimation of the expected D component using a linear 
regression appears to be a satisfactory first step towards precision audiology.

Copyright © 2022. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2022.108609
PMID: 36209657 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of conflicting interests The Authors 
declare that there is no conflict of interest.


358. Afr J Med Med Sci. 2016 May;45(1):51-60.

Is there any relationship between hearing threshold levels and CD4 cell count of 
human immunodeficiency virus infected adults?

Fasunla AJ, Ijitola JO, Akpa OM, Nwaorgu OGB, Taiwo B, Olaleye DO, Murphy RL, 
Adewole IF, Akinyinka OO.

Background The role of viral load level and/or CD4 (Cluster of differentiation 
4) cell count in the aetiopathogenesis of hearing loss in HIV infection is 
unclear. Therefore, we investigated the relationship between CD4 cell counts, 
viral load and hearing threshold of HIV (Human immunodeficiency virus) infected 
adults.
METHODS: This cohort audiometric study involved consecutive HIV-infected and 
HIV-uninfected adults as controls. Clinical data relating to hearing loss, HIV 
status, and highly -active antiretroviral therapy (HAART) were obtained. 
Audiornetric evaluation was performed. The most recent CD4 cell counts and RNA 
viral load-of HIV-infected participants were obtained from clinic records.
RESULTS: There were 299(66.7%) HIV-infected adults and 149(33.3%) controls with 
mean age of 39.64± 12.45 years and 39.60±12.45 years respectively (p=0.98). In 
both groups, there were more participants with left hearing loss. Mild to 
profound hearing loss was found in 65.9% HIV- infected participants and 53.7% 
controls. Majority (86.3%) of the HIV-infected participants were on HAART. The 
mean CD4 cell count was 654.58±289.15 in 41 HIV-infected participants not on 
HAART and 523.95±300.17 in 258 participants on HAART (p=0.01). Majority,- 197 
(62%) HIV- infected participants with hearing loss had CD4 cell count ≤200 
cells/mm3. Higher viral load significantly correlated with low CD4 cell counts 
(p<0.0 1; r=0. 18) and low CD4 cell count significantly correlated with high 
hearing threshold (p<O.01; r=0. 17).
CONCLUSION: There was a trend towards more hearing loss among the HIV-infected 
adults. The higher hearing threshold in those with low CD4 cell counts of <200 
cells/mm3 suggests possible relationship between hearing status and severity of 
HIV disease.

PMID: 28686827 [Indexed for MEDLINE]


359. Trends Hear. 2018 Jan-Dec;22:2331216518805690. doi: 10.1177/2331216518805690.

Potential Consequences of Spectral and Binaural Loudness Summation for Bilateral 
Hearing Aid Fitting.

van Beurden M(1)(2), Boymans M(1)(2), van Geleuken M(1), Oetting D(3)(4), 
Kollmeier B(5), Dreschler WA(1).

Author information:
(1)1 Department of Clinical and Experimental Audiology, Amsterdam UMC, 
Amsterdam, the Netherlands.
(2)2 Libra Rehabilitation and Audiology, Eindhoven, the Netherlands.
(3)3 HörTech gGmbH, Oldenburg, Germany.
(4)4 Cluster of Excellence Hearing4all, Oldenburg, Germany.
(5)5 Medizinische Physik, Universität Oldenburg, Oldenburg, Germany.

Aversiveness of loud sounds is a frequent complaint by hearing aid users, 
especially when fitted bilaterally. This study investigates whether loudness 
summation can be held responsible for this finding. Two aspects of loudness 
summation should be taken into account: spectral loudness summation for 
broadband signals and binaural loudness summation for signals that are presented 
binaurally. In this study, the effect of different symmetrical hearing losses 
was studied. Measurements were obtained with the widely used technique of 
Adaptive Categorical Loudness Scaling. For large bandwidths, spectral loudness 
summation for hearing-impaired listeners was found to be greater than that for 
normal-hearing listeners, both for monaurally and binaurally presented signals. 
For binaural loudness summation, the effect of hearing loss was not significant. 
In all cases, individual differences were substantial.

DOI: 10.1177/2331216518805690
PMCID: PMC6201175
PMID: 30353784 [Indexed for MEDLINE]


360. Hear Res. 2021 Feb;400:108132. doi: 10.1016/j.heares.2020.108132. Epub 2020 Dec 
1.

Enhancing the sensitivity of the envelope-following response for cochlear 
synaptopathy screening in humans: The role of stimulus envelope.

Vasilkov V(1), Garrett M(2), Mauermann M(2), Verhulst S(3).

Author information:
(1)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Technologiepark 126, Zwijnaarde 9052, Belgium.
(2)Medizinische Physik and Cluster of Excellence "Hearing4all", Department of 
Medical Physics and Acoustics, Carl von Ossietzky University of Oldenburg, 
Carl-von-Ossietzky-Straße 9-11, Oldenburg, 26129, Germany.
(3)Hearing Technology @ WAVES, Department of Information Technology, Ghent 
University, Technologiepark 126, Zwijnaarde 9052, Belgium. Electronic address: 
s.verhulst@ugent.be.

Auditory de-afferentation, a permanent reduction in the number of 
inner-hair-cells and auditory-nerve synapses due to cochlear damage or 
synaptopathy, can reliably be quantified using temporal bone histology and 
immunostaining. However, there is an urgent need for non-invasive markers of 
synaptopathy to study its perceptual consequences in live humans and to develop 
effective therapeutic interventions. While animal studies have identified 
candidate auditory-evoked-potential (AEP) markers for synaptopathy, their 
interpretation in humans has suffered from translational issues related to 
neural generator differences, unknown hearing-damage histopathologies or lack of 
measurement sensitivity. To render AEP-based markers of synaptopathy more 
sensitive and differential to the synaptopathy aspect of sensorineural hearing 
loss, we followed a combined computational and experimental approach. Starting 
from the known characteristics of auditory-nerve physiology, we optimized the 
stimulus envelope to stimulate the available auditory-nerve population optimally 
and synchronously to generate strong envelope-following-responses (EFRs). We 
further used model simulations to explore which stimuli evoked a response that 
was sensitive to synaptopathy, while being maximally insensitive to possible 
co-existing outer-hair-cell pathologies. We compared the model-predicted trends 
to AEPs recorded in younger and older listeners (N=44, 24f) who had normal or 
impaired audiograms with suspected age-related synaptopathy in the older cohort. 
We conclude that optimal stimulation paradigms for EFR-based quantification of 
synaptopathy should have sharply rising envelope shapes, a minimal plateau 
duration of 1.7-2.1 ms for a 120-Hz modulation rate, and inter-peak intervals 
which contain near-zero amplitudes. From our recordings, the optimal EFR-evoking 
stimulus had a rectangular envelope shape with a 25% duty cycle and a 95% 
modulation depth. Older listeners with normal or impaired audiometric thresholds 
showed significantly reduced EFRs, which were consistent with how (age-induced) 
synaptopathy affected these responses in the model.

Copyright © 2020. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2020.108132
PMID: 33333426 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest Ghent 
University filed a patent application (PCTEP2020053192) which covers some of the 
ideas presented in this paper. Sarah Verhulst and Viacheslav Vasilkov are 
inventors.


361. Int J Audiol. 2012 Feb;51 Suppl 1(Suppl 1):S51-62. doi: 
10.3109/14992027.2011.635713.

Multivariate DPOAE metrics for identifying changes in hearing: perspectives from 
ototoxicity monitoring.

Konrad-Martin D(1), Reavis KM, McMillan GP, Dille MF.

Author information:
(1)VA RR&D National Center for Rehabilitative Auditory Research (NCRAR), 
Portland VA Medical Center, Portland, Oregon 97239, USA. dawn.martin@va.gov

Distortion-product otoacoustic emissions (DPOAEs) provide a window into 
real-time cochlear mechanical function. Yet, relationships between the changes 
in DPOAE metrics and auditory sensitivity are still poorly understood. 
Explicating these relationships might support the use of DPOAEs in hearing 
conservation programs (HCPs) for detecting early damage leading to noise-induced 
hearing loss (NIHL) so that mitigating steps might be taken to limit any lasting 
damage. This report describes the development of DPOAE-based statistical models 
to assess the risk of hearing loss from cisplatin treatment among cancer 
patients. Ototoxicity risk assessment (ORA) models were constructed using a 
machine learning paradigm in which partial least squares and leave-one-out 
cross-validation were applied, yielding optimal screening algorithms from a set 
of known risk factors for ototoxicity and DPOAE changes from pre-exposure 
baseline measures. Single DPOAE metrics alone were poorer indicators of the risk 
of ototoxic hearing shifts than the best performing multivariate models. This 
finding suggests that multivariate approaches applied to the use of DPOAEs in a 
HCP, will improve the ability of DPOAE measures to identify ears with 
noise-induced mechanical damage and/or hearing loss at each monitoring interval. 
This prediction must be empirically assessed in noise-exposed subjects.

DOI: 10.3109/14992027.2011.635713
PMCID: PMC5588874
PMID: 22264063 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of interest: The authors report no 
conflicts of interest. The authors alone are responsible for the content and 
writing of the paper.


362. J Neurosci. 2016 Jul 20;36(29):7740-9. doi: 10.1523/JNEUROSCI.0554-16.2016.

The Severity of Infection Determines the Localization of Damage and Extent of 
Sensorineural Hearing Loss in Experimental Pneumococcal Meningitis.

Perny M(1), Roccio M(2), Grandgirard D(3), Solyga M(1), Senn P(4), Leib SL(5).

Author information:
(1)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, 3001 Bern, Switzerland, Laboratory of Inner Ear Research, Department of 
Clinical Research, University of Bern and University Department of 
Otorhinolaryngology, Head & Neck Surgery, Inselspital, 3008 Bern, Switzerland, 
Cluster for Regenerative Neuroscience, Department of Clinical Research, 
University of Bern, 3008 Bern, Switzerland.
(2)Laboratory of Inner Ear Research, Department of Clinical Research, University 
of Bern and University Department of Otorhinolaryngology, Head & Neck Surgery, 
Inselspital, 3008 Bern, Switzerland, Cluster for Regenerative Neuroscience, 
Department of Clinical Research, University of Bern, 3008 Bern, Switzerland.
(3)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, 3001 Bern, Switzerland, Cluster for Regenerative Neuroscience, Department 
of Clinical Research, University of Bern, 3008 Bern, Switzerland.
(4)Laboratory of Inner Ear Research, Department of Clinical Research, University 
of Bern and University Department of Otorhinolaryngology, Head & Neck Surgery, 
Inselspital, 3008 Bern, Switzerland, Department of Otorhinolaryngology, Head and 
Neck Surgery, University Hospital Geneva, 1205 Geneva, Switzerland, and Cluster 
for Regenerative Neuroscience, Department of Clinical Research, University of 
Bern, 3008 Bern, Switzerland.
(5)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, 3001 Bern, Switzerland, Cluster for Regenerative Neuroscience, Department 
of Clinical Research, University of Bern, 3008 Bern, Switzerland 
stephen.leib@ifik.unibe.ch.

Hearing loss is an important sequela of pneumococcal meningitis (PM), occurring 
in up to 30% of survivors. The role of the severity of infection on hearing 
function and pathomorphological consequences in the cochlea secondary to PM have 
not been investigated to date. Using a well-established model of PM, we 
systematically investigated the functional hearing outcome and the long-term 
fate of neurosensory cells in the cochlea, i.e., hair cells and spiral ganglion 
neurons (SGNs), with a focus on their tonotopic distribution. Intracisternal 
infection of infant rats with increasing inocula of Streptococcus pneumoniae 
resulted in a dose-dependent increase in CSF levels of interleukin-1β, 
interleukin-6, tumor necrosis factor α, interleukin-10, and interferon-γ in 
acute disease. The severity of long-term hearing loss at 3 weeks after 
infection, measured by auditory brainstem response recordings, correlated to the 
initial inoculum dose and to the levels of proinflammatory cytokines determined 
in the acute phase of PM. Quantitative cochlear histomorphology revealed a 
significant loss of SGNs and outer hair cells that strongly correlated to the 
level of infection, with the most severe damage occurring in the basal part of 
the cochlea. Inner hair cells (IHCs) were not significantly affected throughout 
the entire cochlea. However, surviving IHCs lost synaptic connectivity to 
remaining SGNs in all cochlear regions. These findings provide evidence that the 
inoculum concentration, i.e., severity of infection, is the major determinant of 
long-term morphological cell pathologies in the cochlea and functional hearing 
loss.
SIGNIFICANCE STATEMENT: Hearing loss is a neurofunctional deficit occurring in 
up to 30% of patients surviving pneumococcal meningitis (PM). Here, we analyze 
the correlation between the severity of infection and the inflammatory response 
in the CSF, the tonotopic distribution of neurosensory pathologies in the 
cochlea, and the long-term hearing function in a rat model of pneumococcal 
meningitis. Our study identifies the severity of infection as the key 
determinant of long-term hearing loss, underlining the importance of the prompt 
institution of antibiotic therapy in patients suffering from PM. Furthermore, 
our findings reveal in detail the spatial loss of cochlear neurosensory cells, 
providing new insights into the pathogenesis of meningitis-associated hearing 
loss that reveal new starting points for the development of otoprotective 
therapies.

Copyright © 2016 the authors 0270-6474/16/367740-10$15.00/0.

DOI: 10.1523/JNEUROSCI.0554-16.2016
PMCID: PMC6705551
PMID: 27445150 [Indexed for MEDLINE]


363. Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi. 2016 Apr 20;34(4):271-4. doi: 
10.3760/cma.j.issn.1001-9391.2016.04.008.

[Influencing factors for the use of earplugs in workers exposed to noise in a 
city].

[Article in Chinese]

Zhu QR(1), Shao YX, Cao CJ, Wu X, Xie WQ, Xu M, Yang L, Xu LW.

Author information:
(1)Medical College, Hangzhou Normal University, Hangzhou 310000, China.

OBJECTIVE: To investigate the current status of hearing loss and the use of 
earplugs in workers exposed to noise who have been provided earplugs in a city, 
as well as major influencing factors for the use of earplugs.
METHODS: Cluster random sampling was used to conduct a questionnaire survey in 
workers exposed to noise who had been provided earplugs in 15 enterprises with 
noise exposure in a city from June to December, 2014.
RESULTS: In the workers exposed to noise who had been provided earplugs, the 
rate of high-frequency anomaly in both ears was 57.8%, and the workers who kept 
wearing earplugs only accounted for 55.4%. The results of binary logistic 
regression analysis showed that the protective factors for the use of earplugs 
included workers' own feeling of hearing condition (OR=1.704), comfort of 
earplugs (OR= 1.892), enterprise's inspection of the use of earplugs (OR=1.461), 
workers' knowledge of the function and usage of earplugs (OR=1.581), workers' 
understanding of the necessity of earplugs (OR=4.482), workers' initiative to 
search for related data (OR=4.029), the use of earplugs by colleagues 
(OR=5.071), and reminders from family members or friends (OR=2.678) (all 
P<0.05).
CONCLUSION: The workers exposed to noise in this city have a high rate of 
abnormal hearing, and only half of the workers keep wearing earplugs during 
work. The use of earplugs is related to the factors including workers' own 
feeling of hearing condition, comfort of earplugs, workers' knowledge of 
protection, the enterprise' s management of hearing protection, and 
environmental support.

DOI: 10.3760/cma.j.issn.1001-9391.2016.04.008
PMID: 27514260 [Indexed for MEDLINE]


364. Genet Med. 2008 Nov;10(11):797-804. doi: 10.1097/GIM.0b013e318187e106.

Audioprofile-directed screening identifies novel mutations in KCNQ4 causing 
hearing loss at the DFNA2 locus.

Hildebrand MS(1), Tack D, McMordie SJ, DeLuca A, Hur IA, Nishimura C, Huygen P, 
Casavant TL, Smith RJ.

Author information:
(1)Department of Otolaryngology - Head and Neck Surgery, University of Iowa, 
Iowa City, IA 52242, USA. michael-hildebrand@uiowa.edu

PURPOSE: Gene identification in small families segregating autosomal dominant 
sensorineural hearing loss presents a significant challenge. To address this 
challenge, we have developed a machine learning-based software tool, AudioGene 
v2.0, to prioritize candidate genes for mutation screening based on 
audioprofiling.
METHODS: We analyzed audiometric data from a cohort of American families with 
high-frequency autosomal dominant sensorineural hearing loss. Those families 
predicted to have a DFNA2 audioprofile by AudioGene v2.0 were screened for 
mutations in the KCNQ4 gene.
RESULTS: Two novel missense mutations and a stop mutation were detected in three 
American families predicted to have DFNA2-related deafness for a positive 
predictive value of 6.3%. The false negative rate was 0%. The missense mutations 
were located in the channel pore region and the stop mutation was in 
transmembrane domain S5. The latter is the first DFNA2-causing stop mutation 
reported in KCNQ4.
CONCLUSIONS: Our data suggest that the N-terminal end of the P-loop is crucial 
in maintaining the integrity of the KCNQ4 channel pore and AudioGene 
audioprofile analysis can effectively prioritize genes for mutation screening in 
small families segregating high-frequency autosomal dominant sensorineural 
hearing loss. AudioGene software will be made freely available to clinicians and 
researchers once it has been fully validated.

DOI: 10.1097/GIM.0b013e318187e106
PMCID: PMC3337550
PMID: 18941426 [Indexed for MEDLINE]

Conflict of interest statement: No researchers involved in this study report a 
conflict of interest.


365. Int J Pediatr Otorhinolaryngol. 1996 Dec 5;38(1):1-11. doi: 
10.1016/s0165-5876(96)01389-4.

Neuronal networks and self-organizing maps: new computer techniques in the 
acoustic evaluation of the infant cry.

Schönweiler R(1), Kaese S, Möller S, Rinscheid A, Ptok M.

Author information:
(1)Department of Phoniatrics and Pedaudiology, Hannover Medical School, Germany.

Neuronal networks are computer-based techniques for the evaluation and control 
of complex information systems and processes. So far, they have been used in 
engineering, telecommunications, artificial speech and speech recognition. A new 
approach in neuronal network is the self-organizing map (Kohonen map). In the 
phase of 'learning', the map adapts to the patterns of the primary signals. If, 
the phase of 'using the map', the input signal hits the field of the primary 
signals, it resembles them and is called a 'winner'. In our study, we recorded 
the cries of newborns and young infants using digital audio tape (DAT) and a 
high quality microphone. The cries were elicited by tactile stimuli wearing 
headphones. In 27 cases, delayed auditory feedback was presented to the children 
using a headphone and an additional three-head tape-recorder. Spectrographic 
characteristics of the cries were classified by 20-step bark spectra and then 
applied to the neuronal networks. It was possible to recognize similarities of 
different cries of the same children as well as interindividual differences, 
which are also audible to experienced listeners. Differences were obvious in 
profound hearing loss. We know much about the cries of both healthy and sick 
infants, but a reliable investigation regimen, which can be used for clinical 
routine purposes, has yet not been developed. If, in the future, it becomes 
possible to classify spectrographic characteristics automatically, even if they 
are not audible, neuronal networks may be helpful in the early diagnosis of 
infant diseases.

DOI: 10.1016/s0165-5876(96)01389-4
PMID: 9119588 [Indexed for MEDLINE]


366. J Acoust Soc Am. 2010 Mar;127(3):1584-94. doi: 10.1121/1.3293001.

A reanalysis of McGurk data suggests that audiovisual fusion in speech 
perception is subject-dependent.

Schwartz JL(1).

Author information:
(1)Department of Speech and Cognition/Institut de la Communication Parlee, 
GIPSA-Lab, UMR 5216, CNRS, Grenoble University, 38402 Saint Martin d'Heres 
Cedex, France. jean-luc.schwartz@gipsa-lab.inpg.fr

Audiovisual perception of conflicting stimuli displays a large level of 
intersubject variability, generally larger than pure auditory or visual data. 
However, it is not clear whether this actually reflects differences in 
integration per se or just the consequence of slight differences in unisensory 
perception. It is argued that the debate has been blurred by methodological 
problems in the analysis of experimental data, particularly when using the 
fuzzy-logical model of perception (FLMP) [Massaro, D. W. (1987). Speech 
Perception by Ear and Eye: A Paradigm for Psychological Inquiry (Laurence 
Erlbaum Associates, London)] shown to display overfitting abilities with McGurk 
stimuli [Schwartz, J. L. (2006). J. Acoust. Soc. Am. 120, 1795-1798]. A large 
corpus of McGurk data is reanalyzed, using a methodology based on (1) comparison 
of FLMP and a variant with subject-dependent weights of the auditory and visual 
inputs in the fusion process, weighted FLMP (WFLMP); (2) use of a Bayesian 
selection model criterion instead of a root mean square error fit in model 
assessment; and (3) systematic exploration of the number of useful parameters in 
the models to compare, attempting to discard poorly explicative parameters. It 
is shown that WFLMP performs significantly better than FLMP, suggesting that 
audiovisual fusion is indeed subject-dependent, some subjects being more 
"auditory," and others more "visual." Intersubject variability has important 
consequences for theoretical understanding of the fusion process, and 
re-education of hearing impaired people.

DOI: 10.1121/1.3293001
PMID: 20329858 [Indexed for MEDLINE]


367. Hear Res. 2018 Mar;359:40-49. doi: 10.1016/j.heares.2017.12.014. Epub 2017 Dec 
27.

Single-ended prediction of listening effort using deep neural networks.

Huber R(1), Krüger M(2), Meyer BT(3).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Carl-von-Ossietzky 
Universität Oldenburg, Carl-von-Ossietzky-Str. 9-11, 26129 Oldenburg, Germany. 
Electronic address: Rainer.Huber@uni-oldenburg.de.
(2)Hörzentrum Oldenburg, Marie-Curie-Str. 2, 26129 Oldenburg, Germany. 
Electronic address: Melanie.Krueger@hoerzentrum-oldenburg.de.
(3)Medizinische Physik and Cluster of Excellence Hearing4all, Carl-von-Ossietzky 
Universität Oldenburg, Carl-von-Ossietzky-Str. 9-11, 26129 Oldenburg, Germany. 
Electronic address: Bernd.Meyer@uni-oldenburg.de.

The effort required to listen to and understand noisy speech is an important 
factor in the evaluation of noise reduction schemes. This paper introduces a 
model for Listening Effort prediction from Acoustic Parameters (LEAP). The model 
is based on methods from automatic speech recognition, specifically on 
performance measures that quantify the degradation of phoneme posteriorgrams 
produced by a deep neural net: Noise or artifacts introduced by speech 
enhancement often result in a temporal smearing of phoneme representations, 
which is measured by comparison of phoneme vectors. This procedure does not 
require a priori knowledge about the processed speech, and is therefore 
single-ended. The proposed model was evaluated using three datasets of noisy 
speech signals with listening effort ratings obtained from normal hearing and 
hearing impaired subjects. The prediction quality was compared to several 
baseline models such as the ITU-T standard P.563 for single-ended speech quality 
assessment, the American National Standard ANIQUE+ for single-ended speech 
quality assessment, and a single-ended SNR estimator. In all three datasets, the 
proposed new model achieved clearly better prediction accuracies than the 
baseline models; correlations with subjective ratings were above 0.9. So far, 
the model is trained on the specific noise types used in the evaluation. Future 
work will be concerned with overcoming this limitation by training the model on 
a variety of different noise types in a multi-condition way in order to make it 
generalize to unknown noise types.

Copyright © 2018 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.12.014
PMID: 29373159 [Indexed for MEDLINE]


368. Ear Hear. 2015 Jan;36(1):92-101. doi: 10.1097/AUD.0000000000000085.

Stages of change in adults who have failed an online hearing screening.

Laplante-Lévesque A(1), Brännström KJ, Ingo E, Andersson G, Lunner T.

Author information:
(1)1Department of Behavioural Sciences and Learning, Swedish Institute for 
Disability Research, Linköping University, Linköping, Sweden; 2Eriksholm 
Research Centre, Oticon A/S, Snekkersten, Denmark; 3Department of Logopedics, 
Phoniatrics and Audiology, Lund University, Lund, Sweden; and 4Department of 
Clinical Neuroscience, Karolinska Institute, Stockholm, Sweden.

OBJECTIVES: Hearing screening has been proposed to promote help-seeking and 
rehabilitation in adults with hearing impairment. However, some longitudinal 
studies point to low help-seeking and subsequent rehabilitation after a failed 
hearing screening (positive screening result). Some barriers to help-seeking and 
rehabilitation could be intrinsic to the profiles and needs of people who have 
failed a hearing screening. Theories of health behavior change could help to 
understand this population. One of these theories is the transtheoretical 
(stages-of-change) model of health behavior change, which describes profiles and 
needs of people facing behavior changes such as seeking help and taking up 
rehabilitation. According to this model, people go through distinct stages 
toward health behavior change: precontemplation, contemplation, action, and 
finally, maintenance. The present study describes the psychometric properties 
(construct validity) of the stages of change in adults who have failed an online 
hearing screening. Stages of change were measured with the University of Rhode 
Island Change Assessment (URICA). Principal component analysis is presented, 
along with cluster analysis. Internal consistency was investigated. Finally, 
relationships between URICA scores and speech-in-noise recognition threshold, 
self-reported hearing disability, and self-reported duration of hearing 
disability are presented.
DESIGN: In total, 224 adults who had failed a Swedish online hearing screening 
test (measure of speech-in-noise recognition) completed further questionnaires 
online, including the URICA.
RESULTS: A principal component analysis identified the stages of 
precontemplation, contemplation, and action, plus an additional stage, termed 
preparation (between contemplation and action). According to the URICA, half 
(50%) of the participants were in the preparation stage of change. The 
contemplation stage was represented by 38% of participants, while 9% were in the 
precontemplation stage. Finally, the action stage was represented by 
approximately 3% of the participants. Cluster analysis identified four 
stages-of-change clusters: they were named decision making (44% of sample), 
participation (28% of sample), indecision (16% of sample), and reluctance (12% 
of sample). The construct validity of the model was good. Participants who 
reported a more advanced stage of change had significantly greater self-reported 
hearing disability. However, participants who reported a more advanced stage of 
change did not have a significantly worse speech-in-noise recognition threshold 
or reported a significantly longer duration of hearing impairment.
CONCLUSIONS: The additional stage this study uncovered, and which other studies 
have also uncovered, preparation, highlights the need for adequate guidance for 
adults who are yet to seek help for their hearing. The fact that very few people 
were in the action stage (approximately 3% of the sample) signals that screening 
alone is unlikely to be enough to improve help-seeking and rehabilitation rates. 
As expected, people in the later stages of change reported significantly greater 
hearing disability. The lack of significant relationships between 
stages-of-change measures and speech-in-noise recognition threshold and 
self-reported duration of hearing disability highlights the complex interplay 
between impairment, disability, and behaviors in adults who have failed an 
online hearing screening and who are yet to seek help.

DOI: 10.1097/AUD.0000000000000085
PMID: 25158981 [Indexed for MEDLINE]


369. PLoS One. 2015 Jun 5;10(6):e0128743. doi: 10.1371/journal.pone.0128743. 
eCollection 2015.

Positron Emission Tomography Imaging Reveals Auditory and Frontal Cortical 
Regions Involved with Speech Perception and Loudness Adaptation.

Berding G(1), Wilke F(2), Rode T(3), Haense C(4), Joseph G(5), Meyer GJ(4), 
Mamach M(1), Lenarz M(6), Geworski L(2), Bengel FM(4), Lenarz T(3), Lim HH(7).

Author information:
(1)Department of Nuclear Medicine, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence Hearing4all, Hannover Medical School, Hannover, Germany.
(2)Department of Medical Physics and Radiation Protection, Hannover Medical 
School, Hannover, Germany.
(3)Cluster of Excellence Hearing4all, Hannover Medical School, Hannover, 
Germany; Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(4)Department of Nuclear Medicine, Hannover Medical School, Hannover, Germany.
(5)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(6)Department of Otolaryngology, Charité, University Medicine Berlin, Berlin, 
Germany.
(7)Departments of Biomedical Engineering and Otolaryngology-Head & Neck Surgery, 
University of Minnesota, Minneapolis, Minnesota, United States of America.

Considerable progress has been made in the treatment of hearing loss with 
auditory implants. However, there are still many implanted patients that 
experience hearing deficiencies, such as limited speech understanding or 
vanishing perception with continuous stimulation (i.e., abnormal loudness 
adaptation). The present study aims to identify specific patterns of cerebral 
cortex activity involved with such deficiencies. We performed O-15-water 
positron emission tomography (PET) in patients implanted with electrodes within 
the cochlea, brainstem, or midbrain to investigate the pattern of cortical 
activation in response to speech or continuous multi-tone stimuli directly 
inputted into the implant processor that then delivered electrical patterns 
through those electrodes. Statistical parametric mapping was performed on a 
single subject basis. Better speech understanding was correlated with a larger 
extent of bilateral auditory cortex activation. In contrast to speech, the 
continuous multi-tone stimulus elicited mainly unilateral auditory cortical 
activity in which greater loudness adaptation corresponded to weaker activation 
and even deactivation. Interestingly, greater loudness adaptation was correlated 
with stronger activity within the ventral prefrontal cortex, which could be 
up-regulated to suppress the irrelevant or aberrant signals into the auditory 
cortex. The ability to detect these specific cortical patterns and differences 
across patients and stimuli demonstrates the potential for using PET to diagnose 
auditory function or dysfunction in implant patients, which in turn could guide 
the development of appropriate stimulation strategies for improving hearing 
rehabilitation. Beyond hearing restoration, our study also reveals a potential 
role of the frontal cortex in suppressing irrelevant or aberrant activity within 
the auditory cortex, and thus may be relevant for understanding and treating 
tinnitus.

DOI: 10.1371/journal.pone.0128743
PMCID: PMC4457827
PMID: 26046763 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


370. Brain Res. 2017 Mar 15;1659:96-112. doi: 10.1016/j.brainres.2017.01.021. Epub 
2017 Jan 21.

An analysis of current source density profiles activated by local stimulation in 
the mouse auditory cortex in vitro.

Yamamura D(1), Sano A(2), Tateno T(3).

Author information:
(1)Bioengineering and Bioinformatics, Graduate School of Information Science and 
Technology, Hokkaido University, Kita 14, Nishi 9, Kita-ku, Sapporo 060-0814, 
Japan. Electronic address: Yamamura_Daiki@ist.hokudai.ac.jp.
(2)Bioengineering and Bioinformatics, Graduate School of Information Science and 
Technology, Hokkaido University, Kita 14, Nishi 9, Kita-ku, Sapporo 060-0814, 
Japan.
(3)Bioengineering and Bioinformatics, Graduate School of Information Science and 
Technology, Hokkaido University, Kita 14, Nishi 9, Kita-ku, Sapporo 060-0814, 
Japan. Electronic address: tateno@ist.hokudai.ac.jp.

To examine local network properties of the mouse auditory cortex in vitro, we 
recorded extracellular spatiotemporal laminar profiles driven by short electric 
local stimulation on a planar multielectrode array substrate. The recorded local 
field potentials were subsequently evaluated using current source density (CSD) 
analysis to identify sources and sinks. Current sinks are thought to be an 
indicator of net synaptic current in the small volume of cortex surrounding the 
recording site. Thus, CSD analysis combined with multielectrode arrays enabled 
us to compare mean synaptic activity in response to small current stimuli on a 
layer-by-layer basis. We also used senescence-accelerated mice (SAM), some 
strains of which show earlier onset of age-related hearing loss, to examine the 
characteristic spatiotemporal CSD profiles stimulated by electrodes in specific 
cortical layers. Thus, the CSD patterns were classified into several clusters 
based on stimulation sites in the cortical layers. We also found some 
differences in CSD patterns between the two SAM strains in terms of aging 
according to principle component analysis with dimension reduction. For 
simultaneous two-site stimulation, we modeled the obtained CSD profiles as a 
linear superposition of the CSD profiles to individual single-site stimulation. 
The model analysis indicated the nonlinearity of spatiotemporal integration over 
stimulus-driven activity in a layer-specific manner. Finally, on the basis of 
these results, we discuss the auditory cortex local network properties and the 
effects of aging on these mouse strains.

Copyright Â© 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.brainres.2017.01.021
PMID: 28119054 [Indexed for MEDLINE]


371. Ear Hear. 2016 Jul-Aug;37(4):412-23. doi: 10.1097/AUD.0000000000000269.

Validation of a French-Language Version of the Spatial Hearing Questionnaire, 
Cluster Analysis and Comparison with the Speech, Spatial, and Qualities of 
Hearing Scale.

Moulin A(1), Richard C.

Author information:
(1)1INSERM U1028, Lyon Neuroscience Research Center, Brain Dynamics and 
Cognition Team, Lyon, France; 2CNRS UMR5292, Lyon Neuroscience Research Center, 
Brain Dynamics and Cognition Team, Lyon, France; 3University of Lyon, Lyon, 
France; 4Department of Oto-Rhino-Laryngology, Head and Neck Surgery, University 
Hospital (CHUV), Lausanne, Switzerland; and 5The Laboratory for Investigative 
Neurophysiology (The LINE), Department of Radiology & Department of Clinical 
Neurosciences, University Hospital Centre and University of Lausanne, Lausanne, 
Switzerland.

OBJECTIVES: To validate a French-language version of the spatial hearing 
questionnaire (SHQ), including investigating its internal structure using 
cluster analysis and exploring its construct validity on a large population of 
hearing-impaired (HI) and normal-hearing (NH) subjects, and to compare the SHQ 
with the speech, spatial, and qualities of hearing scale (SSQ) in the same 
population.
DESIGN: The SHQ was translated in accordance with the principles of the 
Universalist Model of cross-cultural adaptation of patient-reported outcome 
instruments. The SSQ and SHQ were then presented in a counterbalanced order, in 
a self-report mode, in a population of 230 HI subjects (mean age = 54 years and 
pure-tone audiometry [PTA] on the better ear = 28 dB HL) and 100 NH subjects 
(mean age = 21 years). The SHQ feasibility, readability, and psychometric 
properties were systematically investigated using reliability indices, cluster, 
and factor analyses and multiregression analyses. SHQ characteristics were 
compared both to different literature data obtained with different language 
versions and to the SSQ scores obtained in the same population.
RESULTS: Internal validity was high and very good reproducibility of scores and 
intersubject variability were obtained across the 24 items between the English 
and French SHQ for NH subjects. Factor and cluster analyses concurred in 
identifying five correlated factors, corresponding to several SHQ subscales: (1) 
speech in noise (corresponding to SHQ subscales 7 and 8), (2) localization of 
voice sounds from behind, (3) speech in quiet (corresponding to SHQ subscale 1), 
(4) localization of everyday sounds, and (5) localization of voices and music 
(corresponding to parts of the SHQ localization subscale). Correlations between 
SSQ subscales and SHQ factors identified the greatest correlations between SHQ 
factors 2, 4, and 5 and SSQ spatial subscales, whereas SHQ factor 1 had the 
greatest correlation with SSQ_speech. SHQ and SSQ scores were similar, whether 
in NH subjects (8.5 versus 8.4) or in HI subjects (6.6 for both), sharing more 
than 80% of variance. The SHQ localization subscale gave similar scores as the 
SSQ spatial subscale, sharing more than 75% of variance. Construct validity 
identified better ear PTA and PTA asymmetry as the two main predictors of SHQ 
scores, to a degree similar to that seen for the SSQ. The SHQ was shorter, 
easier to read and less sensitive to the number of years of formal education 
than the SSQ, but this came at a cost of ecological validity, which was rated 
higher for the SSQ than for the SHQ.
CONCLUSIONS: A comparison of factor analysis outcomes among the English, Dutch, 
and French versions of the SHQ confirmed good conceptual equivalence across 
languages and robustness of the SHQ for use in international settings. In 
addition, SHQ and SSQ scores showed remarkable similarities, suggesting the 
possibility of extrapolating the results from one questionnaire to the other. 
Although the SHQ was originally designed in a population of cochlear implant 
patients, the present results show that its usefulness could easily be extended 
to noncochlear-implanted, HI subjects.

DOI: 10.1097/AUD.0000000000000269
PMID: 26808287 [Indexed for MEDLINE]


372. Hear Res. 2010 Jun 1;264(1-2):10-20. doi: 10.1016/j.heares.2010.02.001. Epub 
2010 Feb 6.

Presbycusis phenotypes form a heterogeneous continuum when ordered by degree and 
configuration of hearing loss.

Allen PD(1), Eddins DA.

Author information:
(1)Department of Neurobiology and Anatomy, University of Rochester School of 
Medicine and Dentistry, 601 Elmwood Avenue, Box 603, Rochester, NY 14642, USA. 
paul_allen@urmc.rochester.edu

Many reports have documented age-by-frequency increases in average auditory 
thresholds in various human populations. Despite this, the prevalence of 
different patterns of hearing loss in presbycusis remains uncertain. We examined 
'presbycusis phenotypes' in a database of 960 subjects (552 female, 408 male, 
18-92 years) that each had 30 measures of peripheral hearing sensitivity: pure 
tone audiograms for left and right ears from 0.25 to 8 kHz and DPOAE for each 
ear with F(mean)=1-6.4 kHz. Surprisingly, the hearing phenotypes did not 
naturally separate into discrete classes of presbycusis. Principal component 
(PC) analysis revealed that two principal components account for 74% of the 
variance among the 30 measures of hearing. The two components represent the 
overall degree (PC1) and configuration of loss (Flat vs. Sloping; PC2) and the 
phenotypes form a continuum when plotted against them. A heuristic partitioning 
of this continuum produced classes of presbycusis that vary in their degree of 
Sloping or Flat hearing loss, suggesting that the previously reported sub-types 
of presbycusis arise from the categorical segregation of a continuous and 
heterogeneous distribution. Further, most phenotypes lie intermediate to the 
extremes of either Flat or Sloping loss, indicating that if audiometric 
configuration does predict presbycusis etiology, then a mixed origin is the most 
prevalent.

Copyright 2010 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2010.02.001
PMCID: PMC2868118
PMID: 20144701 [Indexed for MEDLINE]


373. Hear Res. 2014 Oct;316:16-27. doi: 10.1016/j.heares.2014.07.003. Epub 2014 Jul 
21.

Optimized loudness-function estimation for categorical loudness scaling data.

Oetting D(1), Brand T(2), Ewert SD(2).

Author information:
(1)Project Group Hearing, Speech and Audio Technology of the Fraunhofer IDMT and 
Cluster of Excellence Hearing4all, Marie-Curie-Str. 2, 26129 Oldenburg, Germany; 
Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, 26111 Oldenburg, Germany. Electronic address: 
dirk.oetting@idmt.fraunhofer.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Universität 
Oldenburg, 26111 Oldenburg, Germany.

Individual loudness perception can be assessed using categorical loudness 
scaling (CLS). The procedure does not require any training and is frequently 
used in clinics. The goal of this study was to investigate different methods of 
loudness-function estimation from CLS data in terms of their test-retest 
behaviour and to suggest an improved method compared to Brand and Hohmann (2002) 
for adaptive CLS. Four different runs of the CLS procedure were conducted using 
13 normal-hearing and 11 hearing-impaired listeners. The following approaches 
for loudness-function estimation (fitting) by minimising the error between the 
data and loudness function were compared: Errors were defined both in level and 
in loudness direction, respectively. The hearing threshold level (HTL) was 
extracted from CLS by splitting the responses into an audible and an inaudible 
category. The extracted HTL was used as a fixed starting point of the loudness 
function. The uncomfortable loudness level (UCL) was estimated if presentation 
levels were not sufficiently high to yield responses in the upper loudness 
range, as often observed in practise. Compared to the original fitting method, 
the modified estimation of the HTL was closer to the pure-tone audiometric 
threshold. Results of a computer simulation for UCL estimation showed that the 
estimation error was reduced for data sets with sparse or absent responses in 
the upper loudness range. Overall, the suggested modifications lead to a better 
test-retest behaviour. If CLS data are highly consistent over the whole loudness 
range, all fitting methods lead to almost equal loudness functions. A 
considerable advantage of the suggested fitting method is observed for data sets 
where the responses either show high standard deviations or where responses are 
not present in the upper loudness range. Both cases regularly occur in clinical 
practice.

Copyright © 2014 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2014.07.003
PMID: 25058812 [Indexed for MEDLINE]


374. Otol Neurotol. 2017 Jun;38(5):642-647. doi: 10.1097/MAO.0000000000001394.

Audiological Results in SSD With an Active Transcutaneous Bone Conduction 
Implant at a Retrosigmoidal Position.

Salcher R(1), Zimmermann D, Giere T, Lenarz T, Maier H.

Author information:
(1)*Cluster of Excellence Hearing4All †Department of Otolaryngology, Medical 
University Hannover, Hannover, Germany.

OBJECTIVE: One option for patients with single sided deafness (SSD) who 
experience problems with insufficient hearing in different surroundings is the 
treatment with percutaneous bone-anchored hearing aids. Common medical problems 
associated to a skin penetrating abutment can be avoided by active 
transcutaneous bone conduction hearing implants. The purpose of our study was to 
evaluate the benefit of an active transcutaneous bone conduction hearing implant 
in patients with SSD.
PATIENTS AND METHODS: Patients suffering from SSD who are implanted with an 
active transcutaneous bone conduction hearing implant in retrosigmoidal position 
were audiologically analyzed. The audiological test battery included air and 
bone conduction thresholds, word recognition score (WRS) in quiet and speech 
intelligibility (Oldenburg Sentence Test [OLSA]) in noise. Patient satisfaction 
was evaluated with the Abbreviated Profile of Hearing Aid Benefit (APHAB) and 
the Bern-Benefit in Single-Sided Deafness (BBSS) questionnaire.
RESULTS: The monosyllable WRS and the signal-to-noise ratio (SNR) assessed by 
the OLSA was significantly better in all aided conditions. Also, the APHAB 
categories ease of communication and reverberation and the average benefit in 
the BBSS improved significantly if using the device.
CONCLUSION: The Bonebridge is a transcutaneous alternative to the 
well-established percutaneous bone conducting devices in patients with single 
sided deafness. An improvement in hearing in noise and quiet as well as a 
decrease of the head shadow effect can be expected.

DOI: 10.1097/MAO.0000000000001394
PMID: 28375939 [Indexed for MEDLINE]


375. Cortex. 2012 Apr;48(4):492-503. doi: 10.1016/j.cortex.2010.10.001. Epub 2010 Oct 
14.

Pseudohypacusis in childhood and adolescence is associated with increased gray 
matter volume in the medial frontal gyrus and superior temporal gyrus.

Tomoda A(1), Kinoshita S, Korenaga Y, Mabe H.

Author information:
(1)Department of Child Development, Faculty of Life Sciences, Kumamoto 
University, Japan. tomo@kumamoto-u.ac.jp

Pseudohypacusis is a somatoform disorder characterized by hearing loss with 
discrepancies between pure-tone audiometry and auditory brainstem response 
(ABR), but the underlying neuronal mechanisms remain unclear. Using voxel-based 
morphometry (VBM) with magnetic resonance (MR) imaging for 14 unmedicated, 
right-handed patients and 35 healthy control subjects, we investigated whether 
functional hearing loss was associated with discernible changes of brain 
morphology. Group differences in gray matter volume (GMV) were assessed using 
high-resolution, T1-weighted, volumetric MR imaging datasets (3T Trio scanner; 
Siemens AG) and analyzed with covariant factors of age, sex, socioeconomic 
status (SES), and total GMV, which was increased by 27.9% in the left medial 
frontal gyrus (MFG) (Brodmann area 10) (p=.001, corrected cluster level) and by 
14.4% in the right superior temporal gyrus (STG) and the adjacent middle 
temporal gyrus (MTG) (BA42 to 21) (p=.009, corrected cluster level) in patients 
with pseudohypacusis. The GMV in the right STG (BA42) and verbal intelligence 
quotient (IQ) were correlated significantly with the Wechsler Intelligence Scale 
for Children - Third Edition (WISC-III) (ß=-.57, p<.0001) and level of SES 
(ß=-.55, p<.0001). The present findings suggest that the development of the 
auditory association cortex involved in language processing is affected, causing 
insufficient pruning during brain development. We therefore assert that 
differences in the neuroanatomical substrate of pseudohypacusis subjects result 
from a developmental disorder in auditory processing.

Copyright Â© 2010 Elsevier Srl. All rights reserved.

DOI: 10.1016/j.cortex.2010.10.001
PMID: 21074149 [Indexed for MEDLINE]


376. Dev Neurobiol. 2020 Mar;80(3-4):132-146. doi: 10.1002/dneu.22754. Epub 2020 May 
20.

Manipulations of sensory experiences during development reveal mechanisms 
underlying vocal learning biases in zebra finches.

James LS(1)(2), Davies R Jr(1), Mori C(3), Wada K(3)(4), Sakata JT(1)(2)(5).

Author information:
(1)Department of Biology, McGill University, Montreal, QC, Canada.
(2)Centre for Research in Brain, Language and Music, McGill University, 
Montreal, Quebec, Canada.
(3)Graduate School of Life Science, Hokkaido University, Sapporo, Japan.
(4)Faculty of Science, Hokkaido University, Sapporo, Japan.
(5)Center for Studies of Behavioral Neurobiology, Concordia University, 
Montreal, QC, Canada.

Biological predispositions in learning can bias and constrain the cultural 
evolution of social and communicative behaviors (e.g., speech and birdsong), and 
lead to the emergence of behavioral and cultural "universals." For example, 
surveys of laboratory and wild populations of zebra finches (Taeniopygia 
guttata) document consistent patterning of vocal elements ("syllables") with 
respect to their acoustic properties (e.g., duration, mean frequency). 
Furthermore, such universal patterns are also produced by birds that are 
experimentally tutored with songs containing randomly sequenced syllables 
("tutored birds"). Despite extensive demonstrations of learning biases, much 
remains to be uncovered about the nature of biological predispositions that bias 
song learning and production in songbirds. Here, we examined the degree to which 
"innate" auditory templates and/or biases in vocal motor production contribute 
to vocal learning biases and production in zebra finches. Such contributions can 
be revealed by examining acoustic patterns in the songs of birds raised without 
sensory exposure to song ("untutored birds") or of birds that are unable to hear 
from early in development ("early-deafened birds"). We observed that untutored 
zebra finches and early-deafened zebra finches produce songs with positional 
variation in some acoustic features (e.g., mean frequency) that resemble 
universal patterns observed in tutored birds. Similar to tutored birds, 
early-deafened birds also produced song motifs with alternation in acoustic 
features across adjacent syllables. That universal acoustic patterns are 
observed in the songs of both untutored and early-deafened birds highlights the 
contribution motor production biases to the emergence of universals in 
culturally transmitted behaviors.

© 2020 Wiley Periodicals, LLC.

DOI: 10.1002/dneu.22754
PMID: 32330360 [Indexed for MEDLINE]


377. Audiol Neurootol. 2004 Mar-Apr;9(2):81-7. doi: 10.1159/000075999.

Diagnosis of sensorineural hearing loss with neural networks versus logistic 
regression modeling of distortion product otoacoustic emissions.

Ziavra N(1), Kastanioudakis I, Trikalinos TA, Skevas A, Ioannidis JP.

Author information:
(1)ENT Department, University Hospital of Ioannina, Ioannina, Greece.

We investigated whether modeling with artificial neural networks or logistic 
regression of distortion product otoacoustic emissions (DPOAE), across diverse 
frequencies, may achieve an accurate diagnosis of sensorineural hearing loss 
(SNHL) of cochlear origin. 256 ears (90 with SNHL and 166 with normal hearing) 
were evaluated with pure-tone audiometry, impedance audiometry, speech 
audiometry and DPOAE. Ears were split into training (n = 176) and validation (n 
= 80) sets. Input variables included gender, age, examination time, DPOAE 
intensity at F(2) frequencies 593, 937, 1906, 3812 and 6031 Hz, and respective 
values corrected for noise levels. In the validation data set, an average 
network had an area under the receiver operating characteristic curve (AUC) of 
0.86 (accuracy 84%). Logistic regressions including all these variables or those 
selected by backward elimination had AUC values of 0.91 and 0.92, respectively 
(accuracy 85% both). Eleven of 12 trained networks had better specificity than 
the backward elimination logistic regression, and the backward elimination 
logistic regression had a better sensitivity than 11 of the 12 networks. Both 
modeling approaches correctly identified all ears with sudden hearing loss, 
congenital hearing loss, head trauma, nuclear jaundice and ototoxicity, and 2-3 
of 5 ears with acoustic trauma, but missed 1-3 of 3 ears with Ménière's disease 
and 4-6 of 8 ears with abnormal pure-tone thresholds on audiometry which had no 
accompanying findings. For SNHL exceeding 45 dB HL on a pure-tone threshold, 
sensitivity was 83% (15/18) by neural networks and 84 or 94% (16/18 or 17/18) by 
logistic regression. Both neural-network-based analysis and logistic regression 
modeling of the DPOAE pattern across a range of frequencies offer promising 
approaches for the objective diagnosis of moderate and severe SNHL.

Copyright 2004 S. Karger AG, Basel

DOI: 10.1159/000075999
PMID: 14981356 [Indexed for MEDLINE]


378. Eur Arch Otorhinolaryngol. 2016 Jul;273(7):1677-87. doi: 
10.1007/s00405-015-3711-9. Epub 2015 Jul 18.

The European GWAS-identified risk SNP rs457717 within IQGAP2 is not associated 
with age-related hearing impairment in Han male Chinese population.

Luo H(1), Wu H(2)(3), Shen H(4), Chen H(5)(6), Yang T(2)(3), Huang Z(2)(3), Jin 
X(1), Pang X(2)(3), Li L(2)(3), Hu X(2), Jiang X(3)(7), Fan Z(8), Li J(9).

Author information:
(1)Department of Otolaryngology, Renji Hospital, School of Medicine, Shanghai 
Jiaotong University, 160 Pujian Road Pudong New Area, Shanghai, 200127, People's 
Republic of China.
(2)Department of Otolaryngology-Head and Neck Surgery, Xinhua Hospital, Shanghai 
Jiaotong University, Shanghai, People's Republic of China.
(3)Ear Institute, School of Medicine, Shanghai Jiaotong University, Shanghai, 
People's Republic of China.
(4)Renji-Med X Clinical Stem Cell Research Center, Renji Hospital, School of 
Medicine, Shanghai Jiaotong University, Shanghai, People's Republic of China.
(5)Shanghai Center for Bioinformation Technology, Shanghai, 200235, People's 
Republic of China.
(6)Department of Bioinformatics and Biostatistics, College of Life Sciences and 
Biotechnology, Shanghai Jiaotong University, Shanghai, 200240, People's Republic 
of China.
(7)Health Check-up Center, Xinhua Hospital, School of Medicine, Shanghai 
Jiaotong University, Shanghai, People's Republic of China.
(8)Health Check-up Center, Renji Hospital, School of Medicine, Shanghai Jiaotong 
University, Shanghai, People's Republic of China.
(9)Department of Otolaryngology, Renji Hospital, School of Medicine, Shanghai 
Jiaotong University, 160 Pujian Road Pudong New Area, Shanghai, 200127, People's 
Republic of China. drlijiping@163.com.

This study aimed to test the association between the European GWAS-identified 
risk IQGAP2 SNP rs457717 (A>G) and age-related hearing impairment (ARHI) in a 
Han male Chinese (HMC) population. A total of 2420 HMC subjects were divided 
into two groups [group 70+: >70 years (n = 1306), and group 70-: ≤70 years 
(n = 1114)]. The participants were categorised into case and control groups 
according to Z high scores for group 70- and the severity of hearing loss and 
different audiogram shapes identified by K-means cluster analysis for group 70+. 
The IQGAP2 tagSNP rs457717 was genotyped in accordance with the different ARHI 
phenotypes. The genotype distributions of IQGAP2 (AA/AG/GG) were not 
significantly different between the case and control groups (P = 0.613 for group 
70-; P = 0.602 for group 70+). Compared with genotype AA, the ORs of genotypes 
AG and GG for ARHI were not significantly different following adjustment for 
other environmental risk factors. We demonstrated that the IQGAP2 TagSNP 
rs457717 (A/G) was not associated with ARHI in HMC individuals.

DOI: 10.1007/s00405-015-3711-9
PMID: 26187738 [Indexed for MEDLINE]


379. Int J Audiol. 2015;54 Suppl 2:71-9. doi: 10.3109/14992027.2015.1079929. Epub 
2015 Nov 10.

Do you hear the noise? The German matrix sentence test with a fixed noise level 
in subjects with normal hearing and hearing impairment.

Wardenga N(1), Batsoulis C(1)(2), Wagener KC(3)(4), Brand T(3)(5), Lenarz 
T(3)(1), Maier H(3)(1).

Author information:
(1)b Department of Otolaryngology , Hannover Medical School , Hannover , 
Germany.
(2)e MED-EL Medical Electronics , Hannover , Germany.
(3)a * Cluster of Excellence 'Hearing4all' , Hannover & Oldenburg , Germany.
(4)c Hörzentrum Oldenburg GmbH , Oldenburg , Germany.
(5)d Department of Medical Physics , Carl-von-Ossietzky-University Oldenburg , 
Oldenburg , Germany.

OBJECTIVE: The aim of this study was to determine the relationship between 
hearing loss and speech reception threshold (SRT) in a fixed noise condition 
using the German Oldenburg sentence test (OLSA).
DESIGN: After training with two easily-audible lists of the OLSA, SRTs were 
determined monaurally with headphones at a fixed noise level of 65 dB SPL using 
a standard adaptive procedure, converging to 50% speech intelligibility.
STUDY SAMPLE: Data was obtained from 315 ears of 177 subjects with hearing 
losses ranging from -5 to 90 dB HL pure-tone average (PTA, 0.5, 1, 2, 3 kHz).
RESULTS: Two domains were identified with a linear dependence of SRT on PTA. The 
SRT increased with a slope of 0.094 ± 0.006 dB SNR/dB HL (standard deviation 
(SD) of residuals = 1.17 dB) for PTAs < 47 dB HL and with a slope of 0.811 ± 
0.049 dB SNR/dB HL (SD of residuals = 5.54 dB) for higher PTAs.
CONCLUSION: The OLSA can be applied to subjects with a wide range of hearing 
losses. With 65 dB SPL fixed noise presentation level the SRT is determined by 
listening in noise for PTAs < ∼47 dB HL, and above it is determined by listening 
in quiet.

DOI: 10.3109/14992027.2015.1079929
PMID: 26555195 [Indexed for MEDLINE]


380. Psychon Bull Rev. 2017 Jun;24(3):863-872. doi: 10.3758/s13423-016-1148-9.

McGurk stimuli for the investigation of multisensory integration in cochlear 
implant users: The Oldenburg Audio Visual Speech Stimuli (OLAVS).

Stropahl M(1), Schellhardt S(2), Debener S(3)(4).

Author information:
(1)Department of Psychology, Neuropsychology Lab, European Medical School, Carl 
von Ossietzky University of Oldenburg, Ammerländer Herrstraße 114-118, 26129, 
Oldenburg, Germany. maren.stropahl@uni-oldenburg.de.
(2)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.
(3)Department of Psychology, Neuropsychology Lab, European Medical School, Carl 
von Ossietzky University of Oldenburg, Ammerländer Herrstraße 114-118, 26129, 
Oldenburg, Germany.
(4)Cluster of Excellence Hearing4all Oldenburg, Oldenburg, Germany.

The concurrent presentation of different auditory and visual syllables may 
result in the perception of a third syllable, reflecting an illusory fusion of 
visual and auditory information. This well-known McGurk effect is frequently 
used for the study of audio-visual integration. Recently, it was shown that the 
McGurk effect is strongly stimulus-dependent, which complicates comparisons 
across perceivers and inferences across studies. To overcome this limitation, we 
developed the freely available Oldenburg audio-visual speech stimuli (OLAVS), 
consisting of 8 different talkers and 12 different syllable combinations. The 
quality of the OLAVS set was evaluated with 24 normal-hearing subjects. All 96 
stimuli were characterized based on their stimulus disparity, which was obtained 
from a probabilistic model (cf. Magnotti & Beauchamp, 2015). Moreover, the 
McGurk effect was studied in eight adult cochlear implant (CI) users. By 
applying the individual, stimulus-independent parameters of the probabilistic 
model, the predicted effect of stronger audio-visual integration in CI users 
could be confirmed, demonstrating the validity of the new stimulus material.

DOI: 10.3758/s13423-016-1148-9
PMID: 27562763 [Indexed for MEDLINE]


381. BMC Vet Res. 2012 Oct 29;8:202. doi: 10.1186/1746-6148-8-202.

Prevalence of congenital hereditary sensorineural deafness in Australian Cattle 
Dogs and associations with coat characteristics and sex.

Sommerlad SF(1), Morton JM, Haile-Mariam M, Johnstone I, Seddon JM, O'Leary CA.

Author information:
(1)School of Veterinary Science, The University of Queensland, Gatton, 
Queensland, 4343, Australia. s.sommerlad@uq.edu.au

BACKGROUND: Congenital hereditary sensorineural deafness (CHSD) occurs in many 
dog breeds, including Australian Cattle Dogs. In some breeds, CHSD is associated 
with a lack of cochlear melanocytes in the stria vascularis, certain coat 
characteristics, and potentially, abnormalities in neuroepithelial pigment 
production. This study investigates phenotypic markers for CHSD in 899 
Australian Cattle Dogs.
RESULTS: Auditory function was tested in 899 Australian Cattle Dogs in family 
groups using brainstem auditory evoked response testing. Coat colour and 
patterns, facial and body markings, gender and parental hearing status were 
recorded.Deafness prevalence among all 899 dogs was 10.8% with 7.5% unilaterally 
deaf, and 3.3% bilaterally deaf, and amongst pups from completely tested litters 
(n = 696) was 11.1%, with 7.5% unilaterally deaf, and 3.6% bilaterally 
deaf.Univariable and multivariable analyses revealed a negative association 
between deafness and bilateral facial masks (odds ratio 0.2; P ≤ 0.001). Using 
multivariable logistic animal modelling, the risk of deafness was lower in dogs 
with pigmented body spots (odds ratio 0.4; P = 0.050).No significant 
associations were found between deafness and coat colour.Within unilaterally 
deaf dogs with unilateral facial masks, no association was observed between the 
side of deafness and side of mask. The side of unilateral deafness was not 
significantly clustered amongst unilaterally deaf dogs from the same litter. 
Females were at increased risk of deafness (odds ratio from a logistic animal 
model 1.9; P = 0.034) after adjusting for any confounding by mask type and 
pigmented body spots.
CONCLUSIONS: Australian Cattle Dogs suffer from CHSD, and this disease is more 
common in dogs with mask-free faces, and in those without pigmented body 
patches. In unilaterally deaf dogs with unilateral masks, the lack of observed 
association between side of deafness and side of mask suggests that if CHSD is 
due to defects in molecular pigment pathways, the molecular control of embryonic 
melanoblast migration from ectoderm to skin differs from control of migration 
from ectoderm to cochlea. In Australian Cattle Dogs, CHSD may be more common in 
females.

DOI: 10.1186/1746-6148-8-202
PMCID: PMC3489614
PMID: 23107143 [Indexed for MEDLINE]


382. Audiology. 1995 Mar-Apr;34(2):76-84. doi: 10.3109/00206099509071900.

Dispositional optimism, dysphoria, health, and coping with hearing impairment in 
elderly adults.

Andersson G(1), Melin L, Lindberg P, Scott B.

Author information:
(1)Department of Clinical, Psychology, Uppsala University, Sweden.

Sixty-eight elderly hearing impaired subjects were interviewed and completed 
self-report measures on hearing disability, dispositional optimism, dysphoria, 
and general health. The measures used were the Hearing Coping Assessment (HCA), 
the Hearing Questions (HQ), the Life Orientation Test (LOT), The Beck Depression 
Inventory (BDI), and a subscale from the Göteborg Quality of Life (GQL). 
Psychometric analyses of HCA, HQ, LOT, BDI, and GQL revealed high reliability in 
terms of Cronbach's Alpha and split-half r's. Significant intercorrelations were 
found between several measures, but not with pure-tone audiometry (0.5, 1, 2, 
and 3 kHz). Cluster analysis was used to identify subgroups in the sample. As a 
result three clusters were identified interpreted as 'high copers', 'copers with 
moderate psychological and somatic complaints', and 'low copers'. Results from 
the cluster analyses were confirmed by using two different clustering methods 
and by between-cluster comparisons on the HQ, which had not been used to obtain 
the clusters.

DOI: 10.3109/00206099509071900
PMID: 8561685 [Indexed for MEDLINE]


383. Int J Pediatr Otorhinolaryngol. 2003 Oct;67(10):1061-7. doi: 
10.1016/s0165-5876(03)00187-3.

Monosyllable speech perception of Japanese hearing aid users with prelingual 
hearing loss: implications for surgical indication of cochlear implant.

Fukuda S(1), Fukushima K, Toida N, Tsukamura K, Maeda Y, Kibayashi N, Nagayasu 
R, Orita Y, Kasai N, Kataoka Y, Nishizaki K.

Author information:
(1)Auditory Center for Hearing Impaired Children, Kanariya Gakuen, Okayama, 
Japan.

OBJECTIVE: The monosyllable speech perception ability after years of educational 
intervention was compared between prelingually deafened pediatric hearing aid 
users and their cochlear implant counterparts.
DESIGN: An open-set monosyllabic speech perception test was conducted on all 
subjects. The test required subjects to indicate a corresponding Japanese 
character to that spoken by the examiner. Fifty-two subjects with prelingual 
hearing impairment (47 hearing aid users and 5 cochlear implant users) were 
examined.
RESULTS: Hearing aid users with average pure-tone thresholds less than 90 dB HL 
demonstrated generally better monosyllable perception than 70%, which was 
equivalent or better performance than that of the cochlear implant group. Widely 
dispersed speech perception was observed within the 90-99 dB HL hearing-aid user 
group with most subjects demonstrating less than 50% speech perception. In the 
cluster of >100 dB HL, few cases demonstrated more than 50% in speech 
perception. The perception ability of the vowel part of each mora within the 
cochlear implant group was 100% and corresponding to that of hearing aid users 
with moderate and severe hearing loss.
CONCLUSION: Hearing ability among cochlear implant users can be comparable with 
that of hearing aid users with average unaided pure-tone thresholds of 90 dB HL, 
after monosyllabic speech perception testing was performed.

DOI: 10.1016/s0165-5876(03)00187-3
PMID: 14550959 [Indexed for MEDLINE]


384. Trends Hear. 2015 Dec 1;19:2331216515617143. doi: 10.1177/2331216515617143.

Comparison of Interaural Electrode Pairing Methods for Bilateral Cochlear 
Implants.

Hu H(1), Dietz M(2).

Author information:
(1)Medizinische Physik, Universität Oldenburg and Cluster of Excellence 
"Hearing4all", Germany hongmei.hu@uni-oldenburg.de.
(2)Medizinische Physik, Universität Oldenburg and Cluster of Excellence 
"Hearing4all", Germany.

In patients with bilateral cochlear implants (CIs), pairing matched interaural 
electrodes and stimulating them with the same frequency band is expected to 
facilitate binaural functions such as binaural fusion, localization, and spatial 
release from masking. Because clinical procedures typically do not include 
patient-specific interaural electrode pairing, it remains the case that each 
electrode is allocated to a generic frequency range, based simply on the 
electrode number. Two psychoacoustic techniques for determining interaurally 
paired electrodes have been demonstrated in several studies: interaural pitch 
comparison and interaural time difference (ITD) sensitivity. However, these two 
methods are rarely, if ever, compared directly. A third, more objective method 
is to assess the amplitude of the binaural interaction component (BIC) derived 
from electrically evoked auditory brainstem responses for different electrode 
pairings; a method has been demonstrated to be a potential candidate for 
bilateral CI users. Here, we tested all three measures in the same eight CI 
users. We found good correspondence between the electrode pair producing the 
largest BIC and the electrode pair producing the maximum ITD sensitivity. The 
correspondence between the pairs producing the largest BIC and the pitch-matched 
electrode pairs was considerably weaker, supporting the previously proposed 
hypothesis that whilst place pitch might adapt over time to accommodate 
mismatched inputs, sensitivity to ITDs does not adapt to the same degree.

© The Author(s) 2015.

DOI: 10.1177/2331216515617143
PMCID: PMC4771032
PMID: 26631108 [Indexed for MEDLINE]


385. Ear Hear. 2011 Feb;32(1):104-13. doi: 10.1097/AUD.0b013e3181ec5d95.

Electrical compound action potentials recorded with automated neural response 
telemetry: threshold changes as a function of time and electrode position.

Spivak L(1), Auerbach C, Vambutas A, Geshkovich S, Wexler L, Popecki B.

Author information:
(1)Apelian Cochlear Implant Center, Long Island Jewish Medical Center, New Hyde 
Park, New York, USA. spivak@lij.edu

OBJECTIVE: Since the introduction of neural response telemetry (NRT) for the 
Nucleus 24 cochlear implant (CI24), researchers and clinicians have investigated 
the feasibility of using the electrically evoked compound action potential 
(ECAP) threshold to objectively predict psychophysical measurements that are 
used in the programming of the speech processor. The ability to substitute 
objective for behavioral measurements, particularly measurements made at the 
time of surgery, would greatly facilitate programming the MAP for young children 
and other individuals who are not able to provide reliable behavioral data 
required for MAP programming. There have been a number of studies that have 
examined characteristics of the ECAP measured at the time of surgery and 
postoperatively; however, all the available published data are based on the 
CI24. With the introduction of the Nucleus Freedom device, an automated NRT 
(AutoNRT) program became available, which was capable of measuring ECAP 
thresholds at lower levels than was previously possible with NRT software 
associated with the CI24 device. It was hypothesized that the enhancements to 
the NRT program may improve the predictability of postoperative measurements 
from intraoperatively recorded ECAP thresholds. The purpose of this study was to 
track ECAP thresholds obtained using AutoNRT as a function of time and electrode 
position.
DESIGN: ECAP thresholds were recorded from 71 children and adults implanted with 
the Nucleus Freedom device using the AutoNRT test protocol. ECAP thresholds were 
obtained at the time of surgery, at initial stimulation, and 3 mos 
poststimulation. Five electrodes located at basal, middle, and apical positions 
in the cochlea were tested at each time interval and thresholds were compared.
RESULTS: Significant differences were found in ECAP thresholds measured with 
AutoNRT as a function of both time and electrode position. Basal electrodes had 
higher ECAP thresholds than apical electrodes and that relationship was 
consistent for each time period. Thresholds for all electrodes decreased between 
surgery and initial stimulation and remained relatively stable at 3 mos 
poststimulation. ECAP thresholds were consistently lower for children compared 
with adults at each time point. Mid-array electrodes (11 and 16) showed the 
least amount of change over time.
CONCLUSIONS: AutoNRT thresholds demonstrated significant change over time, 
limiting the ability to use intraoperatively recorded ECAP thresholds to predict 
postoperative measurements. In this study, electrodes 11 and 16 showed the least 
amount of change in ECAP threshold over time and therefore would be the best 
choices for estimating postoperative ECAP thresholds. Although not an ideal 
solution, mid-array ECAP thresholds obtained intraoperatively may prove to be 
helpful in creating a first MAP when no other behavioral or electrophysiological 
data are available.

DOI: 10.1097/AUD.0b013e3181ec5d95
PMID: 20686409 [Indexed for MEDLINE]


386. J Speech Lang Hear Res. 2004 Apr;47(2):304-20. doi: 10.1044/1092-4388(2004/025).

Using visible speech to train perception and production of speech for 
individuals with hearing loss.

Massaro DW(1), Light J.

Author information:
(1)Department of Psychology, University of California, Santa Cruz, CA, USA. 
massaro@fuzzy.ucsc.edu

The main goal of this study was to implement a computer-animated talking head, 
Baldi, as a language tutor for speech perception and production for individuals 
with hearing loss. Baldi can speak slowly; illustrate articulation by making the 
skin transparent to reveal the tongue, teeth, and palate; and show supplementary 
articulatory features, such as vibration of the neck to show voicing and 
turbulent airflow to show frication. Seven students with hearing loss between 
the ages of 8 and 13 were trained for 6 hours across 21 weeks on 8 categories of 
segments (4 voiced vs. voiceless distinctions, 3 consonant cluster distinctions, 
and 1 fricative vs. affricate distinction). Training included practice at the 
segment and the word level. Perception and production improved for each of the 7 
children. Speech production also generalized to new words not included in the 
training lessons. Finally, speech production deteriorated somewhat after 6 weeks 
without training, indicating that the training method rather than some other 
experience was responsible for the improvement that was found.

DOI: 10.1044/1092-4388(2004/025)
PMID: 15157132 [Indexed for MEDLINE]


387. Ear Hear. 2015 Mar-Apr;36(2):212-6. doi: 10.1097/AUD.0000000000000101.

Targeting regional pediatric congenital hearing loss using a spatial scan 
statistic.

Bush ML(1), Christian WJ, Bianchi K, Lester C, Schoenberg N.

Author information:
(1)1Department of Otolaryngology-Head and Neck Surgery, University of Kentucky, 
Lexington, Kentucky, USA; 2Department of Epidemiology, College of Public Health, 
Lexington, Kentucky, USA; 3College of Medicine, University of Kentucky, 
Lexington, Kentucky, USA; 4Cabinet for Health and Family Services, Commission 
for Children with Special Health Care Needs, Louisville, Kentucky, USA; and 
5Department of Behavioral Science, University of Kentucky, Lexington, Kentucky, 
USA.

OBJECTIVES: Congenital hearing loss is a common problem, and timely 
identification and intervention are paramount for language development. Patients 
from rural regions may have many barriers to timely diagnosis and intervention. 
The purpose of this study was to examine the spatial and hospital-based 
distribution of failed infant hearing screening testing and pediatric congenital 
hearing loss throughout Kentucky.
DESIGN: Data on live births and audiological reporting of infant hearing loss 
results in Kentucky from 2009 to 2011 were analyzed. The authors used spatial 
scan statistics to identify high-rate clusters of failed newborn screening tests 
and permanent congenital hearing loss (PCHL), based on the total number of live 
births per county. The authors conducted further analyses on PCHL and failed 
newborn hearing screening tests, based on birth hospital data and method of 
screening.
RESULTS: The authors observed four statistically significant (p < 0.05) 
high-rate clusters with failed newborn hearing screenings in Kentucky, including 
two in the Appalachian region. Hospitals using two-stage otoacoustic emission 
testing demonstrated higher rates of failed screening (p = 0.009) than those 
using two-stage automated auditory brainstem response testing. A significant 
cluster of high rate of PCHL was observed in Western Kentucky. Five of the 54 
birthing hospitals were found to have higher relative risk of PCHL, and two of 
those hospitals are located in a very rural region of Western Kentucky within 
the cluster.
CONCLUSIONS: This spatial analysis in children in Kentucky has identified 
specific regions throughout the state with high rates of congenital hearing loss 
and failed newborn hearing screening tests. Further investigation regarding 
causative factors is warranted. This method of analysis can be useful in the 
setting of hearing health disparities to focus efforts on regions facing high 
incidence of congenital hearing loss.

DOI: 10.1097/AUD.0000000000000101
PMCID: PMC4336591
PMID: 25225918 [Indexed for MEDLINE]


388. Cochlear Implants Int. 2020 Sep;21(5):299-305. doi: 
10.1080/14670100.2019.1667574. Epub 2019 Sep 17.

From manual to artificial intelligence fitting: Two cochlear implant case 
studies.

Wathour J(1), Govaerts PJ(2), Deggouj N(1).

Author information:
(1)Cliniques Universitaires Saint-Luc, Avenue Hippocrate 10, Brussels, 1200, 
Belgium.
(2)Eargroup, Antwerpen-Deurne, Belgium.

Objective: To assess whether CI programming by means of a software application 
using artificial intelligence (AI), FOX®, may improve cochlear implant (CI) 
performance. Patients: Two adult CI recipients who had mixed auditory results 
with their manual fitting were selected for an AI-assisted fitting. Even after 
17 months CI experience and 19 manual fitting sessions, the first subject hadn't 
developed open set word recognition. The second subject, after 9 months of 
manual fitting, had developed good open set word recognition, but his scores 
remained poor at soft and loud presentation levels. Main outcome measure(s): 
Cochlear implant fitting parameters, pure tone thresholds, bisyllabic word 
recognition, phonemic discrimination scores and loudness scaling curves. 
Results: For subject 1, a first approach trying to optimize the home maps by 
means of AI-proposed adaptations was not successful whereas a second approach 
based on the use of Automaps (an AI approach based on universal, i.e. population 
based group statistics) during 3 months allowed the development of open set word 
recognition. For subject 2, the word recognition scores improved at soft and 
loud intensities with the AI suggestions. The AI-suggested modifications seem to 
be atypical. Conclusions: The two case studies illustrate that adults implanted 
with manual CI fitting may experience an improvement in their auditory results 
with AI-assisted fitting.

DOI: 10.1080/14670100.2019.1667574
PMID: 31530099 [Indexed for MEDLINE]


389. Ear Hear. 2020 Nov/Dec;41 Suppl 1(Suppl 1):140S-146S. doi: 
10.1097/AUD.0000000000000961.

Potential of Augmented Reality Platforms to Improve Individual Hearing Aids and 
to Support More Ecologically Valid Research.

Mehra R(1), Brimijoin O, Robinson P, Lunner T.

Author information:
(1)Facebook Reality Labs Research, Redmond, Washington, USA.

An augmented reality (AR) platform combines several technologies in a system 
that can render individual "digital objects" that can be manipulated for a given 
purpose. In the audio domain, these may, for example, be generated by speaker 
separation, noise suppression, and signal enhancement. Access to the "digital 
objects" could be used to augment auditory objects that the user wants to hear 
better. Such AR platforms in conjunction with traditional hearing aids may 
contribute to closing the gap for people with hearing loss through multimodal 
sensor integration, leveraging extensive current artificial intelligence 
research, and machine-learning frameworks. This could take the form of an 
attention-driven signal enhancement and noise suppression platform, together 
with context awareness, which would improve the interpersonal communication 
experience in complex real-life situations. In that sense, an AR platform could 
serve as a frontend to current and future hearing solutions. The AR device would 
enhance the signals to be attended, but the hearing amplification would still be 
handled by hearing aids. In this article, suggestions are made about why AR 
platforms may offer ideal affordances to compensate for hearing loss, and how 
research-focused AR platforms could help toward better understanding of the role 
of hearing in everyday life.

DOI: 10.1097/AUD.0000000000000961
PMCID: PMC7676615
PMID: 33105268 [Indexed for MEDLINE]


390. Annu Int Conf IEEE Eng Med Biol Soc. 2018 Jul;2018:987-990. doi: 
10.1109/EMBC.2018.8512491.

Individual Classification of Single Trial EEG Traces to Discriminate Brain 
responses to Speech with Different Signal-to-Noise Ratios.

Cabrera AF, Petersen EB, Graversen C, Sorensen AT, Lunner T, Rank ML.

To gain knowledge of listening effort in adverse situations, it is important to 
know how the brain processes speech with different signal-to-noise ratios (SNR). 
To investigate this, we conducted a study with 33 hearing impaired individuals, 
whose electroencephalographic (EEG) signals were recorded while listening to 
sentences presented in high and low levels of background noise. To discriminate 
between these two conditions, features from the 64-channel EEG recordings were 
extracted using the power spectrum obtained by a Fast Fourier Transform. 
Features vectors were selected on an individual basis by using the statistical 
R2 approach. The selected features were then classified by a Support Vector 
Machine with a nonlinear kernel, and the classification results were validated 
using a leave-one-out strategy, and presented an average classification accuracy 
over all 33 subjects of 83% (SD=6.4%). The most discriminative features were 
selected in the high-beta (19-30 Hz) and gamma (30-45 Hz) bands. These results 
suggest that specific brain oscillations are involved in addressing background 
noise during speech stimuli, which may reflect differences in cognitive load 
between the conditions of low and high background noise.

DOI: 10.1109/EMBC.2018.8512491
PMID: 30440556 [Indexed for MEDLINE]


391. Stud Health Technol Inform. 2007;129(Pt 2):1289-93.

A comparison of supervised classification methods for auditory brainstem 
response determination.

McCullagh P(1), Wang H, Zheng H, Lightbody G, McAllister G.

Author information:
(1)Department of Computing and Mathematics, University of Ulster, United 
Kingdom.

The ABR is commonly used in the Audiology clinic to determine and quantify 
hearing loss. Its interpretation is subjective, dependent upon the expertise and 
experience of the clinical scientist. In this study we investigated the role of 
machine learning for pattern classification in this domain. We extracted 
features from the ABRs of 85 test subjects (550 waveforms) and compared four 
complimentary supervised classification methods: Naïve Bayes, Support Vector 
Machine Multi-Layer Perceptron and KStar. The Abr dataset comprised both high 
level and near threshold recordings, labeled as 'response' or 'no response' by 
the human expert. Features were extracted from single averaged recordings to 
make the classification process straightforward. A best classification accuracy 
of 83.4% was obtained using Naïve Bayes and five relevant features extracted 
from time and wavelet domains. Naïve Bayes also achieved the highest specificity 
(86.3%). The highest sensitivity (93.1%) was obtained with Support Vector 
Machine-based classification models. In terms of the overall classification 
accuracy, four classifiers have shown the consistent, relatively high 
performance, indicating the relevance of selected features and the feasibility 
of using machine learning and statistical classification models in the analysis 
of ABR.

PMID: 17911922 [Indexed for MEDLINE]


392. S Afr J Commun Disord. 2016 Apr 8;63(1):105. doi: 10.4102/sajcd.v63i1.105.

The prevalence of hearing impairment within the Cape Town Metropolitan area.

Ramma L(1), Sebothoma B.

Author information:
(1)Division of Communication Sciences & Disorders, University of Cape Town. 
Lebogang.Ramma@uct.ac.za.

BACKGROUND: There is a lack of data on the prevalence of hearing impairment in 
South Africa. Current data is unreliable as it is based on national census 
information which tends to underestimate the prevalence of hearing impairment.
AIM: The aim of this study was to estimate the prevalence of hearing impairment 
in the Cape Town Metropolitan area and to determine factors associated with 
hearing impairment.
METHOD: A cross-sectional household survey involving 2494 partcipants from 718 
households was conducted between the months of February and October 2013. Random 
cluster sampling was used to select four health sub-districts from eight health 
sub-districts in the Cape Town Metropolitan area using a method of probability 
proportional to size (PPS). The survey was conducted according to the World 
Health Organization (WHO) Ear and Hearing Disorders Survey Protocol and the 
classifcation of hearing impairment matched the WHO's criteria for the grading 
of hearing impairment.
RESULTS: The overall prevalence of hearing impairment in the population of this 
study was 12.35% (95%CI: 11.06% - 13.64%) and prevalence of disabling hearing 
impairment was 4.57% (95% CI: 3.75% - 5.39%) amongst individuals ≥ 4 years old. 
The following factors were found to be associated with hearing impairment; male 
gender, age, hypertension, a history of head and neck trauma and a family 
history of hearing impairment.
CONCLUSION: Based on the data from communities surveyed during this study, 
hearing impairment is more prevalent than previously estimated based on national 
population census information. Interventions for the prevention of hearing 
impairment in these communities should focus on individuals with associated risk 
factors.

DOI: 10.4102/sajcd.v63i1.105
PMCID: PMC5843235
PMID: 27247255 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no financial 
or personal relationships which may have inappropriately influenced them in 
writing this article.


393. Antimicrob Agents Chemother. 2015 Oct;59(10):6337-43. doi: 10.1128/AAC.01050-15. 
Epub 2015 Jul 27.

Amikacin Concentrations Predictive of Ototoxicity in Multidrug-Resistant 
Tuberculosis Patients.

Modongo C(1), Pasipanodya JG(2), Zetola NM(3), Williams SM(4), Sirugo G(5), 
Gumbo T(6).

Author information:
(1)Division of Infectious Diseases, University of Pennsylvania, Philadelphia, 
Pennsylvania, USA Botswana-University of Pennsylvania Partnership, Gaborone, 
Botswana.
(2)Office of Global Health, University of Texas Southwestern Medical Center, 
Dallas, Texas, USA.
(3)Division of Infectious Diseases, University of Pennsylvania, Philadelphia, 
Pennsylvania, USA Botswana-University of Pennsylvania Partnership, Gaborone, 
Botswana Department of Medicine, University of Botswana, Gaborone, Botswana.
(4)Department of Genetics, Geisel School of Medicine, Dartmouth College, 
Hanover, New Hampshire, USA.
(5)Centro di Ricerca, Ospedale San Pietro Fatebenefratelli, Rome, Italy.
(6)Office of Global Health, University of Texas Southwestern Medical Center, 
Dallas, Texas, USA Department of Medicine, University of Cape Town, Observatory, 
South Africa Tawanda.Gumbo@BaylorHealth.edu.

Aminoglycosides, such as amikacin, are used to treat multidrug-resistant 
tuberculosis. However, ototoxicity is a common problem and is monitored using 
peak and trough amikacin concentrations based on World Health Organization 
recommendations. Our objective was to identify clinical factors predictive of 
ototoxicity using an agnostic machine learning method. We used classification 
and regression tree (CART) analyses to identify clinical factors, including 
amikacin concentration thresholds that predicted audiometry-confirmed 
ototoxicity among 28 multidrug-resistant pulmonary tuberculosis patients in 
Botswana. Amikacin concentrations were measured for all patients. The 
quantitative relationship between predictive factors and the probability of 
ototoxicity were then identified using probit analyses. The primary predictors 
of ototoxicity on CART analyses were cumulative days of therapy, followed by 
cumulative area under the concentration-time curve (AUC), which improved on the 
primary predictor by 87%. The area under the receiver operating curve was 0.97 
on the test set. Peak and trough were not predictors in any tree. When 
algorithms were forced to pick peak and trough as primary predictors, the area 
under the receiver operating curve fell to 0.46. Probit analysis revealed that 
the probability of ototoxicity increased sharply starting after 6 months of 
therapy to near maximum at 9 months. A 10% probability of ototoxicity occurred 
with a threshold cumulative AUC of 87,232 days · mg · h/liter, while that of 20% 
occurred at 120,000 days · mg · h/liter. Thus, cumulative amikacin AUC and 
duration of therapy, and not peak and trough concentrations, should be used as 
the primary decision-making parameters to minimize the likelihood of ototoxicity 
in multidrug-resistant tuberculosis.

Copyright © 2015, Modongo et al.

DOI: 10.1128/AAC.01050-15
PMCID: PMC4576092
PMID: 26248372 [Indexed for MEDLINE]


394. PLoS One. 2013 Oct 11;8(10):e77153. doi: 10.1371/journal.pone.0077153. 
eCollection 2013.

Association of GRM7 variants with different phenotype patterns of age-related 
hearing impairment in an elderly male Han Chinese population.

Luo H(1), Yang T, Jin X, Pang X, Li J, Chai Y, Li L, Zhang Y, Zhang L, Zhang Z, 
Wu W, Zhang Q, Hu X, Sun J, Jiang X, Fan Z, Huang Z, Wu H.

Author information:
(1)Department of Otolaryngology Head and Neck Surgery, Xinhua Hospital, Shanghai 
JiaoTong University School of Medicine, Shanghai, China ; Ear Institute, 
Shanghai JiaoTong University School of Medicine, Shanghai, China ; Department of 
Otolaryngology Head and Neck Surgery, RenJi Hospital, Shanghai JiaoTong 
University School of Medicine, Shanghai, China.

Several single nucleotide polymorphisms (SNPs) of the Glutamate metabotrophic 
receptor 7 gene (GRM7) have recently been identified by the genome-wide 
association study (GWAS) as potentially playing a role in susceptibility to 
age-related hearing impairment (ARHI), however this has not been validated in 
the Han Chinese population. The aim of this study was to determine if these SNPs 
are also associated with ARHI in an elderly male Han Chinese population. In this 
case-control candidate genes association study, a total of 982 men with ARHI and 
324 normal-hearing controls subjects were studied. Using K-means cluster 
analysis, four audiogram shape subtypes of ARHI were identified in the case 
group: ''flat shape (FL)'', ''sloping shape (SL)'', ''2-4 kHz abrupt loss (AL) 
shape'' and ''8 kHz dip (8D) shape''. Results suggested that the SNP rs11928865 
(A>T) of GRM7 was significantly associated with ARHI after adjusting for 
non-genetic factors (p = 0.000472, OR = 1.599, 95%CI = 1.229~2.081). 
Furthermore, frequency of TT genotype (rs11928865) were significant higher in 
the SL subgroup and AL subgroup with compared to controls group (p = 9.41E-05, 
OR = 1.945, 95%CI = 1.393~2.715; p = 0.000109, OR = 1.915, 95%CI = 1.378~2.661 
adjusted, respectively) after Bonferroni correction. However, there wasn't 
significant difference in the frequency of the TT genotype between cases in the 
FL subgroup or the 8D subgroup with when compared with controls. Results of the 
current study suggest that, in an elderly male Han Chinese population, GRM7 SNP 
rs11928865 (TT) occurs more frequently in ARHI patients with SL and AL phenotype 
patterns.

DOI: 10.1371/journal.pone.0077153
PMCID: PMC3795658
PMID: 24146964 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


395. Trends Amplif. 2005;9(2):77-98. doi: 10.1177/108471380500900203.

Adaptive dynamic range optimization (ADRO): a digital amplification strategy for 
hearing aids and cochlear implants.

Blamey PJ(1).

Author information:
(1)Dynamic Hearing Pty Ltd, Richmond, Victoria, Australia. 
pblamey@dynamichearing.com.au

Adaptive dynamic range optimization (ADRO) is an amplification strategy that 
uses digital signal processing techniques to improve the audibility, comfort, 
and intelligibility of sounds for people who use cochlear implants and/or 
hearing aids. The strategy uses statistical analysis to select the most 
information-rich section of the input dynamic range in multiple-frequency 
channels. Fuzzy logic rules control the gain in each frequency channel so that 
the selected section of the dynamic range is presented at an audible and 
comfortable level. The ADRO processing thus adaptively optimizes the dynamic 
range of the signal in multiple-frequency channels. Clinical studies show that 
ADRO can be fitted easily to all degrees of hearing loss for hearing aids and 
cochlear implants in a direct and intuitive manner, taking the preferences of 
the listener into account. The result is high acceptance by new and experienced 
hearing aid users and strong preferences for ADRO compared with alternative 
amplification strategies. The ADRO processing is particularly well suited to 
bimodal and hybrid stimulation which combine electric and acoustic stimulation 
in opposite ears or in the same ear, respectively.

DOI: 10.1177/108471380500900203
PMCID: PMC4111489
PMID: 16012705 [Indexed for MEDLINE]


396. Southeast Asian J Trop Med Public Health. 2005 Jul;36(4):1048-56.

Perceived industrial deafness and hearing loss among people in a small 
Queensland rural community.

Jirojwong S(1), Joubert D, Anastasi S; Wowan/Dululu Community Volunteer Group 
Inc.

Author information:
(1)Faculty of Arts, Health and Sciences, Central Queensland University, 
Rockhampton QLD, Australia. s.jirojwong@cqu.edu.au

This paper aims to describe chronic diseases including hearing loss reported by 
people in a small rural community. It will present the results of audiometric 
screening among a group of people in this community and their self reported risk 
factors of hearing loss. Different risk factors experienced by men and women 
will be compared. Two surveys were conducted in a small Queensland rural 
community. The first survey gathered information relating to chronic diseases 
among 604 people using a telephone interview method. The second survey assessed 
the level of hearing among 64 people who presented themselves for audiometric 
screening, their history of exposure to loud noise and their previous use of 
hearing protective measures. A higher rate of "industrial deafness" was reported 
(110.75 per 1,000 population) than the 1995 National rate (95.2 per 1,000 
population). Of 64 people who attended the audiometric assessment, 60 (93.8%) 
had some level of hearing loss using the 2000 International Standard of hearing 
level (ISO 7029: 2000) taking age and gender into account. However, 15 persons 
(23.4%) perceived that they had good hearing. When compared to ISO 7029: 2000 
standard, men and women had a similar pattern of hearing loss. Compared to men, 
a lower percentage of women were exposed to different sources of loud noise and 
were less likely to use hearing protection devices.

PMID: 16295567 [Indexed for MEDLINE]


397. Hear Res. 2014 Mar;309:8-16. doi: 10.1016/j.heares.2013.10.005. Epub 2013 Nov 8.

Left hemisphere fractional anisotropy increase in noise-induced tinnitus: a 
diffusion tensor imaging (DTI) study of white matter tracts in the brain.

Benson RR(1), Gattu R(2), Cacace AT(3).

Author information:
(1)Center for Neurological Studies, Novi, MI, USA.
(2)Department of Radiology, Wayne State University School of Medicine, Detroit, 
MI, USA.
(3)Department of Communication Sciences & Disorders, Wayne State University, 207 
Rackham, 60 Farnsworth, Detroit, MI 48202, USA. Electronic address: 
cacacea@wayne.edu.

Diffusion tensor imaging (DTI) is a contemporary neuroimaging modality used to 
study connectivity patterns and microstructure of white matter tracts in the 
brain. The use of DTI in the study of tinnitus is a relatively unexplored 
methodology with no studies focusing specifically on tinnitus induced by noise 
exposure. In this investigation, participants were two groups of adults matched 
for etiology, age, and degree of peripheral hearing loss, but differed by the 
presence or absence (+/-) of tinnitus. It is assumed that matching individuals 
on the basis of peripheral hearing loss, allows for differentiating changes in 
white matter microstructure due to hearing loss from changes due to the effects 
of chronic tinnitus. Alterations in white matter tracts, using the fractional 
anisotropy (FA) metric, which measures directional diffusion of water, were 
quantified using tract-based spatial statistics (TBSS) with additional details 
provided by in vivo probabilistic tractography. Our results indicate that 10 
voxel clusters differentiated the two groups, including 9 with higher FA in the 
group with tinnitus. A decrease in FA was found for a single cluster in the 
group with tinnitus. However, seven of the 9 clusters with higher FA were in 
left hemisphere thalamic, frontal, and parietal white matter. These foci were 
localized to the anterior thalamic radiations and the inferior and superior 
longitudinal fasciculi. The two right-sided clusters with increased FA were 
located in the inferior fronto-occipital fasciculus and superior longitudinal 
fasciculus. The only decrease in FA for the tinnitus-positive group was found in 
the superior longitudinal fasciculus of the left parietal lobe.

Copyright © 2013 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2013.10.005
PMID: 24212050 [Indexed for MEDLINE]


398. Ear Hear. 2012 Sep-Oct;33(5):615-6. doi: 10.1097/AUD.0b013e31824e0ba7.

Hearing disability measured by the speech, spatial, and qualities of hearing 
scale in clinically normal-hearing and hearing-impaired middle-aged persons, and 
disability screening by means of a reduced SSQ (the SSQ5).

Demeester K(1), Topsakal V, Hendrickx JJ, Fransen E, van Laer L, Van Camp G, Van 
de Heyning P, van Wieringen A.

Author information:
(1)Department of Otolaryngology, University and University Hospital of Antwerp, 
Belgium. kelly.demeester@ua.ac.be

OBJECTIVES: : The goals of the present study were twofold: in the first part, 
the prevalence and profile of hearing disability in healthy, middle-aged persons 
were determined by the speech, spatial, and qualities of hearing scale (SSQ). In 
the second part of this study, the number of SSQ items was reduced to five to 
make this questionnaire available for routine usage in clinical settings and for 
screening purposes.
METHODS: : SSQ responses derived from 103 normal-hearing 18- to 25-year-old 
persons were compared with the SSQ responses of 24 clinically normal-hearing 
(all thresholds between 125 and 8000 Hz ≤25 dB HL) and 109 healthy, 55- to 
65-year-old persons with age-related hearing impairment to determine the 
prevalence and profile of hearing disability. The 45 items of the SSQ were 
reduced to five by cluster analyses and binary logistic regression analyses. The 
robustness of this five-item version (SSQ5) was determined in three control 
populations: an adult 25- to 55-year-old population (n = 159), an ENT-patient 
population (n = 60), and a population of hearing aid candidates (n = 50). The 
feasibility of the SSQ5 for screening was compared with the feasibility of the 
simple question "Do you have hearing loss?" by determining, respectively, the 
sensitivity, specificity, and maximum achievable discriminatory power for 
predicting hearing status according to speech-in-noise performance.
RESULTS: : Prevalence numbers showed data of healthy, middle-aged persons with 
significant disability, despite minimal impairment (25%) versus data of 
middle-aged persons with significant impairment and nevertheless, minimal 
disability (61%). The profile of hearing disability seemed similar in all 
normal-hearing and hearing-impaired subgroups (i.e., most problems with 
understanding speech especially in noise conditions, and least problems with 
sound quality). Compared with the single question: "Do you have hearing loss?" 
the use of the SSQ5 had 37% more maximum discriminatory power for determining 
hearing status category based on speech-in-noise performance in 55- to 
65-year-old persons. In addition, the SSQ5 seemed robust in adult populations of 
different ages (89.6% correlation between the answers of the SSQ5 and SSQ45), as 
well as in ENT-patient populations (93.7% correlation) and hearing aid candidate 
populations (79.2% correlation).
CONCLUSIONS: : The results of this study suggest that disability measures and 
measures for hearing impairment cannot replace each other, but are 
complementary. Therefore, it is advised to implement both disability measures 
and impairment measures in screening and referral policies for hearing loss. To 
get a first impression of hearing disability, our results suggest that it is 
useful to ask five disability questions (SSQ5) instead of one general question 
like "Do you have hearing loss?"

DOI: 10.1097/AUD.0b013e31824e0ba7
PMID: 22568994 [Indexed for MEDLINE]


399. Neuroreport. 2007 Sep 17;18(14):1483-6. doi: 10.1097/WNR.0b013e3282e9a73e.

Brain activation in patients with congenital bilateral hearing impairment.

Hwang JH(1), Wu CW, Lee CW, Chen JH, Liu TC.

Author information:
(1)College of Medicine, Graduate Institute of Clinical Medicine, Chiayi, Taiwan.

Twelve patients with idiopathic, congenital, symmetric, moderate-to-severe 
sensorineural hearing loss participated in this study. Functional magnetic 
resonance imaging was performed while speech sounds were presented to each 
patient monaurally. Notable blood oxygenation level-dependent responses were 
clustered mainly in the superior temporal gyrus and transverse temporal gyrus of 
both hemispheres during right and left ear stimulation. In addition, the middle 
temporal gyrus of the right hemisphere was activated during right ear 
stimulation. The activation pattern was very similar to that of participants 
with normal hearing. Thus, as long as peripheral acoustic stimulation has not 
been totally absent from childhood, the classical activation pattern can be 
elicited in patients with congenital bilateral hearing impairment.

DOI: 10.1097/WNR.0b013e3282e9a73e
PMID: 17712279 [Indexed for MEDLINE]


400. J Pediatr. 2020 Mar;218:151-156.e2. doi: 10.1016/j.jpeds.2019.12.005. Epub 2020 
Jan 14.

A Cross-Sectional Study of Caregiver Perceptions of Congenital Cytomegalovirus 
Infection: Knowledge and Attitudes about Screening.

Diener ML(1), Shi K(2), Park AH(2).

Author information:
(1)Department of Family and Consumer Studies, University of Utah, Salt Lake 
City, UT. Electronic address: marissa.diener@fcs.utah.edu.
(2)Department of Surgery, Division of Otolaryngology-Head and Neck Surgery, 
University of Utah, Salt Lake City, UT.

OBJECTIVES: To understand caregiver knowledge of and attitudes toward congenital 
cytomegalovirus (cCMV) testing in Utah.
STUDY DESIGN: We surveyed 365 caregivers whose children were being seen in an 
otolaryngology clinic at a tertiary pediatric hospital about their knowledge of 
and attitudes toward cCMV and cCMV screening. Descriptive statistics and cluster 
analysis were used to examine their responses.
RESULTS: The majority of caregivers were unsure how cCMV was spread, the 
symptoms of cCMV, and why cCMV screening of infants was important. Most 
caregivers did not know that cCMV screening was required by law in Utah if an 
infant is referred after newborn hearing screening. A majority wanted to know if 
their child had cCMV even if asymptomatic and were willing to pay $20 for cCMV 
screening. Caregivers of children who had been tested for cCMV were 
significantly more likely to be strongly in favor of cCMV screening than 
expected by chance. Caregivers in the highly knowledgeable cluster were more 
likely to be strongly in favor of cCMV screening.
CONCLUSIONS: Caregivers frequently were unaware of cCMV and its implications. 
Attitudes toward cCMV screening generally were positive. Education on 
epidemiology and impact of cCMV may benefit both prevention of infection and 
attitudes toward screening.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jpeds.2019.12.005
PMID: 31952844 [Indexed for MEDLINE]


401. Biol Cybern. 1993;68(6):545-52. doi: 10.1007/BF00200814.

An application of mapping neural networks and a digital signal processor for 
cochlear neuroprostheses.

Zadák J(1), Unbehauen R.

Author information:
(1)Lehrstuhl für Allgemeine und Theoretische Elektrotechnik, Universität 
Erlangen-Nürnberg, Germany.

Cochlear neuroprostheses strive to restore the sensation of hearing to patients 
with a profound sensorineural deafness. They exhibit a stimulation of the 
surviving auditory nerve neurons by electrical currents delivered through 
electrodes placed on or within the cochlea. The present article describes a new 
method for an efficient derivation of the required information from the incoming 
speech signal necessary for the implant stimulation. Also some realization 
aspects of the new approach are addressed. In the new strategy, a multilayer 
neural network is employed in the formant frequency estimation having some 
suitable speech signal descriptors as particular input signals. The proposed 
method allows us a fast formant frequency estimation necessary for the implant 
stimulation. With the developed strategy, the prosthesis can be adjusted to the 
environment which the patient is supposed to live in. Moreover, the neural 
network concept offers us an alternative for dealing with the areas of neural 
loss or "holes" in the frequency map of the patient's ear.

DOI: 10.1007/BF00200814
PMID: 8324062 [Indexed for MEDLINE]


402. J Acoust Soc Am. 2019 Apr;145(4):2388. doi: 10.1121/1.5096643.

Development of an automatic classifier for the prediction of hearing impairment 
from industrial noise exposure.

Zhao Y(1), Tian Y(1), Zhang M(2), Li J(1), Qiu W(3).

Author information:
(1)Key Laboratory for Biomedical Engineering of Ministry of Education, College 
of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, 
China.
(2)Institute of Environmental and Occupational Health, Zhejiang Provincial 
Center for Disease Control and Prevention, Hangzhou, China.
(3)Auditory Research Laboratory, State University of New York at Plattsburgh, 
Plattsburgh, New York 12901, USA.

The ISO-1999 [(2013). International Organization for Standardization, Geneva, 
Switzerland] standard is the most commonly used approach for estimating 
noise-induced hearing trauma. However, its insensitivity to noise 
characteristics limits its practical application. In this study, an automatic 
classification method using the support vector machine (SVM) was developed to 
predict hearing impairment in workers exposed to both Gaussian (G) and 
non-Gaussian (non-G) industrial noises. A recently collected human database 
(N = 2,110) from industrial workers in China was used in the present study. A 
statistical metric, kurtosis, was used to characterize the industrial noise. In 
addition to using all the data as one group, the data were also broken down into 
the following four subgroups based on the level of kurtosis: G/quasi-G, 
low-kurtosis, middle-kurtosis, and high-kurtosis groups. The performance of the 
ISO-1999 and the SVM models was compared over these five groups. The results 
showed that: (1) The performance of the SVM model significantly outperformed the 
ISO-1999 model in all five groups. (2) The ISO-1999 model could not properly 
predict hearing impairment for the high-kurtosis group. Moreover, the ISO-1999 
model is likely to underestimate hearing impairment caused by both G and non-G 
noise exposures. (3) The SVM model is a potential tool to predict hearing 
impairment caused by diverse noise exposures.

DOI: 10.1121/1.5096643
PMID: 31046337 [Indexed for MEDLINE]


403. Hear Res. 2016 Oct;340:185-190. doi: 10.1016/j.heares.2016.01.016. Epub 2016 Feb 
4.

Indication of direct acoustical cochlea stimulation in comparison to cochlear 
implants.

Kludt E(1), Büchner A(2), Schwab B(2), Lenarz T(2), Maier H(2).

Author information:
(1)Cluster of Excellence Hearing4all, Germany; Dept. of Otolaryngology, Medical 
University Hannover, Hannover, Germany. Electronic address: 
Kludt.Eugen@MH-Hannover.de.
(2)Cluster of Excellence Hearing4all, Germany; Dept. of Otolaryngology, Medical 
University Hannover, Hannover, Germany.

The new implantable hearing system Codacs™ was designed to close the treatment 
gap between active middle ear implants and cochlear implants in cases of 
severe-to-profound mixed hearing loss. The Codacs™ actuator is attached to 
conventional stapes prosthesis during the implantation and thereby provides 
acoustical stimulation through a stapedotomy to the cochlea. Cochlear implants 
(CIs) on the other hand are an established treatment option for profoundly deaf 
patients including mixed hearing losses that are possible candidates for the 
Codacs™. In this retrospective study, we compared the clinical outcome of 25 
patients with the Codacs™ (≥3 month post-activation) to 54 CI patients (two 
years post-activation) with comparable pre-operative bone conduction (BC) 
thresholds that were potential candidates for both categories of devices. The 
word recognition score (Freiburg monosyllables test) in quiet was significantly 
(p < 0.05) better in the Codacs™ than in the corresponding CI patients for 
average pre-operative bone conduction below 60 dB HL and equal in patients with 
a pre-operative BC PTA between 60 and 70 dB HL. Speech in noise intelligibility 
(HSM sentences test at +10 dB SNR) was significantly (p < 0.001) better in 
Codacs™ (80% median) than in CI patients (25% median) in all tested groups. Our 
results indicate for patients with sufficient cochlear reserve that speech 
intelligibility in noise with the Codacs™ hearing implant is significantly 
better than with a CI. Further, results in Codacs™ were better predictable, 
encouraging the extension of the indication to patients with less cochlear 
reserve than reported here.

Copyright © 2016 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.01.016
PMID: 26836967 [Indexed for MEDLINE]


404. Hear Res. 1995 Mar;83(1-2):62-79. doi: 10.1016/0378-5955(94)00192-s.

Toxicodynamics and toxicokinetics of amikacin in the guinea pig cochlea.

Beaubien AR(1), Karpinski K, Ormsby E.

Author information:
(1)Biopharmaceutics and Pharmacodynamics Division, Ottawa, Ontario, Canada.

An extensive overview of the relationship between cochlear toxicity and amikacin 
blood concentrations in the guinea pig is provided which should assist in the 
clinical application of this class of antibiotic. A data set previously used to 
relate the incidence of amikacin ototoxicity to dosing rates and blood 
concentrations was re-examined to assess the toxicodynamics of amikacin in terms 
of decibels of hearing loss across dosing rate, hearing frequency and time 
following drug exposure. Animals in this data set had received continuously i.v. 
infused amikacin over an 8-fold range of dosing rates. Preliminary analysis 
indicated that the data were consistent with a sigmoid relationship between 
hearing loss (decibels) and area under the amikacin plasma concentration vs time 
curve cumulated over the entire course of drug administration (cAUC). The 
sigmoid model was therefore used as the backbone of a far more comprehensive 
toxicodynamic model which described all the data with a single equation. Testing 
with this model showed that the cAUC required to produce half-maximum hearing 
loss (cAUC-1/2) was related to dosing rate (P < 0.01), to hearing frequency (P < 
0.00001), and to post-drug interval (P < 0.00001). Maximum hearing loss 
(difference between upper and lower sigmoid asymptotes) was less than total and 
was significantly related to frequency (P < 0.00001). No effects could be 
detected on the sigmoid slope. Further modelling of the significant effects 
detected by the comprehensive toxicodynamic model was done to determine if they 
could be described by simple relationships or by biologically relevant 
sub-models. Modelling of maximum hearing loss (postulated to represent loss of 
mainly outer hair cell function) indicated that this parameter was constant at 
about 61 decibels for 2-12 kHz and linearly decreased with log frequency for 
frequencies > 12 kHz. Modelling of cAUC-1/2 on frequency indicated that there 
was a strong inverse linear relationship to log frequency. Modelling of cAUC-1/2 
on post-drug interval indicated that delayed ototoxicity continued at 
progressively slower rates for at least 56 days after drug administration had 
ceased. Modelling of cAUC-1/2 on dosing rate showed an increased requirement for 
drug as the dosing rate decreased. However, cAUC-1/2 changed no more than 20% 
across the range of dosing rates compared to the 8-fold difference in mean 
steady-state plasma concentrations, suggesting that plasma concentration is not 
a primary determinant of ototoxicity. A toxicokinetic model was developed which 
explained the dosing rate effect on cAUC-1/2 very successfully.(ABSTRACT 
TRUNCATED AT 400 WORDS)

DOI: 10.1016/0378-5955(94)00192-s
PMID: 7607992 [Indexed for MEDLINE]


405. Hear Res. 2016 Oct;340:161-168. doi: 10.1016/j.heares.2015.12.019. Epub 2015 Dec 
23.

Outer ear canal sound pressure and bone vibration measurement in SSD and CHL 
patients using a transcutaneous bone conduction instrument.

Ghoncheh M(1), Lilli G(1), Lenarz T(2), Maier H(3).

Author information:
(1)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany.
(2)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany; Cluster of Excellence Hearing4all, 
Germany.
(3)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany; Cluster of Excellence Hearing4all, 
Germany. Electronic address: Maier.Hannes@MH-Hannover.de.

The intraoperative and postoperative objective functional assessment of 
transcutaneous bone conduction implants is still a challenge. Here we compared 
intraoperative Laser-Doppler-vibrometry (LDV, Polytec Inc.) to measure vibration 
of the bone close to the implant to Outer Ear Canal Sound Pressure Level 
(OEC-SPL) measurements. Twelve single sided deafness (SSD) patients with 
contralateral intact ossicular chains and eight bilateral conductive hearing 
loss (CHL) patients were included in the study. SSD patients had a minor average 
air-bone-gap (ABG) of 0.4 ± 0.4 dB (0.5, 1, 2, 4 kHz mean value (MV) ± standard 
deviation (SD)) on the contralateral side where a normal transmission between 
cochlea and the tympanic membrane can be assumed. CHL patients had an impaired 
middle ear transmission with a mean ABG of 46.0 ± 7.9 dB (MV±SD). Vibration and 
OEC-SPL responses could reliably be recorded with a minimal signal-to-noise 
ratio of at least 12 dB. Average OEC-SPL on the contralateral side and 
intraoperative vibration measurements were strongly correlated in SSD 
(r2 = 0.75) and CHL (r2 = 0.86) patients. The correlation in individual results 
between OEC-SPL and vibration measurements was weak, indicating some underlying 
inter-individual variability. The high correlation of average responses showed 
that OEC-SPL are closely linked to bone vibration, although both cannot be 
equivalently used for intraoperative testing due to the high variability in 
individual results. On the other hand, OEC-SPL provides an easy and affordable 
measurement tool to monitor stability and functionality postoperatively using 
individual reference measurements. We observed no significant differences 
(t-test, p < 0.05) by comparing results from contralateral OEC-SPL in twelve SSD 
and eight CHL patients at frequencies between 0.5 and 8 kHz. This implies that 
the part of the measured sound pressure in the ear canal originating from the 
cochlea and emitted by the tympanic is not dominant and OEC-SPL is mainly due to 
vibration of the external ear-canal walls as the only other pathway of BC sound 
to reach the ear canal. In addition, the transcranial attenuation (contralateral 
outer ear canal sound pressure divided by ipsilateral) was compared to previous 
studies measuring vibration by LDV and accelerometer. The trend in the average 
transcranial attenuation in patients was similar to previous studies measuring 
the OEC-SPL with less than 5 dB difference.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.12.019
PMID: 26723102 [Indexed for MEDLINE]


406. Trends Hear. 2018 Jan-Dec;22:2331216518781746. doi: 10.1177/2331216518781746.

Coherent Coding of Enhanced Interaural Cues Improves Sound Localization in Noise 
With Bilateral Cochlear Implants.

Williges B(1), Jürgens T(1)(2), Hu H(1), Dietz M(1)(3).

Author information:
(1)1 Medizinische Physik and Cluster of Excellence "Hearing4all," Carl von 
Ossietzky Universität Oldenburg, Oldenburg, Germany.
(2)2 Institute of Acoustics, University of Applied Sciences Lübeck, Lübeck, 
Germany.
(3)3 National Centre for Audiology, School of Communication Sciences and 
Disorders, Western University, London, Ontario, Canada.

Bilateral cochlear implant (BCI) users only have very limited spatial hearing 
abilities. Speech coding strategies transmit interaural level differences (ILDs) 
but in a distorted manner. Interaural time difference (ITD) information 
transmission is even more limited. With these cues, most BCI users can coarsely 
localize a single source in quiet, but performance quickly declines in the 
presence of other sound. This proof-of-concept study presents a novel signal 
processing algorithm specific for BCIs, with the aim to improve sound 
localization in noise. The core part of the BCI algorithm duplicates a 
monophonic electrode pulse pattern and applies quasistationary natural or 
artificial ITDs or ILDs based on the estimated direction of the dominant source. 
Three experiments were conducted to evaluate different algorithm variants: 
Experiment 1 tested if ITD transmission alone enables BCI subjects to lateralize 
speech. Results showed that six out of nine BCI subjects were able to lateralize 
intelligible speech in quiet solely based on ITDs. Experiments 2 and 3 assessed 
azimuthal angle discrimination in noise with natural or modified ILDs and ITDs. 
Angle discrimination for frontal locations was possible with all variants, 
including the pure ITD case, but for lateral reference angles, it was only 
possible with a linearized ILD mapping. Speech intelligibility in noise, 
limitations, and challenges of this interaural cue transmission approach are 
discussed alongside suggestions for modifying and further improving the BCI 
algorithm.

DOI: 10.1177/2331216518781746
PMCID: PMC6048749
PMID: 29956589 [Indexed for MEDLINE]


407. J Comput Neurosci. 2011 Apr;30(2):279-99. doi: 10.1007/s10827-010-0256-1. Epub 
2010 Jul 10.

Can homeostatic plasticity in deafferented primary auditory cortex lead to 
travelling waves of excitation?

Chrostowski M(1), Yang L, Wilson HR, Bruce IC, Becker S.

Author information:
(1)McMaster Integrative Neuroscience Discovery & Study, McMaster University, 
1280 Main Street West, Hamilton, ON, Canada. chrostm@mcmaster.ca

Travelling waves of activity in neural circuits have been proposed as a 
mechanism underlying a variety of neurological disorders, including epileptic 
seizures, migraine auras and brain injury. The highly influential Wilson-Cowan 
cortical model describes the dynamics of a network of excitatory and inhibitory 
neurons. The Wilson-Cowan equations predict travelling waves of activity in 
rate-based models that have sufficiently reduced levels of lateral inhibition. 
Travelling waves of excitation may play a role in functional changes in the 
auditory cortex after hearing loss. We propose that down-regulation of lateral 
inhibition may be induced in deafferented cortex via homeostatic plasticity 
mechanisms. We use the Wilson-Cowan equations to construct a spiking model of 
the primary auditory cortex that includes a novel, mathematically formalized 
description of homeostatic plasticity. In our model, the homeostatic mechanisms 
respond to hearing loss by reducing inhibition and increasing excitation, 
producing conditions under which travelling waves of excitation can emerge. 
However, our model predicts that the presence of spontaneous activity prevents 
the development of long-range travelling waves of excitation. Rather, our 
simulations show short-duration excitatory waves that cancel each other out. We 
also describe changes in spontaneous firing, synchrony and tuning after 
simulated hearing loss. With the exception of shifts in characteristic 
frequency, changes after hearing loss were qualitatively the same as empirical 
findings. Finally, we discuss possible applications to tinnitus, the perception 
of sound without an external stimulus.

DOI: 10.1007/s10827-010-0256-1
PMID: 20623168 [Indexed for MEDLINE]


408. Hear Res. 2003 Jun;180(1-2):28-38. doi: 10.1016/s0378-5955(03)00074-1.

Changes in spontaneous firing rate and neural synchrony in cat primary auditory 
cortex after localized tone-induced hearing loss.

Seki S(1), Eggermont JJ.

Author information:
(1)Departments of Physiology and Biophysics, and Psychology, University of 
Calgary, 2500 University Drive N.W., Calgary, AB, Canada T2N 1N4.

Increase in spontaneous neural activity after noise-induced hearing loss has 
frequently been associated with the phenomenon of tinnitus. Eighteen juvenile 
and adult cats were exposed for 2 h to a 6 kHz tone with an intensity of 115 dB 
SPL at the cat's head. Seven non-exposed littermates and seven other normal 
hearing cats were used as age-matched controls. The trauma cats showed localized 
hearing losses, as assessed by ABR, ranging from less than 20 to 60 dB. The 
frequency representation in primary auditory cortex was mapped using an 
eight-electrode array. Single-unit spontaneous activity was recorded for 15 min. 
Peak cross-correlation coefficients (R) for unit cluster activity recorded on 
separate electrodes were calculated. We found elevated spontaneous firing rates 
in regions with reorganization of the tonotopic map compared to the neurons in 
the non-reorganized cortical regions in the same animals. A second finding was 
that in these regions the peak cross-correlation coefficients were also 
increased relative to the non-reorganized parts. A third finding was that 
exposed animals showed higher spontaneous activity compared to controls 
regardless of the presence of cortical reorganization. This may be a correlate 
of tinnitus in the presence of only minor hearing losses.

DOI: 10.1016/s0378-5955(03)00074-1
PMID: 12782350 [Indexed for MEDLINE]


409. Audiol Neurootol. 2016;21(5):305-315. doi: 10.1159/000452123. Epub 2016 Nov 19.

Consequences of Stimulus Type on Higher-Order Processing in Single-Sided Deaf 
Cochlear Implant Users.

Finke M(1), Sandmann P, Bönitz H, Kral A, Büchner A.

Author information:
(1)Cluster of Excellence ''Hearing4all'', Hannover Medical School, Hannover, 
Germany.

Single-sided deaf subjects with a cochlear implant (CI) provide the unique 
opportunity to compare central auditory processing of the electrical input (CI 
ear) and the acoustic input (normal-hearing, NH, ear) within the same 
individual. In these individuals, sensory processing differs between their two 
ears, while cognitive abilities are the same irrespectively of the sensory 
input. To better understand perceptual-cognitive factors modulating speech 
intelligibility with a CI, this electroencephalography study examined the 
central-auditory processing of words, the cognitive abilities, and the speech 
intelligibility in 10 postlingually single-sided deaf CI users. We found lower 
hit rates and prolonged response times for word classification during an oddball 
task for the CI ear when compared with the NH ear. Also, event-related 
potentials reflecting sensory (N1) and higher-order processing (N2/N4) were 
prolonged for word classification (targets versus nontargets) with the CI ear 
compared with the NH ear. Our results suggest that speech processing via the CI 
ear and the NH ear differs both at sensory (N1) and cognitive (N2/N4) processing 
stages, thereby affecting the behavioral performance for speech discrimination. 
These results provide objective evidence for cognition to be a key factor for 
speech perception under adverse listening conditions, such as the degraded 
speech signal provided from the CI.

© 2016 S. Karger AG, Basel.

DOI: 10.1159/000452123
PMID: 27866186 [Indexed for MEDLINE]


410. Hear Res. 2016 May;335:207-219. doi: 10.1016/j.heares.2016.03.007. Epub 2016 Apr 
2.

Categorization of common sounds by cochlear implanted and normal hearing adults.

Collett E(1), Marx M(2), Gaillard P(3), Roby B(2), Fraysse B(4), Deguine O(2), 
Barone P(5).

Author information:
(1)Université de Toulouse, CerCo UMR 5549 CNRS, Université Paul Sabatier, 
Toulouse, France; Université de Toulouse, CerCo UMR 5549 CNRS, Faculté de 
Médecine de Purpan, Toulouse, France; Advanced Bionics SARL, France.
(2)Université de Toulouse, CerCo UMR 5549 CNRS, Université Paul Sabatier, 
Toulouse, France; Université de Toulouse, CerCo UMR 5549 CNRS, Faculté de 
Médecine de Purpan, Toulouse, France; Service d'Oto-Rhino-Laryngologie et 
Oto-Neurologie, Hopital Purpan, Toulouse, France.
(3)Université de Toulouse, CLLE UMR 5263, CNRS, UT2J, Université de Toulouse 
Jean-Jaurès, Toulouse, France.
(4)Service d'Oto-Rhino-Laryngologie et Oto-Neurologie, Hopital Purpan, Toulouse, 
France.
(5)Université de Toulouse, CerCo UMR 5549 CNRS, Université Paul Sabatier, 
Toulouse, France; Université de Toulouse, CerCo UMR 5549 CNRS, Faculté de 
Médecine de Purpan, Toulouse, France. Electronic address: 
Pascal.barone@cerco.ups-tlse.fr.

Auditory categorization involves grouping of acoustic events along one or more 
shared perceptual dimensions which can relate to both semantic and physical 
attributes. This process involves both high level cognitive processes 
(categorization) and low-level perceptual encoding of the acoustic signal, both 
of which are affected by the use of a cochlear implant (CI) device. The goal of 
this study was twofold: I) compare the categorization strategies of CI users and 
normal hearing listeners (NHL) II) investigate if any characteristics of the raw 
acoustic signal could explain the results. 16 experienced CI users and 20 NHL 
were tested using a Free-Sorting Task of 16 common sounds divided into 3 
predefined categories of environmental, musical and vocal sounds. Multiple 
Correspondence Analysis (MCA) and Hierarchical Clustering based on Principal 
Components (HCPC) show that CI users followed a similar categorization strategy 
to that of NHL and were able to discriminate between the three different types 
of sounds. However results for CI users were more varied and showed less 
inter-participant agreement. Acoustic analysis also highlighted the average 
pitch salience and average autocorrelation peak as being important for the 
perception and categorization of the sounds. The results therefore show that on 
a broad level of categorization CI users may not have as many difficulties as 
previously thought in discriminating certain kinds of sound; however the 
perception of individual sounds remains challenging.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.03.007
PMID: 27050944 [Indexed for MEDLINE]


411. Int J Mol Sci. 2012;13(7):8171-8188. doi: 10.3390/ijms13078171. Epub 2012 Jul 2.

Proteomic analysis of the organ of corti using nanoscale liquid chromatography 
coupled with tandem mass spectrometry.

Peng H(1)(2), Liu M(1), Pecka J(3), Beisel KW(3), Ding SJ(1)(4).

Author information:
(1)Department of Pathology and Microbiology, University of Nebraska Medical 
Center, Omaha, NE 68198, USA.
(2)Department of Environmental, Agricultural & Occupational Health, University 
of Nebraska Medical Center, Omaha, NE 68198, USA.
(3)Department of Biomedical Sciences, Creighton University, Omaha, NE 68178, 
USA.
(4)Mass Spectrometry and Proteomics Core Facility, University of Nebraska 
Medical Center, Omaha, NE 68198, USA.

The organ of Corti (OC) in the cochlea plays an essential role in auditory 
signal transduction in the inner ear. For its minute size and trace amount of 
proteins, the identification of the molecules in pathophysiologic processes in 
the bone-encapsulated OC requires both delicate separation and a highly 
sensitive analytical tool. Previously, we reported the development of a high 
resolution metal-free nanoscale liquid chromatography system for highly 
sensitive phosphoproteomic analysis. Here this system was coupled with a 
LTQ-Orbitrap XL mass spectrometer to investigate the OC proteome from normal 
hearing FVB/N male mice. A total of 628 proteins were identified from six 
replicates of single LC-MS/MS analysis, with a false discovery rate of 1% using 
the decoy database approach by the OMSSA search engine. This is currently the 
largest proteome dataset for the OC. A total of 11 proteins, including cochlin, 
myosin VI, and myosin IX, were identified that when defective are associated 
with hearing impairment or loss. This study demonstrated the effectiveness of 
our nanoLC-MS/MS platform for sensitive identification of hearing 
loss-associated proteins from minute amount of tissue samples.

DOI: 10.3390/ijms13078171
PMCID: PMC3430228
PMID: 22942697 [Indexed for MEDLINE]


412. Pediatrics. 2011 Nov;128(5):e1139-46. doi: 10.1542/peds.2011-0770. Epub 2011 Oct 
10.

Randomized trial of a hearing conservation intervention for rural students: 
long-term outcomes.

Marlenga B(1), Linneman JG, Pickett W, Wood DJ, Kirkhorn SR, Broste SK, Knobloch 
MJ, Berg RL.

Author information:
(1)National Farm Medicine Center, Marshfield Clinic Research Foundation, 
Marshfield, WI 54449, USA. marlenga.barbara@mcrf.mfldclin.edu

OBJECTIVES: We had the rare opportunity to conduct a cluster-randomized 
controlled trial to observe the long-term (16-year) effects of a well-designed 
hearing conservation intervention for rural high school students. This trial 
assessed whether the intervention resulted in (1) reduced prevalence of 
noise-induced hearing loss (NIHL) assessed clinically and/or (2) sustained use 
of hearing protection devices.
METHODS: In 1992-1996, 34 rural Wisconsin schools were recruited and 17 were 
assigned randomly to receive a comprehensive, 3-year, hearing conservation 
intervention. In 2009-2010, extensive efforts were made to find and contact all 
students who completed the original trial. Participants in the 16-year follow-up 
study completed an exposure history questionnaire and a clinical audiometric 
examination. Rates of NIHL and use of hearing protection were compared.
RESULTS: We recruited 392 participants from the original trial, 200 (53%) from 
the intervention group and 192 (51%) from the control group. Among participants 
with exposure to agricultural noise, the intervention group reported 
significantly greater use of hearing protection compared with the control group 
(25.9% vs 19.6%; P = .015). The intervention group also reported significantly 
greater use of hearing protection for shooting guns (56.2% vs 41.6%; P = .029), 
but the groups reported similar uses of protection in other contexts. There was 
no significant difference between groups with respect to objective measures of 
NIHL.
CONCLUSION: This novel trial provides objective evidence that a comprehensive 
educational intervention by itself may be of limited effectiveness in preventing 
NIHL in a young rural population.

DOI: 10.1542/peds.2011-0770
PMID: 21987700 [Indexed for MEDLINE]


413. Ear Hear. 2023 Jul-Aug 01;44(4):877-893. doi: 10.1097/AUD.0000000000001336. Epub 
2023 Mar 13.

Changing the Paradigm for School Hearing Screening Globally: Evaluation of 
Screening Protocols From Two Randomized Trials in Rural Alaska.

Robler SK(1)(2), Platt A(3)(4), Jenson CD(2), Meade Inglis S(1)(3)(5), 
Hofstetter P(6), Ross AA(5)(7), Wang NY(8)(9), Labrique A(10), Gallo JJ(11), 
Egger JR(3), Emmett SD(5)(7)(12).

Author information:
(1)Department of Otolaryngology, Head & Neck Surgery, University of Arkansas for 
Medical Sciences, Little Rock, Arkansas, USA.
(2)Department of Audiology, Norton Sound Health Corporation, Nome, Alaska, USA.
(3)Duke Global Health Institute, Durham, North Carolina, USA.
(4)Department of Biostatistics & Bioinformatics, Duke School of Medicine, 
Durham, North Carolina, USA.
(5)Center for Health Policy and Inequalities Research, Duke University, Durham, 
North Carolina, USA.
(6)Petersburg Medical Center, Petersburg, Alaska, USA.
(7)Department of Head and Neck Surgery and Communication Sciences, Duke 
University School of Medicine, Durham, North Carolina, USA.
(8)Department of Medicine, Johns Hopkins University School of Medicine, 
Baltimore, Maryland, USA.
(9)Departments of Biostatistics and Epidemiology, Johns Hopkins Bloomberg School 
of Public Health, Baltimore, Maryland, USA.
(10)Department of International Health, Johns Hopkins Bloomberg School of Public 
Health, Baltimore, Maryland, USA.
(11)Department of Mental Health, Johns Hopkins Bloomberg School of Public 
Health, Baltimore, Maryland, USA.
(12)Department of Epidemiology, Fay W. Boozman College of Public Health, 
University of Arkansas for Medical Sciences, Little Rock, Arkansas, USA.

OBJECTIVES: Diagnostic accuracy was evaluated for various screening tools, 
including mobile health (mHealth) pure-tone screening, tympanometry, distortion 
product otoacoustic emissions (DPOAE), and inclusion of high frequencies to 
determine the most accurate screening protocol for identifying children with 
hearing loss in rural Alaska where the prevalence of middle ear disease is high.
DESIGN: Hearing screening data were collected as part of two cluster randomized 
trials conducted in 15 communities in rural northwest Alaska. All children 
enrolled in school from preschool to 12th grade were eligible. Analysis was 
limited to data collected 2018 to 2019 (n = 1449), when both trials were running 
and measurement of high frequencies were included in the protocols. Analyses 
included estimates of diagnostic accuracy for each screening tool, as well as 
exploring performance by age and grade. Multiple imputation was used to assess 
diagnostic accuracy in younger children, where missing data were more prevalent 
due to requirements for conditioned responses. The audiometric reference 
standard included otoscopy, tympanometry, and high frequencies to ensure 
detection of infection-related and noise-induced hearing loss.
RESULTS: Both the mHealth pure-tone screen and DPOAE screen performed better 
when tympanometry was added to the protocol (increase in sensitivity of 19.9%, 
95% Confidence Interval (CI): 15.9 to 24.1 for mHealth screen, 17.9%, 95% CI: 
14.0 to 21.8 for high-frequency mHealth screen, and 10.4%, 95% CI: 7.5 to 13.9 
for DPOAE). The addition of 6 kHz to the mHealth pure-tone screen provided an 
8.7 percentage point improvement in sensitivity (95% CI: 6.5 to 11.3). 
Completeness of data for both the reference standard and the mHealth screening 
tool differed substantially by age, due to difficulty with behavioral testing in 
young children. By age 7, children were able to complete behavioral testing, and 
data indicated that high-frequency mHealth pure-tone screen with tympanometry 
was the superior tool for children 7 years and older. For children 3 to 6 years 
of age, DPOAE plus tympanometry performed the best, both for complete data and 
multiply imputed data, which better approximates accuracy for children with 
missing data.
CONCLUSIONS: This study directly evaluated pure-tone, DPOAE, and tympanometry 
tools as part of school hearing screening in rural Alaskan children (3 to 18+ 
years). Results from this study indicate that tympanometry is a key component in 
the hearing screening protocol, particularly in environments with higher 
prevalence of infection-related hearing loss. DPOAE is the preferred hearing 
screening tool when evaluating children younger than 7 years of age (below 2nd 
grade in the United States) due to the frequency of missing data with behavioral 
testing in this age group. For children 7 years and older, the addition of high 
frequencies to pure-tone screening increased the accuracy of screening, likely 
due to improved identification of hearing loss from noise exposure. The lack of 
a consistent reference standard in the literature makes comparing across studies 
challenging. In our study with a reference standard inclusive of otoscopy, 
tympanometry, and high frequencies, less than ideal sensitivities were found 
even for the most sensitive screening protocols, suggesting more investigation 
is necessary to ensure screening programs are appropriately identifying noise- 
and infection-related hearing loss in rural, low-resource settings.

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001336
PMCID: PMC10262989
PMID: 36907833 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


414. Cochlear Implants Int. 2019 Jul;20(4):190-206. doi: 
10.1080/14670100.2019.1590499. Epub 2019 Mar 18.

The effect of cross-over frequency on binaural hearing performance of adults 
using electric-acoustic stimulation.

Incerti PV(1)(2)(3), Ching TY(1)(2), Cowan R(2)(3).

Author information:
(1)a National Acoustic Laboratories , Australian Hearing , Sydney , NSW 2109 , 
Australia.
(2)b The Hearing CRC , Melbourne , Australia.
(3)c Department of Audiology and Speech Pathology , The University of Melbourne 
, Melbourne , Australia.

Objective: To investigate the effect of varying cross-over frequency (CF) 
settings for electric-acoustic (EA) stimulation in one ear combined with 
acoustic (A) hearing in the opposite ear on binaural speech perception, 
localization and functional performance in real life. Methods: Performance with 
three different CF settings set according to audiometric-based criterion were 
compared, following a four week familiarisation period with each, in ten adult 
cochlear implant recipients with residual hearing in both ears. On completion of 
all trials participants selected their preferred CF setting. Results: On 
average, CF settings did not have a significant effect on performance scores. 
However, higher ratings on device usage were associated with the preferred CF 
settings. Conclusion: Individuals who use EA + A stimulation may benefit from 
access to different CF settings to achieve maximal device usage.

DOI: 10.1080/14670100.2019.1590499
PMID: 30880646 [Indexed for MEDLINE]


415. Hear Res. 2013 Feb;296:60-6. doi: 10.1016/j.heares.2012.11.023. Epub 2012 Dec 5.

Comodulation masking release induced by controlled electrical stimulation of 
auditory nerve fibers.

Zirn S(1), Hempel JM, Schuster M, Hemmert W.

Author information:
(1)Department of Otolaryngology (ENT)/ Head & Neck Surgery, University Medical 
Center of the Ludwig-Maximilians-University Munich, Marchioninistr. 15, 81377 
München, Germany. Stefan.Zirn@med.uni-muenchen.de

Normal-hearing listeners can perceptually segregate concurrent sound sources, 
but listeners with significant hearing loss or who wear a cochlear implant (CI) 
lag behind in this ability. Perceptual grouping mechanisms are essential to 
segregate concurrent sound sources and affect comodulation masking release 
(CMR). Thus, CMR measurements in CI users could shed light on segregation cues 
needed for forming and grouping of auditory objects. CMR illustrates the fact 
that detection of a target sound embedded in a fluctuating masker is improved by 
the addition of masker energy remote from the target frequency, provided the 
envelope fluctuations across masker components are coherent. We modified such a 
CMR experiment to electrically-induced hearing using direct stimulation and 
measured the effect in 21 CI users. Cluster analysis of our data revealed two 
groups: one showed no or only small CMR of 0.1 dB ± 2.7 (N = 14) and a second 
group achieved a CMR of 10.7 dB ± 3.2 (N = 7), a value that is close to the 
enhancement observed in a comparable acoustic experiment in normal-hearing 
listeners (12.9 dB ± 2.6, N = 6). Interestingly, we observed that CMR in CI 
users may relate to hearing etiology and duration of hearing loss 
pre-implantation. Our study demonstrates for the first time that a substantial 
minority of cochlear-implant listeners (about a third) can show significant CMR. 
This outcome motivates the development of physiologically inspired multi-band 
gain control and/or different coding strategies for these groups in order to 
better preserve coherent modulation and thus to take advantage of the individual 
remaining capabilities to analyze spectro-temporal patterns.

Copyright © 2012 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2012.11.023
PMID: 23220120 [Indexed for MEDLINE]


416. Otol Neurotol. 2016 Feb;37(2):e82-95. doi: 10.1097/MAO.0000000000000915.

Long-term Communication Outcomes for Children Receiving Cochlear Implants 
Younger Than 12 Months: A Multicenter Study.

Dettman SJ(1), Dowell RC, Choo D, Arnott W, Abrahams Y, Davis A, Dornan D, Leigh 
J, Constantinescu G, Cowan R, Briggs RJ.

Author information:
(1)*University of Melbourne, HEARing CRC, Cochlear Implant Clinic, Royal 
Victorian Eye and Ear Hospital †University of Melbourne, HEARing CRC ‡Hear and 
Say Centre §The Shepherd Centre ||Cochlear Implant Clinic, Royal Victorian Eye 
and Ear Hospital ¶University of Melbourne, HEARing CRC #University of Melbourne, 
HEARing CRC, Royal Victorian Eye and Ear Hospital, East Melbourne, Victoria, 
Australia.

OBJECTIVE: Examine the influence of age at implant on speech perception, 
language, and speech production outcomes in a large unselected paediatric 
cohort.
STUDY DESIGN: This study pools available assessment data (collected 
prospectively and entered into respective databases from 1990 to 2014) from 
three Australian centers.
PATIENTS: Children (n = 403) with congenital bilateral severe to profound 
hearing loss who received cochlear implants under 6 years of age (excluding 
those with acquired onset of profound hearing loss after 12 mo, those with 
progressive hearing loss and those with mild/moderate/severe additional 
cognitive delay/disability).
MAIN OUTCOME MEASURE(S): Speech perception; open-set words (scored for words and 
phonemes correct) and sentence understanding at school entry and late primary 
school time points. Language; PLS and PPVT standard score equivalents at school 
entry, CELF standard scores. Speech Production; DEAP percentage accuracy of 
vowels, consonants, phonemes-total and clusters, and percentage 
word-intelligibility at school entry.
RESULTS: Regression analysis indicated a significant effect for age-at-implant 
for all outcome measures. Cognitive skills also accounted for significant 
variance in all outcome measures except open-set phoneme scores. ANOVA with 
Tukey pairwise comparisons examined group differences for children implanted 
younger than 12 months (Group 1), between 13 and 18 months (Group 2), between 19 
and 24 months (Group 3), between 25 and 42 months (Group 4), and between 43 and 
72 months (Group 5). Open-set speech perception scores for Groups 1, 2, and 3 
were significantly higher than Groups 4 and 5. Language standard scores for 
Group 1 were significantly higher than Groups 2, 3, 4, and 5. Speech production 
outcomes for Group 1 were significantly higher than scores obtained for Groups 
2, 3, and 4 combined. Cross tabulation and χ2 tests supported the hypothesis 
that a greater percentage of Group 1 children (than Groups 2, 3, 4, or 5) 
demonstrated language performance within the normative range by school entry.
CONCLUSIONS: Results support provision of cochlear implants younger than 12 
months of age for children with severe to profound hearing loss to optimize 
speech perception and subsequent language acquisition and speech production 
accuracy.

DOI: 10.1097/MAO.0000000000000915
PMID: 26756160 [Indexed for MEDLINE]


417. Clin Linguist Phon. 2015 Mar;29(3):216-35. doi: 10.3109/02699206.2014.987926. 
Epub 2014 Dec 9.

Segmental and suprasegmental properties in nonword repetition--an explorative 
study of the associations with nonword decoding in children with normal hearing 
and children with bilateral cochlear implants.

Nakeva Von Mentzer C(1), Lyxell B, Sahlén B, Dahlström Ö, Lindgren M, Ors M, 
Kallioinen P, Engström E, Uhlén I.

Author information:
(1)Department of Behavioral Sciences and Learning, Swedish Institute for 
Disability Research, Linköping University , Linköping , Sweden .

This study explored nonword repetition (NWR) and nonword decoding in 
normal-hearing (NH) children and in children with bilateral cochlear implants 
(CI). Participants were 11 children, with CI, 5:0-7:11 years (M = 6.5 years), 
and 11 NH children, individually age-matched to the children with CI. This study 
fills an important gap in research, since it thoroughly describes detailed 
aspects of NWR and nonword decoding and their possible associations. All 
children were assessed after having practiced with a computer-assisted reading 
intervention with a phonics approach during four weeks. Results showed that NH 
children outperformed children with CI on the majority of aspects of NWR. The 
analysis of syllable number in NWR revealed that children with CI made more 
syllable omissions than did the NH children, and predominantly in prestressed 
positions. In addition, the consonant cluster analysis in NWR showed 
significantly more consonant omissions and substitutions in children with CI 
suggesting that reaching fine-grained levels of phonological processing was 
particularly difficult for these children. No significant difference was found 
for nonword-decoding accuracy between the groups, as measured by whole words 
correct and phonemes correct, but differences were observed regarding error 
patterns. In children with CI phoneme, deletions occurred significantly more 
often than in children with NH. The correlation analysis revealed that the 
ability to repeat consonant clusters in NWR had the strongest associations to 
nonword decoding in both groups. The absence of as frequent significant 
associations between NWR and nonword decoding in children with CI compared to 
children with NH suggest that these children partly use other decoding 
strategies to compensate for less precise phonological knowledge, for example, 
lexicalizations in nonword decoding, specifically, making a real word of a 
nonword.

DOI: 10.3109/02699206.2014.987926
PMID: 25489675 [Indexed for MEDLINE]


418. Int J Audiol. 2015 Feb;54(2):136-41. doi: 10.3109/14992027.2014.952458. Epub 
2014 Sep 8.

Development of a German reading span test with dual task design for application 
in cognitive hearing research.

Carroll R(1), Meis M, Schulte M, Vormann M, Kießling J, Meister H.

Author information:
(1)* Cluster of Excellence 'Hearing4all' , Oldenburg , Germany.

OBJECTIVE: To report the development of a standardized German version of a 
reading span test (RST) with a dual task design. Special attention was paid to 
psycholinguistic control of the test items and time-sensitive scoring. We aim to 
establish our RST version to use for determining an individual's working memory 
in the framework of hearing research in German contexts.
DESIGN: RST stimuli were controlled and pretested for psycholinguistic factors. 
The RST task was to read sentences, quickly determine their plausibility, and 
later recall certain words to determine a listener's individual reading span. 
RST results were correlated with outcomes of additional sentence-in-noise tests 
measured in an aided and an unaided listening condition, each at two reception 
thresholds.
STUDY SAMPLE: Item plausibility was pre-determined by 28 native German 
participants. An additional 62 listeners (45-86 years, M = 69.8) with 
mild-to-moderate hearing loss were tested for speech intelligibility and reading 
span in a multicenter study.
RESULTS: The reading span test significantly correlated with speech 
intelligibility at both speech reception thresholds in the aided listening 
condition.
CONCLUSION: Our German RST is standardized with respect to psycholinguistic 
construction principles of the stimuli, and is a cognitive correlate of 
intelligibility in a German matrix speech-in-noise test.

DOI: 10.3109/14992027.2014.952458
PMID: 25195607 [Indexed for MEDLINE]


419. HNO. 2023 Jun;71(6):386-395. doi: 10.1007/s00106-023-01288-9. Epub 2023 May 2.

[Automatic hearing screening for better monitoring of hearing health using the 
example of the German armed forces].

[Article in German; Abstract available in German from the publisher]

Jacob R(1), Zokoll MA(2)(3), Berg D(2)(3), Meis M(4).

Author information:
(1)HNOplus, Bergstr 63a, 56203, Höhr-Grenzhausen, Deutschland. 
rolandjacob@online.de.
(2)Hörzentrum Oldenburg gGmbH, Oldenburg, Deutschland.
(3)Cluster of Excellence "Hearing4all", Oldenburg, Deutschland.
(4)Cochlear Deutschland GmbH & Co. KG, Hannover, Deutschland.

In the present study, the concept of a systematic automated screening of 
temporary soldiers was evaluated based on the example of the ENT Department of 
the Bundeswehr Central Hospital Koblenz. From 2014 to 2017, anonymized data of 
169 individuals were collected from the setting of the Bundeswehr Central 
Hospital. Included in the data are results from measurements with automated 
pure-tone audiometry (APTA; e.g., [3]), from measurements with the digit triple 
test for determination of the speech discrimination threshold in noise (e.g., 
[20]), and from interviews with questionnaires (Hearing-Dependent Daily 
Activities [HDDA], e.g., [14]; HearCom questionnaire, e.g., [15]). There was an 
initial publication from this project evaluating the questionnaires in terms of 
their suitability for detecting hearing loss [14]. In the following (from March 
2015), only the HDDA, which was described as more sensitive, was used for 
measurements at the hearing screening measurement station. A complete run with 
the three procedures took approximately 22 min. Approximately 17% of the 
examined participants had abnormal findings in at least one of the procedures at 
the screening station. The results of the respective methods taken together 
detect more than any method alone and can be assumed to be complementary. 
Deviations between APTA with level monitor and manual tone audiometry were 
within the measurement accuracy. In the range between 1 and 4 kHz, hearing 
thresholds are somewhat underestimated with APTA. The threshold for the HDDA 
questionnaire with an HDDA sum ≥ 19 was confirmed. Automated hearing screening 
offers a good opportunity to check hearing ability on a regular basis in 
a standardized and reliable manner, while keeping personnel requirements low.

Publisher: In der vorliegenden Studie wurde das Konzept eines systematischen 
automatisierten Screenings von Zeitsoldaten am Beispiel der HNO-Abteilung des 
Bundeswehrzentralkrankenhauses Koblenz evaluiert. In den Jahren 2014 bis 2017 
sind Daten von 169 Personen aus dem Umfeld des Bundeswehrzentralkrankenhauses 
anonymisiert gesammelt worden. In den Daten enthalten sind Ergebnisse aus 
Messungen mit der automatisierten Reintonaudiometrie (APTA; Automatic Pure Tone 
Audiometry, z. B. [3]), aus Messungen mit dem Ziffern-Tripel-Test für die 
Ermittlung einer Sprachverständlichkeitsschwelle im Störgeräusch z. B. [20], 
sowie aus Befragungen mit Fragebögen (HDDA, Hearing-Dependent Daily Activities, 
z. B. [14], HearCom-Fragebogen, z. B. [15]). Eine erste Publikation aus diesem 
Projekt gab es zur Evaluation der Fragebögen hinsichtlich ihrer Eignung zur 
Detektion von Hörverlusten [20]. Im Folgenden (ab März 2015) wurde nur noch der 
hierbei als sensitiver beschriebene HDDA für Messungen mit der 
Hörscreening-Messstation verwendet. Ein kompletter Durchgang mit den drei 
Verfahren dauerte ca. 22 min. Circa 17 % der untersuchten Teilnehmer zeigten 
auffällige Ergebnisse in mindestens einem der Verfahren auf der 
Screening-Station. Die Ergebnisse der jeweiligen Verfahren zusammengenommen 
detektieren mehr als ein Verfahren allein und können als komplementär angenommen 
werden. Abweichungen zwischen APTA mit Pegelwächter und manueller Tonaudiometrie 
lagen innerhalb der Messungenauigkeit. Im Bereich zwischen 1 und 4 kHz werden 
die Hörschwellen mit APTA etwas unterschätzt. Der Schwellenwert für den 
HDDA-Fragebogen mit einer HDDA-Summe ≥ 19 konnte bestätigt werden. Ein 
automatisiertes Hörscreening bietet eine gute Möglichkeit auf regelmäßiger Basis 
die Hörfähigkeit in standardisierter und zuverlässiger Weise zu überprüfen und 
dabei gleichzeitig den Personaleinsatz gering zu halten.

© 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
ein Teil von Springer Nature.

DOI: 10.1007/s00106-023-01288-9
PMID: 37129641 [Indexed for MEDLINE]


420. J Assoc Res Otolaryngol. 2008 Sep;9(3):264-76; discussion 261-3. doi: 
10.1007/s10162-008-0123-1. Epub 2008 Jun 10.

Occupational noise, smoking, and a high body mass index are risk factors for 
age-related hearing impairment and moderate alcohol consumption is protective: a 
European population-based multicenter study.

Fransen E(1), Topsakal V, Hendrickx JJ, Van Laer L, Huyghe JR, Van Eyken E, 
Lemkens N, Hannula S, Mäki-Torkko E, Jensen M, Demeester K, Tropitzsch A, 
Bonaconsa A, Mazzoli M, Espeso A, Verbruggen K, Huyghe J, Huygen PL, Kunst S, 
Manninen M, Diaz-Lacava A, Steffens M, Wienker TF, Pyykkö I, Cremers CW, Kremer 
H, Dhooge I, Stephens D, Orzan E, Pfister M, Bille M, Parving A, Sorri M, Van de 
Heyning P, Van Camp G.

Author information:
(1)Department of Medical Genetics, University of Antwerp, Universiteitsplein, 
2610 Antwerp, Belgium.

A multicenter study was set up to elucidate the environmental and medical risk 
factors contributing to age-related hearing impairment (ARHI). Nine subsamples, 
collected by nine audiological centers across Europe, added up to a total of 
4,083 subjects between 53 and 67 years. Audiometric data (pure-tone average 
[PTA]) were collected and the participants filled out a questionnaire on 
environmental risk factors and medical history. People with a history of disease 
that could affect hearing were excluded. PTAs were adjusted for age and sex and 
tested for association with exposure to risk factors. Noise exposure was 
associated with a significant loss of hearing at high sound frequencies (>1 
kHz). Smoking significantly increased high-frequency hearing loss, and the 
effect was dose-dependent. The effect of smoking remained significant when 
accounting for cardiovascular disease events. Taller people had better hearing 
on average with a more pronounced effect at low sound frequencies (<2 kHz). A 
high body mass index (BMI) correlated with hearing loss across the frequency 
range tested. Moderate alcohol consumption was inversely correlated with hearing 
loss. Significant associations were found in the high as well as in the low 
frequencies. The results suggest that a healthy lifestyle can protect against 
age-related hearing impairment.

DOI: 10.1007/s10162-008-0123-1
PMCID: PMC2492985
PMID: 18543032 [Indexed for MEDLINE]


421. Hear Res. 2019 Dec;384:107823. doi: 10.1016/j.heares.2019.107823. Epub 2019 Oct 
18.

Cortical thickness of left Heschl's gyrus correlates with hearing acuity in 
adults - A surface-based morphometry study.

Neuschwander P(1), Hänggi J(2), Zekveld AA(3), Meyer M(4).

Author information:
(1)University of Zurich, Neuropsychology Division, Department of Psychology, 
Zurich, Switzerland. Electronic address: pia.neuschwander@psychologie.uzh.ch.
(2)University of Zurich, Neuropsychology Division, Department of Psychology, 
Zurich, Switzerland.
(3)Amsterdam UMC, Vrije Universiteit Amsterdam, Otolaryngology - Head and Neck 
Surgery, Ear & Hearing, Amsterdam Public Health Research Institute, De 
Boelelaan, 1117, Amsterdam, the Netherlands.
(4)University of Zurich, Neuropsychology Division, Department of Psychology, 
Zurich, Switzerland; Tinnituszentrum, Charité - Universitätsmedizin, Berlin, 
Germany.

To date, research examining the relationship between brain structure and hearing 
acuity is sparse, especially given the context of a broad age range. To 
investigate this relationship, we applied an automated surface-based morphometry 
(SBM) approach (FreeSurfer) in this study to re-examine a sample of 
normal-hearing (n = 17) and hearing-impaired (n = 17) age- and education-matched 
adults, aged between 20 and 63 years (Alfandari et al., 2018). The SBM approach 
allows the disentanglement of cortical surface area (CSA) from cortical 
thickness (CT), the 2 independent constituents of cortical volume (CV). We 
extend the findings of Alfandari and colleagues by showing several clusters in 
auditory-related areas as well as in the left and right angular gyrus that 
showed reduced CT, CSA and CV in hearing-impaired compared to normal-hearing 
listeners. Nevertheless, none of the clusters found correlated significantly 
with hearing acuity, measured by pure-tone thresholds, in the 2 groups. An 
additional vertex-wise correlation analysis between hearing acuity and 
morphometric parameters over all participants revealed a single significant 
cluster encompassing the left Heschl's gyrus. Higher hearing thresholds were 
associated with a thinner cortex within this cluster. Our results imply that 
hearing impairment is associated with reduced thickness in primary and secondary 
auditory cortex regions, those regions especially involved in perceiving and 
processing relevant speech cues. This decrease was observed not only in older 
but also in younger and middle-aged adults, independent of age-related decline 
in the cognitive domain and age-dependent whole-brain atrophy. Further, the 
results show the value added when considering CV, CT and CSA separately, 
relative to previous studies which have solely relied on voxel-based morphometry 
to investigate brain structure and hearing acuity across the lifespan.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.107823
PMID: 31678891 [Indexed for MEDLINE]


422. Otol Neurotol. 2015 Jun;36(5):842-8. doi: 10.1097/MAO.0000000000000727.

Comparison of audiologic results and patient satisfaction for two 
osseointegrated bone conduction devices: results of a prospective study.

Busch S(1), Giere T, Lenarz T, Maier H.

Author information:
(1)*Department of Otolaryngology and †Cluster of Excellence Hearing4all, Medical 
University Hannover, Hannover, Germany.

OBJECTIVE: Osseointegrated bone conduction (BC) devices are an important 
rehabilitation option for patients with mixed or conductive hearing loss or 
single-sided deafness. The development of new devices is ongoing and requires 
evaluation of the performance of new hearing aids. Here, we compared the 
audiologic outcome and subjective benefit of two different designs of 
osseointegrated implant systems from different manufacturers.
STUDY DESIGN: Prospective, experimental, monocentric, crossover study performed 
at the Medical University Hannover, Germany.
PATIENTS AND INTERVENTIONS: Eleven patients, already implanted with an adequate 
abutment, tested each device in daily life situations sequentially for a period 
of 3 weeks.
MAIN OUTCOME MEASURES: Bone conduction, word recognition in quiet (Freiburg 
monosyllable test, L50%), and speech reception thresholds in noise (Oldenburg 
Sentence Test) were measured unaided and aided with the devices after each test 
period. The subjective benefit was assessed by the Abbreviated Profile of 
Hearing Aid Benefit; the Speech, Spatial and Qualities of Hearing 
Scale-Comparative questionnaire; and a self-developed handling questionnaire.
RESULTS: Audiologic results indicate a slightly better performance of the BCB. 
However, subjective benefit and patient satisfaction and preference evaluated 
with questionnaires were higher with the BCP than with the BCB.
CONCLUSION: Amplification-wise, both devices are suitable treatments for 
hearing-impaired patients. Nevertheless, audiometric tests do not reflect 
subjective benefit and patients' satisfaction, and both options should be tested 
to provide each patient with the best possible hearing solution. The study 
further elucidates the importance and necessity of questionnaires in the process 
of evaluating the hearing benefit of hearing devices.

DOI: 10.1097/MAO.0000000000000727
PMID: 25730448 [Indexed for MEDLINE]


423. Zhonghua Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2017 Aug 7;52(8):573-579. doi: 
10.3760/cma.j.issn.1673-0860.2017.08.003.

[The application of artificial neural network on the assessment of lexical tone 
production of pediatric cochlear implant users].

[Article in Chinese; Abstract available in Chinese from the publisher]

Mao YT(1), Chen ZM(2), Xu L(3).

Author information:
(1)Department of Radiology, Xiangya Hospital, Central South University, Changsha 
410008, China; School of Rehabilitation and Communication Sciences, Ohio 
University, Athens, OH 45701, USA.
(2)Department of Rehabilitation Medicine, Language Disorder Center, the First 
Affiliated Hospital of Jinan University, Guangzhou 510630, China.
(3)School of Rehabilitation and Communication Sciences, Ohio University, Athens, 
OH 45701, USA.

Objective: The present study was carried out to explore the tone production 
ability of the Mandarin-speaking children with cochlear implants (CI) by using 
an artificial neural network model and to examine the potential contributing 
factors underlining their tone production performance. The results of this study 
might provide useful guidelines for post-operative rehabilitation processes of 
pediatric CI users. Methods: Two hundred and seventy-eight prelingually deafened 
children who received unilateral CI participated in this study. As controls, 170 
similarly-aged children with normal hearing (NH) were recruited. A total of 36 
Chinese monosyllabic words were selected as the tone production targets. Vocal 
production samples were recorded and the fundamental frequency (F0) contour of 
each syllable was extracted using an auto-correlation algorithm followed by 
manual correction. An artificial neural network was created in MATLAB to 
classify the tone production. The relationships between tone production and 
several demographic factors were evaluated. Results: Pediatric CI users produced 
Mandarin tones much less accurately than did the NH children (58.8% vs. 91.5% 
correct). Tremendous variability in tone production performance existed among 
the CI children. Tones 2 and 3 were produced less accurately than tones 1 and 4 
for both groups. For the CI group, all tones when in error tended to be judged 
as tone 1. The tone production accuracy was negatively correlated with age at 
implantation and positively correlated with CI use duration with correlation 
coefficients (r) of -0.215 (P=0.003) and 0.203 (P=0.005), respectively. Age was 
one of the determinants of tonal ability for NH children. Conclusions: For 
children with severe to profound hearing loss, early implantation and persistent 
use of CI are beneficial to their tone production development. Artificial neural 
network is a convenient and reliable assessment tool for the development of 
tonal ability of hearing-impaired children who are in the rehabilitation 
processes that focus on speech and language expression.

Publisher: 目的： 
了解以普通话为母语的语前聋人工耳蜗植入儿童在普通话声调发声上存在的问题并探索影响其声调发声能力的潜在因素，对基于计算机技术进行声调发声的特征提取和自动化判别的可行性进行实验论证，以期对此类儿童的术后声调发声康复提供指导。 
方法： 
278例语前聋单侧人工耳蜗植入儿童和170名年龄相仿的听力正常儿童参加了本项研究。对受试儿童的声调发声样本进行录音，在MATLAB平台上对每个受试儿童的每个发声音节进行基频提取并手动纠偏。构建人工神经网络，加以训练后对受试儿童的基频数据进行判读并分析结果。利用MATLAB统计工具对所得结果进行统计分析。 
结果： 
人工耳蜗植入儿童的声调发声准确率(58.8%)明显低于同龄正常儿童(91.5%)，且个体差异较大。二声和三声的发声准确率较一声和四声低，人工耳蜗植入儿童的声调发声出错时最易被判读成一声。人工耳蜗植入儿童声调发声准确率与植入年龄呈负相关(r＝－0.215, 
P＝0.003)，与设备使用时长呈正相关(r＝0.203, P＝0.005)。年龄是影响正常听力儿童声调发声能力的决定因素之一。 结论： 
对于确诊为重度至极重度聋的儿童，早期植入人工耳蜗并长期坚持使用有利于其声调能力的发展。人工神经网络可作为监测聋儿声调发声能力发展及康复效果的方便且可靠的评估手段。.

DOI: 10.3760/cma.j.issn.1673-0860.2017.08.003
PMID: 28822408 [Indexed for MEDLINE]


424. Ear Hear. 2014 Sep-Oct;35(5):e213-27. doi: 10.1097/AUD.0000000000000054.

Perceptual consequences of different signal changes due to binaural noise 
reduction: do hearing loss and working memory capacity play a role?

Neher T(1), Grimm G, Hohmann V.

Author information:
(1)Medical Physics and Cluster of Excellence "Hearing4all," Department of 
Medical Physics and Acoustics, Carl-von-Ossietzky University, Oldenburg, 
Germany.

OBJECTIVES: In a previous study, ) investigated whether pure-tone average (PTA) 
hearing loss and working memory capacity (WMC) modulate benefit from different 
binaural noise reduction (NR) settings. Results showed that listeners with 
smaller WMC preferred strong over moderate NR even at the expense of poorer 
speech recognition due to greater speech distortion (SD), whereas listeners with 
larger WMC did not. To enable a better understanding of these findings, the main 
aims of the present study were (1) to explore the perceptual consequences of 
changes to the signal mixture, target speech, and background noise caused by 
binaural NR, and (2) to determine whether response to these changes varies with 
WMC and PTA.
DESIGN: As in the previous study, four age-matched groups of elderly listeners 
(with N = 10 per group) characterized by either mild or moderate PTAs and either 
better or worse performance on a visual measure of WMC participated. Five 
processing conditions were tested, which were based on the previously used 
(binaural coherence-based) NR scheme designed to attenuate diffuse signal 
components at mid to high frequencies. The five conditions differed in terms of 
the type of processing that was applied (no NR, strong NR, or strong NR with 
restoration of the long-term stimulus spectrum) and in terms of whether the 
target speech and background noise were processed in the same manner or whether 
one signal was left unprocessed while the other signal was processed with the 
gains computed for the signal mixture. Comparison across these conditions 
allowed assessing the effects of changes in high-frequency audibility (HFA), SD, 
and noise attenuation and distortion (NAD). Outcome measures included a 
dual-task paradigm combining speech recognition with a visual reaction time 
(VRT) task as well as ratings of perceived effort and overall preference. All 
measurements were carried out using headphone simulations of a frontal target 
speaker in a busy cafeteria.
RESULTS: Relative to no NR, strong NR was found to impair speech recognition and 
VRT performance slightly and to improve perceived effort and overall preference 
markedly. Relative to strong NR, strong NR with restoration of the long-term 
stimulus spectrum and thus HFA did not affect speech recognition, restored VRT 
performance to that achievable with no NR, and increased perceived effort and 
reduced overall preference markedly. SD had negative effects on speech 
recognition and perceived effort, particularly when both speech and noise were 
processed with the gains computed for the signal mixture. NAD had positive 
effects on speech recognition, perceived effort, and overall preference, 
particularly when the target speech was left unprocessed. VRT performance was 
unaffected by SD and NAD. None of the datasets exhibited any clear signs that 
response to the different signal changes varies with PTA or WMC.
CONCLUSIONS: For the outcome measures and stimuli applied here, the present 
study provides little evidence that PTA or WMC affect response to changes in 
HFA, SD, and NAD caused by binaural NR. However, statistical power restrictions 
suggest further research is needed. This research should also investigate 
whether partial HFA restoration combined with some pre-processing that reduces 
co-modulation distortion results in a more favorable balance of the effects of 
binaural NR across outcome dimensions and whether NR strength has any influence 
on these results.

DOI: 10.1097/AUD.0000000000000054
PMID: 25010636 [Indexed for MEDLINE]


425. Trials. 2016 Aug 8;17:394. doi: 10.1186/s13063-016-1526-7.

ACEMg-mediated hearing preservation in cochlear implant patients receiving 
different electrode lengths (PROHEARING): study protocol for a randomized 
controlled trial.

Scheper V(1)(2), Leifholz M(3), von der Leyen H(4), Keller M(4), Denkena U(4), 
Koch A(5), Karch A(5), Miller J(6), Lenarz T(3)(7).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany. scheper.verena@mh-hannover.de.
(2)Cluster of Excellence Hearing4all, Hannover and Oldenburg, Germany. 
scheper.verena@mh-hannover.de.
(3)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany.
(4)Hannover Clinical Trial Center, Carl-Neuberg-Str. 1, 30625, Hannover, 
Germany.
(5)Institute for Biostatistics, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany.
(6)Kresge Hearing Research Institute, University of Michigan, 4605 Medical 
Science Unit II, Ann Arbor, MI, 48109-5616, USA.
(7)Cluster of Excellence Hearing4all, Hannover and Oldenburg, Germany.

BACKGROUND: The indications for a cochlear implant (CI) have been extended to 
include patients with some residual hearing. Shorter and thinner atraumatic 
electrodes have been designed to preserve the residual hearing in the implanted 
ear. However, the insertion of the electrode array into the cochlea, with 
potential mechanical trauma and the presence of this foreign body inside the 
cochlea, may lead to free radical formation and reduced blood perfusion of the 
cochlea which can result in the loss of residual hearing.
METHODS/DESIGN: In this single-center, randomized, placebo-controlled, 
double-blind phase II clinical trial the effect of free radical scavengers and a 
vasodilator on the residual hearing of 140 CI patients will be evaluated. The 
formulation is composed of β-carotene (vitamin A), ascorbic acid (vitamin C), 
dl-α-tocopherol acetate (vitamin E) and the vasodilator magnesium (Mg), or 
ACEMg. Medication is administered twice daily per os for approximately 3 months. 
The primary measure is based upon the reduction in postoperative low-frequency 
air-conducted pure-tone thresholds compared to preoperative thresholds in 
ACEMg-treated patients compared to those of a placebo group. Additionally, the 
effect of different electrode lengths (20, 24 and 28 mm) is analyzed. Study 
visits are scheduled 2 days before surgery, at first fitting, which is the 
adjustment and start of stimulation via CI 4 weeks after surgery and 3, 6, 9 and 
12 months after first fitting. The primary endpoint is the air-conduction 
hearing loss at 500 Hz 3 months after first fitting. Additionally, speech 
recognition tests, hearing aid benefit in the implanted ear and 
electrophysiological measurements of implant function are assessed. Since this 
is a blinded clinical trial and recruitment is still ongoing, data continue to 
accrue and we cannot yet analyze the outcome of the ACEMg treatment.
DISCUSSION: There is an unfulfilled need for new strategies to preserve acoustic 
hearing in CI patients. This study will provide first-in-man data on 
ACEMg-mediated protection of residual hearing in CI patients. Performing all 
surgeries and patient follow-up at one study site improves consistency in 
diagnosis and therapy and less variability in surgery, audiological test 
techniques and fitting. This approach will allow investigation of the influence 
of ACEMg on residual hearing in CI patients.
TRIAL REGISTRATION: The German Bundesinstitut für Arzneimittel und 
Medizinprodukte (BfArM) application number 4039192, was registered on 6 December 
2013 with protocol amendment version 3.0 from 19 August 2014. EudraCT number: 
2012-005002-22 .

DOI: 10.1186/s13063-016-1526-7
PMCID: PMC4977680
PMID: 27502589 [Indexed for MEDLINE]


426. ORL J Otorhinolaryngol Relat Spec. 1998 Jul-Aug;60(4):181-9. doi: 
10.1159/000027591.

Interleukin 8 can affect inner ear function.

Iguchi H(1), Anniko M.

Author information:
(1)Department of Otorhinolaryngology and Head and Neck Surgery, Uppsala 
University Hospital, Sweden.

The chemokine interleukin 8 (IL-8) was instilled into the round window niche of 
rats through a small perforation in the tympanic membrane in order to study its 
effect on inner ear function by electrophysiological and morphological 
techniques. The frequency-specific auditory brainstem response (ABR) was 
recorded at the frequencies 4, 8, 10, 12, 16 and 20 kHz just before and 1, 2, 5 
and 14 days after instilling IL-8 to ascertain the hearing level during each 
interval. Morphological examination by light microscopy was performed during the 
same interval following the instillation of IL-8. On day 1, the rise in ABR 
threshold was within 5 dB SPL (non-significant elevation). However, a 
significant threshold elevation (above 5 dB SPL) occurred in high-frequency 
areas (16 and 20 kHz) on day 2, and in middle frequency areas (10 and 12 kHz) on 
day 5 with sensorineural hearing loss type intensity-latency curves. By day 14, 
the elevated thresholds had returned to pre-instillation levels. In the lowest 
areas (4 and 8 kHz), no significant threshold elevation was detected at any time 
during the observation period. By light microscopy, on day 1, clusters of 
inflammatory cells (predominantly neutrophils) were observed just outside the 
round window membrane (RWM), while only a few neutrophils were detected in the 
cochlea. These cells were still present outside the RWM on day 2. The 
neutrophils had disappeared by day 5 and only macrophages were present on the 
middle ear side of the RWM. However, throughout the observation period, the 
organ of Corti and stria vascularis appeared to be intact. These results suggest 
that IL-8 in the middle ear cavity is able to influence inner ear function.

DOI: 10.1159/000027591
PMID: 9646304 [Indexed for MEDLINE]


427. J Acoust Soc Am. 2020 Jan;147(1):350. doi: 10.1121/10.0000577.

Electric-acoustic interaction measurements in cochlear-implant users with 
ipsilateral residual hearing using electrocochleography.

Krüger B(1), Büchner A(1), Lenarz T(1), Nogueira W(1).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Cluster of Excellence 
Hearing4all, Carl-Neuberg-Straße 1, 30625 Hannover, Germany.

Cochlear implantation is increasingly being used as a hearing-loss treatment for 
patients with residual hearing in the low acoustic frequencies. These patients 
obtain combined electric-acoustic stimulation (EAS). Substantial residual 
hearing and relatively long electrode arrays can lead to interactions between 
the electric and acoustic stimulation. This work investigated EAS interaction 
through psychophysical and electrophysiological measures. Moreover, cone-beam 
computed-tomography data was used to characterize the interaction along spatial 
cochlear locations. Psychophysical EAS interaction was estimated based on the 
threshold of audibility of an acoustic probe stimulus in the presence of a 
simultaneously presented electric masker stimulus. Intracochlear 
electrocochleography was used to estimate electrophysiological EAS interaction 
via the telemetry capability of the cochlear implant. EAS interaction was 
observed using psychophysical and electrophysiological measurements. While 
psychoacoustic EAS interaction was most pronounced close to the electrical 
stimulation site, electrophysiological EAS interaction was observed over a wider 
range of spatial cochlear locations. Psychophysical EAS interaction was 
significantly larger than electrophysiological EAS interaction for acoustic 
probes close to the electrode position.

DOI: 10.1121/10.0000577
PMID: 32006967 [Indexed for MEDLINE]


428. Neural Comput. 2006 Dec;18(12):2942-58. doi: 10.1162/neco.2006.18.12.2942.

A spiking neuron model of cortical correlates of sensorineural hearing loss: 
Spontaneous firing, synchrony, and tinnitus.

Dominguez M(1), Becker S, Bruce I, Read H.

Author information:
(1)melidomi@yahoo.com

Hearing loss due to peripheral damage is associated with cochlear hair cell 
damage or loss and some retrograde degeneration of auditory nerve fibers. 
Surviving auditory nerve fibers in the impaired region exhibit elevated and 
broadened frequency tuning, and the cochleotopic representation of broadband 
stimuli such as speech is distorted. In impaired cortical regions, increased 
tuning to frequencies near the edge of the hearing loss coupled with increased 
spontaneous and synchronous firing is observed. Tinnitus, an auditory percept in 
the absence of sensory input, may arise under these circumstances as a result of 
plastic reorganization in the auditory cortex. We present a spiking neuron model 
of auditory cortex that captures several key features of cortical organization. 
A key assumption in the model is that in response to reduced afferent excitatory 
input in the damaged region, a compensatory change in the connection strengths 
of lateral excitatory and inhibitory connections occurs. These changes allow the 
model to capture some of the cortical correlates of sensorineural hearing loss, 
including changes in spontaneous firing and synchrony; these phenomena may 
explain central tinnitus. This model may also be useful for evaluating 
procedures designed to segregate synchronous activity underlying tinnitus and 
for evaluating adaptive hearing devices that compensate for selective hearing 
loss.

DOI: 10.1162/neco.2006.18.12.2942
PMID: 17052154 [Indexed for MEDLINE]


429. J Neurosci. 2004 Feb 25;24(8):1936-40. doi: 10.1523/JNEUROSCI.4554-03.2004.

Loss of Kv3.1 tonotopicity and alterations in cAMP response element-binding 
protein signaling in central auditory neurons of hearing impaired mice.

von Hehn CA(1), Bhattacharjee A, Kaczmarek LK.

Author information:
(1)Department of Pharmacology, Yale University School of Medicine, New Haven, 
Connecticut 06520, USA.

The promoter for the kv3.1 potassium channel gene is regulated by a Ca2+-cAMP 
responsive element, which binds the transcription factor cAMP response 
element-binding protein (CREB). Kv3.1 is expressed in a tonotopic gradient 
within the medial nucleus of the trapezoid body (MNTB) of the auditory 
brainstem, where Kv3.1 levels are highest at the medial end, which corresponds 
to high auditory frequencies. We have compared the levels of Kv3.1, CREB, and 
the phosphorylated form of CREB (pCREB) in a mouse strain that maintains good 
hearing throughout life, CBA/J (CBA), with one that suffers early cochlear hair 
cell loss, C57BL/6 (BL/6). A gradient of Kv3.1 immunoreactivity in the MNTB was 
detected in both young (6 week) and older (8 month) CBA mice. Although no 
gradient of CREB was detected, pCREB-immunopositive cells were grouped together 
in distinct clusters along the tonotopic axis. The same pattern of Kv3.1, CREB, 
and pCREB localization was also found in young BL/6 mice at a time (6 weeks) 
when hearing is normal. In contrast, at 8 months, when hearing is impaired, the 
gradient of Kv3.1 was abolished. Moreover, in the older BL/6 mice there was a 
decrease in CREB expression along the tonotopic axis, and the pattern of pCREB 
labeling appeared random, with no discrete clusters of pCREB-positive cells 
along the tonotopic axis. Our findings are consistent with the hypothesis that 
ongoing activity in auditory brainstem neurons is necessary for the maintenance 
of Kv3.1 tonotopicity through the CREB pathway.

DOI: 10.1523/JNEUROSCI.4554-03.2004
PMCID: PMC6730406
PMID: 14985434 [Indexed for MEDLINE]


430. Int J Audiol. 2018 Jun;57(sup3):S112-S117. doi: 10.1080/14992027.2016.1247501. 
Epub 2016 Nov 4.

Virtual acoustic environments for comprehensive evaluation of model-based 
hearing devices<sup/>.

Grimm G(1)(2), Luberadzka J(1), Hohmann V(1)(2).

Author information:
(1)a Medizinische Physik and Cluster of Excellence Hearing4all , Universität 
Oldenburg , Oldenburg , Germany and.
(2)b HörTech gGmbH , Oldenburg , Germany.

OBJECTIVE: Create virtual acoustic environments (VAEs) with interactive dynamic 
rendering for applications in audiology.
DESIGN: A toolbox for creation and rendering of dynamic virtual acoustic 
environments (TASCAR) that allows direct user interaction was developed for 
application in hearing aid research and audiology. The software architecture and 
the simulation methods used to produce VAEs are outlined. Example environments 
are described and analysed.
CONCLUSION: With the proposed software, a tool for simulation of VAEs is 
available. A set of VAEs rendered with the proposed software was described.

DOI: 10.1080/14992027.2016.1247501
PMID: 27813439 [Indexed for MEDLINE]


431. Trends Hear. 2016 Sep 5;20:2331216516660966. doi: 10.1177/2331216516660966.

Are Experienced Hearing Aid Users Faster at Grasping the Meaning of a Sentence 
Than Inexperienced Users? An Eye-Tracking Study.

Habicht J(1), Kollmeier B(2), Neher T(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence Hearing4all, Oldenburg 
University, Germany julia.habicht@uni-oldenburg.de.
(2)Medizinische Physik and Cluster of Excellence Hearing4all, Oldenburg 
University, Germany.

This study assessed the effects of hearing aid (HA) experience on how quickly a 
participant can grasp the meaning of an acoustic sentence-in-noise stimulus 
presented together with two similar pictures that either correctly (target) or 
incorrectly (competitor) depict the meaning conveyed by the sentence. Using an 
eye tracker, the time taken by the participant to start fixating the target (the 
processing time) was measured for two levels of linguistic complexity (low vs. 
high) and three HA conditions: clinical linear amplification (National Acoustic 
Laboratories-Revised), single-microphone noise reduction with National Acoustic 
Laboratories-Revised, and linear amplification ensuring a sensation level 
of ≥ 15 dB up to at least 4 kHz for the speech material used here. Timed button 
presses to the target stimuli after the end of the sentences (offline reaction 
times) were also collected. Groups of experienced (eHA) and inexperienced (iHA) 
HA users matched in terms of age, hearing loss, and working memory capacity took 
part (N = 15 each). For the offline reaction times, no effects were found. In 
contrast, processing times increased with linguistic complexity. Furthermore, 
for all HA conditions, processing times were longer (poorer) for the iHA group 
than for the eHA group, despite comparable speech recognition performance. Taken 
together, these results indicate that processing times are more sensitive to 
speech processing-related factors than offline reaction times. Furthermore, they 
support the idea that HA experience positively impacts the ability to process 
noisy speech quickly, irrespective of the precise gain characteristics.

© The Author(s) 2016.

DOI: 10.1177/2331216516660966
PMCID: PMC5014089
PMID: 27595793 [Indexed for MEDLINE]


432. Hear Res. 2014 Mar;309:124-35. doi: 10.1016/j.heares.2013.11.009. Epub 2013 Dec 
12.

Connexin 26 null mice exhibit spiral ganglion degeneration that can be blocked 
by BDNF gene therapy.

Takada Y(1), Beyer LA(2), Swiderski DL(2), O'Neal AL(2), Prieskorn DM(2), 
Shivatzki S(3), Avraham KB(3), Raphael Y(4).

Author information:
(1)Kresge Hearing Research Institute, Department of Otolaryngology - Head and 
Neck Surgery, University of Michigan, 1150 West. Medical Center Dr., Ann Arbor, 
MI 48109-5648, USA; Department of Otolaryngology, Kansai Medical University, 
2-3-1, Shinmachi, Hirakata, Osaka 573-1191, Japan.
(2)Kresge Hearing Research Institute, Department of Otolaryngology - Head and 
Neck Surgery, University of Michigan, 1150 West. Medical Center Dr., Ann Arbor, 
MI 48109-5648, USA.
(3)Department of Human Molecular Genetics and Biochemistry, Sackler Faculty of 
Medicine and Sagol School of Neuroscience, Tel Aviv University, Tel Aviv 69978, 
Israel.
(4)Kresge Hearing Research Institute, Department of Otolaryngology - Head and 
Neck Surgery, University of Michigan, 1150 West. Medical Center Dr., Ann Arbor, 
MI 48109-5648, USA. Electronic address: yoash@umich.edu.

Mutations in the connexin 26 gene (GJB2) are the most common genetic cause of 
deafness, leading to congenital bilateral non-syndromic sensorineural hearing 
loss. Here we report the generation of a mouse model for a connexin 26 (Cx26) 
mutation, in which cre-Sox10 drives excision of the Cx26 gene from non-sensory 
cells flanking the auditory epithelium. We determined that these conditional 
knockout mice, designated Gjb2-CKO, have a severe hearing loss. 
Immunocytochemistry of the auditory epithelium confirmed absence of Cx26 in the 
non-sensory cells. Histology of the organ of Corti and the spiral ganglion 
neurons (SGNs) performed at ages 1, 3, or 6 months revealed that in Gjb2-CKO 
mice, the organ of Corti began to degenerate in the basal cochlear turn at an 
early stage, and the degeneration rapidly spread to the apex. In addition, the 
density of SGNs in Rosenthal's canal decreased rapidly along a gradient from the 
base of the cochlea to the apex, where some SGNs survived until at least 6 
months of age. Surviving neurons often clustered together and formed clumps of 
cells in the canal. We then assessed the influence of brain derived neurotrophic 
factor (BDNF) gene therapy on the SGNs of Gjb2-CKO mice by inoculating 
Adenovirus with the BDNF gene insert (Ad.BDNF) into the base of the cochlea via 
the scala tympani or scala media. We determined that over-expression of BDNF 
beginning around 1 month of age resulted in a significant rescue of neurons in 
Rosenthal's canal of the cochlear basal turn but not in the middle or apical 
portions. This data may be used to design therapies for enhancing the SGN 
physiological status in all GJB2 patients and especially in a sub-group of GJB2 
patients where the hearing loss progresses due to ongoing degeneration of the 
auditory nerve, thereby improving the outcome of cochlear implant therapy in 
these ears.

Copyright © 2013 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2013.11.009
PMCID: PMC3946535
PMID: 24333301 [Indexed for MEDLINE]


433. Zhonghua Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2006 Sep;41(9):661-4.

[Epidemiologic study on hearing impairment and ear diseases in old people].

[Article in Chinese]

Liu C(1), Bu XK, Xing GQ, Zhou L, Xu X, Wang DY, Chen ZB, Zhou H, Tian HQ, Li 
XL, Lu L, Zhao XN, Li FL, Tan CQ.

Author information:
(1)Department of Otorhinolaryngology, First Affiliated Hospital of Nanjing 
Medical University, Nanjing 210029, China.

OBJECTIVE: To investigate the prevalence of hearing impairment and ear diseases 
in old people and provide scientific data for drawing up the prevention and 
treatment strategies.
METHODS: Using the probability proportion to size (PPS) method, 1261 people over 
60 years were investigated in 40 clusters in Jiangsu Province with the WHO 
protocol.
RESULTS: The prevalence of hearing impairment was 58.1% (the standardized rate: 
59.5% in the whole country, 60.9% in Jiangsu province). Degrees of hearing 
impairment were mild (33.1%), moderate (17.8%), severe (5.9%) and profound 
(1.3%). The prevalence of hearing disability was 25.0% (the standardized rate: 
26.6% in the whole country, 28.1% in Jiangsu province). There were significant 
difference of the prevalence between male and female, as well as urban and 
rural, and different ages. The prevalence of the ear diseases was auricle 
malformation (0.2%), wax (1.7%), otitis externa (0.1%), fungi (0.5%), serous 
otitis media (1.2%), chronic suppurative otitis media (1.6%), dry perforation of 
tympanic membrance (2.3%). The causes of hearing impairment were ear diseases 
(2.9%), non-infectious condition (92.6%), genetic condition (0.3%) and 
undetermined causes (4.2%). Of which, 31.1% of persons needed hearing aids while 
2.3% of persons needed medicine treatment, but 0.9% of persons needed non-urgent 
surgery and 1.0% of persons needed other treatment.
CONCLUSIONS: The prevalence of hearing impairment and disability in the old 
rised obviously than the last investigation in 1987. It was a heavy burden for 
social development in China. The government and the whole society should take 
more concern about the problem. The scientific strategies of prevention and 
treatment were urgently needed and implemented.

PMID: 17111805 [Indexed for MEDLINE]


434. Laryngorhinootologie. 1994 Mar;73(3):118-22. doi: 10.1055/s-2007-997092.

[Evoked otoacoustic emissions and middle ear function].

[Article in German]

Rödel R(1), Breuer T.

Author information:
(1)Universitäts-Hals-Nasen-Ohren-Klinik Bonn.

Transiently evoked otoacustic emissions (TEOAE) recorded in 98 ears were 
compared depending on the results of tympanometry. The values of middle ear 
pressure in patients without detectable TEOAE are significantly smaller compared 
to those of patients with detectable TEOAE. In cases of detectable TEOAE, the 
amplitudes and frequency components were compared to the results of 
tympanometry. When maximal compliances are shifted towards negative values of 
middle ear pressure, the amplitudes of TEOAE are reduced with a loss of low 
frequency components. Small compliance values result in reduced amplitudes of 
TEOAE with the loss of low frequency components. By means of cluster analysis in 
the scatter plot of middle ear compliance and pressure, a classification is 
obtained separating two groups representing significantly groups of patients 
with and without detectable TEOAE. Summing up, it must be stated that there is 
an effect of middle ear function on TEOAE which must be taken into consideration 
when TEOAE are used in clinical application.

DOI: 10.1055/s-2007-997092
PMID: 8172629 [Indexed for MEDLINE]


435. J Am Acad Audiol. 2008 Oct;19(9):672-85. doi: 10.3766/jaaa.19.9.3.

Prevalence of hearing impairment by gender and audiometric configuration: 
results from the National Health and Nutrition Examination Survey (1999-2004) 
and the Keokuk County Rural Health Study (1994-1998).

Ciletti L(1), Flamme GA.

Author information:
(1)Department of Speech Pathology and Audiology, Western Michigan University, 
1903 W. Michigan Ave., Kalamazoo, MI 49008, USA.

PURPOSE: This study describes the most common audiometric configurations and the 
prevalence of these configurations among adults (ages 20 to 69) in the 
noninstitutionalized population of the United States and in a sample of 
residents of a rural county in Iowa.
RESEARCH DESIGN: This was a cross-sectional population-based study.
STUDY SAMPLE: Estimates generalizing to the noninstitutionalized population of 
the United States were based on National Health and Nutrition Examination Survey 
(NHANES) data collected from 2819 women and 2525 men between 1999 and 2004. 
Estimates from the rural county were based on Keokuk County Rural Health Study 
(KCRHS) data collected from 892 women and 750 men between 1994 and 1998.
DATA COLLECTION AND ANALYSIS: Cluster analyses (kappa-means) were used to divide 
participants into groups including maximally similar bilateral air conduction 
audiograms. Separate cluster analyses were conducted for each gender. For NHANES 
data, prevalence and error estimates were obtained using sample weights intended 
to provide data generalizing to the noninstitutionalized population of the 
United States within this age range.
RESULTS: The hierarchical structure of audiometric configurations revealed that 
approximately 25% of women and 50% of men aged 20 to 69 in the 
noninstitutionalized population of the United States were best described by a 
configuration consistent with a marked hearing impairment in at least one 
frequency. Hearing impairments were more common among participants in the KCRHS. 
Gently sloping configurations of hearing impairment were dominant among women, 
while configurations featuring a greater slope were dominant among men. There 
was a greater variety of audiometric configurations in men than women.
CONCLUSIONS: In addition to their descriptive value, these data can be used to 
inform future studies of risk factors and progression of hearing loss, and to 
improve the generalizability of studies involving rehabilitative options for 
people with hearing impairment.

DOI: 10.3766/jaaa.19.9.3
PMID: 19418707 [Indexed for MEDLINE]


436. PLoS One. 2014 Nov 17;9(11):e110260. doi: 10.1371/journal.pone.0110260. 
eCollection 2014.

Predicting the perceived sound quality of frequency-compressed speech.

Huber R(1), Parsa V(2), Scollie S(2).

Author information:
(1)Centre of Competence HörTech gGmbH, Oldenburg, Germany; Cluster of Excellence 
Hearing4All, Oldenburg and Hannover, Germany.
(2)National Centre for Audiology, Western University, London, Canada.

The performance of objective speech and audio quality measures for the 
prediction of the perceived quality of frequency-compressed speech in hearing 
aids is investigated in this paper. A number of existing quality measures have 
been applied to speech signals processed by a hearing aid, which compresses 
speech spectra along frequency in order to make information contained in higher 
frequencies audible for listeners with severe high-frequency hearing loss. 
Quality measures were compared with subjective ratings obtained from normal 
hearing and hearing impaired children and adults in an earlier study. High 
correlations were achieved with quality measures computed by quality models that 
are based on the auditory model of Dau et al., namely, the measure PSM, computed 
by the quality model PEMO-Q; the measure qc, computed by the quality model 
proposed by Hansen and Kollmeier; and the linear subcomponent of the HASQI. For 
the prediction of quality ratings by hearing impaired listeners, extensions of 
some models incorporating hearing loss were implemented and shown to achieve 
improved prediction accuracy. Results indicate that these objective quality 
measures can potentially serve as tools for assisting in initial setting of 
frequency compression parameters.

DOI: 10.1371/journal.pone.0110260
PMCID: PMC4234248
PMID: 25402456 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


437. J Am Acad Audiol. 2018 May;29(5):389-404. doi: 10.3766/jaaa.16149.

fMRI as a Preimplant Objective Tool to Predict Children's Postimplant Auditory 
and Language Outcomes as Measured by Parental Observations.

Deshpande AK(1), Tan L(2)(3), Lu LJ(2)(4), Altaye M(5), Holland SK(6)(7).

Author information:
(1)Department of Speech-Language-Hearing Sciences, Hofstra University, 
Hempstead, NY.
(2)Division of Biomedical Informatics, Cincinnati Children's Hospital Research 
Foundation, Cincinnati, OH.
(3)School of Computing Sciences and Informatics, University of Cincinnati, 
Cincinnati, OH.
(4)Department of Environmental Health, College of Medicine, University of 
Cincinnati, Cincinnati, OH.
(5)Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital 
Medical Center, Cincinnati, OH.
(6)Pediatric Neuroimaging Research Consortium, Cincinnati Children's Hospital 
Medical Center, Cincinnati, OH.
(7)Department of Pediatric Radiology, Cincinnati Children's Hospital Medical 
Center, Cincinnati, OH.

BACKGROUND: The trends in cochlear implantation candidacy and benefit have 
changed rapidly in the last two decades. It is now widely accepted that early 
implantation leads to better postimplant outcomes. Although some generalizations 
can be made about postimplant auditory and language performance, neural 
mechanisms need to be studied to predict individual prognosis.
PURPOSE: The aim of this study was to use functional magnetic resonance imaging 
(fMRI) to identify preimplant neuroimaging biomarkers that predict children's 
postimplant auditory and language outcomes as measured by parental 
observation/reports.
RESEARCH DESIGN: This is a pre-post correlational measures study.
STUDY SAMPLE: Twelve possible cochlear implant candidates with bilateral severe 
to profound hearing loss were recruited via referrals for a clinical magnetic 
resonance imaging to ensure structural integrity of the auditory nerve for 
implantation.
INTERVENTION: Participants underwent cochlear implantation at a mean age of 19.4 
mo. All children used the advanced combination encoder strategy (ACE, Cochlear 
Corporation™, Nucleus® Freedom cochlear implants). Three participants received 
an implant in the right ear; one in the left ear whereas eight participants 
received bilateral implants. Participants' preimplant neuronal activation in 
response to two auditory stimuli was studied using an event-related fMRI method.
DATA COLLECTION AND ANALYSIS: Blood oxygen level dependent contrast maps were 
calculated for speech and noise stimuli. The general linear model was used to 
create z-maps. The Auditory Skills Checklist (ASC) and the SKI-HI Language 
Development Scale (SKI-HI LDS) were administered to the parents 2 yr after 
implantation. A nonparametric correlation analysis was implemented between 
preimplant fMRI activation and postimplant auditory and language outcomes based 
on ASC and SKI-HI LDS. Statistical Parametric Mapping software was used to 
create regression maps between fMRI activation and scores on the aforementioned 
tests. Regression maps were overlaid on the Imaging Research Center infant 
template and visualized in MRIcro.
RESULTS: Regression maps revealed two clusters of brain activation for the 
speech versus silence contrast and five clusters for the noise versus silence 
contrast that were significantly correlated with the parental reports. These 
clusters included auditory and extra-auditory regions such as the middle 
temporal gyrus, supramarginal gyrus, precuneus, cingulate gyrus, middle frontal 
gyrus, subgyral, and middle occipital gyrus. Both positive and negative 
correlations were observed. Correlation values for the different clusters ranged 
from -0.90 to 0.95 and were significant at a corrected p value of <0.05. 
Correlations suggest that postimplant performance may be predicted by activation 
in specific brain regions.
CONCLUSIONS: The results of the present study suggest that (1) fMRI can be used 
to identify neuroimaging biomarkers of auditory and language performance before 
implantation and (2) activation in certain brain regions may be predictive of 
postimplant auditory and language performance as measured by parental 
observation/reports.

American Academy of Audiology.

DOI: 10.3766/jaaa.16149
PMID: 29708489 [Indexed for MEDLINE]


438. Ear Nose Throat J. 1994 Nov;73(11):812-3, 817-23.

A neural network approach to the prediction of pure tone thresholds with 
distortion product emissions.

Kimberley BP(1), Kimberley BM, Roth L.

Author information:
(1)Hearing Research Laboratory, Calgary, Alberta, Canada.

Distortion Product Emission (DPE) growth functions, demographic data, and pure 
tone thresholds were recorded in 229 normal-hearing and hearing-impaired ears. 
Half of the data set (115 ears) was used to train a set of neural networks to 
map DPE and demographic features to pure tone thresholds at six frequencies in 
the audiometric range. The six networks developed from this training process 
were then used to predict pure tone thresholds in the remaining 114-ear data 
set. When normal pure tone threshold was defined as a threshold less than 20 dB 
HL, frequency-specific prediction accuracy varied from 57% (correct 
classification of hearing impairment at 1025 Hz) to 100% (correct classification 
of hearing impairment at 2050 Hz). Overall prediction accuracy was 90% for 
impaired pure tone thresholds and 80% for normal pure tone thresholds. This 
neural network approach was found to be more accurate than discriminant analysis 
in the prediction of pure tone thresholds. It is concluded that a general 
strategy exists whereby DPE measures can accurately categorize pure tone 
thresholds as normal or impaired in large populations of ears with purely 
cochlear hearing dysfunction.

PMID: 7828474 [Indexed for MEDLINE]


439. Prev Med. 2009 Dec;49(6):546-52. doi: 10.1016/j.ypmed.2009.09.020. Epub 2009 Oct 
2.

Hearing conservation program for agricultural students: short-term outcomes from 
a cluster-randomized trial with planned long-term follow-up.

Berg RL(1), Pickett W, Fitz-Randolph M, Broste SK, Knobloch MJ, Wood DJ, 
Kirkhorn SR, Linneman JG, Marlenga B.

Author information:
(1)Biomedical Informatics Research Center, Marshfield Clinic Research 
Foundation, Marshfield, WI, USA.

OBJECTIVES: (1) To conduct a contemporary analysis of historical data on 
short-term efficacy of a 3-year hearing conservation program conducted from 1992 
to 1996 in Wisconsin, USA, with 753 high school students actively involved in 
farm work; (2) to establish procedures for assessment of hearing loss for use in 
a recently funded follow-up of this same hearing conservation program cohort.
METHODS: We analyzed a pragmatic cluster-randomized controlled trial, with 
schools as the unit of randomization. Thirty-four rural schools were recruited 
and randomized to intervention or control. The intervention included classroom 
instruction, distribution of hearing protection devices, direct mailings, noise 
level assessments, and yearly audiometric testing. The control group received 
the audiometric testing.
RESULTS: Students exposed to the hearing conservation program reported more 
frequent use of hearing protection devices, but there was no evidence of reduced 
levels of noise-induced hearing loss (NIHL).
CONCLUSION: Our analysis suggests that, since NIHL is cumulative, a 3-year study 
was likely not long enough to evaluate the efficacy of this intervention. While 
improvements in reported use of hearing protection devices were noted, the 
lasting impact of these behaviors is unknown and the finding merits 
corroboration by longer term objective hearing tests. A follow-up study of the 
cohort has recently been started.

DOI: 10.1016/j.ypmed.2009.09.020
PMID: 19800914 [Indexed for MEDLINE]


440. J Neurophysiol. 2002 Jan;87(1):493-507. doi: 10.1152/jn.00211.2001.

Auditory cortical images of cochlear-implant stimuli: coding of stimulus channel 
and current level.

Middlebrooks JC(1), Bierer JA.

Author information:
(1)Kresge Hearing Research Institute (Department of Otorhinolaryngology) and 
Neuroscience Program, University of Michigan, Ann Arbor, Michigan 48109-0506, 
USA. jmidd@umich.edu

This study quantified the accuracy with which populations of neurons in the 
auditory cortex can represent aspects of electrical cochlear stimuli presented 
through a cochlear implant. We tested the accuracy of coding of the place of 
stimulation (i.e., identification of the active stimulation channel) and of the 
stimulus current level. Physiological data came from the companion study, which 
recorded spike activity of neurons simultaneously from 16 sites along the 
tonotopic axis of the guinea pig's auditory cortex. In that study, cochlear 
electrical stimuli were presented to acutely deafened animals through a 
6-electrode animal version of the 22-electrode Nucleus banded electrode array 
(Cochlear). Cochlear electrode configurations consisted of monopolar (MP), 
bipolar (BP + N) with N inactive electrodes between the active and return 
electrodes (0 < or = N < or = 3), tripolar (TP) with one active electrode and 
two flanking return electrodes, and common ground (CG) with one active electrode 
and as many as five return electrodes. In the present analysis, an artificial 
neural network was trained to recognize spatiotemporal patterns of cortical 
activity in response to single presentations of particular stimuli and, thereby, 
to identify those stimuli. The accuracy of pair-wise discrimination of 
stimulation channels or of current levels was represented by the discrimination 
index, d', where d' = 1 was taken as threshold. In many cases, the threshold for 
discrimination of place of cochlear stimulation was < 0.75 mm, and the threshold 
for discrimination of current levels was < 1 dB. Cochlear electrode 
configurations varied in the accuracy with which they signaled to the auditory 
cortex the place of cochlear stimulation. The BP + N and TP configurations 
provided considerably greater sensitivity to place of stimulation than did the 
MP configuration. The TP configuration maintained accurate signaling of place of 
stimulation up to the highest current levels, whereas sensitivity was degraded 
at high current levels in BP + N configurations. Electrode configurations also 
varied in the dynamic range over which they signaled stimulus current level. 
Dynamic ranges were widest for the BP + 0 configuration and narrowest for the TP 
configuration. That is, the configuration that showed the most accurate 
signaling of cochlear place of stimulation (TP) showed the most restricted 
dynamic range for signaling of current level. These results suggest that the 
choice of the optimal electrode configuration for use by human 
cochlear-prosthesis users would depend on the particular demands of the 
speech-processing strategy that is to be employed.

DOI: 10.1152/jn.00211.2001
PMID: 11784765 [Indexed for MEDLINE]


441. Brain. 2009 Oct;132(Pt 10):2761-71. doi: 10.1093/brain/awp159. Epub 2009 Jun 16.

Speech experience shapes the speechreading network and subsequent deafness 
facilitates it.

Suh MW(1), Lee HJ, Kim JS, Chung CK, Oh SH.

Author information:
(1)Department of Otorhinolaryngology, Seoul National University College of 
Medicine, Yongon-Dong, Chongno-Gu, Seoul, South Korea.

Speechreading is a visual communicative skill for perceiving speech. In this 
study, we tested the effects of speech experience and deafness on the 
speechreading neural network in normal hearing controls and in two groups of 
deaf patients who became deaf either before (prelingual deafness) or after 
(postlingual deafness) auditory language acquisition. Magnetic signals from the 
cerebral cortex were recorded using a 306-channel magnetoencephalographic 
system. During magnetoencephalographic measurements, subjects were asked to 
perform a speechreading task from video clips of a female speaker either 
pronouncing syllables (speechreading condition) or showing closed-mouth 
movement. The sources of the evoked fields were modelled using equivalent 
current dipoles, the origins of which were fitted to the intracranial space 
based on magnetic resonance imaging findings. During the speechreading 
condition, the latency of auditory cortex activation was shorter in the 
postlingual deafness group than in the normal hearing control group. This 
parameter negatively correlated with speechreading scores measured clinically. 
Furthermore, as the duration of deafness increased, the latency of auditory 
cortex activation decreased exponentially. However, no such correlation was 
found in the prelingual deafness group which differed significantly from the two 
other groups in this respect. The latency of auditory cortex activation was 
significantly longer in the prelingual deafness group than in the two other 
groups. Thus, auditory experience may be crucial for the development of a normal 
neural network for speechreading. The pre-existing speechreading network in the 
postlingual deafness group is made more efficient by speeding up the neural 
response.

DOI: 10.1093/brain/awp159
PMID: 19531532 [Indexed for MEDLINE]


442. Trends Hear. 2015 Apr 24;19:2331216515584149. doi: 10.1177/2331216515584149.

How hearing impairment affects sentence comprehension: using eye fixations to 
investigate the duration of speech processing.

Wendt D(1), Kollmeier B(2), Brand T(2).

Author information:
(1)Medizinische Physik, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany Hearing Systems, Department of Electrical Engineering, Technical 
University of Denmark, Kgs. Lyngby, Denmark wendt@elektro.dtu.dk.
(2)Medizinische Physik, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany Cluster of Excellence Hearing4all, Oldenburg, Germany.

The main objective of this study was to investigate the extent to which hearing 
impairment influences the duration of sentence processing. An eye-tracking 
paradigm is introduced that provides an online measure of how hearing impairment 
prolongs processing of linguistically complex sentences; this measure uses eye 
fixations recorded while the participant listens to a sentence. Eye fixations 
toward a target picture (which matches the aurally presented sentence) were 
measured in the presence of a competitor picture. Based on the recorded eye 
fixations, the single target detection amplitude, which reflects the tendency of 
the participant to fixate the target picture, was used as a metric to estimate 
the duration of sentence processing. The single target detection amplitude was 
calculated for sentence structures with different levels of linguistic 
complexity and for different listening conditions: in quiet and in two different 
noise conditions. Participants with hearing impairment spent more time 
processing sentences, even at high levels of speech intelligibility. In 
addition, the relationship between the proposed online measure and 
listener-specific factors, such as hearing aid use and cognitive abilities, was 
investigated. Longer processing durations were measured for participants with 
hearing impairment who were not accustomed to using a hearing aid. Moreover, 
significant correlations were found between sentence processing duration and 
individual cognitive abilities (such as working memory capacity or 
susceptibility to interference). These findings are discussed with respect to 
audiological applications.

© The Author(s) 2015.

DOI: 10.1177/2331216515584149
PMCID: PMC4409940
PMID: 25910503 [Indexed for MEDLINE]


443. Clin Neurophysiol. 2011 Apr;122(4):823-33. doi: 10.1016/j.clinph.2010.10.037. 
Epub 2010 Nov 19.

Multiple effects of childhood deafness on cortical activity in children 
receiving bilateral cochlear implants simultaneously.

Gordon KA(1), Tanaka S, Wong DD, Stockley T, Ramsden JD, Brown T, Jewell S, 
Papsin BC.

Author information:
(1)Archie's Cochlear Implant Laboratory, The Hospital for Sick Children, 
Toronto, Canada. karen.gordon@utoronto.ca

OBJECTIVE: Auditory development is disrupted without normal hearing but might 
proceed to some extent depending on the type and onset of deafness. We therefore 
hypothesized that activity in the auditory cortex would be highly variable in 
children who are deaf.
METHODS: To answer this, activity in the deaf brain was evoked by electrical 
pulses from newly provided bilateral cochlear implants (CIs) in 72 children 
(n=144 responses).
RESULTS: Responses were categorized by visual inspection into 3 main types which 
were validated by principal component cluster analyses; 49% had a negative 
amplitude wave similar to that previously reported in pre-term infants, 26% were 
dominated by a positive peak typical of responses in young normal hearing 
children and experienced paediatric CI users, 25% were novel multi-peaked 
responses. No significant demographic differences, including duration and onset 
of deafness, were found between response types. However, children with severe 
biallelic mutations of GJB-2 showed predominately negative peak type responses 
(79%) as compared with their peers without these mutations who had a more equal 
distribution between cortical response types.
CONCLUSION: Cortical development in children who are deaf is heterogeneous but 
can be better predicted when the genotype is known to be a GJB-2 mutation.
SIGNIFICANCE: Remediation of childhood deafness seeks to restore normal 
development and function of central auditory functions and thus may need to be 
tailored to account for effects specific to the aetiology of deafness.

Copyright © 2010 International Federation of Clinical Neurophysiology. Published 
by Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.clinph.2010.10.037
PMID: 21094084 [Indexed for MEDLINE]


444. Trends Hear. 2015 Dec 30;19:2331216515618903. doi: 10.1177/2331216515618903.

A Binaural Steering Beamformer System for Enhancing a Moving Speech Source.

Adiloğlu K(1), Kayser H(2), Baumgärtel RM(2), Rennebeck S(3), Dietz M(2), 
Hohmann V(4).

Author information:
(1)HörTech gGmbH, Oldenburg, Germany Cluster of Excellence "Hearing4all," 
Oldenburg, Germany k.adiloglu@hoertech.de.
(2)Cluster of Excellence "Hearing4all," Oldenburg, Germany Medizinische Physik, 
Universität Oldenburg, Germany.
(3)Cluster of Excellence "Hearing4all," Oldenburg, Germany Medizinische Physik, 
Universität Oldenburg, Germany Jade Hochschule, Oldenburg, Germany.
(4)HörTech gGmbH, Oldenburg, Germany Cluster of Excellence "Hearing4all," 
Oldenburg, Germany Medizinische Physik, Universität Oldenburg, Germany.

In many daily life communication situations, several sound sources are 
simultaneously active. While normal-hearing listeners can easily distinguish the 
target sound source from interfering sound sources-as long as target and 
interferers are spatially or spectrally separated-and concentrate on the target, 
hearing-impaired listeners and cochlear implant users have difficulties in 
making such a distinction. In this article, we propose a binaural approach 
composed of a spatial filter controlled by a direction-of-arrival estimator to 
track and enhance a moving target sound. This approach was implemented on a 
real-time signal processing platform enabling experiments with test subjects in 
situ. To evaluate the proposed method, a data set of sound signals with a single 
moving sound source in an anechoic diffuse noise environment was generated using 
virtual acoustics. The proposed steering method was compared with a fixed 
(nonsteering) method that enhances sound from the frontal direction in an 
objective evaluation and subjective experiments using this database. In both 
cases, the obtained results indicated a significant improvement in speech 
intelligibility and quality compared with the unprocessed signal. Furthermore, 
the proposed method outperformed the nonsteering method.

© The Author(s) 2015.

DOI: 10.1177/2331216515618903
PMCID: PMC4771043
PMID: 26721924 [Indexed for MEDLINE]


445. Clin Otolaryngol Allied Sci. 2004 Dec;29(6):606-11. doi: 
10.1111/j.1365-2273.2004.00896.x.

Outcomes of myringoplasty in Australian Aboriginal children and factors 
associated with success: a prospective case series.

Mak D(1), MacKendrick A, Bulsara M, Coates H, Lannigan F, Lehmann D, Leidwinger 
L, Weeks S.

Author information:
(1)Kimberley Public Health Unit, Derby, and School of Population Health, The 
University of Western Australia, Perth, Australia. makho@bigpond.com

The objective of this study was to assess the outcomes of myringoplasties in 
Aboriginal children and to identify factors associated with a successful outcome 
with the use of prospective case series from primary health care clinics and 
hospitals in four rural and remote regions of Western Australia. All 58 
Aboriginal children, aged 5-15 years, who underwent 78 myringoplasties between 1 
January 2000 and 30 June 2001 were included in the study. Complete postoperative 
(post-op) follow-up was achieved following 78% of myringoplasties. The main 
outcome measures were (a) success, i.e. an intact tympanic membrane and normal 
hearing six or more months post-op in the operated ear, (b) closure of the 
perforation, (c) Post-op hearing improvement. Forty-nine per cent of 
myringoplasties were successful, 72% resulted in closure or reduction in the 
size of the perforation and 51% resulted in hearing improvement. After 
controlling for age, sex, clustering and number of previous myringoplasties, no 
association was observed between success or hearing improvement and perforation 
size, or the presence of serous aural discharge at the time of surgery. 
Myringoplasty resulted in hearing improvement and/or perforation closure in a 
significant proportion of children. Thus, primary school-aged Aboriginal 
children in whom conservative management of chronic suppurative otitis media has 
been unsuccessful should have access to myringoplasty because of the positive 
impact on their socialization, language and learning that results from improved 
hearing.

DOI: 10.1111/j.1365-2273.2004.00896.x
PMID: 15533146 [Indexed for MEDLINE]


446. Audiology. 1993;32(2):137-52. doi: 10.3109/00206099309071863.

Structure of perceived handicap in middle-aged males with noise-induced hearing 
loss, with and without tinnitus.

Hallberg LR(1), Johnsson T, Axelsson A.

Author information:
(1)Department of Psychology, University of Göteborg, Sweden.

By using a modified stepwise regression analysis technique, the structure of 
self-perceived handicap and tinnitus annoyance in 89 males with noise-induced 
hearing loss was described. Handicap was related to three clusters of variables, 
reflecting individual, environmental, and socioeconomic aspects, and 60% of the 
variance in self-perceived handicap was explained by the representatives of 
these clusters: i.e. 'acceptance of hearing problems', 'social support related 
to tinnitus' and 'years of education'. Tinnitus had no impact of its own on 
self-perceived handicap and only a modest portion (36%) of the variance in 
tinnitus annoyance was explained by 'sleep disturbance' and 'auditory perceptual 
difficulties'.

DOI: 10.3109/00206099309071863
PMID: 8476352 [Indexed for MEDLINE]


447. Acta Otolaryngol Suppl. 1994;514:73-7. doi: 10.3109/00016489409127565.

Study on the distribution of hearing levels in idiopathic bilateral 
sensorineural hearing loss.

Hirayama M(1), Shitara T, Okamoto M, Sano H.

Author information:
(1)Department of Otolaryngology, Kitasato University, Sagamihara, Japan.

The pattern of aggravation in hearing was investigated in 105 patients who were 
diagnosed as having idiopathic bilateral sensorineural hearing loss at the 
Hearing Loss Clinic, Department of Otolaryngology, Kitasato University Hospital. 
Audiograms were taken 1,069 times from the 105 cases over more than 3 years, and 
were used to obtain the distribution of hearing levels at each test frequency. 
The clinical course of idiopathic bilateral sensorineural hearing loss was 
divided into three stages: Stages I, II and III, based on the pattern of 
aggravation. The pattern of distribution of hearing levels at different stages 
was compared with each other with reference to peaks or clustering points. 
Similar peaks were noted at Stage II and Stage III as aggravation proceeded from 
Stage I. Another peak was noted in the zone of scale-out.

DOI: 10.3109/00016489409127565
PMID: 8073891 [Indexed for MEDLINE]


448. Vestn Otorinolaringol. 2016;81(6):42-46. doi: 10.17116/otorino201681642-46.

[The Russian-language version of the matrix test (RUMatrix) in free field in 
patients after cochlear implantation in the long term].

[Article in Russian; Abstract available in Russian from the publisher]

Goykhburg MV(1), Bakhshinyan VV(2), Petrova IP(3), Wazybok A(4), Kollmeier B(4), 
Tavartkiladze GA(2).

Author information:
(1)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513.
(2)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513; Russian Medical Academy for 
Post-Graduate Education, Moscow, Russia, 125993.
(3)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513; Voronezh Children's Clinical 
Hospital No 1, Voronezh, Russia, 394024.
(4)Medical Physics and Cluster of Excellence Hearing4all, Carl-von-Ossietzky, 
University Oldenburg, 26129, Oldenburg Germany.

The deterioration of speech intelligibility in the patients using cochlear 
implantation (CI) systems is especially well apparent in the noisy environment. 
It explains why phrasal speech tests, such as a Matrix sentence test, have 
become increasingly more popular in the speech audiometry during rehabilitation 
after CI. The Matrix test allows to estimate speech perception by the patients 
in a real life situation. The objective of this study was to assess the 
effectiveness of audiological rehabilitation of CI patients using the 
Russian-language version of the matrix test (RUMatrix) in free field in the 
noisy environment. 33 patients aged from 5 to 40 years with a more than 3 year 
experience of using cochlear implants inserted at the National Research Center 
for Audiology and Hearing Rehabilitation were included in our study. Five of 
these patients were implanted bilaterally. The results of our study showed a 
statistically significant improvement of speech intelligibility in the noisy 
environment after the speech processor adjustment; dynamics of the 
signal-to-noise ratio changes was -1.7 dB (p<0.001).
CONCLUSION: The RUMatrix test is a highly efficient method for the estimation of 
speech intelligibility in the patients undergoing clinical investigations in the 
noisy environment. The high degree of comparability of the RUMatrix test with 
the Matrix tests in other languages makes possible its application in 
international multicenter studies.

Publisher: У пациентов, использующих системы кохлеарной имплантации (КИ), 
разборчивость речи ухудшается именно в шумной обстановке, в связи с чем в 
настоящее время в мире все большую популярность приобретают фразовые тесты в 
шуме для оценки восприятия речи пациентом в реальной акустической обстановке, 
такие как матриксный фразовый тест RUMatrix. Цель исследования - оценка 
эффективности слухоречевой реабилитации у пациентов после КИ c использованием 
фразового теста RUMatrix в свободном звуковом поле в шуме. Обследованы 33 
пациента в возрасте от 5 до 40 лет после КИ, выполненной в Российском 
научно-практическом центре аудиологии и слухопротезирования, с опытом 
использования системы КИ более 3 лет, из них 5 пациентов - после билатеральной 
КИ. Выявлено статистически значимое улучшение разборчивости речи в шуме после 
проведения корректирующей настройки речевого процессора; динамика изменений 
составила: –1,7 дБ соотношения сигнал/шум (ОСШ) (р<0,001). RUMatrix является 
эффективным методом обследования для определения разборчивости речи у пациентов 
после КИ в шумной обстановке. Учитывая высокую сопоставимость RUMatrix с тестами 
на других языках, возможно его использование для проведения международных 
мультицентровых исследований.

Publisher: У пациентов, использующих системы кохлеарной имплантации (КИ), 
разборчивость речи ухудшается именно в шумной обстановке, в связи с чем в 
настоящее время в мире все большую популярность приобретают фразовые тесты в 
шуме для оценки восприятия речи пациентом в реальной акустической обстановке, 
такие как матриксный фразовый тест RUMatrix. Цель исследования - оценка 
эффективности слухоречевой реабилитации у пациентов после КИ c использованием 
фразового теста RUMatrix в свободном звуковом поле в шуме. Обследованы 33 
пациента в возрасте от 5 до 40 лет после КИ, выполненной в Российском 
научно-практическом центре аудиологии и слухопротезирования, с опытом 
использования системы КИ более 3 лет, из них 5 пациентов - после билатеральной 
КИ. Выявлено статистически значимое улучшение разборчивости речи в шуме после 
проведения корректирующей настройки речевого процессора; динамика изменений 
составила: –1,7 дБ соотношения сигнал/шум (ОСШ) (р<0,001). RUMatrix является 
эффективным методом обследования для определения разборчивости речи у пациентов 
после КИ в шумной обстановке. Учитывая высокую сопоставимость RUMatrix с тестами 
на других языках, возможно его использование для проведения международных 
мультицентровых исследований.

DOI: 10.17116/otorino201681642-46
PMID: 28091475 [Indexed for MEDLINE]


449. Trends Hear. 2018 Jan-Dec;22:2331216518779719. doi: 10.1177/2331216518779719.

Influence of Multi-microphone Signal Enhancement Algorithms on the Acoustics and 
Detectability of Angular and Radial Source Movements.

Lundbeck M(1)(2), Hartog L(1)(2), Grimm G(1)(2), Hohmann V(1)(2), Bramsløw L(3), 
Neher T(1)(4).

Author information:
(1)1 Medizinische Physik and Cluster of Excellence "Hearing4all", Oldenburg 
University, Germany.
(2)2 HörTech gGmbH, Oldenburg, Germany.
(3)3 Eriksholm Research Centre, Oticon A/S, Snekkersten, Denmark.
(4)4 Institute of Clinical Research, University of Southern Denmark, Odense, 
Denmark.

Hearing-impaired listeners are known to have difficulties not only with 
understanding speech in noise but also with judging source distance and 
movement, and these deficits are related to perceived handicap. It is possible 
that the perception of spatially dynamic sounds can be improved with hearing 
aids (HAs), but so far this has not been investigated. In a previous study, 
older hearing-impaired listeners showed poorer detectability for virtual 
left-right (angular) and near-far (radial) source movements due to lateral 
interfering sounds and reverberation, respectively. In the current study, 
potential ways of improving these deficits with HAs were explored. Using stimuli 
very similar to before, detailed acoustic analyses were carried out to examine 
the influence of different HA algorithms for suppressing noise and reverberation 
on the acoustic cues previously shown to be associated with source movement 
detectability. For an algorithm that combined unilateral directional microphones 
with binaural coherence-based noise reduction and for a bilateral beamformer 
with binaural cue preservation, movement-induced changes in spectral coloration, 
signal-to-noise ratio, and direct-to-reverberant energy ratio were greater 
compared with no HA processing. To evaluate these two algorithms perceptually, 
aided measurements of angular and radial source movement detectability were 
performed with 20 older hearing-impaired listeners. The analyses showed that, in 
the presence of concurrent interfering sounds and reverberation, the bilateral 
beamformer could restore source movement detectability in both spatial 
dimensions, whereas the other algorithm only improved detectability in the 
near-far dimension. Together, these results provide a basis for improving the 
detectability of spatially dynamic sounds with HAs.

DOI: 10.1177/2331216518779719
PMCID: PMC6024528
PMID: 29900799 [Indexed for MEDLINE]


450. Hear Res. 2017 Mar;345:96-107. doi: 10.1016/j.heares.2017.01.010. Epub 2017 Jan 
16.

Adding simultaneous stimulating channels to reduce power consumption in cochlear 
implants.

Langner F(1), Saoji AA(2), Büchner A(3), Nogueira W(3).

Author information:
(1)Department of Otolaryngology, Medical University Hannover and Cluster of 
Excellence Hearing4all, Hanover, Germany. Electronic address: 
langner.florian@mh-hannover.de.
(2)Advanced Bionics LLC, Valencia, CA, USA.
(3)Department of Otolaryngology, Medical University Hannover and Cluster of 
Excellence Hearing4all, Hanover, Germany.

Sound coding strategies for Cochlear Implant (CI) listeners can be used to 
control the trade-off between speech performance and power consumption. Most 
commercial CI strategies use non-simultaneous channel stimulation, stimulating 
only one electrode at a time. One could add parallel simultaneous stimulating 
channels such that the electrical interaction between channels is increased. 
This would produce spectral smearing, because the electrical fields of the 
simultaneous stimulated channels interact, but also power savings. The parallel 
channels produce a louder sensation than sequential stimulation. To test this 
hypothesis we implemented different sound coding strategies using a research 
interface from Advanced Bionics: the commercial F120 strategy using sequential 
channel stimulation (one channel equals two electrodes with current steering) 
and the Paired strategy, consisting of simultaneous stimulation with two 
channels. Here, the electrical field of both channels will interact, requiring 
less current on each channel to perceive the same loudness as with F120. 
However, channel interaction between the independent channels may reduce speech 
recognition or understanding. This can be diminished by adding an 
inverse-polarity stimulation channel between both channels. This strategy is 
termed Paired with Flanks. Additionally, Triplet with three channels and an 
adjacent Flank style was investigated. For each strategy we measured speech 
intelligibility with the Hochmair-Schulz-Moser sentence test. Spectral 
resolution was assessed using a spectral modulation depth detection task. 
Results show that Paired without Flanks obtains similar performance while 
reducing the current by 20% on average compared to F120. Triplet with and 
without Flanks shows overall poorer performance when compared to F120. All 
strategies inhibit the option to increase the pulse width which would result in 
even further decreased power consumption.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.01.010
PMID: 28104408 [Indexed for MEDLINE]


451. J Commun Disord. 1992 Mar;25(1):43-53. doi: 10.1016/0021-9924(92)90013-m.

The use of artificial neural networks to estimate speech intelligibility from 
acoustic variables: a preliminary analysis.

Metz DE(1), Schiavetti N, Knight SD.

Author information:
(1)Department of Communication Research, NTID, Rochester Institute of 
Technology, NY 14623-0887.

Previous research has used regression analysis to attempt to predict the 
intelligibility of hearing-impaired speakers from acoustic speech parameters. 
Improvement of prediction may be achieved by the use of computerized artificial 
neural networks to process mathematically the acoustic input variables as part 
of the intelligibility process. A preliminary scheme for estimating speech 
intelligibility from acoustic parameters using a neural network is outlined and 
preliminary data illustrate its use.

DOI: 10.1016/0021-9924(92)90013-m
PMID: 1401230 [Indexed for MEDLINE]


452. IEEE Trans Biomed Eng. 2002 Nov;49(11):1299-309. doi: 10.1109/TBME.2002.804590.

The application of bionic wavelet transform to speech signal processing in 
cochlear implants using neural network simulations.

Yao J(1), Zhang YT.

Author information:
(1)Department of Electronic Engineering, Chinese University of Hong Kong, N. T., 
Shatin, Hong Kong.

Cochlear implants (CIs) restore partial hearing to people with severe to 
profound sensorineural deafness; but there is still a marked performance gap in 
speech recognition between those who have received cochlear implant and people 
with a normal hearing capability. One of the factors that may lead to this 
performance gap is the inadequate signal processing method used in CIs. This 
paper investigates the application of an improved signal-processing method 
called bionic wavelet transform (BWT). This method is based upon the auditory 
model and allows for signal processing. Comparing the neural network simulations 
on the same experimental materials processed by wavelet transform (WT) and BWT, 
the application of BWT to speech signal processing in CI has a number of 
advantages, including: improvement in recognition rates for both consonants and 
vowels, reduction of the number of required channels, reduction of the average 
stimulation duration for words, and high noise tolerance. Consonant recognition 
results in 15 normal hearing subjects show that the BWT produces significantly 
better performance than the WT (t = -4.36276, p = 0.00065). The BWT has great 
potential to reduce the performance gap between CI listeners and people with a 
normal hearing capability in the future.

DOI: 10.1109/TBME.2002.804590
PMID: 12450360 [Indexed for MEDLINE]


453. J Acoust Soc Am. 2010 Jun;127(6):3689-95. doi: 10.1121/1.3365256.

Environment-specific noise suppression for improved speech intelligibility by 
cochlear implant users.

Hu Y(1), Loizou PC.

Author information:
(1)Department of Electrical Engineering, University of Texas-Dallas, Richardson, 
Texas 75080, USA. huy@uwm.edu

Attempts to develop noise-suppression algorithms that can significantly improve 
speech intelligibility in noise by cochlear implant (CI) users have met with 
limited success. This is partly because algorithms were sought that would work 
equally well in all listening situations. Accomplishing this has been quite 
challenging given the variability in the temporal/spectral characteristics of 
real-world maskers. A different approach is taken in the present study focused 
on the development of environment-specific noise suppression algorithms. The 
proposed algorithm selects a subset of the envelope amplitudes for stimulation 
based on the signal-to-noise ratio (SNR) of each channel. Binary classifiers, 
trained using data collected from a particular noisy environment, are first used 
to classify the mixture envelopes of each channel as either target-dominated 
(SNR>or=0 dB) or masker-dominated (SNR<0 dB). Only target-dominated channels are 
subsequently selected for stimulation. Results with CI listeners indicated 
substantial improvements (by nearly 44 percentage points at 5 dB SNR) in 
intelligibility with the proposed algorithm when tested with sentences embedded 
in three real-world maskers. The present study demonstrated that the 
environment-specific approach to noise reduction has the potential to restore 
speech intelligibility in noise to a level near to that attained in quiet.

DOI: 10.1121/1.3365256
PMCID: PMC2896410
PMID: 20550267 [Indexed for MEDLINE]


454. IEEE Trans Biomed Eng. 2007 Dec;54(12):2193-204. doi: 10.1109/tbme.2007.908336.

Expediting the identification of impaired channels in cochlear implants via 
analysis of speech-based confusion matrices.

Remus JJ(1), Throckmorton CS, Collins LM.

Author information:
(1)Department of Electrical and Computer Engineering, Duke University, Durham, 
NC 27708-0291, USA.

There is significant variability in the benefit provided by cochlear implants to 
severely deafened individuals. The reasons why some subjects exhibit low speech 
recognition scores are unknown; however, underlying physiological or 
psychophysical factors may be involved. Certain phenomena, such as 
indiscriminable electrodes and nonmonotonic pitch rankings, might hint at 
limitations in the ability of individual channels in the cochlear implant and/or 
sensorineural pathway to convey speech information. In this paper, four 
approaches for analyzing the results of a simple listening test using speech 
stimuli are investigated for the purpose of targeting channels of concern in 
order for follow-on psychophysical experiments to correctly identify channels 
performing in an "impaired" or anomalous manner. Listening tests were first 
conducted with normal-hearing subjects and acoustic models simulating 
channel-specific anomalies. Results indicate that these proposed analyses 
perform significantly better than chance in providing information about the 
location of anomalous channels. Vowel and consonant confusion matrices from six 
cochlear implant subjects were also analyzed to test the robustness of the 
proposed analyses to variability intrinsic to cochlear implant data. The current 
study suggests that confusion matrix analyses have the potential to expedite the 
identification of impaired channels by providing preliminary information prior 
to exhaustive psychophysical testing.

DOI: 10.1109/tbme.2007.908336
PMID: 18075035 [Indexed for MEDLINE]


455. Otol Neurotol. 2014 Oct;35(9):e240-4. doi: 10.1097/MAO.0000000000000529.

Evaluation of the bimodal benefit in a large cohort of cochlear implant subjects 
using a contralateral hearing aid.

Illg A(1), Bojanowicz M, Lesinski-Schiedat A, Lenarz T, Büchner A.

Author information:
(1)*Department of Otolaryngology, Hannover Medical School, Hannover, Germany; 
and †Cluster of Excellence, Hearing4All, Medizinische Hochschule Hannover, 
Germany.

OBJECTIVE: To investigate the benefit of contralateral residual hearing in a 
large group of cochlear implant recipients with different degrees of residual 
hearing.
PATIENTS: One hundred and forty-one adult patients (age in years: mean 58.82, 
min 16.27, max 88.20) wearing a cochlear implant and a contralateral hearing 
aid, bimodal.
INTERVENTION: Rehabilitative.
MAIN OUTCOME MEASURES: All 141 patients underwent speech perception testing in 
quiet and noise with cochlear implant (CI) alone, and with CI and hearing aid 
(HA). Additionally, pure-tone air conduction threshold levels were measured in 
all subjects. The bimodal benefit was analyzed and correlations to the hearing 
threshold for different audiometric frequencies were calculated.
RESULTS: Comparison between the scores for CI alone and CI + HA showed 
statistically significant advantages (p < 0.0001) in all four tests. The benefit 
for sentences in noise to each individual patient showed a negative correlation 
with the hearing threshold level of 125 Hz and 250 Hz, using a linear regression 
analysis applying the Spearman's rho correlation coefficient (r = -0.32, 
-0.232), and a significant difference at p = 0.006, p = 0.007. The correlations 
involving speech understanding in sentences in noise, and the hearing level of 
500 Hz and above, are not significant for the benefit obtained with a 
contralateral hearing aid.
CONCLUSION: The benefit of combined electric and acoustic hearing in bimodally 
fitted subjects depends mainly on residual hearing in the low-frequency range 
below 500 Hz. For bimodal fitting to yield significant benefits, hearing loss in 
the contralateral ear should not exceed 80 dB HL in the low frequencies.

DOI: 10.1097/MAO.0000000000000529
PMID: 25058838 [Indexed for MEDLINE]


456. IEEE Trans Biomed Eng. 2004 May;51(5):752-60. doi: 10.1109/TBME.2004.826597.

A novel speech-processing strategy incorporating tonal information for cochlear 
implants.

Lan N(1), Nie KB, Gao SK, Zeng FG.

Author information:
(1)Department of Biokinesiology and Physical Therapy, University of Soutern 
California, CHP-155, Los Angeles, CA 90089, USA. ninglan@usc.edu

Good performance in cochlear implant users depends in large part on the ability 
of a speech processor to effectively decompose speech signals into multiple 
channels of narrow-band electrical pulses for stimulation of the auditory nerve. 
Speech processors that extract only envelopes of the narrow-band signals (e.g., 
the continuous interleaved sampling (CIS) processor) may not provide sufficient 
information to encode the tonal cues in languages such as Chinese. To improve 
the performance in cochlear implant users who speak tonal language, we proposed 
and developed a novel speech-processing strategy, which extracted both the 
envelopes of the narrow-band signals and the fundamental frequency (F0) of the 
speech signal, and used them to modulate both the amplitude and the frequency of 
the electrical pulses delivered to stimulation electrodes. We developed an 
algorithm to extract the fundatmental frequency and identified the general 
patterns of pitch variations of four typical tones in Chinese speech. The 
effectiveness of the extraction algorithm was verified with an artificial neural 
network that recognized the tonal patterns from the extracted F0 information. We 
then compared the novel strategy with the envelope-extraction CIS strategy in 
human subjects with normal hearing. The novel strategy produced significant 
improvement in perception of Chinese tones, phrases, and sentences. This novel 
processor with dynamic modulation of both frequency and amplitude is encouraging 
for the design of a cochlear implant device for sensorineurally deaf patients 
who speak tonal languages.

DOI: 10.1109/TBME.2004.826597
PMID: 15132501 [Indexed for MEDLINE]


457. Disabil Rehabil. 2002 Nov 20;24(17):904-13. doi: 10.1080/09638280210148602.

Audiometric configurations of hearing impaired children in Hong Kong: 
implications for amplification.

Yuen KC(1), McPherson B.

Author information:
(1)Department of Speech and Hearing Sciences, University of Hong Kong, Hong 
Kong, China.

PURPOSE: Children with hearing loss who require special school placement may 
have a wide range of audiometric configurations. Since such children will vary 
in auditory status their amplification requirements may also be diverse. This 
study examined the audiological records of 231 children attending four schools 
for hearing impaired children in Hong Kong to gain an understanding of common 
audiometric patterns found in the school children and their auditory 
rehabilitation needs.
METHOD: Data on the children's aetiology of hearing loss, hearing status, 
tympanometric findings and the electroacoustic characteristics of their hearing 
aids were obtained. For 424 children's ears considered having essentially 
sensorineural hearing loss, k-means cluster analysis methods were used to 
categorize audiometric configuration groups.
RESULTS: Cluster analysis that indicated that five distinct audiometric 
configurations could be found among the school children. Different clusters 
contained children who had differing amplification needs. The study analysed a 
number of parameters to check fitting outcomes, including average prescribed 
gain, frequency-specific measured versus prescribed gain, prescribed frequency 
response, measured versus prescribed frequency response and the predicted aided 
thresholds for the children.
CONCLUSION: The amplification needs associated with these five configurations, 
including recommended prescription gain, maximum power output and possible 
signal processing strategies, were considered. The clustering algorithm approach 
proved useful as a means of grouping distinctive audiometric profiles.

DOI: 10.1080/09638280210148602
PMID: 12519486 [Indexed for MEDLINE]


458. Br J Audiol. 1991 Feb;25(1):15-24. doi: 10.3109/03005369109077860.

Psychological dimensions in patients with disabling tinnitus and 
craniomandibular disorders.

Erlandsson SI(1), Rubinstein B, Axelsson A, Carlsson SG.

Author information:
(1)Department of Psychology, University of Göteborg, Sweden.

Forty-two patients with severe tinnitus and craniomandibular disorders (CMD) are 
presented from an audiological and psychological point of view. During a 2-week 
period, the patients rated their mood and their tinnitus. Based upon mood 
ratings, patients were grouped into three clusters (high, medium and low mood). 
The three groups differed in a number of respects, audiological as well as 
psychological. Patients in the low mood group experienced significantly more 
intense and severe tinnitus and more daily stress than patients in the high mood 
group. Ratings of irritation and concentration difficulties seemed to be mood 
related, and discriminated between patients in the low mood group and patients 
in the moderate and the high mood groups. Difference in hearing level between 
the left and the right ear was more pronounced in patients with low mood. There 
were, however, no significant differences between the groups in the 
stomatognathic variables. It is concluded that the above mentioned audiological 
and psychological observations should be considered as potentially important for 
satisfactory management of individual tinnitus patients. Further studies of the 
effects of optimally compensated hearing on depressed mood in patients with 
noise-induced hearing loss (NIHL) and tinnitus are required.

DOI: 10.3109/03005369109077860
PMID: 2012899 [Indexed for MEDLINE]


459. Ear Hear. 2003 Dec;24(6):528-38. doi: 10.1097/01.AUD.0000100207.97243.88.

The reception of environmental sounds through wearable tactual Aids.

Reed CM(1), Delhorne LA.

Author information:
(1)Research Laboratory of Electronics, Massachusetts Institute of Technology, 
Cambridge, Massachusetts 02139, USA. reed@zaphod.mit.edu

OBJECTIVE: The objective of this study was to investigate the ability to 
identify environmental sounds through a wearable tactual aid.
DESIGN: A test of the ability to identify environmental sounds was developed, 
employing closed sets of ten sounds in each of four different settings (General 
Home, Kitchen, Office, and Outdoors). The participants in the study included a 
group of three laboratory-trained subjects with normal hearing and a group of 
three subjects with profound deafness who were experienced users of a tactual 
device (the Tactaid 7). Identification testing was conducted in each of the four 
environmental-sound settings using a one-interval, ten-alternative, 
forced-choice procedure. The laboratory-trained subjects received training with 
trial-by-trial correct-answer feedback, followed by testing in the absence of 
feedback using the Tactaid 7 device. The experienced tactual-aid users were 
tested initially without feedback to establish baseline levels of performance 
derived from their prior field experience with the Tactaid 7. These subjects 
then received additional trials in the presence of correct-answer feedback to 
determine the effects of training on their performance. The data were summarized 
in terms of overall percent-correct identification scores and information 
transfer (IT) in bits. Confusion patterns were described using a hierarchical 
clustering analysis.
RESULTS: Post-training results with the laboratory-trained subjects on the 
Tactaid 7 indicated that performance was similar for the four test environments, 
with percent-correct scores averaging 65% (and IT of 2.0 bits). For the 
experienced tactual-aid users, performance was similar across the four 
environments, averaging 36% correct (and IT of 1.4 bits) for initial testing 
without feedback. Scores were increased to 60% correct (and IT of 1.9 bits) in 
the presence of correct-answer feedback. Similar trends were observed in the 
hierarchical-clustering analysis across both groups of subjects. Within each 
stimulus set, certain items tended to cluster together, whereas other items 
tended to appear in single-item clusters. The highly identified stimuli tended 
to be characterized by unique temporal patterns and confused stimuli seemed to 
be most similar in terms of their spectral characteristics.
CONCLUSIONS: Through the multi-channel spectral display of the Tactaid 7 device, 
subjects were able to identify roughly 2 bits of information in each of four 
10-item sets of sounds representative of different environmental settings. 
Temporal cues appeared to play a larger role in identification of sounds than 
spectral or intensive cues.

DOI: 10.1097/01.AUD.0000100207.97243.88
PMID: 14663352 [Indexed for MEDLINE]


460. Vestn Otorinolaringol. 2016;81(6):47-50. doi: 10.17116/otorino201681647-50.

[Application of the mathematical model for prognosis in the rehabilitation of 
children after cochlear implantation].

[Article in Russian; Abstract available in Russian from the publisher]

Petrova IP(1), Balashova EA(2), Goykhburg MV(3), Mashchenko AI(1), Markova 
TG(4), Bakhshinyan VV(4), Tavartkiladze GA(4).

Author information:
(1)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513; Voronezh Children's Clinical 
Hospital No 1, Voronezh, Russia, 394024.
(2)Federal State Budgetary Educational Institution of Higher Professional 
Education 'Voronezh State University of Engineering Technologies', Voronezh, 
Russia, 394036.
(3)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513.
(4)National Research Center for Audiology and Hearing Rehabilitation, Russian 
Medico-Biological Agency, Moscow, Russia, 117513; Russian Medical Academy for 
Post-Graduate Education, Moscow, Russia, 125993.

Despite the variety of etiological factors, cochlear implantation (CI) remains 
the only effective method for the rehabilitation of the patients presenting with 
total deafness. The aim of this study was the enhancement of the efficiency of 
selection of the candidates for CI, the improvement of the quality of 
rehabilitation of the patients with cochlear implants, and the determination of 
the prognostic criteria for clinical trials.
PATIENTS AND METHODS: (CI). The decision-making support system (DMSS) based on 
the artificial neural networks (ANNs) has been created to enhance the efficiency 
of rehabilitation of the patients with cochlear implants and increase the 
effectiveness of the selection of candidates for cochlear implantation. The 
results of the children's rehabilitation after CI have been analyzed by using a 
mathematical model of artificial neural networks (Kohonen layer). The basis for 
the assessment of ANNs was formed by the results of the observations of 
audioverbal perception in 110 patients aged from 6 months to 17 years. The 
initial data were the average values obtained with the use of the 
Russian-language version of the Nottingham children's implant profile's test T1 
- T3. The testing was performed before CI and 3, 6, 12, 18, and 24 months after 
it.
MAIN RESULTS: The work yielded the four-cluster data structure. It made it 
possible to estimate the effectiveness of the clinical trials in selected 
classes depending on the etiology of the disease, the age of the patients, and 
their experience with the application of hearing aids. The reliable estimation 
of the dynamics of auditory perception at the stage of rehabilitation and 
prognosis of the outcomes of CI made it possible to take additional preventive 
and therapeutic measures in the combination with complementary psychological and 
educational procedures.

Publisher: Цель исследования - повышение эффективности отбора кандидатов на 
кохлеарную имплантацию (КИ), улучшение качества реабилитации пациентов с 
имплантами, определение прогностических критериев КИ. Проведен анализ 
результатов реабилитации детей после КИ с использованием математической модели 
ИНС (слоя Кохонена). В основу построения ИНС легли результаты оценки развития 
слухоречевого восприятия у 110 пациентов в возрасте от 6 мес до 17 лет. 
Тестирование пациентов проводилось до КИ и через 3, 6, 12, 18 и 24 мес после 
проведенной КИ с помощью русскоязычной версии батареи тестов EARS. Проведенная 
работа позволила получить четырехкластерную структуру данных, оценить 
эффективность КИ в выделенных классах в зависимости от этиологии заболевания, 
возраста, наличия опыта слухопротезирования. На этапе реабилитации произведены 
достоверная оценка динамики развития слухового восприятия и прогноз результатов 
КИ, что дало возможность своевременно применить дополнительные методы лечения в 
сложных случаях.

Publisher: Цель исследования - повышение эффективности отбора кандидатов на 
кохлеарную имплантацию (КИ), улучшение качества реабилитации пациентов с 
имплантами, определение прогностических критериев КИ. Проведен анализ 
результатов реабилитации детей после КИ с использованием математической модели 
ИНС (слоя Кохонена). В основу построения ИНС легли результаты оценки развития 
слухоречевого восприятия у 110 пациентов в возрасте от 6 мес до 17 лет. 
Тестирование пациентов проводилось до КИ и через 3, 6, 12, 18 и 24 мес после 
проведенной КИ с помощью русскоязычной версии батареи тестов EARS. Проведенная 
работа позволила получить четырехкластерную структуру данных, оценить 
эффективность КИ в выделенных классах в зависимости от этиологии заболевания, 
возраста, наличия опыта слухопротезирования. На этапе реабилитации произведены 
достоверная оценка динамики развития слухового восприятия и прогноз результатов 
КИ, что дало возможность своевременно применить дополнительные методы лечения в 
сложных случаях.

DOI: 10.17116/otorino201681647-50
PMID: 28091476 [Indexed for MEDLINE]


461. Hear Res. 1997 Feb;104(1-2):101-11. doi: 10.1016/s0378-5955(96)00184-0.

Histopathologic observations of the aging gerbil cochlea.

Adams JC(1), Schulte BA.

Author information:
(1)Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, Boston 
02114, USA.

Age-related histopathologic changes were examined in cochleas from 17 gerbils 
born and kept in a quiet environment until near the end of their life 
expectancy. Hearing loss varied greatly as did the loss of outer hair cells 
(OHC). Inner hair cells (IHC) were seldom missing even in cochleas with severe 
hearing losses. Flask- and spherical-shaped OHCs were frequently seen in the 
apical turn. Stereocilia were usually present and orderly on OHCs, but the 
tallest row of stereocilia on IHCs was often disarrayed and sometimes missing. 
Alterations in supporting cells were sometimes present in regions of extensive 
OHC loss. Although pillar cells were seldom missing, the nuclei of outer pillar 
cells were commonly displaced from their normal basal position. The density of 
radial fibers appeared similar to that in young gerbils except in the apical 
turn of one old ear where a marked loss of radial fibers occurred without an 
attendant loss of IHCs. All of the quiet-aged cochleas showed a characteristic 
clustering of epithelial cells lining the scala media surface of Reissner's 
membrane. This structural rearrangement was not accompanied by a significant 
decrease in the total number of cells forming Reissner's membrane and did not 
appear to be associated with hearing loss. The findings confirm and extend 
earlier work showing that several different types of cells are susceptible to 
histopathologic changes in old ears. The extent of histopathologic changes 
varied widely as did the degree of hearing loss in animals with a restricted 
genetic background and maintained under carefully controlled environmental 
conditions. It was not possible, based on these initial findings, to relate 
specific structural to specific functional changes in the aging cochlea. Further 
light and electron microscopic analysis of other regions from these aged 
cochleas may provide more conclusive data.

DOI: 10.1016/s0378-5955(96)00184-0
PMID: 9119754 [Indexed for MEDLINE]


462. J Acoust Soc Am. 1995 Jan;97(1):461-70. doi: 10.1121/1.412274.

Classification of background noises for hearing-aid applications.

Kates JM(1).

Author information:
(1)Center for Research in Speech and Hearing Sciences, City University of New 
York, Graduate Center, New York 10036.

A background-noise classification procedure is being developed for hearing-aid 
applications, wherein the hearing-aid response would be adjusted in response to 
changes in the noise environment. The classification procedure is based on 
measuring four signal features giving the fluctuations of the signal envelope 
and the mean frequency and low- and high-frequency slopes of the average 
spectrum. A more complicated procedure, based on determining the envelope 
modulation spectra in auditory critical bands, was also investigated and was 
found to offer no advantages over the simpler procedure. The accuracy of the 
classification procedure was determined for eleven everyday background noises 
under optimal conditions where the training and test noise sequences were 
different portions of the same short noise recording. A cluster analysis was 
used to determine the similarities among the feature vectors for the noises, and 
when the noises are grouped into a reduced number of clusters the 
noise-classification accuracy using the four features exceeds 90%.

DOI: 10.1121/1.412274
PMID: 7860827 [Indexed for MEDLINE]


463. J Acoust Soc Am. 2017 Apr;141(4):2338. doi: 10.1121/1.4979114.

Extent of lateralization at large interaural time differences in simulated 
electric hearing and bilateral cochlear implant users.

Baumgärtel RM(1), Hu H(1), Kollmeier B(1), Dietz M(1).

Author information:
(1)Medizinische Physik, Carl von Ossietzky Universität Oldenburg and Cluster of 
Excellence "Hearing4all," Oldenburg, Germany.

Normal-hearing (NH) listeners are able to localize sound sources with 
extraordinary accuracy through interaural cues, most importantly interaural time 
differences (ITDs) in the temporal fine structure. Bilateral cochlear implant 
(CI) users are also able to localize sound sources, yet generally at lower 
accuracy than NH listeners. The gap in performance can in part be attributed to 
current CI systems not faithfully transmitting interaural cues, especially ITDs. 
With the introduction of binaurally linked CI systems, the presentation of ITD 
cues for bilateral CI users is foreseeable. The current study therefore 
investigated extent-of-lateralization percepts elicited in bilateral CI 
listeners when presented with single-electrode pulse-trains carrying controlled 
ITD cues. The results were compared against NH listeners listening to broadband 
stimuli as well as simulations of CI listening. Broadband stimuli in NH 
listeners were perceived as fully lateralized within the natural ITD range. 
Using simulated as well as real CI stimuli, however, only a fraction of the full 
extent of lateralization range was covered by natural ITDs. The maximum extent 
of lateralization was reached at ITDs as large as twice the natural limit. The 
results suggest that ITD-enhancement might be a viable option for improving 
localization abilities with future binaural CI systems.

DOI: 10.1121/1.4979114
PMID: 28464641 [Indexed for MEDLINE]


464. Int J Lang Commun Disord. 2016 Sep;51(5):518-30. doi: 10.1111/1460-6984.12228. 
Epub 2016 Feb 11.

Linguistic profiles of children with CI as compared with children with hearing 
or specific language impairment.

de Hoog BE(1), Langereis MC(2), van Weerdenburg M(1), Knoors HE(1)(3), Verhoeven 
L(1).

Author information:
(1)Behavioural Science Institute, Radboud University Nijmegen, P.O. Box 9104, 
6500, HE Nijmegen, The Netherlands.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, Hearing and 
Implants, Radboud University Medical Center, Donders Institute for Brain, 
Cognition and Behaviour, P.O. Box 9101, 6500, HB Nijmegen, The Netherlands.
(3)Royal Dutch Kentalis, P.O. Box 7, 5270, BA Sint-Michielsgestel, The 
Netherlands.

BACKGROUND: The spoken language difficulties of children with moderate or severe 
to profound hearing loss are mainly related to limited auditory speech 
perception. However, degraded or filtered auditory input as evidenced in 
children with cochlear implants (CIs) may result in less efficient or slower 
language processing as well. To provide insight into the underlying nature of 
the spoken language difficulties in children with CIs, linguistic profiles of 
children with CIs are compared with those of hard-of-hearing (HoH) children with 
conventional hearing aids and children with specific language impairment (SLI).
AIMS: To examine differences in linguistic abilities and profiles of children 
with CIs as compared with HoH children and children with SLI, and whether the 
spoken language difficulties of children with CIs mainly lie in limited auditory 
perception or in language processing problems.
METHODS & PROCEDURE: Differences in linguistic abilities and differential 
linguistic profiles of 47 children with CI, 66 HoH children with moderate to 
severe hearing loss, and 127 children with SLI are compared, divided into two 
age cohorts. Standardized Dutch tests were administered. Factor analyses and 
cluster analyses were conducted to find homogeneous linguistic profiles of the 
children.
OUTCOMES & RESULTS: The children with CIs were outperformed by their HoH peers 
and peers with SLI on most linguistic abilities. Concerning the linguistic 
profiles, the largest group of children with CIs and HoH children shared similar 
profiles. The profiles observed for most of the children with SLI were different 
from those of their peers with hearing loss in both age cohorts.
CONCLUSIONS & IMPLICATIONS: Results suggest that the underlying nature of spoken 
language problems in most children with CIs manifests in limited auditory 
perception instead of language processing difficulties. However, there appears 
to be a subgroup of children with CIs whose linguistic profiles resemble those 
of children with SLI.

© 2016 Royal College of Speech and Language Therapists.

DOI: 10.1111/1460-6984.12228
PMID: 26864995 [Indexed for MEDLINE]


465. Ear Hear. 2024 Jan-Feb 01;45(1):219-226. doi: 10.1097/AUD.0000000000001415. Epub 
2023 Aug 15.

A Novel Method to Determine the Maximum Output of Individual Patients for an 
Active Transcutaneous Bone Conduction Implant Using Clinical Routine Data.

Ghoncheh M(1), Busch S(1)(2), Lenarz T(1)(2), Maier H(1)(2).

Author information:
(1)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence "Hearing4all", Hannover Medical School, Hannover, 
Germany.

OBJECTIVES: The maximum output provided by a bone conduction (BC) device is one 
of the main factors that determines the success when treating patients with 
conductive or mixed hearing loss. Different approaches such as sound pressure 
measurements using a probe microphone in the external auditory canal or a 
surface microphone on the forehead have been previously introduced to determine 
the maximum output of active transcutaneous BC devices that are not directly 
accessible after implantation. Here, we introduce a method to determine the 
maximum output hearing level (MOHL) of a transcutaneous active BC device using 
patients' audiometric data.
DESIGN: We determined the maximum output in terms of hearing level MOHL (dB HL) 
of the Bonebridge using the audiometric and direct BC threshold of the patient 
together with corresponding force levels at hearing threshold and the maximum 
force output of the device. Seventy-one patients implanted with the Bonebridge 
between 2011 and 2020 (average age 45 ± 19 years ranging from 5 to 84 years) 
were included in this study. The analyses of MOHLs were performed by (1) 
dividing patients into two groups with better or worse average audiometric BC 
threshold (0.5, 1, 2, 4 kHz), on the ipsilateral side or (2) by separating the 
MOHLs based on better or worse frequency-by-frequency specific audiometric BC 
thresholds on the ipsilateral (implanted) side.
RESULTS: When using a frequency-by-frequency analysis obtained average 
ipsilateral MOHLs were in the range between 51 and 73 dB HL for frequencies from 
0.5 to 6 kHz in the group with better audiometric BC threshold on the 
ipsilateral ears. The average contralateral MOHLs in the group with better 
contralateral hearing were in the range from 43 to 67 dB HL. The variability of 
the data was approximately 6 to 11 dB (SDs) across measured frequencies (0.5 to 
6 kHz). The average MOHLs were 4 to 8 dB higher across frequencies in the group 
with better audiometric BC threshold on the ipsilateral ears than in the group 
with better audiometric BC threshold on the contralateral ears. The differences 
between groups were significant across measured frequencies ( t test; p < 0.05).
CONCLUSIONS: Our proposed method demonstrates that the individual 
frequency-specific MOHL on the ipsilateral and contralateral side of individual 
patients with a transcutaneous BC device can be determined mainly using direct 
and audiometric BC threshold data of the patients from clinical routine. The 
average MOHL of the implant was found 4 to 8 dB higher on the ipsilateral 
(implanted) side than on the contralateral side.

Copyright © 2023 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health, Inc.

DOI: 10.1097/AUD.0000000000001415
PMCID: PMC10718211
PMID: 37580866 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


466. Otol Neurotol. 2013 Dec;34(9):1711-8. doi: 10.1097/MAO.0000000000000225.

First clinical experiences with a direct acoustic cochlear stimulator in 
comparison to preoperative fitted conventional hearing aids.

Busch S(1), Kruck S, Spickers D, Leuwer R, Hoth S, Praetorius M, Plinkert PK, 
Mojallal H, Schwab B, Maier H, Lenarz T.

Author information:
(1)*Department of Otolaryngology, and †Cluster of Excellence Hearing4all, 
Medical University Hannover, Hannover; ‡Department of Oto-Rhino-Laryngology, 
HELIOS Hospital Krefeld, Krefeld; and §Department of Otolaryngology, Head and 
Neck Surgery, University of Heidelberg, Heidelberg, Germany.

OBJECTIVE: Patients with moderate-to-severe mixed hearing losses (MHLs) are hard 
to provide sufficient benefit with currently available conventional hearing 
aids. Here, the long-term safety of a direct acoustic cochlear stimulator (DACS) 
and the effectiveness compared with conventional "high-performance" hearing aids 
were investigated.
STUDY DESIGN: Prospective, within patient reference, nonrandomized, 
interventional multicenter clinical study performed at these 3 centers: Medical 
University Hannover, University of Heidelberg, and Helios Hospital Krefeld.
PATIENTS AND INTERVENTION: Ten otosclerosis patients with severe-to-profound MHL 
were preoperatively fitted with state-of-the-art conventional hearing aids (HA). 
After 2 months of testing conventional HA, 9 of the patients decided to be 
implanted with a DACS.
MAIN OUTCOME MEASURES: Air conduction (AC) and bone conduction (BC) aided and 
unaided thresholds, speech discrimination before and after implantation and at 
3, 6, and 12 months after activation. The subjective benefit was assessed by the 
Abbreviated Profile of Hearing Aid Benefit (APHAB).
RESULTS: Preoperative hearing thresholds were preserved over the 12 month 
observation time after activation. Average functional gain (0.5-4 kHz) achieved 
with conventional HA was 47 dB compared with 56 dB with the DACS. 
Speech-in-noise tests revealed a lower SNR for DACS (3.1 dB) than for the HA 
(6.6 dB) and patients were more satisfied with the DACS.
CONCLUSION: The DACS significantly improved hearing, speech intelligibility, and 
satisfaction in patients with a severe-to-profound mixed hearing loss and can be 
considered a safe and useful alternative to conventional hearing aids.

DOI: 10.1097/MAO.0000000000000225
PMID: 24232068 [Indexed for MEDLINE]


467. J Am Acad Audiol. 1993 May;4(3):163-71.

Development of an expert system for pediatric auditory brainstem response 
interpretation.

Tharpe AM(1), Biswas G, Hall JW 3rd.

Author information:
(1)Division of Hearing and Speech Sciences, Vanderbilt University School of 
Medicine, Nashville, Tennessee.

Expert systems are computer programs which incorporate artificial intelligence 
technology and are created to emulate the decision-making abilities of human 
experts. The advantage of such systems lies in their ability to capture and 
model expert problem solving knowledge in a domain and make it available to an 
unlimited number of consumers in an economic and efficient way. The purpose of 
this project was to develop an expert system to interpret infant auditory 
brainstem response data as entered by the user. The resulting system provides 
diagnostic conclusions regarding hearing status, type of hearing loss, and 
brainstem function at an accuracy level equal to that of a human expert.

PMID: 8318707 [Indexed for MEDLINE]


468. IEEE Trans Neural Syst Rehabil Eng. 2001 Mar;9(1):42-8. doi: 
10.1109/7333.918275.

A neural network model for optimizing vowel recognition by cochlear implant 
listeners.

Chang CH(1), Anderson GT, Loizou PC.

Author information:
(1)Applied Science Department at the University of Arkansas at Little Rock, 
72204, USA.

Due to the variability in performance among cochlear implant (CI) patients, it 
is becoming increasingly important to find ways to optimally fit patients with 
speech processing strategies. This paper proposes an approach based on neural 
networks, which can be used to automatically optimize the performance of CI 
patients. The neural network model is implemented in two stages. In the first 
stage, a neural network is trained to mimic the CI patient's performance on the 
vowel identification task. The trained neural network is then used in the second 
stage to adjust a free parameter to improve vowel recognition performance for 
each individual patient. The parameter examined in this study was a weighting 
function applied to the compressed channel amplitudes extracted from a 6-channel 
continuous interleaved sampling (CIS) strategy. Two types of weighting functions 
were examined, one which assumed channel interaction, and one which assumed no 
interaction between channels. Results showed that the neural network models 
closely matched the performance of five Med-EI/CIS-Link implant patients. The 
resulting weighting functions obtained after neural network training improved 
vowel performance, with the larger improvement (4%) attained by the weighting 
function which modeled channel interaction.

DOI: 10.1109/7333.918275
PMID: 11482362 [Indexed for MEDLINE]


469. Ear Hear. 2005 Feb;26(1):48-61. doi: 10.1097/00003446-200502000-00005.

Reception of environmental sounds through cochlear implants.

Reed CM(1), Delhorne LA.

Author information:
(1)Research Laboratory of Electronics, Massachusetts Institute of Technology, 
Cambridge, Massachusetts 02139, USA.

OBJECTIVE: The objective of this study was to measure the performance of persons 
with cochlear implants on a test of environmental-sound reception.
DESIGN: The reception of environmental sounds was studied using a test employing 
closed sets of 10 sounds in each of four different settings (General Home, 
Kitchen, Office, and Outside). The participants in the study were 11 subjects 
with cochlear implants. Identification testing was conducted under each of the 
four closed sets of stimuli using a one-interval, 10-alternative, forced-choice 
procedure. The data were summarized in terms of overall percent correct 
identification scores and information transfer (IT) in bits. Confusion patterns 
were described using a hierarchical-clustering analysis. In addition, individual 
performance on the environmental-sound task was related to the ability to 
recognize isolated words through the cochlear implant alone.
RESULTS: Levels of performance were similar across the four stimulus sets. Mean 
scores across subjects ranged from 45.3% correct (and IT of 1.5 bits) to 93.8% 
correct (and IT of 3.1 bits). Performance on the environmental-sound 
identification test was roughly related to NU-6 word recognition ability. 
Specifically, those subjects with word scores greater than 34% correct performed 
at levels of 80 to 94% on environmental-sound recognition, whereas subjects with 
word scores less than 34% had greater difficulty on the task. Results of the 
hierarchical clustering analysis, conducted on two groups of subjects (a 
high-performing [HP] group and a low-performing [LP] group), indicated that 
confusions were confined to three or four specific stimuli for the HP subjects 
and that larger clusters of confused stimuli were observed in the data of the LP 
group. Signals with distinct temporal-envelope characteristics were easily 
perceived by all subjects, and confused items tended to share similar overall 
durations and temporal envelopes.
CONCLUSIONS: Temporal-envelope cues appear to play a large role in the 
identification of environmental sounds through cochlear implants. The finer 
distinctions made by the HP group compared with the LP group may be related to a 
better ability both to resolve temporal differences and to use gross spectral 
cues. These findings are qualitatively consistent with patterns of confusions 
observed in the reception of speech segments through cochlear implants.

DOI: 10.1097/00003446-200502000-00005
PMID: 15692304 [Indexed for MEDLINE]


470. Ear Hear. 2016 Jul-Aug;37(4):e263-72. doi: 10.1097/AUD.0000000000000259.

fMRI as a Preimplant Objective Tool to Predict Postimplant Oral Language 
Outcomes in Children with Cochlear Implants.

Deshpande AK(1), Tan L, Lu LJ, Altaye M, Holland SK.

Author information:
(1)1Department of Speech-Language-Hearing Sciences, Hofstra University, 
Hempstead, New York, USA; 2Division of Biomedical Informatics, Cincinnati 
Children's Hospital Research Foundation, Cincinnati, Ohio, USA; 3School of 
Computing Sciences and Informatics, 4Department of Environmental Health, College 
of Medicine, University of Cincinnati, Cincinnati, Ohio, USA; 5Division of 
Biostatistics and Epidemiology, 6Pediatric Neuroimaging Research Consortium, and 
7Department of Pediatric Radiology, Cincinnati Children's Hospital Medical 
Center, Cincinnati, Ohio, USA.

OBJECTIVES: Despite the positive effects of cochlear implantation, postimplant 
variability in speech perception and oral language outcomes is still difficult 
to predict. The aim of this study was to identify neuroimaging biomarkers of 
postimplant speech perception and oral language performance in children with 
hearing loss who receive a cochlear implant. The authors hypothesized positive 
correlations between blood oxygen level-dependent functional magnetic resonance 
imaging (fMRI) activation in brain regions related to auditory language 
processing and attention and scores on the Clinical Evaluation of Language 
Fundamentals-Preschool, Second Edition (CELF-P2) and the Early Speech Perception 
Test for Profoundly Hearing-Impaired Children (ESP), in children with congenital 
hearing loss.
DESIGN: Eleven children with congenital hearing loss were recruited for the 
present study based on referral for clinical MRI and other inclusion criteria. 
All participants were <24 months at fMRI scanning and <36 months at first 
implantation. A silent background fMRI acquisition method was performed to 
acquire fMRI during auditory stimulation. A voxel-based analysis technique was 
utilized to generate z maps showing significant contrast in brain activation 
between auditory stimulation conditions (spoken narratives and narrow band 
noise). CELF-P2 and ESP were administered 2 years after implantation. Because 
most participants reached a ceiling on ESP, a voxel-wise regression analysis was 
performed between preimplant fMRI activation and postimplant CELF-P2 scores 
alone. Age at implantation and preimplant hearing thresholds were controlled in 
this regression analysis.
RESULTS: Four brain regions were found to be significantly correlated with 
CELF-P2 scores. These clusters of positive correlation encompassed the 
temporo-parieto-occipital junction, areas in the prefrontal cortex and the 
cingulate gyrus. For the story versus silence contrast, CELF-P2 core language 
score demonstrated significant positive correlation with activation in the right 
angular gyrus (r = 0.95), left medial frontal gyrus (r = 0.94), and left 
cingulate gyrus (r = 0.96). For the narrow band noise versus silence contrast, 
the CELF-P2 core language score exhibited significant positive correlation with 
activation in the left angular gyrus (r = 0.89; for all clusters, corrected p < 
0.05).
CONCLUSIONS: Four brain regions related to language function and attention were 
identified that correlated with CELF-P2. Children with better oral language 
performance postimplant displayed greater activation in these regions 
preimplant. The results suggest that despite auditory deprivation, these regions 
are more receptive to gains in oral language development performance of children 
with hearing loss who receive early intervention via cochlear implantation. The 
present study suggests that oral language outcome following cochlear implant may 
be predicted by preimplant fMRI with auditory stimulation using natural speech.

DOI: 10.1097/AUD.0000000000000259
PMID: 26689275 [Indexed for MEDLINE]


471. Sci Rep. 2019 Mar 6;9(1):3675. doi: 10.1038/s41598-019-40300-7.

Standard Audiograms for Koreans Derived through Hierarchical Clustering Using 
Data from the Korean National Health and Nutrition Examination Survey 2009-2012.

Chang YS(1), Yoon SH(2), Kim JR(2), Baek SY(3), Cho YS(2), Hong SH(4), Kim S(3), 
Moon IJ(5).

Author information:
(1)Department of Otorhinolaryngology - Head and Neck Surgery, Korea University 
College of Medicine, Korea University Ansan Hospital, Ansan, Republic of Korea.
(2)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Medical 
Center, Sungkyunkwan University School of Medicine, Seoul, Korea.
(3)Statistics and Data Center, Research Institute for Future Medicine, Samsung 
Medical Center, Seoul, Korea.
(4)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Changwon 
Hospital, Sungkyunkwan University School of Medicine, Seoul, Korea.
(5)Department of Otorhinolaryngology-Head and Neck Surgery, Samsung Medical 
Center, Sungkyunkwan University School of Medicine, Seoul, Korea. 
moonij@skku.edu.

Assessments of standardized region/population-specific audiological 
characteristics are needed for provision of effective rehabilitative services 
through reducing costs associated with hearing aids. This study aims to propose 
a set of standard audiograms representing the Korean population that were 
derived by analyzing data from the 2009-2012 Korea National Health and Nutrition 
Examination Survey (KNHANES), a nationwide epidemiologic study conducted by 
Korean government organizations. Standard audiograms were derived by applying a 
hierarchical clustering method from recorded audiologic data that were obtained 
independently at 6 frequencies for each ear: 0.5, 1.0, 2.0, 3.0, 4.0, and 
6.0 kHz (in dB HL). To derive the optimal number of clusters of the desired 
standard audiograms, cubic clustering criterion, pseudo-F-, and 
pseudo-t2-statistics were calculated. These analyses resulted in 29 clusters 
representing a standard audiogram of the South Korean population. Eighteen of 
the clusters represented normal hearing audiograms (73.11%), while 11 
represented hearing-impaired (HI) standard audiograms (27.89%). Of the 11 HI 
audiograms, 7 were defined as flat-type (17.81%), while the remaining 4 were 
defined as sloping-type (9.08%). In conclusion, 29 audiograms representing 
standard audiograms for the Korean population have been derived using KNHANES 
data. Improved understanding of the characteristics of each cluster may be 
helpful for development of more personalized, fixed-setting hearing aids.

DOI: 10.1038/s41598-019-40300-7
PMCID: PMC6403394
PMID: 30842521 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


472. Otol Neurotol. 2014 Mar;35(3):431-6. doi: 10.1097/MAO.0000000000000255.

Perception of polyphony with cochlear implants for 2 and 3 simultaneous pitches.

Penninger RT(1), Kludt E, Limb CJ, Leman M, Dhooge I, Buechner A.

Author information:
(1)*Institute for Psychoacoustics and Electronic Music, University Ghent, Ghent, 
Belgium; †Cluster of Excellence "Hearing4all" Department of Otolaryngology, 
Medical University of Hannover, Hannover, Germany; ‡Department of 
Otolaryngology-Head and Neck Surgery, Johns Hopkins Hospital, Baltimore, 
Maryland, U.S.A.; §Peabody Conservatory of Music, Baltimore, Maryland, U.S.A.; 
and ∥Department of Otolaryngology, University Hospital Ghent, Ghent, Belgium.

HYPOTHESIS: It was hypothesized that cochlear implant (CI) subjects would be 
able to correctly identify 1, 2, and 3 simultaneous pitches through direct 
electrical stimulation. We further hypothesized that the location on the implant 
array and the fundamental frequency of the pitches would have an impact on the 
performance.
BACKGROUND: "They gave me back speech but not music" is a sentence commonly 
heard by CI subjects. One of the reasons is that in music, multiple streams are 
frequently played at the same time, which is an essential feature of harmony. 
Current CI speech processors do not allow CI users to perceive such complex 
polyphonic sounds.
METHODS: In the present study, the authors assessed the ability of CI subjects 
to perceive simultaneous modulation frequencies based on direct electrical 
stimulation. Ten CI subjects were asked to identify 1, 2, and 3 simultaneous 
pitches applied on different electrodes using sinusoidal amplitude modulation. 
All stimuli were loudness balanced before the actual identification task.
RESULTS: Subjects were able to identify 1, 2, and 3 simultaneous pitches. The 
further the distance between the 2 electrodes, the better was the performance in 
the 2-pitch condition. The distance between the modulation frequencies had a 
significant effect on the performance in the 2-and 3-pitch condition.
CONCLUSION: Subjects are able to identify complex polyphonic stimuli based on 
the number of active electrodes. The additional polyphonic rate pitch cue 
improves performance in some conditions.

DOI: 10.1097/MAO.0000000000000255
PMID: 24518404 [Indexed for MEDLINE]


473. Neuroimage. 2004 Apr;21(4):1701-20. doi: 10.1016/j.neuroimage.2003.11.012.

Relating neuronal dynamics for auditory object processing to neuroimaging 
activity: a computational modeling and an fMRI study.

Husain FT(1), Tagamets MA, Fromm SJ, Braun AR, Horwitz B.

Author information:
(1)Brain Imaging and Modeling Section, National Institute on Deafness and Other 
Communication Disorders, National Institutes of Health, Bethesda, MD 20892, USA. 
husainf@nidcd.nih.gov

We investigated the neural basis of auditory object processing in the cerebral 
cortex by combining neural modeling and functional neuroimaging. We developed a 
large-scale, neurobiologically realistic network model of auditory pattern 
recognition that relates the neuronal dynamics of cortical auditory processing 
of frequency modulated (FM) sweeps to functional neuroimaging data of the type 
obtained using PET and fMRI. Areas included in the model extend from primary 
auditory to prefrontal cortex. The electrical activities of the neuronal units 
of the model were constrained to agree with data from the neurophysiological 
literature regarding the perception of FM sweeps. We also conducted an fMRI 
experiment using stimuli and tasks similar to those used in our simulations. The 
integrated synaptic activity of the neuronal units in each region of the model, 
convolved with a hemodynamic response function, was used as a correlate of the 
simulated fMRI activity, and generally agreed with the experimentally observed 
fMRI data in the brain areas corresponding to the regions of the model. Our 
results demonstrate that the model is capable of exhibiting the salient features 
of both electrophysiological neuronal activities and fMRI values that are in 
agreement with empirically observed data. These findings provide support for our 
hypotheses concerning how auditory objects are processed by primate neocortex.

DOI: 10.1016/j.neuroimage.2003.11.012
PMID: 15050592 [Indexed for MEDLINE]


474. HNO. 1996 Apr;44(4):201-6.

[Use of self-organizing neural networks (Kohonen maps) for classification of 
voice acoustic signals exemplified by the infant voice with and without 
time-delayed auditory feedback].

[Article in German]

Schönweiler R(1), Kaese S, Möller S, Rinscheid A, Ptok M.

Author information:
(1)Klinik für Phoniatrie und Pädaudiologie, Medizinische Hochschule Hannover.

Subjective and auditory assessment of the voice is now more commonly being 
replaced by objective voice analysis. Because of the amount of data available 
from computer-aided voice analysis, subjective selection and interpretation of 
single data sets remain a matter of experience of the individual investigator. 
Since neuronal networks are widely used in telecommunication and speech 
recognition, we applied self-organizing Kohonen networks to classify voice 
patterns. In the phase of "learning," the Kohonen map is adapted to patterns of 
the primary signals obtained. If, in the phase of using the map, the input 
signal hits the field of the primary signals, it will resemble them closely. In 
this study, we recorded newborn and young infant cries using a DAT recorder and 
a high-quality microphone. The cries were elicited by wearing uncomfortable 
headphones ("cries of discomfort"). Spectrographic characteristics of the cries 
were classified by 20-step bark spectra and then applied to the neuronal 
networks. It was possible to recognize similarities of different cries of the 
same children and interindividual differences, as well as cries of children with 
profound hearing loss. In addition, delayed auditory feedback at 80 dB SL was 
presented to 27 children via headphone using a three-headed tape-recorder as a 
model for induced individual cry changes. However, it was not possible to 
classify short-term changes as in a delayed feedback procedure. Nevertheless, 
neuronal networks may be helpful as an additional tool in spectrographic voice 
analysis.

PMID: 8655351 [Indexed for MEDLINE]


475. PLoS One. 2016 Feb 3;11(2):e0147552. doi: 10.1371/journal.pone.0147552. 
eCollection 2016.

Impedance Changes and Fibrous Tissue Growth after Cochlear Implantation Are 
Correlated and Can Be Reduced Using a Dexamethasone Eluting Electrode.

Wilk M(1)(2), Hessler R(3), Mugridge K(3), Jolly C(3), Fehr M(2), Lenarz 
T(1)(4), Scheper V(1)(4).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Clinic for Exotic Pets, Reptiles, Pet and Feral Birds, University of 
Veterinary Medicine, Foundation, Hannover, Germany.
(3)MED-EL GmbH, Innsbruck, Austria.
(4)Cluster of Excellence "Hearing4all", Hannover Medical School, Hannover, 
Germany.

BACKGROUND: The efficiency of cochlear implants (CIs) is affected by 
postoperative connective tissue growth around the electrode array. This tissue 
formation is thought to be the cause behind post-operative increases in 
impedance. Dexamethasone (DEX) eluting CIs may reduce fibrous tissue growth 
around the electrode array subsequently moderating elevations in impedance of 
the electrode contacts.
METHODS: For this study, DEX was incorporated into the silicone of the CI 
electrode arrays at 1% and 10% (w/w) concentration. Electrodes prepared by the 
same process but without dexamethasone served as controls. All electrodes were 
implanted into guinea pig cochleae though the round window membrane approach. 
Potential additive or synergistic effects of electrical stimulation (60 minutes) 
were investigated by measuring impedances before and after stimulation (days 0, 
7, 28, 56 and 91). Acoustically evoked auditory brainstem responses were 
recorded before and after CI insertion as well as on experimental days 7, 28, 
56, and 91. Additionally, histology performed on epoxy embedded samples enabled 
measurement of the area of scala tympani occupied with fibrous tissue.
RESULTS: In all experimental groups, the highest levels of fibrous tissue were 
detected in the basal region of the cochlea in vicinity to the round window 
niche. Both DEX concentrations, 10% and 1% (w/w), significantly reduced fibrosis 
around the electrode array of the CI. Following 3 months of implantation 
impedance levels in both DEX-eluting groups were significantly lower compared to 
the control group, the 10% group producing a greater effect. The same effects 
were observed before and after electrical stimulation.
CONCLUSION: To our knowledge, this is the first study to demonstrate a 
correlation between the extent of new tissue growth around the electrode and 
impedance changes after cochlear implantation. We conclude that DEX-eluting CIs 
are a means to reduce this tissue reaction and improve the functional benefits 
of the implant by attenuating electrode impedance.

DOI: 10.1371/journal.pone.0147552
PMCID: PMC4739581
PMID: 26840740 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The data and results 
presented within this manuscript are in total obtained with MEDEL as a research 
partner having no financial interest on the outcome of the study. No products 
exactly comparable to the one used in this study will be released to the market. 
RH, KM, and CJ are employed by MEDEL Corporation. This does not alter the 
authors’ adherence to PLOS ONE policies on sharing data and materials.


476. Nihon Jibiinkoka Gakkai Kaiho. 1993 Jan;96(1):18-23. doi: 
10.3950/jibiinkoka.96.18.

[Hearing distribution of idiopathic bilateral sensorineural hearing loss].

[Article in Japanese]

Hirayama M(1).

Author information:
(1)Department of Otolaryngology, Kitasato University, Sagamihara.

We investigated the mode of progression of idiopathic bilateral sensorineural 
hearing loss diagnosed in patients seen in the Hearing Loss Clinic at the 
Department of Otolaryngology of Kitasato University Hospital. Entered into the 
study were 105 patients whose courses could be observed for more than 3 years. 
Audiograms were taken 1069 times in these 105 patients and were examined with 
regard to the distribution of hearing levels by frequency. Idiopathic bilateral 
sensorineural hearing loss was divided into three stages from the aspect of the 
time of hearing change stages I, II and III. Hearing clustering points of the 
respective stages were compared with each other. Proceeding from the peak of 
stage I to that of stage II was found to take place at the same peak as that of 
stage III. Another peak hearing clustering point was noted at s.o..

DOI: 10.3950/jibiinkoka.96.18
PMID: 8459305 [Indexed for MEDLINE]


477. J Speech Hear Res. 1994 Jun;37(3):671-9. doi: 10.1044/jshr.3703.671.

The phonological abilities of Cantonese-speaking children with hearing loss.

Dodd BJ(1), So LK.

Author information:
(1)Department of Speech and Hearing, University of Queensland, St. Lucia, 
Australia.

Little is known about the acquisition of phonology by children with hearing loss 
who learn languages other than English. In this study, the phonological 
abilities of 12 Cantonese-speaking children (ages 4:2 to 6:11) with prelingual 
hearing impairment are described. All but 3 children had almost complete 
syllable-initial consonant repertoires; all but 2 had complete syllable-final 
consonant and vowel repertoires; and only 1 child failed to produce all nine 
tones. Children's perception of single words was assessed using sets of words 
that included tone, consonant, and semantic distractors. Although the 
performance of the subjects was not age appropriate, they nevertheless most 
often chose the target, with most errors observed for the tone distractor. The 
phonological rules used included those that characterize the speech of younger 
hearing children acquiring Cantonese (e.g., cluster reduction, stopping, and 
deaspiration). However, most children also used at least one unusual 
phonological rule (e.g., frication, addition, initial consonant deletion, and/or 
backing). These rules are common in the speech of Cantonese-speaking children 
diagnosed as phonologically disordered. The influence of the ambient language on 
children's patterns of phonological errors is discussed.

DOI: 10.1044/jshr.3703.671
PMID: 8084197 [Indexed for MEDLINE]


478. IEEE Trans Biomed Eng. 2000 Apr;47(4):487-96. doi: 10.1109/10.828148.

Development of speechreading supplements based on automatic speech recognition.

Duchnowski P(1), Lum DS, Krause JC, Sexton MG, Bratakos MS, Braida LD.

Author information:
(1)Research Laboratory of Electronics, Massachusetts Institute of Technology, 
Cambridge 02139, USA.

In manual-cued speech (MCS) a speaker produces hand gestures to resolve 
ambiguities among speech elements that are often confused by speechreaders. The 
shape of the hand distinguishes among consonants; the position of the hand 
relative to the face distinguishes among vowels. Experienced receivers of MCS 
achieve nearly perfect reception of everyday connected speech. MCS has been 
taught to very young deaf children and greatly facilitates language learning, 
communication, and general education. This manuscript describes a system that 
can produce a form of cued speech automatically in real time and reports on its 
evaluation by trained receivers of MCS. Cues are derived by a hidden markov 
models (HMM)-based speaker-dependent phonetic speech recognizer that uses 
context-dependent phone models and are presented visually by superimposing 
animated handshapes on the face of the talker. The benefit provided by these 
cues strongly depends on articulation of hand movements and on precise 
synchronization of the actions of the hands and the face. Using the system 
reported here, experienced cue receivers can recognize roughly two-thirds of the 
keywords in cued low-context sentences correctly, compared to roughly one-third 
by speechreading alone (SA). The practical significance of these improvements is 
to support fairly normal rates of reception of conversational speech, a task 
that is often difficult via SA.

DOI: 10.1109/10.828148
PMID: 10763294 [Indexed for MEDLINE]


479. Lin Chuang Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2015 Feb;29(4):310-4.

[Meta-analysis on effectiveness of prelingually deaf patients at different ages 
following cochlear implantation].

[Article in Chinese]

Xu Q, Zhai S, Han D, Yang S, Shen W.

OBJECTIVE: To assess the clinical effeetiveness of prelingually deaf children 
after cochlear implantation at different ages so as to provide reasonable 
expectations for the patients and guidance for the clinical treatment.
METHOD: Electronic databases PubMed, YZ365. COM, WANFANG DATA, CMJD, CHKD, CNKI 
were searched using relevant keywords. Extracted data included author, year of 
publication, diagnosis, et al. Reported treatment outcomes were clustered into 
speech discrimination and hearing abilities. Meta-analyses were performed on 
studies with numerical results using random or fixed effects model.
RESULT: There were eight randomized control studies including 442 patients. 
Comparing speech perception of prelingually deaf children after cochlear 
implantation younger than three years old (experimental group) and 3-6 years old 
(control group), three and six months after operation showed that experimental 
group performed significantly worse than control group; 12 months after 
operation showed that experimental group performed significantly better than 
control group. Comparing hearing abilities, three and six months after operation 
showed that experimental group performed significantly worse than control group; 
12 months after operation showed showed that experimental group performed 
significantly better than control group. Comparing speech perception of younger 
or older than 4. 5 years old children showed that after 1.5-2 years of operation 
children implanted younger than 4.5 years of age performed significantly better 
than children implanted older than 4.5 years old. Comparing speech perception of 
7-12 years old children showed that after 3, 6, 12 months of operation patients 
of 7-12 years old performed significantly better than those children older than 
12 years old. Comparing speech perception of implantation younger or older than 
18 years old (7-14 yeas old was group A, > 14-18 yeas old was group B, older 
than 18 yeas old was group C) showed that after one and four years of operation 
A > B > C, and there were significant differences among them. Comparing warble 
tone threshold average (WTA) showed that after one year of operation A < B < C, 
and there were significant differences among them. However, after four years of 
operation, there was no significant difference among them.
CONCLUSION: Prelinguistically deafened patients younger than three years old 
with cochlear implantation, insisting on scienctific rehabilitation training for 
a long period of time can receive the optimal recovery effect. The older 
patients are suggested as early as possible receiving cochlear implantation. The 
longer they are implanted, the better results they will receive. Moreover, the 
younger age they are implanted, the faster postoperative language progress they 
will receive. Further controlled studies with longer follow-up periods and more 
person included may make the effectiveness of cochlear implantaion more 
reliable.

PMID: 26121827 [Indexed for MEDLINE]


480. Brain Res. 2004 Aug 6;1016(2):182-94. doi: 10.1016/j.brainres.2004.05.016.

Two types of afferent terminals innervate cochlear inner hair cells in C57BL/6J 
mice.

Francis HW(1), Rivas A, Lehar M, Ryugo DK.

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins University, 
720 Rutland Avenue, Baltimore, MD 21205, USA. hfrancis@jhmi.edu

Afferent synapses on inner hair cells (IHC) transfer auditory information to the 
central nervous system (CNS). Despite the importance of these synapses for 
normal hearing, their response to cochlear disease and dysfunction is not well 
understood. The C57BL/6J mouse is a model for presbycusis and noise-induced 
hearing loss because of its age-related hearing loss and susceptibility to 
acoustic over-exposure. In this context, we sought to establish normal synaptic 
structure in order to better evaluate synaptic changes due to presbycusis and 
noise exposure. Ultrastructural analysis of IHCs and afferent terminals was 
performed in a normal hearing 3-month-old C57BL/6J mouse at cochlear sites 
corresponding to 8, 16 and 32 kHz using semi-serial sections. A stereologic 
survey of random sections was conducted of IHCs in 11 additional mice. Two 
morphologically distinct groups of afferent terminals were identified at all 3 
frequency locations in 11 out of 12 animals. "Simple" endings demonstrated 
classic features of bouton terminals, whereas "folded" endings were larger in 
size and exhibited a novel morphologic feature that consisted of a fully 
internalized double membrane that partially divided the terminal into two 
compartments. In many cases, the double membrane was continuous with the outer 
terminal membrane as if produced by an invagination. We still must determine the 
generality of these observations with respect to other mouse strains.

DOI: 10.1016/j.brainres.2004.05.016
PMID: 15246854 [Indexed for MEDLINE]


481. Neural Comput. 2005 Dec;17(12):2648-71. doi: 10.1162/089976605774320575.

A novel model-based hearing compensation design using a gradient-free 
optimization method.

Chen Z(1), Becker S, Bondy J, Bruce IC, Haykin S.

Author information:
(1)Department of Electrical and Computer Engineering, McMaster University, 
Hamilton, Ontario L85 4k1, Canada. zhechen@soma.ece.mcmaster.ca

We propose a novel model-based hearing compensation strategy and gradient-free 
optimization procedure for a learning-based hearing aid design. Motivated by 
physiological data and normal and impaired auditory nerve models, a hearing 
compensation strategy is cast as a neural coding problem, and a Neurocompensator 
is designed to compensate for the hearing loss and enhance the speech. With the 
goal of learning the Neurocompensator parameters, we use a gradient-free 
optimization procedure, an improved version of the ALOPEX that we have 
developed, to learn the unknown parameters of the Neurocompensator. We present 
our methodology, learning procedure, and experimental results in detail; 
discussion is also given regarding the unsupervised learning and optimization 
methods.

DOI: 10.1162/089976605774320575
PMID: 16212766 [Indexed for MEDLINE]


482. Stat Med. 1997 Nov 15;16(21):2475-88. doi: 
10.1002/(sici)1097-0258(19971115)16:21<2475::aid-sim669>3.0.co;2-d.

Construction of hearing percentiles in women with non-constant variance from the 
linear mixed-effects model.

Morrell CH(1), Pearson JD, Brant LJ, Gordon-Salant S.

Author information:
(1)Mathematical Sciences Department, Loyola College, Baltimore, MD 21210, USA.

Current age-specific reference standards for adult hearing thresholds are 
primarily cross-sectional in nature and vary in the degree of screening of the 
reference sample for noise-induced hearing loss and other hearing problems. We 
develop methods to construct age-specific percentiles for longitudinal data that 
have been modelled using the linear mixed-effects model. We apply these methods 
to construct percentiles of hearing level using data from a carefully screened 
sample of women from the Baltimore Longitudinal Study of Aging. However, the 
variation in the residuals and random effects from the linear mixed-effects 
model does not remain constant with age and frequency of the stimulus tone. In 
addition, the distribution of the hearing levels is not symmetric about the 
mean. We develop a number of methods to use the output from the linear 
mixed-effects model to construct percentiles that do not have constant variance. 
We use a transformation of the hearing levels to provide for skewness in the 
final percentile curves. The change in the variation of the residuals and random 
effects is modelled as a function of beginning age and frequency and we use this 
variance function to construct the hearing percentiles. We present a number of 
approaches. First, we use the absolute values of the population residuals to 
model the total deviation about the mean as a function of beginning age and 
frequency. Second, we model the standard deviation in the person-specific 
(cluster) residuals as well as the standard deviation in the estimated random 
effects. Finally, we use weighted least squares with the regressions on the 
absolute cluster residuals and absolute estimated random effects where the 
weights are the reciprocal of the standard deviations of their estimates.

DOI: 10.1002/(sici)1097-0258(19971115)16:21<2475::aid-sim669>3.0.co;2-d
PMID: 9364655 [Indexed for MEDLINE]


483. J Comp Neurol. 2009 Jan 1;512(1):101-14. doi: 10.1002/cne.21886.

Cochlear implant use following neonatal deafness influences the cochleotopic 
organization of the primary auditory cortex in cats.

Fallon JB(1), Irvine DR, Shepherd RK.

Author information:
(1)The Bionic Ear Institute, Melbourne, Victoria, Australia 3002. 
jfallon@bionicear.org

Electrical stimulation of spiral ganglion neurons in a deafened cochlea, via a 
cochlear implant, provides a means of investigating the effects of the removal 
and subsequent restoration of afferent input on the functional organization of 
the primary auditory cortex (AI). We neonatally deafened 17 cats before the 
onset of hearing, thereby abolishing virtually all afferent input from the 
auditory periphery. In seven animals the auditory pathway was chronically 
reactivated with environmentally derived electrical stimuli presented via a 
multichannel intracochlear electrode array implanted at 8 weeks of age. 
Electrical stimulation was provided by a clinical cochlear implant that was used 
continuously for periods of up to 7 months. In 10 long-term deafened cats and 
three age-matched normal-hearing controls, an intracochlear electrode array was 
implanted immediately prior to cortical recording. We recorded from a total of 
812 single unit and multiunit clusters in AI of all cats as adults using a 
combination of single tungsten and multichannel silicon electrode arrays. The 
absence of afferent activity in the long-term deafened animals had little effect 
on the basic response properties of AI neurons but resulted in complete loss of 
the normal cochleotopic organization of AI. This effect was almost completely 
reversed by chronic reactivation of the auditory pathway via the cochlear 
implant. We hypothesize that maintenance or reestablishment of a 
cochleotopically organized AI by activation of a restricted sector of the 
cochlea, as demonstrated in the present study, contributes to the remarkable 
clinical performance observed among human patients implanted at a young age.

DOI: 10.1002/cne.21886
PMCID: PMC2597008
PMID: 18972570 [Indexed for MEDLINE]


484. Clin Linguist Phon. 2002 Mar;16(2):79-99. doi: 10.1080/02699200110109802.

Tone discrimination in Cantonese-speaking children using a cochlear implant.

Barry JG(1), Blamey PJ, Martin LF, Lee KY, Tang T, Ming YY, Van Hasselt CA.

Author information:
(1)University of Melbourne, Melbourne, Victoria, Australia. 
j.barry@medoto.unimelb.edu.au

Most tone perception tests for Cantonese-speaking cochlear implant users have 
been based on tone identification tasks which require significant cognitive 
development to be successfully completed. Results from such tests suggest that 
cochlear implant child users are performing at about chance level and may not be 
receiving much information about pitch using the implant. This paper reports on 
the ability of cochlear implant child users to discriminate pitch variations in 
Cantonese by using an experimental procedure based on play audiometry. As part 
of the study, the usefulness of higher rates of electrode stimulation for aiding 
tone discrimination is also examined. Cochlear implant users are shown to derive 
sufficient information about pitch to discriminate most tone contrasts 
relatively successfully, with performance being most variable for contrasts 
involving tones clustered in the lower register of the speaker's fundamental 
frequency range. Contrary to hypothesis, higher electrode stimulation rates are 
not found to offer significant benefits for aiding pitch discrimination.

DOI: 10.1080/02699200110109802
PMID: 11987495 [Indexed for MEDLINE]


485. Clin Linguist Phon. 2003 Oct-Nov;17(7):507-28. doi: 10.1080/0269920031000138169.

A diagnostic marker for speech delay associated with otitis media with effusion: 
the intelligibility-speech gap.

Shriberg LD(1), Flipsen P Jr, Kwiatkowski J, McSweeny JL.

Author information:
(1)Phonology Project, Waisman Center, University of Wisconsin-Madison, 1500 
Highland Avenue, Madison, WI 53705, USA. shriberg@waisman.wisc.edu

The goal of this study was to determine if notably reduced intelligibility is a 
potential diagnostic marker for children with speech delay and histories of 
early recurrent otitis media with effusion (SD-OME). Intelligibility was 
assessed in one 5-10 minute conversational speech sample from each of 281 
speakers. The OME histories of 148 of these children with normal speech 
acquisition were described in two prior reports. OME histories of 85 additional 
children with speech delay were obtained from case history reports. For both 
groups, the children with positive OME (OME+) histories had significantly lower 
intelligibility scores but significantly higher speech production scores than 
children with negative OME (OME-) histories. Findings for a diagnostic marker to 
discriminate speech delayed children with OME+ versus OME- histories were 
promising, considering that the data were obtained retrospectively and did not 
include audiological information characterizing children's concurrent fluctuant 
hearing loss. The formula for the diagnostic marker, termed the 
Intelligibility-Speech Gap, was identified by a machine learning routine. 
Diagnostic accuracy findings for the marker were as follows: positive predictive 
value = 74%, negative predictive value = 86%, sensitivity = 79%, specificity = 
83%, positive likelihood ratio = 4.6 and negative likelihood ratio = 0.25. 
Discussion considers speech processing perspectives on the source of the 
intelligibility-speech gap in children with suspected SD-OME, and methodological 
perspectives on its development as a diagnostic marker of one etiological 
subtype of speech delay.

DOI: 10.1080/0269920031000138169
PMID: 14608797 [Indexed for MEDLINE]


486. Annu Int Conf IEEE Eng Med Biol Soc. 2007;2007:6224-7. doi: 
10.1109/IEMBS.2007.4353777.

Objective source selection in Blind Source Separation of AEPs in children with 
Cochlear Implants.

Castañeda-Villa N(1), James CJ.

Author information:
(1)ISVR, University of Southampton, SO171BJ, UK. ncv@soton.ac.uk

Multi-channel Auditory Evoked Potentials (AEPs) are a useful methodology for 
evaluating the auditory performance of children with Cochlear Implants (CIs). 
These recordings are generally contaminated, not only with well known 
physiological artifacts (blinking, muscle) and line noise etc., but also by CI 
artifact. The CI induces an artifact in the recording at the electrodes in the 
temporal lobe area (where it is implanted) when specific tones are presented, 
this artifact in particular makes the detection and analysis of AEPs much more 
challenging. This paper evaluates the convenience of using Blind Source 
Separation (BSS) and Independent Component Analysis (ICA) in order to identify 
the AEPs from ongoing recordings and to isolate the artifact when testing a 
child with a CI. We propose a new procedure to elicit an objective 
differentiation between the independent components (ICs) related to the AEPs and 
CI artifact; two concepts are fundamental in this procedure Mutual Information 
(MI) and Clustering. Finally, the variability of three BSS/ICA algorithms is 
assessed; in order to determine which one is more convenient to isolate the 
respective ICs of interest. Temporal decorrelation based ICA showed the least 
change in the estimation of both the AEPs and the CI artifact; this has allowed 
for considerable autonomy in the construction of relevant, consistent clusters.

DOI: 10.1109/IEMBS.2007.4353777
PMID: 18003443 [Indexed for MEDLINE]


487. J Acoust Soc Am. 2016 Feb;139(2):800-10. doi: 10.1121/1.4941567.

Cochlear implant speech intelligibility outcomes with structured and 
unstructured binary mask errors.

Kressner AA(1), Westermann A(1), Buchholz JM(1), Rozell CJ(2).

Author information:
(1)National Acoustic Laboratories, Australian Hearing, 16 University Avenue, 
Macquarie University, New South Wales 2109, Australia.
(2)School of Electrical and Computer Engineering, 777 Atlantic Drive Northwest, 
Georgia Institute of Technology, Atlanta, Georgia 30332, USA.

It has been shown that intelligibility can be improved for cochlear implant (CI) 
recipients with the ideal binary mask (IBM). In realistic scenarios where prior 
information is unavailable, however, the IBM must be estimated, and these 
estimations will inevitably contain errors. Although the effects of both 
unstructured and structured binary mask errors have been investigated with 
normal-hearing (NH) listeners, they have not been investigated with CI 
recipients. This study assesses these effects with CI recipients using masks 
that have been generated systematically with a statistical model. The results 
demonstrate that clustering of mask errors substantially decreases the tolerance 
of errors, that incorrectly removing target-dominated regions can be as 
detrimental to intelligibility as incorrectly adding interferer-dominated 
regions, and that the individual tolerances of the different types of errors can 
change when both are present. These trends follow those of NH listeners. 
However, analysis with a mixed effects model suggests that CI recipients tend to 
be less tolerant than NH listeners to mask errors in most conditions, at least 
with respect to the testing methods in each of the studies. This study clearly 
demonstrates that structure influences the tolerance of errors and therefore 
should be considered when analyzing binary-masking algorithms.

DOI: 10.1121/1.4941567
PMID: 26936562 [Indexed for MEDLINE]


488. Int J Audiol. 2011 Jan;50(1):50-8. doi: 10.3109/14992027.2010.531294. Epub 2010 
Nov 22.

Experiences of the use of FOX, an intelligent agent, for programming cochlear 
implant sound processors in new users.

Vaerenberg B(1), Govaerts PJ, de Ceulaer G, Daemers K, Schauwers K.

Author information:
(1)The Eargroup, Antwerp-Deurne, Belgium.

OBJECTIVE: This report describes the application of the software tool "Fitting 
to Outcomes eXpert" (FOX) in programming the cochlear implant (CI) processor in 
new users. FOX is an intelligent agent to assist in the programming of CI 
processors. The concept of FOX is to modify maps on the basis of specific 
outcome measures, achieved using heuristic logic and based on a set of 
deterministic "rules".
DESIGN: A prospective study was conducted on eight consecutive CI-users with a 
follow-up of three months.
STUDY SAMPLE: Eight adult subjects with postlingual deafness were implanted with 
the Advanced Bionics HiRes90k device. The implants were programmed using FOX, 
running a set of rules known as Eargroup's EG0910 advice, which features a set 
of "automaps". The protocol employed for the initial 3 months is presented, with 
description of the map modifications generated by FOX and the corresponding 
psychoacoustic test results.
RESULTS: The 3 month median results show 25 dBHL as PTA, 77% (55 dBSPL) and 71% 
(70 dBSPL) phoneme score at speech audiometry and loudness scaling in or near to 
the normal zone at different frequencies.
CONCLUSIONS: It is concluded that this approach is feasible to start up CI 
fitting and yields good outcome.

DOI: 10.3109/14992027.2010.531294
PMID: 21091083 [Indexed for MEDLINE]


489. Audiology. 1997 Sep-Oct;36(5):279-97. doi: 10.3109/00206099709071980.

Changes in vowel quality in post-lingually deafened cochlear implant users.

Langereis MC(1), Bosman AJ, van Olphen AF, Smoorenburg GF.

Author information:
(1)Department of Otorhinolaryngology, University Hospital, Utrecht, The 
Netherlands.

The present study addresses the effect of cochlear implantation on vowel 
production of 20 post-lingually deafened Dutch subjects. All subjects received 
the Nucleus 22 implant (3 WSP and 17 MSP processors). Speech recordings were 
made pre-implantation and three and twelve months post-implantation with the 
implant switched on and off. The first and second formant frequencies were 
measured for eleven Dutch vowels (monophthongs only) in an h-vowel-t context. 
Twelve months post-implantation, the results showed an increase in the ranges of 
the first and second formant frequency covered by the respective vowels when the 
implant was switched on. The increase in the formant frequency range was most 
marked for some subjects with a relatively small formant range pre-implantation. 
Also, at 12 months post-implantation with the implant switched on we found a 
significant shift of the first and second formant frequency towards the 
normative values. Moreover, at this time the results showed significantly 
increased clustering of the respective vowels, suggesting an improvement in the 
ability to produce phonological contrasts between vowels. Clustering is defined 
as the ratio of the between-vowel variance of the first and second formant 
frequency and the within-vowel variance of three tokens of the same vowel.

DOI: 10.3109/00206099709071980
PMID: 9305524 [Indexed for MEDLINE]


490. Biomed Tech (Berl). 2000 Sep;45(9):248-54. doi: 10.1515/bmte.2000.45.9.248.

[Expert system for aiding diagnosis in hearing tests].

[Article in German]

Buller G(1), Hoth S, Suchandt S.

Author information:
(1)Hochschule Wismar, Fachbereich Elektrotechnik und Informatik. 
g.buller@et.hs-wismar.de

For expert systems intended to aid diagnosis, a structure with five levels is 
proposed. These levels are the original area, the parameter and a reduced 
parameter layer, the classification and the final-decision layer. On the basis 
of this structures, an expert system was developed specifically for neonatal 
hearing screening with transitory evoked otoacoustic emissions (TEOAE). In a 
second step, this system was investigated for its suitability to classify 
emissions, regardless of patient age. For the comparison measurements in 252 
mainly adult patients, some with an acquired hearing impairment, were used. To 
adapt the pass/fail decision to the extended evaluation criteria, the false 
classifications from a first run with the new data were used for training. 
Thereafter, the expert system, working with a wider data basis, classified the 
new data with a sensitivity that was increased by 4.8% to 97.2%, and a 2.0% 
improvement in specificity to 95.5% when classifying new data, These results, 
together with those of 97.3% and 94.3% achieved with exclusively neonatal TEOAE 
classification, clearly show the advantage of the expert system structures 
chosen, and document evidence of the practical applicability of the method.

DOI: 10.1515/bmte.2000.45.9.248
PMID: 11030095 [Indexed for MEDLINE]


491. Lin Chuang Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2011 Feb;25(4):151-3.

[Hearing the impact of MP3 on a survey of middle school students].

[Article in Chinese]

Xu Z(1), Li Z, Chen Y, He Y, Chunyu X, Wang F, Zhang P, Gao L, Qiu S, Liu S, 
Qiao L, Qiu J.

Author information:
(1)Department of Otolaryngology, the First People's Hospital of Yongkang, 
Zhejiang Province, Yongkang, 321300, China.

OBJECTIVE: To understand the usage of MP3 and effects on hearing of middle 
school students in Xi'an, and discuss controlling strategies.
METHOD: Stratified random cluster sampling method was used in the 1567 middle 
school students in Xi'an through questionnaire survey, ear examination and 
hearing examination, data were analysed by the SPSS13.0 statistical software.
RESULT: 1) The rate of holding MP3 in the middle school students was 85.2%. 
Average daily use time was (1.41 +/- 1.11) h. 2) The noise group of pure tone 
hearing threshold was significantly higher compared with the control group 
(P<0.01), and increased the detection rate of hearing loss with the increasing 
use of MP3. 3) The detection rate of symptoms increased with the increasing use 
of MP3.
CONCLUSION: The usage of MP3 can harm hearing in middle school students, which 
can result in neurasthenic syndrome.

PMID: 21563460 [Indexed for MEDLINE]


492. Public Health. 1996 Sep;110(5):293-7. doi: 10.1016/s0033-3506(96)80092-8.

Hearing impairment among young Chinese in a rural area.

Morioka I(1), Luo WZ, Miyashita K, Takeda S, Wang YX, Li SC.

Author information:
(1)Department of Hygiene, School of Medicine, Wakayama Medical University, 
Japan.

To evaluate hearing levels in Chinese young people, audiometry was carried out 
at a rural village in Shandong Prefecture. The subjects were 282 healthy school 
children and students ranging in age from 7-17 y. All subjects were asked to 
complete a brief questionnaire on otological symptoms, personal histories and 
use of noisy playthings. Audiometric threshold testing was performed at the 
audiometric frequencies of 0.5, 1, 2, 4 and 8 kHz. Cluster analysis was used to 
estimate the associations between questions in the questionnaire and hearing 
impairment. Fifty-six subjects (20% subjects) were excluded from the normal 
groups. Twenty-two ears of the excluded subjects showed 4 kHz-dip and 38 ears 
showed high frequency hearing loss. An increased prevalence of hearing 
impairment was found when compared with young Japanese (1% from the nationwide 
school health survey) and with young Chinese in Shandong Prefecture (0.5%). In 
the questionnaire, 4 questions on dizziness, head trauma, aminoglycoside 
administration, and suspicion of Meniere's syndrome, were included in the 
cluster of hearing impairment. The cause of this hearing impairment was proposed 
to be the potentiating effects of aminoglycoside antibiotics and exposure to 
noise.

DOI: 10.1016/s0033-3506(96)80092-8
PMID: 8885666 [Indexed for MEDLINE]


493. Hear Res. 1992 Apr;59(1):46-58. doi: 10.1016/0378-5955(92)90101-r.

Hair cell regeneration in the adult budgerigar after kanamycin ototoxicity.

Hashino E(1), Tanaka Y, Salvi RJ, Sokabe M.

Author information:
(1)Hearing Research Laboratories, State University of New York, Buffalo 14214.

Adult budgerigars were given kanamycin at a dose of 200 mg/kg/day for 10 
successive days. At 1, 7, 14 and 28 days after the drug treatment, the cochleae 
of the birds were processed for scanning electron microscopy (SEM). Complete 
degeneration of sensory hair cells was observed in the basal 55-75% of the 
basilar papilla immediately after the treatment. Regenerating hair cells, 
characterized by clusters of microvilli and small apical surfaces, were present 
in the basal end of the papilla as early as one day post-treatment. During the 
28 day recovery period, the number of hair cells progressively increased 
beginning at the base and spreading toward the apex. Although the appearance of 
the basilar papilla had improved considerably by 28 days post-treatment, the 
sensory epithelium still contained a number of pathologies, most noticeably, 
incomplete restoration of hair cell number in the most apical part of the 
damaged region and the disorganization of hair cell packing. These remaining 
pathologies may be responsible for the permanent threshold shifts observed in 
budgerigars exposed to the same dose of kanamycin treatment (Hashino and Sokabe, 
1989).

DOI: 10.1016/0378-5955(92)90101-r
PMID: 1629046 [Indexed for MEDLINE]


494. Am J Otolaryngol. 2020 May-Jun;41(3):102487. doi: 10.1016/j.amjoto.2020.102487. 
Epub 2020 Apr 16.

New type of corona virus induced acute otitis media in adult.

Fidan V(1).

Author information:
(1)Otorhinolaryngology Dept, Eskisehir City Hospital, Eskisehir, Turkey. 
Electronic address: vuralfidan@gmail.com.

Since late December 2019, a new type of coronavirus (CIVID-19) causing a cluster 
of respiratory infections was first identified in Wuhan-China. And it 
disseminated to all countries. Generally, COVID-19 cases have fever, cough, 
respiratory distress findings (dyspnoea, intercostal retraction, cyanosis etc.). 
In this paper, we have presented an adult otitis media case whom infected with 
COVID-19, but she have not any classical COVID-19 symptoms.

Copyright © 2020 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.amjoto.2020.102487
PMCID: PMC7161479
PMID: 32336572 [Indexed for MEDLINE]


495. Int J Pediatr Otorhinolaryngol. 1996 Jan;34(1-2):45-51. doi: 
10.1016/0165-5876(95)01238-9.

Identification of childhood hearing impairment in Uusimaa County, Finland.

Marttila TI(1), Karikoski JO.

Author information:
(1)Department of Audiology, Ear, Nose and Throat Clinic Helsinki University 
Central Hospital, Finland.

The purpose was to report the identification age of the hard-of-hearing children 
born between 1 January 1973 and 31 December 1990. The subjects comprised all 
children (353) fitted with hearing aid in an age-matched target population of 
270 726 persons in Uusimaa County including Helsinki. The age of identification 
was studied in three groups; pure tone average (0.5, 1 and 2 kHz) > or = 30 dB, 
> or = 35 dB and > or = 50 dB HL enabling comparison with the identification 
ages reported in the literature. In the first group the median identification 
age was 3.6 years (mean 4.2), in the second 2.9 years (mean 3.8) and in the 
third 2.1 years (mean 2.8). The first group was identified significantly later 
than the third one (P = 0.004). The second group differed from the third 
significantly in detection age as well (P = 0.004). The severity of hearing 
impairment correlated highly with the detection age (r = -0.69. P < 0.0001). The 
data clustered at the ages of 1-2.5 years (hearing level 90-120 dB) and at 4-8 
years (30-60 dB).

DOI: 10.1016/0165-5876(95)01238-9
PMID: 8770672 [Indexed for MEDLINE]


496. Laryngorhinootologie. 2001 Jan;80(1):61-2. doi: 10.1055/s-2001-11035.

[Classification of complex signal patterns with artificial neural networks in 
hearing and voice diagnosis].

[Article in German]

Schönweiler R(1).

Author information:
(1)Klinik und Poliklinik für Phoniatrie und Pädaudiologie Medizinische 
Hochschule Hannover Carl-Neuberg-Strasse 1 30625 Hannover.

DOI: 10.1055/s-2001-11035
PMID: 11272251 [Indexed for MEDLINE]


497. Conf Proc IEEE Eng Med Biol Soc. 2006;2006:1236-9. doi: 
10.1109/IEMBS.2006.259368.

Loudness normalization for cochlear implant using pulse-rate modulation to 
convey Mandarin tonal information: a model-based study.

Chen F(1), Zhang YT.

Author information:
(1)Shun Hing Institute of Advanced Engineering, Chinese University of Hong Kong, 
Hong Kong.

Cochlear implant (CI) devices employ electrical pulsatile stimulation of the 
auditory nerves (AN) to restore partial hearing to a profoundly deafened person. 
In order to improve the speech perception for CI users speaking tonal language, 
such as Mandarin, the pulse-rate has been suggested to be modulated according to 
the Mandarin tonal patterns to convey the Mandarin tonal information. However, 
recent psychological experiments have found that the pulse-rate modulation will 
produce accompanying variation of perceived loudness. The purpose of this paper 
is to introduce an amplitude compensation scheme to normalize the loudness 
perception when the pulse-rate is modulated to convey the Mandarin tonal 
information. Based on an integrate-and-fire AN model, a loudness perception 
model and a pitch perception were implemented. Result of model-based simulation 
showed that using the proposed amplitude compensation scheme, the estimated 
loudness was normalized while the Mandarin tonal information could still be 
efficiently transmitted. It is believed that, when the proposed electrical 
pulsatile stimulation incorporating both pulse-rate modulation and amplitude 
compensation is integrated with present CI devices, it would more efficiently 
enhance the speech identification for cochlear implantee speaking tonal 
languages, such as Mandarin.

DOI: 10.1109/IEMBS.2006.259368
PMID: 17946451 [Indexed for MEDLINE]


498. Adv Otorhinolaryngol. 1995;50:96-101. doi: 10.1159/000424442.

A new concept for cochlear implant speech processing for prelingually deaf 
children.

Leisenberg M(1).

Author information:
(1)Southampton University, Institute for Sound and Vibration Research, Wessex 
Regional Audiology Centre, Hants, UK.

DOI: 10.1159/000424442
PMID: 7610977 [Indexed for MEDLINE]


499. J Med Eng Technol. 2004 Nov-Dec;28(6):235-41. doi: 10.1080/0309190031000139065.

BAEP dynamic estimation in case of endocochlear pathologies using a time delay 
correction method.

Cherrid N(1), Naït-Ali A, Siarry P.

Author information:
(1)Université Paris 12 LERISS, 61 avenue du Général de Gaulle 94010, Créteil, 
France. cherrid@univ-paris12.fr

Extraction of Brainstem Auditory Evoked Potentials (BAEPs) from the 
electroencephalogram (EEG) is generally difficult when both BAEP and EEG are 
non-stationary. In this paper we focus on the problem of BAEP 
non-stationarities, in particular those observed in some endocochlear 
pathologies assumed causing random delays of BAEPs due to an abnormal behaviour 
of the cochlea. The technique developed in this paper, called the Time Delay 
Correction (TDC) method, allows us to estimate the averaged BAEP by an optimal 
alignment of responses based on a correlation criterion. We demonstrate that the 
TDC method avoids wave smoothness, generally produced with the classical 
ensemble averaging method, especially in the case when the hypothesis of the 
time delay non-stationarity is verified. The TDC method is performed using 
simulated annealing (SA) algorithm, since the criterion to be optimized is 
nonlinear. Real signals recorded from pathological subjects are used to validate 
the model of non-stationarity.

DOI: 10.1080/0309190031000139065
PMID: 15513741 [Indexed for MEDLINE]


500. Ann Otol Rhinol Laryngol Suppl. 1995 Sep;166:370-2.

First results on patient experiments with CINSTIM: the Southampton Cochlear 
Implant-Neural Network stimulation framework.

Leisenberg M(1), Southgate J.

Author information:
(1)University of Southampton, Institute for Sound and Vibration Research, 
England.

PMID: 7668711 [Indexed for MEDLINE]


501. Cortex. 2017 Jan;86:109-122. doi: 10.1016/j.cortex.2016.10.014. Epub 2016 Oct 
31.

Changed crossmodal functional connectivity in older adults with hearing loss.

Puschmann S(1), Thiel CM(2).

Author information:
(1)Biological Psychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany. Electronic address: 
sebastian.puschmann@uni-oldenburg.de.
(2)Biological Psychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, Carl von Ossietzky Universität 
Oldenburg, Oldenburg, Germany; Research Center Neurosensory Science, Carl von 
Ossietzky Universität Oldenburg, Oldenburg, Germany.

Previous work compellingly demonstrates a crossmodal plastic reorganization of 
auditory cortex in deaf individuals, leading to increased neural responses to 
non-auditory sensory input. Recent data indicate that crossmodal adaptive 
plasticity is not restricted to severe hearing impairments, but may also occur 
as a result of high-frequency hearing loss in older adults and affect 
audiovisual processing in these subjects. We here used functional magnetic 
resonance imaging (fMRI) to study the effect of hearing loss in older adults on 
auditory cortex response patterns as well as on functional connectivity between 
auditory and visual cortex during audiovisual processing. Older participants 
with a varying degree of high frequency hearing loss performed an auditory 
stimulus categorization task, in which they had to categorize 
frequency-modulated (FM) tones presented alone or in the context of matching or 
non-matching visual motion. A motion only condition served as control for a 
visual take-over of auditory cortex. While the individual hearing status did not 
affect auditory cortex responses to auditory, visual, or audiovisual stimuli, we 
observed a significant hearing loss-related increase in functional connectivity 
between auditory cortex and the right motion-sensitive visual area MT+ when 
processing matching audiovisual input. Hearing loss also modulated resting state 
connectivity between right area MT+ and parts of the left auditory cortex, 
suggesting the existence of permanent, task-independent changes in coupling 
between visual and auditory sensory areas with an increasing degree of hearing 
loss. Our data thus indicate that hearing loss impacts on functional 
connectivity between sensory cortices in older adults.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2016.10.014
PMID: 27930898 [Indexed for MEDLINE]


502. Biomed Tech (Berl). 2004 Apr;49(4):78-82. doi: 10.1515/BMT.2004.016.

Restoring hearing with active hearing implants.

Federspil PA(1), Plinkert PK.

Author information:
(1)University of Saarland, Department of Oto-Rhino-Laryngology, Homburg (Saar), 
Germany. Ph.Federspil@uniklinik-saarland.de

Due to shortcomings of conventional hearing aid technology, such as 
unsatisfactory sound quality due to limited frequency range and undesired 
distortion, occlusion of the outer ear canal, and acoustic feedback with high 
amplification, but also psychological aspects of stigmatization, a significant 
of patients in need of hearing aids are actually not wearing them. Active 
hearing implants can be distinguished in: (1) impedance transformation implants 
(ITI), (2) cochlear amplifier implants (CAI), (3) cochlear implants (CI), and 
(4) brain stem implants (BSI). Whereas ITI are designed for patients with middle 
ear hearing loss, CAI are intended to restore hearing in patients with inner ear 
hearing loss. Advantages of CAI may be: (1) improved sound fidelity, (2) no 
occlusion of the outer ear canal, (3) no feedback, and (4) invisibility. 
However, not all features are true for every device. CI replace inner ear 
function in deaf or almost deaf patients. This article gives an overview on the 
range of active hearing implants to restore hearing and outlines the future use 
of computer and robot aided surgery.

DOI: 10.1515/BMT.2004.016
PMID: 15171586 [Indexed for MEDLINE]


503. Int J Audiol. 2020 Jul;59(7):534-547. doi: 10.1080/14992027.2020.1728401. Epub 
2020 Feb 24.

Common Audiological Functional Parameters (CAFPAs) for single patient cases: 
deriving statistical models from an expert-labelled data set.

Buhl M(1)(2), Warzybok A(1)(2), Schädler MR(1)(2), Majdani O(2)(3), Kollmeier 
B(1)(2)(4)(5).

Author information:
(1)Medizinische Physik, Universität Oldenburg, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Universität Oldenburg, Oldenburg, Germany.
(3)Clinic for otolaryngology, Städt. Klinikum Wolfsburg, Wolfsburg, Germany.
(4)HörTech gGmbH, Oldenburg, Germany.
(5)Hearing, Speech and Audio Technology, Fraunhofer IDMT, Oldenburg, Germany.

Objective: Statistical knowledge about many patients could be exploited using 
machine learning to provide supporting information to otolaryngologists and 
other hearing health care professionals, but needs to be made accessible. The 
Common Audiological Functional Parameters (CAFPAs) were recently introduced for 
the purpose of integrating data from different databases by providing an 
abstract representation of audiological measurements. This paper aims at 
collecting expert labels for a sample database and to determine statistical 
models from the labelled data set.Design: By an expert survey, CAFPAs as well as 
labels for audiological findings and treatment recommendations were collected 
for patients from the database of Hörzentrum Oldenburg.Study sample: A total of 
287 single patient cases were assessed by twelve highly experienced audiological 
experts.Results: The labelled data set was used to derive probability density 
functions for categories given by the expert labels. The collected data set is 
suitable for estimating training distributions due to realistic variability 
contained in data for different, distinct categories. Suitable distribution 
functions were determined. The derived training distributions were compared 
regarding different audiological questions.Conclusions: The method-expert 
survey, sorting data into categories, and determining training distributions - 
could be extended to other data sets, which could then be integrated via the 
CAFPAs and used in a classification task.

DOI: 10.1080/14992027.2020.1728401
PMID: 32091289 [Indexed for MEDLINE]


504. Trends Hear. 2018 Jan-Dec;22:2331216518809737. doi: 10.1177/2331216518809737.

What Keeps Older Adults With Hearing Impairment From Adopting Hearing Aids?

Tahden MAS(1)(2), Gieseler A(1)(2), Meis M(1)(3)(4), Wagener KC(1)(3)(4), 
Colonius H(1)(2).

Author information:
(1)1 Cluster of Excellence 'Hearing4all', University of Oldenburg, Germany.
(2)2 Cognitive Psychology Lab, Department of Psychology, University of 
Oldenburg, Germany.
(3)3 Hörzentrum Oldenburg GmbH, Germany.
(4)4 HörTech gGmbH, Oldenburg, Germany.

The aim of this study was to compare elderly individuals who are hearing 
impaired but inexperienced in using hearing aids (hearing aid non-users; HA-NU) 
with their aided counterparts (hearing aid users; HA-U) across various auditory 
and non-auditory measures in order to identify differences that might be 
associated with the low hearing aid uptake rate. We have drawn data of 72 HA-NU 
and 139 HA-U with a mild-to-moderate hearing loss, and matched these two groups 
on the degree of hearing impairment, age, and sex. First, HA-NU and HA-U were 
compared across 65 auditory, cognitive, health-specific, and socioeconomic test 
measures as well as measures assessing technology commitment. Second, a logistic 
regression approach was performed to identify relevant predictors for using 
hearing aids. Finally, we conducted a sensitivity analysis for the matching 
approach. Group comparisons indicated that HA-NU perceive their hearing problem 
as less severe than their aided counterparts. Furthermore, HA-NU showed worse 
technology commitment and lower socioeconomic status than HA-U. The logistic 
regression revealed self-reported hearing performance, technology commitment, 
and the socioeconomic and health status as the most important predictors for 
using hearing aids.

DOI: 10.1177/2331216518809737
PMCID: PMC6243636
PMID: 30451099 [Indexed for MEDLINE]


505. Med Image Anal. 2020 Apr;61:101659. doi: 10.1016/j.media.2020.101659. Epub 2020 
Jan 28.

HeadLocNet: Deep convolutional neural networks for accurate classification and 
multi-landmark localization of head CTs.

Zhang D(1), Wang J(2), Noble JH(2), Dawant BM(3).

Author information:
(1)Department of Electrical Engineering and Computer Science, Vanderbilt 
University, Nashville, TN, 37235, USA. Electronic address: zhangdq20@gmail.com.
(2)Department of Electrical Engineering and Computer Science, Vanderbilt 
University, Nashville, TN, 37235, USA.
(3)Department of Electrical Engineering and Computer Science, Vanderbilt 
University, Nashville, TN, 37235, USA. Electronic address: 
benoit.dawant@vanderbilt.edu.

Cochlear implants (CIs) are used to treat subjects with hearing loss. In a CI 
surgery, an electrode array is inserted into the cochlea to stimulate auditory 
nerves. After surgery, CIs need to be programmed. Studies have shown that the 
cochlea-electrode spatial relationship derived from medical images can guide CI 
programming and lead to significant improvement in hearing outcomes. We have 
developed a series of algorithms to segment the inner ear anatomy and localize 
the electrodes. But, because clinical head CT images are acquired with different 
protocols, the field of view and orientation of the image volumes vary greatly. 
As a consequence, visual inspection and manual image registration to an atlas 
image are needed to document their content and to initialize intensity-based 
registration algorithms used in our processing pipeline. For large-scale 
evaluation and deployment of our methods these steps need to be automated. In 
this article we propose to achieve this with a deep convolutional neural network 
(CNN) that can be trained end-to-end to classify a head CT image in terms of its 
content and to localize landmarks. The detected landmarks can then be used to 
estimate a point-based registration with the atlas image in which the same 
landmark set's positions are known. We achieve 99.5% classification accuracy and 
an average localization error of 3.45 mm for 7 landmarks located around each 
inner ear. This is better than what was achieved with earlier methods we have 
proposed for the same tasks.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.media.2020.101659
PMCID: PMC7959656
PMID: 32062157 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


506. J Assoc Res Otolaryngol. 2022 Jun;23(3):319-349. doi: 
10.1007/s10162-022-00846-2. Epub 2022 Apr 20.

Harnessing the Power of Artificial Intelligence in Otolaryngology and the 
Communication Sciences.

Wilson BS(1)(2)(3)(4)(5), Tucci DL(6)(7), Moses DA(8)(9), Chang EF(8)(9), Young 
NM(10)(11)(12), Zeng FG(13)(14)(15)(16)(17), Lesica NA(18), Bur AM(19), 
Kavookjian H(19), Mussatto C(19), Penn J(19), Goodwin S(19), Kraft S(19), Wang 
G(20), Cohen JM(6)(21), Ginsburg GS(22)(23)(24)(25)(26)(27), Dawson 
G(28)(29)(30), Francis HW(6).

Author information:
(1)Department of Head and Neck Surgery & Communication Sciences, Duke University 
School of Medicine, Durham, NC, 27710, USA. blake.wilson@duke.edu.
(2)Duke Hearing Center, Duke University School of Medicine, Durham, NC, 27710, 
USA. blake.wilson@duke.edu.
(3)Department of Electrical & Computer Engineering, Duke University, Durham, NC, 
27708, USA. blake.wilson@duke.edu.
(4)Department of Biomedical Engineering, Duke University, Durham, NC, 27708, 
USA. blake.wilson@duke.edu.
(5)Department of Otolaryngology - Head & Neck Surgery, University of North 
Carolina, Chapel Hill, Chapel Hill, NC, 27599, USA. blake.wilson@duke.edu.
(6)Department of Head and Neck Surgery & Communication Sciences, Duke University 
School of Medicine, Durham, NC, 27710, USA.
(7)National Institute On Deafness and Other Communication Disorders, National 
Institutes of Health, Bethesda, MD, 20892, USA.
(8)Department of Neurological Surgery, University of California, San Francisco, 
San Francisco, CA, 94143, USA.
(9)UCSF Weill Institute for Neurosciences, University of California, San 
Francisco, San Francisco, CA, 94117, USA.
(10)Division of Otolaryngology, Ann and Robert H. Lurie Childrens Hospital of 
Chicago, Chicago, IL, 60611, USA.
(11)Department of Otolaryngology - Head and Neck Surgery, Northwestern 
University Feinberg School of Medicine, Chicago, IL, 60611, USA.
(12)Department of Communication, Knowles Hearing Center, Northwestern 
University, Evanston, IL, 60208, USA.
(13)Center for Hearing Research, University of California, Irvine, Irvine, CA, 
92697, USA.
(14)Department of Anatomy and Neurobiology, University of California, Irvine, 
Irvine, CA, 92697, USA.
(15)Department of Biomedical Engineering, University of California, Irvine, 
Irvine, CA, 92697, USA.
(16)Department of Cognitive Sciences, University of California, Irvine, Irvine, 
CA, 92697, USA.
(17)Department of Otolaryngology - Head and Neck Surgery, University of 
California, Irvine, CA, 92697, USA.
(18)UCL Ear Institute, University College London, London, WC1X 8EE, UK.
(19)Department of Otolaryngology - Head and Neck Surgery, Medical Center, 
University of Kansas, Kansas City, KS, 66160, USA.
(20)Department of Computer Science, Ryerson University, Toronto, ON, M5B 2K3, 
Canada.
(21)ENT Department, Kaplan Medical Center, 7661041, Rehovot, Israel.
(22)Department of Biomedical Engineering, Duke University, Durham, NC, 27708, 
USA.
(23)MEDx (Medicine & Engineering at Duke), Duke University, Durham, NC, 27708, 
USA.
(24)Center for Applied Genomics & Precision Medicine, Duke University School of 
Medicine, Durham, NC, 27710, USA.
(25)Department of Medicine, Duke University School of Medicine, Durham, NC, 
27710, USA.
(26)Department of Pathology, Duke University School of Medicine, Durham, NC, 
27710, USA.
(27)Department of Biostatistics and Bioinformatics, Duke University School of 
Medicine, Durham, NC, 27710, USA.
(28)Duke Institute for Brain Sciences, Duke University, Durham, NC, 27710, USA.
(29)Duke Center for Autism and Brain Development, Duke University School of 
Medicine and the Duke Institute for Brain Sciences, NIH Autism Center of 
Excellence, Durham, NC, 27705, USA.
(30)Department of Psychiatry and Behavioral Sciences, Duke University School of 
Medicine, Durham, NC, 27701, USA.

Use of artificial intelligence (AI) is a burgeoning field in otolaryngology and 
the communication sciences. A virtual symposium on the topic was convened from 
Duke University on October 26, 2020, and was attended by more than 170 
participants worldwide. This review presents summaries of all but one of the 
talks presented during the symposium; recordings of all the talks, along with 
the discussions for the talks, are available at 
https://www.youtube.com/watch?v=ktfewrXvEFg and 
https://www.youtube.com/watch?v=-gQ5qX2v3rg . Each of the summaries is about 
2500 words in length and each summary includes two figures. This level of detail 
far exceeds the brief summaries presented in traditional reviews and thus 
provides a more-informed glimpse into the power and diversity of current AI 
applications in otolaryngology and the communication sciences and how to harness 
that power for future applications.

© 2022. The Author(s) under exclusive licence to Association for Research in 
Otolaryngology.

DOI: 10.1007/s10162-022-00846-2
PMCID: PMC9086071
PMID: 35441936 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interest.


507. J Am Acad Audiol. 2014 Feb;25(2):187-98. doi: 10.3766/jaaa.25.2.7.

Patterns of hearing aid usage predict hearing aid use amount (data logged and 
self-reported) and overreport.

Laplante-Lévesque A(1), Nielsen C(2), Jensen LD(2), Naylor G(2).

Author information:
(1)Eriksholm Research Centre, Oticon A/S, Denmark; Department of Behavioural 
Sciences and Learning, Linköping University, Sweden.
(2)Eriksholm Research Centre, Oticon A/S, Denmark.

BACKGROUND: Previous studies found that, on average, users overreport their 
daily amount of hearing aid use compared to objective measures such as data 
logging. However, the reasons for this are unclear.
PURPOSE: This study assessed data-logged and self-reported amount of hearing aid 
use in a clinical sample of hearing aid users. It identified predictors of 
data-logged hearing aid use, self-reported hearing aid use, and hearing aid use 
overreport.
RESEARCH DESIGN: This observational study recruited adult hearing aid users from 
22 private dispensers in the Netherlands and in Denmark.
STUDY SAMPLE: The sample consisted of 228 hearing aid users. Typical 
participants were over the age of 65 and retired, were fitted binaurally, and 
had financially contributed to the cost of their hearing aids. Participants had 
on average a mild-to-severe sloping bilateral hearing impairment.
DATA COLLECTION AND ANALYSIS: Participants completed a purposefully designed 
questionnaire regarding hearing aid usage and the International Outcome 
Inventory-Hearing Aids. Dispensers collected audiometric results and data 
logging. Multiple linear regression identified predictors of data-logged hearing 
aid use, self-reported hearing aid use, and hearing aid use overreport when 
controlling for covariates.
RESULTS: Data logging showed on average 10.5 hr of hearing aid use (n = 184), 
while participants reported on average 11.8 hr of daily hearing aid use (n = 
206). In participants for which both data-logged and self-reported hearing aid 
use data were available (n = 166), the average absolute overreport of daily 
hearing aid use was 1.2 (1 hr and 11 min). Relative overreport was expressed as 
a rate of absolute overreport divided by data-logged hearing aid use. A positive 
rate denotes hearing aid use overreport: the average overreport rate was .38. 
Cluster analysis identified two data-logged patterns: "Regular," where hearing 
aids are typically switched on for between 12 and 20 hr before their user powers 
them off (57% of the sample), and "On-off," where hearing aids are typically 
switched on for shorter periods of time before being powered off (43% of the 
sample). In terms of self-report, 77% of the sample described their hearing aid 
use to be the same every day, while 23% of the sample described their hearing 
aid use to be different from day to day. Participants for whom data logging 
showed an On-off pattern or who reported their hearing aid use to be different 
from day to day had significantly fewer data-logged and self-reported hours of 
hearing aid use. Having an On-off data-logging pattern or describing hearing aid 
use as the same every day was associated with a significantly greater hearing 
aid use overreport.
CONCLUSIONS: Data-logged and self-reported usage patterns significantly 
predicted data-logged hearing aid use, self-reported hearing aid use, and 
overreport when controlling for covariates. The results point to patterns of 
hearing aid usage as being at least as important a concept as amount of hearing 
aid use. Dispensers should discuss not only the "how much", but also the "how" 
of hearing aid usage with their clients.

American Academy of Audiology.

DOI: 10.3766/jaaa.25.2.7
PMID: 24828219 [Indexed for MEDLINE]


508. Cochlear Implants Int. 2023 Jul;24(4):195-204. doi: 
10.1080/14670100.2022.2148351. Epub 2023 Jan 8.

Auditory rehabilitation after temporal bone fracture with cochlear implants - a 
case control study.

Heine K(1), Timm ME(1)(2), Gärtner L(1), Lenarz T(1), Lesinski-Schiedat A(1).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence, Hearing4all, Hannover Medical School, Hannover, 
Germany.

OBJECTIVES: Temporal bone fracture can cause posttraumatic deafness. Sequelae 
like ossification or obliteration of the cochlea can impact the outcome of 
cochlear implantation. This study highlights the effect of localisation of the 
fracture to morphologic, electric and functional criteria.
METHODS: The study group consists of patients suffering from hearing loss caused 
by temporal bone fracture (n = 61 ears). Patients were divided into otic capsule 
sparing (OCS) and otic capsule involving (OCI) fractures. The OCI group was 
additionally divided into subgroups with or without signs of ossification inside 
the cochlea. Postoperative imaging, hearing tests and electrode impedances were 
analysed.
RESULTS: The results of postoperative hearing rehabilitation showed lower speech 
understanding scores for the OCI group, especially for the ossification group. 
OCI fractures with signs of ossification showed increased impedances. Patients 
in the OCI group suffered more frequently from facial nerve stimulation (FNS). 
FNS was most frequently observed within the ossification group.
CONCLUSION: Cochlear implantation in patients with temporal bone fracture is 
adequate therapy for the treatment of fracture-induced deafness. In long-term 
observation, these patients show comparable results with regular cochlear 
implant (CI) patients. Implantation should be performed as soon as possible 
after hearing loss, before obstructing obliteration or ossification of the 
cochlea start.

DOI: 10.1080/14670100.2022.2148351
PMID: 36617461 [Indexed for MEDLINE]


509. BMC Neurol. 2024 Apr 8;24(1):115. doi: 10.1186/s12883-024-03616-0.

Improving emotion perception in cochlear implant users: insights from machine 
learning analysis of EEG signals.

Paquette S(1)(2)(3), Gouin S(4)(5), Lehmann A(6)(4)(5).

Author information:
(1)Psychology Department, Faculty of Arts and Science, Trent University, 
Peterborough, ON, Canada. sebastienpaquette@trentu.ca.
(2)Research Institute of the McGill University Health Centre (RI-MUHC), 
Montreal, QC, Canada. sebastienpaquette@trentu.ca.
(3)Centre for Research On Brain, Language, and Music (CRBLM), International 
Laboratory for Brain, Music & Sound Research (BRAMS), Psychology Department, 
University of Montreal, Montreal, QC, Canada. sebastienpaquette@trentu.ca.
(4)Centre for Research On Brain, Language, and Music (CRBLM), International 
Laboratory for Brain, Music & Sound Research (BRAMS), Psychology Department, 
University of Montreal, Montreal, QC, Canada.
(5)Faculty of Medicine and Health Sciences, Department of Otolaryngology-Head 
and Neck Surgery, McGill University, Montreal, QC, Canada.
(6)Research Institute of the McGill University Health Centre (RI-MUHC), 
Montreal, QC, Canada.

BACKGROUND: Although cochlear implants can restore auditory inputs to 
deafferented auditory cortices, the quality of the sound signal transmitted to 
the brain is severely degraded, limiting functional outcomes in terms of speech 
perception and emotion perception. The latter deficit negatively impacts 
cochlear implant users' social integration and quality of life; however, emotion 
perception is not currently part of rehabilitation. Developing rehabilitation 
programs incorporating emotional cognition requires a deeper understanding of 
cochlear implant users' residual emotion perception abilities.
METHODS: To identify the neural underpinnings of these residual abilities, we 
investigated whether machine learning techniques could be used to identify 
emotion-specific patterns of neural activity in cochlear implant users. Using 
existing electroencephalography data from 22 cochlear implant users, we employed 
a random forest classifier to establish if we could model and subsequently 
predict from participants' brain responses the auditory emotions (vocal and 
musical) presented to them.
RESULTS: Our findings suggest that consistent emotion-specific biomarkers exist 
in cochlear implant users, which could be used to develop effective 
rehabilitation programs incorporating emotion perception training.
CONCLUSIONS: This study highlights the potential of machine learning techniques 
to improve outcomes for cochlear implant users, particularly in terms of emotion 
perception.

© 2024. The Author(s).

DOI: 10.1186/s12883-024-03616-0
PMCID: PMC11000345
PMID: 38589815 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


510. Biomolecules. 2021 Jun 17;11(6):900. doi: 10.3390/biom11060900.

The Conspicuous Link between Ear, Brain and Heart-Could Neurotrophin-Treatment 
of Age-Related Hearing Loss Help Prevent Alzheimer's Disease and Associated 
Amyloid Cardiomyopathy?

Shityakov S(1)(2), Hayashi K(3), Störk S(4), Scheper V(5), Lenarz T(5), Förster 
CY(1).

Author information:
(1)Department of Anaesthesiology, Intensive Care, Emergency and Pain Medicine, 
University Hospital Würzburg, D-97080 Würzburg, Germany.
(2)Infochemistry Scientific Center, Laboratory of Chemoinformatics, ITMO 
University, 191002 Saint-Petersburg, Russia.
(3)Advanced Stroke Center, Shimane University Hospital, 89-1 Enya, Shimane, 
Izumo 693-8501, Japan.
(4)Comprehensive Heart Failure Q9 Center, University of Würzburg, D-97080 
Würzburg, Germany.
(5)Department of Otolaryngology, Hannover Medical School and Cluster of 
Excellence "Hearing4All", 30625 Hannover, Germany.

Alzheimer's disease (AD), the most common cause of dementia in the elderly, is a 
neurodegenerative disorder associated with neurovascular dysfunction and 
cognitive decline. While the deposition of amyloid β peptide (Aβ) and the 
formation of neurofibrillary tangles (NFTs) are the pathological hallmarks of 
AD-affected brains, the majority of cases exhibits a combination of 
comorbidities that ultimately lead to multi-organ failure. Of particular 
interest, it can be demonstrated that Aβ pathology is present in the hearts of 
patients with AD, while the formation of NFT in the auditory system can be 
detected much earlier than the onset of symptoms. Progressive hearing impairment 
may beget social isolation and accelerate cognitive decline and increase the 
risk of developing dementia. The current review discusses the concept of a 
brain-ear-heart axis by which Aβ and NFT inhibition could be achieved through 
targeted supplementation of neurotrophic factors to the cochlea and the brain. 
Such amyloid inhibition might also indirectly affect amyloid accumulation in the 
heart, thus reducing the risk of developing AD-associated amyloid cardiomyopathy 
and cardiovascular disease.

DOI: 10.3390/biom11060900
PMCID: PMC8235707
PMID: 34204299 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


511. Hear Res. 2017 Jul;350:110-121. doi: 10.1016/j.heares.2017.04.013. Epub 2017 Apr 
25.

Encapsulated cell device approach for combined electrical stimulation and 
neurotrophic treatment of the deaf cochlea.

Konerding WS(1), Janssen H(2), Hubka P(3), Tornøe J(4), Mistrik P(5), Wahlberg 
L(6), Lenarz T(7), Kral A(8), Scheper V(9).

Author information:
(1)Institute of AudioNeuroTechnology, Department of Experimental Otology, 
Hannover Medical School, Hannover, Germany; Department of Otolaryngology, 
Hannover Medical School, Hannover, Germany. Electronic address: 
Konerding.wiebke@mh-hannover.de.
(2)Institute of AudioNeuroTechnology, Department of Experimental Otology, 
Hannover Medical School, Hannover, Germany; Department of Otolaryngology, 
Hannover Medical School, Hannover, Germany; Institute of Zoology, University of 
Veterinary Medicine Hannover, Foundation, Hannover, Germany. Electronic address: 
Janssen.Heike@mh-hannover.de.
(3)Institute of AudioNeuroTechnology, Department of Experimental Otology, 
Hannover Medical School, Hannover, Germany. Electronic address: 
Hubka.Peter@mh-hannover.de.
(4)NsGene A/S, Ballerup, Denmark. Electronic address: jt@nsgene.com.
(5)MED-EL, Innsbruck, Austria. Electronic address: Pavel.Mistrik@medel.com.
(6)NsGene A/S, Ballerup, Denmark. Electronic address: luw@nsgene.com.
(7)Department of Otolaryngology, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence Hearing4all, German Research Foundation, Hannover, 
Germany. Electronic address: Lenarz.Thomas@mh-hannover.de.
(8)Institute of AudioNeuroTechnology, Department of Experimental Otology, 
Hannover Medical School, Hannover, Germany; Cluster of Excellence Hearing4all, 
German Research Foundation, Hannover, Germany. Electronic address: 
Kral.Andrej@mh-hannover.de.
(9)Department of Otolaryngology, Hannover Medical School, Hannover, Germany; 
Cluster of Excellence Hearing4all, German Research Foundation, Hannover, 
Germany. Electronic address: Scheper.Verena@mh-hannover.de.

Profound hearing impairment can be overcome by electrical stimulation (ES) of 
spiral ganglion neurons (SGNs) via a cochlear implant (CI). Thus, SGN survival 
is critical for CI efficacy. Application of glial cell line-derived neurotrophic 
factor (GDNF) has been shown to reduce SGN degeneration following deafness. We 
tested a novel method for local, continuous GDNF-delivery in combination with ES 
via a CI. The encapsulated cell (EC) device contained a human ARPE-19 cell-line, 
genetically engineered for secretion of GDNF. In vitro, GDNF delivery was stable 
during ES delivered via a CI. In the chronic in vivo part, cats were 
systemically deafened and unilaterally implanted into the scala tympani with a 
CI and an EC device, which they wore for six months. The implantation of control 
devices (same cell-line not producing GDNF) had no negative effect on SGN 
survival. GDNF application without ES led to an unexpected reduction in SGN 
survival, however, the combination of GDNF with initial, short-term ES resulted 
in a significant protection of SGNs. A tight fibrous tissue formation in the 
scala tympani of the GDNF-only group is thought to be responsible for the 
increased SGN degeneration, due to mechanisms related to an aggravated foreign 
body response. Furthermore, the fibrotic encapsulation of the EC device led to 
cell death or cessation of GDNF release within the EC device during the six 
months in vivo. In both in vitro and in vivo, fibrosis was reduced by CI 
stimulation, enabling the neuroprotective effect of the combined treatment. 
Thus, fibrous tissue growth limits treatment possibilities with an EC device. 
For a stable and successful long-term neurotrophic treatment of the SGN via EC 
devices in human CI users, it would be necessary to make changes in the 
treatment approach (provision of anti-inflammatories), the EC device surface 
(reduced cell adhesion) and the ES (initiation prior to fibrosis formation).

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.04.013
PMID: 28463804 [Indexed for MEDLINE]


512. Int J Audiol. 2007 Dec;46(12):732-7. doi: 10.1080/14992020701448986.

Prevalence of hearing impairment in an adult population in Southern Taiwan.

Lin CY(1), Yang YC, Guo YL, Wu CH, Chang CJ, Wu JL.

Author information:
(1)Department of Otolaryngology, Tainan Municipal Hospital, Tainan, Taiwan.

The objective of this study was to estimate the prevalence of hearing impairment 
in a representative adult population in southern Taiwan and compare the results 
to those of similar studies in other countries. A stratified systematic cluster 
sample of 1140 residents, aged > or =20 years, of Tainan City was studied from 
2001 to 2003. The test battery included otoscopy, pure-tone audiometry, and a 
questionnaire covering relevant personal, occupational, and family history. The 
hearing threshold level (HTL) was defined as the better ear pure-tone average 
(BPTA) (i.e. the average of hearing thresholds at frequencies 500, 1000, 2000, 
and 4000 Hz). The prevalence of hearing impairment was 21.4% (95% confidence 
interval: 19.3-23.7%) at BPTA > or =25 dB HTL. Middle ear disease was a 
significant risk factor for hearing impairment in addition to age and gender. 
The overall prevalence of hearing impairment may be higher in Taiwan (17.1%) 
than in western populations (11.5%), but differences in the definition of 
hearing impairment severity and variation in sex distribution among studies may 
account for this higher prevalence.

DOI: 10.1080/14992020701448986
PMID: 18049962 [Indexed for MEDLINE]


513. Laryngoscope. 2007 Jul;117(7):1260-6. doi: 10.1097/MLG.0b013e31806009c9.

Cochlear implantation in Children with CHARGE syndrome: therapeutic decisions 
and outcomes.

Lanson BG(1), Green JE, Roland JT Jr, Lalwani AK, Waltzman SB.

Author information:
(1)Department of Otolaryngology, NYU School of Medicine, New York, NY 10016, 
USA.

OBJECTIVES: Ear anomalies and deafness are associated with CHARGE syndrome, 
which also presents with a cluster of features including coloboma of the eye, 
heart defects, atresia of the choanae, developmental retardation, and 
genitourinary abnormalities. The aim of this study is to explore the viability 
of cochlear implantation in children with CHARGE syndrome and to assess the 
outcome.
STUDY DESIGN: Retrospective chart review.
METHODS: Eleven children presenting with severe to profound sensorineural 
hearing loss associated with CHARGE syndrome were the subjects of this study. 
Routine audiometric measurements and the Infant Toddler Meaningful Auditory 
Integration Scale (IT-MAIS) were performed pre- and postoperatively. In 
addition, the degree of the subjects' cochlear deformity were measured and 
correlated to outcome.
RESULTS: All patients had varying degrees of ear anomalies, seven patients 
suffered from coloboma of the eyes, two had heart defects, five exhibited 
choanal atresia, eleven showed developmental retardation, and six had 
genitourinary abnormalities. Ten of the children underwent cochlear implantation 
with complete insertion of the electrode array without complication and were 
followed over a 3-month to a 7-year period. The eleventh child was not implanted 
because of severe retardation. All of the implanted children showed varying, but 
limited degrees, of auditory benefit as measured by routine audiometry and the 
IT-MAIS.
CONCLUSIONS: Careful treatment planning for children with sensorineural hearing 
loss and CHARGE syndrome can lead to varying, but limited degrees, of auditory 
benefit with no increase in surgical complications. Although the implant 
enhanced the children's 'connectivity' to the environment, it did not promote 
the development of oral language skills in this population.

DOI: 10.1097/MLG.0b013e31806009c9
PMID: 17507827 [Indexed for MEDLINE]


514. Neuroinformatics. 2004;2(2):251-66. doi: 10.1385/NI:2:2:251.

Relating fMRI and PET signals to neural activity by means of large-scale neural 
models.

Horwitz B(1).

Author information:
(1)Section on Brain Imaging and Modeling, National Institute on Deafness and 
Other Communication Disorders, National Institutes of Health, Bethesda, MD, USA. 
horwitz@helix.nih.gov

This article reviews the four ways by which large-scale, neurobiologically 
realistic modeling can be used in conjunction with functional neuroimaging data, 
especially that obtained by functional magnetic resonance imaging (fMRI) and 
positron emission tomography (PET), to help investigators understand the neural 
bases for sensorimotor and cognitive functions. The conceptually distinct 
purposes served are:(1) formulating and implementing specific hypotheses about 
how neuronal populations mediate a task, which will be illustrated using models 
of visual and auditory object processing; (2) determining how well an 
experimental design paradigm or analysis method works, which will be illustrated 
by examining event-related fMRI; (3) investigating the meaning in neural terms 
of macro-level concepts, which will be illustrated using functional 
connectivity; and (4) combining different types of macroscopic data with one 
another, which will be illustrated using transcranial magnetic stimulation (TMS) 
and PET.

DOI: 10.1385/NI:2:2:251
PMID: 15319520 [Indexed for MEDLINE]


515. Lin Chuang Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2010 Nov;24(22):1018-22.

[Functional MRI study of auditory cortical responses in normal subjects and 
unilateral sensorineural hearing loss subjects].

[Article in Chinese]

Ji H(1), Huang Z, Yang M, Feng X, Meng L.

Author information:
(1)Department of Otorhinolaryngology, Zhongda Hospital of Southeast University, 
Nanjing, 210009, China.

OBJECTIVE: Amplitude modulation of auditory cortical responses was evaluated 
with functional MRI (fMRI) in subjects of unilateral sensorineural hearing loss 
(USNHL) and those of normal hearing (NH).
METHOD: Twenty-one subjects with USNHL and 11 with normal hearing were examined 
with fMRI in response to amplitude modulation tones of 500 Hz with the 
modulation frequency at 8 Hz. An event related design was combined with a sparse 
clustered volume acquisitioning paradigm in data collection in order to reduce 
the influence of acoustic scanner noise. SPM2 software was used for offline data 
analyzing.
RESULT: Significant activation, including volume and intensity, were found in 
the temporal lobe of control subjects, and significant differences in the volume 
and intensity were noted between the contralateral and ipsilateral activated 
auditory cortexes in them, exhibiting clearly contralateral predominance. When 
the normal ear with unilateral sensorineural hearing loss received signals, 
while significant activations in bilateral auditory cortexes, greater activation 
in the contralateral auditory cortexes was found in the normal ear.
CONCLUSION: The difference in the lateralization between the two groups suggests 
the plasticity of auditory cortex with unilateral sensorineural hearing loss.

PMID: 21322926 [Indexed for MEDLINE]


516. Rev Neurol (Paris). 2001 Sep;157(8-9 Pt 1):837-46.

[Auditory perception and language: functional imaging of speech sensitive 
auditory cortex].

[Article in French]

Samson Y(1), Belin P, Thivard L, Boddaert N, Crozier S, Zilbovicius M.

Author information:
(1)CEA, DRM, Service Hospitalier Frédéric Joliot, Orsay, France. 
yves.samson@psl.ap-hop-paris.fr

Since the description of cortical deafness, it has been known that the superior 
temporal cortex is bilaterally involved in the initial stages of language 
auditory perception but the precise anatomical limits and the function of this 
area remain debated. Here we reviewed more than 40 recent papers of positron 
emission tomography and functional magnetic resonance imaging related to 
language auditory perception, and we performed a meta-analysis of the 
localization of the peaks of activation in the Talairach's space. We found 8 
studies reporting word versus non-word listening contrasts with 54 activation 
peaks in the temporal lobes. These peaks clustered in a bilateral and 
well-limited area of the temporal superior cortex, which is here operationally 
defined as the speech sensitive auditory cortex. This area is more than 4cm 
long, located in the superior temporal gyrus and the superior temporal sulcus, 
both anterior and posterior to Heschl's gyrus. It do not include the primary 
auditory cortex nor the ascending part of the planum temporale. The speech 
sensitive auditory cortex is not activated by pure tones, environmental sounds, 
or attention directed toward elementary components of a sound such as intensity, 
pitch, or duration, and thus has some specificity for speech signals. The 
specificity is not perfect, since we found a number of non-speech auditory 
stimuli activating the speech sensitive auditory cortex. Yet the latter studies 
always involve auditory perception mechanisms which are also relevant to speech 
perception either at the level of primitive auditory scene analysis processes, 
or at the level of specific schema-based recognition processes. The dorsal part 
of the speech sensitive auditory cortex may be involved in primitive scene 
analysis processes, whereas distributed activation of this area may contribute 
to the emergence of a broad class of "voice" schemas and of more specific 
"speech schemas/phonetic modules" related to different languages. In addition, 
this area is activated by language-related lip movement, suggesting that a 
multimodal integration of the auditory and the visual information relevant in 
speech perception occurs at this level. Finally, there is a task-related 
top-down modulation of the pattern of activation of the speech sensitive 
auditory cortex which may reflect the fact that the different parts of this 
structure are connected to different down-stream cortical regions involved in 
the neural processing of different types of tasks.

PMID: 11677406 [Indexed for MEDLINE]


517. Otol Neurotol. 2008 Jan;29(1):93-6. doi: 10.1097/mao.0b013e31815c2abb.

Familial clustering of migraine, episodic vertigo, and Ménière's disease.

Cha YH(1), Kane MJ, Baloh RW.

Author information:
(1)Department of Neurology, University of California-Los Angeles, Los Angeles, 
California 90095, USA. yhcha@mednet.ucla.edu

OBJECTIVE: To evaluate the association between migraine, episodic vertigo, and 
Ménière's disease in families.
STUDY DESIGN: Clinical report.
SETTING: University Neurotology Clinic.
PATIENTS: Index patients identified with Ménière's disease and migraine and 
their family members.
INTERVENTION: Structured interview to assess a diagnosis of migraine, episodic 
vertigo, and Ménière's disease in 6 families. Genotyping was performed on 3 sets 
of twins to analyze monozygosity or dizygosity.
MAIN OUTCOME MEASURES: Clinical history of migraine, episodic vertigo, and 
Ménière's disease.
RESULTS: Six index patients and 57 family members were interviewed either by a 
senior neurologist in person or over the phone by a trained study coordinator. 
An additional 6 family members completed questionnaires by mail. All 6 index 
patients had Ménière's disease and migraine. Twenty-six (41%) of the 63 
relatives met International Classification of Headache Disorders II criteria for 
migraine headaches. Thirteen (50%) of these 26 experienced migraine with aura. 
Three others experienced typical aura without headache. Seventeen (27%) of 63 
family members experienced recurrent spells of spontaneous episodic vertigo. 
There was one twin pair in each of 3 families; 2 pairs were monozygotic and one 
was dizygotic. In each twin pair, one twin had migraine and Ménière's disease, 
whereas the other experienced migraine and episodic vertigo without auditory 
symptoms.
CONCLUSION: The frequent association of episodic vertigo, migraine, and 
Ménière's disease in closely related individuals, including identical twins 
supports the heritability of a migraine-Ménière's syndrome, with variable 
expression of the individual features of hearing loss, episodic vertigo, and 
migraine headaches.

DOI: 10.1097/mao.0b013e31815c2abb
PMCID: PMC2820370
PMID: 18046258 [Indexed for MEDLINE]

Conflict of interest statement: The authors report no conflicts of interest.


518. PLoS One. 2016 Jan 25;11(1):e0145096. doi: 10.1371/journal.pone.0145096. 
eCollection 2016.

Learning to Produce Syllabic Speech Sounds via Reward-Modulated Neural 
Plasticity.

Warlaumont AS(1), Finnegan MK(2).

Author information:
(1)Cognitive and Information Sciences, University of California, Merced, Merced, 
CA, United States of America.
(2)Speech & Hearing Sciences, University of Illinois at Urbana-Champaign, 
Champaign, IL, United States of America.

At around 7 months of age, human infants begin to reliably produce well-formed 
syllables containing both consonants and vowels, a behavior called canonical 
babbling. Over subsequent months, the frequency of canonical babbling continues 
to increase. How the infant's nervous system supports the acquisition of this 
ability is unknown. Here we present a computational model that combines a 
spiking neural network, reinforcement-modulated spike-timing-dependent 
plasticity, and a human-like vocal tract to simulate the acquisition of 
canonical babbling. Like human infants, the model's frequency of canonical 
babbling gradually increases. The model is rewarded when it produces a sound 
that is more auditorily salient than sounds it has previously produced. This is 
consistent with data from human infants indicating that contingent adult 
responses shape infant behavior and with data from deaf and tracheostomized 
infants indicating that hearing, including hearing one's own vocalizations, is 
critical for canonical babbling development. Reward receipt increases the level 
of dopamine in the neural network. The neural network contains a reservoir with 
recurrent connections and two motor neuron groups, one agonist and one 
antagonist, which control the masseter and orbicularis oris muscles, promoting 
or inhibiting mouth closure. The model learns to increase the number of salient, 
syllabic sounds it produces by adjusting the base level of muscle activation and 
increasing their range of activity. Our results support the possibility that 
through dopamine-modulated spike-timing-dependent plasticity, the motor cortex 
learns to harness its natural oscillations in activity in order to produce 
syllabic sounds. It thus suggests that learning to produce rhythmic mouth 
movements for speech production may be supported by general cortical learning 
mechanisms. The model makes several testable predictions and has implications 
for our understanding not only of how syllabic vocalizations develop in infancy 
but also for our understanding of how they may have evolved.

DOI: 10.1371/journal.pone.0145096
PMCID: PMC4726623
PMID: 26808148 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


519. Hear Res. 2009 Aug;254(1-2):54-63. doi: 10.1016/j.heares.2009.04.011. Epub 2009 
Apr 22.

Relation of focal hair-cell lesions to noise-exposure parameters from a 4- or a 
0.5-kHz octave band of noise.

Harding GW(1), Bohne BA.

Author information:
(1)Department of Otolaryngology, Box 8115, Washington University School of 
Medicine, 660 South Euclid Avenue, St. Louis, MO 63110, USA. 
hardingg@ent.wustl.edu

In a previous study, we examined the relation between total energy in a noise 
exposure and the percentage losses of outer (OHC) and inner (IHC) hair cells in 
the basal and apical halves of 607 chinchilla cochleae [Harding, G.W., Bohne, 
B.A., 2004a. Noise-induced hair-cell loss and total exposure energy: analysis of 
a large data set. J. Acoust. Soc. Am. 115, 2207-2220]. The animals had been 
exposed continuously to either a 4-kHz octave band of noise (OBN) at 47-108 dB 
SPL for 0.5h-36 d, or a 0.5-kHz OBN at 65-128 dB SPL for 3.5h-433 d. Interrupted 
exposures were also employed with both OBNs. Post-exposure recovery times ranged 
from 0 to 913 days. Cluster analysis was used to separate the data into three 
magnitudes of damage. The data were also separated into recovery times of 0 days 
(acute) and >0 days (chronic) and the apical and basal halves of the organ of 
Corti (OC). A substantial part of these hair-cell losses occurred in focal 
lesions (i.e., >or=50% loss of IHCs, OHCs or both over a distance of >or=0.03 
mm). This aspect of the damage from noise was not included in the previous 
analysis. The present analysis describes, within the same three clusters, the 
apex-to-base distribution of 1820 focal lesions found in 468 of 660 (71%) 
noise-exposed cochleae. In these cochleae, OC length in mm was converted to 
percent distance from the apex. The lesion data were analyzed for location in 
percent distance from the apex and size (mm) of the lesions. In 55 of 140 (39%) 
non-noise-exposed, control OCs, there were 186 focal hair-cell lesions, the 
characteristics of which were also determined. Focal lesions with hair-cell loss 
>or=50% involved predominantly OHCs, IHCs only, or both OHCs and IHCs (i.e., 
combined OHC-IHC lesions). The predominantly OHC and combined lesions were 
pooled together for the analysis. The distributions of lesion location (in 
percent distance from the apex), weighted by lesion size (in percent of OC 
length) were tallied in 2%-distance bins. In controls, focal lesions were 
uniformly distributed from apex to base and 70% of them were pure IHC lesions. 
In cochleae exposed to the 4-kHz OBN, lesions were distributed throughout the 
basal half of the OC. In cochleae exposed to the 0.5-kHz OBN, lesions occurred 
in both halves of the OC. With continuous exposures, 74% of the lesions were 
predominantly OHC or combined lesions. With interrupted exposures, 52% of the 
lesions were OHC or combined lesions. Lesion size was generally larger in the 
chronic compared to acute cochleae with similar exposures. There was a minimum 
total energy at which focal lesions began to appear and slightly higher energies 
resulted in nearly all exposed cochleae having focal lesions.

DOI: 10.1016/j.heares.2009.04.011
PMID: 19393307 [Indexed for MEDLINE]


520. Ear Hear. 2023 Jan-Feb 01;44(1):2-9. doi: 10.1097/AUD.0000000000001265. Epub 
2022 Aug 23.

Environmental Factors for Hearing Loss and Middle Ear Disease in Alaska Native 
Children and Adolescents: A Cross-Sectional Analysis from a Cluster Randomized 
Trial.

Hicks KL(1), Robler SK(2)(3), Platt A(4)(5), Morton SN(4)(5), Egger JR(5), 
Emmett SD(5)(6)(7).

Author information:
(1)Department of Otolaryngology/Head and Neck Surgery, University of North 
Carolina - Chapel Hill, Chapel Hill, North Carolina, USA.
(2)Department of Audiology, Norton Sound Health Corporation, Nome, Alaska, USA.
(3)Department of Otolaryngology, Head and Neck Surgery, University of Arkansas 
for Medical Sciences, Little Rock, Arkansas, USA.
(4)Department of Biostatistics and Bioinformatics, Duke University, Durham, 
North Carolina, USA.
(5)Duke Global Health Institute, Durham, North Carolina, USA.
(6)Department of Head and Neck Surgery and Communication Sciences, Duke 
University School of Medicine, Durham, North Carolina, USA.
(7)Center for Health Policy and Inequalities Research, Duke University, Durham, 
North Carolina, USA.

OBJECTIVES: Infection-related childhood hearing loss is one of the few 
preventable chronic health conditions that can affect a child's lifelong 
trajectory. This study sought to quantify relationships between 
infection-mediated hearing loss and middle ear disease and environmental 
factors, such as exposure to wood smoke, cigarette smoke, household crowding, 
and lack of access to plumbed (running) water, in a northwest region of rural 
Alaska.
DESIGN: This study is a cross-sectional analysis to estimate environmental 
factors of infection-related hearing loss in children aged 3 to 21 years. School 
hearing screenings were performed as part of two cluster randomized trials in 
rural Alaska over two academic years (2017-2018 and 2018-2019). The first 
available screening for each child was used for this analysis. Sociodemographic 
questionnaires were completed by parents/guardians upon entry into the study. 
Multivariable regression was performed to estimate prevalence differences and 
prevalence ratios (PR). A priori knowledge about the prevalence of middle ear 
disease and the difficulty inherent in obtaining objective hearing loss data in 
younger children led to analysis of children by age (3 to 6 years versus 7 years 
and older) and a separate multiple imputation sensitivity analysis for pure-tone 
average (PTA)-based infection-related hearing loss measures.
RESULTS: A total of 1634 children participated. Hearing loss was present in 
11.1% of children sampled based on otoacoustic emission as the primary indicator 
of hearing loss and was not associated with exposure to cigarette smoke (PR = 
1.07; 95% confidence interval [CI], 0.48 to 2.38), use of a wood-burning stove 
(PR = 0.85; 95% CI, 0.55 to 1.32), number of persons living in the household (PR 
= 1.06; 95% CI, 0.97 to 1.16), or lack of access to running water (PR = 1.38; 
95% CI, 0.80 to 2.39). Using PTA as a secondary indicator of hearing loss also 
showed no association with environmental factors. Middle ear disease was present 
in 17.4% of children. There was a higher prevalence of middle ear disease in 
homes without running water versus those with access to running water (PR = 
1.53; 95% CI, 1.03 to 2.27). There was little evidence to support any cumulative 
effects of environmental factors. Heterogeneity of effect models by age found 
sample prevalence of hearing loss higher for children aged 3 to 6 years (12.2%; 
95% CI, 9.3 to 15.7) compared to children 7 years and older (10.6%; 95% CI, 8.9 
to 2.6), as well as for sample prevalence of middle ear disease (22.7%; 95% CI, 
18.9 to 26.9 and 15.3%; 95% CI, 13.3 to 17.5, respectively).
CONCLUSIONS: Lack of access to running water in the home was associated with 
increased prevalence of middle ear disease in this rural, Alaska Native 
population, particularly among younger children (aged 3 to 6 years). There was 
little evidence in this study that cigarette smoke, wood-burning stoves, and 
greater numbers of persons in the household were associated with 
infection-mediated hearing loss or middle ear disease. Future research with 
larger sample sizes and more sensitive measures of environmental exposure is 
necessary to further evaluate these relationships. Children who live in homes 
without access to running water may benefit from earlier and more frequent 
hearing health visits.

Copyright © 2022 The Authors. Ear & Hearing is published on behalf of the 
American Auditory Society, by Wolters Kluwer Health.

DOI: 10.1097/AUD.0000000000001265
PMCID: PMC9780156
PMID: 35998103 [Indexed for MEDLINE]

Conflict of interest statement: There are no conflicts of interest, financial, 
or otherwise.


521. Hear Res. 2016 Mar;333:37-48. doi: 10.1016/j.heares.2015.12.018. Epub 2015 Dec 
21.

Somatic memory and gain increase as preconditions for tinnitus: Insights from 
congenital deafness.

Eggermont JJ(1), Kral A(2).

Author information:
(1)Departments of Psychology, Physiology and Pharmacology, University of 
Calgary, Calgary, Alberta, Canada. Electronic address: eggermon@ucalgary.ca.
(2)Cluster of Excellence Hearing4all, Institute of AudioNeuroTechnology and 
Dept. of Experimental Otology of the ENT Clinics, Hannover Medical School, 
Germany.

Tinnitus is the conscious perception of sound heard in the absence of physical 
sound sources internal or external to the body. The characterization of tinnitus 
by its spectrum reflects the missing frequencies originally represented in the 
hearing loss, i.e., partially or completely deafferented, region. The tinnitus 
percept, despite a total hearing loss, may thus be dependent on the persisting 
existence of a somatic memory for the "lost" frequencies. Somatic memory in this 
context is the reference for phantom sensations attributed to missing sensory 
surfaces or parts thereof. This raises the question whether tinnitus can exist 
in congenital deafness, were somatic representations have not been formed. We 
review the development of tonotopic maps in altricial and precocial animals 
evidence for a lack of tinnitus in congenital deafness and the effects of 
cochlear implants on the formation of tonotopic maps in the congenitally deaf. 
The latter relates to the emergence of tinnitus in these subjects. The reviewed 
material is consistent with the hypothesis that tinnitus requires an established 
and actively used somatotopic map that leads to a corresponding somatic memory. 
The absence of such experience explains the absence of tinnitus in congenital 
bilateral and unilateral deafness.

Copyright © 2015 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.12.018
PMID: 26719143 [Indexed for MEDLINE]


522. J Comput Neurosci. 2011 Nov;31(3):509-32. doi: 10.1007/s10827-011-0318-z. Epub 
2011 Mar 15.

A reafferent and feed-forward model of song syntax generation in the Bengalese 
finch.

Hanuschkin A(1), Diesmann M, Morrison A.

Author information:
(1)Functional Neural Circuits Group, Faculty of Biology, Albert-Ludwig 
University of Freiburg, Schänzlestrasse 1, 79104 Freiburg, Germany. 
hanuschkin@bccn.uni-freiburg.de

Adult Bengalese finches generate a variable song that obeys a distinct and 
individual syntax. The syntax is gradually lost over a period of days after 
deafening and is recovered when hearing is restored. We present a spiking 
neuronal network model of the song syntax generation and its loss, based on the 
assumption that the syntax is stored in reafferent connections from the auditory 
to the motor control area. Propagating synfire activity in the HVC codes for 
individual syllables of the song and priming signals from the auditory network 
reduce the competition between syllables to allow only those transitions that 
are permitted by the syntax. Both imprinting of song syntax within HVC and the 
interaction of the reafferent signal with an efference copy of the motor command 
are sufficient to explain the gradual loss of syntax in the absence of auditory 
feedback. The model also reproduces for the first time experimental findings on 
the influence of altered auditory feedback on the song syntax generation, and 
predicts song- and species-specific low frequency components in the LFP. This 
study illustrates how sequential compositionality following a defined syntax can 
be realized in networks of spiking neurons.

DOI: 10.1007/s10827-011-0318-z
PMCID: PMC3232349
PMID: 21404048 [Indexed for MEDLINE]


523. Annu Int Conf IEEE Eng Med Biol Soc. 2009;2009:2078-81. doi: 
10.1109/IEMBS.2009.5333956.

On the cognitive neurodynamics of listening effort: a phase clustering analysis 
of large-scale neural correlates.

Strauss DJ(1), Corona-Strauss FI, Bernarding C, Reith W, Latzel M, Froehlich M.

Author information:
(1)Computational Diagnostics & Biocybernetics Unit, Saarland University Hospital 
and Saarland University of Applied Sciences, Homburg/Saar, Germany. 
strauss@cdb-unit.de

An increased listening effort represents a major problem in humans with hearing 
impairment. Neurodiagnostic methods for an objective listening effort estimation 
could revolutionize auditory rehabilitation. However the cognitive neurodynamics 
of listening effort is not understood and research related its neural correlates 
is still in its infancy. In this paper we present a phase clustering analysis of 
large-scale listening effort correlates in auditory late responses (ALRs). For 
this we apply the complex wavelet transform as well as tight Gabor Frame (TGF) 
operators. We show (a) that phase clustering on the unit circle can separate ALR 
data from auditory paradigms which require a graduated effort for their 
solution; (b) the application of TGFs for an inverse artificial phase 
stabilization at the alpha/theta-border enlarges the endogenously driven 
listening effort correlates in the reconstructed time- domain waveforms. It is 
concluded that listening effort correlates can be extracted from ALR sequences 
using an instantaneous phase clustering analysis, at least by means of the 
applied experimental pure tone paradigm.

DOI: 10.1109/IEMBS.2009.5333956
PMID: 19964575 [Indexed for MEDLINE]


524. Lancet. 1996 Oct 26;348(9035):1128-33. doi: 10.1016/S0140-6736(96)09388-9.

Randomised controlled trial of treatment of chronic suppurative otitis media in 
Kenyan schoolchildren.

Smith AW(1), Hatcher J, Mackenzie IJ, Thompson S, Bal I, Macharia I, Mugwe P, 
Okoth-Olende C, Oburra H, Wanjohi Z.

Author information:
(1)Hearing Impairment Research Group, Liverpool School of Tropical Medicine, UK.

Comment in
    Lancet. 1996 Oct 26;348(9035):1113-4.

BACKGROUND: The outcomes of treatment of chronic suppurative otitis media (CSOM) 
are disappointing and uncertain, especially in developing countries. Because 
CSOM is the commonest cause of hearing impairment in children in these 
countries, an effective method of management that can be implemented on a wide 
scale is needed. We report a randomised, controlled trial of treatment of CSOM 
among children in Kenya; unaffected schoolchildren were taught to administer the 
interventions.
METHODS: We enrolled 524 children with CSOM, aged 5-15 years, from 145 primary 
schools in Kiambu district of Kenya. The schools were randomly assigned 
treatments in clusters of five in a ratio of two to dry mopping alone (201 
children), two to dry mopping with topical and systemic antibiotics and topical 
steroids (221 children), and one to no specific treatment (102 children). 
Schools were matched on factors thought to be related to their socioeconomic 
status. The primary outcome measures were resolution of otorrhoea and healing of 
tympanic membranes on otoscopy by 8, 12, and 16 weeks after induction. Absence 
of perforation was confirmed by tympanometry, and hearing levels were assessed 
by audiometry. 29 children were withdrawn from the trial because they took 
non-trial antibiotics. There was no evidence of differences in timing of 
withdrawals between the groups.
FINDINGS: By the 16-week follow-up visit, otorrhoea had resolved in a weighted 
mean proportion of 51% (95% CI 42-59) of children who received dry mopping with 
antibiotics, compared with 22% (14-31) of those who received dry mopping alone 
and 22% (9-35) of controls. Similar differences were recorded by the 8-week and 
12-week visits. The weighted mean proportions of children with healing of the 
tympanic membranes by 16 weeks were 15% (10-21) in the dry-mopping plus 
antibiotics group, 13% (5-20) in the dry-mopping alone group, and 13% (3-23) in 
the control group. The proportion with resolution in the dry-mopping alone group 
did not differ significantly from that in the control group at any time. Hearing 
thresholds were significantly better for children with no otorrhoea at 16 weeks 
than for those who had otorrhoea, and were also significantly better for those 
whose ears had healed than for those with otorrhoea at all times.
INTERPRETATION: Our finding that dry mopping plus topical and systemic 
antibiotics is superior to dry mopping alone contrasts with that of the only 
previous community-based trial in a developing country, though it accords with 
findings of most other trials in developed countries. The potential role of 
antibiotics needs further investigation. Further, similar trials are needed to 
identify the most cost-effective and appropriate treatment regimen for CSOM in 
children in developing countries.

PIP: 524 children aged 5-15 years with chronic suppurative otitis media (CSOM) 
were enrolled in a study to determine the effectiveness of different treatment 
regimens. The subjects were from 145 primary schools in Kenya's Kiambu district. 
201 children received dry mopping treatment, 221 received dry mopping with 
topical and systemic antibiotics and topical steroids, and 102 received no 
treatment. Participating schools were matched on factors thought to be related 
to their socioeconomic status. 29 children were withdrawn from the trial for 
taking non-trial antibiotics, with no evidence observed of differences in the 
timing of withdrawals between the two groups. At 16 weeks of follow-up, 
otorrhoea had resolved in a weighted mean proportion of 51% of children who 
received dry mopping with antibiotics, 22% of children who received dry mopping 
alone, and 22% of untreated children. Similar differences were observed at 8 and 
12 weeks of follow-up. The weighted mean proportions of children with healing of 
the tympanic membranes by 16 weeks were 15% in the dry-mopping plus antibiotics 
group, 13% in the dry-mopping alone group, and 13% in the control group. Hearing 
thresholds were significantly better for children with no otorrhoea at 16 weeks 
than for those who had otorrhoea, and were also significantly better for those 
whose ears had healed than for those with otorrhoea at all times.

DOI: 10.1016/S0140-6736(96)09388-9
PMID: 8888166 [Indexed for MEDLINE]


525. Exp Brain Res. 2018 Apr;236(4):1161-1179. doi: 10.1007/s00221-018-5206-6. Epub 
2018 Feb 16.

Does hearing aid use affect audiovisual integration in mild hearing impairment?

Gieseler A(1)(2), Tahden MAS(3)(4), Thiel CM(3)(5), Colonius H(3)(4).

Author information:
(1)Cluster of Excellence 'Hearing4all', University of Oldenburg, Oldenburg, 
Germany. anja.gieseler@uni-oldenburg.de.
(2)Cognitive Psychology Lab, Department of Psychology, University of Oldenburg, 
Oldenburg, Germany. anja.gieseler@uni-oldenburg.de.
(3)Cluster of Excellence 'Hearing4all', University of Oldenburg, Oldenburg, 
Germany.
(4)Cognitive Psychology Lab, Department of Psychology, University of Oldenburg, 
Oldenburg, Germany.
(5)Biological Psychology Lab, Department of Psychology, University of Oldenburg, 
Oldenburg, Germany.

There is converging evidence for altered audiovisual integration abilities in 
hearing-impaired individuals and those with profound hearing loss who are 
provided with cochlear implants, compared to normal-hearing adults. Still, 
little is known on the effects of hearing aid use on audiovisual integration in 
mild hearing loss, although this constitutes one of the most prevalent 
conditions in the elderly and, yet, often remains untreated in its early stages. 
This study investigated differences in the strength of audiovisual integration 
between elderly hearing aid users and those with the same degree of mild hearing 
loss who were not using hearing aids, the non-users, by measuring their 
susceptibility to the sound-induced flash illusion. We also explored the 
corresponding window of integration by varying the stimulus onset asynchronies. 
To examine general group differences that are not attributable to specific 
hearing aid settings but rather reflect overall changes associated with habitual 
hearing aid use, the group of hearing aid users was tested unaided while 
individually controlling for audibility. We found greater audiovisual 
integration together with a wider window of integration in hearing aid users 
compared to their age-matched untreated peers. Signal detection analyses 
indicate that a change in perceptual sensitivity as well as in bias may underlie 
the observed effects. Our results and comparisons with other studies in 
normal-hearing older adults suggest that both mild hearing impairment and 
hearing aid use seem to affect audiovisual integration, possibly in the sense 
that hearing aid use may reverse the effects of hearing loss on audiovisual 
integration. We suggest that these findings may be particularly important for 
auditory rehabilitation and call for a longitudinal study.

DOI: 10.1007/s00221-018-5206-6
PMID: 29453491 [Indexed for MEDLINE]


526. Lab Anim. 2023 Dec;57(6):631-641. doi: 10.1177/00236772231167679. Epub 2023 Apr 
18.

Refinement of systemic guinea pig deafening in hearing research: Sensorineural 
hearing loss induced by co-administration of kanamycin and furosemide via the 
leg veins.

Behrends W(1)(2), Ahrens D(3), Bankstahl JP(3), Esser KH(2), Paasche G(1)(4), 
Lenarz T(1)(4), Scheper V(1)(4).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Auditory Neuroethology and Neurobiology, Institute of Zoology, University of 
Veterinary Medicine Hannover Foundation, Germany.
(3)Department of Nuclear Medicine, Hannover Medical School, Germany.
(4)Hearing4all Cluster of Excellence, Hannover Medical School, Germany.

Auditory disabilities have a large impact on the human population worldwide. 
Research into understanding and treating hearing disabilities has increased 
significantly in recent years. One of the most relevant animal species in this 
context is the guinea pig, which has to be deafened to study several of the 
hearing pathologies and develop novel therapies. Applying kanamycin 
subcutaneously and furosemide intravenously is a long-established method in 
hearing research, leading to permanent hearing loss without surgical 
intervention at the ear. The intravenous application of furosemide requires 
invasive surgery in the cervical area of the animals to expose the jugular vein, 
since a relatively large volume (1 ml per 500 g body weight) must be injected 
over a period of about 2.5 min. We have established a gentler alternative by 
applying the furosemide by puncture of the leg veins. For this, custom-made 
cannula-needle devices were built to allow the vein puncture and subsequent slow 
injection of the furosemide. This approach was tested in 11 guinea pigs through 
the foreleg via the cephalic antebrachial vein and through the hind leg via the 
saphenous vein. Frequency-specific hearing thresholds were measured before and 
after the procedure to verify normal hearing and successful deafening, 
respectively. The novel approach of systemic deafening was successfully 
implemented in 10 out of 11 animals. The Vena saphena was best suited to the 
application. Since the animals' condition, post leg vein application, was better 
in comparison to animals deafened by exposure of the Vena jugularis, the 
postulated refinement that reduced animal stress was deemed successful.

DOI: 10.1177/00236772231167679
PMID: 37070340 [Indexed for MEDLINE]


527. J Med Syst. 2018 Jun 2;42(7):127. doi: 10.1007/s10916-018-0978-6.

Development of Improved Software Intelligent System for Audiological Solutions.

Rajkumar S(1), Muttan S(2), Sapthagirivasan V(3)(4), Jaya V(5), Vignesh SS(5).

Author information:
(1)Department of Biomedical Engineering, Rajalakshmi Engineering College, 
Chennai, Tamil Nadu, 602117, India. rajkumar.s@rajalakshmi.edu.in.
(2)Department of Electronics and Communication Engineering, College of 
Engineering, Guindy, Anna University, Chennai, Tamil Nadu, 600025, India.
(3)SRM University, Kancheepuram, Tamil Nadu, 603203, India.
(4)Medical Solution's Group, Product and Engineering Services Department, IT 
Service Company, Bengaluru, Karnataka, 560066, India.
(5)Department of Ear, Nose & Throat, Madras Medical College & Rajiv Gandhi 
Government Hospital, Chennai, Tamil Nadu, 600003, India.

Of late, there has been an increase in hearing impairment cases and to provide 
the most advantageous solutions to them is an uphill task for audiologists. 
Significant difficulty faced by the audiologists is in effective programming of 
hearing aids to provide enhanced satisfaction to the users. The main aim of our 
study was to develop a software intelligent system (SIS): (i) to perform the 
required audiological investigations for finding the degree and type of hearing 
loss, and (ii) to suggest appropriate values of hearing aid parameters for 
enhancing the speech intelligibility and the satisfaction level among the 
hearing aid users. In this paper, we present a Neuro-Fuzzy based SIS to 
automatically predict and suggest the hearing-aid parameters such as gain 
values, compression ratio and threshold knee point, which are needed to be fixed 
for different octave frequencies of sound inputs during the hearing-aid trial. 
The test signals for audiological investigations are generated through the 
standard hardware present in a personal computer system and with the aid of a 
software algorithm. The proposed system was validated with 243 subjects' data 
collected at the Government General Hospital, Chennai, India. The calculated 
sensitivity, specificity and accuracy of the proposed audiometer incorporated in 
the SIS were 98.6%, 96.4 and 98.2%, respectively, by comparing its 
interpretations with those of the 'gold standard' audiometers. Furthermore, 91% 
(221 of 243) of the hearing impaired subjects attained satisfaction in the first 
hearing aid trials itself with the gain values as recommended by the improved 
SIS. The proposed system reduced around 75% of the 'trial and error' time spent 
by audiologists for enhancing satisfactory usage of the hearing aid. Hence, the 
proposed SIS could be used to find the degree and type of hearing loss and to 
recommend hearing aid parameters to provide optimal solutions to the hearing aid 
users.

DOI: 10.1007/s10916-018-0978-6
PMID: 29860544 [Indexed for MEDLINE]


528. Eur J Neurosci. 2014 Mar;39(5):811-20. doi: 10.1111/ejn.12445. Epub 2013 Dec 10.

Effects of chronic cochlear electrical stimulation after an extended period of 
profound deafness on primary auditory cortex organization in cats.

Fallon JB(1), Shepherd RK, Irvine DR.

Author information:
(1)Bionics Institute, 384-388 Albert Street, East Melbourne, Vic., 3002, 
Australia; Department of Otolaryngology, University of Melbourne, Melbourne, 
Vic., Australia; Medical Bionics Department, University of Melbourne, Melbourne, 
Vic., Australia.

Extended periods of deafness have profound effects on central auditory system 
function and organization. Neonatal deafening results in loss of the normal 
cochleotopic organization of the primary auditory cortex (AI), but 
environmentally-derived intracochlear electrical stimulation, via a cochlear 
implant, initiated shortly after deafening, can prevent this loss. We 
investigated whether such stimulation initiated after an extended period of 
deafness can restore cochleotopy. In two groups of neonatally-deafened cats, a 
multi-channel intracochlear electrode array was implanted at 8 weeks of age. One 
group received only minimal stimulation, associated with brief recordings at 
4-6-week intervals, over the following 6 months to check the efficacy of the 
implant. In the other group, this 6-month period was followed by 6 months of 
near-continuous intracochlear electrical stimulation from a modified clinical 
cochlear implant system. We recorded multi-unit clusters in the auditory cortex 
and used two different methods to define the region of interest in the putative 
AI. There was no evidence of cochleotopy in any of the minimally stimulated 
animals, confirming our earlier finding. In three of six chronically stimulated 
cats there was clear evidence of AI cochleotopy, and in a fourth cat in which 
the majority of penetrations were in the anterior auditory field there was clear 
evidence of cochleotopy in that field. The finding that chronic intracochlear 
electrical stimulation after an extended period of deafness is able to restore 
cochleotopy in some (but not all) cases has implications for the performance of 
patients implanted after an extended period of deafness.

© 2013 Federation of European Neuroscience Societies and John Wiley & Sons Ltd.

DOI: 10.1111/ejn.12445
PMID: 24325274 [Indexed for MEDLINE]


529. J Neurosci. 2019 Jun 5;39(23):4434-4447. doi: 10.1523/JNEUROSCI.2228-18.2019. 
Epub 2019 Mar 29.

Vesicular Glutamatergic Transmission in Noise-Induced Loss and Repair of 
Cochlear Ribbon Synapses.

Kim KX(1), Payne S(1), Yang-Hood A(1), Li SZ(1), Davis B(1)(2), Carlquist J(1), 
V-Ghaffari B(1), Gantz JA(1), Kallogjeri D(1), Fitzpatrick JAJ(3), Ohlemiller 
KK(1), Hirose K(1), Rutherford MA(4).

Author information:
(1)Department of Otolaryngology, Washington University School of Medicine.
(2)Program in Audiology and Communication Sciences, Washington University School 
of Medicine, St. Louis, Missouri 63110, and.
(3)Washington University Center for Cellular Imaging, Department of 
Neuroscience, Department of Cell Biology and Physiology, Department of 
Biomedical Engineering, Washington University School of Medicine, St. Louis, 
Missouri 63110.
(4)Department of Otolaryngology, Washington University School of Medicine, 
RutherfordM@ent.wustl.edu.

Noise-induced excitotoxicity is thought to depend on glutamate. However, the 
excitotoxic mechanisms are unknown, and the necessity of glutamate for synapse 
loss or regeneration is unclear. Despite absence of glutamatergic transmission 
from cochlear inner hair cells in mice lacking the vesicular glutamate 
transporter-3 (Vglut3KO ), at 9-11 weeks, approximately half the number of 
synapses found in Vglut3WT were maintained as postsynaptic AMPA receptors 
juxtaposed with presynaptic ribbons and voltage-gated calcium channels (CaV1.3). 
Synapses were larger in Vglut3KO than Vglut3WT In Vglut3WT and Vglut3+/- mice, 
8-16 kHz octave-band noise exposure at 100 dB sound pressure level caused a 
threshold shift (∼40 dB) and a loss of synapses (>50%) at 24 h after exposure. 
Hearing threshold and synapse number partially recovered by 2 weeks after 
exposure as ribbons became larger, whereas recovery was significantly better in 
Vglut3WT Noise exposure at 94 dB sound pressure level caused auditory threshold 
shifts that fully recovered in 2 weeks, whereas suprathreshold hearing recovered 
faster in Vglut3WT than Vglut3+/- These results, from mice of both sexes, 
suggest that spontaneous repair of synapses after noise depends on the level of 
Vglut3 protein or the level of glutamate release during the recovery period. 
Noise-induced loss of presynaptic ribbons or postsynaptic AMPA receptors was not 
observed in Vglut3KO , demonstrating its dependence on vesicular glutamate 
release. In Vglut3WT and Vglut3+/-, noise exposure caused unpairing of 
presynaptic ribbons and presynaptic CaV1.3, but not in Vglut3KO where CaV1.3 
remained clustered with ribbons at presynaptic active zones. These results 
suggest that, without glutamate release, noise-induced presynaptic Ca2+ influx 
was insufficient to disassemble the active zone. However, synapse volume 
increased by 2 weeks after exposure in Vglut3KO , suggesting 
glutamate-independent mechanisms.SIGNIFICANCE STATEMENT Hearing depends on 
glutamatergic transmission mediated by Vglut3, but the role of glutamate in 
synapse loss and repair is unclear. Here, using mice of both sexes, we show that 
one copy of the Vglut3 gene is sufficient for noise-induced threshold shift and 
loss of ribbon synapses, but both copies are required for normal recovery of 
hearing function and ribbon synapse number. Impairment of the recovery process 
in mice having only one functional copy suggests that glutamate release may 
promote synapse regeneration. At least one copy of the Vglut3 gene is necessary 
for noise-induced synapse loss. Although the excitotoxic mechanism remains 
unknown, these findings are consistent with the presumption that glutamate is 
the key mediator of noise-induced synaptopathy.

Copyright © 2019 the authors.

DOI: 10.1523/JNEUROSCI.2228-18.2019
PMCID: PMC6554621
PMID: 30926748 [Indexed for MEDLINE]


530. Am J Audiol. 2020 Sep 3;29(3):460-475. doi: 10.1044/2020_AJA-20-00025. Epub 2020 
Jul 21.

Common Configurations of Real-Ear Aided Response Targets Prescribed by NAL-NL2 
for Older Adults With Mild-to-Moderate Hearing Loss.

Jensen J(1), Vyas D(2), Urbanski D(1), Garudadri H(3), Chipara O(2), Wu YH(1).

Author information:
(1)Department of Communication Sciences and Disorders, The University of Iowa, 
Iowa City.
(2)Department of Computer Science, The University of Iowa, Iowa City.
(3)Qualcomm Institute, University of California San Diego.

Purpose This study investigates common real-ear aided response (REAR) 
configurations prescribed by the NAL-NL2 algorithm for older adults with hearing 
loss. Method A data set that is representative of the older adult U.S. 
population with mild-to-moderate sensorineural hearing loss was constructed from 
the audiometric data of 934 adults (aged 55-85 years) from the National Health 
and Nutrition Examination Survey years 1999-2012. Two clustering approaches were 
implemented to generate common REAR configurations for eight frequencies (0.25, 
0.5, 1, 2, 3, 4, 6, and 8 kHz) at three input levels (55, 65, and 75 dB SPL). 
(a) In the REAR-based clustering approach, the National Health and Nutrition 
Examination Survey audiograms were first converted to REAR targets and then 
clustered to generate common REAR configurations. (b) In the audiogram-based 
clustering approach, the audiograms were first clustered into common hearing 
loss profiles and then converted to REAR configurations. The trade-off between 
the number of available REAR configurations and the percentage of the U.S. 
population whose hearing loss could be fit by at least one of them (i.e., 
percent coverage) was evaluated. Hearing loss fit was defined as less than ± 
5-dB difference between an individual's REAR targets and those of the clustered 
REAR configuration. Results Percent coverage increases with the number of 
available REAR configurations, with four configurations resulting in 75% 
population coverage. Overall, REAR-based clustering yielded 5 percentage points 
better coverage on average compared to audiogram-based clustering. Conclusions 
The common REAR configurations can be used for programming the gain frequency 
responses in preconfigured over-the-counter hearing aids and provide clinically 
appropriate amplification settings for older adults with mild-to-moderate 
hearing loss.

DOI: 10.1044/2020_AJA-20-00025
PMCID: PMC7842845
PMID: 32693613 [Indexed for MEDLINE]


531. Trends Hear. 2021 Jan-Dec;25:23312165211051215. doi: 10.1177/23312165211051215.

Functional Consequences of Poor Binaural Hearing in Development: Evidence From 
Children With Unilateral Hearing Loss and Children Receiving Bilateral Cochlear 
Implants.

McSweeny C(1), Cushing SL(1)(2)(3), Campos JL(4)(5), Papsin BC(1)(2)(3), Gordon 
KA(1)(2).

Author information:
(1)Archie's Cochlear Implant Lab, 7979Hospital for Sick Children, Toronto, 
Ontario, Canada.
(2)Department of Otolaryngology, Head & Neck Surgery, Faculty of Medicine, 
University of Toronto, Ontario, Canada.
(3)Department of Otolaryngology, Head & Neck Surgery, 7979Hospital for Sick 
Children, Toronto, Ontario, Canada.
(4)KITE-Toronto Rehabilitation Institute, Toronto, Ontario, Canada.
(5)Department of Psychology, University of Toronto, Toronto, Ontario, Canada.

Poor binaural hearing in children was hypothesized to contribute to related 
cognitive and academic deficits. Children with unilateral hearing have normal 
hearing in one ear but no access to binaural cues. Their cognitive and academic 
deficits could be unique from children receiving bilateral cochlear implants 
(CIs) at young ages who have poor access to spectral cues and impaired binaural 
sensitivity. Both groups are at risk for vestibular/balance deficits which could 
further contribute to memory and learning challenges. Eighty-eight children (43 
male:45 female, aged 9.89  ±  3.40 years), grouped by unilateral hearing loss 
(n = 20), bilateral CI (n = 32), and typically developing (n = 36), completed a 
battery of sensory, cognitive, and academic tests. Analyses revealed that 
children in both hearing loss groups had significantly poorer skills (accounting 
for age) on most tests than their normal hearing peers. Children with unilateral 
hearing loss had more asymmetric speech perception than children with bilateral 
CIs (p < .0001) but balance and language deficits (p = .0004, p < .0001, 
respectively) were similar in the two hearing loss groups (p > .05). 
Visuospatial memory deficits occurred in both hearing loss groups (p = .02) but 
more consistently across tests in children with unilateral hearing loss. Verbal 
memory was not significantly different than normal (p > .05). Principal 
component analyses revealed deficits in a main cluster of visuospatial memory, 
oral language, mathematics, and reading measures (explaining 46.8% data 
variability). The remaining components revealed clusters of self-reported 
hearing, balance and vestibular function, and speech perception deficits. The 
findings indicate significant developmental impacts of poor binaural hearing in 
children.

DOI: 10.1177/23312165211051215
PMCID: PMC8527588
PMID: 34661482 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared the following potential conflicts of interest with respect to 
the research, authorship, and/or publication of this article: KG: speaker for 
Cochlear Corp, Advanced Bionics, lecturer: Salus University. SLC holds sponsored 
research agreements with Cochlear Americas, is a speaker for Cochlear Americas 
and Interacoustics, earns royalties from the book, Balance Disorders in the 
Pediatric Population, Plural Publishing and is a patent holders for Patents #: 
7041–0: Systems and Methods for Balance Stabilization..


532. J Acoust Soc Am. 2013 May;133(5):2818-33. doi: 10.1121/1.4795783.

On the balance of envelope and temporal fine structure in the encoding of speech 
in the early auditory system.

Shamma S(1), Lorenzi C.

Author information:
(1)Electrical and Computer Engineering Department and Institute for Systems 
Research, University of Maryland, College Park, Maryland 20742, USA. sas@umd.edu

There is much debate on how the spectrotemporal modulations of speech (or its 
spectrogram) are encoded in the responses of the auditory nerve, and whether 
speech intelligibility is best conveyed via the "envelope" (E) or "temporal 
fine-structure" (TFS) of the neural responses. Wide use of vocoders to resolve 
this question has commonly assumed that manipulating the amplitude-modulation 
and frequency-modulation components of the vocoded signal alters the relative 
importance of E or TFS encoding on the nerve, thus facilitating assessment of 
their relative importance to intelligibility. Here we argue that this assumption 
is incorrect, and that the vocoder approach is ineffective in differentially 
altering the neural E and TFS. In fact, we demonstrate using a simplified model 
of early auditory processing that both neural E and TFS encode the speech 
spectrogram with constant and comparable relative effectiveness regardless of 
the vocoder manipulations. However, we also show that neural TFS cues are less 
vulnerable than their E counterparts under severe noisy conditions, and hence 
should play a more prominent role in cochlear stimulation strategies.

DOI: 10.1121/1.4795783
PMCID: PMC3663870
PMID: 23654388 [Indexed for MEDLINE]


533. Sci Rep. 2021 Jan 26;11(1):2243. doi: 10.1038/s41598-021-81728-0.

The impact of tinnitus distress on cognition.

Neff P(1)(2), Simões J(1), Psatha S(3), Nyamaa A(3), Boecking B(3), Rausch L(3), 
Dettling-Papargyris J(4), Funk C(4), Brueggemann P(3), Mazurek B(5).

Author information:
(1)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany.
(2)University Research Priority Program 'Dynamics of Healthy Aging', University 
of Zürich, Zürich, Switzerland.
(3)Tinnitus-Zentrum, Charité - Universitätsmedizin, Berlin, Germany.
(4)Terzo Institute, ISMA AG, Sonneberg, Germany.
(5)Tinnitus-Zentrum, Charité - Universitätsmedizin, Berlin, Germany. 
birgit.mazurek@charite.de.

Tinnitus is the chronic perception of a phantom sound with different levels of 
related distress. Past research has elucidated interactions of tinnitus distress 
with audiological, affective and further clinical variables. The influence of 
tinnitus distress on cognition is underinvestigated. Our study aims at 
investigating specific influences of tinnitus distress and further associated 
predictors on cognition in a cohort of n = 146 out-ward clinical tinnitus 
patients. Age, educational level, hearing loss, Tinnitus Questionnaire (TQ) 
score, tinnitus duration, speech in noise (SIN), stress, anxiety and depression, 
and psychological well-being were included as predictors of a machine learning 
regression approach (elastic net) in three models with scores of a multiple 
choice vocabulary test (MWT-B), or two trail-making tests (TMT-A and TMT-B), as 
dependent variables. TQ scores predicted lower MWT-B scores and higher TMT-B 
test completion time. Stress, emotional, and psychological variables were not 
found to be relevant predictors in all models with the exception of small 
positive influences of SIN and depression on TMT-B. Effect sizes were small to 
medium for all models and predictors. Results are indicative of specific 
influence of tinnitus distress on cognitive performance, especially on general 
or crystallized intelligence and executive functions. More research is needed at 
the delicate intersection of tinnitus distress and cognitive skills needed in 
daily functioning.

DOI: 10.1038/s41598-021-81728-0
PMCID: PMC7838303
PMID: 33500489 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


534. Am J Hum Genet. 1990 Jul;47(1):20-7.

Genetic mapping of X-linked albinism-deafness syndrome (ADFN) to Xq26.3-q27.I.

Shiloh Y(1), Litvak G, Ziv Y, Lehner T, Sandkuyl L, Hildesheimer M, Buchris V, 
Cremers FP, Szabo P, White BN, et al.

Author information:
(1)Department of Human Genetics, Sackler School of Medicine, Tel-Aviv 
University, Israel.

X-linked albinism-deafness syndrome (ADFN) was described in one Israeli Jewish 
family and is characterized by congenital nerve deafness and piebaldness. The 
ADFN mutation probably affects the migration of neural crest-derived precursors 
of the melanocytes. As a first step toward identifying the ADFN gene, a linkage 
study was performed to localize the disease locus on the X chromosome. The 
family was found to be informative for 11 of 107 RFLPs along the X, and 
two-point analysis showed four of them--factor 9 (F9), DXS91, DXS37, and 
DNF1--to have definite or suggestive linkage with ADFN. Multipoint linkage 
analysis indicated two possible orders within this cluster of loci, neither of 
which was preferable. In both orders F9 was the most distal, and the best 
estimate for the location of ADFN was between F9 and the next proximal marker 
(8.6 cM from F9 [Z = 8.1] or 8.3 cM from F9 [Z = 7.9]). These results suggest 
that the ADFN is at Xq26.3-q27.1. Disagreement between our data and previous 
localization of DXS91 at Xq11-q13 was resolved by hybridization of the probe 
pXG-17, which detects the DXS91 locus, to a panel of somatic cell hybrids 
containing different portions of the X chromosome. This experiment showed that 
this locus is definitely at Xq24-q26. Together with the linkage data, our 
results place DXS91 at Xq26 and underscore the importance of using more than one 
mapping method for the localization of molecular probes.

PMCID: PMC1683749
PMID: 2349949 [Indexed for MEDLINE]


535. Hear Res. 2017 Feb;344:135-147. doi: 10.1016/j.heares.2016.11.005. Epub 2016 Nov 
12.

An integrated model of pitch perception incorporating place and temporal pitch 
codes with application to cochlear implant research.

Erfanian Saeedi N(1), Blamey PJ(2), Burkitt AN(3), Grayden DB(4).

Author information:
(1)NeuroEngineering Laboratory, Dept. of Electrical & Electronic Engineering, 
University of Melbourne, Australia; Centre for Neural Engineering, University of 
Melbourne, Australia. Electronic address: 
n.erfaniansaeedi@student.unimelb.edu.au.
(2)The Bionics Institute, East Melbourne, Australia; Dept. of Medical Bionics, 
University of Melbourne, Australia.
(3)NeuroEngineering Laboratory, Dept. of Electrical & Electronic Engineering, 
University of Melbourne, Australia; The Bionics Institute, East Melbourne, 
Australia.
(4)NeuroEngineering Laboratory, Dept. of Electrical & Electronic Engineering, 
University of Melbourne, Australia; Centre for Neural Engineering, University of 
Melbourne, Australia; The Bionics Institute, East Melbourne, Australia.

Although the neural mechanisms underlying pitch perception are not yet fully 
understood, there is general agreement that place and temporal representations 
of pitch are both used by the auditory system. This paper describes a neural 
network model of pitch perception that integrates both codes of pitch and 
explores the contributions of, and the interactions between, the two 
representations in simulated pitch ranking trials in normal and cochlear implant 
hearing. The model can replicate various psychophysical observations including 
the perception of the missing fundamental pitch and sensitivity to pitch 
interval sizes. As a case study, the model was used to investigate the 
efficiency of pitch perception cues in a novel sound processing scheme, 
Stimulation based on Auditory Modelling (SAM), that aims to improve pitch 
perception in cochlear implant hearing. Results showed that enhancement of the 
pitch perception cues would lead to better pitch ranking scores in the 
integrated model only if the place and temporal pitch cues were consistent.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2016.11.005
PMID: 27845260 [Indexed for MEDLINE]


536. Sci Rep. 2020 Feb 4;10(1):1797. doi: 10.1038/s41598-020-58512-7.

A Precision Driver Device for Intraoperative Stimulation of a Bone Conduction 
Implant.

Ghoncheh M(1)(2), Lenarz T(3)(4), Maier H(3)(4).

Author information:
(1)Cluster of Excellence Hearing4all, Hannover, Germany. 
Ghoncheh.Mohammad@MH-Hannover.de.
(2)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany. Ghoncheh.Mohammad@MH-Hannover.de.
(3)Cluster of Excellence Hearing4all, Hannover, Germany.
(4)Department of Otolaryngology and Institute of Audioneurotechnology (VIANNA), 
Hannover Medical School, Hannover, Germany.

Semi-implantable bone conduction implants (BCI) and active middle ear implants 
(AMEI) for patients with sensorineural, conductive or mixed hearing loss 
commonly use an amplitude modulation technology to transmit power and sound 
signals from an external audio processor to the implant. In patients, the 
distance dependence of the signal amplitude is of minor importance as the skin 
thickness is constant and only varies between 3-7 mm. In this range, critical 
coupling transmission technique sufficiently reduces the variability in 
amplitude, but fails to provide well-defined amplitudes in many research and 
clinical applications such as intraoperative integrity tests where the distance 
range is exceeded by using sterile covers. Here we used the BCI Bonebridge (BB, 
Med-El, Austria) as an example to develop and demonstrate a system that 
synthesizes the transmission signal, determines the distance between the 
transmitter and the receiver implant coil and compensates transmission losses. 
When compared to an external audio processor (AP304) on an artificial mastoid, 
our system mainly decreased amplitude variability from over 11 dB to less than 
3 dB for audio frequencies (0.1-10 kHz) at distances up to 15 mm, making it 
adequate for intraoperative and audiometric tests.

DOI: 10.1038/s41598-020-58512-7
PMCID: PMC7000405
PMID: 32019957 [Indexed for MEDLINE]

Conflict of interest statement: This work is part of the doctoral thesis of MG 
and was supported by the DFG Cluster of Excellence EXC 1077/1 “Hearing4all”. MG 
and HM received travel support to conferences by MED-El and TL declares no 
competing interests.


537. Small. 2022 Apr;18(13):e2106960. doi: 10.1002/smll.202106960. Epub 2022 Feb 5.

Ultrathin Eardrum-Inspired Self-Powered Acoustic Sensor for Vocal 
Synchronization Recognition with the Assistance of Machine Learning.

Jiang Y(1)(2), Zhang Y(1)(2), Ning C(1)(2), Ji Q(3), Peng X(1)(2), Dong K(1)(2), 
Wang ZL(1)(2)(4)(5).

Author information:
(1)Beijing Institute of Nanoenergy and Nanosystems, Chinese Academy of Sciences, 
Beijing, 101400, P. R. China.
(2)School of Nanoscience and Technology, University of Chinese Academy of 
Sciences, Beijing, 100049, P. R. China.
(3)Institute of Computing Technology, Chinese Academy of Sciences, University of 
Chinese Academy of Sciences, Beijing, 100049, P. R. China.
(4)CUSTech Institute of Technology, Wenzhou, Zhejiang, 325024, P. R. China.
(5)School of Materials Science and Engineering, Georgia Institute of Technology, 
Atlanta, GA, 30332-0245, USA.

With the rapid development of human-machine interfaces, artificial acoustic 
sensors play an important role in the hearing impaired. Here, an ultrathin 
eardrum-like triboelectric acoustic sensor (ETAS) is presented consisting of 
silver-coated nanofibers, whose thickness is only 40 µm. The sensitivity and 
frequency response range of the ETAS are closely related to the geometric 
parameters. The ETAS endows a high sensitivity of 228.5 mV Pa-1 at 95 dB, and 
the ETAS has a broad frequency response ranging from 20 to 5000 Hz, which can be 
tuned by adjusting the thickness, size, or shape of the sensor. Cooperating with 
artificial intelligence (AI) algorithms, the ETAS can achieve real-time voice 
conversion with a high identification accuracy of 92.64%. Under good working 
property and the AI system, the ETAS simplifies signal processing and reduces 
the power consumption. This work presents a strategy for self-power auditory 
systems, which can greatly accelerate the miniaturization of self-powered 
systems used in wearable electronics, augmented reality, virtual reality, and 
control hubs for automation.

© 2022 Wiley-VCH GmbH.

DOI: 10.1002/smll.202106960
PMID: 35122473 [Indexed for MEDLINE]


538. Neuroimage. 2023 Sep;278:120285. doi: 10.1016/j.neuroimage.2023.120285. Epub 
2023 Jul 20.

A multidimensional characterization of the neurocognitive architecture 
underlying age-related temporal speech processing.

Elmer S(1), Kurthen I(2), Meyer M(3), Giroud N(4).

Author information:
(1)Department of Computational Linguistics, Computational Neuroscience of Speech 
& Hearing, University of Zurich, Zurich, Switzerland; Competence center Language 
& Medicine, University of Zurich, Switzerland. Electronic address: 
s.elmer@psychologie.uzh.ch.
(2)Department of Computational Linguistics, Computational Neuroscience of Speech 
& Hearing, University of Zurich, Zurich, Switzerland.
(3)Department of Comparative Language Science, University of Zurich, Zurich, 
Switzerland; Center for Neuroscience Zurich, University and ETH of Zurich, 
Zurich, Switzerland; Center for the Interdisciplinary Study of Language 
Evolution (ISLE), University of Zurich, Zurich, Switzerland; Cognitive 
Psychology Unit, Alpen-Adria University, Klagenfurt, Austria.
(4)Department of Computational Linguistics, Computational Neuroscience of Speech 
& Hearing, University of Zurich, Zurich, Switzerland; Center for Neuroscience 
Zurich, University and ETH of Zurich, Zurich, Switzerland; Competence center 
Language & Medicine, University of Zurich, Switzerland.

Healthy aging is often associated with speech comprehension difficulties in 
everyday life situations despite a pure-tone hearing threshold in the normative 
range. Drawing on this background, we used a multidimensional approach to assess 
the functional and structural neural correlates underlying age-related temporal 
speech processing while controlling for pure-tone hearing acuity. Accordingly, 
we combined structural magnetic resonance imaging and electroencephalography, 
and collected behavioral data while younger and older adults completed a 
phonetic categorization and discrimination task with consonant-vowel syllables 
varying along a voice-onset time continuum. The behavioral results confirmed 
age-related temporal speech processing singularities which were reflected in a 
shift of the boundary of the psychometric categorization function, with older 
adults perceiving more syllable characterized by a short voice-onset time as 
/ta/ compared to younger adults. Furthermore, despite the absence of any 
between-group differences in phonetic discrimination abilities, older adults 
demonstrated longer N100/P200 latencies as well as increased P200 amplitudes 
while processing the consonant-vowel syllables varying in voice-onset time. 
Finally, older adults also exhibited a divergent anatomical gray matter 
infrastructure in bilateral auditory-related and frontal brain regions, as 
manifested in reduced cortical thickness and surface area. Notably, in the 
younger adults but not in the older adult cohort, cortical surface area in these 
two gross anatomical clusters correlated with the categorization of 
consonant-vowel syllables characterized by a short voice-onset time, suggesting 
the existence of a critical gray matter threshold that is crucial for consistent 
mapping of phonetic categories varying along the temporal dimension. Taken 
together, our results highlight the multifaceted dimensions of age-related 
temporal speech processing characteristics, and pave the way toward a better 
understanding of the relationships between hearing, speech and the brain in 
older age.

Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2023.120285
PMID: 37481009 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no competing interests.


539. Int J Audiol. 2023 Jun;62(6):552-561. doi: 10.1080/14992027.2022.2078433. Epub 
2022 Jun 19.

Conformities and gaps of clinical audiological data with the international 
classification of functioning disability and health core sets for hearing loss.

Afghah T(1)(2), Schütze J(3), Meis M(1)(2), Kollmeier B(1)(2)(3), Wagener 
KC(1)(2).

Author information:
(1)Hörzentrum Oldenburg gGmbH, Oldenburg, Germany.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany.
(3)Carl von Ossietzky, Universität Oldenburg, Oldenburg, Germany.

OBJECTIVE: The International Classification of Functioning Disability and Health 
(ICF) is a classification of health and health-related domains created by the 
World Health Organization and can be used as a standard to evaluate the health 
and disability of individuals. The ICF Core Set for Hearing Loss (CSHL) refers 
to the ICF categories found to be relative to Hearing Loss (HL) and the 
consequences of it on daily life. This study aimed to adapt the content of a 
database gathered in Hörzentrum Oldenburg gGmbH that included HL medical 
assessments and audiological data to the ICF.
DESIGN: ICF linking rules were applied to these assessment methods including 
medical interviews, ear examinations, pure-tone audiometry, Adaptive Categorical 
Loudness Scaling, and speech intelligibility test.
STUDY SAMPLE: 1316 subjects.
RESULTS: In total, 44% of the brief and 18% of the comprehensive CSHL categories 
were addressed. The hearing functions were broadly evaluated. "Activities and 
Participation" and "Environmental Factors" were poorly examined (17% and 12% of 
the comprehensive CSHL categories, respectively).
CONCLUSIONS: The HL correlation with day-to-day activities limitation, 
performance restriction, and environmental conditions were poorly addressed. 
This study showed the essence of incorporating these methodologies with 
approaches that assess the daily-life challenges caused by HL in rehabilitation.

DOI: 10.1080/14992027.2022.2078433
PMID: 35722856 [Indexed for MEDLINE]


540. Nihon Jibiinkoka Gakkai Kaiho. 1996 Apr;99(4):558-66. doi: 
10.3950/jibiinkoka.99.558.

[A longitudinal study of hearing level aggravation due to aging].

[Article in Japanese]

Ono Y(1).

Author information:
(1)Department of Oto-rhino-laryngology, School of Medicine, Kitasato University, 
Sagamihara.

It has been reported that hearing aggravation due to aging is predominantly in 
the high frequency range and that there are rapid and slow phase of aggravation 
in hearing level. In the present study, the pattern of aggravation of hearing 
level due to aging was investigated in 387 adults of over 35 years of age who 
had visited the Kitasato Health Science Center for a regular health check-up 
annually for more than 5 years, and were diagnosed as having neither external of 
middle ear diseases nor hearing impairment of obvious origin at their first 
visit. The subjects were divided into 8 groups according to their ages in 
increments of 5 years. Their audiograms were obtained annually, and the results 
were used to obtain the distribution of the hearing level at each test 
frequency. All of the subjects were examined for individual changes in 
audiograms and those who showed 20 dB or more aggravation of hearing in a 1-year 
period without subsequent improvement were defined as having a rapid phase of 
aggravation. There were clustering points in hearing distribution at around 30 
dB and 60 dB at the test frequency of 8 kHz in those subjects showing a rapid 
phase of aggravation. Similar clustering points were also noted in those 
subjects who showed gradual aggravation of 20 dB or more in a 5-year period and 
who had 20 dB or more aggravation in one year but showed later improvement. As 
for the test frequencies lower than 4 kHz, there appeared to be a clustering 
point at around 30 dB. The incidence of the rapid phase of aggravation was then 
determined in each group, in order to investigate the relationship between aging 
and the appearance of the rapid phase of aggravation. The rapid phase was 
already noted in the youngest age group (range, 35-39 years), while the 
incidence gradually increased up to the 50-54-year group and stayed at a 
constant level in the 55-69-year groups. The incidence markedly decreased 
thereafter. The results suggest that hearing aggravation due to aging does not 
occur at any particular age. Rather, the hearing aggravation appeared to be 
closely related to the hearing level, and to manifest itself when the hearing 
level approaches 30 dB or 60 dB.

DOI: 10.3950/jibiinkoka.99.558
PMID: 8683366 [Indexed for MEDLINE]


541. Cochlear Implants Int. 2020 Mar;21(2):67-74. doi: 10.1080/14670100.2019.1668617. 
Epub 2019 Sep 25.

Dimensions of artefacts caused by cochlear and auditory brainstem implants in 
magnetic resonance imaging.

Majdani E(1), Majdani O(1)(2), Steffens M(1), Warnecke A(1)(2), 
Lesinski-Schiedat A(1), Lenarz T(1)(2), Götz F(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence of the German Research Foundation (DFG; 'Deutsche 
Forschungsgemeinschaft') 'Hearing4all', Hannover, Germany.
(3)Institute of Neuroradiology, Hannover Medical School, Hannover, Germany.

Background: The aim of the study was to investigate the extent of MRI artefacts 
due to the magnet of selected auditory implants.Study design: Artefacts of the 
Synchrony cochlear implant at 1.5 T as well as at 3 T MRI devices were examined 
in cadavers and compared to the artefacts in MRI scans at 1.5 T of 17 patients 
implanted with CI (n = 12) and auditory brainstem implants (ABI) 
(n = 5).Results: None of the scanned implants showed any failure after MRI. 
After removal of the magnet, only a portion of the images in the direct 
neighbourhood of the implant, especially in the temporal and parietal lobe, 
contained artefacts. More anatomical substructures were visible without 
artefacts using the MedEl Synchrony device.Conclusion: Artefacts can be markedly 
reduced by rotating, self-aligning magnet. Removal of the magnet also results in 
reduction of artefacts.

DOI: 10.1080/14670100.2019.1668617
PMID: 31553273 [Indexed for MEDLINE]


542. Biomed Res Int. 2018 Jun 13;2018:8137614. doi: 10.1155/2018/8137614. eCollection 
2018.

Potential of Gene and Cell Therapy for Inner Ear Hair Cells.

Lee MY(1), Park YH(2)(3).

Author information:
(1)Department of Otorhinolaryngology and Head & Neck Surgery, Dankook University 
Hospital, Cheonan, Chungnam, Republic of Korea.
(2)Department of Otolaryngology-Head and Neck Surgery, College of Medicine, 
Chungnam National University, Daejeon, Republic of Korea.
(3)Brain Research Institute, College of Medicine, Chungnam National University, 
Daejeon, Republic of Korea.

Erratum in
    Biomed Res Int. 2019 Mar 7;2019:9601260.

Sensorineural hearing loss is caused by the loss of sensory hair cells (HCs) or 
a damaged afferent nerve pathway to the auditory cortex. The most common option 
for the treatment of sensorineural hearing loss is hearing rehabilitation using 
hearing devices. Various kinds of hearing devices are available but, despite 
recent advancements, their perceived sound quality does not mimic that of the 
"naïve" cochlea. Damage to crucial cochlear structures is mostly irreversible 
and results in permanent hearing loss. Cochlear HC regeneration has long been an 
important goal in the field of hearing research. However, it remains challenging 
because, thus far, no medical treatment has successfully regenerated cochlear 
HCs. Recent advances in genetic modulation and developmental techniques have led 
to novel approaches to generating HCs or protecting against HC loss, to preserve 
hearing. In this review, we present and review the current status of two 
different approaches to restoring or protecting hearing, gene therapy, including 
the newly introduced CRISPR/Cas9 genome editing, and stem cell therapy, and 
suggest the future direction.

DOI: 10.1155/2018/8137614
PMCID: PMC6020521
PMID: 30009175 [Indexed for MEDLINE]


543. EMBO Mol Med. 2024 Apr;16(4):675-677. doi: 10.1038/s44321-024-00058-6. Epub 2024 
Mar 25.

Gene therapy for deafness: are we there now?

Moser T(1)(2)(3)(4), Chen H(5)(6), Kusch K(5)(6)(7)(8), Behr R(9), Vona 
B(5)(10).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099, Göttingen, Germany. tmoser@gwdg.de.
(2)Auditory Neuroscience and Synaptic Nanophysiology Group, Max-Planck-Institute 
for Multidisciplinary Sciences, Göttingen, Germany. tmoser@gwdg.de.
(3)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany. tmoser@gwdg.de.
(4)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, Göttingen, 
Germany. tmoser@gwdg.de.
(5)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099, Göttingen, Germany.
(6)Auditory Neuroscience and Synaptic Nanophysiology Group, Max-Planck-Institute 
for Multidisciplinary Sciences, Göttingen, Germany.
(7)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(8)Functional Auditory Genomics group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(9)Platform Degenerative Diseases, German Primate Center, Göttingen, Germany.
(10)Institute of Human Genetics, University Medical Center Göttingen, 37099, 
Göttingen, Germany.

Approximately half a billion people—5% of the world’s population—suffer from 
disabling hearing impairment (HI) according to the WHO 
(http://www.who.int/features/factfiles/deafness/en/). HI commonly hampers speech 
acquisition, leads to social isolation and increases risk for depression and 
cognitive decline. One to two per thousand children are born with disabling HI 
and over 50% of sensorineural HI is caused by defects in individual genes 
(deafness genes) of which roughly 150 have been identified so far 
(http://hereditaryhearingloss.org/). In case of profound hearing impairment or 
deafness, cochlear implants that bypass the dysfunctional or lost sensory hair 
cells and electrically stimulate the auditory nerve partially restore hearing. 
However, hearing with cochlear implants has shortcomings such as limited 
understanding of speech in background noise. So, there remains a major unmet 
medical need for improved hearing restoration (Wolf et al, 2022). Yet, despite 
major research efforts, a causal treatment based on pharmacology, gene therapy, 
or stem cells had, so far, not been clinically available. Now, this is finally 
changing at least for some patients: first in human trials prove the concept for 
inner ear gene therapy of otoferlin-related synaptic deafness.

This Commentary discusses the successes of the recent first in human trials for 
gene therapy of otoferlin-deficient hearing impairment. [Image: see text]

DOI: 10.1038/s44321-024-00058-6
PMCID: PMC11018804
PMID: 38528140 [Indexed for MEDLINE]

Conflict of interest statement: Tobias Moser is co-founder of OptoGenTech 
company that aims to develop optogenetic hearing restoration. The remaining 
authors declare no competing interests.


544. Ned Tijdschr Geneeskd. 1998 Jan 10;142(2):63-7.

[Rehabilitation possibilities for hearing-impaired subjects].

[Article in Dutch]

Kapteyn TS(1).

Author information:
(1)Academisch Ziekenhuis Vrije Universiteit, afd. KNO, Amsterdam.

Hearing impairment is a symptom, not a diagnosis. A number of types of hearing 
impairment can be distinguished. The self-reported hearing problems cluster 
around six hearing factors, the most important of which are speech understanding 
in noise and localisation of a sound source. For these capabilities equivalent 
functioning of both ears is important. The general practitioner can determine 
diagnosis and severity of the impairment using rather simple tools. When the 
cause of the impairment cannot be reduced in a proper way an adaptation of the 
sound to the impaired ear will be indicated. This can be arranged by either an 
ENT specialist or a centre for audiology. The selection of a proper hearing aid 
requires expertise and particular attention for the complaints. It is of the 
utmost importance that the hearing-impaired person can try out the effects of 
the hearing aid in daily circumstances for some weeks. If the patient, members 
of the family or the prescriber are not satisfied with the results, 
supplementary help is required, for example training in communication skills or 
special devices.

PMID: 9556995 [Indexed for MEDLINE]


545. Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi. 2022 Jun 20;40(6):434-438. doi: 
10.3760/cma.j.cn121094-20210615-00286.

[Health hazards and hearing loss risk assessment of workers exposed to noise in 
an automobile manufacturing enterprise].

[Article in Chinese; Abstract available in Chinese from the publisher]

Liu T(1), Liu J(2), Han C(2), Liu YT(2), Zeng Q(3), Gu Q(4).

Author information:
(1)School of Public Health, Tianjin Medical University, Tianjin 300070, China.
(2)Institute for Occupational Health, Tianjin Centers for Disease Control and 
Prevention, Tianjin 300011, China.
(3)School of Public Health, Tianjin Medical University, Tianjin 300070, China 
Institute for Occupational Health, Tianjin Centers for Disease Control and 
Prevention, Tianjin 300011, China.
(4)School of Public Health, Tianjin Medical University, Tianjin 300070, China 
Tianjin Municipal Health Commission, Tianjin 300070, China.

Objective: To investigate the current situation of occupational exposure to 
noise among noise workers in an automobile manufacturing enterprise in Tianjin, 
understand the impact of noise on workers＇ nervous system and hearing, and 
assess the risk of hearing loss among noise workers. Methods: In May 2021, 3516 
workers in an automobile manufacturing enterprise were investigated by using a 
self-made questionnaire＂Noise Workers Questionnaire＂ and cluster sampling 
method. The occupational noise hygiene survey and occupational hazards detection 
were carried out in their workplaces. They were divided into noise exposure 
group and non-noise exposure group according to whether they were exposed to 
noise or not. The general characteristics, hearing and nervous system symptoms 
of the two groups of workers were compared, and the risk of hearing loss was 
assessed. Results: There were 758 workers in the noise exposure group, aged 
(26±5) years old, with a working age of 3.0 (2.0, 6.0) years exposed to noise. 
2758 workers in the non-noise exposure group, aged (25±6) years old, with a 
working age of 2.0 (1.0, 4.0) years. There were statistically significant 
differences in the distribution of workers＇education level, working age and 
memory loss between the two groups (χ(2)=37.98, 38.70, 5.20, P<0.05). The 
workers in the noise exposure group showed a decreasing trend of insomnia, 
dreaminess, sweating and fatigue with the increase of working age 
(χ(2trend)=6.16, 7.99, P<0.05). The risk classification of binaural 
high-frequency hearing loss for workers in all noise positions until the age of 
50 and 60 was negligible, the risk of occupational noise deafness was low for 
workers in stamping and welding noise positions until the age of 60. Conclusion: 
The occupational noise exposed to automobile manufacturing workers may cause 
certain harm to their nervous and auditory systems. Noise protection measures 
should be taken to reduce the risk of hearing loss and occupational noise 
deafness.

Publisher: 目的： 
调查天津市某汽车制造企业噪声岗位工人职业接触噪声现状，了解噪声对作业工人神经系统和听力的影响，并对噪声岗位工人进行听力损失风险评估。 方法： 
于2021年5月，以整群抽样方法，对某汽车制造企业3 
516名工人进行《噪声作业工人调查表》调查，对其所在工作场所进行职业噪声检测，按是否接触噪声作业分为接噪组和非接噪组。比较两组工人之间的一般特征、听力情况、神经系统症状，并对接触噪声工人进行听力损失风险评估。 
结果： 接噪组工人758人，年龄（26±5）岁，接触噪声工龄3.0（2.0，6.0）年；非接噪组工人2 
758人，年龄（25±6）岁，工龄2.0（1.0，4.0）年；两组作业工人文化程度、工龄和记忆力减退分布差异均有统计学意义（χ(2)=37.98、38.70、5.20，P<0.05）；接噪组工人随着工龄增加，失眠多梦、多汗乏力呈下降趋势（χ(2)(趋势)=6.16、7.99，P<0.05）。各噪声岗位工人工作至50、60岁时发生双耳高频听力损失的风险分级均为可忽略风险，冲压、焊装噪声岗位工人工作至60岁时发生职业性噪声聋的风险均为低风险。 
结论： 汽车制造业工人接触的职业噪声会对其神经、听觉系统产生一定危害，应采取噪声防护措施降低其听力损失和职业性噪声聋的风险。.

DOI: 10.3760/cma.j.cn121094-20210615-00286
PMID: 35785897 [Indexed for MEDLINE]


546. Cereb Cortex. 2008 Dec;18(12):2855-67. doi: 10.1093/cercor/bhn044. Epub 2008 Apr 
9.

Hearing loss alters the subcellular distribution of presynaptic GAD and 
postsynaptic GABAA receptors in the auditory cortex.

Sarro EC(1), Kotak VC, Sanes DH, Aoki C.

Author information:
(1)Center for Neural Science, New York University, New York, NY 10003, USA.

We have shown previously that auditory experience regulates the maturation of 
excitatory synapses in the auditory cortex (ACx). In this study, we used 
electron microscopic immunocytochemistry to determine whether the heightened 
excitability of the ACx following neonatal sensorineural hearing loss (SNHL) 
also involves pre- or postsynaptic alterations of GABAergic synapses. SNHL was 
induced in gerbils just prior to the onset of hearing (postnatal day 10). At 
P17, the gamma-aminobutyri acid type A (GABA(A)) receptor's beta2/3-subunit 
(GABA(A)beta2/3) clusters residing at plasma membranes in layers 2/3 of ACx was 
reduced significantly in size (P < 0.05) and number (P < 0.005), whereas the 
overall number of immunoreactive puncta (intracellular + plasmalemmal) remained 
unchanged. The reduction of GABA(A)beta2/3 was observed along perikaryal plasma 
membranes of excitatory neurons but not of GABAergic interneurons. This 
cell-specific change can contribute to the enhanced excitability of SNHL ACx. 
Presynaptically, GABAergic axon terminals were significantly larger but less 
numerous and contained 47% greater density of glutamic acid decarboxylase 
immunoreactivity (P < 0.05). This suggests that GABA synthesis may be 
upregulated by a retrograde signal arising from lowered levels of postsynaptic 
GABA(A)R. Thus, both, the pre- and postsynaptic sides of inhibitory synapses 
that form upon pyramidal neurons of the ACx are regulated by neonatal auditory 
experience.

DOI: 10.1093/cercor/bhn044
PMCID: PMC2583158
PMID: 18403398 [Indexed for MEDLINE]


547. Front Aging Neurosci. 2023 Sep 15;15:1225786. doi: 10.3389/fnagi.2023.1225786. 
eCollection 2023.

Investigation of hearing loss in elderly vertigo and dizziness patients in the 
past 10 years.

Wang Q(1)(2)(3)(4), Chen A(1)(2)(3)(4), Hong M(1)(2)(3)(4), Liu X(1)(2)(3)(4), 
Du Y(1)(2)(3)(4), Wu Z(1)(2)(3)(4), Cheng W(5), Ji F(1)(2)(3)(4).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, The Medical Center of PLA 
General Hospital, Beijing, China.
(2)National Clinical Research Center for Otolaryngologic Diseases, Beijing, 
China.
(3)State Key Laboratory of Hearing Science, Ministry of Education, Beijing, 
China.
(4)Beijing Key Laboratory of Hearing Impairment Prevention and Treatment, 
Beijing, China.
(5)Academy of Medical Technology and Information Engineering, Zhejiang Chinese 
Medical University, Hangzhou, China.

BACKGROUND: Vertigo and hearing loss are both prevalent in the elderly. This 
study retrospectively analyzed hearing test results from elderly patients 
experiencing vertigo and dizziness at ENT outpatient over a 10-year period, in 
order to study the patterns of hearing loss in this patient population.
METHODS: Nine thousand three hundred eighty four patients over 50 years old 
underwent retrospective collection and screening of outpatient diagnosis, pure 
tone audiometry, acoustic immittance measurement (tympanogram) and auditory 
brainstem response (ABR) test. The patient's audiograms are divided into 7 
subtypes according to a set of fixed criteria. Meanwhile, K-Means clustering 
analysis method was used to classify the audiogram.
RESULTS: The Jerger classification of tympanogram in elderly patients with 
vertigo and dizziness showed the majority falling under type A. The leading 
audiogram shapes were flat (27.81% in right ear and 26.89% in left ear), 
high-frequency gently sloping (25.97% in right ear and 27.34% in left ear), and 
high-frequency steeply sloping (21.60% in right ear and 22.53% in left ear). 
Meniere's disease (MD; 30.87%), benign recurrent vertigo (BRV; 19.07%), and 
benign paroxysmal positional vertigo (BPPV; 15.66%) were the most common 
etiologies in elderly vestibular diseases. We observed statistically significant 
differences in hearing thresholds among these vestibular diseases (P < 0.001). 
K-Means clustering analysis suggested that the optimal number of clusters was 
three, with sample sizes for the three clusters being 2,747, 2,413, and 4,139, 
respectively. The ANOVA statistical results of each characteristic value showed 
P < 0.001.
CONCLUSION: The elderly patients often have mild to moderate hearing loss as a 
concomitant symptom with vertigo. Female patients have better hearing thresholds 
than males. The dominant audiometric shapes in this patient population were 
flat, high-frequency gently sloping, and high-frequency steeply sloping 
according to a set of fixed criteria. This study highlights the need for 
tailored strategies in managing hearing loss in elderly patients with vertigo 
and dizziness.

Copyright © 2023 Wang, Chen, Hong, Liu, Du, Wu, Cheng and Ji.

DOI: 10.3389/fnagi.2023.1225786
PMCID: PMC10543661
PMID: 37790285

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


548. Clin Oncol (R Coll Radiol). 2022 Apr;34(4):e160-e167. doi: 
10.1016/j.clon.2021.10.013. Epub 2021 Nov 10.

Sensorineural Hearing Loss in Nasopharyngeal Carcinoma Survivors in the Modern 
Treatment Era - The Early and Late Effects of Radiation and Cisplatin.

Yip PL(1), Mok KCJ(2), Ho HS(1), Lee WYV(1), Wong ACL(2), Lau CT(1), Wong 
FCS(1), Yeung KW(2), Lee SF(3).

Author information:
(1)Department of Clinical Oncology, Tuen Mun Hospital, New Territories West 
Cluster, Hospital Authority, Hong Kong.
(2)Department of Otorhinolaryngology, Tuen Mun Hospital, New Territories West 
Cluster, Hospital Authority, Hong Kong.
(3)Department of Clinical Oncology, Tuen Mun Hospital, New Territories West 
Cluster, Hospital Authority, Hong Kong; Department of Clinical Oncology, 
University of Hong Kong, Hong Kong. Electronic address: leesf@hku.hk.

AIMS: Hearing loss is a common debilitating complication in nasopharyngeal 
carcinoma (NPC) survivors. The aim of the present study was to investigate the 
impact of inner ear/cochlear radiation dose and cisplatin use on early and late 
sensorineural hearing loss (SNHL) in NPC patients treated with radiotherapy 
alone, concurrent chemoradiation (cCRT) and induction chemotherapy followed by 
cCRT (iCRT) in the intensity-modulated radiotherapy era.
MATERIALS AND METHODS: The study included 81 NPC patients treated with 
intensity-modulated radiotherapy between 2014 and 2016. Pure tone audiometry was 
carried out at baseline and follow-up. The effects of cochlear/inner ear 
radiation and cisplatin doses on early (<12 months) and late (≥24 months) SNHL 
were analysed using multivariable regression after adjusting for important 
predictors.
RESULTS: In total, 156 ears were examined. In early SNHL (n = 136), cisplatin 
use predicted the incidence of early high-frequency SHNL (HF-SNHL) (odds ratio 
6.4, 95% confidence interval 1.7-23.9, P = 0.005). Ninety ears were analysed for 
late SNHL (median follow-up 38 months). Inner ear/cochlear radiation and 
cisplatin doses and better pre-treatment hearing were independent predictors of 
threshold change at 4 kHz. Every 10 Gy increase in inner ear/cochlear Dmean 
resulted in 5-dB and 6-dB threshold changes, respectively (cochlear Dmean: B = 
0.005, 95% confidence interval 0.0004-0.009, P = 0.031; inner ear Dmean: B = 
0.006, 95% confidence interval 0.001-0.010, P = 0.014). Cisplatin use was 
associated with late HF-SNHL (odds ratio 3.74, 95% confidence interval 1.1-12.3, 
P = 0.031). In the cCRT and iCRT subgroups, no cisplatin dose-dependent 
ototoxicity was observed. Severe (≥30 dB) late HF-SNHL occurred in 14% and 25% 
of the patients when the cochlear dose constraints were 40 Gy and 44 Gy, 
respectively. The radiotherapy-alone group did not develop severe late HF-SNHL.
CONCLUSION: Cochlear/inner ear radiation dose and cisplatin use showed 
differential and independent ototoxicity in early and late SNHL. As 
cochlear/inner ear dose-dependent ototoxicity was demonstrated, the cochlear 
dose constraint should be as low as reasonably achievable, especially when 
cisplatin is also administered.

Copyright © 2021 The Royal College of Radiologists. Published by Elsevier Ltd. 
All rights reserved.

DOI: 10.1016/j.clon.2021.10.013
PMID: 34772581 [Indexed for MEDLINE]


549. PLoS Biol. 2023 Aug 24;21(8):e3002257. doi: 10.1371/journal.pbio.3002257. 
eCollection 2023 Aug.

Phytosterols reverse antiretroviral-induced hearing loss, with potential 
implications for cochlear aging.

Sodero AO(1), Castagna VC(2)(3), Elorza SD(4), Gonzalez-Rodulfo SM(1), Paulazo 
MA(1), Ballestero JA(2), Martin MG(4), Gomez-Casati ME(2).

Author information:
(1)Instituto de Investigaciones Biomédicas, Pontificia Universidad Católica 
Argentina, Consejo Nacional de Investigaciones Científicas y Técnicas (BIOMED, 
UCA-CONICET), Buenos Aires, Argentina.
(2)Instituto de Farmacología, Facultad de Medicina, Universidad de Buenos Aires, 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos 
Aires, Argentina.
(3)Instituto de Investigaciones en Ingeniería Genética y Biología Molecular, Dr. 
Héctor N. Torres, Consejo Nacional de Investigaciones Científicas y Técnicas 
(INGEBI-CONICET), Buenos Aires, Argentina.
(4)Laboratorio de Neurobiología, Instituto de Investigaciones Médicas Mercedes y 
Martín Ferreyra, Consejo Nacional de Investigaciones Científicas y Técnicas 
(INIMEC-CONICET-UNC), Universidad Nacional de Córdoba, Córdoba, Argentina.

Cholesterol contributes to neuronal membrane integrity, supports membrane 
protein clustering and function, and facilitates proper signal transduction. 
Extensive evidence has shown that cholesterol imbalances in the central nervous 
system occur in aging and in the development of neurodegenerative diseases. In 
this work, we characterize cholesterol homeostasis in the inner ear of young and 
aged mice as a new unexplored possibility for the prevention and treatment of 
hearing loss. Our results show that cholesterol levels in the inner ear are 
reduced during aging, an effect that is associated with an increased expression 
of the cholesterol 24-hydroxylase (CYP46A1), the main enzyme responsible for 
cholesterol turnover in the brain. In addition, we show that pharmacological 
activation of CYP46A1 with the antiretroviral drug efavirenz reduces the 
cholesterol content in outer hair cells (OHCs), leading to a decrease in prestin 
immunolabeling and resulting in an increase in the distortion product 
otoacoustic emissions (DPOAEs) thresholds. Moreover, dietary supplementation 
with phytosterols, plant sterols with structure and function similar to 
cholesterol, was able to rescue the effect of efavirenz administration on the 
auditory function. Altogether, our findings point towards the importance of 
cholesterol homeostasis in the inner ear as an innovative therapeutic strategy 
in preventing and/or delaying hearing loss.

Copyright: © 2023 Sodero et al. This is an open access article distributed under 
the terms of the Creative Commons Attribution License, which permits 
unrestricted use, distribution, and reproduction in any medium, provided the 
original author and source are credited.

DOI: 10.1371/journal.pbio.3002257
PMCID: PMC10449472
PMID: 37619212 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


550. Zhonghua Yi Xue Za Zhi. 2009 Sep 8;89(33):2329-32.

[Functional MRI in normal subjects and sudden unilateral sensorineural hearing 
loss patients].

[Article in Chinese]

Yang M(1), Liu B, Teng GJ, Huang ZC, Gao WW, Ji H, Wu M, Feng X, Zhang HY, Wang 
J.

Author information:
(1)Department of Radiology, Zhongda Hospital of Southeast University, Nanjing 
210009, China.

OBJECTIVE: Brain activities in responses to amplitude modulation (AM) was 
evaluated using functional MRI (fMRI) in subjects with sudden unilateral 
sensorineural hearing loss (SSNHL) and those with normal hearing (NH).
METHODS: Totally 25 subjects with normal hearing and 30 with SSNHL were examined 
with fMRI in response to AM tones of 500, 2000 and 4000 Hz respectively with the 
modulation frequency at 8 Hz. The fMRI was examined within 12 days after the 
onset of SSNHL. The AM signals were presented at 96 dB SPL binaurally. An 
event-related design was combined with a sparse clustered volume acquisitioning 
paradigm in data collection in the attempt to reduce the influence of acoustic 
scanner noise. SPM2 software was used for offline data analyzing.
RESULTS: Brain activation in fMRI image was found mainly in the primary auditory 
cortex (PAC) in both subjects with NH and SSNHL NH subjects showed a clear 
lateralization to left cerebral hemisphere(11/16) and SSNHL patients showed a 
lateralization ipsilateral to the impaired ear(16/22). The activation voxel and 
intensity shown in BOLD were found to be decreased with increasing signal 
frequency in both groups.
CONCLUSION: The difference in the lateralization between the two groups suggests 
that an adaptive process occurs shortly after the onset of SSNHL

PMID: 20095354 [Indexed for MEDLINE]


551. Acta Otolaryngol Suppl. 1995;519:30-5. doi: 10.3109/00016489509121867.

Effects of chronic cochlear damage on threshold and frequency tuning of neurons 
in AI auditory cortex.

Harrison RV(1), Stanton SG, Mount RJ.

Author information:
(1)Research Institute, Hospital for Sick Children, Toronto, Canada.

We describe the effects of long-term cochlear lesions on the frequency response 
properties of AI cortical neurons in the cat. Young animals were treated with 
amikacin to produce bilateral, basal to mid-turn cochlear lesions. After 12-24 
months the response properties of single neurons or small unit clusters in 
primary auditory cortex were recorded in anesthetized animals. Responses to 
stimulus frequency and intensity were mapped in detail and frequency threshold 
curves (FTCs) and Q10dB values were derived. Subsequent to recording 
experiments, scanning electron microscopy of the sensory epithelium was used to 
characterize the degree and extent of the cochlear damage. In normal control 
animals, Q10dB values were, on average, lower than those derived by others from 
cochlear nerve fibre recordings in the same species. In amikacin-treated 
animals, deterioration was evident in the threshold and tuning properties of 
cortical neurons, particularly in those cells whose input originated in damaged 
cochlear regions. Often, neurons associated with 'normal' cochlear areas (as 
assessed by scanning microscopy) also had poor frequency tuning compared with 
controls. As an animal model of sensorineural hearing loss, we consider the cat 
with long-term cochlear lesions to be more appropriate than animals with acute 
or short-term pathology. We also suggest that in making 
physiological-psychophysical correlations, neural responses from the central 
auditory system (e.g. cortex) should perhaps be given more consideration than 
data derived at the cochlear level.

DOI: 10.3109/00016489509121867
PMID: 7610889 [Indexed for MEDLINE]


552. Int J Tuberc Lung Dis. 2020 Jan 1;24(1):65-72. doi: 10.5588/ijtld.19.0062.

Risk of hearing loss among multidrug-resistant tuberculosis patients according 
to cumulative aminoglycoside dose.

Hong H(1), Dowdy DW(2), Dooley KE(3), Francis HW(4), Budhathoki C(5), Han HR(6), 
Farley JE(1).

Author information:
(1)Johns Hopkins University School of Nursing, Baltimore, MD, The REACH 
Initiative, Johns Hopkins University School of Nursing, Baltimore, MD.
(2)Departments of Epidemiology and International Health, Johns Hopkins Bloomberg 
School of Public Health, Baltimore, MD.
(3)Divisions of Clinical Pharmacology and Infectious Disease, Johns Hopkins 
University School of Medicine, Baltimore, MD.
(4)Division of Head and Neck Surgery and Communication Sciences, Duke University 
School of Medicine, Durham, NC.
(5)Johns Hopkins University School of Nursing, Baltimore, MD.
(6)Johns Hopkins University School of Nursing, Baltimore, MD, Center for 
Cardiovascular and Chronic Care, Johns Hopkins University, Baltimore, MD, USA.

SETTING: The ototoxic effects of aminoglycosides (AGs) lead to permanent hearing 
loss, which is one of the devastating consequences of multidrug-resistant 
tuberculosis (MDR-TB) treatment. As AG ototoxicity is dose-dependent, the impact 
of a surrogate measure of AG exposure on AG-induced hearing loss warrants close 
attention for settings with limited therapeutic drug monitoring.OBJECTIVE: To 
explore the prognostic impact of cumulative AG dose on AG ototoxicity in 
patients following initiation of AG-containing treatment for MDR-TB.DESIGN: This 
prospective cohort study was nested within an ongoing cluster-randomized trial 
of nurse case management intervention across 10 MDR-TB hospitals in South 
Africa.RESULTS: The adjusted hazard of AG regimen modification due to 
ototoxicity in the high-dose group (≥75 mg/kg/week) was 1.33 times higher than 
in the low-dose group (<75 mg/kg/week, 95%CI 1.09-1.64). The adjusted hazard of 
developing audiometric hearing loss was 1.34 times higher than in the low-dose 
group (95%CI 1.01-1.77). Pre-existing hearing loss (adjusted hazard ratio [aHR] 
1.71, 95%CI 1.29-2.26) and age (aHR 1.16 per 10 years of age, 95%CI 1.01-1.33) 
were also associated with an increased risk of hearing loss.CONCLUSION: MDR-TB 
patients with high AG dose, advanced age and pre-existing hearing loss have a 
significantly higher risk of AG-induced hearing loss. Those at high risk may be 
candidates for more frequent monitoring or AG-sparing regimens.

DOI: 10.5588/ijtld.19.0062
PMCID: PMC7594545
PMID: 32005308 [Indexed for MEDLINE]


553. Trends Hear. 2016 Sep 7;20:2331216516659632. doi: 10.1177/2331216516659632.

Forward-Masked Frequency Selectivity Improvements in Simulated and Actual 
Cochlear Implant Users Using a Preprocessing Algorithm.

Langner F(1), Jürgens T(2).

Author information:
(1)Medizinische Physik, Cluster of Excellence "Hearing4all," Carl von Ossietzky 
University, Oldenburg, Germany Forschungszentrum Neurosensorik, Carl von 
Ossietzky University, Oldenburg, Germany Department of Otolaryngology, Medical 
University Hannover, Hannover, Germany langner.florian@mh-hannover.de.
(2)Medizinische Physik, Cluster of Excellence "Hearing4all," Carl von Ossietzky 
University, Oldenburg, Germany Forschungszentrum Neurosensorik, Carl von 
Ossietzky University, Oldenburg, Germany.

Frequency selectivity can be quantified using masking paradigms, such as 
psychophysical tuning curves (PTCs). Normal-hearing (NH) listeners show sharp 
PTCs that are level- and frequency-dependent, whereas frequency selectivity is 
strongly reduced in cochlear implant (CI) users. This study aims at (a) 
assessing individual shapes of PTCs in CI users, (b) comparing these shapes to 
those of simulated CI listeners (NH listeners hearing through a CI simulation), 
and (c) increasing the sharpness of PTCs using a biologically inspired dynamic 
compression algorithm, BioAid, which has been shown to sharpen the PTC shape in 
hearing-impaired listeners. A three-alternative-forced-choice forward-masking 
technique was used to assess PTCs in 8 CI users (with their own speech 
processor) and 11 NH listeners (with and without listening through a vocoder to 
simulate electric hearing). CI users showed flat PTCs with large interindividual 
variability in shape, whereas simulated CI listeners had PTCs of the same 
average flatness, but more homogeneous shapes across listeners. The algorithm 
BioAid was used to process the stimuli before entering the CI users' speech 
processor or the vocoder simulation. This algorithm was able to partially 
restore frequency selectivity in both groups, particularly in seven out of eight 
CI users, meaning significantly sharper PTCs than in the unprocessed condition. 
The results indicate that algorithms can improve the large-scale sharpness of 
frequency selectivity in some CI users. This finding may be useful for the 
design of sound coding strategies particularly for situations in which high 
frequency selectivity is desired, such as for music perception.

© The Author(s) 2016.

DOI: 10.1177/2331216516659632
PMCID: PMC5017570
PMID: 27604785 [Indexed for MEDLINE]


554. Int J Dev Neurosci. 2021 Jun;81(4):364-369. doi: 10.1002/jdn.10104. Epub 2021 
Mar 26.

Report of a case with ferredoxin reductase (FDXR) gene variants in a Chinese boy 
exhibiting hearing loss, visual impairment, and motor retardation.

Yang C(1), Zhang Y(1), Li J(2), Song Z(1), Yi Z(1), Li F(1), Xue J(1), Zhang 
W(3)(4), Wang C(4).

Author information:
(1)Department of Pediatric, the Affiliated Hospital of Qingdao University, 
Shandong, China.
(2)Department of Neurology, Beijing Children's Hospital, Capital Medical 
University, National Center for Children's Health, Beijing, China.
(3)Department of Molecular and Human Genetics, Baylor College of Medicine, 
Houston, TX, USA.
(4)AmCare Genomics Lab, GuangZhou, China.

Ferredoxin reductase (FDXR), located in 17q25.1, encodes for a mitochondrial 
NADPH: adrenodoxin oxidoreductase or ferredoxin reductase, the sole human 
ferredoxin reductase involved in the biosynthesis of iron-sulfur (Fe-S) clusters 
and heme formation. Iron-sulfur (Fe-S) clusters are involved in enzymatic 
catalysis, gene expression, and DNA replication and repair. Variants in FDXR 
lead to sensorial neuropathies, damage optic, and auditory neurons. Here, we 
report a Chinese boy with hearing loss, visual impairment, and motor 
retardation, with two novel compound heterozygous variants in FDXR (NM_004110), 
namely, c.250C > T (p.P84S) and c.634G > C (p.D212H), identified by whole-exome 
sequencing. Compared with the reported cases, except hearing loss and visual 
impairment, the clinical manifestations of this boy were more serious, who also 
had motor retardation and died in infancy after infection. The present study 
expands our knowledge of FDXR variants and related phenotypes, and provides new 
information on the genetic defects associated with this disease for clinical 
diagnosis.

© 2021 International Society for Developmental Neuroscience.

DOI: 10.1002/jdn.10104
PMID: 33742450 [Indexed for MEDLINE]


555. J Exp Psychol Hum Percept Perform. 2023 Nov;49(11):1377-1394. doi: 
10.1037/xhp0001159.

Are there good days and bad days for hearing? Quantifying day-to-day 
intraindividual speech perception variability in older and younger adults.

Kuhlmann I(1), Angonese G(1), Thiel C(1), Kollmeier B(1), Hildebrandt A(1).

Author information:
(1)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität.

Moment-to-moment variations in hearing and speech perception have long been 
observed. Depending on the researcher's theoretical position, the observed 
fluctuations have been attributed to measurement error or to internal, 
nonsensory factors such as fluctuations in attention. While cognitive 
performance has been shown to fluctuate from day to day over longer time, such 
fluctuations have not been quantified for speech perception, despite being 
well-recognized by clinical audiologists and hearing-impaired patients. In three 
studies, we aimed to explore and quantify the magnitude of daily variability in 
speech perception and to investigate whether such variability goes beyond test 
unreliability. We also asked whether intraindividual variability depends on 
overall speech perception performance as observed in different groups of 
individuals. Older adults with objective hearing impairment and mostly hearing 
aids (N₁ = 45), with subjective hearing problems but no hearing aids (N₂ = 113), 
and younger adults without hearing problems (N₃ = 20) participated in three 
ecological momentary assessment studies. They performed a digit-in-noise test 
two to three times a day for several weeks. Variance heterogeneous linear 
mixed-effects models indicated reliable intraindividual variability in speech 
perception and substantial individual differences in daily variability. A 
protective factor against daily fluctuations is a higher average speech 
perception. These studies show that day-to-day variations in speech perception 
cannot simply be attributed to test unreliability and pave the way for 
investigating how psychological states that do not vary from moment-to-moment, 
but rather from day to day, predict variations in speech perception. (PsycInfo 
Database Record (c) 2023 APA, all rights reserved).

DOI: 10.1037/xhp0001159
PMID: 37870818 [Indexed for MEDLINE]


556. Cochlear Implants Int. 2015 Jan;16 Suppl 1:S26-9. doi: 
10.1179/1467010014Z.000000000229.

Preschool television programmes: analysis using SmartSound IQ data logging.

Hanvey K, DeBold L.

DOI: 10.1179/1467010014Z.000000000229
PMID: 25614262 [Indexed for MEDLINE]


557. Braz J Med Biol Res. 2018 Jan 11;51(3):e6426. doi: 10.1590/1414-431X20176426.

Analysis of serum microRNA expression in male workers with occupational 
noise-induced hearing loss.

Li YH(1)(2), Yang Y(1), Yan YT(1), Xu LW(1), Ma HY(1), Shao YX(3), Cao CJ(3), Wu 
X(1), Qi MJ(1), Wu YY(1), Chen R(1), Hong Y(1), Tan XH(1), Yang L(1)(2).

Author information:
(1)School of Medicine, Hangzhou Normal University, Hangzhou, Zhejiang, China.
(2)College of Life Sciences, Shihezi University, Shihezi, Xinjiang, China.
(3)Hangzhou Hospital for the Prevention and Treatment of Occupational Diseases, 
Hangzhou, Zhejiang, China.

Occupational noise-induced hearing loss (ONIHL) is a prevalent occupational 
disorder that impairs auditory function in workers exposed to prolonged noise. 
However, serum microRNA expression in ONIHL subjects has not yet been studied. 
We aimed to compare the serum microRNA expression profiles in male workers of 
ONIHL subjects and controls. MicroRNA microarray analysis revealed that four 
serum microRNAs were differentially expressed between controls (n=3) and ONIHL 
subjects (n=3). Among these microRNAs, three were upregulated (hsa-miR-3162-5p, 
hsa-miR-4484, hsa-miR-1229-5p) and one was downregulated (hsa-miR-4652-3p) in 
the ONIHL group (fold change >1.5 and Pbon value <0.05). Real time quantitative 
PCR was conducted for validation of the microRNA expression. Significantly 
increased serum levels of miR-1229-5p were found in ONIHL subjects compared to 
controls (n=10 for each group; P<0.05). A total of 659 (27.0%) genes were 
predicted as the target genes of miR-1229-5p. These genes were involved in 
various pathways, such as mitogen-activated protein kinase (MAPK) signaling 
pathway. Overexpression of miR-1229-5p dramatically inhibited the luciferase 
activity of 3' UTR segment of MAPK1 (P<0.01). Compared to the negative control, 
HEK293T cells expressing miR-1229-5p mimics showed a significant decline in mRNA 
levels of MAPK1 (P<0.05). This preliminary study indicated that serum 
miR-1229-5p was significantly elevated in ONIHL subjects. Increased miR-1229-5p 
may participate in the pathogenesis of ONIHL through repressing MAPK1 signaling.

DOI: 10.1590/1414-431X20176426
PMCID: PMC5769754
PMID: 29340520 [Indexed for MEDLINE]


558. Hear Res. 2022 Jul;420:108507. doi: 10.1016/j.heares.2022.108507. Epub 2022 Apr 
11.

Modelling speech reception thresholds and their improvements due to spatial 
noise reduction algorithms in bimodal cochlear implant users.

Zedan A(1), Jürgens T(2), Williges B(3), Hülsmeier D(4), Kollmeier B(5).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all," 
Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany. Electronic 
address: ayham.zedan@uni-oldenburg.de.
(2)Institut für Akustik, Technische Hochschule Lübeck, Lübeck, Germany. 
Electronic address: tim.juergens@th-luebeck.de.
(3)Medizinische Physik and Cluster of Excellence "Hearing4all," 
Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany; SOUND Lab & 
Cambridge Hearing Group, Department of Clinical Neurosciences, University of 
Cambridge, Cambridge, United Kingdom. Electronic address: 
bw429@medschl.cam.ac.uk.
(4)Medizinische Physik and Cluster of Excellence "Hearing4all," 
Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany. Electronic 
address: david.huelsmeier@uni-oldenburg.de.
(5)Medizinische Physik and Cluster of Excellence "Hearing4all," 
Carl-von-Ossietzky Universität Oldenburg, Oldenburg, Germany. Electronic 
address: birger.kollmeier@uni-oldenburg.de.

Spatial noise reduction algorithms ("beamformers") can considerably improve 
speech reception thresholds (SRTs) for bimodal cochlear implant (CI) users. The 
goal of this study was to model SRTs and SRT-benefit due to beamformers for 
bimodal CI users. Two existing model approaches varying in computational 
complexity and binaural processing assumption were compared: (i) the framework 
of auditory discrimination experiments (FADE) and (ii) the binaural speech 
intelligibility model (BSIM), both with CI and aided hearing-impaired 
front-ends. The exact same acoustic scenarios, and open-access beamformers as in 
the comparison clinical study Zedan et al. (2021) were used to quantify goodness 
of prediction. FADE was capable of modeling SRTs ab-initio, i.e., no calibration 
of the model was necessary to achieve high correlations and low root-mean square 
errors (RMSE) to both, measured SRTs (r = 0.85, RMSE = 2.8 dB) and to measured 
SRT-benefits (r = 0.96). BSIM achieved somewhat poorer predictions to both, 
measured SRTs (r = 0.78, RMSE = 6.7 dB) and to measured SRT-benefits (r = 0.91) 
and needs to be calibrated for matching average SRTs in one condition. Greatest 
deviations in predictions of BSIM were observed in diffuse multi-talker babble 
noise, which were not found with FADE. SRT-benefit predictions of both models 
were similar to instrumental signal-to-noise ratio (iSNR) improvements due to 
the beamformers. This indicates that FADE is preferrable for modeling absolute 
SRTs. However, for prediction of SRT-benefit due to spatial noise reduction 
algorithms in bimodal CI users, the average iSNR is a much simpler approach with 
similar performance.

Copyright © 2022. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2022.108507
PMCID: PMC9188268
PMID: 35484022 [Indexed for MEDLINE]


559. Front Neurosci. 2019 Jul 16;13:730. doi: 10.3389/fnins.2019.00730. eCollection 
2019.

Acquisition of Subcortical Auditory Potentials With Around-the-Ear cEEGrid 
Technology in Normal and Hearing Impaired Listeners.

Garrett M(1)(2), Debener S(2)(3), Verhulst S(4).

Author information:
(1)Department of Medical Physics and Acoustics, University of Oldenburg, 
Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all", Oldenburg, Germany.
(3)Neuropsychology Laboratory, Department of Psychology, University of 
Oldenburg, Oldenburg, Germany.
(4)Department of Information Technology, Hearing Technology @ WAVES, Ghent 
University, Ghent, Belgium.

Even though the principles of recording brain electrical activity remain 
unchanged since their discovery, their acquisition has seen major improvements. 
The cEEGrid, a recently developed flex-printed multi-channel sensory array, can 
be placed around the ear and successfully record well-known cortical 
electrophysiological potentials such as late auditory evoked potentials (AEPs) 
or the P300. Due to its fast and easy application as well as its long-lasting 
signal recording window, the cEEGrid technology offers great potential as a 
flexible and 'wearable' solution for the acquisition of neural correlates of 
hearing. Early potentials of auditory processing such as the auditory brainstem 
response (ABR) are already used in clinical assessment of sensorineural hearing 
disorders and envelope following responses (EFR) have shown promising results in 
the diagnosis of suprathreshold hearing deficits. This study evaluates the 
suitability of the cEEGrid electrode configuration to capture these AEPs. 
cEEGrid potentials were recorded and compared to cap-EEG potentials for young 
normal-hearing listeners and older listeners with high-frequency sloping 
audiograms to assess whether the recordings are adequately sensitive for hearing 
diagnostics. ABRs were elicited by presenting clicks (70 and 100-dB peSPL) and 
stimulation for the EFRs consisted of 120 Hz amplitude-modulated white noise 
carriers presented at 70-dB SPL. Data from nine bipolar cEEGrid channels and one 
classical cap-EEG montage (earlobes to vertex) were analysed and outcome 
measures were compared. Results show that the cEEGrid is able to record ABRs and 
EFRs with comparable shape to those recorded using a conventional cap-EEG 
recording montage and the same amplifier. Signal strength is lower but can still 
produce responses above the individual neural electrophysiological noise floor. 
This study shows that the application of the cEEGrid can be extended to the 
acquisition of early auditory evoked potentials.

DOI: 10.3389/fnins.2019.00730
PMCID: PMC6646709
PMID: 31379484


560. Hear Res. 2015 Oct;328:133-47. doi: 10.1016/j.heares.2015.08.009. Epub 2015 Aug 
21.

Enhanced audio-visual interactions in the auditory cortex of elderly 
cochlear-implant users.

Schierholz I(1), Finke M(2), Schulte S(3), Hauthal N(4), Kantzke C(5), Rach 
S(6), Büchner A(2), Dengler R(5), Sandmann P(5).

Author information:
(1)Cluster of Excellence "Hearing4all", Hannover, Germany; Department of 
Neurology, Hannover Medical School, Hannover, Germany. Electronic address: 
Schierholz.Irina@mh-hannover.de.
(2)Cluster of Excellence "Hearing4all", Hannover, Germany; Department of 
Otolaryngology, Hannover Medical School, Hannover, Germany.
(3)Department of Neurology, Hannover Medical School, Hannover, Germany.
(4)Cluster of Excellence "Hearing4all", Hannover, Germany; Department of 
Psychology, European Medical School, University of Oldenburg, Oldenburg, 
Germany.
(5)Cluster of Excellence "Hearing4all", Hannover, Germany; Department of 
Neurology, Hannover Medical School, Hannover, Germany.
(6)Department of Epidemiological Methods and Etiological Research, Leibniz 
Institute of Prevention Research and Epidemiology - BIPS, Bremen, Germany.

Auditory deprivation and the restoration of hearing via a cochlear implant (CI) 
can induce functional plasticity in auditory cortical areas. How these plastic 
changes affect the ability to integrate combined auditory (A) and visual (V) 
information is not yet well understood. In the present study, we used 
electroencephalography (EEG) to examine whether age, temporary deafness and 
altered sensory experience with a CI can affect audio-visual (AV) interactions 
in post-lingually deafened CI users. Young and elderly CI users and age-matched 
NH listeners performed a speeded response task on basic auditory, visual and 
audio-visual stimuli. Regarding the behavioral results, a redundant signals 
effect, that is, faster response times to cross-modal (AV) than to both of the 
two modality-specific stimuli (A, V), was revealed for all groups of 
participants. Moreover, in all four groups, we found evidence for audio-visual 
integration. Regarding event-related responses (ERPs), we observed a more 
pronounced visual modulation of the cortical auditory response at N1 latency 
(approximately 100 ms after stimulus onset) in the elderly CI users when 
compared with young CI users and elderly NH listeners. Thus, elderly CI users 
showed enhanced audio-visual binding which may be a consequence of compensatory 
strategies developed due to temporary deafness and/or degraded sensory input 
after implantation. These results indicate that the combination of aging, 
sensory deprivation and CI facilitates the coupling between the auditory and the 
visual modality. We suggest that this enhancement in multisensory interactions 
could be used to optimize auditory rehabilitation, especially in elderly CI 
users, by the application of strong audio-visually based rehabilitation 
strategies after implant switch-on.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.08.009
PMID: 26302946 [Indexed for MEDLINE]


561. Trends Hear. 2018 Jan-Dec;22:2331216518773632. doi: 10.1177/2331216518773632.

Application of Data Mining to a Large Hearing-Aid Manufacturer's Dataset to 
Identify Possible Benefits for Clinicians, Manufacturers, and Users.

Mellor J(1), Stone MA(2)(3), Keane J(1)(4).

Author information:
(1)1 School of Computer Science, University of Manchester, Manchester, UK.
(2)2 Manchester Centre for Audiology and Deafness, University of Manchester, 
Manchester, UK.
(3)3 Manchester Academic Health Sciences Centre, University of Manchester, 
Manchester, UK.
(4)4 Manchester Institute of Biotechnology, University of Manchester, 
Manchester, UK.

Modern hearing instruments contain logging technology to record data, such as 
the acoustic environments in which the device is being used and how the signal 
processing is consequently operating. Combined with patient data, such as the 
audiogram, this information gives a more comprehensive picture of the user and 
their relationship with the aid. Here, a relatively large, anonymized dataset 
(>300,000 devices, >150,000 wearers) from a hearing-aid manufacturer was data 
mined for connections between subsets of the logged varieties of data. Apart 
from replicating links that have previously been reported in labor-intensive 
studies, a link between device style (in-the-ear/behind-the-ear) and the sound 
levels of encountered environments was demonstrated, suggesting that some device 
types are more successful from a lifestyle perspective. Furthermore, the data 
also suggested links between the audiogram and the sound environments in which 
the aid was operated. Modeling the expected link between the environment and the 
microphone directionality settings revealed patterns of either abnormal fitting 
or where the aid was not operating correctly-factors that may indicate a failed 
fitting. Given the necessarily redacted nature of the dataset, the reported 
findings represent a proof-of-concept of the use of relatively large-scale data 
mining to guide and assess hearing-aid fitting procedures for possible benefits 
to the clinician, manufacturer, and patient.

DOI: 10.1177/2331216518773632
PMCID: PMC6022813
PMID: 29848201 [Indexed for MEDLINE]


562. Ear Hear. 2021 Jan/Feb;42(1):180-192. doi: 10.1097/AUD.0000000000000916.

Prediction of the Functional Status of the Cochlear Nerve in Individual Cochlear 
Implant Users Using Machine Learning and Electrophysiological Measures.

Skidmore J(1), Xu L(2)(3), Chao X(2)(3), Riggs WJ(1)(4), Pellittieri A(5), 
Vaughan C(1), Ning X(6), Wang R(2)(3), Luo J(2)(3), He S(1)(4).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, The Ohio State 
University, Columbus, Ohio, USA.
(2)Department of Otolaryngology-Head and Neck Surgery, Shandong Provincial ENT 
Hospital Affiliated to Shandong University, Jinan, Shandong, People's Republic 
of China.
(3)Department of Auditory Implantation, Shandong ENT Hospital, Jinan, Shandong, 
People's Republic of China.
(4)Department of Audiology, Nationwide Children's Hospital, Columbus, Ohio, USA.
(5)The Cleveland Clinic, Cleveland, Ohio, USA.
(6)Department of Biomedical Informatics, The Ohio State University, Columbus, 
Ohio, USA.

OBJECTIVES: This study aimed to create an objective predictive model for 
assessing the functional status of the cochlear nerve (CN) in individual 
cochlear implant (CI) users.
DESIGN: Study participants included 23 children with cochlear nerve deficiency 
(CND), 29 children with normal-sized CNs (NSCNs), and 20 adults with various 
etiologies of hearing loss. Eight participants were bilateral CI users and were 
tested in both ears. As a result, a total of 80 ears were tested in this study. 
All participants used Cochlear Nucleus CIs in their test ears. For each 
participant, the CN refractory recovery function and input/output (I/O) function 
were measured using electrophysiological measures of the electrically evoked 
compound action potential (eCAP) at three electrode sites across the electrode 
array. Refractory recovery time constants were estimated using statistical 
modeling with an exponential decay function. Slopes of I/O functions were 
estimated using linear regression. The eCAP parameters used as input variables 
in the predictive model were absolute refractory recovery time estimated based 
on the refractory recovery function, eCAP threshold, slope of the eCAP I/O 
function, and negative-peak (i.e., N1) latency. The output variable of the 
predictive model was CN index, an indicator for the functional status of the CN. 
Predictive models were created by performing linear regression, support vector 
machine regression, and logistic regression with eCAP parameters from children 
with CND and the children with NSCNs. One-way analysis of variance with post hoc 
analysis with Tukey's honest significant difference criterion was used to 
compare study variables among study groups.
RESULTS: All three machine learning algorithms created two distinct 
distributions of CN indices for children with CND and children with NSCNs. 
Variations in CN index when calculated using different machine learning 
techniques were observed for adult CI users. Regardless of these variations, CN 
indices calculated using all three techniques in adult CI users were 
significantly correlated with Consonant-Nucleus-Consonant word and AzBio 
sentence scores measured in quiet. The five oldest CI users had smaller CN 
indices than the five youngest CI users in this study.
CONCLUSIONS: The functional status of the CN for individual CI users was 
estimated by our newly developed analytical models. Model predictions of CN 
function for individual adult CI users were positively and significantly 
correlated with speech perception performance. The models presented in this 
study may be useful for understanding and/or predicting CI outcomes for 
individual patients.

Copyright © 2020 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000000916
PMCID: PMC8156737
PMID: 32826505 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest to 
declare.


563. Anticancer Res. 2003 Mar-Apr;23(2B):1249-55.

Sequence variations of mitochondrial DNA and individual sensitivity to the 
ototoxic effect of cisplatin.

Peters U(1), Preisler-Adams S, Lanvers-Kaminsky C, Jürgens H, Lamprecht-Dinnesen 
A.

Author information:
(1)Institute for Human Genetics, University of Muenster, Muenster, Germany.

BACKGROUND: Since mutations in the mitochondrial genome are associated with 
hearing loss, we analyzed whether sequence variations of mtDNA are associated 
with individual sensitivity to cisplatin-induced ototoxicity.
MATERIALS AND METHODS: The mtDNA of 20 patients with and 19 patients without 
hearing impairment under therapeutic doses of cisplatin was sequenced for 
mutations and characterized for haplotype by restriction analysis.
RESULTS: Neither the A7445G mutation, nor the 7472insC insertion or the A1555G 
mutation were identified in any of the patients. Nucleotide variations in the 
variable D-loop region did not correlate with cisplatin-induced hearing loss. 
However, these patients clustered more frequently (5 out of 20) in the rare 
European haplogroup J, than those with normal hearing after therapy (1 out of 
19).
CONCLUSION: The linkage of cisplatin-induced hearing impairment to the 
mitochondrial haplogroup J, which is also associated with the 
mitochondrially-mediated Leber's Hereditary Optic Neuropathy, might act as a 
predisponsing genetic background for biochemical differences in mitochondria.

PMID: 12820379 [Indexed for MEDLINE]


564. Front Neurosci. 2023 Feb 2;17:1075368. doi: 10.3389/fnins.2023.1075368. 
eCollection 2023.

Cortical-brainstem interplay during speech perception in older adults with and 
without hearing loss.

Lai J(1)(2)(3), Alain C(4)(5), Bidelman GM(1)(2)(6)(7).

Author information:
(1)Institute for Intelligent Systems, University of Memphis, Memphis, TN, United 
States.
(2)School of Communication Sciences and Disorders, University of Memphis, 
Memphis, TN, United States.
(3)Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 
Memphis, TN, United States.
(4)Rotman Research Institute, Baycrest Centre for Geriatric Care, Toronto, ON, 
Canada.
(5)Department of Psychology, University of Toronto, Toronto, ON, Canada.
(6)Department of Speech, Language, and Hearing Sciences, Indiana University, 
Bloomington, IN, United States.
(7)Program in Neuroscience, Indiana University, Bloomington, IN, United States.

INTRODUCTION: Real time modulation of brainstem frequency-following responses 
(FFRs) by online changes in cortical arousal state via the corticofugal 
(top-down) pathway has been demonstrated previously in young adults and is more 
prominent in the presence of background noise. FFRs during high cortical arousal 
states also have a stronger relationship with speech perception. Aging is 
associated with increased auditory brain responses, which might reflect degraded 
inhibitory processing within the peripheral and ascending pathways, or changes 
in attentional control regulation via descending auditory pathways. Here, we 
tested the hypothesis that online corticofugal interplay is impacted by 
age-related hearing loss.
METHODS: We measured EEG in older adults with normal-hearing (NH) and mild to 
moderate hearing-loss (HL) while they performed speech identification tasks in 
different noise backgrounds. We measured α power to index online cortical 
arousal states during task engagement. Subsequently, we split brainstem 
speech-FFRs, on a trial-by-trial basis, according to fluctuations in concomitant 
cortical α power into low or high α FFRs to index cortical-brainstem modulation.
RESULTS: We found cortical α power was smaller in the HL than the NH group. In 
NH listeners, α-FFRs modulation for clear speech (i.e., without noise) also 
resembled that previously observed in younger adults for speech in noise. 
Cortical-brainstem modulation was further diminished in HL older adults in the 
clear condition and by noise in NH older adults. Machine learning classification 
showed low α FFR frequency spectra yielded higher accuracy for classifying 
listeners' perceptual performance in both NH and HL participants. Moreover, low 
α FFRs decreased with increased hearing thresholds at 0.5-2 kHz for clear speech 
but noise generally reduced low α FFRs in the HL group.
DISCUSSION: Collectively, our study reveals cortical arousal state actively 
shapes brainstem speech representations and provides a potential new mechanism 
for older listeners' difficulties perceiving speech in cocktail party-like 
listening situations in the form of a miss-coordination between cortical and 
subcortical levels of auditory processing.

Copyright © 2023 Lai, Alain and Bidelman.

DOI: 10.3389/fnins.2023.1075368
PMCID: PMC9932544
PMID: 36816123

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


565. Otol Neurotol. 2018 Dec;39(10):e1060-e1063. doi: 10.1097/MAO.0000000000001996.

Case Report of a New Coupler for Round Window Application of an Active Middle 
Ear Implant.

Lenarz T(1)(2), Zimmermann D(1), Maier H(1)(2), Busch S(1)(2).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School.
(2)Cluster of Excellence EXC 1077/1 "Hearing4all", Hannover, Germany.

OBJECTIVES: To evaluate feasibility, surgical handling, audiological outcome, 
and coupling efficiency of a new coupler (custom-made device) for an active 
middle ear implant.
PATIENT: Revision surgery after implantation of an active middle ear implant in 
a 66-year-old male patient with mixed hearing loss.
INTERVENTION: Prosthetic hearing rehabilitation with a new coupler for round 
window application.
MAIN OUTCOME AND RESULTS: The patient obtained good speech perception in quiet 
(word recognition scores 80%; Freiburg monosyllables) and noise (-3.3 dB SNR; 
Oldenburg Sentence Test). The effective gain with the Hannover coupler improved 
at frequencies > 0.5 kHz compared with the values reported for other round 
window (RW)-coupling modalities.
CONCLUSION: The coupler provides a feasible option for the RW application of the 
middle ear implant actuator. The spring concept of the coupler needs to be 
improved to further standardize RW-coupling and improve coupling efficiency at 
low frequencies (0.5 kHz).

DOI: 10.1097/MAO.0000000000001996
PMID: 30239437 [Indexed for MEDLINE]


566. Ear Nose Throat J. 2021 Jun;100(3_suppl):204S-206S. doi: 
10.1177/0145561320987642. Epub 2021 Jan 18.

3D Printing of a BAHA Protective Cap.

Siu AKY(1)(2), Lee LPY(3), Leung SML(4).

Author information:
(1)Paediatric Otorhinolaryngology, Kowloon East Cluster, Hospital Authority, 
Hong Kong.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, the Chinese 
University of Hong Kong, Hong Kong.
(3)Department of Paediatrics and Adolescent Medicine, 36621United Christian 
Hospital, Kowloon East Cluster, Hospital Authority, Hong Kong.
(4)Occupational Therapy, 36621United Christian Hospital, Kowloon East Cluster, 
Hospital Authority, Hong Kong.

Mechanical feedback is one of the most common difficulties encountered when 
fitting hearing aids for toddlers and young children. We described the use of 3D 
printing to tailor a protective cap for a toddler with bilateral microtia/canal 
atresia to facilitate bone-anchoring hearing aid use.

DOI: 10.1177/0145561320987642
PMID: 33459563 [Indexed for MEDLINE]


567. J Assoc Res Otolaryngol. 2008 Jun;9(2):225-40. doi: 10.1007/s10162-008-0119-x. 
Epub 2008 May 1.

Transplantation of mouse embryonic stem cells into the cochlea of an 
auditory-neuropathy animal model: effects of timing after injury.

Lang H(1), Schulte BA, Goddard JC, Hedrick M, Schulte JB, Wei L, Schmiedt RA.

Author information:
(1)Department of Pathology and Laboratory Medicine, Medical University of South 
Carolina, 165 Ashley Avenue, P.O. Box 250908, Charleston, SC 29425, USA. 
langh@musc.edu

Application of ouabain to the round window membrane of the gerbil selectively 
induces the death of most spiral ganglion neurons and thus provides an excellent 
model for investigating the survival and differentiation of embryonic stem cells 
(ESCs) introduced into the inner ear. In this study, mouse ESCs were pretreated 
with a neural-induction protocol and transplanted into Rosenthal's canal (RC), 
perilymph, or endolymph of Mongolian gerbils either 1-3 days (early post-injury 
transplant group) or 7 days or longer (late post-injury transplant group) after 
ouabain injury. Overall, ESC survival in RC and perilymphatic spaces was 
significantly greater in the early post-injury microenvironment as compared to 
the later post-injury condition. Viable clusters of ESCs within RC and 
perilymphatic spaces appeared to be associated with neovascularization in the 
early post-injury group. A small number of ESCs transplanted within RC stained 
for mature neuronal or glial cell markers. ESCs introduced into perilymph 
survived in several locations, but most differentiated into glia-like cells. 
ESCs transplanted into endolymph survived poorly if at all. These experiments 
demonstrate that there is an optimal time window for engraftment and survival of 
ESCs that occurs in the early post-injury period.

DOI: 10.1007/s10162-008-0119-x
PMCID: PMC2504604
PMID: 18449604 [Indexed for MEDLINE]


568. Eur Ann Otorhinolaryngol Head Neck Dis. 2016 Jun;133 Suppl 1:S1-3. doi: 
10.1016/j.anorl.2016.04.015. Epub 2016 Jun 1.

ECAP analysis in cochlear implant patients as a function of patient's age and 
electrode-design.

Christov F(1), Munder P(2), Berg L(2), Bagus H(2), Lang S(2), Arweiler-Harbeck 
D(2).

Author information:
(1)Department for head and neck surgery, Universitätsklinikum, Essen, Germany. 
Electronic address: florian.christov@uk-essen.de.
(2)Department for head and neck surgery, Universitätsklinikum, Essen, Germany.

INTRODUCTION: Electric compound action potentials (ECAPs) provide information 
about the nerve's and device's function in and after cochlear implantation. In 
general, lower ECAP values are expected to generate better results. Aim was an 
analysis of ECAPs in the course of time as a function of the patient's age and 
electrode design.
PATIENTS AND METHODS: Between 2008 and 2013, 168 patients of eight defined age 
groups were included into the investigation. NRTs were measured 
intraoperatively, after 6 and after 12months.
RESULTS: The intraoperative mean value of ECAP was 174.14CL (current level) and 
decreased after 6months to 156.38CL. Highest ECAPs were achieved 
intraoperatively in the clusters "younger than 18months" (181.04CL) and "older 
than 80 years" (190.45CL). CI 422 showed apparently higher ECAP thresholds 
(182.69) during surgery than CI 24 RE (171.47) and CI 512 (170.64).
CONCLUSION: ECAPs are a well-established method to get information about the 
CI's and nerve's function during and after surgery. After initial higher values 
NRTs decrease after 6months and remain stable in the following controls. Very 
young and older patients tend to have higher thresholds than middle-aged groups. 
Perimodiolar electrodes are significantly attached to lower values because there 
is a closer nerve-electrode interaction.

Copyright © 2016 Elsevier Masson SAS. All rights reserved.

DOI: 10.1016/j.anorl.2016.04.015
PMID: 27262349 [Indexed for MEDLINE]


569. Cell Tissue Res. 2015 Jul;361(1):279-94. doi: 10.1007/s00441-014-2059-6. Epub 
2014 Dec 19.

Auditory feedback modulates development of kitten vocalizations.

Hubka P(1), Konerding W, Kral A.

Author information:
(1)Institute of AudioNeuroTechnology and Department of Experimental Otology, ENT 
Clinics, Cluster of Excellence 'Hearing4all', Hannover Medical School, 
Feodor-Lynen-Str. 35, 30175, Hannover, Germany.

Effects of hearing loss on vocal behavior are species-specific. To study the 
impact of auditory feedback on feline vocal behavior, vocalizations of 
normal-hearing, hearing-impaired (white) and congenitally deaf (white) cats were 
analyzed at around weaning age. Eleven animals were placed in a soundproof booth 
for 30 min at different ages, from the first to the beginning of the fourth 
postnatal month, every 2 weeks of life. In total, 13,874 vocalizations were 
analyzed using an automated procedure. Firstly, vocalizations were detected and 
segmented, with voiced and unvoiced vocalizations being differentiated. The 
voiced isolation calls ('meow') were further analyzed. These vocalizations 
showed developmental changes affecting several parameters in hearing controls, 
whereas the developmental sequence was delayed in congenitally deaf cats. In 
hearing-impaired and deaf animals, we observed differences both in vocal 
behavior (loudness and duration) and in the calls' acoustic structure 
(fundamental frequency and higher harmonics). The fundamental frequency 
decreased with age in all groups, most likely due to maturation of the vocal 
apparatus. In deaf cats, however, other aspects of the acoustic structure of the 
vocalizations did not fully mature. The harmonic ratio (i.e., frequency of first 
harmonic divided by fundamental frequency) was higher and more variable in deaf 
cats than in the other study groups. Auditory feedback thus affects the acoustic 
structure of vocalizations and their ontogenetic development. The study suggests 
that both the vocal apparatus and its neuronal motor control are subject to 
maturational processes, whereas the latter is additionally dependent on auditory 
feedback in cats.

DOI: 10.1007/s00441-014-2059-6
PMCID: PMC4487352
PMID: 25519045 [Indexed for MEDLINE]


570. Hear Res. 2021 May;404:108215. doi: 10.1016/j.heares.2021.108215. Epub 2021 Feb 
21.

Sex difference in the efferent inner hair cell synapses of the aging murine 
cochlea.

Dondzillo A(1), Takeda H(2), Gubbels SP(3).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, School of Medicine, 
University of Colorado Anschutz Medical Campus, Aurora, CO, USA. Electronic 
address: anna.dondzillo@ucdenver.edu.
(2)Department of Otolaryngology-Head and Neck Surgery, School of Medicine, 
University of Colorado Anschutz Medical Campus, Aurora, CO, USA; Departments of 
Otolaryngology-Head and Neck Surgery, Kumamoto University Graduate School of 
Medicine, Kumamoto city, Japan.
(3)Department of Otolaryngology-Head and Neck Surgery, School of Medicine, 
University of Colorado Anschutz Medical Campus, Aurora, CO, USA.

Efferent innervation of the inner hair cells changes over time. At an early age 
in mice, inner hair cells receive efferent feedback, which helps fine-tune 
tonotopic maps in the brainstem. In adulthood, inner hair cell efferent 
innervation wanes but increases again in older animals. It is not clear, 
however, whether age-related inner hair cell efferents increase along the entire 
range of the cochlear frequencies, or if this increase is restricted to a 
particular frequency-region, and whether this phenomenon occurs in both sexes. 
Age-related hearing loss, presbycusis, affects men and women differently. In 
mice, this difference is also strain specific. In aging black six mice, the 
auditory brainstem response thresholds increase in females earlier than in 
males. Here, we study age-related increase of the inner hair cell efferent 
innervation throughout the cochlea before hearing onset, in one month old and in 
ten months old and older male and female black six mice. We collected confocal 
images of immunostained inner hair cell efferents and quantified the labeled 
terminals in the entire cochlea using a machine learning algorithm. The overall 
number of the inner hair cell efferents in both sexes did not change 
significantly between age-groups. The distribution of the inner hair cell 
efferent innervation did not differ across frequencies in the cochlea. However, 
in females, inner hair cells received on average up to four times more efferent 
innervation than in males per each of the frequency regions tested. Sex 
differences were also found in the oldest age-group tested (≥ 10 months) where 
on average inner hair cells received six times more efferents in females than in 
males of matching age. Our findings emphasize the importance of including both 
sexes in sensorineural hearing loss research.

Copyright © 2021 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2021.108215
PMCID: PMC8143057
PMID: 33677192 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest S.P.G. is a 
consultant for Cochlear Corporation and Sirocco Therapeutics. In addition, he is 
on the advisory board for the Cystic Fibrosis Foundation and Pipeline 
Therapeutics and receives research support without personal financial 
remuneration from Med-El Corporation. A.D. and H.T. have no competing interests.


571. Neurosci Biobehav Rev. 2017 Jun;77:194-208. doi: 
10.1016/j.neubiorev.2017.03.009. Epub 2017 Mar 19.

Acoustic startle modification as a tool for evaluating auditory function of the 
mouse: Progress, pitfalls, and potential.

Lauer AM(1), Behrens D(2), Klump G(2).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery and Center for Hearing and 
Balance, Johns Hopkins University, 515 Traylor Building, 720 Rutland Ave., 
Baltimore, MD 21205, USA. Electronic address: alauer2@jhmi.edu.
(2)Cluster of Excellence Hearing4all, Animal Physiology & Behavior Group, 
Department for Neuroscience, School of Medicine and Health Sciences, Carl Von 
Ossietzky University Oldenburg, Carl Von Ossietzky Str. 9-11, 26111 Oldenburg, 
Germany.

Acoustic startle response (ASR) modification procedures, especially prepulse 
inhibition (PPI), are increasingly used as behavioral measures of auditory 
processing and sensorimotor gating in rodents due to their perceived ease of 
implementation and short testing times. In practice, ASR and PPI procedures are 
extremely variable across animals, experimental setups, and studies, and the 
interpretation of results is subject to numerous caveats and confounding 
influences. We review considerations for modification of the ASR using acoustic 
stimuli, and we compare the sensitivity of PPI procedures to more traditional 
operant psychoacoustic techniques. We also discuss non-auditory variables that 
must be considered. We conclude that ASR and PPI measures cannot substitute for 
traditional operant techniques due to their low sensitivity. Additionally, a 
substantial amount of pilot testing must be performed to properly optimize an 
ASR modification experiment, negating any time benefit over operant 
conditioning. Nevertheless, there are some circumstances where ASR measures may 
be the only option for assessing auditory behavior, such as when testing mouse 
strains with early-onset hearing loss or learning impairments.

Copyright © 2017 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neubiorev.2017.03.009
PMCID: PMC5446932
PMID: 28327385 [Indexed for MEDLINE]


572. Proc Natl Acad Sci U S A. 2015 Jun 16;112(24):E3141-9. doi: 
10.1073/pnas.1417207112. Epub 2015 Jun 1.

Rab3-interacting molecules 2α and 2β promote the abundance of voltage-gated 
CaV1.3 Ca2+ channels at hair cell active zones.

Jung S(1), Oshima-Takago T(2), Chakrabarti R(3), Wong AB(4), Jing Z(5), 
Yamanbaeva G(5), Picher MM(6), Wojcik SM(7), Göttfert F(8), Predoehl F(9), 
Michel K(10), Hell SW(11), Schoch S(10), Strenzke N(12), Wichmann C(13), Moser 
T(14).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany; Center for Nanoscale Microscopy and 
Molecular Physiology of the Brain, University of Göttingen, 37099 Göttingen, 
Germany;
(2)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany; Sensory and Motor Neuroscience 
Program, Göttingen Graduate School for Neurosciences, Biophysics and Molecular 
Biosciences, University of Göttingen, 37099 Göttingen, Germany;
(3)Sensory and Motor Neuroscience Program, Göttingen Graduate School for 
Neurosciences, Biophysics and Molecular Biosciences, University of Göttingen, 
37099 Göttingen, Germany; Molecular Architecture of Synapses Group, Institute 
for Auditory Neuroscience and InnerEarLab, University Medical Center Göttingen, 
37099 Göttingen, Germany; Collaborative Sensory Research Center 889, University 
of Göttingen, 37099 Göttingen, Germany;
(4)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany; Sensory and Motor Neuroscience 
Program, Göttingen Graduate School for Neurosciences, Biophysics and Molecular 
Biosciences, University of Göttingen, 37099 Göttingen, Germany; Collaborative 
Sensory Research Center 889, University of Göttingen, 37099 Göttingen, Germany;
(5)Sensory and Motor Neuroscience Program, Göttingen Graduate School for 
Neurosciences, Biophysics and Molecular Biosciences, University of Göttingen, 
37099 Göttingen, Germany; Collaborative Sensory Research Center 889, University 
of Göttingen, 37099 Göttingen, Germany; Auditory Systems Physiology Group, 
InnerEarLab, Department of Otolaryngology, University of Göttingen Medical 
Center, 37099 Göttingen, Germany;
(6)Sensory and Motor Neuroscience Program, Göttingen Graduate School for 
Neurosciences, Biophysics and Molecular Biosciences, University of Göttingen, 
37099 Göttingen, Germany; Collaborative Sensory Research Center 889, University 
of Göttingen, 37099 Göttingen, Germany; Bernstein Center for Computational 
Neuroscience, University of Göttingen, 37073 Göttingen, Germany;
(7)Department of Molecular Neurobiology, Max Planck Institute for Experimental 
Medicine, 37075 Göttingen, Germany;
(8)Sensory and Motor Neuroscience Program, Göttingen Graduate School for 
Neurosciences, Biophysics and Molecular Biosciences, University of Göttingen, 
37099 Göttingen, Germany; Department of Nanobiophotonics, Max Planck Institute 
for Biophysical Chemistry, 37077 Göttingen, Germany;
(9)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany;
(10)Institute of Neuropathology, University of Bonn, 53111 Bonn, Germany; 
Department of Epileptology, University of Bonn, 53111 Bonn, Germany.
(11)Center for Nanoscale Microscopy and Molecular Physiology of the Brain, 
University of Göttingen, 37099 Göttingen, Germany; Department of 
Nanobiophotonics, Max Planck Institute for Biophysical Chemistry, 37077 
Göttingen, Germany;
(12)Collaborative Sensory Research Center 889, University of Göttingen, 37099 
Göttingen, Germany; Auditory Systems Physiology Group, InnerEarLab, Department 
of Otolaryngology, University of Göttingen Medical Center, 37099 Göttingen, 
Germany; tmoser@gwdg.de NStrenzke@med.uni-goettingen.de cwichma@gwdg.de.
(13)Molecular Architecture of Synapses Group, Institute for Auditory 
Neuroscience and InnerEarLab, University Medical Center Göttingen, 37099 
Göttingen, Germany; Collaborative Sensory Research Center 889, University of 
Göttingen, 37099 Göttingen, Germany; tmoser@gwdg.de 
NStrenzke@med.uni-goettingen.de cwichma@gwdg.de.
(14)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany; Center for Nanoscale Microscopy and 
Molecular Physiology of the Brain, University of Göttingen, 37099 Göttingen, 
Germany; Collaborative Sensory Research Center 889, University of Göttingen, 
37099 Göttingen, Germany; Bernstein Center for Computational Neuroscience, 
University of Göttingen, 37073 Göttingen, Germany; tmoser@gwdg.de 
NStrenzke@med.uni-goettingen.de cwichma@gwdg.de.

Ca(2+) influx triggers the fusion of synaptic vesicles at the presynaptic active 
zone (AZ). Here we demonstrate a role of Ras-related in brain 3 
(Rab3)-interacting molecules 2α and β (RIM2α and RIM2β) in clustering 
voltage-gated CaV1.3 Ca(2+) channels at the AZs of sensory inner hair cells 
(IHCs). We show that IHCs of hearing mice express mainly RIM2α, but also RIM2β 
and RIM3γ, which all localize to the AZs, as shown by immunofluorescence 
microscopy. Immunohistochemistry, patch-clamp, fluctuation analysis, and 
confocal Ca(2+) imaging demonstrate that AZs of RIM2α-deficient IHCs cluster 
fewer synaptic CaV1.3 Ca(2+) channels, resulting in reduced synaptic Ca(2+) 
influx. Using superresolution microscopy, we found that Ca(2+) channels remained 
clustered in stripes underneath anchored ribbons. Electron tomography of 
high-pressure frozen synapses revealed a reduced fraction of membrane-tethered 
vesicles, whereas the total number of membrane-proximal vesicles was unaltered. 
Membrane capacitance measurements revealed a reduction of exocytosis largely in 
proportion with the Ca(2+) current, whereas the apparent Ca(2+) dependence of 
exocytosis was unchanged. Hair cell-specific deletion of all RIM2 isoforms 
caused a stronger reduction of Ca(2+) influx and exocytosis and significantly 
impaired the encoding of sound onset in the postsynaptic spiral ganglion 
neurons. Auditory brainstem responses indicated a mild hearing impairment on 
hair cell-specific deletion of all RIM2 isoforms or global inactivation of 
RIM2α. We conclude that RIM2α and RIM2β promote a large complement of synaptic 
Ca(2+) channels at IHC AZs and are required for normal hearing.

DOI: 10.1073/pnas.1417207112
PMCID: PMC4475996
PMID: 26034270 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


573. Front Neurosci. 2023 Nov 14;17:1238941. doi: 10.3389/fnins.2023.1238941. 
eCollection 2023.

Altered neural encoding of vowels in noise does not affect behavioral vowel 
discrimination in gerbils with age-related hearing loss.

Heeringa AN(1), Jüchter C(1), Beutelmann R(1), Klump GM(1), Köppl C(1).

Author information:
(1)Research Centre Neurosensory Science and Cluster of Excellence "Hearing4all", 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, Oldenburg, Germany.

INTRODUCTION: Understanding speech in a noisy environment, as opposed to speech 
in quiet, becomes increasingly more difficult with increasing age. Using the 
quiet-aged gerbil, we studied the effects of aging on speech-in-noise 
processing. Specifically, behavioral vowel discrimination and the encoding of 
these vowels by single auditory-nerve fibers were compared, to elucidate some of 
the underlying mechanisms of age-related speech-in-noise perception deficits.
METHODS: Young-adult and quiet-aged Mongolian gerbils, of either sex, were 
trained to discriminate a deviant naturally-spoken vowel in a sequence of vowel 
standards against a speech-like background noise. In addition, we recorded 
responses from single auditory-nerve fibers of young-adult and quiet-aged 
gerbils while presenting the same speech stimuli.
RESULTS: Behavioral vowel discrimination was not significantly affected by 
aging. For both young-adult and quiet-aged gerbils, the behavioral 
discrimination between /eː/ and /iː/ was more difficult to make than /eː/ vs. 
/aː/ or /iː/ vs. /aː/, as evidenced by longer response times and lower d' 
values. In young-adults, spike timing-based vowel discrimination agreed with the 
behavioral vowel discrimination, while in quiet-aged gerbils it did not. 
Paradoxically, discrimination between vowels based on temporal responses was 
enhanced in aged gerbils for all vowel comparisons. Representation schemes, 
based on the spectrum of the inter-spike interval histogram, revealed stronger 
encoding of both the fundamental and the lower formant frequencies in fibers of 
quiet-aged gerbils, but no qualitative changes in vowel encoding. Elevated 
thresholds in combination with a fixed stimulus level, i.e., lower sensation 
levels of the stimuli for old individuals, can explain the enhanced temporal 
coding of the vowels in noise.
DISCUSSION: These results suggest that the altered auditory-nerve discrimination 
metrics in old gerbils may mask age-related deterioration in the central 
(auditory) system to the extent that behavioral vowel discrimination matches 
that of the young adults.

Copyright © 2023 Heeringa, Jüchter, Beutelmann, Klump and Köppl.

DOI: 10.3389/fnins.2023.1238941
PMCID: PMC10682387
PMID: 38033551

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


574. J Neural Eng. 2009 Dec;6(6):065003. doi: 10.1088/1741-2560/6/6/065003. Epub 2009 
Oct 23.

Neural synchrony in ventral cochlear nucleus neuron populations is not mediated 
by intrinsic processes but is stimulus induced: implications for auditory 
brainstem implants.

Shivdasani MN(1), Mauger SJ, Rathbone GD, Paolini AG.

Author information:
(1)School of Psychological Science, La Trobe University, Bundoora, VIC 3086, 
Australia.

The aim of this investigation was to elucidate if neural synchrony forms part of 
the spike time-based theory for coding of sound information in the ventral 
cochlear nucleus (VCN) of the auditory brainstem. Previous research attempts to 
quantify the degree of neural synchrony at higher levels of the central auditory 
system have indicated that synchronized firing of neurons during presentation of 
an acoustic stimulus could play an important role in coding complex sound 
features. However, it is unknown whether this synchrony could in fact arise from 
the VCN as it is the first station in the central auditory pathway. 
Cross-correlation analysis was conducted on 499 pairs of multiunit clusters 
recorded in the urethane-anesthetized rat VCN in response to pure tones and 
combinations of two tones to determine the presence of neural synchrony. The 
shift predictor correlogram was used as a measure for determining the synchrony 
owing to the effects of the stimulus. Without subtraction of the shift 
predictor, over 65% of the pairs of multiunit clusters exhibited significant 
correlation in neural firing when the frequencies of the tones presented matched 
their characteristic frequencies (CFs). In addition, this stimulus-evoked neural 
synchrony was dependent on the physical distance between electrode sites, and 
the CF difference between multiunit clusters as the number of correlated pairs 
dropped significantly for electrode sites greater than 800 microm apart and for 
multiunit cluster pairs with a CF difference greater than 0.5 octaves. However, 
subtraction of the shift predictor correlograms from the raw correlograms 
resulted in no remaining correlation between all VCN pairs. These results 
suggest that while neural synchrony may be a feature of sound coding in the VCN, 
it is stimulus induced and not due to intrinsic neural interactions within the 
nucleus. These data provide important implications for stimulation strategies 
for the auditory brainstem implant, which is used to provide functional hearing 
to the profoundly deaf through electrical stimulation of the VCN.

DOI: 10.1088/1741-2560/6/6/065003
PMID: 19850978 [Indexed for MEDLINE]


575. PLoS One. 2016 Oct 14;11(10):e0164470. doi: 10.1371/journal.pone.0164470. 
eCollection 2016.

Measuring Disability in Population Based Surveys: The Interrelationship between 
Clinical Impairments and Reported Functional Limitations in Cameroon and India.

Mactaggart I(1), Kuper H(1), Murthy GV(2), Oye J(3), Polack S(1).

Author information:
(1)International Centre for Evidence in Disability, London School of Hygiene & 
Tropical Medicine, London, United Kingdom.
(2)Indian Institute of Public Health, Hyderabad, India.
(3)Sightsavers Cameroon, Yaoundé, Cameroon.

PURPOSE: To investigate the relationship between two distinct measures of 
disability: self-reported functional limitations and objectively-screened 
clinical impairments.
METHODS: We undertook an all age population-based survey of disability in two 
areas: North-West Cameroon (August/October 2013) and Telangana State, India 
(Feb/April 2014). Participants were selected for inclusion via two-stage cluster 
randomised sampling (probability proportionate to size cluster selection and 
compact segment sampling within clusters). Disability was defined as the 
presence of self-reported functional limitations across eight domains, or 
presence of moderate or greater clinical impairments. Clinical impairment 
screening comprised of visual acuity testing for vision impairment, pure tone 
audiometry for hearing impairment, musculoskeletal functioning assessment for 
musculoskeletal impairment, reported seizure history for epilepsy and reported 
symptoms of clinical depression (depression adults only). Information was 
collected using structured questionnaires, observations and examinations.
RESULTS: Self-reported disability prevalence was 5.9% (95% CI 4.7-7.4) and 7.5% 
(5.9-9.4) in Cameroon and India respectively. The prevalence of moderate or 
greater clinical impairments in the same populations were 8.4% (7.5-9.4) in 
Cameroon and 10.5% (9.4-11.7) in India. Overall disability prevalence 
(self-report and/or screened positive to a moderate or greater clinical 
impairment) was 10.5% in Cameroon and 12.2% in India, with limited overlap 
between the sub-populations identified using the two types of tools. 33% of 
participants in Cameroon identified to have a disability, and 45% in India, both 
reported functional limitations and screened positive to objectively-screened 
impairments, whilst the remainder were identified via one or other tool only. A 
large proportion of people with moderate or severe clinical impairments did not 
self-report functional difficulties despite reporting participation 
restrictions.
CONCLUSION: Tools to assess reported functional limitation alone are 
insufficient to identify all persons with participation restrictions and 
moderate or severe clinical impairments. A self-reported functional limitation 
tool followed by clinical screening of all those who report any level of 
difficulty would identify 94% of people with disabilities in Cameroon and 95% in 
India, meeting the study criteria.

DOI: 10.1371/journal.pone.0164470
PMCID: PMC5065175
PMID: 27741320 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


576. Patient Educ Couns. 2017 Aug;100(8):1490-1498. doi: 10.1016/j.pec.2017.03.022. 
Epub 2017 Mar 18.

Audiologist-patient communication profiles in hearing rehabilitation 
appointments.

Meyer C(1), Barr C(2), Khan A(3), Hickson L(4).

Author information:
(1)HEARing CRC, Australia; School of Health and Rehabilitation Sciences, 
University of Queensland, Brisbane, Australia. Electronic address: 
carlyjmeyer@outlook.com.
(2)HEARing CRC, Australia; Department of Audiology and Speech Pathology, 
University of Melbourne, Melbourne, Australia. Electronic address: 
barrcm@unimelb.edu.au.
(3)HEARing CRC, Australia; School of Health and Rehabilitation Sciences, 
University of Queensland, Brisbane, Australia. Electronic address: 
a.khan2@uq.edu.au.
(4)HEARing CRC, Australia; School of Health and Rehabilitation Sciences, 
University of Queensland, Brisbane, Australia. Electronic address: 
l.hickson@uq.edu.au.

OBJECTIVE: To profile the communication between audiologists and patients in 
initial appointments on a biomedical-psychosocial continuum; and explore the 
associations between these profiles and 1) characteristics of the appointment 
and 2) patients' decisions to pursue hearing aids.
METHODS: Sixty-three initial hearing assessment appointments were filmed and 
audiologist-patient communication was coded using the Roter Interaction Analysis 
System. A hierarchical cluster analysis was conducted to profile 
audiologist-patient communication, after which regression modelling and 
Chi-squared analyses were conducted.
RESULTS: Two distinct audiologist-patient communication profiles were identified 
during both the history taking phase (46=biopsychosocial profile, 
15=psychosocial profile) and diagnosis and management planning phase 
(45=expanded biomedical profile, 11=narrowly biomedical profile). Longer 
appointments were significantly more likely to be associated with an expanded 
biomedical interaction during the diagnosis and management planning phase. No 
significant associations were found between audiologist-patient communication 
profile and patients' decisions to pursue hearing aids.
CONCLUSION: Initial audiology consultations appear to remain clinician-centred. 
Three quarters of appointments began with a biopsychosocial interaction; 
however, 80% ended with an expanded biomedical interaction.
PRACTICE IMPLICATIONS: Findings suggest that audiologists could consider 
modifying their communication in initial appointments to more holistically 
address the needs of patients.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.pec.2017.03.022
PMID: 28372897 [Indexed for MEDLINE]


577. J Korean Med Sci. 2023 Mar 27;38(12):e82. doi: 10.3346/jkms.2023.38.e82.

Development of Novel Musical Stimuli to Investigate the Perception of Musical 
Emotions in Individuals With Hearing Loss.

Lee J(1)(2), Han JH(1)(2), Lee HJ(1)(2)(3).

Author information:
(1)Laboratory of Brain & Cognitive Sciences for Convergence Medicine, Hallym 
University College of Medicine, Anyang, Korea.
(2)Ear and Interaction Center, Doheun Institute for Digital Innovation in 
Medicine (D.I.D.I.M.), Hallym University Medical Center, Anyang, Korea.
(3)Department of Otorhinolaryngology, Hallym University College of Medicine, 
Chuncheon, Korea. hyojlee@hallym.ac.kr.

BACKGROUND: Many studies have examined the perception of musical emotion using 
excerpts from familiar music that includes highly expressed emotions to classify 
emotional choices. However, using familiar music to study musical emotions in 
people with acquired hearing loss could produce ambiguous results as to whether 
the emotional perception is due to previous experiences or listening to the 
current musical stimuli. To overcome this limitation, we developed new musical 
stimuli to study emotional perception without the effects of episodic memory.
METHODS: A musician was instructed to compose five melodies with evenly 
distributed pitches around 1 kHz. The melodies were created to express the 
emotions of happy, sad, angry, tender, and neutral. To evaluate whether these 
melodies expressed the intended emotions, two methods were applied. First, we 
classified the expressed emotions of melodies with selected musical features 
from 60 features using genetic algorithm-based k-nearest neighbors. Second, 
forty-four people with normal hearing participated in an online survey regarding 
the emotional perception of music based on dimensional and discrete approaches 
to evaluate the musical stimuli set.
RESULTS: Twenty-four selected musical features produced classification for 
intended emotions with an accuracy of 76%. The results of the online survey in 
the normal hearing (NH) group showed that the intended emotions were selected 
significantly more often than the others. K-means clustering analysis revealed 
that melodies with arousal and valence ratings corresponded to representative 
quadrants of interest. Additionally, the applicability of the stimuli was tested 
in 4 individuals with high-frequency hearing loss.
CONCLUSION: By applying the individuals with NH, the musical stimuli were shown 
to classify emotions with high accuracy, as expressed. These results confirm 
that the set of musical stimuli can be used to study the perceived emotion in 
music, demonstrating the validity of the musical stimuli, independent of innate 
musical bias such as due to episodic memory. Furthermore, musical stimuli could 
be helpful for further studying perceived musical emotion in people with hearing 
loss because of the controlled pitch for each emotion.

© 2023 The Korean Academy of Medical Sciences.

DOI: 10.3346/jkms.2023.38.e82
PMCID: PMC10042730
PMID: 36974396 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no potential conflicts of 
interest to disclose.


578. Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi. 2020 Jun 20;38(6):420-423. doi: 
10.3760/cma.j.cn121094-20191009-00470.

[Combined effect of noise and hand-transmitted vibration on noise-induced 
hearing loss in the automobile manufacturing industry].

[Article in Chinese; Abstract available in Chinese from the publisher]

Duan DP(1), Bai LX(1), Qiu CX(1), Huang TY(2), Tang SH(3), Liu YM(4).

Author information:
(1)Occupational Health Monitoring Center of Occupational Disease Prevention and 
Treatment Hospital, Guangzhou 510620, China.
(2)Prevention and Control Department of Chronic Non Infectious Diseases, 
Guangzhou Center for Disease Control and Prevention, Guangzhou 510440, China.
(3)Evaluation and Testing Center of Occupational Disease Prevention and 
Treatment Hospital, Guangzhou 510620, China.
(4)Occupational Health Monitoring Center of Occupational Disease Prevention and 
Treatment Hospital, Guangzhou 510620, China; Institute of Occupational and 
Environmental Health, Guangzhou Medical University, Guangzhou 510180, China.

Objective: To investigate the combined effect of noise and hand-transmitted 
vibration on noise-induced hearing loss (NIHL) in the automobile manufacturing 
industry. Methods: From September 2018 to January 2019, cluster sampling was 
used to select 998 workers in an automobile factory as study subjects, among 
whom 352 workers exposed to noise alone were enrolled as noise group, 342 
workers exposed to noise and hand-transmitted vibration were enrolled as 
combined effect group, and 304 workers without exposure to occupational 
hazardous factors were enrolled as control group. A questionnaire survey and 
pure tone audiometry were performed for all study subjects. An analysis of 
variance was used for comparison of continuous data between groups, and the 
chi-square test was used for comparison of categorical data between groups; a 
ordinal polytomous logistic regression analysis was used to investigate the 
influencing factors for NIHL (with 0.05 as the inclusion criteria and 0.10 as 
the exclusion criteria for independent variables) . Results: There was a 
significant difference in L(Aeq, 8 h) between groups (P<0.05) ; the noise group 
and the combined effect group had a significantly higher L(Aeq, 8 h) than the 
control group (P<0.05) , while there was no significant difference in L(Aeq, 8 
h) between the noise group and the combined effect group (P>0.05) . The control 
group had a significantly lower detection rate of hearing loss than the noise 
group and the combined effect group (P<0.0125) , and the combined effect group 
had a significantly higher detection rate of hearing loss than the noise group 
(P<0.0125) . The ordinal polytomous logistic regression analysis showed that 
after adjustment for confounding factors such as age, working years, sex, 
smoking, and drinking, both noise exposure and exposure to both noise and 
hand-transmitted vibration had an influence on workers' hearing (P<0.05) , and 
the workers exposed to both noise and hand-transmitted vibration had a higher 
risk of hearing loss than those exposed to noise alone. Conclusion: There may be 
a combined effect of noise and hand-transmitted vibration in the automobile 
manufacturing industry, which can increase the risk of NIHL in workers.

Publisher: 目的： 探讨汽车制造业噪声和手传振动联合作用对噪声性听力损失（NIHL）的影响。 方法： 
于2018年9月至2019年1月，采用整群抽样的方法，选择某大型汽车制造企业的998名员工为研究对象，以其中352名仅接触噪声的工人为噪声组，342名接触噪声和手传振动的工人为联合作用组，304名不接触职业病危害因素的员工为对照组。对研究对象进行问卷调查和纯音听力测试，计量资料组间差异用方差分析，计数资料组间差异用χ(2)检验；NIHL影响因素分析用有序多分类Logistic回归分析法（自变量纳入标准为0.05，剔除标准为0.10）。 
结果： 各组间L(Aeq，8 h)比较，差异有统计学意义（P<0.05）；两两比较显示，噪声组、联合作用组L(Aeq，8 
h)均高于对照组，差异均有统计学意义（P<0.05），噪声组与联合作用组L(Aeq，8 
h)比较，差异无统计学意义（P>0.05）；对照组人群听力损失检出率分别低于噪声组和联合作用组（P<0.012 
5），联合作用组人群听力损失检出率高于噪声组（P<0.012 
5）。有序多分类Logistic回归分析结果显示：在排除年龄、工龄、性别、吸烟、饮酒等混杂因素影响后，噪声接触、手传振动与噪声联合接触均对工人听力有影响（P<0.05），其中，手传振动与噪声联合接触导致听力损失的风险高于单纯噪声接触。 
结论： 汽车制造业中噪声和手传振动可能存在联合作用，可增加劳动者罹患NIHL的风险。.

DOI: 10.3760/cma.j.cn121094-20191009-00470
PMID: 32629569 [Indexed for MEDLINE]


579. Int J Med Robot. 2010 Sep;6(3):281-90. doi: 10.1002/rcs.330.

Automatic determination of optimal linear drilling trajectories for cochlear 
access accounting for drill-positioning error.

Noble JH(1), Majdani O, Labadie RF, Dawant B, Fitzpatrick JM.

Author information:
(1)Department of Electrical Engineering and Computer Science, Vanderbilt 
University, Nashville, TN 37235, USA. jack.h.noble@vanderbilt.edu

BACKGROUND: Cochlear implantation is a surgical procedure in which an electrode 
array is permanently implanted into the cochlea to stimulate the auditory nerve 
and allow deaf people to hear. Percutaneous cochlear access, a new minimally 
invasive implantation approach, requires drilling a single linear channel from 
the skull surface to the cochlea. The focus of this paper addresses a major 
challenge with this approach, which is the ability to determine, in a 
pre-operative CT, a safe and effective drilling trajectory.
METHODS: A measure of the safety and effectiveness of a given trajectory 
relative to sensitive structures is derived using a Monte Carlo approach. The 
drilling trajectory that maximizes this measure is found using an optimization 
algorithm.
RESULTS: In tests on 13 ears, the technique was shown to find approximately 
twice as many acceptable trajectories as those found manually by an experienced 
surgeon.
CONCLUSIONS: Using this method, safe trajectories can be automatically 
determined quickly and consistently.

Copyright 2010 John Wiley & Sons, Ltd.

DOI: 10.1002/rcs.330
PMCID: PMC2933923
PMID: 20812268 [Indexed for MEDLINE]


580. Trends Hear. 2018 Jan-Dec;22:2331216518763689. doi: 10.1177/2331216518763689.

Brain Volume Differences Associated With Hearing Impairment in Adults.

Alfandari D(1)(2), Vriend C(3)(4)(5), Heslenfeld DJ(6), Versfeld NJ(1)(2), 
Kramer SE(1)(2), Zekveld AA(1)(2)(7).

Author information:
(1)1 Department of Otolaryngology-Head and Neck Surgery, Section Ear & Hearing, 
VU University Medical Center, Amsterdam, the Netherlands.
(2)2 Amsterdam Public Health Research Institute, VU University Medical Center, 
the Netherlands.
(3)3 Department of Anatomy & Neurosciences, VU University Medical Center, 
Amsterdam, the Netherlands.
(4)4 Department of Psychiatry, VU University Medical Center, Amsterdam, the 
Netherlands.
(5)5 Amsterdam Neuroscience, Amsterdam, the Netherlands.
(6)6 Department of Psychology, VU University, Amsterdam, the Netherlands.
(7)7 Department of Behavioural Sciences and Learning, Linnaeus Centre HEAD, The 
Swedish Institute for Disability Research, Linköping University, Sweden.

Speech comprehension depends on the successful operation of a network of brain 
regions. Processing of degraded speech is associated with different patterns of 
brain activity in comparison with that of high-quality speech. In this 
exploratory study, we studied whether processing degraded auditory input in 
daily life because of hearing impairment is associated with differences in brain 
volume. We compared T1-weighted structural magnetic resonance images of 17 
hearing-impaired (HI) adults with those of 17 normal-hearing (NH) controls using 
a voxel-based morphometry analysis. HI adults were individually matched with NH 
adults based on age and educational level. Gray and white matter brain volumes 
were compared between the groups by region-of-interest analyses in structures 
associated with speech processing, and by whole-brain analyses. The results 
suggest increased gray matter volume in the right angular gyrus and decreased 
white matter volume in the left fusiform gyrus in HI listeners as compared with 
NH ones. In the HI group, there was a significant correlation between hearing 
acuity and cluster volume of the gray matter cluster in the right angular gyrus. 
This correlation supports the link between partial hearing loss and altered 
brain volume. The alterations in volume may reflect the operation of 
compensatory mechanisms that are related to decoding meaning from degraded 
auditory input.

DOI: 10.1177/2331216518763689
PMCID: PMC5863860
PMID: 29557274 [Indexed for MEDLINE]


581. Int J Lang Commun Disord. 2011 Sep-Oct;46(5):535-49. doi: 
10.1111/j.1460-6984.2011.00005.x. Epub 2011 Mar 7.

Objective eye-gaze behaviour during face-to-face communication with proficient 
alaryngeal speakers: a preliminary study.

Evitts P(1), Gallop R.

Author information:
(1)Department of Audiology, Speech-Language Pathology & Deaf Studies, Towson 
University, MD, USA. pevitts@towson.edu

BACKGROUND: There is a large body of research demonstrating the impact of visual 
information on speaker intelligibility in both normal and disordered speaker 
populations. However, there is minimal information on which specific visual 
features listeners find salient during conversational discourse.
AIMS: To investigate listeners' eye-gaze behaviour during face-to-face 
conversation with normal, laryngeal and proficient alaryngeal speakers.
METHODS & PROCEDURES: Sixty participants individually participated in a 10-min 
conversation with one of four speakers (typical laryngeal, tracheoesophageal, 
oesophageal, electrolaryngeal; 15 participants randomly assigned to one mode of 
speech). All speakers were > 85% intelligible and were judged to be 'proficient' 
by two certified speech-language pathologists. Participants were fitted with a 
head-mounted eye-gaze tracking device (Mobile Eye, ASL) that calculated the 
region of interest and mean duration of eye-gaze. Self-reported gaze behaviour 
was also obtained following the conversation using a 10 cm visual analogue 
scale.
OUTCOMES & RESULTS: While listening, participants viewed the lower facial region 
of the oesophageal speaker more than the normal or tracheoesophageal speaker. 
Results of non-hierarchical cluster analyses showed that while listening, the 
pattern of eye-gaze was predominantly directed at the lower face of the 
oesophageal and electrolaryngeal speaker and more evenly dispersed among the 
background, lower face, and eyes of the normal and tracheoesophageal speakers. 
Finally, results show a low correlation between self-reported eye-gaze behaviour 
and objective regions of interest data.
CONCLUSIONS & IMPLICATIONS: Overall, results suggest similar eye-gaze behaviour 
when healthy controls converse with normal and tracheoesophageal speakers and 
that participants had significantly different eye-gaze patterns when conversing 
with an oesophageal speaker. Results are discussed in terms of existing eye-gaze 
data and its potential implications on auditory-visual speech perception.

© 2011 Royal College of Speech & Language Therapists.

DOI: 10.1111/j.1460-6984.2011.00005.x
PMID: 21899671 [Indexed for MEDLINE]


582. J Neurophysiol. 2017 Feb 1;117(2):582-593. doi: 10.1152/jn.00617.2016. Epub 2016 
Nov 9.

Activity-dependent formation and location of voltage-gated sodium channel 
clusters at a CNS nerve terminal during postnatal development.

Xu J(1), Berret E(1), Kim JH(2)(3).

Author information:
(1)The Department of Physiology, University of Texas Health Science Center, San 
Antonio, Texas; and.
(2)The Department of Physiology, University of Texas Health Science Center, San 
Antonio, Texas; and kimjh@uthscsa.edu.
(3)Center for Biomedical Neuroscience, University of Texas Health Science 
Center, San Antonio, Texas.

In auditory pathways, the precision of action potential (AP) propagation depends 
on axon myelination and high densities of voltage-gated Na (Nav) channels 
clustered at nodes of Ranvier. Changes in Nav channel expression at the 
heminode, the final node before the nerve terminal, can alter AP invasion into 
the presynaptic terminal. We studied the activity-dependent formation of Nav 
channel clusters before and after hearing onset at postnatal day 12 in the rat 
and mouse auditory brain stem. In rats, the Nav channel cluster at the heminode 
formed progressively during the second postnatal week, around hearing onset, 
whereas the Nav channel cluster at the nodes was present before hearing onset. 
Initiation of heminodal Nav channel clustering was correlated with the 
expression of scaffolding protein ankyrinG and paranodal protein Caspr. However, 
in whirler mice with congenital deafness, heminodal Nav channels did not form 
clusters and maintained broad expression, but Nav channel clustering was normal 
at the nodes. In addition, a clear difference in the distance from the heminodal 
Nav channel to the calyx across the mediolateral axis of the medial nucleus of 
the trapezoid body (MNTB) developed after hearing onset. In the medial MNTB, 
where neurons respond best to high-frequency sounds, the heminodal Nav channel 
cluster was located closer to the terminal than in the lateral MNTB, where 
neurons respond best to low-frequency sounds. Thus sound-mediated neuronal 
activities are potentially associated with the refinement of the heminode 
adjacent to the presynaptic terminal in the auditory brain stem.
NEW & NOTEWORTHY: Clustering of voltage-gated sodium (Nav) channels and their 
distribution along the axon, specifically at the unmyelinated axon segment next 
to the nerve terminal, are essential for tuning propagated action potentials. 
Nav channel clusters near the nerve terminal and their location as a function of 
neuronal position along the mediolateral axis are controlled by auditory inputs 
after hearing onset. Thus sound-mediated neuronal activity influences the 
tonotopic organization of Nav channels at the nerve terminal in the auditory 
brain stem.

Copyright © 2017 the American Physiological Society.

DOI: 10.1152/jn.00617.2016
PMCID: PMC5288486
PMID: 27832602 [Indexed for MEDLINE]


583. J Cell Biol. 2004 Sep 27;166(7):983-90. doi: 10.1083/jcb.200408007. Epub 2004 
Sep 20.

BetaIVSigma1 spectrin stabilizes the nodes of Ranvier and axon initial segments.

Lacas-Gervais S(1), Guo J, Strenzke N, Scarfone E, Kolpe M, Jahkel M, De Camilli 
P, Moser T, Rasband MN, Solimena M.

Author information:
(1)Medical School, University of Technology-Dresden, Fetscherstrasse 74, 01307 
Dresden, Germany.

Saltatory electric conduction requires clustered voltage-gated sodium channels 
(VGSCs) at axon initial segments (AIS) and nodes of Ranvier (NR). A dense 
membrane undercoat is present at these sites, which is thought to be key for the 
focal accumulation of channels. Here, we prove that betaIVSigma1 spectrin, the 
only betaIV spectrin with an actin-binding domain, is an essential component of 
this coat. Specifically, betaIVSigma1 coexists with betaIVSigma6 at both AIS and 
NR, being the predominant spectrin at AIS. Removal of betaIVSigma1 alone causes 
the disappearance of the nodal coat, an increased diameter of the NR, and the 
presence of dilations filled with organelles. Moreover, in myelinated cochlear 
afferent fibers, VGSC and ankyrin G clusters appear fragmented. These 
ultrastructural changes can explain the motor and auditory neuropathies present 
in betaIVSigma1 -/- mice and point to the betaIVSigma1 spectrin isoform as a 
master-stabilizing factor of AIS/NR membranes.

DOI: 10.1083/jcb.200408007
PMCID: PMC2172023
PMID: 15381686 [Indexed for MEDLINE]


584. Acta Otolaryngol. 2009 May;129(5):533-40. doi: 10.1080/00016480802294369.

Use of telemedicine in the remote programming of cochlear implants.

Ramos A(1), Rodriguez C, Martinez-Beneyto P, Perez D, Gault A, Falcon JC, Boyle 
P.

Author information:
(1)Ear, Neck and Throat Department, Complejo Hospitalario Universitario Insular 
Materno-Infantil de Gran Canaria, Las Palmas de Gran Canaria, Spain. 
ramosorl@idecnet.com

CONCLUSION: Remote cochlear implant (CI) programming is a viable, safe, 
user-friendly and cost-effective procedure, equivalent to standard programming 
in terms of efficacy and user's perception, which can complement the standard 
procedures. The potential benefits of this technique are outlined.
OBJECTIVES: We assessed the technical viability, risks and difficulties of 
remote CI programming; and evaluated the benefits for the user comparing the 
standard on-site CI programming versus the remote CI programming.
SUBJECTS AND METHODS: The Remote Programming System (RPS) basically consists of 
completing the habitual programming protocol in a regular CI centre, assisted by 
local staff, although guided by a remote expert, who programs the CI device 
using a remote programming station that takes control of the local station 
through the Internet. A randomized prospective study has been designed with the 
appropriate controls comparing RPS to the standard on-site CI programming. Study 
subjects were implanted adults with a HiRes 90K(R) CI with post-lingual onset of 
profound deafness and 4-12 weeks of device use. Subjects underwent two daily CI 
programming sessions either remote or standard, on 4 programming days separated 
by 3 month intervals. A total of 12 remote and 12 standard sessions were 
completed. To compare both CI programming modes we analysed: program parameters, 
subjects' auditory progress, subjects' perceptions of the CI programming 
sessions, and technical aspects, risks and difficulties of remote CI 
programming.
RESULTS: Control of the local station from the remote station was carried out 
successfully and remote programming sessions were achieved completely and 
without incidents. Remote and standard program parameters were compared and no 
significant differences were found between the groups. The performance evaluated 
in subjects who had been using either standard or remote programs for 3 months 
showed no significant difference. Subjects were satisfied with both the remote 
and standard sessions. Safety was proven by checking emergency stops in 
different conditions. A very small delay was noticed that did not affect the 
ease of the fitting. The oral and video communication between the local and the 
remote equipment was established without difficulties and was of high quality.

DOI: 10.1080/00016480802294369
PMID: 18649152 [Indexed for MEDLINE]


585. J Laryngol Otol. 2007 Apr;121(4):301-5. doi: 10.1017/S0022215107006111. Epub 
2007 Feb 19.

Acoustic shock.

McFerran DJ(1), Baguley DM.

Author information:
(1)Department of Otolaryngology and Head and Neck Surgery, Essex County 
Hospital, Colchester, UK. donald.mcferran@essexrivers.nhs.uk

Acoustic shock is a recently recognised clinical entity: following an abrupt, 
intense and unanticipated acoustic stimulus, usually delivered by a telephone 
handset or headset, some individuals report a symptom cluster that includes 
otalgia, altered hearing, aural fullness, imbalance, tinnitus, dislike or even 
fear of loud noises, and anxiety and/or depression. Symptoms start shortly after 
the triggering acoustic incident and can be short-lived or can last for a 
considerable time. If persistent, the condition can lead to significant 
disability. Proposed mechanisms include involvement of the tensor tympani 
muscle, hyperexcitability of central auditory pathways, and a precursive state 
of raised anxiety or arousal. A formal treatment programme has not yet been 
proposed, but the potential utility of modern therapeutic techniques for 
tinnitus and hyperacusis are considered. Given the large number of UK residents 
working in telephone call centres, this condition is of considerable clinical 
importance.

DOI: 10.1017/S0022215107006111
PMID: 17306048 [Indexed for MEDLINE]


586. J Neural Eng. 2019 Jul 30;16(5):056008. doi: 10.1088/1741-2552/ab1e80.

Epidural recordings in cochlear implant users.

Haumann S(1), Bauernfeind G, Teschner MJ, Schierholz I, Bleichner MG, Büchner A, 
Lenarz T.

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany. 
Cluster of Excellence 'Hearing4all', Hannover & Oldenburg, Germany.

OBJECTIVE: In the long term it is desirable for CI users to control their device 
via brain signals. A possible strategy is the use of auditory evoked potentials 
(AEPs). Several studies have shown the suitability of auditory paradigms for 
such an approach. However, these investigations are based on non-invasive 
recordings. When thinking about everyday life applications, it would be more 
convenient to use implanted electrodes for signal acquisition. Ideally, the 
electrodes would be directly integrated into the CI. Further it is to be 
expected that invasively recorded signals have higher signal quality and are 
less affected by artifacts.
APPROACH: In this project we investigated the feasibility of implanting epidural 
electrodes temporarily during CI surgery and the possibility to record AEPs in 
the course of several days after implantation. Intraoperatively, auditory 
brainstem responses were recorded, whereas various kinds of AEPs were recorded 
postoperatively. After a few days the epidural electrodes were removed.
MAIN RESULTS: Data sets of ten subjects were obtained. Invasively recorded 
potentials were compared subjectively and objectively to clinical standard 
recordings using surface electrodes. Especially the cortical evoked response 
audiometry depicted clearer N1 waves for the epidural electrodes which were also 
visible at lower stimulation intensities compared to scalp electrodes. 
Furthermore the signal was less disturbed by artifacts. The objective quality 
measure (based on data sets of six patients) showed a significant better signal 
quality for the epidural compared to the scalp recordings.
SIGNIFICANCE: Altogether the approach revealed to be feasible and well tolerated 
by the patients. The epidural recordings showed a clearly better signal quality 
than the scalp recordings with AEPs being clearer recognizable. The results of 
the present study suggest that including epidural recording electrodes in future 
CI systems will improve the everyday life applicability of auditory closed loop 
systems for CI subjects.

DOI: 10.1088/1741-2552/ab1e80
PMID: 31042688 [Indexed for MEDLINE]


587. Hear Res. 2013 Jan;295:100-13. doi: 10.1016/j.heares.2012.11.016. Epub 2012 Nov 
27.

Salicylate-induced cochlear impairments, cortical hyperactivity and re-tuning, 
and tinnitus.

Chen GD(1), Stolzberg D, Lobarinas E, Sun W, Ding D, Salvi R.

Author information:
(1)Center for Hearing & Deafness, SUNY at Buffalo, 137 Cary Hall, Buffalo, NY 
14214, USA. gchen7@buffalo.edu

High doses of sodium salicylate (SS) have long been known to induce temporary 
hearing loss and tinnitus, effects attributed to cochlear dysfunction. However, 
our recent publications reviewed here show that SS can induce profound, 
permanent, and unexpected changes in the cochlea and central nervous system. 
Prolonged treatment with SS permanently decreased the cochlear compound action 
potential (CAP) amplitude in vivo. In vitro, high dose SS resulted in a 
permanent loss of spiral ganglion neurons and nerve fibers, but did not damage 
hair cells. Acute treatment with high-dose SS produced a frequency-dependent 
decrease in the amplitude of distortion product otoacoustic emissions and CAP. 
Losses were greatest at low and high frequencies, but least at the 
mid-frequencies (10-20 kHz), the mid-frequency band that corresponds to the 
tinnitus pitch measured behaviorally. In the auditory cortex, medial geniculate 
body and amygdala, high-dose SS enhanced sound-evoked neural responses at high 
stimulus levels, but it suppressed activity at low intensities and elevated 
response threshold. When SS was applied directly to the auditory cortex or 
amygdala, it only enhanced sound evoked activity, but did not elevate response 
threshold. Current source density analysis revealed enhanced current flow into 
the supragranular layer of auditory cortex following systemic SS treatment. 
Systemic SS treatment also altered tuning in auditory cortex and amygdala; low 
frequency and high frequency multiunit clusters up-shifted or down-shifted their 
characteristic frequency into the 10-20 kHz range thereby altering auditory 
cortex tonotopy and enhancing neural activity at mid-frequencies corresponding 
to the tinnitus pitch. These results suggest that SS-induced hyperactivity in 
auditory cortex originates in the central nervous system, that the amygdala 
potentiates these effects and that the SS-induced tonotopic shifts in auditory 
cortex, the putative neural correlate of tinnitus, arises from the interaction 
between the frequency-dependent losses in the cochlea and hyperactivity in the 
central nervous system.

Copyright © 2012 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2012.11.016
PMCID: PMC4191647
PMID: 23201030 [Indexed for MEDLINE]


588. J Deaf Stud Deaf Educ. 2021 Jun 14;26(3):427-437. doi: 10.1093/deafed/enab013.

Reading Achievement of Deaf Students: Challenging the Fourth Grade Ceiling.

Mayer C(1), Trezek BJ(2), Hancock GR(3).

Author information:
(1)Faculty of Education, York University, Toronto, ON, Canada.
(2)Department of Rehabilitation Psychology and Special Education, University of 
Wisconsin-Madison, Madison, WI, USA.
(3)Department of Human Development and Quantitative Methodology, University of 
Maryland, College Park, MD, USA.

Historically it has been reported that deaf students do not achieve 
age-appropriate outcomes in reading, with this performance often being 
characterized in terms of a fourth grade ceiling. However, given the shifts in 
the field during the past 20 years (e.g., widespread implementation of newborn 
hearing screening, advances in hearing technologies), it would be timely to 
question whether this continues to serve as a meaningful benchmark. To this end, 
the purpose of this study was to investigate reading outcomes of a Canadian 
cohort of school-aged deaf learners (N = 70) who all used listening and spoken 
language as the primary mode of communication. Specifically, the goal was to 
establish whether their achievement approached that of their hearing age peers 
and to identify demographic factors influencing performance (i.e., gender, 
unilateral/bilateral hearing loss, personal amplification, level of auditory 
functioning, grade placement, additional disabilities, home language). Results 
indicate that participants obtained standard scores in the average range on both 
the Basic Reading and Reading Comprehension clusters of the Woodcock Johnson 
III-Diagnostic Reading Battery (Woodcock et al., 2004), surpassing the fourth 
grade reading achievement ceiling often reported for this population.

© The Author(s) 2021. Published by Oxford University Press. All rights reserved. 
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/deafed/enab013
PMID: 34060625 [Indexed for MEDLINE]


589. Int J Environ Res Public Health. 2021 Dec 21;19(1):1. doi: 
10.3390/ijerph19010001.

Occupational Hearing Loss for Platinum Miners in South Africa: A Case Study of 
Data Sharing Practices and Ethical Challenges in the Mining Industry.

Ntlhakana L(1)(2), Nelson G(1), Khoza-Shangase K(2), Dorkin E(3).

Author information:
(1)Faculty of Health Sciences, School of Public Health, University of the 
Witwatersrand, Johannesburg 2000, South Africa.
(2)Department of Speech Pathology and Audiology, Faculty of Humanities, School 
of Human and Community Development, University of the Witwatersrand, 
Johannesburg 2050, South Africa.
(3)Anglo American, Johannesburg 2091, South Africa.

BACKGROUND: The relevant legislation ensures confidentiality and has paved the 
way for data handling and sharing. However, the industry remains uncertain 
regarding big data handling and sharing practices for improved healthcare 
delivery and medical research.
METHODS: A semi-qualitative cross-sectional study was used which entailed 
analysing miners' personal health records from 2014 to 2018. Data were accessed 
from the audiometry medical surveillance database (n = 480), the hearing 
screening database (n = 24,321), and the occupational hygiene database (n = 
15,769). Ethical principles were applied to demonstrate big data protection and 
sharing.
RESULTS: Some audiometry screening and occupational hygiene records were 
incomplete and/or inaccurate (N = 4675). The database containing medical disease 
and treatment records could not be accessed. Ethical challenges included a lack 
of clarity regarding permission rights when sharing big data, and no policy 
governing the divulgence of miners' personal and medical records for research.
CONCLUSION: This case study illustrates how research can be effectively, 
although not maliciously, obstructed by the strict protection of employee 
medical data. Clearly communicated company policies should be developed for the 
sharing of workers' records in the mining industry to improve HCPs.

DOI: 10.3390/ijerph19010001
PMCID: PMC8750121
PMID: 35010261 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest. The 
funders had no role in the design of the study; in the collection, analyses, or 
interpretation of data; in the writing of the manuscript, or in the decision to 
publish the results.


590. PLoS Genet. 2012;8(10):e1002966. doi: 10.1371/journal.pgen.1002966. Epub 2012 
Oct 4.

A mutation in the Srrm4 gene causes alternative splicing defects and deafness in 
the Bronx waltzer mouse.

Nakano Y(1), Jahan I, Bonde G, Sun X, Hildebrand MS, Engelhardt JF, Smith RJ, 
Cornell RA, Fritzsch B, Bánfi B.

Author information:
(1)Department of Anatomy and Cell Biology, Carver College of Medicine, 
University of Iowa, Iowa City, IA, USA.

Sensory hair cells are essential for hearing and balance. Their development from 
epithelial precursors has been extensively characterized with respect to 
transcriptional regulation, but not in terms of posttranscriptional influences. 
Here we report on the identification and functional characterization of an 
alternative-splicing regulator whose inactivation is responsible for defective 
hair-cell development, deafness, and impaired balance in the spontaneous mutant 
Bronx waltzer (bv) mouse. We used positional cloning and transgenic rescue to 
locate the bv mutation to the splicing factor-encoding gene Ser/Arg repetitive 
matrix 4 (Srrm4). Transcriptome-wide analysis of pre-mRNA splicing in the 
sensory patches of embryonic inner ears revealed that specific alternative exons 
were skipped at abnormally high rates in the bv mice. Minigene experiments in a 
heterologous expression system confirmed that these skipped exons require Srrm4 
for inclusion into the mature mRNA. Sequence analysis and mutagenesis 
experiments showed that the affected transcripts share a novel motif that is 
necessary for the Srrm4-dependent alternative splicing. Functional annotations 
and protein-protein interaction data indicated that the encoded proteins cluster 
in the secretion and neurotransmission pathways. In addition, the splicing of a 
few transcriptional regulators was found to be Srrm4 dependent, and several of 
the genes known to be targeted by these regulators were expressed at reduced 
levels in the bv mice. Although Srrm4 expression was detected in neural tissues 
as well as hair cells, analyses of the bv mouse cerebellum and neocortex failed 
to detect splicing defects. Our data suggest that Srrm4 function is critical in 
the hearing and balance organs, but not in all neural tissues. Srrm4 is the 
first alternative-splicing regulator to be associated with hearing, and the 
analysis of bv mice provides exon-level insights into hair-cell development.

DOI: 10.1371/journal.pgen.1002966
PMCID: PMC3464207
PMID: 23055939 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


591. Zhonghua Yi Xue Za Zhi. 2023 Jul 4;103(25):1911-1917. doi: 
10.3760/cma.j.cn112137-20221107-02337.

[Low-frequency fluctuation amplitude changes in resting-state brain functional 
magnetic resonance imaging and its correlation with clinical hearing levels in 
patients with unilateral hearing impairment].

[Article in Chinese; Abstract available in Chinese from the publisher]

Li HM(1), Han XW(2), Sang CY(1), Sui Y(1), Ma GL(3).

Author information:
(1)Department of Radiology, Fu Xing Hospital, Capital Medical University, 
Beijing 100038, China.
(2)The Affiliated Drum Tower Hospital of Nanjing University Medical School, 
Nanjing 210008, China.
(3)China-Japan Friendship Clinical Medical College of Peking University, Beijing 
100029, China.

Objective: To investigate low-frequency fluctuation amplitude changes in 
resting-state brain fMRI and its correlation with clinical hearing levels in 
patients with clinical hearing level in patients with unilateral hearing 
impairment. Methods: Forty-five patients with unilateral hearing impairment[12 
males and 33 females, aged 36-67 (46.0±9.7) years], and 31 controls with normal 
hearing[9 males and 22 females, aged 36-67 (46.0±10.1) years], were 
retrospectively included. All subjects underwent blood oxygen level-dependent 
(BOLD) resting-state functional magnetic resonance imaging and high-resolution 
T1-weighted imaging. The patients were divided into the left-sided hearing 
impaired group(24 cases), and the right-sided hearing impaired group(21 cases). 
After data being preprocessed, differences in low frequency amplitude (ALFF) 
metrics between the evaluated patients and controls were calculated and 
analyzed, and the statistics were corrected for Gaussian random field (GFR). 
Results: Overall comparative analysis of patients with hearing impairment showed 
that one-way ANOVA among the three groups showed abnormal ALFF values only in 
the right anterior cuneiform lobe (GRF adjusted P=0.002). The ALFF value of the 
hearing impaired group was higher than that of the control group in one cluster 
(peak coordinates: X=9, Y=-72, Z=48, T=5.82), involving the left occipital 
gyrus, right anterior cuneiform lobe, left superior cuneiform lobe, left 
superior parietal gyrus, and left angular gyrus (GRF adjusted P=0.031). The ALFF 
value of the hearing impaired group was lower than that of the control group in 
three clusters (peak coordinates: X=57, Y=-48, Z=-24; T=-4.99; X=45, Y=-66, Z=0, 
T=-4.06; X=42, Y=-12, Z=36, T=-4.03), involving the right inferior temporal 
gyrus, the right middle temporal gyrus, and the right precentral gyrus (GRF 
adjusted P=0.009). Compared with the control group, the ALFF value of the left 
hearing impairment group was significantly higher than that of the control group 
in one cluster (peak coordinates: X=-12, Y=-75, Z=45, T=5.78), involving the 
left anterior cuneiform lobe, right anterior cuneiform lobe, left middle 
occipital gyrus, left superior parietal gyrus, left superior occipital gyrus, 
left cuneiform lobe, and right cuneiform lobe (P=0.023 after GRF correction). 
Compared with the control group, the right hearing impairment group had a 
significantly higher ALFF value in one cluster (peak coordinates: X=9, Y=-46, 
Z=22, T=6.06), involving the left middle occipital gyrus, right anterior 
cuneiform lobe, left cuneiform lobe, right cuneiform lobe, left superior 
occipital gyrus, and right superior occipital gyrus (GRF adjusted P=0.022); The 
brain area with reduced ALFF values is located in the right inferior temporal 
gyrus (GRF adjusted P=0.029). Spearman's two-tailed correlation analysis between 
ALFF values and pure tone average in the abnormal brain regions showed that ALFF 
values in the abnormal brain regions correlated to some extent with the pure 
tone average (PTA) only in the left-sided hearing impaired group(PTA=2 000 Hz, 
r=0.318,P=0.033;PTA=4 000 Hz,r=0.386,P=0.009). Conclusion: The abnormal neural 
activity within the brain are different in patients with left-sided and 
right-sided hearing impairment, and the severity of hearing impairment is 
related to the difference in functional integration of brain regions.

Publisher: 目的： 探讨单侧听力障碍患者静息态脑功能磁共振低频波动振幅（ALFF）差异及其与临床听力的相关性。 方法： 
回顾性纳入2020年10月至2022年10月在首都医科大学附属复兴医院就诊的45例单侧听力障碍患者［男12例，女33例，年龄37~67（46.0±9.7）岁］和31名听力正常的对照者［男9名，女22名，年龄36~67（46.0±10.1）岁］。所有受试者均接受血氧水平依赖（BOLD）静息状态功能磁共振成像和高分辨率T1加权成像检查。将患者分为左侧听力障碍组（24例）和右侧听力障碍组（21例）。数据预处理后，计算和分析评估患者和对照者之间ALFF指标的差异，并对统计结果进行高斯随机场（GFR）校正。 
结果： 
听力障碍患者总体比较分析，三组间单因素方差分析显示仅在右侧楔前叶出现ALFF值异常（GRF校正后P=0.002）；听力障碍组ALFF值高于对照组有1个团簇（峰值坐标为：X=9、Y=-72、Z=48，T=5.82），涉及左侧枕中回、右侧楔前叶、左侧楔叶、左侧枕上回、右侧楔叶、左侧楔前叶、左侧顶上回、左侧角回（GRF校正后P=0.031）；听力障碍组ALFF值低于对照组有3个团簇（峰值坐标分别为：X=57、Y=-48、Z=-24，T=-4.99；X=45、Y=-66、Z=0，T=-4.06；X=42、Y=-12、Z=36，T=-4.03），涉及右侧颞下回、右侧颞中回及右侧中央前回（GRF校正后P=0.009）。左侧听力障碍组与对照组相比，ALFF值高于对照组有1个团簇（峰值坐标为：X=-12、Y=-75、Z=45，T=5.78），涉及左侧楔前叶、右侧楔前叶、左侧枕中回、左侧顶上回、左侧枕上回、左侧楔叶及右侧楔叶（GRF校正后P=0.023）。右侧听力障碍组与对照组相比，ALFF值高于对照组有1个团簇（峰值坐标为：X=9、Y=-46、Z=22，T=6.06），涉及左侧枕中回、右侧楔前叶、左侧楔叶、右侧楔叶、左侧枕上回、右侧枕上回（GRF校正后P<0.022）；ALFF值降低的脑区位于右侧颞下回（GRF校正后P=0.029）。异常脑区ALFF值与纯音平均值（PTA）的Spearman双尾相关分析显示，仅在左侧听力障碍组中异常脑区的ALFF值与PTA具有相关性（PTA=2 
000 Hz，r=0.318，P=0.033；PTA=4 000 Hz，r=0.386，P=0.009）。 结论： 
左侧与右侧听力障碍患者的大脑内部活动发生异常，且听力受损的严重程度与脑区功能整合的差异有关。.

DOI: 10.3760/cma.j.cn112137-20221107-02337
PMID: 37402672 [Indexed for MEDLINE]


592. Asia Pac J Public Health. 2020 Jul;32(5):235-241. doi: 10.1177/1010539520937086. 
Epub 2020 Jul 1.

A National Survey of Hearing Loss in the Philippines.

Newall JP(1), Martinez N(2), Swanepoel W(3), McMahon CM(1).

Author information:
(1)Macquarie University, Sydney, New South Wales, Australia.
(2)University of Santo Tomas, Manila, Philippines.
(3)University of Pretoria, Pretoria, South Africa.

This study aimed to estimate the prevalence of hearing loss in the Philippines 
using a nationally representative sample. A cross-sectional national survey was 
undertaken utilizing a 3-stage stratified cluster design. Participants in the 
present study comprised 2275 adults and children with pure tone hearing 
assessment results. Prevalence of moderate or worse hearing loss, defined as 4FA 
≥41 dBHL, was 7.5% in children <18 years, 14.7% in adults between 18 and 65 
years, and 49.1% in adults >65 years. Factors associated with greater risk of 
moderate hearing loss in the better ear were presence of a middle ear condition 
(adjusted odds ratio = 2.39, 95% confidence interval = 1.49-3.85) and 
socioeconomic status (household income; adjusted odds ratio = 1.64, 95% 
confidence interval = 1.23-2.19). Age was also associated with increased risk, 
with adjusted odds ratios varying with age category. Prevalence of wax occlusion 
and outer and middle ear disease was 12.2% and 14.2%, respectively. Prevalence 
of hearing loss, outer, and middle ear disease appear comparatively high in the 
Philippines when compared with rates reported in high-income countries. Higher 
proportions of severe to profound hearing loss were also identified, indicating 
that there is both an increased prevalence and severity of hearing loss in this 
population.

DOI: 10.1177/1010539520937086
PMID: 32608243 [Indexed for MEDLINE]


593. J Neurophysiol. 2011 Aug;106(2):944-59. doi: 10.1152/jn.00731.2010. Epub 2011 
May 4.

Behavioral training enhances cortical temporal processing in neonatally deafened 
juvenile cats.

Beitel RE(1), Vollmer M, Raggio MW, Schreiner CE.

Author information:
(1)Saul and Ida Epstein Laboratory, Department of Otolaryngology-Head and Neck 
Surgery, University of California,, San Francisco, CA 94143, USA. 
beitel@keck.ucsf.edu

Deaf humans implanted with a cochlear prosthesis depend largely on temporal cues 
for speech recognition because spectral information processing is severely 
impaired. Training with a cochlear prosthesis is typically required before 
speech perception shows improvement, suggesting that relevant experience 
modifies temporal processing in the central auditory system. We tested this 
hypothesis in neonatally deafened cats by comparing temporal processing in the 
primary auditory cortex (AI) of cats that received only chronic passive 
intracochlear electric stimulation (ICES) with cats that were also trained with 
ICES to detect temporally challenging trains of electric pulses. After months of 
chronic passive stimulation and several weeks of detection training in 
behaviorally trained cats, multineuronal AI responses evoked by temporally 
modulated ICES were recorded in anesthetized animals. The stimulus repetition 
rates that produced the maximum number of phase-locked spikes (best repetition 
rate) and 50% cutoff rate were significantly higher in behaviorally trained cats 
than the corresponding rates in cats that received only chronic passive ICES. 
Behavioral training restored neuronal temporal following ability to levels 
comparable with those recorded in naïve prior normal-hearing adult deafened 
animals. Importantly, best repetitition rates and cutoff rates were highest for 
neuronal clusters activated by the electrode configuration used in behavioral 
training. These results suggest that neuroplasticity in the AI is induced by 
behavioral training and perceptual learning in animals deprived of ordinary 
auditory experience during development and indicate that behavioral training can 
ameliorate or restore temporal processing in the AI of profoundly deaf animals.

DOI: 10.1152/jn.00731.2010
PMCID: PMC3154807
PMID: 21543753 [Indexed for MEDLINE]


594. Am J Hum Genet. 2008 Apr;82(4):982-91. doi: 10.1016/j.ajhg.2008.02.015.

A mutation in HOXA2 is responsible for autosomal-recessive microtia in an 
Iranian family.

Alasti F(1), Sadeghi A, Sanati MH, Farhadi M, Stollar E, Somers T, Van Camp G.

Author information:
(1)Department of Medical Genetics, University of Antwerp, 2610 Antwerp, Belgium.

Erratum in
    Am J Hum Genet. 2008 Sep;83(3):424.

Microtia, a congenital deformity manifesting as an abnormally shaped or absent 
external ear, occurs in one out of 8,000-10,000 births. We ascertained a 
consanguineous Iranian family segregating with autosomal-recessive bilateral 
microtia, mixed symmetrical severe to profound hearing impairment, and partial 
cleft palate. Genome-wide linkage analysis localized the responsible gene to 
chromosome 7p14.3-p15.3 with a maximum multi-point LOD score of 4.17. In this 
region, homeobox genes from the HOXA cluster were the most interesting 
candidates. Subsequent DNA sequence analysis of the HOXA1 and HOXA2 homeobox 
genes from the candidate region identified an interesting HOXA2 homeodomain 
variant: a change in a highly conserved amino acid (p.Q186K). The variant was 
not found in 231 Iranian and 109 Belgian control samples. The critical 
contribution of HoxA2 for auditory-system development has already been shown in 
mouse models. We built a homology model to predict the effect of this mutation 
on the structure and DNA-binding activity of the homeodomain by using the 
program Modeler 8v2. In the model of the mutant homeodomain, the position of the 
mutant lysine side chain is consistently farther away from a nearby phosphate 
group; this altered position results in the loss of a hydrogen bond and affects 
the DNA-binding activity.

DOI: 10.1016/j.ajhg.2008.02.015
PMCID: PMC2427268
PMID: 18394579 [Indexed for MEDLINE]


595. PLoS One. 2020 Nov 18;15(11):e0241695. doi: 10.1371/journal.pone.0241695. 
eCollection 2020.

Objective measurement of tinnitus using functional near-infrared spectroscopy 
and machine learning.

Shoushtarian M(1)(2), Alizadehsani R(3), Khosravi A(3), Acevedo N(1), McKay 
CM(1)(2), Nahavandi S(3), Fallon JB(1)(2)(4).

Author information:
(1)The Bionics Institute, East Melbourne, Victoria, Australia.
(2)Medical Bionics Department, The University of Melbourne, Melbourne, 
Australia.
(3)Institute for Intelligent Systems Research and Innovation (IISRI), Deakin 
University, Melbourne, Australia.
(4)Department of Otolaryngology, The University of Melbourne, Melbourne, 
Australia.

Chronic tinnitus is a debilitating condition which affects 10-20% of adults and 
can severely impact their quality of life. Currently there is no objective 
measure of tinnitus that can be used clinically. Clinical assessment of the 
condition uses subjective feedback from individuals which is not always 
reliable. We investigated the sensitivity of functional near-infrared 
spectroscopy (fNIRS) to differentiate individuals with and without tinnitus and 
to identify fNIRS features associated with subjective ratings of tinnitus 
severity. We recorded fNIRS signals in the resting state and in response to 
auditory or visual stimuli from 25 individuals with chronic tinnitus and 21 
controls matched for age and hearing loss. Severity of tinnitus was rated using 
the Tinnitus Handicap Inventory and subjective ratings of tinnitus loudness and 
annoyance were measured on a visual analogue scale. Following statistical group 
comparisons, machine learning methods including feature extraction and 
classification were applied to the fNIRS features to classify patients with 
tinnitus and controls and differentiate tinnitus at different severity levels. 
Resting state measures of connectivity between temporal regions and frontal and 
occipital regions were significantly higher in patients with tinnitus compared 
to controls. In the tinnitus group, temporal-occipital connectivity showed a 
significant increase with subject ratings of loudness. Also in this group, both 
visual and auditory evoked responses were significantly reduced in the visual 
and auditory regions of interest respectively. Naïve Bayes classifiers were able 
to classify patients with tinnitus from controls with an accuracy of 78.3%. An 
accuracy of 87.32% was achieved using Neural Networks to differentiate patients 
with slight/ mild versus moderate/ severe tinnitus. Our findings show the 
feasibility of using fNIRS and machine learning to develop an objective measure 
of tinnitus. Such a measure would greatly benefit clinicians and patients by 
providing a tool to objectively assess new treatments and patients' treatment 
progress.

DOI: 10.1371/journal.pone.0241695
PMCID: PMC7673524
PMID: 33206675 [Indexed for MEDLINE]

Conflict of interest statement: No authors have competing interests.


596. J Assoc Res Otolaryngol. 2024 Feb;25(1):13-33. doi: 10.1007/s10162-024-00925-6. 
Epub 2024 Feb 9.

A Systematic Review on the Genetic Contribution to Tinnitus.

Perez-Carpena P(1)(2)(3), Lopez-Escamez JA(4)(5)(6), Gallego-Martinez Á(7)(8).

Author information:
(1)Otology and Neurotology Group CTS495, Division of Otolaryngology, Department 
of Surgery, Instituto de Investigación Biosanitaria, Ibs.GRANADA, Universidad de 
Granada, Granada, Spain. percarpena@ugr.es.
(2)Sensorineural Pathology Programme, Centro de Investigación Biomédica en Red 
en Enfermedades Raras, CIBERER, Madrid, Spain. percarpena@ugr.es.
(3)Department of Otolaryngology, Instituto de Investigación Biosanitaria 
Ibs.GRANADA, Hospital Universitario Virgen de Las Nieves, Granada, Spain. 
percarpena@ugr.es.
(4)Otology and Neurotology Group CTS495, Division of Otolaryngology, Department 
of Surgery, Instituto de Investigación Biosanitaria, Ibs.GRANADA, Universidad de 
Granada, Granada, Spain. jose.lopezescamez@sydney.edu.au.
(5)Sensorineural Pathology Programme, Centro de Investigación Biomédica en Red 
en Enfermedades Raras, CIBERER, Madrid, Spain. jose.lopezescamez@sydney.edu.au.
(6)Meniere's Disease Neuroscience Research Program, Faculty of Medicine & 
Health, School of Medical Sciences, The Kolling Institute, University of Sydney, 
Sydney, NSW, Australia. jose.lopezescamez@sydney.edu.au.
(7)Otology and Neurotology Group CTS495, Division of Otolaryngology, Department 
of Surgery, Instituto de Investigación Biosanitaria, Ibs.GRANADA, Universidad de 
Granada, Granada, Spain.
(8)Sensorineural Pathology Programme, Centro de Investigación Biomédica en Red 
en Enfermedades Raras, CIBERER, Madrid, Spain.

PURPOSE: To assess the available evidence to support a genetic contribution and 
define the role of common and rare variants in tinnitus.
METHODS: After a systematic search and quality assessment, 31 records including 
383,063 patients were selected (14 epidemiological studies and 17 genetic 
association studies). General information on the sample size, age, sex, tinnitus 
prevalence, severe tinnitus distribution, and sensorineural hearing loss was 
retrieved. Studies that did not include data on hearing assessment were 
excluded. Relative frequencies were used for qualitative variables to compare 
different studies and to obtain average values. Genetic variants and genes were 
listed and clustered according to their potential role in tinnitus development.
RESULTS: The average prevalence of tinnitus estimated from population-based 
studies was 26.3% for any tinnitus, and 20% of patients with tinnitus reported 
it as an annoying symptom. One study has reported population-specific 
differences in the prevalence of tinnitus, the white ancestry being the 
population with a higher prevalence. Genome-wide association studies have 
identified and replicated two common variants in the Chinese population 
(rs2846071; rs4149577) in the intron of TNFRSF1A, associated with noise-induced 
tinnitus. Moreover, gene burden analyses in sequencing data from Spanish and 
Swede patients with severe tinnitus have identified and replicated ANK2, AKAP9, 
and TSC2 genes.
CONCLUSIONS: The genetic contribution to tinnitus is starting to be revealed and 
it shows population-specific effects in European and Asian populations. The 
common allelic variants associated with tinnitus that showed replication are 
associated with noise-induced tinnitus. Although severe tinnitus has been 
associated with rare variants with large effect, their role on hearing or 
hyperacusis has not been established.

© 2024. The Author(s).

DOI: 10.1007/s10162-024-00925-6
PMCID: PMC10907330
PMID: 38334885 [Indexed for MEDLINE]


597. Signal Transduct Target Ther. 2022 Jun 10;7(1):175. doi: 
10.1038/s41392-022-00995-z.

LDL receptor-related protein 1 (LRP1), a novel target for opening the 
blood-labyrinth barrier (BLB).

Shi X(#)(1)(2), Wang Z(#)(3), Ren W(#)(4)(5)(6)(7), Chen L(#)(1)(8), Xu 
C(4)(5)(6)(7), Li M(2), Fan S(3), Xu Y(3), Chen M(4)(5)(6)(7), Zheng 
F(4)(5)(6)(7), Zhang W(8), Zhou X(3), Zhang Y(4)(5)(6)(7), Qiu S(2), Wu L(2), 
Zhou P(8), Lv X(2), Cui T(2), Qiao Y(2), Zhao H(4)(5)(6)(7), Guo W(4)(5)(6)(7), 
Chen W(4)(5)(6)(7), Li S(3), Zhong W(9), Lin J(10)(11), Yang S(12)(13)(14)(15).

Author information:
(1)Department of Pharmacy, Peking University Third Hospital, Beijing, China.
(2)Artificial Auditory Laboratory of Jiangsu Province, Xuzhou Medical 
University, Xuzhou, China.
(3)National Engineering Research Center for the Emergency Drug, Beijing 
Institute of Pharmacology and Toxicology, Beijing, China.
(4)College of Otolaryngology Head and Neck Surgery, Chinese PLA General 
Hospital, Beijing, China.
(5)National Clinical Research Center for Otolaryngologic Diseases, Beijing, 
China.
(6)Key Lab of Hearing Science, Ministry of Education, Beijing, China.
(7)Beijing Key Lab of Hearing Impairment for Prevention and Treatment, Beijing, 
China.
(8)Synthetic and Functional Biomolecules Center, Beijing National Laboratory for 
Molecular Sciences, Key Laboratory of Bioorganic Chemistry and Molecular 
Engineering of Ministry of Education, College of Chemistry and Molecular 
Engineering, Innovation Center for Genomics, Peking University, Beijing, China.
(9)National Engineering Research Center for the Emergency Drug, Beijing 
Institute of Pharmacology and Toxicology, Beijing, China. zhongwu@bmi.ac.cn.
(10)Department of Pharmacy, Peking University Third Hospital, Beijing, China. 
linjian@pku.edu.cn.
(11)Synthetic and Functional Biomolecules Center, Beijing National Laboratory 
for Molecular Sciences, Key Laboratory of Bioorganic Chemistry and Molecular 
Engineering of Ministry of Education, College of Chemistry and Molecular 
Engineering, Innovation Center for Genomics, Peking University, Beijing, China. 
linjian@pku.edu.cn.
(12)College of Otolaryngology Head and Neck Surgery, Chinese PLA General 
Hospital, Beijing, China. shm_yang@163.com.
(13)National Clinical Research Center for Otolaryngologic Diseases, Beijing, 
China. shm_yang@163.com.
(14)Key Lab of Hearing Science, Ministry of Education, Beijing, China. 
shm_yang@163.com.
(15)Beijing Key Lab of Hearing Impairment for Prevention and Treatment, Beijing, 
China. shm_yang@163.com.
(#)Contributed equally

Inner ear disorders are a cluster of diseases that cause hearing loss in more 
than 1.5 billion people worldwide. However, the presence of the blood-labyrinth 
barrier (BLB) on the surface of the inner ear capillaries greatly hinders the 
effectiveness of systemic drugs for prevention and intervention due to the low 
permeability, which restricts the entry of most drug compounds from the 
bloodstream into the inner ear tissue. Here, we report the finding of a novel 
receptor, low-density lipoprotein receptor-related protein 1 (LRP1), that is 
expressed on the BLB, as a potential target for shuttling therapeutics across 
this barrier. As a proof-of-concept, we developed an LRP1-binding peptide, 
IETP2, and covalently conjugated a series of model small-molecule compounds to 
it, including potential drugs and imaging agents. All compounds were 
successfully delivered into the inner ear and inner ear lymph, indicating that 
targeting the receptor LRP1 is a promising strategy to enhance the permeability 
of the BLB. The discovery of the receptor LRP1 will illuminate developing 
strategies for crossing the BLB and for improving systemic drug delivery for 
inner ear disorders.

© 2022. The Author(s).

DOI: 10.1038/s41392-022-00995-z
PMCID: PMC9184653
PMID: 35680846 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


598. Hear Res. 2022 Sep 1;422:108533. doi: 10.1016/j.heares.2022.108533. Epub 2022 
May 21.

Dopaminergic and cholinergic innervation in the mouse cochlea after 
noise-induced or age-related synaptopathy.

Grierson KE(1), Hickman TT(2), Liberman MC(3).

Author information:
(1)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA, 02114 USA; 
Dept of Otolaryngology-Head & Neck Surgery, Harvard Medical School, Boston, MA, 
02115 USA; Hearing Research Lab, Garvan Institute of Medical Research, 
Darlinghurst, NSW, 2010, AUS.
(2)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA, 02114 USA; 
Dept of Otolaryngology-Head & Neck Surgery, Harvard Medical School, Boston, MA, 
02115 USA. Electronic address: tyler_hickman@meei.harvard.edu.
(3)Eaton-Peabody Laboratories, Massachusetts Eye and Ear, Boston, MA, 02114 USA; 
Dept of Otolaryngology-Head & Neck Surgery, Harvard Medical School, Boston, MA, 
02115 USA.

Cochlear synaptopathy, the loss of or damage to connections between 
auditory-nerve fibers (ANFs) and inner hair cells (IHCs), is a prominent 
pathology in noise-induced and age-related hearing loss. Here, we investigated 
if degeneration of the olivocochlear (OC) efferent innervation is also a major 
aspect of the synaptopathic ear, by quantifying the volume and spatial 
organization of its cholinergic and dopaminergic components, using antibodies to 
vesicular acetylcholine transporter (VAT) and tyrosine hydroxylase (TH), 
respectively. CBA/CaJ male mice were examined 1 day to 8 months after a 
synaptopathic noise exposure, and compared to unexposed age-matched controls and 
unexposed aged mice at 24-28 months. In normal ears, cholinergic lateral (L)OC 
terminals were denser in the apical half of the cochlea and on the modiolar side 
of the inner hair cells (IHCs), where ANFs of low-spontaneous rate are typically 
found, while dopaminergic terminals were more common in the basal third of the 
cochlea and, re the IHC axes, were offset towards the habenula with respect to 
cholinergic terminals. The noise had only small and transient effects on the 
density of LOC innervation, its spatial organization around the IHC axes, or the 
extent to which TH and VAT signal were colocalized. The synaptopathic noise also 
had relatively small and transient effects on cholinergic innervation density in 
the outer hair cell (OHC) area, which normally peaks in the 16 kHz region and 
falls monotonically towards higher and lower frequencies. In contrast, in the 
aged ears, there was massive degeneration of OHC efferents, especially in the 
apical half of the cochlea, where there was also significant loss of OHCs. In 
the IHC area, there was significant loss of cholinergic terminals in both apical 
and basal regions and of dopaminergic innervation in the basal half. 
Furthermore, the cholinergic terminals in the aged ears spread from their normal 
clustering near the IHC basolateral pole, where the ANF synapses are found, to 
positions up and down the IHC somata and regions of the neuropil closer to the 
habenula. This apparent migration was most striking in the apex, where the hair 
cell pathology was greatest, and may be a harbinger of impending hair cell 
death.

Copyright © 2022. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2022.108533
PMID: 35671600 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
have no conflicts of interest or relevant financial relationships to disclose


599. Hear Res. 2017 Jul;350:100-109. doi: 10.1016/j.heares.2017.04.012. Epub 2017 Apr 
25.

Streptococcus pneumoniae-induced ototoxicity in organ of Corti explant cultures.

Perny M(1), Solyga M(2), Grandgirard D(3), Roccio M(2), Leib SL(4), Senn P(5).

Author information:
(1)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, Switzerland; Inner Ear Research Laboratory, Department of 
Otorhinolaryngology, Head& Neck Surgery, Inselspital Bern and Department of 
Clinical Research, University of Bern, Switzerland; Cluster for Regenerative 
Neuroscience, Department of Clinical Research, University of Bern, Switzerland.
(2)Inner Ear Research Laboratory, Department of Otorhinolaryngology, Head& Neck 
Surgery, Inselspital Bern and Department of Clinical Research, University of 
Bern, Switzerland; Cluster for Regenerative Neuroscience, Department of Clinical 
Research, University of Bern, Switzerland.
(3)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, Switzerland; Cluster for Regenerative Neuroscience, Department of Clinical 
Research, University of Bern, Switzerland.
(4)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, Switzerland; Cluster for Regenerative Neuroscience, Department of Clinical 
Research, University of Bern, Switzerland. Electronic address: 
Stephen.leib@ifik.unibe.ch.
(5)Inner Ear Research Laboratory, Department of Otorhinolaryngology, Head& Neck 
Surgery, Inselspital Bern and Department of Clinical Research, University of 
Bern, Switzerland; Department of Otorhinolaryngology, Head & Neck Surgery, 
University Hospital Geneva (HUG), Genève, Switzerland; Cluster for Regenerative 
Neuroscience, Department of Clinical Research, University of Bern, Switzerland. 
Electronic address: Pascal.Senn@hcuge.ch.

Hearing loss remains the most common long-term complication of pneumococcal 
meningitis (PM) reported in up to 30% of survivors. Streptococcus pneumoniae 
have been shown to possess different ototoxic properties. Here we present a 
novel ex vivo experimental setup to examine in detail the pattern of hair cell 
loss upon exposure to different S. pneumoniae strains, therefore recapitulating 
pathogen derived aspects of PM-induced hearing loss. Our results show a higher 
susceptibility towards S. pneumoniae-induced cochlear damage for outer hair 
cells (OHC) compared to inner hair cells (IHC), which is consistent with in vivo 
data. S. pneumoniae-induced hair cell loss was both time and dose-dependent. 
Moreover, we have found significant differences in the level of cell damage 
between tissue from the basal and the apical turns. This shows that the higher 
vulnerability of hair cells located at high frequency regions observed in vivo 
cannot be explained solely by the spatial organisation and bacterial 
infiltration from the basal portion of the cochlea. Using a wild type D39 strain 
and a mutant defective for the pneumolysin (PLY) gene, we also have shown that 
the toxin PLY is an important factor involved in ototoxic damages. The obtained 
results indicate that PLY can cause both IHC and OHC loss. Finally, we are 
reporting here for the first time a higher vulnerability of HC located at the 
basal and middle cochlear region to pneumolysin-induced damage. The detailed 
description of the susceptibility of hair cells to Streptococcus pneumoniae 
provided in this report can in the future determine the choice and the 
development of novel otoprotective therapies during pneumococcal meningitis.

Copyright © 2017 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2017.04.012
PMID: 28460251 [Indexed for MEDLINE]


600. Brain Lang. 2004 May;89(2):377-84. doi: 10.1016/S0093-934X(03)00349-3.

Brain network interactions in auditory, visual and linguistic processing.

Horwitz B(1), Braun AR.

Author information:
(1)Voice, Speech, Language Branch, National Institute on Deafness and Other 
Communications Disorders, National Institutes of Health, 9000 Rockville Pike, 
Bldg. 10, Rm. 6C420, MSC 1591, Bethesda, MD 20892, USA. horwitz@helix.nih.gov

In the paper, we discuss the importance of network interactions between brain 
regions in mediating performance of sensorimotor and cognitive tasks, including 
those associated with language processing. Functional neuroimaging, especially 
PET and fMRI, provide data that are obtained essentially simultaneously from 
much of the brain, and thus are ideal for enabling one to assess interregional 
functional interactions. Two ways to use these types of data to assess network 
interactions are presented. First, using PET, we demonstrate that anterior and 
posterior perisylvian language areas have stronger functional connectivity 
during spontaneous narrative production than during other less linguistically 
demanding production tasks. Second, we show how one can use large-scale neural 
network modeling to relate neural activity to the hemodynamically-based data 
generated by fMRI and PET. We review two versions of a model of object 
processing - one for visual and one for auditory objects. The regions comprising 
the models include primary and secondary sensory cortex, association cortex in 
the temporal lobe, and prefrontal cortex. Each model incorporates specific 
assumptions about how neurons in each of these areas function, and how neurons 
in the different areas are interconnected with each other. Each model is able to 
perform a delayed match-to-sample task for simple objects (simple shapes for the 
visual model; tonal contours for the auditory model). We find that the simulated 
electrical activities in each region are similar to those observed in nonhuman 
primates performing analogous tasks, and the absolute values of the simulated 
integrated synaptic activity in each brain region match human fMRI/PET data. 
Thus, this type of modeling provides a way to understand the neural bases for 
the sensorimotor and cognitive tasks of interest.

DOI: 10.1016/S0093-934X(03)00349-3
PMID: 15068921 [Indexed for MEDLINE]


601. Ear Hear. 2017 Mar/Apr;38(2):e118-e127. doi: 10.1097/AUD.0000000000000377.

Toward Automated Cochlear Implant Fitting Procedures Based on Event-Related 
Potentials.

Finke M(1), Billinger M, Büchner A.

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Germany and Cluster of 
Excellence "Hearing4all", Hannover, Germany.

OBJECTIVES: Cochlear implants (CIs) restore hearing to the profoundly deaf by 
direct electrical stimulation of the auditory nerve. To provide an optimal 
electrical stimulation pattern the CI must be individually fitted to each CI 
user. To date, CI fitting is primarily based on subjective feedback from the 
user. However, not all CI users are able to provide such feedback, for example, 
small children. This study explores the possibility of using the 
electroencephalogram (EEG) to objectively determine if CI users are able to hear 
differences in tones presented to them, which has potential applications in CI 
fitting or closed loop systems.
DESIGN: Deviant and standard stimuli were presented to 12 CI users in an active 
auditory oddball paradigm. The EEG was recorded in two sessions and 
classification of the EEG data was performed with shrinkage linear discriminant 
analysis. Also, the impact of CI artifact removal on classification performance 
and the possibility to reuse a trained classifier in future sessions were 
evaluated.
RESULTS: Overall, classification performance was above chance level for all 
participants although performance varied considerably between participants. 
Also, artifacts were successfully removed from the EEG without impairing 
classification performance. Finally, reuse of the classifier causes only a small 
loss in classification performance.
CONCLUSIONS: Our data provide first evidence that EEG can be automatically 
classified on single-trial basis in CI users. Despite the slightly poorer 
classification performance over sessions, classifier and CI artifact correction 
appear stable over successive sessions. Thus, classifier and artifact correction 
weights can be reused without repeating the set-up procedure in every session, 
which makes the technique easier applicable. With our present data, we can show 
successful classification of event-related cortical potential patterns in CI 
users. In the future, this has the potential to objectify and automate parts of 
CI fitting procedures.

DOI: 10.1097/AUD.0000000000000377
PMID: 27787394 [Indexed for MEDLINE]


602. J Assoc Res Otolaryngol. 2019 Apr;20(2):115-131. doi: 
10.1007/s10162-018-00709-9. Epub 2019 Mar 1.

Towards a Mechanistic-Driven Precision Medicine Approach for Tinnitus.

Tzounopoulos T(1), Balaban C(2), Zitelli L(2)(3), Palmer C(2)(3).

Author information:
(1)Pittsburgh Hearing Research Center and Department of Otolaryngology, 
University of Pittsburgh, Pittsburgh, PA, 15261, USA. thanos@pitt.edu.
(2)Pittsburgh Hearing Research Center and Department of Otolaryngology, 
University of Pittsburgh, Pittsburgh, PA, 15261, USA.
(3)Department of Communication Science and Disorders, University of Pittsburgh, 
Pittsburgh, PA, 15213, USA.

In this position review, we propose to establish a path for replacing the 
empirical classification of tinnitus with a taxonomy from precision medicine. 
The goal of a classification system is to understand the inherent heterogeneity 
of individuals experiencing and suffering from tinnitus and to identify what 
differentiates potential subgroups. Identification of different patient 
subgroups with distinct audiological, psychophysical, and neurophysiological 
characteristics will facilitate the management of patients with tinnitus as well 
as the design and execution of drug development and clinical trials, which, for 
the most part, have not yielded conclusive results. An alternative outcome of a 
precision medicine approach in tinnitus would be that additional mechanistic 
phenotyping might not lead to the identification of distinct drivers in each 
individual, but instead, it might reveal that each individual may display a 
quantitative blend of causal factors. Therefore, a precision medicine approach 
towards identifying these causal factors might not lead to subtyping these 
patients but may instead highlight causal pathways that can be manipulated for 
therapeutic gain. These two outcomes are not mutually exclusive, and no matter 
what the final outcome is, a mechanistic-driven precision medicine approach is a 
win-win approach for advancing tinnitus research and treatment. Although there 
are several controversies and inconsistencies in the tinnitus field, which will 
not be discussed here, we will give a few examples, as to how the field can move 
forward by exploring the major neurophysiological tinnitus models, mostly by 
taking advantage of the common features supported by all of the models. Our 
position stems from the central concept that, as a field, we can and must do 
more to bring studies of mechanisms into the realm of neuroscience.

DOI: 10.1007/s10162-018-00709-9
PMCID: PMC6453992
PMID: 30825037 [Indexed for MEDLINE]


603. Front Med (Lausanne). 2021 Jan 11;7:613708. doi: 10.3389/fmed.2020.613708. 
eCollection 2020.

Automatic Recognition of Auditory Brainstem Response Characteristic Waveform 
Based on Bidirectional Long Short-Term Memory.

Chen C(1), Zhan L(2), Pan X(1), Wang Z(1), Guo X(1), Qin H(2), Xiong F(2), Shi 
W(2), Shi M(2), Ji F(2), Wang Q(2), Yu N(2), Xiao R(1)(3).

Author information:
(1)School of Computer and Communication Engineering, University of Science & 
Technology Beijing, Beijing, China.
(2)College of Otolaryngology Head and Neck Surgery, National Clinical Research 
Center for Otolaryngologic Diseases, Key Lab of Hearing Science, Ministry of 
Education, Beijing Key Lab of Hearing Impairment for Prevention and Treatment, 
Chinese PLA General Hospital, Beijing, China.
(3)Institute of Artificial Intelligence, University of Science and Technology 
Beijing, Beijing, China.

Background: Auditory brainstem response (ABR) testing is an invasive 
electrophysiological auditory function test. Its waveforms and threshold can 
reflect auditory functional changes in the auditory centers in the brainstem and 
are widely used in the clinic to diagnose dysfunction in hearing. However, 
identifying its waveforms and threshold is mainly dependent on manual 
recognition by experimental persons, which could be primarily influenced by 
individual experiences. This is also a heavy job in clinical practice. Methods: 
In this work, human ABR was recorded. First, binarization is created to mark 
1,024 sampling points accordingly. The selected characteristic area of ABR data 
is 0-8 ms. The marking area is enlarged to expand feature information and reduce 
marking error. Second, a bidirectional long short-term memory (BiLSTM) network 
structure is established to improve relevance of sampling points, and an ABR 
sampling point classifier is obtained by training. Finally, mark points are 
obtained through thresholding. Results: The specific structure, related 
parameters, recognition effect, and noise resistance of the network were 
explored in 614 sets of ABR clinical data. The results show that the average 
detection time for each data was 0.05 s, and recognition accuracy reached 
92.91%. Discussion: The study proposed an automatic recognition of ABR waveforms 
by using the BiLSTM-based machine learning technique. The results demonstrated 
that the proposed methods could reduce recording time and help doctors in making 
diagnosis, suggesting that the proposed method has the potential to be used in 
the clinic in the future.

Copyright © 2021 Chen, Zhan, Pan, Wang, Guo, Qin, Xiong, Shi, Shi, Ji, Wang, Yu 
and Xiao.

DOI: 10.3389/fmed.2020.613708
PMCID: PMC7829202
PMID: 33505982

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


604. J Neurosci. 2020 Sep 16;40(38):7190-7202. doi: 10.1523/JNEUROSCI.1314-19.2020.

The Neural Bases of Tinnitus: Lessons from Deafness and Cochlear Implants.

Knipper M(1), van Dijk P(2)(3), Schulze H(4), Mazurek B(5), Krauss P(4), Scheper 
V(6)(7), Warnecke A(6)(7), Schlee W(8), Schwabe K(6)(7), Singer W(9), Braun 
C(10), Delano PH(11), Fallgatter AJ(12), Ehlis AC(12), Searchfield GD(13)(14), 
Munk MHJ(12)(15), Baguley DM(16)(17), Rüttiger L(9).

Author information:
(1)University of Tübingen, Department of Otolaryngology, Head and Neck Surgery, 
Tübingen Hearing Research Center, Molecular Physiology of Hearing, 72076 
Tübingen, Germany marlies.knipper@uni-tuebingen.de p.van.dijk@umcg.nl.
(2)Department of Otorhinolaryngology/Head and Neck Surgery, University of 
Groningen, University Medical Center Groningen, 9700 AB Groningen, The 
Netherlands marlies.knipper@uni-tuebingen.de p.van.dijk@umcg.nl.
(3)Graduate School of Medical Sciences (Research School of Behavioural and 
Cognitive Neurosciences), University of Groningen, 9700 AB Groningen, The 
Netherlands.
(4)Experimental Otolaryngology, Neuroscience Laboratory, University Hospital 
Erlangen, Friedrich-Alexander University Erlangen-Nürnberg, 91054 Erlangen, 
Germany.
(5)Charité-Universitätsmedizin Berlin, Tinnituszentrum, 10117 Berlin, Germany.
(6)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, 30625 Hannover, Germany.
(7)Cluster of Excellence "Hearing4all" of the German Research Foundation, 30625 
Hannover, Germany.
(8)Department of Psychiatry and Psychotherapy, University of Regensburg, 93053 
Regensburg, Germany.
(9)University of Tübingen, Department of Otolaryngology, Head and Neck Surgery, 
Tübingen Hearing Research Center, Molecular Physiology of Hearing, 72076 
Tübingen, Germany.
(10)MEG Center, University Hospital Tübingen, 72076 Tübingen, Germany.
(11)Departments of Otolaryngology and Neuroscience, Faculty of Medicine, 
University of Chile, 15782 Santiago, Chile.
(12)Department of Psychiatry, University of Tübingen, 72076 Tübingen, Germany.
(13)Eisdell Moore Centre, Audiology Section, University of Auckland, 1546 
Auckland, New Zealand.
(14)Brain Research New Zealand, Centre for Brain Research, University of 
Auckland, 1142 Auckland, New Zealand.
(15)Department of Biology, Technical University Darmstadt, 64287 Darmstadt, 
Germany.
(16)Hearing Sciences, Division of Clinical Neuroscience, School of Medicine, 
University of Nottingham, NG15DU Nottingham, United Kingdom.
(17)NIHR Nottingham Biomedical Research Centre, University of Nottingham, NG72UH 
Nottingham, United Kingdom.

Subjective tinnitus is the conscious perception of sound in the absence of any 
acoustic source. The literature suggests various tinnitus mechanisms, most of 
which invoke changes in spontaneous firing rates of central auditory neurons 
resulting from modification of neural gain. Here, we present an alternative 
model based on evidence that tinnitus is: (1) rare in people who are 
congenitally deaf, (2) common in people with acquired deafness, and (3) 
potentially suppressed by active cochlear implants used for hearing restoration. 
We propose that tinnitus can only develop after fast auditory fiber activity has 
stimulated the synapse formation between fast-spiking parvalbumin positive (PV+) 
interneurons and projecting neurons in the ascending auditory path and 
coactivated frontostriatal networks after hearing onset. Thereafter, fast 
auditory fiber activity promotes feedforward and feedback inhibition mediated by 
PV+ interneuron activity in auditory-specific circuits. This inhibitory network 
enables enhanced stimulus resolution, attention-driven contrast improvement, and 
augmentation of auditory responses in central auditory pathways (neural gain) 
after damage of slow auditory fibers. When fast auditory fiber activity is lost, 
tonic PV+ interneuron activity is diminished, resulting in the prolonged 
response latencies, sudden hyperexcitability, enhanced cortical synchrony, 
elevated spontaneous γ oscillations, and impaired attention/stress-control that 
have been described in previous tinnitus models. Moreover, because fast 
processing is gained through sensory experience, tinnitus would not exist in 
congenital deafness. Electrical cochlear stimulation may have the potential to 
reestablish tonic inhibitory networks and thus suppress tinnitus. The proposed 
framework unites many ideas of tinnitus pathophysiology and may catalyze 
cooperative efforts to develop tinnitus therapies.

Copyright © 2020 the authors.

DOI: 10.1523/JNEUROSCI.1314-19.2020
PMCID: PMC7534911
PMID: 32938634 [Indexed for MEDLINE]


605. Am J Transl Res. 2023 Apr 15;15(4):2407-2425. eCollection 2023.

Global characteristics and trends of presbycusis research from 2002 to 2021: a 
bibliometric study.

Lv H(1), Gao Z(1), Wang Y(1), Xie Y(1), Guan M(1), Liao H(1)(2), Xu Y(1)(2).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Renmin Hospital of Wuhan 
University Wuhan 430060, Hubei, China.
(2)Research Institute of Otolaryngology-Head and Neck Surgery, Renmin Hospital 
of Wuhan University Wuhan 430060, Hubei, China.

BACKGROUND AND OBJECTIVE: Age-related hearing loss, also termed presbycusis, is 
the most prevalent sensory impairment in older adults. Presbycusis research has 
considerably advanced over the past few decades, however, comprehensive and 
objective reports on the current state of presbycusis research are lacking. We 
used bibliometric methods to objectively analyzed the progress of presbycusis 
research over the past 20 years and to identify the research hotspots and 
emerging trends in this field.
METHODS: Eligible literature metadata published between 2002 and 2021 were 
obtained from the Web of Science Core Collection on September 1, 2022. 
Bibliometric tools including CiteSpace, VOSviewer, Bibliometrix R Package, 
Microsoft Excel 2019, and an online bibliometric platform were used to conduct 
bibliometric and visualized analyses.
RESULTS: A total of 1,693 publications related to presbycusis were retrieved. 
The number of publications increased continuously from 2002 to 2021, and the USA 
occupied the lead position in the field, with the highest research output. The 
most productive and influential institution, author, and journal were the 
University of California, Frisina DR of the University of South Florida, and 
Hearing Research, respectively. Co-citation cluster and trend topics analyses 
revealed that "cochlear synaptopathy", "oxidative stress", and "dementia" were 
the predominant foci of presbycusis research. Burst detection of keywords 
indicated that "auditory cortex" and "Alzheimer's disease" were the 
newly-emerged aspects.
CONCLUSION: During the past two decades, presbycusis research has been 
flourishing. The current research foci are "cochlear synaptopathy", "oxidative 
stress", and "dementia". "Auditory cortex" and "Alzheimer's disease" may be 
potential future directions in this field. This bibliometric analysis represents 
the first quantitative overview of presbycusis research, thus providing valuable 
references and insights for scholars, medical practitioners, and policymakers 
concerned with this field.

AJTR Copyright © 2023.

PMCID: PMC10182487
PMID: 37193136

Conflict of interest statement: None.


606. Annu Int Conf IEEE Eng Med Biol Soc. 2020 Jul;2020:956-959. doi: 
10.1109/EMBC44109.2020.9175693.

Automated machine learning based speech classification for hearing aid 
applications and its real-time implementation on smartphone.

Bhat GS, Shankar N, Panahi IMS.

Deep neural networks (DNNs) have been useful in solving benchmark problems in 
various domains including audio. DNNs have been used to improve several speech 
processing algorithms that improve speech perception for hearing impaired 
listeners. To make use of DNNs to their full potential and to configure models 
easily, automated machine learning (AutoML) systems are developed, focusing on 
model optimization. As an application of AutoML to audio and hearing aids, this 
work presents an AutoML based voice activity detector (VAD) that is implemented 
on a smartphone as a real-time application. The developed VAD can be used to 
elevate the performance of speech processing applications like speech 
enhancement that are widely used in hearing aid devices. The classification 
model generated by AutoML is computationally fast and has minimal processing 
delay, which enables an efficient, real-time operation on a smartphone. The 
steps involved in real-time implementation are discussed in detail. The key 
contribution of this work include the utilization of AutoML platform for hearing 
aid applications and the realization of AutoML model on smartphone. The 
experimental analysis and results demonstrate the significance and importance of 
using the AutoML for the current approach. The evaluations also show 
improvements over the state of art techniques and reflect the practical 
usability of the developed smartphone app in different noisy environments.

DOI: 10.1109/EMBC44109.2020.9175693
PMCID: PMC7545263
PMID: 33018143 [Indexed for MEDLINE]


607. Acta Otolaryngol Suppl. 1995;520 Pt 1:205-6. doi: 10.3109/00016489509125229.

Computer assisted data collection in vestibular disorders.

Kentala E(1), Pyykkö I, Auramo Y, Juhola M.

Author information:
(1)Department of Otolaryngology, University Hospital of Helsinki, Finland.

We have developed an interactive database for vertigo than can be used to assist 
in the diagnostic procedure and to store the data in a form of a database. The 
database offers the possibility to split and reunite the collected information 
in a desired way. The database contains detailed information about patient 
history, symptoms and findings in neurotological, audiological and imaging 
tests. The symptoms are classified into three sets of questions: vertigo 
(including postural instability), hearing loss and tinnitus, and provoking 
factors. Confounding disorders are screened. The neurotological tests involve 
saccades, smooth pursuit, posturography and caloric test. In addition, findings 
in specified antibody testing, clinical neurotological tests. MRI, brain stem 
audiometry and electrocochleography are included. The input information can be 
applied in an expert system ONE for vertigo work-up. The database is 
user-friendly. Besides diagnostic purposes the database is excellent for 
research purposes, and combined with the expert system it works as a tutorial 
guide for medical students.

DOI: 10.3109/00016489509125229
PMID: 8749120 [Indexed for MEDLINE]


608. Neurol Sci. 2024 Mar;45(3):1209-1216. doi: 10.1007/s10072-023-07116-w. Epub 2023 
Oct 16.

Phenotypes and clinical subgroups in vestibular migraine: a cross-sectional 
study with cluster analysis.

Teggi R(1), Colombo B(2), Cugnata F(3), Albera R(4), Libonati GA(5), Balzanelli 
C(6), Casani AP(7), Cangiano I(8), Familiari M(8), Lucisano S(4), Mandalà M(9), 
Neri G(10), Pecci R(11), Bussi M(8), Filippi M(2).

Author information:
(1)ENT Div., San Raffaele Scientific Institute, Vita e Salute University, Milan, 
Italy. teggi.roberto@hsr.it.
(2)Div. of Neurology, San Raffaele Scientific Institute, Vita e Salute 
University, Milan, Italy.
(3)University Centre for Statistics in the Biomedical Sciences (CUSSB), 
Vita-Salute San Raffaele University, Milan, Italy.
(4)Dipartimento di Scienze, Chirurgiche Università di Torino, Turin, Italy.
(5)U.O.S.D. "Vestibologia e Otorinolaringoiatria" Presidio Ospedaliero "Giovanni 
Paolo II, Policoro, Italy.
(6)Department of Otolaryngology, University of Brescia, Spedali Civili, Brescia, 
Italy.
(7)Department of Otorhinolaryngology, Pisa University Medical School 
Otorhinolaryngology, Pisa University Medical School, Pisa, Italy.
(8)ENT Div., San Raffaele Scientific Institute, Vita e Salute University, Milan, 
Italy.
(9)Otology and Skull Base Unit, Azienda Ospedaliera Universitaria Senese, Siena, 
Italy.
(10)Department of Neurosciences, Imaging and Clinical Sciences, University of 
Chieti-Pescara, Chieti, Italy.
(11)Unit of Audiology, Department of Surgical Sciences and Translational 
Medicine, Careggi Hospital, University of Florence, Florence, Italy.

OBJECTIVE: The aim of this multicentric cross-sectional study was to collect 
phenotypes and clinical variability on a large sample of 244 patients enrolled 
in different university centers in Italy, trying to differentiate subtypes of 
VM.
BACKGROUND: VM is one of the most frequent episodic vertigo characterized by a 
great clinical variability for duration of attacks and accompanying symptoms. 
Diagnosis is based only on clinical history of episodic vertigo in 50% of cases 
associated with migrainous headache or photo/phonophobia.
METHODS: We enrolled in different university centers 244 patients affected by 
definite VM according to the criteria of the Barany Society between January 2022 
and December 2022. An audiometric examination and a CNS MRI were performed 
before inclusion. Patients with low-frequency sensorineural hearing loss were 
not included, as well as patients with an MRI positive otherwise that for 
microischemic lesions. Patients were asked to characterize vestibular symptoms 
choosing among (multiple answers were allowed): internal vertigo, dizziness, 
visuo-vestibular symptoms/external vertigo; onset of vertigo and duration, 
neurovegetative, and cochlear accompanying symptoms (hearing loss, tinnitus, and 
fullness during attacks) were collected as well as migrainous headache and/or 
photo/phonophobia during vertigo; autoimmune disorders were also analyzed. A 
bedside examination was performed including study of spontaneous-positional 
nystagmus with infrared video goggles, post head shaking ny, skull vibration 
test, and video head impulse test.
RESULTS: We included 244 subjects, 181 were females (74.2%). The age of onset of 
the first vertigo was 36.6 ± 14.5 while of the first headache was 23.2 ± 10.1. A 
positive correlation has been found between the first headache and the first 
vertigo. The mean duration of vertigo attacks was 11 ± 16 h. We carried on a 
cluster analysis to identify subgroups of patients with common clinical 
features. Four variables allowed to aggregate clusters: age of onset of vertigo, 
duration of vertigo attacks, presence of migrainous headache during vertigo, and 
presence of cochlear symptoms during vertigo. We identified 5 clusters: cluster 
1/group 1 (23 subjects, 9.4%) characterized by longer duration of vertigo 
attacks; cluster 2/group 2 (52 subjects, 21.3%) characterized by absence of 
migrainous headache and cochlear symptoms during vertigo; cluster 3/group 3 (44 
subjects, 18%) characterized by presence of cochlear symptoms during vertigo but 
not headache; cluster 4/group 4 (57 subjects, 23.4%) by the presence of both 
cochlear symptoms and migrainous headache during vertigo; cluster 5/group 5 (68 
subjects, 27.9%) characterized by migrainous headache but no cochlear symptoms 
during vertigo.
CONCLUSION: VM is with any evidence a heterogeneous disorder and clinical 
presentations exhibit a great variability. In VM, both symptoms orienting toward 
a peripheral mechanism (cochlear symptoms) and central ones (long lasting 
positional non-paroxysmal vertigo) may coexist. Our study is the first published 
trying to characterize subgroups of VM subjects, thus orienting toward different 
pathophysiological mechanisms.

© 2023. Fondazione Società Italiana di Neurologia.

DOI: 10.1007/s10072-023-07116-w
PMID: 37845481 [Indexed for MEDLINE]


609. ORL J Otorhinolaryngol Relat Spec. 1990;52(5):273-80. doi: 10.1159/000276150.

Reissner's membrane in aging, Menière's disease, and profound sensorineural 
deafness.

Quijano ML(1), Kimura RS, Fowler KB.

Author information:
(1)Harvard Medical School, Boston, Mass.

The characteristics of Reissner's membrane from 47 human cochleae with mild 
endolymphatic hydrops, profound sensorineural deafness and normal ears were 
studied by light microscopy. The highest cell densities were observed in the 
zones adjacent to the limbus spiralis and the stria vascularis. The cell density 
of Reissner's in normal ears decreased with age concomitant with an increased 
formation of epithelial cell clusters. In hydrops, the density increased with 
the exception of the apical turn. However, sporadic loss of the cells in 
isolated areas of the membrane was observed. The ears with profound deafness 
showed no significant changes compared with age-related controls. No definite 
relationship between Reissner's cell density and hair cell loss or strial 
atrophy was observed.

DOI: 10.1159/000276150
PMID: 2234897 [Indexed for MEDLINE]


610. Hear Res. 2007 Mar;225(1-2):50-9. doi: 10.1016/j.heares.2006.12.012. Epub 2007 
Jan 13.

Distribution of focal lesions in the chinchilla organ of Corti following 
exposure to a 4-kHz or a 0.5-kHz octave band of noise.

Harding GW(1), Bohne BA.

Author information:
(1)Department of Otolaryngology, Box 8115, Washington University School of 
Medicine, 660 South Euclid Avenue, St. Louis, MO 63110, USA. 
hardingg@ent.wustl.edu

An octave band of noise (OBN) delivers fairly uniform acoustic energy over a 
specific range of frequencies. Above and below this range, energy is at least 30 
dB SPL less than that within the OBN. When the ear is exposed to an OBN, 
hair-cell loss often occurs outside the octave band. The frequency location of 
hair-cell loss is evident when the percent distance from the apex of focal 
lesions is analyzed. Focal lesions involve substantial loss of outer hair cells 
(OHCs) only, inner hair cells (IHCs) only, or both OHCs and IHCs (i.e., combined 
lesions) in a specific region of the organ of Corti (OC). Data sets were 
assembled from our permanent collection of noise-exposed chinchillas as follows: 
(1) the sum of exposure duration and recovery time was less than or equal to 11 
d; (2) the exposure level was less than or equal to 108 dB SPL; and (3) focal 
lesions were less than 1.5mm in length. The data sets included a variety of 
exposures ranging from high-level, short duration to moderate-level, moderate 
duration. The center of each focal lesion was expressed as percent distance from 
the OC apex. Means, standard deviations and medians were calculated for 
focal-lesion size resulting from exposure to a 4-kHz or a 0.5-kHz OBN. 
Histograms were then constructed from the percent-location data using 2.0% bins. 
For the 4-kHz OBN, 5% of the lesions were in the apical half of the OC and 95% 
were in the basal half. The mean lesion size was 1.68% of total OC length for 
OHC and combined focal lesions and 0.42% for IHC focal lesions. Most OHC and 
combined lesions occurred in the 5-7-kHz region, at and just above the upper 
edge of the OBN. Clusters of lesions were also found around 8 and 12 kHz. A 
cluster was present at and just below the lower edge of the OBN, as well as 
another in the 1.5-kHz region. For the 0.5-kHz OBN, 34% of the lesions were in 
the apical half of the OC and 66% were in the basal half. The mean lesion size 
was 0.93% for OHC and combined focal lesions and 0.32% for IHC focal lesions. 
OHC and combined focal-lesion distribution showed clusters at 0.25, 0.75 and 1.5 
kHz in the apical half of the OC. In the basal half, the distribution of focal 
lesions was similar to that seen with the 4-kHz OBN (r=0.54). With both OBNs, 
most IHC focal lesions occurred in the basal half of the OC. High resolution 
power spectrum analysis of each OBN and non-invasive tests for harmonics and 
distortion products in a chinchilla were performed to look for exposure energy 
above and below the OBN. No energy was found that could explain the OC damage.

DOI: 10.1016/j.heares.2006.12.012
PMID: 17291699 [Indexed for MEDLINE]


611. J Acoust Soc Am. 2018 Jan;143(1):150. doi: 10.1121/1.5020269.

Stability-controlled hybrid adaptive feedback cancellation scheme for hearing 
aids.

Nordholm S(1), Schepker H(2), Tran LTT(1), Doclo S(2).

Author information:
(1)Department of Electrical and Computer Engineering, Curtin University, Perth, 
WA, 6102, Australia.
(2)Signal Processing Group, Department of Medical Physics and Acoustics and 
Cluster of Excellence "Hearing4All," University of Oldenburg, Oldenburg, 
Germany.

Adaptive feedback cancellation (AFC) techniques are common in modern hearing aid 
devices (HADs) since these techniques have been successful in increasing the 
stable gain. Accordingly, there has been a significant effort to improve AFC 
technology, especially for open-fitting and in-ear HADs, for which howling is 
more prevalent due to the large acoustic coupling between the loudspeaker and 
the microphone. In this paper, the authors propose a hybrid AFC (H-AFC) scheme 
that is able to shorten the time it takes to recover from howling. The proposed 
H-AFC scheme consists of a switched combination adaptive filter, which is 
controlled by a soft-clipping-based stability detector to select either the 
standard normalized least mean squares (NLMS) algorithm or the 
prediction-error-method (PEM) NLMS algorithm to update the adaptive filter. The 
standard NLMS algorithm is used to obtain fast convergence, while the PEM-NLMS 
algorithm is used to provide a low bias solution. This stability-controlled 
adaptation is hence the means to improve performance in terms of both 
convergence rate as well as misalignment, while only slightly increasing 
computational complexity. The proposed H-AFC scheme has been evaluated for both 
speech and music signals, resulting in a significantly improved convergence and 
re-convergence rate, i.e., a shorter howling period, as well as a lower average 
misalignment and a larger added stable gain compared to using either the NLMS or 
the PEM-NLMS algorithm alone. An objective evaluation using the perceptual 
evaluation of speech quality and the perceptual evaluation of audio quality 
measures shows that the proposed H-AFC scheme provides very high-quality speech 
and music signals. This has also been verified through a subjective listening 
experiment with N = 15 normal-hearing subjects using a multi-stimulus test with 
hidden reference and anchor, showing that the proposed H-AFC scheme results in a 
better perceptual quality than the state-of-the-art PEM-NLMS algorithm.

DOI: 10.1121/1.5020269
PMID: 29390746 [Indexed for MEDLINE]


612. J Neurophysiol. 2003 Oct;90(4):2387-401. doi: 10.1152/jn.00139.2003. Epub 2003 
May 28.

Neural changes in cat auditory cortex after a transient pure-tone trauma.

Noreña AJ(1), Tomita M, Eggermont JJ.

Author information:
(1)Department of Physiology, Neuroscience Research Group, University of Calgary, 
Calgary, Alberta T2N 1N4, Canada.

Here we present the changes in cortical activity occurring within a few hours 
after a 1-h exposure to a 120-dB SPL pure tone (5 or 6 kHz). The changes in 
primary auditory cortex of 16 ketamine-anesthetized cats were assessed by 
recording, with two 8-microelectrode arrays, from the same multiunit clusters 
before and after the trauma. The exposure resulted in a peripheral threshold 
increase that stabilized after a few hours to on average 40 dB in the frequency 
range of 6-32 kHz, as measured by the auditory brain stem response. The trauma 
induced a shift in characteristic frequency toward lower frequencies, an 
emergence of new responses, a broadening of the tuning curve, and an increase in 
the maximum of driven discharges. In addition, the onset response after the 
trauma was of shorter duration than before the trauma. The results suggest the 
involvement of both a decrease and an increase in inhibition. They are discussed 
in terms of changes in central inhibition and its implications for tonotopic map 
plasticity.

DOI: 10.1152/jn.00139.2003
PMID: 12773493 [Indexed for MEDLINE]


613. Ear Hear. 2023 Jul-Aug 01;44(4):721-731. doi: 10.1097/AUD.0000000000001317. Epub 
2022 Dec 29.

Conductive Hearing Loss Estimated From Wideband Acoustic Immittance Measurements 
in Ears With Otitis Media With Effusion.

Merchant GR(1), Neely ST.

Author information:
(1)Center for Hearing Research, Boys Town National Research Hospital, Omaha, 
Nebraska, USA.

OBJECTIVES: Previous work has shown that wideband acoustic immittance (WAI) is 
sensitive to the volume of effusion present in ears with otitis media with 
effusion (OME). Prior work also demonstrates that the volume of the effusion 
appears to drive, or at least play a significant role in, how much conductive 
hearing loss (CHL) a child has due to a given episode of OME. Given this 
association, the goal of this work was to determine how well CHL could be 
estimated directly from WAI in ears with OME.
DESIGN: Sixty-three ears from a previously published study on OME (ages 9 months 
to 11 years, 2 months) were grouped based on effusion volume (full, partial, or 
clear) determined during tympanostomy tube placement surgery and compared with 
age-matched normal control ears. Audiometric thresholds were obtained for a 
subset of the 34 ears distributed across the four groups. An electrical-analog 
model of ear-canal acoustics and middle-ear mechanics was fit to the measured 
WAI from individual ears. Initial estimates of CHL were derived from either (1) 
average absorbance or (2) the model component thought to represent damping in 
the ossicular chain.
RESULTS: The analog model produced good fits for all effusion-volume groups. The 
two initial CHL estimates were both well correlated (87% and 81%) with the 
pure-tone average hearing thresholds used to define the CHL. However, in roughly 
a third of the ears (11/34), the estimate based on damping was too large by 
nearly a factor of two. This observation motivated improved CHL estimates.
CONCLUSIONS: Our CHL estimation method can estimate behavioral audiometric 
thresholds (CHL) within a margin of error that is small enough to be clinically 
meaningful. The importance of this finding is increased by the challenges 
associated with behavioral audiometric testing in pediatric populations, where 
OME is the most common. In addition, the discovery of two clusters in the 
damping-related CHL estimate suggests the possible existence of two distinctly 
different types of ears: pressure detectors and power detectors.

Copyright © 2022 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/AUD.0000000000001317
PMCID: PMC10271999
PMID: 36607739 [Indexed for MEDLINE]

Conflict of interest statement: Financial disclosures/conflicts of interest: 
This study was funded by the National Institute of General Medical Sciences 
(P20GM109023) and the National Institute on Deafness and Other Communication 
Disorders (R01DC008318 and L30DC017300). The funding sources had no role in the 
design and conduct of the study; in the collection, analysis, and interpretation 
of the data; or in the decision to submit the article for publication; or in the 
preparation, review, or approval of the article. There are no conflicts of 
interest, financial, or otherwise.


614. Front Psychol. 2017 Feb 21;8:219. doi: 10.3389/fpsyg.2017.00219. eCollection 
2017.

Auditory and Non-Auditory Contributions for Unaided Speech Recognition in Noise 
as a Function of Hearing Aid Use.

Gieseler A(1), Tahden MA(1), Thiel CM(2), Wagener KC(3), Meis M(3), Colonius 
H(1).

Author information:
(1)Cluster of Excellence 'Hearing4all', University of OldenburgOldenburg, 
Germany; Cognitive Psychology Lab, Department of Psychology, University of 
OldenburgOldenburg, Germany.
(2)Cluster of Excellence 'Hearing4all', University of OldenburgOldenburg, 
Germany; Biological Psychology Lab, Department of Psychology, University of 
OldenburgOldenburg, Germany.
(3)Cluster of Excellence 'Hearing4all', University of OldenburgOldenburg, 
Germany; Hörzentrum Oldenburg GmbHOldenburg, Germany.

Differences in understanding speech in noise among hearing-impaired individuals 
cannot be explained entirely by hearing thresholds alone, suggesting the 
contribution of other factors beyond standard auditory ones as derived from the 
audiogram. This paper reports two analyses addressing individual differences in 
the explanation of unaided speech-in-noise performance among n = 438 elderly 
hearing-impaired listeners (mean = 71.1 ± 5.8 years). The main analysis was 
designed to identify clinically relevant auditory and non-auditory measures for 
speech-in-noise prediction using auditory (audiogram, categorical loudness 
scaling) and cognitive tests (verbal-intelligence test, screening test of 
dementia), as well as questionnaires assessing various self-reported measures 
(health status, socio-economic status, and subjective hearing problems). Using 
stepwise linear regression analysis, 62% of the variance in unaided 
speech-in-noise performance was explained, with measures Pure-tone average 
(PTA), Age, and Verbal intelligence emerging as the three most important 
predictors. In the complementary analysis, those individuals with the same 
hearing loss profile were separated into hearing aid users (HAU) and non-users 
(NU), and were then compared regarding potential differences in the test 
measures and in explaining unaided speech-in-noise recognition. The groupwise 
comparisons revealed significant differences in auditory measures and 
self-reported subjective hearing problems, while no differences in the cognitive 
domain were found. Furthermore, groupwise regression analyses revealed that 
Verbal intelligence had a predictive value in both groups, whereas Age and PTA 
only emerged significant in the group of hearing aid NU.

DOI: 10.3389/fpsyg.2017.00219
PMCID: PMC5318449
PMID: 28270784


615. J Neurosci. 2015 Feb 4;35(5):1999-2014. doi: 10.1523/JNEUROSCI.3449-14.2015.

A short splice form of Xin-actin binding repeat containing 2 (XIRP2) lacking the 
Xin repeats is required for maintenance of stereocilia morphology and hearing 
function.

Francis SP(1), Krey JF(2), Krystofiak ES(3), Cui R(3), Nanda S(1), Xu W(4), 
Kachar B(3), Barr-Gillespie PG(2), Shin JB(5).

Author information:
(1)Departments of Neuroscience.
(2)Oregon Hearing Research Center & Vollum Institute, Oregon Health & Science 
University, Portland, Oregon 97239, and.
(3)National Institute for Deafness and Communications Disorders, National 
Institute of Health, Bethesda, Maryland 20892.
(4)Gene Targeting and Transgenic Facility, University of Virginia, 
Charlottesville, Virginia 22908.
(5)Departments of Neuroscience, Brain, Immunology, and Glia Center, and 
js2ee@virginia.edu.

Approximately one-third of known deafness genes encode proteins located in the 
hair bundle, the sensory hair cell's mechanoreceptive organelle. In previous 
studies, we used mass spectrometry to characterize the hair bundle's proteome, 
resulting in the discovery of novel bundle proteins. One such protein is 
Xin-actin binding repeat containing 2 (XIRP2), an actin-cross-linking protein 
previously reported to be specifically expressed in striated muscle. Because 
mutations in other actin-cross-linkers result in hearing loss, we investigated 
the role of XIRP2 in hearing function. In the inner ear, XIRP2 is specifically 
expressed in hair cells, colocalizing with actin-rich structures in bundles, the 
underlying cuticular plate, and the circumferential actin belt. Analysis using 
peptide mass spectrometry revealed that the bundle harbors a previously 
uncharacterized XIRP2 splice variant, suggesting XIRP2's role in the hair cell 
differs significantly from that reported in myocytes. To determine the role of 
XIRP2 in hearing, we applied clustered regularly interspaced short palindromic 
repeat (CRISPR)/Cas9-mediated genome-editing technology to induce targeted 
mutations into the mouse Xirp2 gene, resulting in the elimination of XIRP2 
protein expression in the inner ear. Functional analysis of hearing in the 
resulting Xirp2-null mice revealed high-frequency hearing loss, and 
ultrastructural scanning electron microscopy analyses of hair cells demonstrated 
stereocilia degeneration in these mice. We thus conclude that XIRP2 is required 
for long-term maintenance of hair cell stereocilia, and that its dysfunction 
causes hearing loss in the mouse.

Copyright © 2015 the authors 0270-6474/15/351999-16$15.00/0.

DOI: 10.1523/JNEUROSCI.3449-14.2015
PMCID: PMC4315831
PMID: 25653358 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing financial 
interests.


616. Cereb Cortex. 2005 Jan;15(1):40-8. doi: 10.1093/cercor/bhh106. Epub 2004 Jul 6.

FMRI evidence for activation of multiple cortical regions in the primary 
auditory cortex of deaf subjects users of multichannel cochlear implants.

Seghier ML(1), Boëx C, Lazeyras F, Sigrist A, Pelizzone M.

Author information:
(1)Department of Radiology, University Hospital of Geneva, Micheli-du-Crest 24, 
1211 Geneva, Switzerland. mohamed.seghier@medecine.unige.ch

To investigate the activation of the auditory cortex by fMRI, three deaf 
subjects users of the Ineraid cochlear implant participated in our study. 
Possible interference between fMRI acquisition and the implanted electrodes was 
controlled and safe experimental conditions were obtained. For each subject, 
electrical stimuli were applied on different intracochlear electrodes, in 
monopolar mode. Stimulation of each electrode was actually producing auditory 
sensations of different pitches, as demonstrated by psychophysical pitch-ranking 
measurements in the same subjects. Because deaf subjects did not hear scanner 
noise, the data were collected in 'silent background' conditions, i.e. as a 
result of pure auditory sensations. Functional maps showed activation of the 
primary auditory cortex, predominantly in the left hemisphere. Stimulation of 
each different intracochlear electrode revealed different clusters of 
activation. After cluster grouping, at least three regions have been identified 
in the auditory cortex of each subject, and comparisons with previous 
architectonic and functional studies are proposed. However, a tonotopic 
organization could not be clearly identified within each region. These 
arguments, obtained without interference with unwanted scanner noise, plead in 
favor of a functional subdivision of the primary auditory cortex into multiple 
cortical regions in cochlear implant users.

DOI: 10.1093/cercor/bhh106
PMID: 15238446 [Indexed for MEDLINE]


617. Front Aging Neurosci. 2022 Apr 5;14:853320. doi: 10.3389/fnagi.2022.853320. 
eCollection 2022.

Age-Related Inflammation and Oxidative Stress in the Cochlea Are Exacerbated by 
Long-Term, Short-Duration Noise Stimulation.

Fuentes-Santamaría V(1)(2), Alvarado JC(1)(2), Mellado S(1)(2), Melgar-Rojas 
P(1)(2), Gabaldón-Ull MC(1)(2), Cabanes-Sanchis JJ(1)(2), Juiz JM(1)(2)(3).

Author information:
(1)Instituto de Investigación en Discapacidades Neurológicas (IDINE), Albacete, 
Spain.
(2)Facultad de Medicina, Universidad de Castilla-La Mancha, Albacete, Spain.
(3)Department of Otolaryngology, Hannover Medical School, NIFE-VIANNA, Cluster 
of Excellence Hearing4all-German Research Foundation, Hanover, Germany.

We have previously reported that young adult rats exposed to daily, 
short-duration noise for extended time periods, develop accelerated presbycusis 
starting at 6 months of age. Auditory aging is associated with progressive 
hearing loss, cell deterioration, dysregulation of the antioxidant defense 
system, and chronic inflammation, among others. To further characterize cellular 
and molecular mechanisms at the crossroads between noise and age-related hearing 
loss (ARHL), 3-month-old rats were exposed to a noise-accelerated presbycusis 
(NAP) protocol and tested at 6 and 16 months of age, using auditory brainstem 
responses, Real-Time Reverse Transcription-Quantitative PCR (RT-qPCR) and 
immunocytochemistry. Chronic noise-exposure leading to permanent auditory 
threshold shifts in 6-month-old rats, resulted in impaired sodium/potassium 
activity, degenerative changes in the lateral wall and spiral ganglion, 
increased lipid peroxidation, and sustained cochlear inflammation with advancing 
age. Additionally, at 6 months, noise-exposed rats showed significant increases 
in the gene expression of antioxidant enzymes (superoxide dismutase 1/2, 
glutathione peroxidase 1, and catalase) and inflammation-associated molecules 
[ionized calcium binding adaptor molecule 1, interleukin-1 beta (IL-1β), and 
tumor necrosis factor-alpha]. The levels of IL-1β were upregulated in the spiral 
ganglion and spiral ligament, particularly in type IV fibrocytes; these cells 
showed decreased levels of connective tissue growth factor and increased levels 
of 4-hydroxynonenal. These data provide functional, structural and molecular 
evidence that age-noise interaction contributes to exacerbating presbycusis in 
young rats by leading to progressive dysfunction and early degeneration of 
cochlear cells and structures. These findings contribute to a better 
understanding of NAP etiopathogenesis, which is essential as it affects the life 
quality of young adults worldwide.

Copyright © 2022 Fuentes-Santamaría, Alvarado, Mellado, Melgar-Rojas, 
Gabaldón-Ull, Cabanes-Sanchis and Juiz.

DOI: 10.3389/fnagi.2022.853320
PMCID: PMC9016828
PMID: 35450058

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


618. Trends Hear. 2017 Jan-Dec;21:2331216517717152. doi: 10.1177/2331216517717152.

Sensitivity to Angular and Radial Source Movements as a Function of Acoustic 
Complexity in Normal and Impaired Hearing.

Lundbeck M(1)(2), Grimm G(1)(2), Hohmann V(1)(2), Laugesen S(3), Neher T(1).

Author information:
(1)1 Medizinische Physik and Cluster of Excellence 'Hearing4all,' Department of 
Medical Physics and Acoustics, Oldenburg University, Germany.
(2)2 HörTech gGmbH, Oldenburg, Germany.
(3)3 Eriksholm Research Centre, Snekkersten, Denmark.

In contrast to static sounds, spatially dynamic sounds have received little 
attention in psychoacoustic research so far. This holds true especially for 
acoustically complex (reverberant, multisource) conditions and impaired hearing. 
The current study therefore investigated the influence of reverberation and the 
number of concurrent sound sources on source movement detection in young 
normal-hearing (YNH) and elderly hearing-impaired (EHI) listeners. A listening 
environment based on natural environmental sounds was simulated using virtual 
acoustics and rendered over headphones. Both near-far ('radial') and left-right 
('angular') movements of a frontal target source were considered. The acoustic 
complexity was varied by adding static lateral distractor sound sources as well 
as reverberation. Acoustic analyses confirmed the expected changes in stimulus 
features that are thought to underlie radial and angular source movements under 
anechoic conditions and suggested a special role of monaural spectral changes 
under reverberant conditions. Analyses of the detection thresholds showed that, 
with the exception of the single-source scenarios, the EHI group was less 
sensitive to source movements than the YNH group, despite adequate stimulus 
audibility. Adding static sound sources clearly impaired the detectability of 
angular source movements for the EHI (but not the YNH) group. Reverberation, on 
the other hand, clearly impaired radial source movement detection for the EHI 
(but not the YNH) listeners. These results illustrate the feasibility of 
studying factors related to auditory movement perception with the help of the 
developed test setup.

DOI: 10.1177/2331216517717152
PMCID: PMC5548306
PMID: 28675088 [Indexed for MEDLINE]


619. Hear Res. 2024 Apr 12;447:109008. doi: 10.1016/j.heares.2024.109008. Online 
ahead of print.

Surface electrical stimulation of the auditory cortex preserves efferent medial 
olivocochlear neurons and reduces cochlear traits of age-related hearing loss.

Fuentes-Santamaría V(1), Benítez-Maicán Z(1), Alvarado JC(1), Fernández Del 
Campo IS(2), Gabaldón-Ull MC(1), Merchán MA(2), Juiz JM(3).

Author information:
(1)School of Medicine, Universidad de Castilla-La Mancha (UCLM), Campus in 
Albacete, 02008, Albacete, Spain.
(2)Lab. of Auditory Neuroplasticity, Institute for Neuroscience of Castilla y 
León (INCYL), University of Salamanca, Salamanca, Spain.
(3)School of Medicine, Universidad de Castilla-La Mancha (UCLM), Campus in 
Albacete, 02008, Albacete, Spain; Hannover Medical School, Dept. of 
Otolaryngology and Cluster of Excellence "H4all" of the German Research 
Foundation, DFG, Carl-Neuberg-Str. 1, 30625 Hannover, Germany. Electronic 
address: josemanuel.juiz@uclm.es.

The auditory cortex is the source of descending connections providing contextual 
feedback for auditory signal processing at almost all levels of the lemniscal 
auditory pathway. Such feedback is essential for cognitive processing. It is 
likely that corticofugal pathways are degraded with aging, becoming important 
players in age-related hearing loss and, by extension, in cognitive decline. We 
are testing the hypothesis that surface, epidural stimulation of the auditory 
cortex during aging may regulate the activity of corticofugal pathways, 
resulting in modulation of central and peripheral traits of auditory aging. 
Increased auditory thresholds during ongoing age-related hearing loss in the rat 
are attenuated after two weeks of epidural stimulation with direct current 
applied to the surface of the auditory cortex for two weeks in alternate days 
(Fernández del Campo et al., 2024). Here we report that the same cortical 
electrical stimulation protocol induces structural and cytochemical changes in 
the aging cochlea and auditory brainstem, which may underlie recovery of 
age-degraded auditory sensitivity. Specifically, we found that in 18 month-old 
rats after two weeks of cortical electrical stimulation there is, relative to 
age-matched non-stimulated rats: a) a larger number of choline acetyltransferase 
immunoreactive neuronal cell body profiles in the ventral nucleus of the 
trapezoid body, originating the medial olivocochlear system.; b) a reduction of 
age-related dystrophic changes in the stria vascularis; c) diminished 
immunoreactivity for the pro-inflammatory cytokine TNFα in the stria vascularis 
and spiral ligament. d) diminished immunoreactivity for Iba1 and changes in the 
morphology of Iba1 immunoreactive cells in the lateral wall, suggesting reduced 
activation of macrophage/microglia; d) Increased immunoreactivity levels for 
calretinin in spiral ganglion neurons, suggesting excitability modulation by 
corticofugal stimulation. Altogether, these findings support that non-invasive 
neuromodulation of the auditory cortex during aging preserves the cochlear 
efferent system and ameliorates cochlear aging traits, including stria 
vascularis dystrophy, dysregulated inflammation and altered excitability in 
primary auditory neurons.

Copyright © 2024 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2024.109008
PMID: 38636186

Conflict of interest statement: Declaration of competing interest The authors 
declare that the research was conducted in the absence of any commercial or 
financial relationships that could be construed as a potential conflict of 
interest.


620. Front Aging Neurosci. 2022 Jun 22;14:891202. doi: 10.3389/fnagi.2022.891202. 
eCollection 2022.

Age-Related Decline of Speech Perception.

Hoppe U(1), Hocke T(2), Iro H(1).

Author information:
(1)Department of Audiology, ENT-Clinic, University of Erlangen-Nürnberg, 
Erlangen, Germany.
(2)Cochlear Deutschland GmbH & Co. KG, Hanover, Germany.

Hearing loss is one of the most common disorders worldwide. It affects 
communicative abilities in all age groups. However, it is well known that 
elderly people suffer more frequently from hearing loss. Two different model 
approaches were employed: A generalised linear model and a random forest 
regression model were used to quantify the relationship between pure-tone 
hearing loss, age, and speech perception. Both models were applied to a large 
clinical data set of 19,801 ears, covering all degrees of hearing loss. They 
allow the estimation of age-related decline in speech recognition for different 
types of audiograms. Our results show that speech scores depend on the specific 
type of hearing loss and life decade. We found age effects for all degrees of 
hearing loss. A deterioration in speech recognition of up to 25 percentage 
points across the whole life span was observed for constant pure-tone 
thresholds. The largest decrease was 10 percentage points per life decade. This 
age-related decline in speech recognition cannot be explained by elevated 
hearing thresholds as measured by pure-tone audiometry.

Copyright © 2022 Hoppe, Hocke and Iro.

DOI: 10.3389/fnagi.2022.891202
PMCID: PMC9257541
PMID: 35813942

Conflict of interest statement: TH was employed by Cochlear Deutschland GmbH & 
Co. KG. The remaining authors declare that the research was conducted in the 
absence of any commercial or financial relationships that could be construed as 
a potential conflict of interest.


621. Neuroscience. 2013 Sep 5;247:117-33. doi: 10.1016/j.neuroscience.2013.05.021. 
Epub 2013 May 21.

Auditory critical periods: a review from system's perspective.

Kral A(1).

Author information:
(1)Hearing4all Cluster of Excellence, Hannover School of Medicine, 
Feodor-Lynen-Str. 35, D-30625 Hannover, Germany. kral.andrej@mh-hannover.de

The article reviews evidence for sensitive periods in the sensory systems and 
considers their neuronal mechanisms from the viewpoint of the system's 
neuroscience. It reviews the essential cortical developmental steps and shows 
its dependence on experience. It differentiates feature representation and 
object representation and their neuronal mechanisms. The most important 
developmental effect of experience is considered to be the transformation of a 
naive cortical neuronal network into a network capable of categorization, by 
that establishing auditory objects. The control mechanisms of juvenile and adult 
plasticity are further discussed. Total absence of hearing experience prevents 
the patterning of the naive auditory system with subsequent extensive 
consequences on the auditory function. Additional to developmental changes in 
synaptic plasticity, other brain functions like corticocortical interareal 
couplings are also influenced by deprivation. Experiments with deaf auditory 
systems reveal several integrative effects of deafness and their reversibility 
with experience. Additional to developmental molecular effects on synaptic 
plasticity, a combination of several integrative effects of deprivation on brain 
functions, including feature representation (affecting the starting point for 
learning), categorization function, top-down interactions and cross-modal 
reorganization close the sensitive periods and may contribute to their critical 
nature. Further, non-auditory effects of auditory deprivation are discussed. To 
reopen critical periods, removal of molecular breaks in synaptic plasticity and 
focused training therapy on the integrative effects are required.

Copyright © 2013 The Author. Published by Elsevier Ltd.. All rights reserved.

DOI: 10.1016/j.neuroscience.2013.05.021
PMID: 23707979 [Indexed for MEDLINE]


622. Cereb Cortex. 2016 Apr;26(4):1762-77. doi: 10.1093/cercor/bhv351. Epub 2016 Jan 
22.

Monaural Congenital Deafness Affects Aural Dominance and Degrades Binaural 
Processing.

Tillein J(1), Hubka P(2), Kral A(3).

Author information:
(1)Cluster of Excellence Hearing4all, Institute of AudioNeuroTechnology and 
Department of Experimental Otology of the ENT Clinics, Hannover Medical School, 
Hannover, Germany Department of Otorhinolaryngology, J.W. Goethe University, 
Frankfurt am Main, Germany MED-EL GmbH, Innsbruck, Austria.
(2)Cluster of Excellence Hearing4all, Institute of AudioNeuroTechnology and 
Department of Experimental Otology of the ENT Clinics, Hannover Medical School, 
Hannover, Germany.
(3)Cluster of Excellence Hearing4all, Institute of AudioNeuroTechnology and 
Department of Experimental Otology of the ENT Clinics, Hannover Medical School, 
Hannover, Germany School of Behavioral and Brain Sciences, The University of 
Texas at Dallas, Richardson, TX, USA.

Cortical development extensively depends on sensory experience. Effects of 
congenital monaural and binaural deafness on cortical aural dominance and 
representation of binaural cues were investigated in the present study. We used 
an animal model that precisely mimics the clinical scenario of unilateral 
cochlear implantation in an individual with single-sided congenital deafness. 
Multiunit responses in cortical field A1 to cochlear implant stimulation were 
studied in normal-hearing cats, bilaterally congenitally deaf cats (CDCs), and 
unilaterally deaf cats (uCDCs). Binaural deafness reduced cortical 
responsiveness and decreased response thresholds and dynamic range. In contrast 
to CDCs, in uCDCs, cortical responsiveness was not reduced, but 
hemispheric-specific reorganization of aural dominance and binaural interactions 
were observed. Deafness led to a substantial drop in binaural facilitation in 
CDCs and uCDCs, demonstrating the inevitable role of experience for a binaural 
benefit. Sensitivity to interaural time differences was more reduced in uCDCs 
than in CDCs, particularly at the hemisphere ipsilateral to the hearing ear. 
Compared with binaural deafness, unilateral hearing prevented nonspecific 
reduction in cortical responsiveness, but extensively reorganized aural 
dominance and binaural responses. The deaf ear remained coupled with the cortex 
in uCDCs, demonstrating a significant difference to deprivation amblyopia in the 
visual system.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/cercor/bhv351
PMCID: PMC4785956
PMID: 26803166 [Indexed for MEDLINE]


623. Brain. 2000 Oct;123 ( Pt 10):2065-76. doi: 10.1093/brain/123.10.2065.

Musical hallucinosis in acquired deafness. Phenomenology and brain substrate.

Griffiths TD(1).

Author information:
(1)Department of Neurology, Newcastle University,Newcastle-upon-Tyne, UK. 
t.d.griffiths@ncl.ac.uk

Six subjects with musical hallucinations following acquired deafness are 
described. The subjects all experienced the condition in the absence of any 
other features to suggest epilepsy or psychosis. I propose a neuropsychological 
model for the condition consistent with detailed observation of the subjects' 
phenomenology. The model is based on spontaneous activity within a cognitive 
module for the analysis of temporal pattern in segmented sound. Functional 
imaging was carried out to test the hypothesis that musical hallucinosis is due 
to activity within such a module, for which the neural substrate is a 
distributed network distinct from the primary auditory cortex. PET was carried 
out on the six subjects to identify areas where brain activity increased as a 
function of the severity of the hallucination. In a group analysis, no effect 
was demonstrated in the primary auditory cortices. Clusters of correlated 
activity were demonstrated in the posterior temporal lobes, the right basal 
ganglia, the cerebellum and the inferior frontal cortices. This network is 
similar to that previously demonstrated during the normal perception and imagery 
of patterned-segmented sound, and is consistent with the proposed 
neuropsychological and neural mechanism.

DOI: 10.1093/brain/123.10.2065
PMID: 11004124 [Indexed for MEDLINE]


624. Proc Natl Acad Sci U S A. 2005 May 31;102(22):7894-9. doi: 
10.1073/pnas.0500760102. Epub 2005 May 19.

A missense mutation in the previously undescribed gene Tmhs underlies deafness 
in hurry-scurry (hscy) mice.

Longo-Guess CM(1), Gagnon LH, Cook SA, Wu J, Zheng QY, Johnson KR.

Author information:
(1)The Jackson Laboratory, Bar Harbor, ME 04609, USA.

Mouse deafness mutations provide valuable models of human hearing disorders and 
entry points into molecular pathways important to the hearing process. A newly 
discovered mouse mutation named hurry-scurry (hscy) causes deafness and 
vestibular dysfunction. Scanning electron microscopy of cochleae from 8-day-old 
mutants revealed disorganized hair bundles, and by 50 days of age, many hair 
cells are missing. To positionally clone hscy, 1,160 F(2) mice were produced 
from an intercross of (C57BL/6-hscy x CAST/EiJ) F(1) hybrids, and the mutation 
was localized to a 182-kb region of chromosome 17. A missense mutation causing a 
critical cysteine to phenylalanine codon change was discovered in a previously 
undescribed gene within this candidate interval. The gene is predicted to encode 
an integral membrane protein with four transmembrane helices. A synthetic 
peptide designed from the predicted protein was used to produce specific 
polyclonal antibodies, and strong immunoreactivity was observed on hair bundles 
of both inner and outer hair cells in cochleae of newborn +/+ controls and 
+/hscy heterozygotes but was absent in hscy/hscy mutants. Accordingly, the gene 
was given the name "tetraspan membrane protein of hair cell stereocilia," symbol 
Tmhs. Two related proteins (>60% amino acid identity) are encoded by genes on 
mouse chromosomes 5 and 6 and, together with the Tmhs-encoded protein (TMHS), 
comprise a distinct tetraspan subfamily. Our localization of TMHS to the apical 
membrane of inner ear hair cells during the period of stereocilia formation 
suggests a function in hair bundle morphogenesis.

DOI: 10.1073/pnas.0500760102
PMCID: PMC1142366
PMID: 15905332 [Indexed for MEDLINE]


625. Eur Arch Otorhinolaryngol. 2023 Oct;280(10):4361-4369. doi: 
10.1007/s00405-023-07924-y. Epub 2023 Apr 1.

MMP-9 plasma level as biomarker of cochlear implantation outcome in cohort study 
of deaf children.

Matusiak M(1)(2), Oziębło D(3)(4), Ołdak M(3)(4), Rejmak E(5), Kaczmarek L(5), 
Dobek D(6), Skarżyński H(7)(3).

Author information:
(1)Oto-Rhino-Laryngosurgery Clinic, Institute of Physiology and Pathology of 
Hearing, M Mochnackiego 10, 02-042, Warsaw, Poland. m.matusiak@ifps.org.pl.
(2)World Hearing Centre, Mokra 17, 05-830, Nadarzyn, Poland. 
m.matusiak@ifps.org.pl.
(3)World Hearing Centre, Mokra 17, 05-830, Nadarzyn, Poland.
(4)Department of Genetics, Institute of Physiology and Pathology of Hearing, M 
Mochnackiego 10, 02-042, Warsaw, Poland.
(5)BRAINCITY, Nencki Institute of Experimental Biology, L Pasteura 3, 02-093, 
Warsaw, Poland.
(6)Transition Technologies Science, Pawia 55, 01-030, Warsaw, Poland.
(7)Oto-Rhino-Laryngosurgery Clinic, Institute of Physiology and Pathology of 
Hearing, M Mochnackiego 10, 02-042, Warsaw, Poland.

Comment in
    Laryngorhinootologie. 2024 Jan;103(1):8.

PURPOSE: If before cochlear implantation it was possible to assay biomarkers of 
neuroplasticity, we might be able to identify those children with congenital 
deafness who, later on, were at risk of poor speech and language rehabilitation 
outcomes.
METHODS: A group of 40 children aged up to 2 years with DFNB1-related congenital 
deafness was observed in this prospective cohort study over three follow-up 
intervals (0, 8, and 18 months) after cochlear implant (CI) activation. Children 
were assessed for auditory development using the LittlEARS Questionnaire (LEAQ) 
score, and at the same time, measurements were made of matrix 
metalloproteinase-9 (MMP-9) plasma levels.
RESULTS: There were significant negative correlations between plasma levels of 
MMP-9 at 8-month follow-up and LEAQ score at cochlear implantation (p = 0.04) 
and LEAQ score at 18-month follow-up (p = 0.02) and between MMP-9 plasma levels 
at 18-month follow-up and LEAQ score at cochlear implantation (p = 0.04). As 
already reported, we confirmed a significant negative correlation between MMP-9 
plasma level at cochlear implantation and LEAQ score at 18-month follow-up 
(p = 0.005). Based on this latter correlation, two clusters of good and poor CI 
performers could be isolated.
CONCLUSIONS: The study shows that children born deaf who have an MMP-9 plasma 
level of less than 150 ng/ml at cochlear implantation have a good chance of 
attaining a high LEAQ score after 18 months of speech and language 
rehabilitation. This indicates that MMP-9 plasma level at cochlear implantation 
is a good prognostic marker for CI outcome.

© 2023. The Author(s).

DOI: 10.1007/s00405-023-07924-y
PMCID: PMC10497633
PMID: 37004521 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no competing interests to 
declare that are relevant to the content of this article.


626. Res Sq [Preprint]. 2023 Sep 27:rs.3.rs-3370200. doi: 
10.21203/rs.3.rs-3370200/v1.

Neuroinflammation in a Mouse Model of Alzheimer's Disease versus Auditory 
Dysfunction: Machine Learning Interpretation and Analysis.

Na D(1), Yang Y(2), Xie L(1), Piekna-Przybylska D(1), Bunn D(1), Shamambo M(1), 
White P(1).

Author information:
(1)University of Rochester Medical Center.
(2)Rochester Institute of Technology.

BACKGROUND: Auditory dysfunction, including central auditory hyperactivity, 
hearing loss and hearing in noise deficits, has been reported in 5xFAD 
Alzheimer's disease (AD) mice, suggesting a causal relationship between 
amyloidosis and auditory dysfunction. Central auditory hyperactivity correlated 
in time with small amounts of plaque deposition in the inferior colliculus and 
medial geniculate body, which are the auditory midbrain and thalamus, 
respectively. Neuroinflammation has been associated with excitation to 
inhibition imbalance in the central nervous system, and therefore has been 
proposed as a link between central auditory hyperactivity and AD in our previous 
report. However, neuroinflammation in the auditory pathway has not been 
investigated in mouse amyloidosis models.
METHODS: Machine learning was used to classify the previously obtained auditory 
brainstem responses (ABRs) from 5xFAD mice and their wild type (WT) littermates. 
Neuroinflammation was assessed in six auditory-related regions of the cortex, 
thalamus, and brainstem. Cochlear pathology was assessed in cryosection and 
whole mount. Behavioral changes were assessed with fear conditioning, open field 
testing and novel objection recognition.
RESULTS: Reliable machine learning classification of 5xFAD and WT littermate 
ABRs were achieved for 6M and 12M, but not 3M. The top features for accurate 
classification at 6 months of age were characteristics of Waves IV and V. 
Microglial and astrocytic activation were pronounced in 5xFAD inferior 
colliculus and medial geniculate body at 6 months, two neural centers that are 
thought to contribute to these waves. Lower regions of the brainstem were 
unaffected, and cortical auditory centers also displayed inflammation beginning 
at 6 months. No losses were seen in numbers of spiral ganglion neurons (SGNs), 
auditory synapses, or efferent synapses in the cochlea. 5xFAD mice had reduced 
responses to tones in fear conditioning compared to WT littermates beginning at 
6 months.
CONCLUSIONS: Serial use of ABR in early AD patients represents a promising 
approach for early and inexpensive detection of neuroinflammation in higher 
auditory brainstem processing centers. As changes in auditory processing are 
strongly linked to AD progression, central auditory hyperactivity may serve as a 
biomarker for AD progression and/or stratify AD patients into distinct 
populations.

DOI: 10.21203/rs.3.rs-3370200/v1
PMCID: PMC10571613
PMID: 37841847


627. Hear Res. 2019 Jan;371:40-52. doi: 10.1016/j.heares.2018.11.003. Epub 2018 Nov 
12.

Intracochlear near infrared stimulation: Feasibility of optoacoustic stimulation 
in vivo.

Baumhoff P(1), Kallweit N(2), Kral A(3).

Author information:
(1)Institute of AudioNeuroTechnology and Department of Experimental Otology, ENT 
Clinics, Hannover Medical School, Stadtfelddamm 34, 30625, Hannover, Germany. 
Electronic address: baumhoff.peter@mh-hannover.de.
(2)Laser Zentrum Hannover e.V. (LZH), Hollerithallee 8, 30419, Hannover, 
Germany; DFG Cluster of Excellence, Hearing 4 All, Germany. Electronic address: 
nicolekallweit@gmx.de.
(3)Institute of AudioNeuroTechnology and Department of Experimental Otology, ENT 
Clinics, Hannover Medical School, Stadtfelddamm 34, 30625, Hannover, Germany; 
DFG Cluster of Excellence, Hearing 4 All, Germany. Electronic address: 
kral.andrej@mh-hannover.de.

Intracochlear optical stimulation has been suggested as an alternative approach 
to hearing prosthetics in recent years. This study investigated the properties 
of a near infrared laser (NIR) induced optoacoustic effect. Pressure recordings 
were performed at the external meatus of anaesthetized guinea pigs during 
intracochlear NIR stimulation. The sound pressure and power spectra were 
determined. The results were compared to multi unit responses in the inferior 
colliculus (IC). Additionally, the responses to NIR stimulation were compared to 
IC responses induced by intracochlear electric stimulation at the same cochlear 
position to investigate a potentially confounding contribution of direct neural 
NIR stimulation. The power spectra of the sound recorded at the external meatus 
(n = 7) had most power at frequencies below 10 kHz and showed little variation 
for different stimulation sites. The mean spike rates of IC units responding to 
intracochlear NIR stimulation (n = 222) of 17 animals were significantly 
correlated with the power of the externally recorded signal at frequencies 
corresponding to the best frequencies of the IC units. The response strength as 
well as the sound pressure at the external meatus depended on the pulse peak 
power of the optical stimulus. The sound pressure recorded at the external 
meatus reached levels above 70 dB SPL peak equivalent. In hearing animals a 
cochlear activation apical to the location of the fiber was found. The absence 
of any NIR responses after pharmacologically deafening and the comparison to 
electric stimulation at the NIR stimulation site revealed no indication of a 
confounding direct neural NIR stimulation. Intracochlear optoacoustic 
stimulation might become useful in combined electro-acoustic stimulation devices 
in the future.

Copyright © 2018 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2018.11.003
PMID: 30458383 [Indexed for MEDLINE]


628. Sci Rep. 2020 May 12;10(1):7848. doi: 10.1038/s41598-020-64671-4.

Statistical learning of transition patterns in the songbird auditory forebrain.

Dong M(1), Vicario DS(2).

Author information:
(1)Department of Psychology, Rutgers, the State University of New Jersey, New 
Brunswick, NJ, United States. mingwen.dong7@gmail.com.
(2)Department of Psychology, Rutgers, the State University of New Jersey, New 
Brunswick, NJ, United States.

Statistical learning of transition patterns between sounds-a striking capability 
of the auditory system-plays an essential role in animals' survival (e.g., 
detect deviant sounds that signal danger). However, the neural mechanisms 
underlying this capability are still not fully understood. We recorded 
extracellular multi-unit and single-unit activity in the auditory forebrain of 
awake male zebra finches while presenting rare repetitions of a single sound in 
a long sequence of sounds (canary and zebra finch song syllables) patterned in 
either an alternating or random order at different inter-stimulus intervals 
(ISI). When preceding stimuli were regularly alternating (alternating 
condition), a repeated stimulus violated the preceding transition pattern and 
was a deviant. When preceding stimuli were in random order (control condition), 
a repeated stimulus did not violate any regularities and was not a deviant. At 
all ISIs tested (1 s, 3 s, or jittered at 0.8-1.2 s), deviant repetition 
enhanced neural responses in the alternating condition in a secondary auditory 
area (caudomedial nidopallium, NCM) but not in the primary auditory area (Field 
L2); in contrast, repetition suppressed responses in the control condition in 
both Field L2 and NCM. When stimuli were presented in the classical oddball 
paradigm at jittered ISI (0.8-1.2 s), neural responses in both NCM and Field L2 
were stronger when a stimulus occurred as deviant with low probability than when 
the same stimulus occurred as standard with high probability. Together, these 
results demonstrate: (1) classical oddball effect exists even when ISI is 
jittered and the onset of a stimulus is not fully predictable; (2) neurons in 
NCM can learn transition patterns between sounds at multiple ISIs and detect 
violation of these transition patterns; (3) sensitivity to deviant sounds 
increases from Field L2 to NCM in the songbird auditory forebrain. Further 
studies using the current paradigms may help us understand the neural substrate 
of statistical learning and even speech comprehension.

DOI: 10.1038/s41598-020-64671-4
PMCID: PMC7217825
PMID: 32398864 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


629. J Comp Neurol. 2005 Mar 21;483(4):458-75. doi: 10.1002/cne.20437.

Quantitative changes in calretinin immunostaining in the cochlear nuclei after 
unilateral cochlear removal in young ferrets.

Fuentes-Santamaria V(1), Alvarado JC, Taylor AR, Brunso-Bechtold JK, Henkel CK.

Author information:
(1)Department of Neurobiology and Anatomy, Wake Forest University School of 
Medicine, Winston-Salem, North Carolina 27157-1010, USA. vfuentes@fubmc.edu

Neurons of the cochlear nuclei receive axosomatic endings from primary afferent 
fibers from the cochlea and have projections that diverge to form parallel 
ascending auditory pathways. These cells are characterized by neurochemical 
phenotypes such as levels of calretinin. To test whether or not early 
deafferentation results in changes in calretinin immunostaining in the cochlear 
nucleus, unilateral cochlear ablations were performed in ferrets soon after 
hearing onset (postnatal day [P]30-P40). Two months later, changes in calretinin 
immunostaining as well as cell size, volume, and synaptophysin immunostaining 
were assessed in the anteroventral (AVCN), posteroventral (PVCN), and dorsal 
cochlear nucleus (DCN). A decrease in calretinin immunostaining was evident 
ipsilaterally within the AVCN and PVCN but not in the DCN. Further analysis 
revealed a decrease both in the calretinin-immunostained neuropil and in the 
calretinin-immunostained area within AVCN and PVCN neurons. These declines were 
accompanied by significant ipsilateral decreases in volume as well as neuron 
area in the AVCN and PVCN compared with the contralateral cochlear nucleus and 
unoperated animals, but not compared with the DCN. In addition, there was a 
significant contralateral increase in calretinin-immunostained area within AVCN 
and PVCN neurons compared with control animals. Finally, a decrease in area of 
synaptophysin immunostaining in both the ipsilateral AVCN and PVCN without 
changes in the number of boutons was found. The present data demonstrate that 
unilateral cochlear ablation leads to 1) decreased immunostaining of the 
neuropil in the AVCN and PVCN ipsilaterally, 2) decreased calretinin 
immunostaining within AVCN and PVCN neurons ipsilaterally, 3) synaptogenesis in 
the AVCN and PVCN ipsilaterally, and 4) increased calretinin immunostaining 
within AVCN and PVCN neurons contralaterally.

Copyright 2005 Wiley-Liss, Inc.

DOI: 10.1002/cne.20437
PMCID: PMC1913210
PMID: 15700274 [Indexed for MEDLINE]


630. Annu Int Conf IEEE Eng Med Biol Soc. 2008;2008:5593-6. doi: 
10.1109/IEMBS.2008.4650482.

Conception and design of an automated insertion tool for cochlear implants.

Hussong A(1), Rau T, Eilers H, Baron S, Heimann B, Leinung M, Lenarz T, Majdani 
O.

Author information:
(1)Institute of Robotics, Leibniz Universität Hannover, Germany.

Cochlear implants (CI) are electronic devices incorporating an electrode 
inserted into the human cochlea for direct electric stimulation of the auditory 
nerve. The implantation has become the standard treatment for patients with 
severe-to-profound sensorineural loss not aidable with conventional hearing 
aids. The state of the art operative technique is a facial recess approach to 
the middle ear, following the opening of the scala tympani (cochleostomy) and 
insertion of the electrode array. The facial recess approach is applicable only 
by experienced surgeons and optimal CI results primarily depend on optimal 
electrode placement and minimal traumatic insertion. This also requires a 
certain amount of experience. Additionally several groups work on 
minimally-invasive approaches to the cochlea, resulting in the necessity to 
insert the implant via a keyhole access, which is not applicable with current 
techniques. This paper presents a mechatronic device for an automated insertion 
of the electrode array of a cochlear implant system. Being designed especially 
for minimally-invasive approaches, the tool is also applicable for regular 
facial recess approaches. Moreover the device allows reliable and repeatable 
insertion studies at synthetic models or cadaver specimen. The functionality of 
the tool is proofed with first experiments on a synthetic model.

DOI: 10.1109/IEMBS.2008.4650482
PMID: 19163985 [Indexed for MEDLINE]


631. Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi. 2021 Jul 20;39(7):498-502. doi: 
10.3760/cma.j.cn121094-20200513-00258.

[Investigation on noise exposure level and health status of workers in 
transportation equipment manufacturing industry].

[Article in Chinese; Abstract available in Chinese from the publisher]

Hu SQ(1), Hu WJ(2), Yang S(1), Zhu XH(1), Sun K(1), Jiang SS(1), Qiu YX(1), Li 
XD(1).

Author information:
(1)Labor Health Occupational Disease Prevention Center of Zhuzhou, Zhuzhou 
412011, China.
(2)National Insitute of Occupational Health and Poison Control, Chinese Center 
for Disease Control and Prevention, Beijing 100050, China.

Objective: To explore the noise exposure level and the health status of workers 
in transportation equipment manufacturing industry, and provide a scientific 
basis for guidance and implementation of intervention measures. Methods: From 
January to December in 2019, a total of 2088 noise workers from a large 
enterprise were selected by cluster sampling method in railway transportation 
equipment manufacturing, automobile manufacturing and aerospace aircraft 
manufacturing enterprises. The worker's noise exposure level was detected. 
Occupational health checkups were performed on the noise workers including 
electrical audiometry, blood pressure and electrocardiogram. χ(2) test and trend 
χ(2) test were used to analyze the data. Results: The noise exposure level of 
66.9% (1396/2088) workers exceeded 85 dB (A) , and the median noise level was 
87.9 (84.3-90.3) dB (A) . Among them, workers of railway transportation 
equipment manufacturing enterprises had the highest noise exposure level[89.9 
(87.8-91.6) dB (A) ]. The detection rate of high-frequency hearing loss, 
abnormal blood pressure and abnormal electrocardiogram of noise workers were 
15.7% (327/2088) , 18.1% (378/2088) and 6.1% (128/2088) , respectively. The 
differences in the detection rates of high-frequency hearing loss, abnormal 
blood pressure, and abnormal electrocardiogram in workers of railway 
transportation equipment manufacturing enterprises, automobile manufacturing 
enterprises, and aerospace manufacturing enterprises were statistically 
significant (P<0.05) . Workers of railway transportation equipment manufacturing 
enterprises had higher detection rates of high-frequency hearing loss (17.6%, 
186/1056) . Workers of aerospace manufacturing enterprises had higher detection 
rates of abnormal blood pressure and abnormal electrocardiogram (26.3%, 169/642; 
10.0%, 64/642) . The differences in the detection rates of high-frequency 
hearing loss, abnormal blood pressure and abnormal electrocardiogram of noise 
workers were statistically significant in different age and working age groups, 
and gradually increased with age and working age (P<0.05) . The difference in 
the detection rate of high-frequency hearing loss of noise workers was 
statistically significant in different noise intensity groups, and the overall 
trend was increasing (P<0.05) . Conclusion: The transportation equipment 
manufacturing industry has serious noise hazards, especially the railway 
transportation equipment manufacturing industry. Long-term occupational noise 
exposure can adversely affect workers' hearing and cardiovascular system. 
Enterprises should strengthen occupational health inspections, and at the same 
time, take personal protective measures to protect the health of workers.

Publisher: 目的： 探讨交通运输设备制造行业工人噪声接触水平及其健康状况，为指导和实施干预措施提供科学依据。 方法： 
于2019年1至12月，采用整群抽样方法，在铁路运输设备制造、汽车制造、航天航空器制造企业各选取1家大型企业的噪声作业工人作为调查对象，共2 
088人。测定噪声作业岗位的噪声接触水平，并对噪声作业工人进行纯音测听、血压和心电图测量，采用χ(2)检验和趋势χ(2)检验等统计方法对所得数据进行分析。 
结果： 工人噪声接触水平超过85 dB（A）占66.9%（1 396/2 
088），噪声声级为87.9（84.3~90.3）dB（A），其中铁路运输设备制造企业工人噪声声级最大[89.9（87.8~91.6）dB（A）]。噪声作业工人高频听力损失、血压异常、心电图异常检出率分别为15.7%（327/2 
088）、18.1%（378/2 088）、6.1%（128/2 
088）。铁路运输设备制造、汽车制造、航天航空器制造企业工人的高频听力损失、血压异常和心电图异常检出率差异均有统计学意义（P<0.05）。铁路运输设备制造企业工人高频听力损失检出率较高（17.6%，186/1 
056），航天航空器制造企业工人血压异常和心电图异常检出率较高（26.3%，169/642；10.0%，64/642）。噪声作业工人高频听力损失、血压异常和心电图异常检出率在不同年龄和工龄组的差异均有统计学意义，且随着年龄、工龄增加而逐渐升高（P<0.05），噪声作业工人高频听力损失检出率在不同噪声接触水平组的差异有统计学意义，且总体呈上升趋势（P<0.05）。 
结论： 
交通运输设备制造行业噪声危害严重，尤其是铁路运输设备制造行业。长期职业接触噪声会对工人听力及心血管产生不良影响，企业应加强职业健康检查，同时做好个体防护措施，保护劳动者健康。.

DOI: 10.3760/cma.j.cn121094-20200513-00258
PMID: 34365758 [Indexed for MEDLINE]


632. Development. 2017 Apr 15;144(8):1531-1543. doi: 10.1242/dev.148494. Epub 2017 
Mar 6.

A systems-level approach reveals new gene regulatory modules in the developing 
ear.

Chen J(1), Tambalo M(1), Barembaum M(2), Ranganathan R(1), Simões-Costa M(2), 
Bronner ME(2), Streit A(3).

Author information:
(1)Department of Craniofacial Development and Stem Cell Biology, King's College 
London, London SE1 9RT, UK.
(2)Division of Biology and Biological Engineering, California Institute of 
Technology, Pasadena, CA 91125, USA.
(3)Department of Craniofacial Development and Stem Cell Biology, King's College 
London, London SE1 9RT, UK andrea.streit@kcl.ac.uk.

The inner ear is a complex vertebrate sense organ, yet it arises from a simple 
epithelium, the otic placode. Specification towards otic fate requires diverse 
signals and transcriptional inputs that act sequentially and/or in parallel. 
Using the chick embryo, we uncover novel genes in the gene regulatory network 
underlying otic commitment and reveal dynamic changes in gene expression. 
Functional analysis of selected transcription factors reveals the genetic 
hierarchy underlying the transition from progenitor to committed precursor, 
integrating known and novel molecular players. Our results not only characterize 
the otic transcriptome in unprecedented detail, but also identify new gene 
interactions responsible for inner ear development and for the segregation of 
the otic lineage from epibranchial progenitors. By recapitulating the embryonic 
programme, the genes and genetic sub-circuits discovered here might be useful 
for reprogramming naïve cells towards otic identity to restore hearing loss.

© 2017. Published by The Company of Biologists Ltd.

DOI: 10.1242/dev.148494
PMCID: PMC5399671
PMID: 28264836 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests The authors declare no 
competing or financial interests.


633. Am J Hum Genet. 2017 Oct 5;101(4):630-637. doi: 10.1016/j.ajhg.2017.09.007. Epub 
2017 Sep 28.

FDXR Mutations Cause Sensorial Neuropathies and Expand the Spectrum of 
Mitochondrial Fe-S-Synthesis Diseases.

Paul A(1), Drecourt A(1), Petit F(1), Deguine DD(2), Vasnier C(3), Oufadem M(1), 
Masson C(1), Bonnet C(4), Masmoudi S(5), Mosnier I(6), Mahieu L(7), Bouccara 
D(6), Kaplan J(1), Challe G(8), Domange C(9), Mochel F(10), Sterkers O(6), 
Gerber S(1), Nitschke P(1), Bole-Feysot C(1), Jonard L(11), Gherbi S(12), 
Mercati O(12), Ben Aissa I(12), Lyonnet S(13), Rötig A(1), Delahodde A(3), 
Marlin S(14).

Author information:
(1)UMR 1163, Université Paris Descartes, Sorbonne Paris Cité, Institut IMAGINE, 
24 Boulevard du Montparnasse, 75015 Paris, France.
(2)Service de Génétique Médicale, Hôpital Purpan, 40031 Toulouse, France.
(3)Institute for Integrative Biology of the Cell, Commissariat à l'Energie 
Atomique, Centre National de la Recherche Scientifique, Université Paris-Sud, 
Université Paris-Saclay, 91198, Gif-sur-Yvette Cedex, France.
(4)UMRS 1120, Institut de la Vision, 75012 Paris, France.
(5)Laboratory of Molecular and Cellular Screening Processes, Center of 
Biotechnology of Sfax, 1177 Sfax, Tunisia.
(6)Service d'Oto-Rhino-Laryngologie, Hôpital Pitié-Salpêtrière, Assistance 
Publique-Hôpitaux de Paris, 75013 Paris, France.
(7)Service d'Ophtalmologie, Hôpital Rangueil, 40031 Toulouse, France.
(8)Service d'Ophtalmologie, Hôpital Pitié-Salpêtrière, Assistance 
Publique-Hôpitaux de Paris, 75013 Paris, France.
(9)Service d' d'Oto-Rhino-Laryngologie, Hôpital Lariboisière, 75475 Paris, 
France.
(10)Département de Génétique, Hôpital Pitié-Salpêtrière, Assistance 
Publique-Hôpitaux de Paris, 75013 Paris, France.
(11)Service de Génétique, Laboratoire de Génétique Moléculaire, Hôpital 
Necker-Enfants Malades, Assistance Publique-Hôpitaux de Paris, 75015 Paris, 
France.
(12)Centre de Référence des Surdités Génétiques, Service de Génétique, Hôpital 
Necker-Enfants Malades, Assistance Publique-Hôpitaux de Paris, 75015 Paris, 
France.
(13)UMR 1163, Université Paris Descartes, Sorbonne Paris Cité, Institut IMAGINE, 
24 Boulevard du Montparnasse, 75015 Paris, France; Service de Génétique, Hôpital 
Necker-Enfants Malades, Assistance Publique-Hôpitaux de Paris, 75015 Paris, 
France.
(14)UMR 1163, Université Paris Descartes, Sorbonne Paris Cité, Institut IMAGINE, 
24 Boulevard du Montparnasse, 75015 Paris, France; Centre de Référence des 
Surdités Génétiques, Service de Génétique, Hôpital Necker-Enfants Malades, 
Assistance Publique-Hôpitaux de Paris, 75015 Paris, France; Service de 
Génétique, Hôpital Necker-Enfants Malades, Assistance Publique-Hôpitaux de 
Paris, 75015 Paris, France. Electronic address: sandrine.marlin@aphp.fr.

Hearing loss and visual impairment in childhood have mostly genetic origins, 
some of them being related to sensorial neuronal defects. Here, we report on 
eight subjects from four independent families affected by auditory neuropathy 
and optic atrophy. Whole-exome sequencing revealed biallelic mutations in FDXR 
in affected subjects of each family. FDXR encodes the mitochondrial ferredoxin 
reductase, the sole human ferredoxin reductase implicated in the biosynthesis of 
iron-sulfur clusters (ISCs) and in heme formation. ISC proteins are involved in 
enzymatic catalysis, gene expression, and DNA replication and repair. We 
observed deregulated iron homeostasis in FDXR mutant fibroblasts and indirect 
evidence of mitochondrial iron overload. Functional complementation in a yeast 
strain in which ARH1, the human FDXR ortholog, was deleted established the 
pathogenicity of these mutations. These data highlight the wide clinical 
heterogeneity of mitochondrial disorders related to ISC synthesis.

Copyright © 2017 American Society of Human Genetics. Published by Elsevier Inc. 
All rights reserved.

DOI: 10.1016/j.ajhg.2017.09.007
PMCID: PMC5630197
PMID: 28965846 [Indexed for MEDLINE]


634. PLoS One. 2012;7(12):e52718. doi: 10.1371/journal.pone.0052718. Epub 2012 Dec 
20.

Identification of novel cholesteatoma-related gene expression signatures using 
full-genome microarrays.

Klenke C(1), Janowski S, Borck D, Widera D, Ebmeyer J, Kalinowski J, Leichtle A, 
Hofestädt R, Upile T, Kaltschmidt C, Kaltschmidt B, Sudhoff H.

Author information:
(1)Department of Otolaryngology and Head and Neck Surgery, Klinikum Bielefeld, 
Bielefeld, Germany. christin.zander@klinikumbielefeld.de

BACKGROUND: Cholesteatoma is a gradually expanding destructive epithelial lesion 
within the middle ear. It can cause extensive local tissue destruction in the 
temporal bone and can initially lead to the development of conductive hearing 
loss via ossicular erosion. As the disease progresses, sensorineural hearing 
loss, vertigo or facial palsy may occur. Cholesteatoma may promote the spread of 
infection through the tegmen of the middle ear and cause meningitis or 
intracranial infections with abscess formation. It must, therefore, be 
considered as a potentially life-threatening middle ear disease.
METHODS AND FINDINGS: In this study, we investigated differentially expressed 
genes in human cholesteatomas in comparison to regular auditory canal skin using 
Whole Human Genome Microarrays containing 19,596 human genes. In addition to 
already described up-regulated mRNAs in cholesteatoma, such as MMP9, DEFB2 and 
KRT19, we identified 3558 new cholesteatoma-related transcripts. 811 genes 
appear to be significantly differentially up-regulated in cholesteatoma. 334 
genes were down-regulated more than 2-fold. Significantly regulated genes with 
protein metabolism activity include matrix metalloproteinases as well as PI3, 
SERPINB3 and SERPINB4. Genes like SPP1, KRT6B, PRPH, SPRR1B and LAMC2 are known 
as genes with cell growth and/or maintenance activity. Transport activity genes 
and signal transduction genes are LCN2, GJB2 and CEACAM6. Three cell 
communication genes were identified; one CDH19 and two from the S100 family.
CONCLUSIONS: This study demonstrates that the expression profile of 
cholesteatoma is similar to a metastatic tumour and chronically inflamed tissue. 
Based on the investigated profiles we present novel protein-protein interaction 
and signal transduction networks, which include cholesteatoma-regulated 
transcripts and may be of great value for drug targeting and therapy 
development.

DOI: 10.1371/journal.pone.0052718
PMCID: PMC3527606
PMID: 23285167 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: For this study the authors 
received funding from Cassella-med GmbH & Co. KG. This does not alter the 
authors' adherence to all the PLOS ONE policies on sharing data and materials.


635. Int J Comput Assist Radiol Surg. 2019 Aug;14(8):1267-1273. doi: 
10.1007/s11548-019-01978-2. Epub 2019 Apr 25.

Atlas-based segmentation of temporal bone surface structures.

Powell KA(1), Kashikar T(2), Hittle B(3), Stredney D(3), Kerwin T(3), Wiet 
GJ(4).

Author information:
(1)Department of Biomedical Informatics, The Ohio State University, Columbus, 
OH, 43210, USA. kimerly.powell@osumc.edu.
(2)Ohio University Heritage College of Osteopathic, Ohio University, Athens, OH, 
USA.
(3)Interface Laboratory, The Ohio State University, Columbus, OH, USA.
(4)Department of Otolaryngology, Nationwide Children's Hospital and The Ohio 
State University, Columbus, OH, USA.

PURPOSE: To develop a time-efficient automated segmentation approach that could 
identify surface structures on the temporal bone for use in surgical simulation 
software and preoperative surgical training.
METHODS: An atlas-based segmentation approach was developed to segment the 
tegmen, sigmoid sulcus, exterior auditory canal, interior auditory canal, and 
posterior canal wall in normal temporal bone CT images. This approach was tested 
in images of 20 cadaver bones (10 left, 10 right). The results of the automated 
segmentation were compared to manual segmentation using quantitative metrics of 
similarity, Mahalanobis distance, average Hausdorff distance, and volume 
similarity.
RESULTS: The Mahalanobis distance was less than 0.232 mm for all structures. The 
average Hausdorff distance was less than 0.464 mm for all structures except the 
posterior canal wall and external auditory canal for the right bones. Volume 
similarity was 0.80 or greater for all structures except the sigmoid sulcus that 
was 0.75 for both left and right bones. Visually, the segmented structures were 
accurate and similar to that manually traced by an expert observer.
CONCLUSIONS: An atlas-based approach using a deformable registration of a 
Gaussian-smoothed temporal bone image and refinements using surface landmarks 
was successful in segmenting surface structures of temporal bone anatomy for use 
in pre-surgical planning and training.

DOI: 10.1007/s11548-019-01978-2
PMID: 31025245 [Indexed for MEDLINE]


636. Front Neurosci. 2022 Nov 10;16:966568. doi: 10.3389/fnins.2022.966568. 
eCollection 2022.

Processing of auditory information in forebrain regions after hearing loss in 
adulthood: Behavioral and electrophysiological studies in a rat model.

Johne M(1)(2), Helgers SOA(1), Alam M(1), Jelinek J(1), Hubka P(2)(3)(4), Krauss 
JK(1), Scheper V(2)(5), Kral A(2)(3)(4), Schwabe K(1)(2).

Author information:
(1)Department of Neurosurgery, Hannover Medical School, Hanover, Germany.
(2)Cluster of Excellence Hearing4all, German Research Foundation, Hanover, 
Germany.
(3)Hannover Medical School, Institute of Audioneurotechnology, Hanover, Germany.
(4)Department of Experimental Otology of the ENT Clinics, Hannover Medical 
School, Hanover, Germany.
(5)Department of Otolaryngology, Hannover Medical School, Hanover, Germany.

BACKGROUND: Hearing loss was proposed as a factor affecting development of 
cognitive impairment in elderly. Deficits cannot be explained primarily by 
dysfunctional neuronal networks within the central auditory system. We here 
tested the impact of hearing loss in adult rats on motor, social, and cognitive 
function. Furthermore, potential changes in the neuronal activity in the medial 
prefrontal cortex (mPFC) and the inferior colliculus (IC) were evaluated.
MATERIALS AND METHODS: In adult male Sprague Dawley rats hearing loss was 
induced under general anesthesia with intracochlear injection of neomycin. 
Sham-operated and naive rats served as controls. Postsurgical acoustically 
evoked auditory brainstem response (ABR)-measurements verified hearing loss 
after intracochlear neomycin-injection, respectively, intact hearing in 
sham-operated and naive controls. In intervals of 8 weeks and up to 12 months 
after surgery rats were tested for locomotor activity (open field) and 
coordination (Rotarod), for social interaction and preference, and for learning 
and memory (4-arms baited 8-arms radial maze test). In a final setting, 
electrophysiological recordings were performed in the mPFC and the IC.
RESULTS: Locomotor activity did not differ between deaf and control rats, 
whereas motor coordination on the Rotarod was disturbed in deaf rats (P < 0.05). 
Learning the concept of the radial maze test was initially disturbed in deaf 
rats (P < 0.05), whereas retesting every 8 weeks did not show long-term memory 
deficits. Social interaction and preference was also not affected by hearing 
loss. Final electrophysiological recordings in anesthetized rats revealed 
reduced firing rates, enhanced irregular firing, and reduced oscillatory theta 
band activity (4-8 Hz) in the mPFC of deaf rats as compared to controls (P < 
0.05). In the IC, reduced oscillatory theta (4-8 Hz) and gamma (30-100 Hz) band 
activity was found in deaf rats (P < 0.05).
CONCLUSION: Minor and transient behavioral deficits do not confirm direct impact 
of long-term hearing loss on cognitive function in rats. However, the altered 
neuronal activities in the mPFC and IC after hearing loss indicate effects on 
neuronal networks in and outside the central auditory system with potential 
consequences on cognitive function.

Copyright © 2022 Johne, Helgers, Alam, Jelinek, Hubka, Krauss, Scheper, Kral and 
Schwabe.

DOI: 10.3389/fnins.2022.966568
PMCID: PMC9684731
PMID: 36440269

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


637. Cell. 2018 Aug 23;174(5):1247-1263.e15. doi: 10.1016/j.cell.2018.07.008. Epub 
2018 Aug 2.

Hair Cell Mechanotransduction Regulates Spontaneous Activity and Spiral Ganglion 
Subtype Specification in the Auditory System.

Sun S(1), Babola T(1), Pregernig G(2), So KS(2), Nguyen M(2), Su SM(2), Palermo 
AT(2), Bergles DE(1), Burns JC(3), Müller U(4).

Author information:
(1)The Solomon Snyder Department of Neuroscience and Department of 
Otolaryngology, Head and Neck Surgery, Johns Hopkins University School of 
Medicine, 725 N. Wolfe Street, Baltimore, MD 21205, USA.
(2)Decibel Therapeutics, 1325 Boylston Street, Suite 500, Boston, MA 02215, USA.
(3)Decibel Therapeutics, 1325 Boylston Street, Suite 500, Boston, MA 02215, USA. 
Electronic address: jburns@decibeltx.com.
(4)The Solomon Snyder Department of Neuroscience and Department of 
Otolaryngology, Head and Neck Surgery, Johns Hopkins University School of 
Medicine, 725 N. Wolfe Street, Baltimore, MD 21205, USA. Electronic address: 
umuelle3@jhmi.edu.

Comment in
    Nat Rev Neurosci. 2018 Oct;19(10):579.

Type I spiral ganglion neurons (SGNs) transmit sound information from cochlear 
hair cells to the CNS. Using transcriptome analysis of thousands of single 
neurons, we demonstrate that murine type I SGNs consist of subclasses that are 
defined by the expression of subsets of transcription factors, cell adhesion 
molecules, ion channels, and neurotransmitter receptors. Subtype specification 
is initiated prior to the onset of hearing during the time period when auditory 
circuits mature. Gene mutations linked to deafness that disrupt hair cell 
mechanotransduction or glutamatergic signaling perturb the firing behavior of 
SGNs prior to hearing onset and disrupt SGN subtype specification. We thus 
conclude that an intact hair cell mechanotransduction machinery is critical 
during the pre-hearing period to regulate the firing behavior of SGNs and their 
segregation into subtypes. Because deafness is frequently caused by defects in 
hair cells, our findings have significant ramifications for the etiology of 
hearing loss and its treatment.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cell.2018.07.008
PMCID: PMC6429032
PMID: 30078710 [Indexed for MEDLINE]


638. Neuroreport. 2000 May 15;11(7):1389-93. doi: 10.1097/00001756-200005150-00008.

Microglia-like cells in rat organ of Corti following aminoglycoside ototoxicity.

Wang Z(1), Li H.

Author information:
(1)Department of Otolaryngology, EENT Hospital, Shanghai Medical University, PR 
China.

The repair process of neomycin induced cochlear damage in the postnatal 
developing rat was investigated in the present study. The results showed that 
electron dense atypical cells with a cluster of microvilli on their apical 
surface, resembling early stage of embryonic hair cell, were observed in the 
former hair cell region. The striking finding was that microglia-like cells 
appeared and replaced OHCs in the injured auditory sensory epithelium. Using 
Brdu immunohistochemistry, cell proliferation was found in the area of inner and 
outer spiral sulcus but not in the hair cells and supporting cells. It is 
proposed that microglia-like cells play a role in eliminating waste products 
from the organ of Corti and may participate in direct structural repair.

DOI: 10.1097/00001756-200005150-00008
PMID: 10841344 [Indexed for MEDLINE]


639. Neuroimage. 2017 Feb 1;146:600-608. doi: 10.1016/j.neuroimage.2016.09.033. Epub 
2016 Sep 15.

Enhanced visual adaptation in cochlear implant users revealed by concurrent 
EEG-fNIRS.

Chen LC(1), Stropahl M(2), Schönwiesner M(3), Debener S(4).

Author information:
(1)Neuropsychology Lab, Department of Psychology, European Medical School, 
University of Oldenburg, Oldenburg, Germany. Electronic address: 
ling-chia.chen@uni-oldenburg.de.
(2)Neuropsychology Lab, Department of Psychology, European Medical School, 
University of Oldenburg, Oldenburg, Germany.
(3)International Laboratory for Brain, Music and Sound Research (BRAMS), 
Université de Montréal, Montréal, Québec, Canada.
(4)Neuropsychology Lab, Department of Psychology, European Medical School, 
University of Oldenburg, Oldenburg, Germany; Cluster of Excellence Hearing4all, 
Germany; Research Center Neurosensory Science, University of Oldenburg, Germany.

Previous studies have observed lower visual cortex activation for visual 
processing in cochlear implant (CI) users compared to normal hearing controls, 
while others reported enhanced visual speechreading abilities in CI users. The 
present work investigated whether lower visual cortical activation for visual 
processing can be explained by a more efficient visual sensory encoding in CI 
users. Specifically, we investigated whether CI users show enhanced 
stimulus-specific adaptation for visual stimuli compared to controls. Auditory 
sensory adaptation was also investigated to explore the sensory specificity of 
the predicted effect. Twenty post-lingually deafened adult CI users and twenty 
age-matched controls were presented with repeated visual and auditory stimuli 
during simultaneous acquisition of electroencephalography (EEG) and functional 
near-infrared spectroscopy (fNIRS). By integrating EEG and fNIRS signals we 
found significantly enhanced visual adaptation and lower visual cortex 
activation in CI users compared to controls. That is, responses to repeated 
visual stimuli decreased more prominently in CI users than in controls. The 
results suggest that CI users process visual stimuli more efficiently than 
controls.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2016.09.033
PMID: 27640748 [Indexed for MEDLINE]


640. PLoS One. 2021 Aug 31;16(8):e0256647. doi: 10.1371/journal.pone.0256647. 
eCollection 2021.

Knowledge, attitude and management of hearing screening in children among family 
physicians in the Kingdom of Saudi Arabia.

Alqudah O(1), Alqudah S(2), Al-Bashaireh AM(3), Alharbi N(4), Alqudah AM(5).

Author information:
(1)Department of Community Health, King Fahad Medical City, Riyadh, Saudi 
Arabia.
(2)Faculty of Applied Medical Sciences, Department of Rehabilitation Sciences, 
Jordan University of Science and Technology, Irbid, Jordan.
(3)Faculty of Nursing, Department of Primary Care Nursing, Al-Ahliyya Amman 
University, Amman, Jordan.
(4)Department of Community Health, Second Cluster, Riyadh, Saudi Arabia.
(5)Graduate studies, Al-Balqa Applied University, Amman, Jordan.

BACKGROUND: Early detection and management of hearing loss are important to 
develop ordinary speaking language and academic skills during childhood. Lack of 
knowledge by either parents or health care providers could hinder the process of 
hearing loss diagnosis, such that the intervention will be less effective. There 
is little evidence about the knowledge and practice of family physicians 
regarding hearing screening in Saudi Arabia and worldwide.
OBJECTIVES: This study aimed to assess family physicians' knowledge, attitudes, 
and practices related to hearing loss in children. This in turn will help policy 
makers and educational institutions to establish and promote a program concerned 
with screening, diagnosis and intervention of paediatric hearing loss.
METHODS: A cross-sectional descriptive study enrolled 133 family physicians 
working at primary health centres in Saudi Arabia from March 2020 to September 
2020. A self-reported questionnaire was used to assess the knowledge, attitudes, 
and practices of family physicians concerning hearing loss in children.
RESULTS: The majority of the participants were working under the umbrella of the 
Ministry of Health and around half of them did not screen any child for hearing 
loss. Despite that, 91.7% indicated the importance of neonatal hearing 
screening, 70.7% indicate infant candidacy for cochlear implant and only 33.1% 
know about the existence of the early hearing detection and intervention (EHDI) 
governmental program in kingdom of Saudi Arabia (KSA). Participants were able to 
identify factors associated with hearing loss such as a family history of 
hearing loss (85.6%), meningitis (75%) and craniofacial anomalies (51.5%). The 
most frequent specialists for patient referrals were ear nose and throat ENT 
(75.2%) and audiologists (67.7%).
CONCLUSION: This study shows that family physicians have good general background 
about the benefits of EHDI programs and the management of hearing loss in the 
paediatric population. However, it also indicated insufficient knowledge in 
other domains of hearing loss, including assessments and the presence of the 
EHDI governmental program in KSA. Further actions on the involvement of family 
physicians in the process of neonatal hearing screening, diagnosis and 
intervention for hearing impairment are needed.

DOI: 10.1371/journal.pone.0256647
PMCID: PMC8407574
PMID: 34464417 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


641. J Neurophysiol. 2004 Feb;91(2):1006-12. doi: 10.1152/jn.00771.2003. Epub 2003 
Oct 15.

Differences in glycinergic mIPSCs in the auditory brain stem of normal and 
congenitally deaf neonatal mice.

Leao RN(1), Oleskevich S, Sun H, Bautista M, Fyffe RE, Walmsley B.

Author information:
(1)Synaptic Structure and Function Group, Division of Neuroscience, The John 
Curtin School of Medical Research, The Australian National University, Canberra 
ACT 0200, Australia.

We have investigated the fundamental properties of central auditory glycinergic 
synapses in early postnatal development in normal and congenitally deaf (dn/dn) 
mice. Glycinergic miniature inhibitory postsynaptic currents (mIPSCs) were 
recorded using patch-clamp methods in neurons from a brain slice preparation of 
the medial nucleus of the trapezoid body (MNTB), at 12-14 days postnatal age. 
Our results show a number of significant differences between normal and deaf 
mice. The frequency of mIPSCs is greater (50%) in deaf versus normal mice. Mean 
mIPSC amplitude is smaller in deaf mice than in normal mice (mean mIPSC 
amplitude: deaf, 64 pA; normal, 106 pA). Peak-scaled fluctuation analysis of 
mIPSCs showed that mean single channel conductance is greater in the deaf mice 
(deaf, 64 pS; normal, 45 pS). The mean decay time course of mIPSCs is slower in 
MNTB neurons from deaf mice (mean half-width: deaf, 2.9 ms; normal, 2.3 ms). 
Light- and electron-microscopic immunolabeling results showed that MNTB neurons 
from deaf mice have more (30%) inhibitory synaptic sites (postsynaptic gephyrin 
clusters) than MNTB neurons in normal mice. Our results demonstrate substantial 
differences in glycinergic transmission in normal and congenitally deaf mice, 
supporting a role for activity during development in regulating both synaptic 
structure (connectivity) and the fundamental (quantal) properties of mIPSCs at 
central glycinergic synapses.

DOI: 10.1152/jn.00771.2003
PMID: 14561690 [Indexed for MEDLINE]


642. Front Neurosci. 2023 Aug 29;17:1057551. doi: 10.3389/fnins.2023.1057551. 
eCollection 2023.

Subtle alterations of vestibulomotor functioning in conductive hearing loss.

Manno FAM(1)(2)(3)(4), Cheung P(4), Basnet V(4), Khan MS(4), Mao Y(5), Pan L(5), 
Ma V(6), Cho WC(6), Tian S(7), An Z(7), Feng Y(7)(8)(9), Cai YL(4), Pienkowski 
M(10), Lau C(3)(4).

Author information:
(1)Department of Physics, East Carolina University, Greenville, NC, United 
States.
(2)Department of Biomedical Engineering, Center for Imaging Science, Whiting 
School of Engineering, Johns Hopkins University, Baltimore, MD, United States.
(3)Center for Advanced Nuclear Safety and Sustainable Development, City 
University of Hong Kong, Kowloon, Hong Kong SAR, China.
(4)Department of Physics, City University of Hong Kong, Kowloon, Hong Kong SAR, 
China.
(5)Department of Nautical Injury Prevention, Faculty of Navy Medicine, Second 
Military Medical University, Shanghai, China.
(6)Department of Clinical Oncology, Queen Elizabeth Hospital, Kowloon, Hong Kong 
SAR, China.
(7)School of Biomedical Engineering, Southern Medical University, Guangzhou, 
China.
(8)Guangdong Provincial Key Laboratory of Medical Image Processing and Guangdong 
Province Engineering Laboratory for Medical Imaging and Diagnostic Technology, 
Southern Medical University, Guangzhou, China.
(9)Key Laboratory of Mental Health of the Ministry of Education, Guangdong-Hong 
Kong-Macao Greater Bay Area Center for Brain Science and Brain-Inspired 
Intelligence, Guangdong Province Key Laboratory of Psychiatric Disorders, 
Department of Neurobiology, School of Basic Medical Sciences, Southern Medical 
University, Guangzhou, China.
(10)Osborne College of Audiology, Salus University, Elkins Park, PA, United 
States.

INTRODUCTION: Conductive hearing loss (CHL) attenuates the ability to transmit 
air conducted sounds to the ear. In humans, severe hearing loss is often 
accompanied by alterations to other neural systems, such as the vestibular 
system; however, the inter-relations are not well understood. The overall goal 
of this study was to assess vestibular-related functioning proxies in a rat CHL 
model.
METHODS: Male Sprague-Dawley rats (N=134, 250g, 2months old) were used in a CHL 
model which produced a >20dB threshold shift induced by tympanic membrane 
puncture. Auditory brainstem response (ABRs) recordings were used to determine 
threshold depth at different times before and after CHL. ABR threshold depths 
were assessed both manually and by an automated ABR machine learning algorithm. 
Vestibular-related functioning proxy assessment was performed using the rotarod, 
balance beam, elevator vertical motion (EVM) and Ferris-wheel rotation (FWR) 
assays.
RESULTS: The Pre-CHL (control) threshold depth was 27.92dB±11.58dB compared to 
the Post-CHL threshold depth of 50.69dB±13.98dB (mean±SD) across the frequencies 
tested. The automated ABR machine learning algorithm determined the following 
threshold depths: Pre-CHL=24.3dB, Post-CHL same day=56dB, Post-CHL 7 
days=41.16dB, and Post-CHL 1 month=32.5dB across the frequencies assessed (1, 2, 
4, 8, 16, and 32kHz). Rotarod assessment of motor function was not significantly 
different between pre and post-CHL (~1week) rats for time duration (sec) or 
speed (RPM), albeit the former had a small effect size difference. Balance beam 
time to transverse was significantly longer for post-CHL rats, likely indicating 
a change in motor coordination. Further, failure to cross was only noted for CHL 
rats. The defection count was significantly reduced for CHL rats compared to 
control rats following FWR, but not EVM. The total distance traveled during 
open-field examination after EVM was significantly different between control and 
CHL rats, but not for FWR. The EVM is associated with linear acceleration 
(acting in the vertical plane: up-down) stimulating the saccule, while the FWR 
is associated with angular acceleration (centrifugal rotation about a circular 
axis) stimulating both otolith organs and semicircular canals; therefore, the 
difference in results could reflect the specific vestibular-organ functional 
role.
DISCUSSION: Less movement (EVM) and increase time to transverse (balance beam) 
may be associated with anxiety and alterations to defecation patterns (FWR) may 
result from autonomic disturbances due to the impact of hearing loss. In this 
regard, vestibulomotor deficits resulting in changes in balance and motion could 
be attributed to comodulation of auditory and vestibular functioning. Future 
studies should manipulate vestibular functioning directly in rats with CHL.

Copyright © 2023 Manno, Cheung, Basnet, Khan, Mao, Pan, Ma, Cho, Tian, An, Feng, 
Cai, Pienkowski and Lau.

DOI: 10.3389/fnins.2023.1057551
PMCID: PMC10495589
PMID: 37706156

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


643. Curr Res Neurobiol. 2024 Jan 29;6:100124. doi: 10.1016/j.crneur.2024.100124. 
eCollection 2024.

Hearing loss in juvenile rats leads to excessive play fighting and 
hyperactivity, mild cognitive deficits and altered neuronal activity in the 
prefrontal cortex.

Jelinek J(1), Johne M(1)(2), Alam M(1), Krauss JK(1), Kral A(2)(3)(4), Schwabe 
K(1)(2).

Author information:
(1)Department of Neurosurgery, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany.
(2)Cluster of Excellence Hearing4all, German Research Foundation, Hannover, 
Germany.
(3)Institute of AudioNeuroTechnology, Hannover Medical School, Stadtfelddamm 34, 
30625, Hanover, Germany.
(4)Department of Experimental Otology of the ENT Clinics, Hannover Medical 
School, Stadtfelddamm 34, 30625, Hannover, Germany.

BACKGROUND: In children, hearing loss has been associated with hyperactivity, 
disturbed social interaction, and risk of cognitive disturbances. Mechanistic 
explanations of these relations sometimes involve language. To investigate the 
effect of hearing loss on behavioral deficits in the absence of language, we 
tested the impact of hearing loss in juvenile rats on motor, social, and 
cognitive behavior and on physiology of prefrontal cortex.
METHODS: Hearing loss was induced in juvenile (postnatal day 14) male 
Sprague-Dawley rats by intracochlear injection of neomycin under general 
anesthesia. Sham-operated and non-operated hearing rats served as controls. One 
week after surgery auditory brainstem response (ABR) measurements verified 
hearing loss or intact hearing in sham-operated and non-operated controls. All 
rats were then tested for locomotor activity (open field), coordination 
(Rotarod), and for social interaction during development in weeks 1, 2, 4, 8, 
16, and 24 after surgery. From week 8 on, rats were trained and tested for 
spatial learning and memory (4-arm baited 8-arm radial maze test). In a final 
setting, neuronal activity was recorded in the medial prefrontal cortex (mPFC).
RESULTS: In the open field deafened rats moved faster and covered more distance 
than sham-operated and non-operated controls from week 8 on (both p < 0.05). 
Deafened rats showed significantly more play fighting during development 
(p < 0.05), whereas other aspects of social interaction, such as following, were 
not affected. Learning of the radial maze test was not impaired in deafened rats 
(p > 0.05), but rats used less next-arm entries than other groups indicating 
impaired concept learning (p < 0.05). In the mPFC neuronal firing rate was 
reduced and enhanced irregular firing was observed. Moreover, oscillatory 
activity was altered, both within the mPFC and in coherence of mPFC with the 
somatosensory cortex (p < 0.05).
CONCLUSIONS: Hearing loss in juvenile rats leads to hyperactive behavior and 
pronounced play-fighting during development, suggesting a causal relationship 
between hearing loss and cognitive development. Altered neuronal activities in 
the mPFC after hearing loss support such effects on neuronal networks outside 
the central auditory system. This animal model provides evidence of 
developmental consequences of juvenile hearing loss on prefrontal cortex in 
absence of language as potential confounding factor.

© 2024 The Authors.

DOI: 10.1016/j.crneur.2024.100124
PMCID: PMC11015060
PMID: 38616957

Conflict of interest statement: The authors declare that they have no known 
competing financial interests or personal relationships that could have appeared 
to influence the work reported in this paper.


644. Front Aging Neurosci. 2022 May 20;14:907070. doi: 10.3389/fnagi.2022.907070. 
eCollection 2022.

Disrupted Topological Organization of Resting-State Functional Brain Networks in 
Age-Related Hearing Loss.

Yong W(1), Song J(1)(2), Xing C(1), Xu JJ(3), Xue Y(4), Yin X(1), Wu Y(3), Chen 
YC(1).

Author information:
(1)Department of Radiology, Nanjing First Hospital, Nanjing Medical University, 
Nanjing, China.
(2)Department of Radiology, Nanjing Pukou Central Hospital, Pukou Branch 
Hospital of Jiangsu Province Hospital, Nanjing, China.
(3)Department of Otolaryngology, Nanjing First Hospital, Nanjing Medical 
University, Nanjing, China.
(4)Department of Otolaryngology, Nanjing Pukou Central Hospital, Pukou Branch 
Hospital of Jiangsu Province Hospital, Nanjing, China.

PURPOSE: Age-related hearing loss (ARHL), associated with the function of speech 
perception decreases characterized by bilateral sensorineural hearing loss at 
high frequencies, has become an increasingly critical public health problem. 
This study aimed to investigate the topological features of the brain functional 
network and structural dysfunction of the central nervous system in ARHL using 
graph theory.
METHODS: Forty-six patients with ARHL and forty-five age, sex, and 
education-matched healthy controls were recruited to undergo a resting-state 
functional magnetic resonance imaging (fMRI) scan in this study. Graph theory 
was applied to analyze the topological properties of the functional connectomes 
by studying the local and global organization of neural networks.
RESULTS: Compared with healthy controls, the patient group showed increased 
local efficiency (Eloc) and clustering coefficient (Cp) of the small-world 
network. Besides, the degree centrality (Dc) and nodal efficiency (Ne) values of 
the left inferior occipital gyrus (IOG) in the patient group showed a decrease 
in contrast with the healthy control group. In addition, the intra-modular 
interaction of the occipital lobe module and the inter-modular interaction of 
the parietal occipital module decreased in the patient group, which was 
positively correlated with Dc and Ne. The intra-modular interaction of the 
occipital lobe module decreased in the patient group, which was negatively 
correlated with the Eloc.
CONCLUSION: Based on fMRI and graph theory, we indicate the aberrant small-world 
network topology in ARHL and dysfunctional interaction of the occipital lobe and 
parietal lobe, emphasizing the importance of dysfunctional left IOG. These 
results suggest that early diagnosis and treatment of patients with ARHL is 
necessary, which can avoid the transformation of brain topology and decreased 
brain function.

Copyright © 2022 Yong, Song, Xing, Xu, Xue, Yin, Wu and Chen.

DOI: 10.3389/fnagi.2022.907070
PMCID: PMC9163682
PMID: 35669463

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest. The reviewer JC declared a 
shared parent affiliation with the authors WY, JS, CX, J-JX, XY, YW, and Y-CC to 
the handling editor at the time of review.


645. Cochrane Database Syst Rev. 2012 Oct 17;10:CD006396. doi: 
10.1002/14651858.CD006396.pub3.

Interventions to prevent occupational noise-induced hearing loss.

Verbeek JH(1), Kateman E, Morata TC, Dreschler WA, Mischke C.

Author information:
(1)Cochrane Occupational Safety and Health Review Group, Finnish Institute of 
Occupational Health, Kuopio, Finland.jos.verbeek@ttl.fi.

Update in
    Cochrane Database Syst Rev. 2017 Jul 07;7:CD006396.

Update of
    Cochrane Database Syst Rev. 2009;(3):CD006396.

BACKGROUND: Millions of workers worldwide are exposed to noise levels that 
increase their risk of hearing impairment. Little is known about the 
effectiveness of hearing loss prevention interventions.
OBJECTIVES: To assess the effectiveness of non-pharmaceutical interventions for 
preventing occupational noise exposure or occupational hearing loss compared to 
no intervention or alternative interventions.
SEARCH METHODS: We searched the Cochrane Central Register of Controlled Trials 
(CENTRAL); PubMed; EMBASE; CINAHL; Web of Science; BIOSIS Previews; Cambridge 
Scientific Abstracts; and OSH update to 25 January 2012.
SELECTION CRITERIA: We included randomised controlled trials (RCT), controlled 
before-after studies (CBA) and interrupted time-series (ITS) of non-clinical 
hearing loss prevention interventions under field conditions among workers 
exposed to noise.
DATA COLLECTION AND ANALYSIS: Two authors independently assessed study 
eligibility and risk of bias and extracted data.
MAIN RESULTS: We included 25 studies. We found no controlled studies on 
engineering controls for noise exposure but one study evaluated legislation to 
reduce noise exposure in a 12-year time-series analysis. Eight studies with 
3,430 participants evaluated immediate and long-term effects of personal hearing 
protection devices (HPDs) and sixteen studies with 82,794 participants evaluated 
short and long-term effects of hearing loss prevention programmes (HLPPs). The 
overall quality of studies was low to very low.The one ITS study that evaluated 
the effect of new legislation in reducing noise exposure found that the median 
noise level decreased by 27.7 dB(A) (95% confidence interval (CI) -36.1 to -19.3 
dB) immediately after the implementation of stricter legislation and that this 
was associated with a favourable downward trend in time of -2.1 dB per year (95% 
CI -4.9 to 0.7).Hearing protection devices attenuated noise with about 20 dB(A) 
with variation among brands and types but for ear plugs these findings depended 
almost completely on proper instruction of insertion. Noise attenuation ratings 
of hearing protection under field conditions were consistently lower than the 
ratings provided by the manufacturers.One cluster-RCT compared a three-year 
information campaign as part of a hearing loss prevention programme for 
agricultural students to audiometry only with three and 16-year follow-up but 
there were no significant differences in hearing loss. Another study compared a 
HLPP, which provided regular personal noise exposure information, to a programme 
without this information in a CBA design. Exposure information was associated 
with a favourable but non-significant reduction of the rate of hearing loss of 
-0.82 dB per year (95% CI -1.86 to 0.22). Another cluster-RCT evaluated the 
effect of extensive on-site training sessions and the use of personal 
noise-level indicators versus information only on noise levels but did not find 
a significant difference after four months follow-up (Mean Difference (MD) -0.30 
dB(A) (95%CI -3.95 to 3.35).There was very low quality evidence in four very 
long-term studies, that better use of HPDs as part of a HLPP decreased the risk 
of hearing loss compared to less well used hearing protection in HLPPs. Other 
aspects of the HLPP such as training and education of workers or engineering 
controls did not show a similar effect.In four long-term studies, workers in a 
HLPP still had a 0.5 dB greater hearing loss at 4 kHz than workers that were not 
exposed to noise (95% CI -0.5 to 1.7) which is about the level of hearing loss 
caused by exposure to 85 dB(A). In addition, two other studies showed 
substantial risk of hearing loss in spite of the protection of a HLPP compared 
to non-exposed workers.
AUTHORS' CONCLUSIONS: There is low quality evidence that implementation of 
stricter legislation can reduce noise levels in workplaces. Even though case 
studies show that substantial reductions in noise levels in the workplace can be 
achieved, there are no controlled studies of the effectiveness of such measures. 
The effectiveness of hearing protection devices depends on training and their 
proper use. There is very low quality evidence that the better use of hearing 
protection devices as part of HLPPs reduces the risk of hearing loss, whereas 
for other programme components of HLPPs we did not find such an effect. Better 
implementation and reinforcement of HLPPs is needed. Better evaluations of 
technical interventions and long-term effects are needed.

DOI: 10.1002/14651858.CD006396.pub3
PMID: 23076923 [Indexed for MEDLINE]


646. Pediatrics. 2000 Sep;106(3):E42.

The effect of ventilation tubes on language development in infants with otitis 
media with effusion: A randomized trial.

Rovers MM(1), Straatman H, Ingels K, van der Wilt GJ, van den Broek P, Zielhuis 
GA.

Author information:
(1)Department of Otorhinolaryngology, University Medical Center Saint Radboud, 
Nijmegen, The Netherlands. m.rovers@mie.kun.nl

OBJECTIVE: To study the effectiveness of ventilation tubes on the language 
development in infants with persistent otitis media with effusion (OME). All 
existing studies addressed children 3 years of age or older. Currently, OME is 
detected and treated with ventilation tubes at a younger age. Because of the 
critical relationship between age, hearing, and language development, we 
conducted a study of the effects of ventilation tubes on language development in 
infants 1 to 2 years old with persistent OME.
DESIGN: A multicenter, randomized, controlled trial (embedded in a cohort) with 
2 treatment arms: 1) treatment with ventilation tubes (VT group; n = 93); or 2) 
with a period of watchful waiting (WW group; n = 94). Hearing loss and 
expressive and comprehensive language were assessed every 6 months, while 
tympanometry and otoscopy were performed every 3 months. Other factors with 
potential influence on language development were also included: adenoidectomy, 
hospital, attending day care, sex, age at randomization, educational level of 
the mother, upper respiratory infections, and the native country of the parents 
and older siblings. The trial was designed to allow for the detection of a mean 
difference in language development of 3 months or more between children 
allocated to the VT and WW groups.
RESULTS: No relevant differences were found in expressive or comprehensive 
language between the 2 groups after adjustment for educational level of the 
mother, IQ of the child, and differences at baseline. A principal component 
analysis showed that in the VT group, the children with frequent complaints 
improved 1.6 months more in comprehensive language than those with no or some 
complaints. The children with favorable language stimulation, however, did not 
improve more than the children with less favorable stimulation. No differences 
were found for expressive language among the various clusters. The probability 
to improve >3 months in comprehensive language was.48 (95% confidence interval 
[CI]:.29-.68) for children with highly educated mothers versus.09 (95% 
CI:.02-.30) for children whose mothers had a low educational level. In the WW 
group, these changes were.30 (95% CI:.14-.53) and.14 (95% CI:.04-.35), 
respectively. The probability to improve >4 months in expressive language was.52 
(95% CI:.32-.71) for children with highly educated mothers versus.06 (95% 
CI:.01-.31) for children whose mothers had a low educational level. In the WW 
group these changes were.42 (95% CI:.23-.64) and.11 (95% CI:.03-.35), 
respectively. In addition, there were delays in expressive language in both 
groups compared with their age expected values. The comprehensive language of 
the children who were effusion-free during the follow-up (n = 54) improved 1.5 
months (95% CI: -.2-3.2) more than that of the children who had persistent 
effusion during the entire follow-up (n = 28). No differences were found for 
expressive language development. Disregarding the intervention contrast, 
improvements in hearing seemed to be related to improvements in language 
development, especially in verbal comprehension.
DISCUSSION: In this study, we used the Reynell, Schlichting, and Lexi tests to 
study the relation between early persistent OME and language development. These 
tests are directly related to normal language, widely accepted, and validated. 
It cannot be ruled out that more specific measures such as auditory perception 
tests would have produced more differences between groups, but the focus was on 
general language development. A total of 10 children in the WW group received 
treatment with ventilation tubes during follow-up. A further 11 children dropped 
out during the trial. A sensitivity analysis with the 10 children who received 
ventilation tubes did not change the results, and baseline differences were not 
found between the 11 children who dropped out and those who completed the trial.
CONCLUSIONS: In the total group of infants with persistent OME, ventilation 
tubes did not h

PMID: 10969126 [Indexed for MEDLINE]


647. J Assoc Res Otolaryngol. 2002 Mar;3(1):45-53. doi: 10.1007/s101620020005.

Gene discovery in the auditory system: characterization of additional 
cochlear-expressed sequences.

Resendes BL(1), Robertson NG, Szustakowski JD, Resendes RJ, Weng Z, Morton CC.

Author information:
(1)Department of Obstetrics, Gynecology and Reproductive Biology, Brigham and 
Women's Hospital, Boston, MA 02115, USA.

To identify genes involved in hearing, 8494 expressed sequence tags (ESTs) were 
generated from a human fetal cochlear cDNA library in two distinct sequencing 
projects. Analysis of the first set of 4304 ESTs revealed clones representing 
517 known human genes, 41 mammalian genes not previously detected in human 
tissues, 487 ESTs from other human tissues, and 541 cochlear-specific ESTs 
(http://hearing.bwh.harvard.edu). We now report results of a DNA sequence 
similarity (BLAST) analysis of an additional 4190 cochlear ESTs and a comparison 
to the first set. Among the 4190 new cochlear ESTs, 959 known human genes were 
identified; 594 were found only among the new ESTs and 365 were found among ESTs 
from both sequencing projects. COL1A2 was the most abundant transcript among 
both sets of ESTs, followed in order by COL3A1, SPARC, EEFY1A1, and TPTI. An 
additional 22 human homologs of known nonhuman mammalian genes and 1595 clusters 
of ESTs, of which 333 are cochlear-specific, were identified among the new 
cochlear ESTs. Map positions were determined for 373 of the new cochlear ESTs 
and revealed 318 additional loci. Forty-nine of the mapped ESTs are located 
within the genetic interval of 23 deafness loci. Reanalysis of unassigned ESTs 
from the prior study revealed 338 additional known human genes. The total number 
of known human genes identified from 8494 cochlear ESTs is 1449 and is 
represented by 4040 ESTs. Among the known human genes are 14 deafness-associated 
genes, including GJB2 (connexin 26) and KVLQT1. The total number of nonhuman 
mammalian genes identified is 43 and is represented by 58 ESTs. The total number 
of ESTs without sequence similarity to known genes is 4055. Of these, 778 also 
do not have sequence similarity to any other ESTs, are categorized into 700 
clusters, and may represent genes uniquely or preferentially expressed in the 
cochlea. Identification of additional known genes, ESTs, and cochlear-specific 
ESTs provides new candidate genes for both syndromic and nonsyndromic deafness 
disorders.

DOI: 10.1007/s101620020005
PMCID: PMC3202364
PMID: 12083723 [Indexed for MEDLINE]


648. Hear Res. 2014 Sep;315:88-98. doi: 10.1016/j.heares.2014.06.007. Epub 2014 Jul 
10.

Morphological brain network assessed using graph theory and network filtration 
in deaf adults.

Kim E(1), Kang H(2), Lee H(3), Lee HJ(4), Suh MW(5), Song JJ(6), Oh SH(7), Lee 
DS(8).

Author information:
(1)Department of Nuclear Medicine, Seoul National University College of 
Medicine, Seoul, Republic of Korea; Institute of Radiation Medicine, Medical 
Research Center, Seoul National University, Seoul, Republic of Korea; 
Interdisciplinary Program in Cognitive Science, Seoul National University, 
Seoul, Republic of Korea.
(2)Department of Nuclear Medicine, Seoul National University College of 
Medicine, Seoul, Republic of Korea; Data Science for Knowledge Creation Research 
Center, Seoul National University, Seoul, Republic of Korea.
(3)Department of Nuclear Medicine, Seoul National University College of 
Medicine, Seoul, Republic of Korea; Institute of Radiation Medicine, Medical 
Research Center, Seoul National University, Seoul, Republic of Korea.
(4)Department of Otorhinolaryngology-Head and Neck Surgery, Hallym University 
College of Medicine, Chuncheon, Republic of Korea.
(5)Sensory Organ Research Institute, Seoul National University Medical Research 
Center, Seoul, Republic of Korea.
(6)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University Bundang Hospital, Seongnam, Republic of Korea.
(7)Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National 
University College of Medicine, Seoul, Republic of Korea; Sensory Organ Research 
Institute, Seoul National University Medical Research Center, Seoul, Republic of 
Korea. Electronic address: shaoh@snu.ac.kr.
(8)Department of Nuclear Medicine, Seoul National University College of 
Medicine, Seoul, Republic of Korea; Institute of Radiation Medicine, Medical 
Research Center, Seoul National University, Seoul, Republic of Korea; 
Interdisciplinary Program in Cognitive Science, Seoul National University, 
Seoul, Republic of Korea; Department of Molecular Medicine and Biopharmaceutical 
Sciences, Graduate School of Convergence Science and Technology, and College of 
Medicine or College of Pharmacy, Seoul National University, Seoul, Republic of 
Korea. Electronic address: dsl@plaza.snu.ac.kr.

Prolonged deprivation of auditory input can change brain networks in pre- and 
postlingual deaf adults by brain-wide reorganization. To investigate 
morphological changes in these brains voxel-based morphometry, voxel-wise 
correlation with the primary auditory cortex, and whole brain network analyses 
using morphological covariance were performed in eight prelingual deaf, eleven 
postlingual deaf, and eleven hearing adults. Network characteristics based on 
graph theory and network filtration based on persistent homology were examined. 
Gray matter density in the primary auditor cortex was preserved in prelingual 
deafness, while it tended to decrease in postlingual deafness. Unlike 
postlingual, prelingual deafness showed increased bilateral temporal 
connectivity of the primary auditory cortex compared to the hearing adults. Of 
the graph theory-based characteristics, clustering coefficient, betweenness 
centrality, and nodal efficiency all increased in prelingual deafness, while all 
the parameters of postlingual deafness were similar to the hearing adults. 
Patterns of connected components changing during network filtration were 
different between prelingual deafness and hearing adults according to the 
barcode, dendrogram, and single linkage matrix representations, while these were 
the same in postlingual deafness. Nodes in fronto-limbic and left temporal 
components were closely coupled, and nodes in the temporo-parietal component 
were loosely coupled, in prelingual deafness. Patterns of connected components 
changing in postlingual deafness were the same as hearing adults. We propose 
that the preserved density of auditory cortex associated with increased 
connectivity in prelingual deafness, and closer coupling between certain brain 
areas, represent distinctive reorganization of auditory and related cortices 
compared with hearing or postlingual deaf adults. The differential network 
reorganization in the prelingual deaf adults could be related to the absence of 
auditory speech experience.

Copyright © 2014 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2014.06.007
PMID: 25016143 [Indexed for MEDLINE]


649. Eur J Neurosci. 2007 Aug;26(3):666-80. doi: 10.1111/j.1460-9568.2007.05695.x. 
Epub 2007 Jul 25.

Plasticity of synaptic endings in the cochlear nucleus following noise-induced 
hearing loss is facilitated in the adult FGF2 overexpressor mouse.

D'Sa C(1), Gross J, Francone VP, Morest DK.

Author information:
(1)Department of Neuroscience, University of Connecticut Health Center, 
Farmington, CT 06030, USA.

In adult mammals a single exposure to loud noise can damage cochlear hair cells 
and initiate subsequent episodes of degeneration of axonal endings in the 
cochlear nucleus (CN). Possible mechanisms are loss of trophic support and/or 
excitotoxicity. Fibroblast growth factor 2 (FGF2), important for development, 
might be involved in either mechanism. To test this hypothesis, we noise-exposed 
FGF2 overexpressor mice and observed the effects on synaptic endings by 
immunolabelling for SV2, a synaptic vesicle protein, at 1, 2, 4, and 8 weeks 
after noise exposure. SV2 staining was observed in two major locations; 
perisomatic, representing axo-somatic terminals, and neuropil, representing 
axo-dendritic terminals. The wildtype (WT) lost both perisomatic and neuropil 
clusters with an intervening period of modest recovery for the perisomatic. In 
contrast, in the overexpressor, the perisomatic clusters remained unchanged 
after intervening periods of increase. The neuropil clusters underwent a period 
of initial decline, followed by a transient recovery and ultimate decline. 
Changes in SV2 immunostaining correlated with changes in vesicular glutamate and 
GABA transporters at synapses and, in the overexpressor, with staining changes 
for FGF2 and FGF receptor 1. These molecules may contribute to the synaptic 
reorganization after noise damage; they may protect and/or aid recovery of 
synapses after overstimulation.

DOI: 10.1111/j.1460-9568.2007.05695.x
PMID: 17651425 [Indexed for MEDLINE]


650. Neuroimage. 2015 Nov 1;121:159-70. doi: 10.1016/j.neuroimage.2015.07.062. Epub 
2015 Jul 26.

Cross-modal reorganization in cochlear implant users: Auditory cortex 
contributes to visual face processing.

Stropahl M(1), Plotz K(2), Schönfeld R(2), Lenarz T(3), Sandmann P(4), Yovel 
G(5), De Vos M(6), Debener S(7).

Author information:
(1)Neuropsychology Lab, Department of Psychology, Carl von Ossietzky University 
Oldenburg, Germany. Electronic address: maren.stropahl@uni-oldenburg.de.
(2)Department of Phoniatrics, Pediatric Audiology and Neurootology, 
Evangelisches Krankenhaus Oldenburg, Germany.
(3)Department of Otolaryngology, Hannover Medical School, Germany; Cluster of 
Excellence Hearing4all Oldenburg, Germany.
(4)Cluster of Excellence Hearing4all Oldenburg, Germany; Department of 
Neurology, Hannover Medical School, Germany.
(5)Department of Psychology, Tel Aviv University, Tel Aviv, Israel.
(6)Cluster of Excellence Hearing4all Oldenburg, Germany; Department of 
Engineering Science, University of Oxford, UK; Methods in Cognitive Psychology, 
Department of Psychology, Carl von Ossietzky University Oldenburg, Germany.
(7)Neuropsychology Lab, Department of Psychology, Carl von Ossietzky University 
Oldenburg, Germany; Cluster of Excellence Hearing4all Oldenburg, Germany.

There is converging evidence that the auditory cortex takes over visual 
functions during a period of auditory deprivation. A residual pattern of 
cross-modal take-over may prevent the auditory cortex to adapt to restored 
sensory input as delivered by a cochlear implant (CI) and limit speech 
intelligibility with a CI. The aim of the present study was to investigate 
whether visual face processing in CI users activates auditory cortex and whether 
this has adaptive or maladaptive consequences. High-density electroencephalogram 
data were recorded from CI users (n=21) and age-matched normal hearing controls 
(n=21) performing a face versus house discrimination task. Lip reading and face 
recognition abilities were measured as well as speech intelligibility. 
Evaluation of event-related potential (ERP) topographies revealed significant 
group differences over occipito-temporal scalp regions. Distributed source 
analysis identified significantly higher activation in the right auditory cortex 
for CI users compared to NH controls, confirming visual take-over. Lip reading 
skills were significantly enhanced in the CI group and appeared to be 
particularly better after a longer duration of deafness, while face recognition 
was not significantly different between groups. However, auditory cortex 
activation in CI users was positively related to face recognition abilities. Our 
results confirm a cross-modal reorganization for ecologically valid visual 
stimuli in CI users. Furthermore, they suggest that residual takeover, which can 
persist even after adaptation to a CI is not necessarily maladaptive.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2015.07.062
PMID: 26220741 [Indexed for MEDLINE]


651. J Biomed Biotechnol. 2008;2008:768232. doi: 10.1155/2008/768232.

A robotic voice simulator and the interactive training for hearing-impaired 
people.

Sawada H(1), Kitani M, Hayashi Y.

Author information:
(1)Department of Intelligent Mechanical Systems Engineering, Faculty of 
Engineering, Kagawa University, Japan. sawada@eng.kagawa-u.ac.jp

A talking and singing robot which adaptively learns the vocalization skill by 
means of an auditory feedback learning algorithm is being developed. The robot 
consists of motor-controlled vocal organs such as vocal cords, a vocal tract and 
a nasal cavity to generate a natural voice imitating a human vocalization. In 
this study, the robot is applied to the training system of speech articulation 
for the hearing-impaired, because the robot is able to reproduce their 
vocalization and to teach them how it is to be improved to generate clear 
speech. The paper briefly introduces the mechanical construction of the robot 
and how it autonomously acquires the vocalization skill in the auditory feedback 
learning by listening to human speech. Then the training system is described, 
together with the evaluation of the speech training by auditory impaired people.

DOI: 10.1155/2008/768232
PMCID: PMC2279150
PMID: 18389073 [Indexed for MEDLINE]


652. Orphanet J Rare Dis. 2015 Feb 10;10:15. doi: 10.1186/s13023-015-0238-5.

OSBPL2 encodes a protein of inner and outer hair cell stereocilia and is mutated 
in autosomal dominant hearing loss (DFNA67).

Thoenes M(1), Zimmermann U(2), Ebermann I(3), Ptok M(4), Lewis MA(5), Thiele 
H(6), Morlot S(7), Hess MM(8), Gal A(9), Eisenberger T(10), Bergmann C(11)(12), 
Nürnberg G(13), Nürnberg P(14)(15), Steel KP(16), Knipper M(17), Bolz 
HJ(18)(19).

Author information:
(1)Institute of Human Genetics, University Hospital of Cologne, Cologne, 
Germany. michaela.thoenes@uk-koeln.de.
(2)Molecular Physiology of Hearing, Hearing Research Centre Tübingen (THRC), 
Department of Otolaryngology, University of Tübingen, Tübingen, Germany. 
ulrike.zimmermann@uni-tuebingen.de.
(3)Institute of Human Genetics, University Hospital of Cologne, Cologne, 
Germany. ingaebermann@yahoo.de.
(4)Department of Phoniatrics and Pediatric Audiology, Hannover Medical School, 
Hannover, Germany. Ptok.Martin@mh-hannover.de.
(5)Wolfson Centre for Age-Related Diseases, King's College London, London, UK. 
morag.lewis@kcl.ac.uk.
(6)Cologne Center for Genomics (CCG) and Center for Molecular Medicine Cologne 
(CMMC), University of Cologne, Cologne, Germany. holger.thiele@uni-koeln.de.
(7)Institute for Human Genetics, Hannover Medical School, Hannover, Germany. 
Morlot.Susanne@mh-hannover.de.
(8)Department of Voice, Speech and Hearing Disorders, University Medical Center 
Hamburg-Eppendorf, Hamburg, Germany. hess@uke.de.
(9)Department of Human Genetics, University Medical Center Hamburg-Eppendorf, 
Hamburg, Germany. gal@uke.de.
(10)Center for Human Genetics, Bioscientia, Ingelheim, Germany. 
tobias.eisenberger@bioscientia.de.
(11)Center for Human Genetics, Bioscientia, Ingelheim, Germany. 
carsten.bergmann@bioscientia.de.
(12)Renal Division, Department of Medicine, University Medical Center Freiburg, 
Freiburg, Germany. carsten.bergmann@bioscientia.de.
(13)Cologne Center for Genomics (CCG) and Center for Molecular Medicine Cologne 
(CMMC), University of Cologne, Cologne, Germany. nuernberg@uni-koeln.de.
(14)Cologne Center for Genomics (CCG) and Center for Molecular Medicine Cologne 
(CMMC), University of Cologne, Cologne, Germany. gudrun.nuernberg@uni-koeln.de.
(15)Cologne Excellence Cluster on Cellular Stress Responses in Aging-Associated 
Diseases (CECAD), University of Cologne, Cologne, Germany. 
gudrun.nuernberg@uni-koeln.de.
(16)Wolfson Centre for Age-Related Diseases, King's College London, London, UK. 
karen.steel@kcl.ac.uk.
(17)Molecular Physiology of Hearing, Hearing Research Centre Tübingen (THRC), 
Department of Otolaryngology, University of Tübingen, Tübingen, Germany. 
marlies.knipper@uni-tuebingen.de.
(18)Institute of Human Genetics, University Hospital of Cologne, Cologne, 
Germany. hanno.bolz@bioscientia.de.
(19)Center for Human Genetics, Bioscientia, Ingelheim, Germany. 
hanno.bolz@bioscientia.de.

BACKGROUND: Early-onset hearing loss is mostly of genetic origin. The complexity 
of the hearing process is reflected by its extensive genetic heterogeneity, with 
probably many causative genes remaining to be identified. Here, we aimed at 
identifying the genetic basis for autosomal dominant non-syndromic hearing loss 
(ADNSHL) in a large German family.
METHODS: A panel of 66 known deafness genes was analyzed for mutations by 
next-generation sequencing (NGS) in the index patient. We then conducted 
genome-wide linkage analysis, and whole-exome sequencing was carried out with 
samples of two patients. Expression of Osbpl2 in the mouse cochlea was 
determined by immunohistochemistry. Because Osbpl2 has been proposed as a target 
of miR-96, we investigated homozygous Mir96 mutant mice for its upregulation.
RESULTS: Onset of hearing loss in the investigated ADNSHL family is in 
childhood, initially affecting the high frequencies and progressing to profound 
deafness in adulthood. However, there is considerable intrafamilial variability. 
We mapped a novel ADNSHL locus, DFNA67, to chromosome 20q13.2-q13.33, and 
subsequently identified a co-segregating heterozygous frameshift mutation, 
c.141_142delTG (p.Arg50Alafs*103), in OSBPL2, encoding a protein known to 
interact with the DFNA1 protein, DIAPH1. In mice, Osbpl2 was prominently 
expressed in stereocilia of cochlear outer and inner hair cells. We found no 
significant Osbpl2 upregulation at the mRNA level in homozygous Mir96 mutant 
mice.
CONCLUSION: The function of OSBPL2 in the hearing process remains to be 
determined. Our study and the recent description of another frameshift mutation 
in a Chinese ADNSHL family identify OSBPL2 as a novel gene for progressive 
deafness.

DOI: 10.1186/s13023-015-0238-5
PMCID: PMC4334766
PMID: 25759012 [Indexed for MEDLINE]


653. PLoS One. 2020 Jul 6;15(7):e0235435. doi: 10.1371/journal.pone.0235435. 
eCollection 2020.

The perception of the stereo effect in bilateral and bimodal cochlear implant 
users and its contribution to music enjoyment.

Buechner A(1)(2), Krueger B(1), Klawitter S(1), Zimmermann D(1), Fredelake S(3), 
Holube I(2)(4).

Author information:
(1)Medical University of Hanover, Hanover, Germany.
(2)Cluster of Excellence Hearing4all, Germany.
(3)Advanced Bionics GmbH, European Research Center, Hanover, Germany.
(4)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.

OBJECTIVES: In this clinical study, stereo perception of music samples and its 
contribution to music enjoyment in CI users is investigated. It is studied in 
free field as well as direct audio presentation.
METHODS: 20 bilateral and 9 bimodal CI users performed stereo detection tests 
and music enjoyment ratings. Music was presented either in mono or in stereo in 
free field or with direct audio presentation. Stereo detection was assessed with 
a 3-AFC paradigm. Music enjoyment was studied with scale ratings.
RESULTS: For bilateral CI users, stereo detection increased from 52% correct in 
free field to 86% with direct audio presentation. Increased music enjoyment with 
improved stereo detection was obtained. Bimodal CI users could not identify 
stereo sounds. Music enjoyment did not increase for stereo presentations in 
bimodal subjects.
DISCUSSION: For bilateral CI users, improved stereo detection might increase 
music enjoyment with direct audio presentation, which is likely due to bypassing 
the room acoustics. In bimodal CI users, no clear improvement was found, which 
is likely attributed due to the different hearing losses and therefore 
individually different interaural frequency overlaps between the hearing aid and 
the cochlear implant.
CONCLUSION: Direct audio presentation is an efficient method to improve music 
enjoyment in bilateral CI users.

DOI: 10.1371/journal.pone.0235435
PMCID: PMC7337296
PMID: 32628690 [Indexed for MEDLINE]

Conflict of interest statement: The authors have read the journal’s policy and 
have the following competing interests: DZ, BK, and SK received funding from 
Advanced Bionics (www.advancedbionics.com) while employed by Medizinische 
Hochschule Hannover (MHH). SF is employed by Advanced Bionics. This does not 
alter the authors' adherence to all the PLOS ONE policies on sharing data and 
materials. There are no patents, products in development or marketed products to 
declare.


654. Neuroimage. 2019 Oct 15;200:231-241. doi: 10.1016/j.neuroimage.2019.06.025. Epub 
2019 Jun 17.

Neural correlates of semantic and syntactic processing in German Sign Language.

Stroh AL(1), Rösler F(2), Dormal G(2), Salden U(2), Skotara N(2), 
Hänel-Faulhaber B(3), Röder B(2).

Author information:
(1)Biological Psychology and Neuropsychology, University of Hamburg, Germany. 
Electronic address: anna-lena.stroh@uni-hamburg.de.
(2)Biological Psychology and Neuropsychology, University of Hamburg, Germany.
(3)Biological Psychology and Neuropsychology, University of Hamburg, Germany; 
Special Education, University of Hamburg, Germany.

The study of deaf and hearing native users of signed languages can offer unique 
insights into how biological constraints and environmental input interact to 
shape the neural bases of language processing. Here, we use functional magnetic 
resonance imaging (fMRI) to address two questions: (1) Do semantic and syntactic 
processing in a signed language rely on anatomically and functionally distinct 
neural substrates as it has been shown for spoken languages? and (2) Does 
hearing status affect the neural correlates of these two types of linguistic 
processing? Deaf and hearing native signers performed a sentence judgement task 
on German Sign Language (Deutsche Gebärdensprache: DGS) sentences which were 
correct or contained either syntactic or semantic violations. We hypothesized 
that processing of semantic and syntactic violations in DGS relies on distinct 
neural substrates as it has been shown for spoken languages. Moreover, we 
hypothesized that effects of hearing status are observed within auditory 
regions, as deaf native signers have been shown to activate auditory areas to a 
greater extent than hearing native signers when processing a signed language. 
Semantic processing activated low-level visual areas and the left inferior 
frontal gyrus (IFG), suggesting both modality-dependent and independent 
processing mechanisms. Syntactic processing elicited increased activation in the 
right supramarginal gyrus (SMG). Moreover, psychophysiological interaction (PPI) 
analyses revealed a cluster in left middle occipital regions showing increased 
functional coupling with the right SMG during syntactic relative to semantic 
processing, possibly indicating spatial processing mechanisms that are specific 
to signed syntax. Effects of hearing status were observed in the right superior 
temporal cortex (STC): deaf but not hearing native signers showed greater 
activation for semantic violations than for syntactic violations in this region. 
Taken together, the present findings suggest that the neural correlates of 
language processing are partly determined by biological constraints, but that 
they may additionally be influenced by the unique processing demands of the 
language modality and different sensory experiences.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.06.025
PMID: 31220577 [Indexed for MEDLINE]


655. PLoS Genet. 2011 Sep;7(9):e1002309. doi: 10.1371/journal.pgen.1002309. Epub 2011 
Sep 29.

Cell type-specific transcriptome analysis reveals a major role for Zeb1 and 
miR-200b in mouse inner ear morphogenesis.

Hertzano R(1), Elkon R, Kurima K, Morrisson A, Chan SL, Sallin M, Biedlingmaier 
A, Darling DS, Griffith AJ, Eisenman DJ, Strome SE.

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, University of 
Maryland, Baltimore, Maryland, United States of America. 
rhertzano@smail.umaryland.edu

Comment in
    A Noncoding Point Mutation of Zeb1 Causes Multiple Developmental 
Malformations and Obesity in Twirler Mice.

Cellular heterogeneity hinders the extraction of functionally significant 
results and inference of regulatory networks from wide-scale expression profiles 
of complex mammalian organs. The mammalian inner ear consists of the auditory 
and vestibular systems that are each composed of hair cells, supporting cells, 
neurons, mesenchymal cells, other epithelial cells, and blood vessels. We 
developed a novel protocol to sort auditory and vestibular tissues of newborn 
mouse inner ears into their major cellular components. Transcriptome profiling 
of the sorted cells identified cell type-specific expression clusters. 
Computational analysis detected transcription factors and microRNAs that play 
key roles in determining cell identity in the inner ear. Specifically, our 
analysis revealed the role of the Zeb1/miR-200b pathway in establishing 
epithelial and mesenchymal identity in the inner ear. Furthermore, we detected a 
misregulation of the ZEB1 pathway in the inner ear of Twirler mice, which 
manifest, among other phenotypes, malformations of the auditory and vestibular 
labyrinth. The association of misregulation of the ZEB1/miR-200b pathway with 
auditory and vestibular defects in the Twirler mutant mice uncovers a novel 
mechanism underlying deafness and balance disorders. Our approach can be 
employed to decipher additional complex regulatory networks underlying other 
hearing and balance mouse mutants.

DOI: 10.1371/journal.pgen.1002309
PMCID: PMC3183091
PMID: 21980309 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


656. Eur Arch Otorhinolaryngol. 2021 Jan;278(1):77-85. doi: 
10.1007/s00405-020-06070-z. Epub 2020 May 26.

Robot-based assistance in middle ear surgery and cochlear implantation: first 
clinical report.

Vittoria S(1)(2)(3), Lahlou G(1)(2), Torres R(4), Daoudi H(1)(2), Mosnier 
I(1)(2), Mazalaigue S(2)(5), Ferrary E(1)(2), Nguyen Y(6)(7), Sterkers O(1)(2).

Author information:
(1)AP-HP, GHU Pitié-Salpêtrière, DMU ChIR, Service ORL, GRC Robotique et 
Innovation Chirurgicale, Sorbonne Université, Paris, France.
(2)Inserm UMR 1120 "Innovative Technologies and Translational Therapeutics for 
Deafness", Hearing Institute Paris, Paris, France.
(3)Otorhinolaryngology Unit, Department of Health Sciences, ASST Santi Paolo E 
Carlo Hospital Università Degli Studi, Milan, Italy.
(4)Departamento de Ciencias Fisiológicas, Facultad de Medicina, Universidad 
Nacional de San Agustín de Arequipa, Av. Alcides Carrión 101, 04000, Arequipa, 
Peru.
(5)Collin Orl, Bagneux, France.
(6)AP-HP, GHU Pitié-Salpêtrière, DMU ChIR, Service ORL, GRC Robotique et 
Innovation Chirurgicale, Sorbonne Université, Paris, France. 
yann.nguyen@inserm.fr.
(7)Inserm UMR 1120 "Innovative Technologies and Translational Therapeutics for 
Deafness", Hearing Institute Paris, Paris, France. yann.nguyen@inserm.fr.

PURPOSE: Middle ear surgery may benefit from robot-based assistance to hold 
micro-instruments or an endoscope. However, the surgical gesture performed by 
one hand may perturb surgeons accustomed to two-handed surgery. A robot-based 
holder may combine the benefits from endoscopic exposure and a two-handed 
technique. Furthermore, tremor suppression and accurate tool control might help 
the surgeon during critical surgical steps. The goal of this work was to study 
the safety of an otological robot-based assistant under clinical conditions in a 
limited series of patients.
METHODS: The RobOtol system has been used as an endoscope or a micro instrument 
holder for this series. Eleven cases were operated on with the robot as an 
endoscope holder for chronic otitis. Twenty-one cases were operated on with the 
robot as a micro-instrument holder for otosclerosis (9 cases), transtympanic 
tube placement (2 cases), or cochlear implantation (10 cases).
RESULTS: No complications related to the robot manipulation occurred during 
surgery nor in postoperative. In the chronic otitis group, all perforations were 
sealed and 3-month postoperative pure-tone average air-bone gap (PTA ABG) was 
15 ± 2.6 dB. In the otosclerosis group, 1-month post-op PTA ABG was 10 ± 1 dB. 
For cochlear implantation cases, a scala tympani insertion, a vestibular scala 
translocation occurred and a full scala vestibuli insertion was observed in 7, 2 
and 1 case, respectively.
CONCLUSION: The RobOtol system has reached the clinical stage. It could be used 
safely and with accurate control as an endoscope holder or a micro instrument 
holder in 32 cases.

DOI: 10.1007/s00405-020-06070-z
PMID: 32458123 [Indexed for MEDLINE]


657. Hear Res. 2015 Dec;330(Pt A):62-77. doi: 10.1016/j.heares.2015.08.016. Epub 2015 
Sep 1.

Comparative gene expression study of the vestibular organ of the Igf1 deficient 
mouse using whole-transcript arrays.

Rodríguez-de la Rosa L(1), Sánchez-Calderón H(2), Contreras J(3), Murillo-Cuesta 
S(1), Falagan S(4), Avendaño C(5), Dopazo J(6), Varela-Nieto I(1), Milo M(7).

Author information:
(1)Neurobiology of Hearing, Department of Endocrine and Nervous System 
Pathophysiology, Alberto Sols Biomedical Research Institute (IIBM), CSIC-UAM, 
Madrid, Spain; Biomedical Research Networking Center on Rare Diseases (CIBERER), 
Institute of Health Carlos III (ISCIII), Madrid, Spain; IdiPAZ Institute for 
Health Research, Madrid, Spain.
(2)Neurobiology of Hearing, Department of Endocrine and Nervous System 
Pathophysiology, Alberto Sols Biomedical Research Institute (IIBM), CSIC-UAM, 
Madrid, Spain.
(3)Neurobiology of Hearing, Department of Endocrine and Nervous System 
Pathophysiology, Alberto Sols Biomedical Research Institute (IIBM), CSIC-UAM, 
Madrid, Spain; Biomedical Research Networking Center on Rare Diseases (CIBERER), 
Institute of Health Carlos III (ISCIII), Madrid, Spain; Department of Anatomy, 
Faculty of Veterinary, Complutense University, Madrid, Spain.
(4)Department of Anatomy, Faculty of Medicine, Autonomous University, Madrid, 
Spain.
(5)IdiPAZ Institute for Health Research, Madrid, Spain; Department of Anatomy, 
Faculty of Medicine, Autonomous University, Madrid, Spain.
(6)Biomedical Research Networking Center on Rare Diseases (CIBERER), Institute 
of Health Carlos III (ISCIII), Madrid, Spain; Department of Computational 
Genomics, Centro de Investigación Príncipe Felipe, Valencia, Spain.
(7)Department of Biomedical Science, University of Sheffield, Sheffield, UK. 
Electronic address: m.milo@sheffield.ac.uk.

The auditory and vestibular organs form the inner ear and have a common 
developmental origin. Insulin like growth factor 1 (IGF-1) has a central role in 
the development of the cochlea and maintenance of hearing. Its deficiency causes 
sensorineural hearing loss in man and mice. During chicken early development, 
IGF-1 modulates neurogenesis of the cochleovestibular ganglion but no further 
studies have been conducted to explore the potential role of IGF-1 in the 
vestibular system. In this study we have compared the whole transcriptome of the 
vestibular organ from wild type and Igf1(-/-) mice at different developmental 
and postnatal times. RNA was prepared from E18.5, P15 and P90 vestibular organs 
of Igf1(-/-) and Igf1(+/+) mice and the transcriptome analysed in triplicates 
using Affymetrix(®) Mouse Gene 1.1 ST Array Plates. These plates are 
whole-transcript arrays that include probes to measure both messenger (mRNA) and 
long intergenic non-coding RNA transcripts (lincRNA), with a coverage of over 28 
thousand coding transcripts and over 7 thousands non-coding transcripts. Given 
the complexity of the data we used two different methods VSN-RMA and mmBGX to 
analyse and compare the data. This is to better evaluate the number of false 
positives and to quantify uncertainty of low signals. We identified a number of 
differentially expressed genes that we described using functional analysis and 
validated using RT-qPCR. The morphology of the vestibular organ did not show 
differences between genotypes and no evident alterations were observed in the 
vestibular sensory areas of the null mice. However, well-defined cellular 
alterations were found in the vestibular neurons with respect their number and 
size. Although these mice did not show a dramatic vestibular phenotype, we 
conducted a functional analysis on differentially expressed genes between 
genotypes and across time. This was with the aim to identify new pathways that 
are involved in the development of the vestibular organ as well as pathways that 
maybe affected by the lack of IGF-1 and be associated to the morphological 
changes of the vestibular neurons that we observed in the Igf1(-/-) mice.

Copyright © 2015 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2015.08.016
PMID: 26341476 [Indexed for MEDLINE]


658. Neuropsychol Dev Cogn B Aging Neuropsychol Cogn. 2023 Jun 12:1-19. doi: 
10.1080/13825585.2023.2223904. Online ahead of print.

The effect of hearing loss on age-related differences in neural distinctiveness.

Guerreiro MJS(1)(2), Puschmann S(1), Eck J(3), Rienäcker F(4), Van Gerven 
PWM(5), Thiel CM(1)(2).

Author information:
(1)Biological Psychology, Department of Psychology, School of Medicine and 
Health Sciences, Carl von Ossietzky University of Oldenburg, Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky University of 
Oldenburg, Oldenburg, Germany.
(3)Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, 
Maastricht University, Maastricht, The Netherlands.
(4)Department of Neuropsychology and Psychopharmacology, Faculty of Psychology 
and Neuroscience, Maastricht University, Maastricht, The Netherlands.
(5)Department of Educational Development & Research, School of Health 
Professions Education (SHE), Faculty of Health, Medicine and Life Sciences, 
Maastricht University, Maastricht, The Netherlands.

Age differences in cognitive performance have been shown to be overestimated if 
age-related hearing loss is not taken into account. Here, we investigated the 
role of age-related hearing loss on age differences in functional brain 
organization by assessing its impact on previously reported age differences in 
neural differentiation. To this end, we analyzed the data of 36 younger adults, 
21 older adults with clinically normal hearing, and 21 older adults with 
mild-to-moderate hearing loss who had taken part in a functional localizer task 
comprising visual (i.e., faces, scenes) and auditory stimuli (i.e., voices, 
music) while undergoing functional magnetic resonance imaging. Evidence for 
reduced neural distinctiveness in the auditory cortex was observed only in older 
adults with hearing loss relative to younger adults, whereas evidence for 
reduced neural distinctiveness in the visual cortex was observed both in older 
adults with normal hearing and in older adults with hearing loss relative to 
younger adults. These results indicate that age-related dedifferentiation in the 
auditory cortex is exacerbated by age-related hearing loss.

DOI: 10.1080/13825585.2023.2223904
PMID: 37306610


659. Front Neurosci. 2020 Jul 16;14:748. doi: 10.3389/fnins.2020.00748. eCollection 
2020.

Decoding Hearing-Related Changes in Older Adults' Spatiotemporal Neural 
Processing of Speech Using Machine Learning.

Mahmud MS(1), Ahmed F(1), Al-Fahad R(1), Moinuddin KA(1), Yeasin M(1), Alain 
C(2)(3)(4), Bidelman GM(5)(6)(7).

Author information:
(1)Department of Electrical and Computer Engineering, The University of Memphis, 
Memphis, TN, United States.
(2)Rotman Research Institute-Baycrest Centre for Geriatric Care, Toronto, ON, 
Canada.
(3)Department of Psychology, University of Toronto, Toronto, ON, Canada.
(4)Institute of Medical Sciences, University of Toronto, Toronto, ON, Canada.
(5)Institute for Intelligent Systems, University of Memphis, Memphis, TN, United 
States.
(6)School of Communication Sciences and Disorders, University of Memphis, 
Memphis, TN, United States.
(7)Department of Anatomy and Neurobiology, University of Tennessee Health 
Science Center, Memphis, TN, United States.

Speech perception in noisy environments depends on complex interactions between 
sensory and cognitive systems. In older adults, such interactions may be 
affected, especially in those individuals who have more severe age-related 
hearing loss. Using a data-driven approach, we assessed the temporal (when in 
time) and spatial (where in the brain) characteristics of cortical speech-evoked 
responses that distinguish older adults with or without mild hearing loss. We 
performed source analyses to estimate cortical surface signals from the EEG 
recordings during a phoneme discrimination task conducted under clear and 
noise-degraded conditions. We computed source-level ERPs (i.e., mean activation 
within each ROI) from each of the 68 ROIs of the Desikan-Killiany (DK) atlas, 
averaged over a randomly chosen 100 trials without replacement to form feature 
vectors. We adopted a multivariate feature selection method called stability 
selection and control to choose features that are consistent over a range of 
model parameters. We use parameter optimized support vector machine (SVM) as a 
classifiers to investigate the time course and brain regions that segregate 
groups and speech clarity. For clear speech perception, whole-brain data 
revealed a classification accuracy of 81.50% [area under the curve (AUC) 80.73%; 
F1-score 82.00%], distinguishing groups within ∼60 ms after speech onset (i.e., 
as early as the P1 wave). We observed lower accuracy of 78.12% [AUC 77.64%; 
F1-score 78.00%] and delayed classification performance when speech was embedded 
in noise, with group segregation at 80 ms. Separate analysis using left (LH) and 
right hemisphere (RH) regions showed that LH speech activity was better at 
distinguishing hearing groups than activity measured in the RH. Moreover, 
stability selection analysis identified 12 brain regions (among 1428 total 
spatiotemporal features from 68 regions) where source activity segregated groups 
with >80% accuracy (clear speech); whereas 16 regions were critical for 
noise-degraded speech to achieve a comparable level of group segregation (78.7% 
accuracy). Our results identify critical time-courses and brain regions that 
distinguish mild hearing loss from normal hearing in older adults and confirm a 
larger number of active areas, particularly in RH, when processing 
noise-degraded speech information.

Copyright © 2020 Mahmud, Ahmed, Al-Fahad, Moinuddin, Yeasin, Alain and Bidelman.

DOI: 10.3389/fnins.2020.00748
PMCID: PMC7378401
PMID: 32765215


660. Audiol Neurootol. 2005 Sep-Oct;10(5):258-73. doi: 10.1159/000086000. Epub 2005 
May 27.

The human spiral ganglion: new insights into ultrastructure, survival rate and 
implications for cochlear implants.

Glueckert R(1), Pfaller K, Kinnefors A, Rask-Andersen H, Schrott-Fischer A.

Author information:
(1)Department of Otolaryngology, Institute of Anatomy and Histology, Medical 
University of Innsbruck, Innsbruck, Austria.

This study was based on high-resolution SEM assessment of freshly fixed, 
normal-hearing, human inner ear tissue. In addition, semiquantitative 
observations were made in long-term deafened temporal bone material, focusing on 
the spiral ganglia and nerve projections, and a detailed study of the fine bone 
structure in macerated tissues was performed. Our main findings detail the 
presence of extensive bony fenestrae surrounding the nerve elements, permitting 
a relatively free flow of perilymph to modiolar structures. The clustering of 
the spiral ganglion cells in Rosenthal's canal and the detailed and intricate 
course of postganglionic axons are described. The close proximity of fibers to 
cell soma is demonstrated by impression in cell surfaces, and presence of small 
microvilli-like structures at the contact regions, anchoring nerve fibers to the 
cell wall. Extensive fenestrae and the presence of a fragile network of 
endosteal bony structures at the surfaces guiding nerve fibers are described in 
detail for the first time. This unique freshly prepared human material offers 
the opportunity for a detailed ultrastructural study not previously possible on 
postmortem fixed material and more accurate information to model 
electrostimulation of the human auditory nerve through a cochlear implant. On 
the basis of this study, we suggest that the concentration and high density of 
spiral ganglion cells, and the close physical interaction between neural 
elements, may explain the slow retrograde degeneration found in humans after 
loss of peripheral receptors. Moreover, the fragile bony columns connecting the 
spiral canal with the osseous spiral lamina may be a potential site for trauma 
in (perimodiolar) electrode positioning.

Copyright (c) 2005 S. Karger AG, Basel.

DOI: 10.1159/000086000
PMID: 15925863 [Indexed for MEDLINE]


661. Am J Otol. 1996 Nov;17(6):883-92.

Characteristics of six otologic diseases involving vertigo.

Kentala E(1).

Author information:
(1)Department of Otolaryngology, University Hospital of Helsinki, Finland.

Comment in
    Am J Otol. 1997 Mar;18(2):267.

To characterize otologic causes for vertigo, data on 564 patients with the six 
most common diseases involving vertigo were retrieved from the database of a 
computer-aided diagnostic system for neurotologic diseases. The diseases were 
Meniere's disease, vestibular schwannoma, benign paroxysmal positional vertigo, 
vestibular neuritis, sudden deafness, and traumatic vertigo. The prevalence of 
tinnitus in the study population was 76%. The most severe forms of vertigo and 
nausea were found in vestibular neuritis, whereas the most severe case of 
tinnitus appeared in Meniere's disease. Of the patients with vestibular 
schwannoma, 49% had had vertigo. A linear discrimination analysis using case 
history classified 90% of the patients into correct groups. The key questions 
discriminating between the diseases concerned the frequency and duration of 
vertigo attacks, the duration of hearing loss and vertigo, and the occurrence of 
head injury. Making a correct diagnosis during the first office visit can be 
difficult, especially for sudden deafness, vestibular schwannoma, and Meniere's 
disease. Neurotologic and audiometric information was of minor value in 
distinguishing between these six diseases. Vestibular schwannoma had 
significantly greater asymmetry in electronystagmography and smaller gains in 
smooth pursuit in comparison with the other disease. Factorial analysis did not 
aid the clustering of these diseases.

PMID: 8915417 [Indexed for MEDLINE]


662. Neuroimage. 2020 Jul 15;215:116806. doi: 10.1016/j.neuroimage.2020.116806. Epub 
2020 Apr 10.

Functional anomaly mapping reveals local and distant dysfunction caused by brain 
lesions.

DeMarco AT(1), Turkeltaub PE(2).

Author information:
(1)Department of Neurology, Georgetown University, Washington, DC, 20057, United 
States. Electronic address: andrew.demarco@georgetown.edu.
(2)Department of Neurology, Georgetown University, Washington, DC, 20057, United 
States; MedStar National Rehabilitation Hospital, Washington, DC, 20010, United 
States.

The lesion method has been important for understanding brain-behavior 
relationships in humans, but has previously used maps based on structural 
damage. Lesion measurement based on structural damage may label partly damaged 
but functional tissue as abnormal, and moreover, ignores distant dysfunction in 
structurally intact tissue caused by deafferentation, diaschisis, and other 
processes. A reliable method to map functional integrity of tissue throughout 
the brain would provide a valuable new approach to measuring lesions. Here, we 
use machine learning on four dimensional resting state fMRI data obtained from 
left-hemisphere stroke survivors in the chronic period of recovery and control 
subjects to generate graded maps of functional anomaly throughout the brain in 
individual patients. These functional anomaly maps identify areas of obvious 
structural lesions and are stable across multiple measurements taken months and 
even years apart. Moreover, the maps identify functionally anomalous regions in 
structurally intact tissue, providing a direct measure of remote effects of 
lesions on the function of distant brain structures. Multivariate 
lesion-behavior mapping using functional anomaly maps replicates classic 
behavioral localization, identifying inferior frontal regions related to speech 
fluency, lateral temporal regions related to auditory comprehension, parietal 
regions related to phonology, and the hand area of motor cortex and descending 
corticospinal pathways for hand motor function. Further, this approach 
identifies relationships between tissue function and behavior distant from the 
structural lesions, including right premotor dysfunction related to ipsilateral 
hand movement, and right cerebellar regions known to contribute to speech 
fluency. Brain-wide maps of the functional effects of focal lesions could have 
wide implications for lesion-behavior association studies and studies of 
recovery after brain injury.

Copyright © 2020 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116806
PMCID: PMC7292795
PMID: 32278896 [Indexed for MEDLINE]


663. J Neurosci. 2004 Apr 28;24(17):4213-23. doi: 10.1523/JNEUROSCI.0223-04.2004.

gemini encodes a zebrafish L-type calcium channel that localizes at sensory hair 
cell ribbon synapses.

Sidi S(1), Busch-Nentwich E, Friedrich R, Schoenberger U, Nicolson T.

Author information:
(1)Max-Planck-Institut für Entwicklungsbiologie, 72076 Tübingen, Germany.

L-type Ca2+ channels (LTCCs) drive the bulk of voltage-gated Ca2+ entry in 
vertebrate inner ear hair cells (HCs) and are essential for mammalian auditory 
processing. LTCC currents have been implicated in neurotransmitter release at 
the HC afferent active zone, the ribbon synapse. It is likely that LTCCs play a 
direct role in vesicle fusion; however, the subcellular localization of the 
channels in HCs has not been fully resolved. Via positional cloning, we show 
that mutations in a zebrafish LTCC encoding gene, cav1.3a, underlie the 
auditory-vestibular defects of gemini (gem) circler mutants. gem homozygous 
receptor mutant HCs display normal cell viability, afferent synaptogenesis, and 
peripheral innervation, yet exhibit strongly reduced extracellular potentials 
(approximately 50% of wild-type potentials). Apical FM1-43 uptake, however, is 
unaffected in gem mutant HCs, suggesting that mechanotransduction channels are 
functional. Using a Gem-specific antibody, we show that the bulk of 
Gem/Ca(v)1.3a immunoreactivity in HCs is restricted to basally located focal 
spots. The number and location of focal spots relative to nerve terminals, and 
their remarkable ring-shaped structure, which is reminiscent of synaptic dense 
bodies, are consistent with Gem/Ca(v)1.3a channels clustering at HC ribbon 
synapses.

DOI: 10.1523/JNEUROSCI.0223-04.2004
PMCID: PMC6729292
PMID: 15115817 [Indexed for MEDLINE]


664. Brain Res. 2024 Apr 1;1828:148775. doi: 10.1016/j.brainres.2024.148775. Epub 
2024 Jan 18.

Research progress of the inferior colliculus: from Neuron, neural circuit to 
auditory disease.

Liu M(1), Wang Y(1), Jiang L(1), Zhang X(1), Wang C(1), Zhang T(2).

Author information:
(1)Department of Otolaryngology Head and Neck Surgery, First Affiliated Hospital 
of Harbin Medical University, Harbin, Heilongjiang 150001, China.
(2)Department of Otolaryngology Head and Neck Surgery, First Affiliated Hospital 
of Harbin Medical University, Harbin, Heilongjiang 150001, China. Electronic 
address: zth3856@126.com.

The auditory midbrain, also known as the inferior colliculus (IC), serves as a 
crucial hub in the auditory pathway. Comprising diverse cell types, the IC plays 
a pivotal role in various auditory functions, including sound localization, 
auditory plasticity, sound detection, and sound-induced behaviors. Notably, the 
IC is implicated in several auditory central disorders, such as tinnitus, 
age-related hearing loss, autism and Fragile X syndrome. Accurate classification 
of IC neurons is vital for comprehending both normal and dysfunctional aspects 
of IC function. Various parameters, including dendritic morphology, 
neurotransmitter synthesis, potassium currents, biomarkers, and axonal targets, 
have been employed to identify distinct neuron types within the IC. However, the 
challenge persists in effectively classifying IC neurons into functional 
categories due to the limited clustering capabilities of most parameters. Recent 
studies utilizing advanced neuroscience technologies have begun to shed light on 
biomarker-based approaches in the IC, providing insights into specific cellular 
properties and offering a potential avenue for understanding IC functions. This 
review focuses on recent advancements in IC research, spanning from neurons and 
neural circuits to aspects related to auditory diseases.

Copyright © 2024 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.brainres.2024.148775
PMID: 38244755 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


665. PLoS One. 2012;7(5):e36066. doi: 10.1371/journal.pone.0036066. Epub 2012 May 3.

Stemness of the organ of Corti relates to the epigenetic status of Sox2 
enhancers.

Waldhaus J(1), Cimerman J, Gohlke H, Ehrich M, Müller M, Löwenheim H.

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Hearing Research 
Center Tübingen, University of Tübingen Medical Center, Tübingen, Germany.

In the adult mammalian auditory epithelium, the organ of Corti, loss of sensory 
hair cells results in permanent hearing loss. The underlying cause for the lack 
of regenerative response is the depletion of otic progenitors in the cell pool 
of the sensory epithelium. Here, we show that an increase in the 
sequence-specific methylation of the otic Sox2 enhancers NOP1 and NOP2 is 
correlated with a reduced self-renewal potential in vivo and in vitro; 
additionally, the degree of methylation of NOP1 and NOP2 is correlated with the 
dedifferentiation potential of postmitotic supporting cells into otic stem 
cells. Thus, the stemness the organ of Corti is related to the epigenetic status 
of the otic Sox2 enhancers. These observations validate the continued 
exploration of treatment strategies for dedifferentiating or reprogramming of 
differentiated supporting cells into progenitors to regenerate the damaged organ 
of Corti.

DOI: 10.1371/journal.pone.0036066
PMCID: PMC3343037
PMID: 22570694 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: HG and ME are employees of 
SEQUENOM GmbH and SEQUENOM, Inc., respectively. All other authors have declared 
that no competing interests exist. This does not alter our adherence to all the 
PLoS ONE policies on sharing data and materials.


666. Front Neurosci. 2019 May 3;13:420. doi: 10.3389/fnins.2019.00420. eCollection 
2019.

Exploring Differences in Speech Processing Among Older Hearing-Impaired 
Listeners With or Without Hearing Aid Experience: Eye-Tracking and fMRI 
Measurements.

Habicht J(1), Behler O(1), Kollmeier B(1), Neher T(2).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all", Oldenburg 
University, Oldenburg, Germany.
(2)Institute of Clinical Research, University of Southern Denmark, Odense, 
Denmark.

Recently, evidence has been accumulating that untreated hearing loss can lead to 
neurophysiological changes that affect speech processing abilities in noise. To 
shed more light on how aiding may impact these effects, this study explored the 
influence of hearing aid (HA) experience on the cognitive processes underlying 
speech comprehension. Eye-tracking and functional magnetic resonance imaging 
(fMRI) measurements were carried out with acoustic sentence-in-noise (SiN) 
stimuli complemented by pairs of pictures that either correctly (target picture) 
or incorrectly (competitor picture) depicted the sentence meanings. For the 
eye-tracking measurements, the time taken by the participants to start fixating 
the target picture (the 'processing time') was measured. For the fMRI 
measurements, brain activation inferred from blood-oxygen-level dependent 
responses following sentence comprehension was measured. A noise-only condition 
was also included. Groups of older hearing-impaired individuals matched in terms 
of age, hearing loss, and working memory capacity with (eHA; N = 13) or without 
(iHA; N = 14) HA experience participated. All acoustic stimuli were presented 
via earphones with individual linear amplification to ensure audibility. 
Consistent with previous findings, the iHA group had significantly longer 
(poorer) processing times than the eHA group, despite no differences in speech 
recognition performance. Concerning the fMRI measurements, there were 
indications of less brain activation in some right frontal areas for SiN 
relative to noise-only stimuli in the eHA group compared to the iHA group. 
Together, these results suggest that HA experience leads to faster 
speech-in-noise processing, possibly related to less recruitment of brain 
regions outside the core sentence-comprehension network. Follow-up research is 
needed to substantiate the findings related to changes in cortical speech 
processing with HA use.

DOI: 10.3389/fnins.2019.00420
PMCID: PMC6509414
PMID: 31130836


667. Front Comput Neurosci. 2022 Mar 30;16:825160. doi: 10.3389/fncom.2022.825160. 
eCollection 2022.

Functional Brain Connections Identify Sensorineural Hearing Loss and Predict the 
Outcome of Cochlear Implantation.

Song Q(1), Qi S(1)(2), Jin C(1), Yang L(1), Qian W(3), Yin Y(4), Zhao H(5), Yu 
H(6).

Author information:
(1)College of Medicine and Biological Information Engineering, Northeastern 
University, Shenyang, China.
(2)Key Laboratory of Intelligent Computing in Medical Image, Ministry of 
Education, Northeastern University, Shenyang, China.
(3)Department of Electrical and Computer Engineering, University of Texas at El 
Paso, El Paso, TX, United States.
(4)Department of Radiology, The Affiliated Hospital of Guizhou Medical 
University, Guiyang, China.
(5)Department of Otolaryngology, The Affiliated Hospital of Guizhou Medical 
University, Guiyang, China.
(6)Department of Radiology, The Seventh Affiliated Hospital, Southern Medical 
University, Foshan, China.

Identification of congenital sensorineural hearing loss (SNHL) and early 
intervention, especially by cochlear implantation (CI), are crucial for 
restoring hearing in patients. However, high accuracy diagnostics of SNHL and 
prognostic prediction of CI are lacking to date. To diagnose SNHL and predict 
the outcome of CI, we propose a method combining functional connections (FCs) 
measured by functional magnetic resonance imaging (fMRI) and machine learning. A 
total of 68 children with SNHL and 34 healthy controls (HC) of matched age and 
gender were recruited to construct classification models for SNHL and HC. A 
total of 52 children with SNHL that underwent CI were selected to establish a 
predictive model of the outcome measured by the category of auditory performance 
(CAP), and their resting-state fMRI images were acquired. After the dimensional 
reduction of FCs by kernel principal component analysis, three machine learning 
methods including the support vector machine, logistic regression, and k-nearest 
neighbor and their voting were used as the classifiers. A multiple logistic 
regression method was performed to predict the CAP of CI. The classification 
model of voting achieves an area under the curve of 0.84, which is higher than 
that of three single classifiers. The multiple logistic regression model 
predicts CAP after CI in SNHL with an average accuracy of 82.7%. These models 
may improve the identification of SNHL through fMRI images and prognosis 
prediction of CI in SNHL.

Copyright © 2022 Song, Qi, Jin, Yang, Qian, Yin, Zhao and Yu.

DOI: 10.3389/fncom.2022.825160
PMCID: PMC9005839
PMID: 35431849

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


668. Sci Data. 2024 Apr 22;11(1):411. doi: 10.1038/s41597-024-03259-3.

Single-unit data for sensory neuroscience: Responses from the auditory nerve of 
young-adult and aging gerbils.

Heeringa AN(1).

Author information:
(1)Research Centre Neurosensory Science and Cluster of Excellence "Hearing4all", 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, Carl von Ossietzky Straße 9-11, 26129, 
Oldenburg, Germany. amarins.nieske.heeringa@uni-oldenburg.de.

This dataset was collected to study the functional consequences of age-related 
hearing loss for the auditory nerve, which carries acoustic information from the 
periphery to the central auditory system. Using high-impedance glass electrodes, 
raw voltage traces and spike times were recorded from more than one thousand 
single fibres of the auditory nerve of young-adult, middle-aged, and old 
Mongolian gerbils raised in a quiet environment. The dataset contains not only 
responses to simple acoustic stimuli to characterize the fibres, but also to 
more complex stimuli, such as speech logatomes in background noise and 
Schroeder-phase stimuli. A software toolbox is provided to search through the 
dataset, to plot various analysed outcomes, and to give insight into the 
analyses. This dataset may serve as a valuable resource to test further 
hypotheses about age-related hearing loss. Additionally, it can aid in 
optimizing available computational models of the auditory system, which can 
contribute to, or eventually even fully replace, animal experiments.

© 2024. The Author(s).

DOI: 10.1038/s41597-024-03259-3
PMID: 38649691


669. Brain Topogr. 2014 May;27(3):412-24. doi: 10.1007/s10548-013-0341-7. Epub 2013 
Dec 12.

Source localisation of visual evoked potentials in congenitally deaf 
individuals.

Hauthal N(1), Thorne JD, Debener S, Sandmann P.

Author information:
(1)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all", European Medical School, University of Oldenburg, 26111, 
Oldenburg, Germany, nadine.hauthal@uni-oldenburg.de.

Previous studies have suggested that individuals deprived of auditory input can 
compensate with specific superior abilities in the remaining sensory modalities. 
To better understand the neural basis of deafness-induced changes, the present 
study used electroencephalography to examine visual functions and cross-modal 
reorganization of the auditory cortex in deaf individuals. Congenitally deaf 
participants and hearing controls were presented with reversing chequerboard 
stimuli that were systematically modulated in luminance ratio. The two groups of 
participants showed similar modulation of visual evoked potential (VEP) 
amplitudes (N85, P110) and latencies (P110) as a function of luminance ratio. 
Analysis of VEPs revealed faster neural processing in deaf participants compared 
with hearing controls at early stages of cortical visual processing (N85). Deaf 
participants also showed higher amplitudes (P110) than hearing participants. In 
contrast to our expectations, the results from VEP source analysis revealed no 
clear evidence for cross-modal reorganization in the auditory cortex of deaf 
participants. However, deaf participants tended to show higher activation in 
posterior parietal cortex (PPC). Moreover, modulation of PPC responses as a 
function of luminance was also stronger in deaf than in hearing participants. 
Taken together, these findings are an indication of more efficient neural 
processing of visual information in the deaf, which may relate to functional 
changes, in particular in multisensory parietal cortex, as a consequence of 
early auditory deprivation.

DOI: 10.1007/s10548-013-0341-7
PMID: 24337445 [Indexed for MEDLINE]


670. Front Cell Neurosci. 2019 May 14;13:177. doi: 10.3389/fncel.2019.00177. 
eCollection 2019.

Stem Cell Based Drug Delivery for Protection of Auditory Neurons in a Guinea Pig 
Model of Cochlear Implantation.

Scheper V(1)(2)(3), Hoffmann A(3)(4), Gepp MM(5)(6), Schulz A(5), Hamm A(3)(4), 
Pannier C(1), Hubka P(3)(7), Lenarz T(1)(2)(3), Schwieger J(1)(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hanover, Germany.
(2)Cluster of Excellence 'Hearing4all', German Research Foundation, Bonn, 
Germany.
(3)Lower Saxony Centre for Biomedical Engineering, Implant Research and 
Development (NIFE), Hanover, Germany.
(4)Department of Orthopaedic Surgery, Hannover Medical School, Hanover, Germany.
(5)Fraunhofer Institute for Biomedical Engineering IBMT, Sulzbach, Germany.
(6)Fraunhofer Project Center for Stem Cell Process Engineering, Würzburg, 
Germany.
(7)Department of Experimental Otology, Hannover Medical School, Hanover, 
Germany.

Background: The success of a cochlear implant (CI), which is the standard 
therapy for patients suffering from severe to profound sensorineural hearing 
loss, depends on the number and excitability of spiral ganglion neurons (SGNs). 
Brain-derived neurotrophic factor (BDNF) has a protective effect on SGNs but 
should be applied chronically to guarantee their lifelong survival. Long-term 
administration of BDNF could be achieved using genetically modified mesenchymal 
stem cells (MSCs), but these cells should be protected - by ultra-high viscous 
(UHV-) alginate ('alginate-MSCs') - from the recipient immune system and from 
uncontrolled migration. Methods: Brain-derived neurotrophic factor-producing 
MSCs were encapsulated in UHV-alginate. Four experimental groups were 
investigated using guinea pigs as an animal model. Three of them were 
systemically deafened and (unilaterally) received one of the following: (I) a 
CI; (II) an alginate-MSC-coated CI; (III) an injection of alginate-embedded MSCs 
into the scala tympani followed by CI insertion and alginate polymerization. 
Group IV was normal hearing, with CI insertion in both ears and a unilateral 
injection of alginate-MSCs. Using acoustically evoked auditory brainstem 
response measurements, hearing thresholds were determined before implantation 
and before sacrificing the animals. Electrode impedance was measured weekly. 
Four weeks after implantation, the animals were sacrificed and the SGN density 
and degree of fibrosis were evaluated. Results: The MSCs survived being 
implanted for 4 weeks in vivo. Neither the alginate-MSC injection nor the 
coating affected electrode impedance or fibrosis. CI insertion with and without 
previous alginate injection in normal-hearing animals resulted in increased 
hearing thresholds within the high-frequency range. Low-frequency hearing loss 
was additionally observed in the alginate-injected and implanted cochleae, but 
not in those treated only with a CI. In deafened animals, the alginate-MSC 
coating of the CI significantly prevented SGN from degeneration, but the 
injection of alginate-MSCs did not. Conclusion: Brain-derived neurotrophic 
factor-producing MSCs encapsulated in UHV-alginate prevent SGNs from 
degeneration in the form of coating on the CI surface, but not in the form of an 
injection. No increase in fibrosis or impedance was detected. Further research 
and development aimed at verifying long-term mechanical and biological 
properties of coated electrodes in vitro and in vivo, in combination with 
chronic electrical stimulation, is needed before the current concept can be 
tested in clinical trials.

DOI: 10.3389/fncel.2019.00177
PMCID: PMC6527816
PMID: 31139049


671. Front Neurosci. 2022 Jan 5;15:781196. doi: 10.3389/fnins.2021.781196. 
eCollection 2021.

Speech-Driven Facial Animations Improve Speech-in-Noise Comprehension of Humans.

Varano E(1), Vougioukas K(2), Ma P(2), Petridis S(2), Pantic M(2), Reichenbach 
T(3).

Author information:
(1)Department of Bioengineering and Centre for Neurotechnology, Imperial College 
London, London, United Kingdom.
(2)Department of Computing, Imperial College London, London, United Kingdom.
(3)Department of Artificial Intelligence in Biomedical Engineering, 
Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany.

Understanding speech becomes a demanding task when the environment is noisy. 
Comprehension of speech in noise can be substantially improved by looking at the 
speaker's face, and this audiovisual benefit is even more pronounced in people 
with hearing impairment. Recent advances in AI have allowed to synthesize 
photorealistic talking faces from a speech recording and a still image of a 
person's face in an end-to-end manner. However, it has remained unknown whether 
such facial animations improve speech-in-noise comprehension. Here we consider 
facial animations produced by a recently introduced generative adversarial 
network (GAN), and show that humans cannot distinguish between the synthesized 
and the natural videos. Importantly, we then show that the end-to-end 
synthesized videos significantly aid humans in understanding speech in noise, 
although the natural facial motions yield a yet higher audiovisual benefit. We 
further find that an audiovisual speech recognizer (AVSR) benefits from the 
synthesized facial animations as well. Our results suggest that synthesizing 
facial motions from speech can be used to aid speech comprehension in difficult 
listening environments.

Copyright © 2022 Varano, Vougioukas, Ma, Petridis, Pantic and Reichenbach.

DOI: 10.3389/fnins.2021.781196
PMCID: PMC8766421
PMID: 35069100

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


672. bioRxiv [Preprint]. 2023 Jun 10:2023.02.15.528661. doi: 
10.1101/2023.02.15.528661.

Cochlear transcriptome analysis of an outbred mouse population (CFW).

Boussaty EC(1), Tedeschi N(2), Novotny M(2), Ninoyu Y(1), Du E(1), Draf C(1), 
Zhang Y(2), Manor U(3), Scheuermann RH(2)(4), Friedman R(1).

Author information:
(1)Department of Otolaryngology, University of California, San Diego, CA.
(2)J. Craig Venter Institute, La Jolla, CA.
(3)Salk Institute for Biological Studies, Waitt Advanced Biophotonics Center, La 
Jolla, CA, United States.
(4)Department of Pathology, University of California, San Diego, CA.

Update in
    Front Cell Neurosci. 2023 Nov 29;17:1256619.

Age-related hearing loss (ARHL) is the most common cause of hearing loss and one 
of the most prevalent conditions affecting the elderly worldwide. Despite 
evidence from our lab and others about its polygenic nature, little is known 
about the specific genes, cell types and pathways involved in ARHL, impeding the 
development of therapeutic interventions. In this manuscript, we describe, for 
the first time, the complete cell-type specific transcriptome of the aging mouse 
cochlea using snRNA-seq in an outbred mouse model in relation to auditory 
threshold variation. Cochlear cell types were identified using unsupervised 
clustering and annotated via a three-tiered approach - first by linking to 
expression of known marker genes, then using the NS-Forest algorithm to select 
minimum cluster-specific marker genes and reduce dimensional feature space for 
statistical comparison of our clusters with existing publicly-available data 
sets on the gEAR website (https://umgear.org/), and finally, by validating and 
refining the annotations using Multiplexed Error Robust Fluorescence In Situ 
Hybridization (MERFISH) and the cluster-specific marker genes as probes. We 
report on 60 unique cell-types expanding the number of defined cochlear cell 
types by more than two times. Importantly, we show significant specific cell 
type increases and decreases associated with loss of hearing acuity implicating 
specific subsets of hair cell subtypes, ganglion cell subtypes, and cell 
subtypes withing the stria vascularis in this model of ARHL. These results 
provide a view into the cellular and molecular mechanisms responsible for 
age-related hearing loss and pathways for therapeutic targeting.

DOI: 10.1101/2023.02.15.528661
PMCID: PMC9948975
PMID: 36824745


673. Trends Amplif. 2011 Mar-Jun;15(1):34-56. doi: 10.1177/1084713811417634.

An integrated knowledge translation experience: use of the Network of Pediatric 
Audiologists of Canada to facilitate the development of the University of 
Western Ontario Pediatric Audiological Monitoring Protocol (UWO PedAMP v1.0).

Moodie ST(1), Bagatto MP, Miller LT, Kothari A, Seewald R, Scollie SD.

Author information:
(1)National Centre for Audiology, Faculty of Health Sciences, University of 
Western Ontario, London, Ontario, Canada. sheila@nca.uwo.ca

Pediatric audiologists lack evidence-based, age-appropriate outcome evaluation 
tools with well-developed normative data that could be used to evaluate the 
auditory development and performance of children aged birth to 6 years with 
permanent childhood hearing impairment. Bagatto and colleagues recommend a 
battery of outcome tools that may be used with this population. This article 
provides results of an evaluation of the individual components of the University 
of Western Ontario Pediatric Audiological Monitoring Protocol (UWO PedAMP) 
version 1.0 by the audiologists associated with the Network of Pediatric 
Audiologists of Canada. It also provides information regarding barriers and 
facilitators to implementing outcome measures in clinical practice. Results 
indicate that when compared to the Parents' Evaluation of Aural/Oral Performance 
of Children (PEACH) Diary, audiologists found the PEACH Rating Scale to be a 
more clinically feasible evaluation tool to implement in practice from a time, 
task, and consistency of use perspective. Results also indicate that the 
LittlEARS(®) Auditory Questionnaire could be used to evaluate the auditory 
development and performance of children aged birth to 6 years with permanent 
childhood hearing impairment (PCHI). The most cited barrier to implementation is 
time. The result of this social collaboration was the creation of a knowledge 
product, the UWO PedAMP v1.0, which has the potential to be useful to 
audiologists and the children and families they serve.

DOI: 10.1177/1084713811417634
PMCID: PMC4040833
PMID: 22194315 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
author(s) declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


674. Front Cell Neurosci. 2023 Nov 29;17:1256619. doi: 10.3389/fncel.2023.1256619. 
eCollection 2023.

Cochlear transcriptome analysis of an outbred mouse population (CFW).

Boussaty EC(#)(1), Tedeschi N(#)(2), Novotny M(2), Ninoyu Y(1), Du E(1), Draf 
C(1), Zhang Y(2), Manor U(3), Scheuermann RH(#)(2)(4), Friedman R(#)(1).

Author information:
(1)Department of Otolaryngology, University of California, San Diego, La Jolla, 
CA, United States.
(2)J. Craig Venter Institute, La Jolla, CA, United States.
(3)Department of Cell and Developmental Biology, University of California San 
Diego, Salk Institute for Biological Studies, Waitt Advanced Biophotonics 
Center, La Jolla, CA, United States.
(4)Department of Pathology, University of California, San Diego, La Jolla, CA, 
United States.
(#)Contributed equally

Update of
    bioRxiv. 2023 Jun 10;:

Age-related hearing loss (ARHL) is the most common cause of hearing loss and one 
of the most prevalent conditions affecting the elderly worldwide. Despite 
evidence from our lab and others about its polygenic nature, little is known 
about the specific genes, cell types, and pathways involved in ARHL, impeding 
the development of therapeutic interventions. In this manuscript, we describe, 
for the first time, the complete cell-type specific transcriptome of the aging 
mouse cochlea using snRNA-seq in an outbred mouse model in relation to auditory 
threshold variation. Cochlear cell types were identified using unsupervised 
clustering and annotated via a three-tiered approach-first by linking to 
expression of known marker genes, then using the NSForest algorithm to select 
minimum cluster-specific marker genes and reduce dimensional feature space for 
statistical comparison of our clusters with existing publicly-available data 
sets on the gEAR website, and finally, by validating and refining the 
annotations using Multiplexed Error Robust Fluorescence In Situ Hybridization 
(MERFISH) and the cluster-specific marker genes as probes. We report on 60 
unique cell-types expanding the number of defined cochlear cell types by more 
than two times. Importantly, we show significant specific cell type increases 
and decreases associated with loss of hearing acuity implicating specific 
subsets of hair cell subtypes, ganglion cell subtypes, and cell subtypes within 
the stria vascularis in this model of ARHL. These results provide a view into 
the cellular and molecular mechanisms responsible for age-related hearing loss 
and pathways for therapeutic targeting.

Copyright © 2023 Boussaty, Tedeschi, Novotny, Ninoyu, Du, Draf, Zhang, Manor, 
Scheuermann and Friedman.

DOI: 10.3389/fncel.2023.1256619
PMCID: PMC10716316
PMID: 38094513

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


675. Semin Hear. 2021 Aug;42(3):175-185. doi: 10.1055/s-0041-1735174. Epub 2021 Sep 
24.

Hearing Aid Technology to Improve Speech Intelligibility in Noise.

Alexander JM(1).

Author information:
(1)Department of Speech, Language, and Hearing Sciences, Purdue University, West 
Lafayette, Indiana.

Understanding speech in noise is difficult for individuals with normal hearing 
and is even more so for individuals with hearing loss. Difficulty understanding 
speech in noise is one of the primary reasons people seek hearing assistance. 
Despite amplification, many hearing aid users still struggle to understand 
speech in noise. In response to this persistent problem, hearing aid 
manufacturers have invested significantly in developing new solutions. Any 
solution is not without its tradeoffs, and decisions must be made when 
optimizing and implementing them. Much of this happens behind the scenes, and 
casual observers fail to appreciate the nuances of developing new hearing aid 
technologies. The difficulty of communicating this information to clinicians may 
hinder the use or the fine-tuning of the various technologies available today. 
The purpose of this issue of Seminars in Hearing is to educate professionals and 
students in audiology, hearing science, and engineering about different 
approaches to combat problems related to environmental and wind noise using 
technologies that include classification, directional microphones, binaural 
signal processing, beamformers, motion sensors, and machine learning. To 
accomplish this purpose, some of the top researchers and engineers from the 
world's largest hearing aid manufacturers agreed to share their unique insights.

The Author(s). This is an open access article published by Thieme under the 
terms of the Creative Commons Attribution-NonDerivative-NonCommercial License, 
permitting copying and reproduction so long as the original work is given 
appropriate credit. Contents may not be used for commercial purposes, or 
adapted, remixed, transformed or built upon. ( 
https://creativecommons.org/licenses/by-nc-nd/4.0/ ).

DOI: 10.1055/s-0041-1735174
PMCID: PMC8463122
PMID: 34594083

Conflict of interest statement: Conflict of Interest None declared.


676. Ups J Med Sci. 2017 Mar;122(1):11-19. doi: 10.1080/03009734.2016.1271843. Epub 
2017 Feb 1.

Supernumerary human hair cells-signs of regeneration or impaired development? A 
field emission scanning electron microscopy study.

Rask-Andersen H(1)(2), Li H(1)(2), Löwenheim H(3)(4)(5), Müller M(3)(4)(5), 
Pfaller K(6), Schrott-Fischer A(7), Glueckert R(7).

Author information:
(1)a Department of Surgical Sciences, Head and Neck Surgery , Section of 
Otolaryngology, Uppsala University Hospital , Uppsala , Sweden.
(2)b Department of Otolaryngology , Uppsala University Hospital , Uppsala , 
Sweden.
(3)c Department of Otolaryngology , Medical University of Innsbruck , Innsbruck 
, Austria.
(4)d Medical Campus University of Oldenburg School of Medicine and Health 
Sciences, European Medical School , Oldenburg , Germany.
(5)e Research Center of Neurosensory Science, University of Oldenburg , 
Oldenburg , Germany.
(6)f Cluster of Excellence Hearing4all , University of Oldenburg , Oldenburg , 
Germany.
(7)g Department of Histology and Molecular Cell Biology , Institute of Anatomy 
and Histology, Medical University of Innsbruck , Innsbruck , Austria.

BACKGROUND: Current attempts to regenerate cochlear sensorineural structures 
motivate further inspection of the human organ of hearing. Here, we analyzed the 
supernumerary inner hair cell (sIHC), a possible sign of regeneration and cell 
replacement.
METHODS: Human cochleae were studied using field emission scanning electron 
microscopy (FESEM; maximum resolution 2 nm) obtained from individuals aged 44, 
48, and 58 years with normal sensorineural pure-tone average (PTA) thresholds 
(PTA <20 dB). The wasted tissue was harvested during trans-cochlear approaches 
and immediately fixed for ultrastructural analysis.
RESULTS: All specimens exhibited sIHCs at all turns except at the extreme lower 
basal turn. In one specimen, it was possible to image and count the inner hair 
cells (IHCs) along the cochlea representing the 0.2 kHz-8 kHz region according 
to the Greenwood place/frequency scale. In a region with 2,321 IHCs, there were 
120 scattered one-cell losses or 'gaps' (5%). Forty-two sIHCs were present 
facing the modiolus. Thirty-eight percent of the sIHCs were located near a 'gap' 
in the IHC row (±6 IHCs).
CONCLUSIONS: The prevalence of ectopic inner hair cells was higher than 
expected. The morphology and placement could reflect a certain ongoing 
regeneration. Further molecular studies are needed to verify if the regenerative 
capacity of the human auditory periphery might have been underestimated.

DOI: 10.1080/03009734.2016.1271843
PMCID: PMC5361427
PMID: 28145795 [Indexed for MEDLINE]


677. Zhonghua Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2016 Nov 7;51(11):819-825. doi: 
10.3760/cma.j.issn.1673-0860.2016.11.004.

[Prevalence of hearing disorders in China: a population-based survey in four 
provinces of China].

[Article in Chinese]

Hu XY(1), Zheng XY(2), Ma FR(3), Long M(1), Han R(1), Zhou LJ(1), Wang F(1), 
Gong R(2), Pan T(3), Zhang SX(3), Du B(4), Jin P(4), Guo CY(5), Zheng YQ(6), Liu 
M(7), He LH(8), Qiu JH(9), Xu M(10), Song L(11), Xu XH(12), Liu XW(13), Wang 
SP(14).

Author information:
(1)China Rehabilitation Research Center for Deaf Children, Beijing 100029, 
China.
(2)Institute of Population Research, Peking University, Beijing 100871, China.
(3)Department of Otorhinolaryngology, Peking University Third Hospital, Beijing 
100191, China.
(4)Department of Otorhinolaryngology Head and Neck Surgery, the First Hospital 
of Jilin University, Changchun 130021, China.
(5)Language and Hearing Rehabilitation Center of Jilin Province, Changchun 
130052, China.
(6)Department of Otorhinolaryngology Head and Neck Surgery, Sun Yat-Sen Memorial 
Hospital, Sun Yat-Sen University, Guangzhou 510120, China.
(7)Otorhinolaryngology Hospital of First Affiliated Hospital of Sun Yetsan 
University, Guangzhou 510080, China.
(8)Guangdong Rehabilitation Centre, Guangzhou 510055, China.
(9)Department of Otorhinolaryngology Head and Neck Surgery, Xijing Hospital, 
Xi'an 710032, China.
(10)Department of Otorhinolaryngology Head and Neck Surgery, Second Affiliated 
Hospital, Xi'an Jiaotong University School of Medicine, Xi'an 710004, China.
(11)Language and Hearing Rehabilitation Center of Shanxi Province, Xi'an 710016, 
China.
(12)Department of Otorhinolaryngology, Lanzhou General Hospital, Lanzhou 
Command, Lanzhou 730050, China.
(13)Department of Otorhinolaryngology, Lanzhou University Second Hospital, 
Lanzhou 730030, China.
(14)Hearing and Language Rehabilitation Center of Gangsu Province, Lanzhou 
730050, China.

Objective: To investigate the prevalence, severity of hearing disorders and 
demographics of people with hearing disorders based on the whole population in 
Jilin, Guangdong, Shannxi and Gansu provinces in China. Methods: According to " 
WHO Ear and Hearing Disorders Survey Protocol" , 144 clusters were chosen with 
probability proportional sampling(PPS) method from the four provinces covering 
194, 688, 061 residents. Audiological test, otological examination and 
questionnaire surveying were conducted for all samples from August, 2014 to 
September, 2015. The hearing disorders were classified according to WHO criteria 
and classification. Results: Among 47 511 targeted residents, 45, 052 
individuals (94.82% response rate) participated in the survey. The standardized 
prevalence rates of hearing disorders and disabling hearing disorders were 15.84 
% and 5.17 % respectively. Almost 50% of people with hearing disorders had no 
awareness of it or its starting time. There was significant difference in the 
prevalence among people of different ages, genders, occupations, provinces, 
marital status and education levels. The prevalence of hearing disorders 
increased significantly as age grew. People above 60 years old occupied 55.31% 
of the total hearing disorders. The prevalence of hearing disorders among male, 
people of low education and those who lost husband or wife, as well as workers 
and farmers was relatively higher. Conclusions: The prevalence of hearing 
disorders is high, and hearing disorders are " invisible" . Demographics and 
socioeconomic factors significantly influence the prevalence of hearing 
disorders.

DOI: 10.3760/cma.j.issn.1673-0860.2016.11.004
PMID: 27938607 [Indexed for MEDLINE]


678. Otol Neurotol. 2021 Apr 1;42(4):e438-e444. doi: 10.1097/MAO.0000000000003002.

Robot-assisted Cochlear Implant Electrode Array Insertion in Adults: A 
Comparative Study With Manual Insertion.

Daoudi H(1)(2), Lahlou G(1)(2), Torres R(3)(2), Sterkers O(1)(2), Lefeuvre 
V(1)(2), Ferrary E(1)(2), Mosnier I(1)(2), Nguyen Y(1)(2).

Author information:
(1)Sorbonne University/AP-HP, GHU Pitié-Salpêtrière, DMU ChIR, Department of 
Oto-Rhino-Laryngology, Unit of Audiology, Auditory Implants and skull base 
surgery.
(2)Inserm/Pasteur Institute, Hearing Institute, Technology and Gene therapy for 
Deafness, Paris, France.
(3)Departamento de Ciencias Fisiologicas, Facultad de Medicina, Universidad 
Nacional de San Agustıon de Arequipa, Arequipa, Perou.

OBJECTIVE: To describe the first cochlear array insertions using a 
robot-assisted technique, with different types of straight or precurved 
electrode arrays, compared with arrays manually inserted into the cochlea.
STUDY DESIGN: Retrospective review.
SETTING: Tertiary otologic center.
PATIENTS: Twenty cochlear implantations in the robot-assisted group and 40 in 
the manually inserted group.
INTERVENTIONS: Cochlear implantations using a robot-assisted technique (RobOtol) 
with straight (eight Cochlear CI522/622, and eight Advanced Bionics Hifocus Slim 
J) or precurved (four Advanced Bionics Hifocus Mid-Scala) matched to manual 
cochlear implantations. Three-dimensional reconstruction images of the basilar 
membrane and the electrode array were obtained from pre- and postimplantation 
computed tomography.
MAIN OUTCOME MEASURES: Rate and localization of scalar translocations.
RESULTS: For straight electrode arrays, scalar translocations occurred in 19% 
(3/16) of the robot-assisted group and 31% (10/32) of the manually inserted 
group. Considering the number of translocated electrodes, this was lower in the 
robot-assisted group (7%) than in the manually inserted group (16%) (p < 0.0001, 
χ2 test). For precurved electrode arrays, scalar translocations occurred in 50% 
(2/4) of the robot-assisted group and 38% (3/8) of the manually inserted group.
CONCLUSION: This study showed a safe and reliable insertion of different 
electrode array types with a robot-assisted technique, with a less traumatic 
robotic insertion of straight electrode arrays when compared with manual 
insertion.

Copyright © 2020, Otology & Neurotology, Inc.

DOI: 10.1097/MAO.0000000000003002
PMID: 33306661 [Indexed for MEDLINE]

Conflict of interest statement: The authors disclose no conflicts of interest.


679. Front Neurosci. 2023 Jul 13;17:1183126. doi: 10.3389/fnins.2023.1183126. 
eCollection 2023.

Towards personalized and optimized fitting of cochlear implants.

Van Opstal AJ(1), Noordanus E(1).

Author information:
(1)Donders Centre for Neuroscience, Section Neurophysics, Radboud University, 
Nijmegen, Netherlands.

A cochlear implant (CI) is a neurotechnological device that restores total 
sensorineural hearing loss. It contains a sophisticated speech processor that 
analyzes and transforms the acoustic input. It distributes its time-enveloped 
spectral content to the auditory nerve as electrical pulsed stimulation trains 
of selected frequency channels on a multi-contact electrode that is surgically 
inserted in the cochlear duct. This remarkable brain interface enables the deaf 
to regain hearing and understand speech. However, tuning of the large (>50) 
number of parameters of the speech processor, so-called "device fitting," is a 
tedious and complex process, which is mainly carried out in the clinic through 
'one-size-fits-all' procedures. Current fitting typically relies on limited and 
often subjective data that must be collected in limited time. Despite the 
success of the CI as a hearing-restoration device, variability in 
speech-recognition scores among users is still very large, and mostly 
unexplained. The major factors that underly this variability incorporate three 
levels: (i) variability in auditory-system malfunction of CI-users, (ii) 
variability in the selectivity of electrode-to-auditory nerve (EL-AN) 
activation, and (iii) lack of objective perceptual measures to optimize the 
fitting. We argue that variability in speech recognition can only be alleviated 
by using objective patient-specific data for an individualized fitting 
procedure, which incorporates knowledge from all three levels. In this paper, we 
propose a series of experiments, aimed at collecting a large amount of objective 
(i.e., quantitative, reproducible, and reliable) data that characterize the 
three processing levels of the user's auditory system. Machine-learning 
algorithms that process these data will eventually enable the clinician to 
derive reliable and personalized characteristics of the user's auditory system, 
the quality of EL-AN signal transfer, and predictions of the perceptual effects 
of changes in the current fitting.

Copyright © 2023 Van Opstal and Noordanus.

DOI: 10.3389/fnins.2023.1183126
PMCID: PMC10372492
PMID: 37521701

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


680. Front Cell Neurosci. 2020 Jul 22;14:226. doi: 10.3389/fncel.2020.00226. 
eCollection 2020.

Antioxidants and Vasodilators for the Treatment of Noise-Induced Hearing Loss: 
Are They Really Effective?

Alvarado JC(1), Fuentes-Santamaría V(1), Juiz JM(1)(2).

Author information:
(1)Facultad de Medicina, Instituto de Investigación en Discapacidades, 
Neurológicas (IDINE), Universidad de Castilla-La Mancha, Albacete, Spain.
(2)Department of Otolaryngology, Hannover Medical School, NIFE-VIANNA, Cluster 
of Excellence Hearing4all-German Research Foundation, Hannover, Germany.

We live in a world continuously immersed in noise, an environmental, 
recreational, and occupational factor present in almost every daily human 
activity. Exposure to high-level noise could affect the auditory function of 
individuals at any age, resulting in a condition called noise-induced hearing 
loss (NIHL). Given that by 2018, more than 400 million people worldwide were 
suffering from disabling hearing loss and that about one-third involved noise 
over-exposure, which represents more than 100 million people, this hearing 
impairment represents a serious health problem. As of today, there are no 
therapeutic measures available to treat NIHL. Conventional preventive measures, 
including public awareness and education and physical barriers to noise, do not 
seem to suffice, as the population is still being affected by damaging noise 
levels. Therefore, it is necessary to develop or test pharmacological agents 
that may prevent and/or diminish the impact of noise on hearing. Data 
availability about the pathophysiological processes involved in triggering NIHL 
has allowed researchers to use compounds, that could act as effective therapies, 
by targeting specific mechanisms such as the excess generation of free radicals 
and blood flow restriction to the cochlea. In this review, we summarize the 
advantages/disadvantages of these therapeutic agents, providing a critical view 
of whether they could be effective in the human clinic.

Copyright © 2020 Alvarado, Fuentes-Santamaría and Juiz.

DOI: 10.3389/fncel.2020.00226
PMCID: PMC7387569
PMID: 32792910


681. Nature. 2003 Jun 19;423(6942):866-9. doi: 10.1038/nature01710.

Somatosensory basis of speech production.

Tremblay S(1), Shiller DM, Ostry DJ.

Author information:
(1)Department of Psychology, McGill University, Montreal, Quebec H3A 1B1, 
Canada.

The hypothesis that speech goals are defined acoustically and maintained by 
auditory feedback is a central idea in speech production research. An 
alternative proposal is that speech production is organized in terms of control 
signals that subserve movements and associated vocal-tract configurations. 
Indeed, the capacity for intelligible speech by deaf speakers suggests that 
somatosensory inputs related to movement play a role in speech production-but 
studies that might have documented a somatosensory component have been 
equivocal. For example, mechanical perturbations that have altered somatosensory 
feedback have simultaneously altered acoustics. Hence, any adaptation observed 
under these conditions may have been a consequence of acoustic change. Here we 
show that somatosensory information on its own is fundamental to the achievement 
of speech movements. This demonstration involves a dissociation of somatosensory 
and auditory feedback during speech production. Over time, subjects correct for 
the effects of a complex mechanical load that alters jaw movements (and hence 
somatosensory feedback), but which has no measurable or perceptible effect on 
acoustic output. The findings indicate that the positions of speech articulators 
and associated somatosensory inputs constitute a goal of speech movements that 
is wholly separate from the sounds produced.

DOI: 10.1038/nature01710
PMID: 12815431 [Indexed for MEDLINE]


682. Environ Sci Pollut Res Int. 2022 Nov;29(53):81076-81086. doi: 
10.1007/s11356-022-21459-5. Epub 2022 Jun 22.

The association between hearing threshold and urinary personal care and consumer 
product metabolites in middle-aged and elderly people from the USA.

Fu YP(#)(1), Chen WY(#)(2), Guo LQ(1), Zhu YQ(1), Yuan JS(1), Liu YH(3).

Author information:
(1)Department of Otorhinolaryngology Head and Neck Surgery, Second Affiliated 
Hospital of Nanchang University, No.1 Minde Road, Nanchang, China.
(2)Interventional Cardiology Department, Second Affiliated Hospital of Nanchang 
University, No.1 Minde Road, Nanchang, China.
(3)Department of Otorhinolaryngology Head and Neck Surgery, Second Affiliated 
Hospital of Nanchang University, No.1 Minde Road, Nanchang, China. 
Liuyuehuindefy@21cn.com.
(#)Contributed equally

Endocrine disruptors have been reported to be associated with hearing ability. 
However, the association between personal care and consumer product chemicals, 
known as commonly detected endocrine disruptors, and age-related hearing loss 
still remains unclear. This study aimed to examine the association between 
exposure to 7 personal care and consumer product chemicals and hearing 
thresholds in middle-aged and elderly people. A 
nationally representative cross-sectional study was performed. Eight hundred 
forty-five adults aged over 45 from the National Health and Nutrition 
Examination Survey (NHANES) were included in this study. Bayesian kernel machine 
regression (BKMR) and the k-medoid cluster analysis were used to evaluate the 
mixture effect of exposure to 7 chemicals on pure-tone average (PTA). Exposure 
to these chemicals was negatively associated with PTA. 2,5-Dichlorophenol had 
the greatest contribution to the mixture effect. The mixture effect was stronger 
in women, elderly people. Four pooled clusters were identified according to 7 
chemicals exposures. Cluster 4 (high TCS exposure) showed a lower HFPTA 
(P = 0.00258) than cluster 3 (the lowest exposure cluster, as a reference). Our 
study provides evidence that exposure to personal care and consumer product 
chemicals might be inversely associated with PTA. More studies are needed to 
fully understand the association of exposure to these chemicals with hearing 
threshold.

© 2022. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
part of Springer Nature.

DOI: 10.1007/s11356-022-21459-5
PMID: 35731440 [Indexed for MEDLINE]


683. Front Neurosci. 2022 Apr 1;16:816712. doi: 10.3389/fnins.2022.816712. 
eCollection 2022.

Sensorineural Hearing Loss Affects Functional Connectivity of the Auditory 
Cortex, Parahippocampal Gyrus and Inferior Prefrontal Gyrus in Tinnitus 
Patients.

Chen J(1), Zhao Y(1), Zou T(1), Wen X(1), Zhou X(1), Yu Y(1), Liu Z(1), Li M(1).

Author information:
(1)Department of Otolaryngology, The First People's Hospital of Foshan, Foshan, 
China.

BACKGROUND: Tinnitus can interfere with a patient's speech discrimination, but 
whether tinnitus itself or the accompanying sensorineural hearing loss (SNHL) 
causes this interference is still unclear. We analyzed event-related 
electroencephalograms (EEGs) to observe auditory-related brain function and 
explore the possible effects of SNHL on auditory processing in tinnitus 
patients.
METHODS: Speech discrimination scores (SDSs) were recorded in 21 healthy control 
subjects, 24 tinnitus patients, 24 SNHL patients, and 27 patients with both SNHL 
and tinnitus. EEGs were collected under an oddball paradigm. Then, the mismatch 
negativity (MMN) amplitude and latency, the clustering coefficient and average 
path length of the whole network in the tinnitus and SNHL groups were compared 
with those in the control group. Additionally, we analyzed the intergroup 
differences in functional connectivity among the primary auditory cortex (AC), 
parahippocampal gyrus (PHG), and inferior frontal gyrus (IFG).
RESULTS: SNHL patients with or without tinnitus had lower SDSs than the control 
subjects. Compared with control subjects, tinnitus patients with or without SNHL 
had decreased MMN amplitudes, and SNHL patients had longer MMN latencies. 
Tinnitus patients without SNHL had a smaller clustering coefficient and a longer 
whole-brain average path length than the control subjects. SNHL patients with or 
without tinnitus had a smaller clustering coefficient and a longer average path 
length than patients with tinnitus alone. The connectivity strength from the AC 
to the PHG and IFG was lower on the affected side in tinnitus patients than that 
in control subjects; the connectivity strength from the PHG to the IFG was also 
lower on the affected side in tinnitus patients than that in control subjects. 
However, the connectivity strength from the IFG to the AC was stronger in 
tinnitus patients than that in the control subjects. In SNHL patients with or 
without tinnitus, these changes were magnified.
CONCLUSION: Changes in auditory processing in tinnitus patients do not influence 
SDSs. Instead, SNHL might cause the activity of the AC, PHG and IFG to change, 
resulting in impaired speech recognition in tinnitus patients with SNHL.

Copyright © 2022 Chen, Zhao, Zou, Wen, Zhou, Yu, Liu and Li.

DOI: 10.3389/fnins.2022.816712
PMCID: PMC9011051
PMID: 35431781

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


684. Front Pharmacol. 2021 Nov 23;12:719267. doi: 10.3389/fphar.2021.719267. 
eCollection 2021.

Prediction of the Molecular Mechanisms Underlying Erlong Zuoci Treatment of 
Age-Related Hearing Loss via Network Pharmacology-Based Analyses Combined with 
Experimental Validation.

Liu Q(1), Li N(1), Yang Y(1), Yan X(1), Dong Y(2), Peng Y(2), Shi J(1).

Author information:
(1)School of Basic Medical Sciences, Shanghai University of Traditional Chinese 
Medicine, Shanghai, China.
(2)Experimental Teaching Center, Shanghai University of Traditional Chinese 
Medicine, Shanghai, China.

Background: The traditional Chinese medicine formula ErLong ZuoCi (ELZC) has 
been extensively used to treat age-related hearing loss (ARHL) in clinical 
practice in China for centuries. However, the underlying molecular mechanisms 
are still poorly understood. Objective: Combine network pharmacology with 
experimental validation to explore the potential molecular mechanisms underlying 
ELZC with a systematic viewpoint. Methods: The chemical components of ELZC were 
collected from the Traditional Chinese Medicine System Pharmacology database, 
and their possible target proteins were predicted using the 
SwissTargetPrediction database. The putative ARHL-related target proteins were 
identified from the database: GeneCards and OMIM. We constructed the drug-target 
network as well as drug-disease specific protein-protein interaction networks 
and performed clustering and topological property analyses. Functional 
annotation and signaling pathways were performed by gene ontology and Kyoto 
Encyclopedia of Genes and Genomes enrichment analysis. Finally, in vitro 
experiments were also performed to validate ELZC's key target proteins and 
treatment effects on ARHL. Results: In total, 63 chemical compounds from ELZC 
and 365 putative ARHL-related targets were identified, and 1860 ARHL-related 
targets were collected from the OMIM and GeneCards. A total of 145 shared 
targets of ELZC and ARHL were acquired by Venn diagram analysis. Functional 
enrichment analysis suggested that ELZC might exert its pharmacological effects 
in multiple biological processes, such as cell proliferation, apoptosis, 
inflammatory response, and synaptic connections, and the potential targets might 
be associated with AKT, ERK, and STAT3, as well as other proteins. In vitro 
experiments revealed that ELZC pretreatment could decrease senescence-associated 
β-galactosidase activity in hydrogen peroxide-induced auditory hair cells, 
eliminate DNA damage, and reduce cellular senescence protein p21 and p53. 
Finally, Western blot analysis confirmed that ELZC could upregulate the 
predicted target ERK phosphorylation. Conclusion: We provide an integrative 
network pharmacology approach, in combination with in vitro experiments to 
explore the underlying molecular mechanisms governing ELZC treatment of ARHL. 
The protective effects of ELZC against ARHL were predicted to be associated with 
cellular senescence, inflammatory response, and synaptic connections which might 
be linked to various pathways such as JNK/STAT3 and ERK cascade signaling 
pathways. As a prosperous possibility, our experimental data suggest 
phosphorylation ERK is essential for ELZC to prevent degeneration of cochlear.

Copyright © 2021 Liu, Li, Yang, Yan, Dong, Peng and Shi.

DOI: 10.3389/fphar.2021.719267
PMCID: PMC8650627
PMID: 34887749

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


685. Mol Imaging Biol. 2020 Apr;22(2):335-347. doi: 10.1007/s11307-019-01371-0.

GABA(A) Receptors in the Mongolian Gerbil: a PET Study Using [(18)F]Flumazenil 
to Determine Receptor Binding in Young and Old Animals.

Kessler M(1)(2), Mamach M(3)(4)(5), Beutelmann R(6), Lukacevic M(3), Eilert 
S(3), Bascuñana P(3), Fasel A(7), Bengel FM(3), Bankstahl JP(3), Ross TL(3), 
Klump GM(4)(6), Berding G(3)(4).

Author information:
(1)Department of Nuclear Medicine, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany. Kessler.Mariella@mh-hannover.de.
(2)Cluster of Excellence Hearing4all, Hannover Medical School and University of 
Oldenburg, Hannover, Germany. Kessler.Mariella@mh-hannover.de.
(3)Department of Nuclear Medicine, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625, Hannover, Germany.
(4)Cluster of Excellence Hearing4all, Hannover Medical School and University of 
Oldenburg, Hannover, Germany.
(5)Department of Medical Physics and Radiation Protection, Hannover Medical 
School, Carl-Neuberg-Str. 1, 30625, Hannover, Germany.
(6)Division of Animal Physiology and Behaviour, Department for Neuroscience, 
School of Medicine and Health Sciences, University of Oldenburg, Carl von 
Ossietzky Str. 9-11, 26129, Oldenburg, Germany.
(7)ABX Advanced Biochemical Compounds GmbH, Heinrich-Glaeser-Strasse 10-14, 
01454, Radeberg, Germany.

PURPOSE: Plastic changes in the central auditory system involving the GABAergic 
system accompany age-related hearing loss. Such processes can be investigated 
with positron emission tomography (PET) imaging using [18F]flumazenil 
([18F]FMZ). Here, [18F]FMZ PET-based modeling approaches allow a simple and 
reliable quantification of GABAA receptor binding capacity revealing regional 
differences and age-related changes.
PROCEDURES: Sixty-minute list-mode PET acquisitions were performed in 9 young 
(range 5-6 months) and 11 old (range 39-42 months) gerbils, starting 
simultaneously with the injection of [18F]FMZ via femoral vein. Non-displaceable 
binding potentials (BPnd) with pons as reference region were calculated for 
auditory cortex (AC), inferior colliculus (IC), medial geniculate body (MGB), 
somatosensory cortex (SC), and cerebellum (CB) using (i) a two-tissue 
compartment model (2TCM), (ii) the Logan plot with image-derived blood-input 
(Logan (BI)), (iii) a simplified reference tissue model (SRTM), and (iv) the 
Logan reference model (Logan (RT)). Statistical parametric mapping analysis 
(SPM) comparing young and old gerbils was performed using 3D parametric images 
for BPnd based on SRTM. Results were verified with in vitro autoradiography from 
five additional young gerbils. Model assessment included the Akaike information 
criterion (AIC). Hearing was evaluated using auditory brainstem responses.
RESULTS: BPnd differed significantly between models (p < 0.0005), showing the 
smallest mean difference between 2TCM as reference and SRTM as simplified 
procedure. SRTM revealed the lowest AIC values. Both volume of distribution 
(r2 = 0.8793, p = 0.018) and BPnd (r2 = 0.8216, p = 0.034) correlated with in 
vitro autoradiography data. A significant age-related decrease of receptor 
binding was observed in auditory (AC, IC, MGB) and other brain regions (SC and 
CB) (p < 0.0001, unpaired t test) being confirmed by SPM using pons as reference 
(p < 0.0001, uncorrected).
CONCLUSION: Imaging of GABAA receptor binding capacity in gerbils using [18F]FMZ 
PET revealed SRTM as a simple and robust quantification method of GABAA 
receptors. Comparison of BPnd in young and old gerbils demonstrated an 
age-related decrease of GABAA receptor binding.

DOI: 10.1007/s11307-019-01371-0
PMID: 31102039 [Indexed for MEDLINE]


686. Antioxidants (Basel). 2020 Nov 25;9(12):1177. doi: 10.3390/antiox9121177.

Oral Antioxidant Vitamins and Magnesium Limit Noise-Induced Hearing Loss by 
Promoting Sensory Hair Cell Survival: Role of Antioxidant Enzymes and Apoptosis 
Genes.

Alvarado JC(1), Fuentes-Santamaría V(1), Melgar-Rojas P(1), Gabaldón-Ull MC(1), 
Cabanes-Sanchis JJ(1), Juiz JM(1)(2).

Author information:
(1)Instituto de Investigación en Discapacidades Neurológicas (IDINE), School of 
Medicine, Universidad de Castilla-La Mancha, 02008 Albacete, Spain.
(2)Department of Otolaryngology, Hannover Medical School, NIFE-VIANNA, Cluster 
of Excellence Hearing4all-German Research Foundation, 30625 Hannover, Germany.

Noise induces oxidative stress in the cochlea followed by sensory cell death and 
hearing loss. The proof of principle that injections of antioxidant vitamins and 
Mg2+ prevent noise-induced hearing loss (NIHL) has been established. However, 
effectiveness of oral administration remains controversial and otoprotection 
mechanisms are unclear. Using auditory evoked potentials, quantitative PCR, and 
immunocytochemistry, we explored effects of oral administration of vitamins A, 
C, E, and Mg2+ (ACEMg) on auditory function and sensory cell survival following 
NIHL in rats. Oral ACEMg reduced auditory thresholds shifts after NIHL. Improved 
auditory function correlated with increased survival of sensory outer hair 
cells. In parallel, oral ACEMg modulated the expression timeline of antioxidant 
enzymes in the cochlea after NIHL. There was increased expression of glutathione 
peroxidase-1 and catalase at 1 and 10 days, respectively. Also, pro-apoptotic 
caspase-3 and Bax levels were diminished in ACEMg-treated rats, at 10 and 30 
days, respectively, following noise overstimulation, whereas, at day 10 after 
noise exposure, the levels of anti-apoptotic Bcl-2, were significantly 
increased. Therefore, oral ACEMg improves auditory function by limiting sensory 
hair cell death in the auditory receptor following NIHL. Regulation of the 
expression of antioxidant enzymes and apoptosis-related proteins in cochlear 
structures is involved in such an otoprotective mechanism.

DOI: 10.3390/antiox9121177
PMCID: PMC7761130
PMID: 33255728

Conflict of interest statement: J.C.A., V.F.-S., and J.M.J. are co-inventors of 
the US Patents 9,889,156, “Method for treating noise-induced hearing loss 
(NIHL)” and 9,919,008, “Methods for treating age-related hearing loss (ARHL)”. 
Both patents are based on the use of oral ACEMg, but currently, they are not 
involved in any trials testing this compound or any other commercial 
exploitation. The authors have no other relevant affiliations or financial 
involvement with any organization or entity with a financial interest in or 
financial conflict with the subject matter or materials discussed in the paper 
apart from those disclosed. The funders had no role in the design of the study; 
in the collection, analyses, or interpretation of data; in the writing of the 
manuscript, or in the decision to publish the results.


687. Front Neurosci. 2021 Jul 12;15:666651. doi: 10.3389/fnins.2021.666651. 
eCollection 2021.

Disrupted Topological Organization in White Matter Networks in Unilateral Sudden 
Sensorineural Hearing Loss.

Zou Y(1)(2), Ma H(1)(2), Liu B(3), Li D(3), Liu D(1)(2), Wang X(4), Wang 
S(1)(2), Fan W(1)(2), Han P(1)(2).

Author information:
(1)Department of Radiology, Union Hospital, Tongji Medical College, Huazhong 
University of Science and Technology, Wuhan, China.
(2)Hubei Key Laboratory of Molecular Imaging, Union Hospital, Tongji Medical 
College, Huazhong University of Science and Technology, Wuhan, China.
(3)Department of Otorhinolaryngology, Union Hospital, Tongji Medical College, 
Huazhong University of Science and Technology, Wuhan, China.
(4)GE Healthcare, Shanghai, China.

Sudden sensorineural hearing loss (SSNHL) is a sudden-onset hearing impairment 
that rapidly develops within 72 h and is mostly unilateral. Only a few patients 
can be identified with a defined cause by routine clinical examinations. 
Recently, some studies have shown that unilateral SSNHL is associated with 
alterations in the central nervous system. However, little is known about the 
topological organization of white matter (WM) networks in unilateral SSNHL 
patients in the acute phase. In this study, 145 patients with SSNHL and 91 age-, 
gender-, and education-matched healthy controls were evaluated using diffusion 
tensor imaging (DTI) and graph theoretical approaches. The topological 
properties of WM networks, including global and nodal parameters, were 
investigated. At the global level, SSNHL patients displayed decreased clustering 
coefficient, local efficiency, global efficiency, normalized clustering 
coefficient, normalized characteristic path length, and small-worldness and 
increased characteristic path length (p < 0.05) compared with healthy controls. 
At the nodal level, altered nodal centralities in brain regions involved the 
auditory network, visual network, attention network, default mode network (DMN), 
sensorimotor network, and subcortical network (p < 0.05, Bonferroni corrected). 
These findings indicate a shift of the WM network topology in SSNHL patients 
toward randomization, which is characterized by decreased global network 
integration and segregation and is reflected by decreased global connectivity 
and altered nodal centralities. This study could help us understand the 
potential pathophysiology of unilateral SSNHL.

Copyright © 2021 Zou, Ma, Liu, Li, Liu, Wang, Wang, Fan and Han.

DOI: 10.3389/fnins.2021.666651
PMCID: PMC8312563
PMID: 34321993

Conflict of interest statement: XW was employed by company GE Healthcare, 
Shanghai. The remaining authors declare that the research was conducted in the 
absence of any commercial or financial relationships that could be construed as 
a potential conflict of interest.


688. Int J Mol Sci. 2024 Feb 27;25(5):2738. doi: 10.3390/ijms25052738.

Cochlear Ribbon Synapses in Aged Gerbils.

Bovee S(1), Klump GM(1)(2)(3), Pyott SJ(4), Sielaff C(1)(5), Köppl C(1)(2)(3).

Author information:
(1)Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky Universität Oldenburg, 26129 Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4all", Carl von Ossietzky Universität 
Oldenburg, 26129 Oldenburg, Germany.
(3)Research Centre Neurosensory Science, Carl von Ossietzky Universität 
Oldenburg, 26129 Oldenburg, Germany.
(4)Department of Otorhinolaryngology/Head and Neck Surgery, University Medical 
Center Groningen, University of Groningen, P.O. Box 30.001, 9700 RB Groningen, 
The Netherlands.
(5)Fraunhofer Institute for Toxicology and Experimental Medicine (ITEM), 30625 
Hannover, Germany.

In mammalian hearing, type-I afferent auditory nerve fibers comprise the basis 
of the afferent auditory pathway. They are connected to inner hair cells of the 
cochlea via specialized ribbon synapses. Auditory nerve fibers of different 
physiological types differ subtly in their synaptic location and morphology. 
Low-spontaneous-rate auditory nerve fibers typically connect on the modiolar 
side of the inner hair cell, while high-spontaneous-rate fibers are typically 
found on the pillar side. In aging and noise-damaged ears, this fine-tuned 
balance between auditory nerve fiber populations can be disrupted and the 
functional consequences are currently unclear. Here, using immunofluorescent 
labeling of presynaptic ribbons and postsynaptic glutamate receptor patches, we 
investigated changes in synaptic morphology at three different tonotopic 
locations along the cochlea of aging gerbils compared to those of young adults. 
Quiet-aged gerbils showed about 20% loss of afferent ribbon synapses. While the 
loss was random at apical, low-frequency cochlear locations, at the basal, 
high-frequency location it almost exclusively affected the modiolar-located 
synapses. The subtle differences in volumes of pre- and postsynaptic elements 
located on the inner hair cell's modiolar versus pillar side were unaffected by 
age. This is consistent with known physiology and suggests a predominant, 
age-related loss in the low-spontaneous-rate auditory nerve population in the 
cochlear base, but not the apex.

DOI: 10.3390/ijms25052738
PMCID: PMC10931817
PMID: 38473985 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflicts of interest. 
The funders had no role in the design of the study; in the collection, analyses, 
or interpretation of data; in the writing of the manuscript; or in the decision 
to publish the results.


689. J Neurosci. 2005 Jul 20;25(29):6857-68. doi: 10.1523/JNEUROSCI.0123-05.2005.

Where is the spike generator of the cochlear nerve? Voltage-gated sodium 
channels in the mouse cochlea.

Hossain WA(1), Antic SD, Yang Y, Rasband MN, Morest DK.

Author information:
(1)Department of Neuroscience, University of Connecticut Health Center, 
Farmington, Connecticut 06030, USA. whossain@neuron.uchc.edu

The origin of the action potential in the cochlea has been a long-standing 
puzzle. Because voltage-dependent Na+ (Nav) channels are essential for action 
potential generation, we investigated the detailed distribution of Nav1.6 and 
Nav1.2 in the cochlear ganglion, cochlear nerve, and organ of Corti, including 
the type I and type II ganglion cells. In most type I ganglion cells, Nav1.6 was 
present at the first nodes flanking the myelinated bipolar cell body and at 
subsequent nodes of Ranvier. In the other ganglion cells, including type II, 
Nav1.6 clustered in the initial segments of both of the axons that flank the 
unmyelinated bipolar ganglion cell bodies. In the organ of Corti, Nav1.6 was 
localized in the short segments of the afferent axons and their sensory endings 
beneath each inner hair cell. Surprisingly, the outer spiral fibers and their 
sensory endings were well labeled beneath the outer hair cells over their entire 
trajectory. In contrast, Nav1.2 in the organ of Corti was localized to the 
unmyelinated efferent axons and their endings on the inner and outer hair cells. 
We present a computational model illustrating the potential role of the Nav 
channel distribution described here. In the deaf mutant quivering mouse, the 
localization of Nav1.6 was disrupted in the sensory epithelium and ganglion. 
Together, these results suggest that distinct Nav channels generate and 
regenerate action potentials at multiple sites along the cochlear ganglion cells 
and nerve fibers, including the afferent endings, ganglionic initial segments, 
and nodes of Ranvier.

DOI: 10.1523/JNEUROSCI.0123-05.2005
PMCID: PMC1378182
PMID: 16033895 [Indexed for MEDLINE]


690. J Acoust Soc Am. 2017 Feb;141(2):EL159. doi: 10.1121/1.4976327.

Characterizing the binaural contribution to speech-in-noise reception in elderly 
hearing-impaired listeners.

Neher T(1).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all," Oldenburg 
University, Oldenburg, Germany tobias.neher@uni-oldenburg.de.

To scrutinize the binaural contribution to speech-in-noise reception, four 
groups of elderly participants with or without audiometric asymmetry <2 kHz and 
with or without near-normal binaural intelligibility level difference (BILD) 
completed tests of monaural and binaural phase sensitivity as well as cognitive 
function. Groups did not differ in age, overall degree of hearing loss, or 
cognitive function. Analyses revealed an influence of BILD status but not 
audiometric asymmetry on monaural phase sensitivity, strong correlations between 
monaural and binaural detection thresholds, and monaural and binaural but not 
cognitive BILD contributions. Furthermore, the N0Sπ threshold at 500 Hz 
predicted BILD performance effectively.

DOI: 10.1121/1.4976327
PMID: 28253695


691. J Neurophysiol. 2023 Sep 1;130(3):736-750. doi: 10.1152/jn.00090.2023. Epub 2023 
Aug 16.

Cochlear aging disrupts the correlation between spontaneous rate- and 
sound-level coding in auditory nerve fibers.

Heeringa AN(1)(2), Teske F(2), Ashida G(1)(2), Köppl C(1)(2).

Author information:
(1)Cluster of Excellence "Hearing4all," Department of Neuroscience, School of 
Medicine and Health Science, Carl von Ossietzky University Oldenburg, Oldenburg, 
Germany.
(2)Research Centre Neurosensory Science, Department of Neuroscience, School of 
Medicine and Health Science, Carl von Ossietzky University Oldenburg, Oldenburg, 
Germany.

The spiking activity of auditory nerve fibers (ANFs) transmits information about 
the acoustic environment from the cochlea to the central auditory system. 
Increasing age leads to degeneration of cochlear tissues, including the sensory 
hair cells and stria vascularis. Here, we aim to identify the functional effects 
of such age-related cochlear pathologies of ANFs. Rate-level functions (RLFs) 
were recorded from single-unit ANFs of young adult (n = 52, 3-12 months) and 
quiet-aged (n = 24, >36 months) Mongolian gerbils of either sex. RLFs were used 
to determine sensitivity and spontaneous rates (SRs) and were classified into 
flat-saturating, sloping-saturating, and straight categories, as previously 
established. A physiologically based cochlear model, adapted for the gerbil, was 
used to simulate the effects of cochlear degeneration on ANF physiology. In ANFs 
tuned to low frequencies (<3.5 kHz), SR was lower in those of aged gerbils, 
while an age-related loss of low-SR fibers was evident in ANFs tuned to high 
frequencies. These changes in SR distribution did not affect the typical SR 
versus sensitivity correlation. The distribution of RLF types among low-SR 
fibers, however, shifted toward that of high-SR fibers, specifically showing 
more fast-saturating and fewer sloping-saturating RLFs. A modeled striatal 
degeneration, which affects the combined inner hair cell and synaptic output, 
reduced SR but left RLF type unchanged. An additional reduced basilar membrane 
gain, which decreased sensitivity, explained the changed RLF types. Overall, the 
data indicated age-related changes in the characteristics of single ANFs that 
blurred the established relationships between SR and RLF types.NEW & NOTEWORTHY 
Auditory nerve fibers, which connect the cochlea to the central auditory system, 
change their encoding of sound level in aged gerbils. In addition to a general 
shift to higher levels, indicative of decreased sensitivity, level coding was 
also differentially affected in fibers with low- and high-spontaneous rates. 
Loss of low-spontaneous rate fibers, combined with a general decrease of 
spontaneous rate, further blurs the categorization of auditory nerve fiber types 
in the aged gerbil.

DOI: 10.1152/jn.00090.2023
PMID: 37584075 [Indexed for MEDLINE]


692. Polymers (Basel). 2022 Apr 26;14(9):1766. doi: 10.3390/polym14091766.

Medical-Grade Silicone Rubber-Hydrogel-Composites for Modiolar Hugging Cochlear 
Implants.

Yilmaz-Bayraktar S(1)(2), Foremny K(1)(2), Kreienmeyer M(1)(2), Warnecke 
A(1)(2), Doll T(1)(2)(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Straße 1, 
30625 Hannover, Germany.
(2)Cluster of Excellence Hearing4All, Carl-Neuberg-Straße 1, 30625 Hannover, 
Germany.
(3)Fraunhofer Institute for Toxicology and Experimental Medicine (ITEM), 
Nikolai-Fuchs-Straße 1, 30625 Hannover, Germany.

The gold standard for the partial restoration of sensorineural hearing loss is 
cochlear implant surgery, which restores patients' speech comprehension. The 
remaining limitations, e.g., music perception, are partly due to a gap between 
cochlear implant electrodes and the auditory nerve cells in the modiolus of the 
inner ear. Reducing this gap will most likely lead to improved cochlear implant 
performance. To achieve this, a bending or curling mechanism in the electrode 
array is discussed. We propose a silicone rubber-hydrogel actuator where the 
hydrogel forms a percolating network in the dorsal silicone rubber compartment 
of the electrode array to exert bending forces at low volume swelling ratios. A 
material study of suitable polymers (medical-grade PDMS and hydrogels), 
including parametrized bending curvature measurements, is presented. The 
curvature radii measured meet the anatomical needs for positioning electrodes 
very closely to the modiolus. Besides stage-one biocompatibility according to 
ISO 10993-5, we also developed and validated a simplified mathematical model for 
designing hydrogel-actuated CI with modiolar hugging functionality.

DOI: 10.3390/polym14091766
PMCID: PMC9103165
PMID: 35566935

Conflict of interest statement: The authors declare no conflict of interest.


693. J Acoust Soc Am. 2017 Feb;141(2):971. doi: 10.1121/1.4976080.

Sensorineural hearing loss enhances auditory sensitivity and temporal 
integration for amplitude modulation.

Wallaert N(1), Moore BC(2), Ewert SD(3), Lorenzi C(1).

Author information:
(1)UMR CNRS LSP 8248, Institut d'Etude de la Cognition, Ecole normale 
supérieure, Paris Sciences et Lettres Research University, 29 rue d'Ulm, 75005 
Paris, France.
(2)Department of Experimental Psychology, University of Cambridge, Downing 
Street, Cambridge CB2 3EB, United Kingdom.
(3)Medizinische Physik and Cluster of Excellence Hearing4All, Universität 
Oldenburg, 26111 Oldenburg, Germany.

Amplitude-modulation detection thresholds (AMDTs) were measured at 40 dB 
sensation level for listeners with mild-to-moderate sensorineural hearing loss 
(age: 50-64 yr) for a carrier frequency of 500 Hz and rates of 2 and 20 Hz. The 
number of modulation cycles, N, varied between two and nine. The data were 
compared with AMDTs measured for young and older normal-hearing listeners 
[Wallaert, Moore, and Lorenzi (2016). J. Acoust. Soc. Am. 139, 3088-3096]. As 
for normal-hearing listeners, AMDTs were lower for the 2-Hz than for the 20-Hz 
rate, and AMDTs decreased with increasing N. AMDTs were lower for 
hearing-impaired listeners than for normal-hearing listeners, and the effect of 
increasing N was greater for hearing-impaired listeners. A computational model 
based on the modulation-filterbank concept and a template-matching decision 
strategy was developed to account for the data. The psychophysical and 
simulation data suggest that the loss of amplitude compression in the impaired 
cochlea is mainly responsible for the enhanced sensitivity and temporal 
integration of temporal envelope cues found for hearing-impaired listeners. The 
data also suggest that, for AM detection, cochlear damage is associated with 
increased internal noise, but preserved short-term memory and decision 
mechanisms.

DOI: 10.1121/1.4976080
PMID: 28253641


694. Front Psychol. 2018 May 11;9:678. doi: 10.3389/fpsyg.2018.00678. eCollection 
2018.

Exploring the Link Between Cognitive Abilities and Speech Recognition in the 
Elderly Under Different Listening Conditions.

Nuesse T(1)(2), Steenken R(1)(2), Neher T(2)(3)(4), Holube I(1)(2).

Author information:
(1)Institute of Hearing Technology and Audiology, Jade University of Applied 
Sciences, Oldenburg, Germany.
(2)Cluster of Excellence "Hearing4All", Oldenburg, Germany.
(3)Medizinische Physik, Oldenburg University, Oldenburg, Germany.
(4)Faculty of Health Sciences, Institute of Clinical Research, University of 
Southern Denmark, Odense, Denmark.

Elderly listeners are known to differ considerably in their ability to 
understand speech in noise. Several studies have addressed the underlying 
factors that contribute to these differences. These factors include audibility, 
and age-related changes in supra-threshold auditory processing abilities, and it 
has been suggested that differences in cognitive abilities may also be 
important. The objective of this study was to investigate associations between 
performance in cognitive tasks and speech recognition under different listening 
conditions in older adults with either age appropriate hearing or 
hearing-impairment. To that end, speech recognition threshold (SRT) measurements 
were performed under several masking conditions that varied along the perceptual 
dimensions of dip listening, spatial separation, and informational masking. In 
addition, a neuropsychological test battery was administered, which included 
measures of verbal working and short-term memory, executive functioning, 
selective and divided attention, and lexical and semantic abilities. Age-matched 
groups of older adults with either age-appropriate hearing (ENH, n = 20) or 
aided hearing impairment (EHI, n = 21) participated. In repeated linear 
regression analyses, composite scores of cognitive test outcomes (evaluated 
using PCA) were included to predict SRTs. These associations were different for 
the two groups. When hearing thresholds were controlled for, composed cognitive 
factors were significantly associated with the SRTs for the ENH listeners. 
Whereas better lexical and semantic abilities were associated with lower 
(better) SRTs in this group, there was a negative association between 
attentional abilities and speech recognition in the presence of spatially 
separated speech-like maskers. For the EHI group, the pure-tone thresholds 
(averaged across 0.5, 1, 2, and 4 kHz) were significantly associated with the 
SRTs, despite the fact that all signals were amplified and therefore in 
principle audible.

DOI: 10.3389/fpsyg.2018.00678
PMCID: PMC5968383
PMID: 29867654


695. Int J Audiol. 2023 Nov 27:1-10. doi: 10.1080/14992027.2023.2284675. Online ahead 
of print.

Does experience with hearing aid amplification influence electrophysiological 
measures of speech comprehension?

Deshpande P(1)(2), Brandt C(1)(2), Debener S(3)(4)(5), Neher T(1)(2).

Author information:
(1)Institute of Clinical Research, University of Southern Denmark, Odense, 
Denmark.
(2)Research Unit for ORL - Head & Neck Surgery and Audiology, Odense University 
Hospital & University of Southern Denmark, Odense, Denmark.
(3)Neuropsychology Lab, Department of Psychology, University of Oldenburg, 
Germany.
(4)Cluster of Excellence Hearing4all, University of Oldenburg, Oldenburg, 
Germany.
(5)Branch for Hearing, Speech and Audio Technology HSA, Fraunhofer Institute for 
Digital Media Technology IDMT, Oldenburg, Germany.

OBJECTIVE: To explore if experience with hearing aid (HA) amplification affects 
speech-evoked cortical potentials reflecting comprehension abilities.
DESIGN: N400 and late positive complex (LPC) responses as well as behavioural 
response times to congruent and incongruent digit triplets were measured. The 
digits were presented against stationary speech-shaped noise 10 dB above 
individually measured speech recognition thresholds. Stimulus presentation was 
either acoustic (digits 1-3) or first visual (digits 1-2) and then acoustic 
(digit 3).
STUDY SAMPLE: Three groups of older participants (N = 3 × 15) with (1) pure-tone 
average hearing thresholds <25 dB HL from 500-4000 Hz, (2) mild-to-moderate 
sensorineural hearing loss (SNHL) but no prior HA experience, and (3) 
mild-to-moderate SNHL and >2 years of HA experience. Groups 2-3 were fitted with 
test devices in accordance with clinical gain targets.
RESULTS: No group differences were found in the electrophysiological data. N400 
amplitudes were larger and LPC latencies shorter with acoustic presentation. For 
group 1, behavioural response times were shorter with visual-then-acoustic 
presentation.
CONCLUSION: When speech audibility is ensured, comprehension-related 
electrophysiological responses appear intact in individuals with 
mild-to-moderate SNHL, regardless of prior experience with amplified sound. 
Further research into the effects of audibility versus acclimatisation-related 
neurophysiological changes is warranted.

DOI: 10.1080/14992027.2023.2284675
PMID: 38010629


696. J Assoc Res Otolaryngol. 2010 Sep;11(3):407-18. doi: 10.1007/s10162-010-0211-x. 
Epub 2010 Apr 13.

CD44 is a marker for the outer pillar cells in the early postnatal mouse inner 
ear.

Hertzano R(1), Puligilla C, Chan SL, Timothy C, Depireux DA, Ahmed Z, Wolf J, 
Eisenman DJ, Friedman TB, Riazuddin S, Kelley MW, Strome SE.

Author information:
(1)Department of Otorhinolaryngology-Head and Neck Surgery, University of 
Maryland, 16 South Eutaw Street, Baltimore, MD 21201, USA. 
rhertzano@smail.umaryland.edu

Cluster of differentiation antigens (CD proteins) are classically used as immune 
cell markers. However, their expression within the inner ear is still largely 
undefined. In this study, we explored the possibility that specific CD proteins 
might be useful for defining inner ear cell populations. mRNA expression 
profiling of microdissected auditory and vestibular sensory epithelia revealed 
107 CD genes as expressed in the early postnatal mouse inner ear. The expression 
of 68 CD genes was validated with real-time RT-PCR using RNA extracted from 
microdissected sensory epithelia of cochleae, utricles, saccules, and cristae of 
newborn mice. Specifically, CD44 was identified as preferentially expressed in 
the auditory sensory epithelium. Immunohistochemistry revealed that within the 
early postnatal organ of Corti, the expression of CD44 is restricted to outer 
pillar cells. In order to confirm and expand this finding, we characterized the 
expression of CD44 in two different strains of mice with loss- and 
gain-of-function mutations in Fgfr3 which encodes a receptor for FGF8 that is 
essential for pillar cell development. We found that the expression of CD44 is 
abolished from the immature pillar cells in homozygous Fgfr3 knockout mice. In 
contrast, both the outer pillar cells and the aberrant Deiters' cells in the 
Fgfr3 ( P244R/ ) (+) mice express CD44. The deafness phenotype segregating in 
DFNB51 families maps to a linkage interval that includes CD44. To study the 
potential role of CD44 in hearing, we characterized the auditory system of CD44 
knockout mice and sequenced the entire open reading frame of CD44 of affected 
members of DFNB51 families. Our results suggest that CD44 does not underlie the 
deafness phenotype of the DFNB51 families. Finally, our study reveals multiple 
potential new cell type-specific markers in the mouse inner ear and identifies a 
new marker for outer pillar cells.

DOI: 10.1007/s10162-010-0211-x
PMCID: PMC2914240
PMID: 20386946 [Indexed for MEDLINE]


697. Front Neurosci. 2023 Oct 6;17:1293552. doi: 10.3389/fnins.2023.1293552. 
eCollection 2023.

Editorial: Auditory perception and phantom perception in brains, minds and 
machines.

Schilling A(1)(2), Schaette R(3), Sedley W(4), Gerum RC(5), Maier A(6), Krauss 
P(1)(2).

Author information:
(1)Neuroscience Lab, University Hospital Erlangen, Erlangen, Germany.
(2)Cognitive Computational Neuroscience Group, University Erlangen-Nürnberg, 
Erlangen, Germany.
(3)UCL Ear Institute, University College London, London, United Kingdom.
(4)Faculty of Medical Sciences, Newcastle University, Newcastle upon Tyne, 
United Kingdom.
(5)Department of Physics and Astronomy, York University, Toronto, ON, Canada.
(6)Pattern Recognition Lab, University Erlangen-Nürnberg, Erlangen, Germany.

Comment on
    Editorial on the Research Topic Auditory perception and phantom perception 
in brains, minds and machines.

DOI: 10.3389/fnins.2023.1293552
PMCID: PMC10588478
PMID: 37869508

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest. The author(s) declared that 
they were an editorial board member of Frontiers, at the time of submission. 
This had no impact on the peer review process and the final decision.


698. Clin Exp Otorhinolaryngol. 2016 Sep;9(3):212-9. doi: 10.21053/ceo.2015.01368. 
Epub 2016 Jul 2.

Disability of Hearing Impairment Is Positively Associated With Urine 
Albumin/Creatinine Ratio in Korean Adults: The 2011-2012 Korea National Health 
and Nutrition Examination Survey.

Kim YS(1), Lee DH(1), Chae HS(1), Lee TK(1), Sohn TS(1), Jeong SC(1), Kim HY(1), 
Lee JI(1), Song JY(1), Yeo CD(1), Lee YB(1), Ahn HS(1), Hong M(1), Han K(2).

Author information:
(1)Epidemiology Study Cluster of Uijeongbu St. Mary's Hospital, Uijeongbu St. 
Mary's Hospital, College of Medicine, The Catholic University of Korea, 
Uijeongbu, Korea.
(2)Department of Biostatistics, College of Medicine, The Catholic University of 
Korea, Seoul, Korea.

OBJECTIVES: The aim of this study was to determine whether chronic kidney 
disease (CKD) is associated with hearing thresholds in the nationwide, 
large-scaled Korean population.
METHODS: This study analyzed the data of 9,798 subjects of 19 years and older 
(4,387 males and 5,411 females). Urine albumin-to-creatinine ratio (ACR) was 
measured from first-voided spot urine samples. The air-conduction hearing 
threshold was measured at 0.5, 1, 2, 3, 4, and 6 kHz and pure tone audiogram 
(PTA) average was calculated as the four-frequency average of 0.5, 1, 2, and 4 
kHz.
RESULTS: Urine ACR was significantly correlated with the PTA average of better 
ear in both genders, especially at 3 and 6 kHz in males and at 1, 3, 4, and 6 
kHz in females. After adjusting, urine ACR also increased the risk of hearing 
loss in female, especially if urine ACR was 30 mg/g and more (odds ratio, 
1.636-2.229. This study showed that the degree of hearing loss was significantly 
different according to categories of urine ACR in both genders. Hearing loss 
without disability was found less but that with bilateral hearing disability was 
found more as urine ACR increased. In generally, prevalence of hearing loss with 
disability was higher in males than females.
CONCLUSION: This study demonstrated that urine ACR was significantly correlated 
with the PTA average of better ear in Korean adults of both genders. This study 
suggests that clinicians should carefully monitor the hearing level for subjects 
with elevated urine ACR, even though high urine ACR within the normal range.

DOI: 10.21053/ceo.2015.01368
PMCID: PMC4996098
PMID: 27416740

Conflict of interest statement: No potential conflict of interest relevant to 
this article was reported.


699. J Cell Biol. 2014 Nov 10;207(3):375-91. doi: 10.1083/jcb.201404016. Epub 2014 
Nov 3.

Clarin-1 acts as a modulator of mechanotransduction activity and presynaptic 
ribbon assembly.

Ogun O(1), Zallocchi M(2).

Author information:
(1)Sensory Neuroscience Department, Boys Town National Research Hospital, Omaha, 
NE 68131.
(2)Sensory Neuroscience Department, Boys Town National Research Hospital, Omaha, 
NE 68131 marisa.zallocchi@boystown.org.

Clarin-1 is a four-transmembrane protein expressed by hair cells and 
photoreceptors. Mutations in its corresponding gene are associated with Usher 
syndrome type 3, characterized by late-onset and progressive hearing and vision 
loss in humans. Mice carrying mutations in the clarin-1 gene have hair bundle 
dysmorphology and a delay in synapse maturation. In this paper, we examined the 
expression and function of clarin-1 in zebrafish hair cells. We observed protein 
expression as early as 1 d postfertilization. Knockdown of clarin-1 resulted in 
inhibition of FM1-43 incorporation, shortening of the kinocilia, and 
mislocalization of ribeye b clusters. These phenotypes were fully prevented by 
co-injection with clarin-1 transcript, requiring its C-terminal tail. We also 
observed an in vivo interaction between clarin-1 and Pcdh15a. Altogether, our 
results suggest that clarin-1 is functionally important for mechanotransduction 
channel activity and for proper localization of synaptic components, 
establishing a critical role for clarin-1 at the apical and basal poles of hair 
cells.

© 2014 Ogun and Zallocchi.

DOI: 10.1083/jcb.201404016
PMCID: PMC4226736
PMID: 25365995 [Indexed for MEDLINE]


700. Front Neurol. 2021 Mar 3;12:627294. doi: 10.3389/fneur.2021.627294. eCollection 
2021.

Applications of Multivariate Statistical and Data Mining Analyses to the Search 
for Biomarkers of Sensorineural Hearing Loss, Tinnitus, and Vestibular 
Dysfunction.

Smith PF(1)(2)(3), Zheng Y(1)(2)(3).

Author information:
(1)Department of Pharmacology and Toxicology, Brain Health Research Centre, 
School of Biomedical Sciences, University of Otago, Dunedin, New Zealand.
(2)Brain Research New Zealand Centre of Research Excellence, University of 
Auckland, Auckland, New Zealand.
(3)The Eisdell Moore Centre for Hearing and Balance Research, University of 
Auckland, Auckland, New Zealand.

Disorders of sensory systems, as with most disorders of the nervous system, 
usually involve the interaction of multiple variables to cause some change, and 
yet often basic sensory neuroscience data are analyzed using univariate 
statistical analyses only. The exclusive use of univariate statistical 
procedures, analyzing one variable at a time, may limit the potential of studies 
to determine how interactions between variables may, as a network, determine a 
particular result. The use of multivariate statistical and data mining methods 
provides the opportunity to analyse many variables together, in order to 
appreciate how they may function as a system of interacting variables, and how 
this system or network may change as a result of sensory disorders such as 
sensorineural hearing loss, tinnitus or different types of vestibular 
dysfunction. Here we provide an overview of the potential applications of 
multivariate statistical and data mining techniques, such as principal component 
and factor analysis, cluster analysis, multiple linear regression, random forest 
regression, linear discriminant analysis, support vector machines, random forest 
classification, Bayesian classification, and orthogonal partial least squares 
discriminant analysis, to the study of auditory and vestibular dysfunction, with 
an emphasis on classification analytic methods that may be used in the search 
for biomarkers of disease.

Copyright © 2021 Smith and Zheng.

DOI: 10.3389/fneur.2021.627294
PMCID: PMC7966509
PMID: 33746881

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


701. iScience. 2023 Aug 25;26(10):107725. doi: 10.1016/j.isci.2023.107725. 
eCollection 2023 Oct 20.

En route to sound coding strategies for optical cochlear implants.

Khurana L(1)(2)(3)(4)(5)(6), Harczos T(1)(2), Moser T(1)(2)(3)(6)(7), Jablonski 
L(1)(2)(4)(6).

Author information:
(1)Institute for Auditory Neuroscience, University Medical Center Göttingen, 
Göttingen, Germany.
(2)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(3)Auditory Neuroscience and Synaptic Nanophysiology Group, Max-Planck-Institute 
for Multidisciplinary Sciences, Göttingen, Germany.
(4)Junior Research Group "Computational Neuroscience and Neuroengineering", 
Göttingen, Germany.
(5)The Doctoral Program "Sensory and Motor Neuroscience", Göttingen Graduate 
Center for Neurosciences, Biophysics, and Molecular Biosciences (GGNB), 
Göttingen, Germany.
(6)InnerEarLab, University Medical Center Göttingen, Göttingen, Germany.
(7)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, Göttingen, 
Germany.

Hearing loss is the most common human sensory deficit. Severe-to-complete 
sensorineural hearing loss is often treated by electrical cochlear implants 
(eCIs) bypassing dysfunctional or lost hair cells by direct stimulation of the 
auditory nerve. The wide current spread from each intracochlear electrode array 
contact activates large sets of tonotopically organized neurons limiting 
spectral selectivity of sound coding. Despite many efforts, an increase in the 
number of independent eCI stimulation channels seems impossible to achieve. 
Light, which can be better confined in space than electric current may help 
optical cochlear implants (oCIs) to overcome eCI shortcomings. In this review, 
we present the current state of the optogenetic sound encoding. We highlight 
optical sound coding strategy development capitalizing on the optical 
stimulation that requires fine-grained, fast, and power-efficient real-time 
sound processing controlling dozens of microscale optical emitters as an 
emerging research area.

© 2023 The Author(s).

DOI: 10.1016/j.isci.2023.107725
PMCID: PMC10502376
PMID: 37720089

Conflict of interest statement: T.M. is a co-founder of OptoGenTech GmbH.


702. Front Pediatr. 2023 Jul 3;11:1187815. doi: 10.3389/fped.2023.1187815. 
eCollection 2023.

Concept and considerations of a medical device: the active noise cancelling 
incubator.

Jaschke AC(1)(2)(3), Bos AF(1).

Author information:
(1)Department of Paediatrics, Division of Neonatology, Beatrix Children's 
Hospital, University Medical Center Groningen, University of Groningen, 
Groningen, Netherlands.
(2)Department of Music Therapy, ArtEZ University of the Arts, Enschede, 
Netherlands.
(3)Cambridge Institute for Music Therapy Research, Anglia Ruskin University, 
Cambridge, United Kingdom.

BACKGROUND: An increasingly 24/7 connected and urbanised world has created a 
silent pandemic of noise-induced hearing loss. Ensuring survival to children 
born (extremely) preterm is crucial. The incubator is a closed medical device, 
modifying the internal climate, and thus providing an environment for the child, 
as safe, warm, and comfortable as possible. While sound outside the incubator is 
managed and has decreased over the years, managing the noise inside the 
incubator is still a challenge.
METHOD: Using active noise cancelling in an incubator will eliminate unwanted 
sounds (i.e., from the respirator and heating) inside the incubator, and by 
adding sophisticated algorithms, normal human speech, neonatal intensive care 
unit music-based therapeutic interventions, and natural sounds will be sustained 
for the child in the pod. Applying different methods such as active noise 
cancelling, motion capture, sonological engineering. and sophisticated machine 
learning algorithms will be implemented in the development of the incubator.
PROJECTED RESULTS: A controlled and active sound environment in and around the 
incubator can in turn promote the wellbeing, neural development, and speech 
development of the child and minimise distress caused by unwanted noises. While 
developing the hardware and software pose individual challenges, it is about the 
system design and aspects contributing to it. On the one hand, it is crucial to 
measure the auditory range and frequencies in the incubator, as well as the 
predictable sounds that will have to be played back into the environment. On the 
other, there are many technical issues that have to be addressed when it comes 
to algorithms, datasets, delay, microphone technology, transducers, convergence, 
tracking, impulse control and noise rejection, noise mitigation stability, 
detection, polarity, and performance.
CONCLUSION: Solving a complex problem like this, however, requires a 
de-disciplinary approach, where each discipline will realise its own 
shortcomings and boundaries, and in turn will allow for innovations and new 
avenues. Technical developments used for building the active noise 
cancellation-incubator have the potential to contribute to improved care 
solutions for patients, both infants and adults.Code available at: 
10.3389/fped.2023.1187815.

© 2023 Jaschke and Bos.

DOI: 10.3389/fped.2023.1187815
PMCID: PMC10350684
PMID: 37465419

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


703. Sci Rep. 2016 Jun 15;6:28141. doi: 10.1038/srep28141.

Optoacoustic effect is responsible for laser-induced cochlear responses.

Kallweit N(1)(2), Baumhoff P(3), Krueger A(1)(2), Tinne N(1)(2), Kral A(2)(3), 
Ripken T(1)(2), Maier H(2)(3).

Author information:
(1)Laser Zentrum Hannover e.V., Hollerithallee 8, 30419 Hannover, Germany.
(2)Cluster of Excellence "Hearing4all", Germany.
(3)Institute of Audioneurotechnology and Dept. of Experimental Otology, ENT 
Clinics, Hannover Medical School, Feodor-Lynen-Str. 35, 30625 Hannover, Germany.

Optical stimulation of the cochlea with laser light has been suggested as an 
alternative to conventional treatment of sensorineural hearing loss with 
cochlear implants. The underlying mechanisms are controversially discussed: The 
stimulation can either be based on a direct excitation of neurons, or it is a 
result of an optoacoustic pressure wave acting on the basilar membrane. Animal 
studies comparing the intra-cochlear optical stimulation of hearing and deafened 
guinea pigs have indicated that the stimulation requires intact hair cells. 
Therefore, optoacoustic stimulation seems to be the underlying mechanism. The 
present study investigates optoacoustic characteristics using pulsed laser 
stimulation for in vivo experiments on hearing guinea pigs and pressure 
measurements in water. As a result, in vivo as well as pressure measurements 
showed corresponding signal shapes. The amplitude of the signal for both 
measurements depended on the absorption coefficient and on the maximum of the 
first time-derivative of laser pulse power (velocity of heat deposition). In 
conclusion, the pressure measurements directly demonstrated that laser light 
generates acoustic waves, with amplitudes suitable for stimulating the 
(partially) intact cochlea. These findings corroborate optoacoustic as the basic 
mechanism of optical intra-cochlear stimulation.

DOI: 10.1038/srep28141
PMCID: PMC4908384
PMID: 27301846 [Indexed for MEDLINE]


704. J Assoc Res Otolaryngol. 2021 Jul;22(4):365-386. doi: 
10.1007/s10162-021-00789-0. Epub 2021 May 20.

Visual Influences on Auditory Behavioral, Neural, and Perceptual Processes: A 
Review.

Opoku-Baah C(1)(2), Schoenhaut AM(1)(2), Vassall SG(1)(2), Tovar DA(1)(2), 
Ramachandran R(2)(3)(4)(5), Wallace MT(6)(7)(8)(9)(10)(11).

Author information:
(1)Neuroscience Graduate Program, Vanderbilt University, Nashville, TN, USA.
(2)Vanderbilt Brain Institute, Vanderbilt University, Nashville, TN, USA.
(3)Department of Psychology, Vanderbilt University, Nashville, TN, USA.
(4)Department of Hearing and Speech, Vanderbilt University Medical Center, 
Nashville, TN, USA.
(5)Vanderbilt Vision Research Center, Nashville, TN, USA.
(6)Vanderbilt Brain Institute, Vanderbilt University, Nashville, TN, USA. 
mark.wallace@vanderbilt.edu.
(7)Department of Psychology, Vanderbilt University, Nashville, TN, USA. 
mark.wallace@vanderbilt.edu.
(8)Department of Hearing and Speech, Vanderbilt University Medical Center, 
Nashville, TN, USA. mark.wallace@vanderbilt.edu.
(9)Vanderbilt Vision Research Center, Nashville, TN, USA. 
mark.wallace@vanderbilt.edu.
(10)Department of Psychiatry and Behavioral Sciences, Vanderbilt University 
Medical Center, Nashville, TN, USA. mark.wallace@vanderbilt.edu.
(11)Department of Pharmacology, Vanderbilt University, Nashville, TN, USA. 
mark.wallace@vanderbilt.edu.

In a naturalistic environment, auditory cues are often accompanied by 
information from other senses, which can be redundant with or complementary to 
the auditory information. Although the multisensory interactions derived from 
this combination of information and that shape auditory function are seen across 
all sensory modalities, our greatest body of knowledge to date centers on how 
vision influences audition. In this review, we attempt to capture the state of 
our understanding at this point in time regarding this topic. Following a 
general introduction, the review is divided into 5 sections. In the first 
section, we review the psychophysical evidence in humans regarding vision's 
influence in audition, making the distinction between vision's ability to 
enhance versus alter auditory performance and perception. Three examples are 
then described that serve to highlight vision's ability to modulate auditory 
processes: spatial ventriloquism, cross-modal dynamic capture, and the McGurk 
effect. The final part of this section discusses models that have been built 
based on available psychophysical data and that seek to provide greater 
mechanistic insights into how vision can impact audition. The second section 
reviews the extant neuroimaging and far-field imaging work on this topic, with a 
strong emphasis on the roles of feedforward and feedback processes, on imaging 
insights into the causal nature of audiovisual interactions, and on the 
limitations of current imaging-based approaches. These limitations point to a 
greater need for machine-learning-based decoding approaches toward understanding 
how auditory representations are shaped by vision. The third section reviews the 
wealth of neuroanatomical and neurophysiological data from animal models that 
highlights audiovisual interactions at the neuronal and circuit level in both 
subcortical and cortical structures. It also speaks to the functional 
significance of audiovisual interactions for two critically important facets of 
auditory perception-scene analysis and communication. The fourth section 
presents current evidence for alterations in audiovisual processes in three 
clinical conditions: autism, schizophrenia, and sensorineural hearing loss. 
These changes in audiovisual interactions are postulated to have cascading 
effects on higher-order domains of dysfunction in these conditions. The final 
section highlights ongoing work seeking to leverage our knowledge of audiovisual 
interactions to develop better remediation approaches to these sensory-based 
disorders, founded in concepts of perceptual plasticity in which vision has been 
shown to have the capacity to facilitate auditory learning.

© 2021. The Author(s).

DOI: 10.1007/s10162-021-00789-0
PMCID: PMC8329114
PMID: 34014416 [Indexed for MEDLINE]


705. Hear Res. 2018 Jul;364:81-89. doi: 10.1016/j.heares.2018.03.028. Epub 2018 Apr 
1.

Concurrent gradients of ribbon volume and AMPA-receptor patch volume in cochlear 
afferent synapses on gerbil inner hair cells.

Zhang L(1), Engler S(1), Koepcke L(2), Steenken F(1), Köppl C(3).

Author information:
(1)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129 Oldenburg, Germany.
(2)Department of Neuroscience, Computational Neuroscience, Carl von Ossietzky 
University Oldenburg, 26129 Oldenburg, Germany.
(3)Cluster of Excellence "Hearing4all" and Research Centre Neurosensory Science, 
Department of Neuroscience, School of Medicine and Health Science, Carl von 
Ossietzky University Oldenburg, 26129 Oldenburg, Germany. Electronic address: 
christine.koeppl@uol.de.

The Mongolian gerbil is a classic animal model for age-related hearing loss. As 
a prerequisite for studying age-related changes, we characterized cochlear 
afferent synaptic morphology in young adult gerbils, using immunolabeling and 
quantitative analysis of confocal microscopic images. Cochlear wholemounts were 
triple-labeled with a hair-cell marker, a marker of presynaptic ribbons, and a 
marker of postsynaptic AMPA-type glutamate receptors. Seven cochlear positions 
covering an equivalent frequency range from 0.5 - 32 kHz were evaluated. The 
spatial positions of synapses were determined in a coordinate system with 
reference to their individual inner hair cell. Synapse numbers confirmed 
previous reports for gerbils (on average, 20-22 afferents per inner hair cell). 
The volumes of presynaptic ribbons and postsynaptic glutamate receptor patches 
were positively correlated: larger ribbons associated with larger receptor 
patches and smaller ribbons with smaller patches. Furthermore, the volumes of 
both presynaptic ribbons and postsynaptic receptor patches co-varied along the 
modiolar-pillar and the longitudinal axes of their hair cell. The gradients in 
ribbon volume are consistent with previous findings in cat, guinea pig, mouse 
and rat and further support a role in differentiating the physiological 
properties of type I afferents. However, the positive correlation between the 
volumes of pre- and postsynaptic elements in the gerbil is different to the 
opposing gradients found in the mouse, suggesting species-specific differences 
in the postsynaptic AMPA receptors that are unrelated to the fundamental classes 
of type I afferents.

Copyright © 2018 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2018.03.028
PMID: 29631778 [Indexed for MEDLINE]


706. Front Neurol. 2019 Jun 10;10:570. doi: 10.3389/fneur.2019.00570. eCollection 
2019.

Anti-inflammatory and Oto-Protective Effect of the Small Heat Shock Protein 
Alpha B-Crystallin (HspB5) in Experimental Pneumococcal Meningitis.

Erni ST(1)(2)(3)(4), Fernandes G(1)(2)(3), Buri M(1)(2), Perny M(1)(2)(3), 
Rutten RJ(5), van Noort JM(6), Senn P(7), Grandgirard D(1)(2), Roccio 
M(2)(3)(8), Leib SL(1)(2).

Author information:
(1)Neuroinfection Laboratory, Institute for Infectious Diseases, University of 
Bern, Bern, Switzerland.
(2)Cluster for Regenerative Neuroscience, DBMR, University of Bern, Bern, 
Switzerland.
(3)Laboratory of Inner Ear Research, DBMR, University of Bern, Bern, 
Switzerland.
(4)Graduate School for Cellular and Biomedical Sciences, University of Bern, 
Bern, Switzerland.
(5)Audion Therapeutics, Amsterdam, Netherlands.
(6)Delta Crystallon BV, Leiden, Netherlands.
(7)Service d'oto-rhino-laryngologie (ORL) et de chirurgie cervico-faciale, 
Département des Neurosciences Cliniques, Hôpitaux Universitaires de Genève, 
Geneva, Switzerland.
(8)Department of Otorhinolaryngology, Head & Neck Surgery, Inselspital, Bern, 
Switzerland.

Sensorineural hearing loss is the most common long-term deficit after 
pneumococcal meningitis (PM), occurring in up to 30% of surviving patients. The 
infection and the following overshooting inflammatory host response damage the 
vulnerable sensory cells of the inner ear, resulting in loss of hair cells and 
spiral ganglion neurons, ultimately leading to elevated hearing thresholds. 
Here, we tested the oto-protective properties of the small heat shock protein 
alpha B-crystallin (HspB5) with previously reported anti-inflammatory, 
anti-apoptotic and neuroprotective functions, in an experimental model of 
PM-induced hearing loss. We analyzed the effect of local and systemic delivery 
of HspB5 in an infant rat model of PM, as well as ex vivo, using whole mount 
cultures. Cytokine secretion profile, hearing thresholds and inner ear damage 
were assessed at predefined stages of the disease up to 1 month after infection. 
PM was accompanied by elevated pro-inflammatory cytokine concentrations in the 
cerebrospinal fluid (CSF), leukocyte and neutrophil infiltration in the 
perilymphatic spaces of the cochlea with neutrophils extracellular trap 
formation during the acute phase of the disease. Elevated hearing thresholds 
were measured after recovery from meningitis. Intracisternal but not 
intraperitoneal administration of HspB5 significantly reduced the levels of 
TNF-α, IL-6 IFN-γ and IL-10 in the acute phase of the disease. This resulted in 
a greater outer hair cell survival, as well as improved hearing thresholds at 
later stages. These results suggest that high local concentrations of HspB5 are 
needed to prevent inner ear damage in acute PM. HspB5 represents a promising 
therapeutic option to improve the auditory outcome and counteract hearing loss 
after PM.

DOI: 10.3389/fneur.2019.00570
PMCID: PMC6573805
PMID: 31244750


707. Clin Exp Otorhinolaryngol. 2012 Apr;5 Suppl 1(Suppl 1):S37-42. doi: 
10.3342/ceo.2012.5.S1.S37. Epub 2012 Apr 30.

Voxel-wise analysis of diffusion tensor imaging for clinical outcome of cochlear 
implantation: retrospective study.

Chang Y(1), Lee HR, Paik JS, Lee KY, Lee SH.

Author information:
(1)Department of Molecular Medicine, Kyungpook National University School of 
Medicine, Daegu, Korea.

OBJECTIVES: To evaluate retrospectively, the possible difference in diffusion 
tensor imaging (DTI) metric of fractional anisotropy (FA) between good and poor 
surgical outcome cochlear implantation (CI) patients using 
investigator-independent voxel-wise analysis.
METHODS: Eighteen patients (11 males, 7 females; mean age, 5.9 years) with 
profound sensorineural hearing loss underwent DTI scans using a 3.0 Tesla 
magnetic resonance scanner. Among the 18 patients, 10 patients with categories 
of auditory performance (CAP) score over 6 were classified into the good outcome 
group and 8 patients with CAP score below 6 were classified into the poor 
outcome group. The diffusion tensor scalar measure was calculated from the 
eigenvalues of the tensor on a voxel-by-voxel basis from each subject and 
two-sample t-test evaluation between good and poor outcome subjects were 
performed for each voxel of FA values, across the entire brain, with a 
voxel-wise intensity threshold of P<0.0005 (uncorrected) and a contiguous 
cluster size of 64 voxels. Individual values of FA were measured by using the 
region-of-interest based analysis for correlation analysis with CAP scores, open 
sentence and open word scores.
RESULTS: Two-sample t-test evaluation using SPM voxel-wise analysis found 
significantly higher FA values at the several brain areas including Broca's 
area, genu of the corpus callosum, and auditory tract in good outcome subjects 
compared to poor outcome subjects. Correlation analyses between FA and CAP 
scores, open sentence and open word scores revealed strong correlations at 
medial geniculate nucleus, Broca's area, genu of the corpus callosum and 
auditory tract.
CONCLUSION: Investigator-independent voxel-based analysis of DTI image 
demonstrated that good outcome subjects showed better neural integrity at brain 
areas associated with language and auditory functions, suggesting that the 
conservation of microstructural integrity of these brain areas is important. 
Preoperative functional imaging may be helpful for CI.

DOI: 10.3342/ceo.2012.5.S1.S37
PMCID: PMC3369980
PMID: 22701772

Conflict of interest statement: No potential conflict of interest relevant to 
this article was reported.


708. Brain Stimul. 2018 Sep-Oct;11(5):1161-1174. doi: 10.1016/j.brs.2018.05.009. Epub 
2018 May 17.

Electrical stimulation of the midbrain excites the auditory cortex 
asymmetrically.

Quass GL(1), Kurt S(2), Hildebrandt KJ(3), Kral A(2).

Author information:
(1)Institute of AudioNeuroTechnology (VIANNA), Dept. of Experimental Otology, 
ENT Clinics, Hannover Medical School, 30625 Hannover, Germany; Cluster of 
Excellence "Hearing4all", Germany. Electronic address: 
quass.gunnar@mh-hannover.de.
(2)Institute of AudioNeuroTechnology (VIANNA), Dept. of Experimental Otology, 
ENT Clinics, Hannover Medical School, 30625 Hannover, Germany; Cluster of 
Excellence "Hearing4all", Germany.
(3)Cluster of Excellence "Hearing4all", Germany; Research Center Neurosensory 
Science, University of Oldenburg, 26111 Oldenburg, Germany.

BACKGROUND: Auditory midbrain implant users cannot achieve open speech 
perception and have limited frequency resolution. It remains unclear whether the 
spread of excitation contributes to this issue and how much it can be 
compensated by current-focusing, which is an effective approach in cochlear 
implants.
OBJECTIVE: The present study examined the spread of excitation in the cortex 
elicited by electric midbrain stimulation. We further tested whether 
current-focusing via bipolar and tripolar stimulation is effective with electric 
midbrain stimulation and whether these modes hold any advantage over monopolar 
stimulation also in conditions when the stimulation electrodes are in direct 
contact with the target tissue.
METHODS: Using penetrating multielectrode arrays, we recorded cortical 
population responses to single pulse electric midbrain stimulation in 10 
ketamine/xylazine anesthetized mice. We compared monopolar, bipolar, and 
tripolar stimulation configurations with regard to the spread of excitation and 
the characteristic frequency difference between the stimulation/recording 
electrodes.
RESULTS: The cortical responses were distributed asymmetrically around the 
characteristic frequency of the stimulated midbrain region with a strong 
activation in regions tuned up to one octave higher. We found no significant 
differences between monopolar, bipolar, and tripolar stimulation in threshold, 
evoked firing rate, or dynamic range.
CONCLUSION: The cortical responses to electric midbrain stimulation are biased 
towards higher tonotopic frequencies. Current-focusing is not effective in 
direct contact electrical stimulation. Electrode maps should account for the 
asymmetrical spread of excitation when fitting auditory midbrain implants by 
shifting the frequency-bands downward and stimulating as dorsally as possible.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.brs.2018.05.009
PMID: 29853311 [Indexed for MEDLINE]


709. Front Neurosci. 2022 May 19;16:898902. doi: 10.3389/fnins.2022.898902. 
eCollection 2022.

Aberrant Functional Network of Small-World in Sudden Sensorineural Hearing Loss 
With Tinnitus.

Hua JC(1), Xu XM(2), Xu ZG(1), Xu JJ(3), Hu JH(3), Xue Y(1), Wu Y(3).

Author information:
(1)Department of Otolaryngology, Nanjing Pukou Central Hospital, Pukou Branch 
Hospital of Jiangsu Province Hospital, Nanjing, China.
(2)Department of Radiology, Nanjing First Hospital, Nanjing Medical University, 
Nanjing, China.
(3)Department of Otolaryngology, Nanjing First Hospital, Nanjing Medical 
University, Nanjing, China.

Few researchers investigated the topological properties and relationships with 
cognitive deficits in sudden sensorineural hearing loss (SNHL) with tinnitus. To 
explore the topological characteristics of the brain connectome following SNHL 
from the global level and nodal level, we recruited 36 bilateral SNHL patients 
with tinnitus and 37 well-matched healthy controls. Every subject underwent pure 
tone audiometry tests, neuropsychological assessments, and MRI scanning. AAL 
atlas was employed to divide a brain into 90 cortical and subcortical regions of 
interest, then investigated the global and nodal properties of "small world" 
network in SNHL and control groups using a graph-theory analysis. The global 
characteristics include small worldness, cluster coefficient, characteristic 
path length, local efficiency, and global efficiency. Node properties include 
degree centrality, betweenness centrality, nodal efficiency, and nodal 
clustering coefficient. Interregional connectivity analysis was also computed 
among 90 nodes. We found that the SNHL group had significantly higher hearing 
thresholds and cognitive impairments, as well as disrupted internal connections 
among 90 nodes. SNHL group displayed lower AUC of cluster coefficient and path 
length lambda, but increased global efficiency. The opercular and triangular 
parts of the inferior frontal gyrus, rectus gyrus, parahippocampal gyrus, 
precuneus, and amygdala showed abnormal local features. Some of these connectome 
alterations were correlated with cognitive ability and the duration of SNHL. 
This study may prove potential imaging biomarkers and treatment targets for 
future studies.

Copyright © 2022 Hua, Xu, Xu, Xu, Hu, Xue and Wu.

DOI: 10.3389/fnins.2022.898902
PMCID: PMC9160300
PMID: 35663555

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


710. Neuroimage Clin. 2021;32:102823. doi: 10.1016/j.nicl.2021.102823. Epub 2021 Sep 
21.

Glucose hypometabolism in the Auditory Pathway in Age Related Hearing Loss in 
the ADNI cohort.

Zainul Abidin FN(1), Scelsi MA(2), Dawson SJ(3), Altmann A(4); Alzheimer's 
Disease Neuroimaging Initiative.

Author information:
(1)UCL Ear Institute, University College London, London, UK; Centre for Medical 
Image Computing, Department of Medical Physics and Biomedical Engineering, 
University College London, London, UK.
(2)Centre for Medical Image Computing, Department of Medical Physics and 
Biomedical Engineering, University College London, London, UK.
(3)UCL Ear Institute, University College London, London, UK.
(4)Centre for Medical Image Computing, Department of Medical Physics and 
Biomedical Engineering, University College London, London, UK. Electronic 
address: a.altmann@ucl.ac.uk.

PURPOSE: Hearing loss (HL) is one of the most common age-related diseases. Here, 
we investigate the central auditory correlates of HL in people with normal 
cognition and mild cognitive impairment (MCI) and test their association with 
genetic markers with the aim of revealing pathogenic mechanisms.
METHODS: Brain glucose metabolism based on FDG-PET, self-reported HL status, and 
genetic data were obtained from the Alzheimer's Disease Neuroimaging Initiative 
(ADNI) cohort. FDG-PET data was analysed from 742 control subjects (non-HL with 
normal cognition or MCI) and 162 cases (HL with normal cognition or MCI) with 
age ranges of 72.2 ± 7.1 and 77.4 ± 6.4, respectively. Voxel-wise statistics of 
FDG uptake differences between cases and controls were computed using the 
generalised linear model in SPM12. An additional 1515 FDG-PET scans of 618 
participants were analysed using linear mixed effect models to assess 
longitudinal HL effects. Furthermore, a quantitative trait genome-wide 
association study (GWAS) was conducted on the glucose uptake within regions of 
interest (ROIs), which were defined by the voxel-wise comparison, using 
genotyping data with 5,082,878 variants available for HL cases and HL controls 
(N = 817).
RESULTS: The HL group exhibited hypometabolism in the bilateral Heschl's gyrus 
(kleft = 323; kright = 151; Tleft = 4.55; Tright = 4.14; peak Puncorr < 0.001), 
the inferior colliculus (k = 219;T = 3.53; peak Puncorr < 0.001) and cochlear 
nucleus (k = 18;T = 3.55; peak Puncorr < 0.001) after age correction and using a 
cluster forming height threshold P < 0.005 (FWE-uncorrected). Moreover, in an 
age-matched subset, the cluster comprising the left Heschl's gyrus survived the 
FWE-correction (kleft = 1903; Tleft = 4.39; cluster PFWE-corr = 0.001). The 
quantitative trait GWAS identified no genome-wide significant locus in the three 
HL ROIs. However, various loci were associated at the suggestive threshold 
(p < 1e-05).
CONCLUSION: Compared to the non-HL group, glucose metabolism in the HL group was 
lower in the auditory cortex, the inferior colliculus, and the cochlear nucleus 
although the effect sizes were small. The GWAS identified candidate genes that 
might influence FDG uptake in these regions. However, the specific biological 
pathway(s) underlying the role of these genes in FDG-hypometabolism in the 
auditory pathway requires further investigation.

Copyright © 2021 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.nicl.2021.102823
PMCID: PMC8503577
PMID: 34624637 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no known 
competing financial interests or personal relationships that could have appeared 
to influence the work reported in this paper.


711. Front Neurosci. 2022 Jun 8;16:908330. doi: 10.3389/fnins.2022.908330. 
eCollection 2022.

Intrinsic Noise Improves Speech Recognition in a Computational Model of the 
Auditory Pathway.

Schilling A(1)(2)(3), Gerum R(4), Metzner C(2)(5), Maier A(6), Krauss 
P(2)(3)(6)(7).

Author information:
(1)Laboratory of Sensory and Cognitive Neuroscience, Aix-Marseille University, 
Marseille, France.
(2)Neuroscience Lab, University Hospital Erlangen, Erlangen, Germany.
(3)Cognitive Computational Neuroscience Group, Friedrich-Alexander-University 
Erlangen-Nuremberg (FAU), Erlangen, Germany.
(4)Department of Physics and Center for Vision Research, York University, 
Toronto, ON, Canada.
(5)Friedrich-Alexander-University Erlangen-Nuremberg (FAU), Erlangen, Germany.
(6)Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg 
(FAU), Erlangen, Germany.
(7)Linguistics Lab, Friedrich-Alexander-University Erlangen-Nuremberg (FAU), 
Erlangen, Germany.

Noise is generally considered to harm information processing performance. 
However, in the context of stochastic resonance, noise has been shown to improve 
signal detection of weak sub- threshold signals, and it has been proposed that 
the brain might actively exploit this phenomenon. Especially within the auditory 
system, recent studies suggest that intrinsic noise plays a key role in signal 
processing and might even correspond to increased spontaneous neuronal firing 
rates observed in early processing stages of the auditory brain stem and cortex 
after hearing loss. Here we present a computational model of the auditory 
pathway based on a deep neural network, trained on speech recognition. We 
simulate different levels of hearing loss and investigate the effect of 
intrinsic noise. Remarkably, speech recognition after hearing loss actually 
improves with additional intrinsic noise. This surprising result indicates that 
intrinsic noise might not only play a crucial role in human auditory processing, 
but might even be beneficial for contemporary machine learning approaches.

Copyright © 2022 Schilling, Gerum, Metzner, Maier and Krauss.

DOI: 10.3389/fnins.2022.908330
PMCID: PMC9215117
PMID: 35757533

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


712. Front Neurosci. 2021 Aug 31;15:723877. doi: 10.3389/fnins.2021.723877. 
eCollection 2021.

Can Haptic Stimulation Enhance Music Perception in Hearing-Impaired Listeners?

Fletcher MD(1)(2).

Author information:
(1)University of Southampton Auditory Implant Service, Faculty of Engineering 
and Physical Sciences, University of Southampton, Southampton, United Kingdom.
(2)Institute of Sound and Vibration Research, Faculty of Engineering and 
Physical Sciences, University of Southampton, Southampton, United Kingdom.

Cochlear implants (CIs) have been remarkably successful at restoring hearing in 
severely-to-profoundly hearing-impaired individuals. However, users often 
struggle to deconstruct complex auditory scenes with multiple simultaneous 
sounds, which can result in reduced music enjoyment and impaired speech 
understanding in background noise. Hearing aid users often have similar issues, 
though these are typically less acute. Several recent studies have shown that 
haptic stimulation can enhance CI listening by giving access to sound features 
that are poorly transmitted through the electrical CI signal. This 
"electro-haptic stimulation" improves melody recognition and pitch 
discrimination, as well as speech-in-noise performance and sound localization. 
The success of this approach suggests it could also enhance auditory perception 
in hearing-aid users and other hearing-impaired listeners. This review focuses 
on the use of haptic stimulation to enhance music perception in hearing-impaired 
listeners. Music is prevalent throughout everyday life, being critical to media 
such as film and video games, and often being central to events such as weddings 
and funerals. It represents the biggest challenge for signal processing, as it 
is typically an extremely complex acoustic signal, containing multiple 
simultaneous harmonic and inharmonic sounds. Signal-processing approaches 
developed for enhancing music perception could therefore have significant 
utility for other key issues faced by hearing-impaired listeners, such as 
understanding speech in noisy environments. This review first discusses the 
limits of music perception in hearing-impaired listeners and the limits of the 
tactile system. It then discusses the evidence around integration of audio and 
haptic stimulation in the brain. Next, the features, suitability, and success of 
current haptic devices for enhancing music perception are reviewed, as well as 
the signal-processing approaches that could be deployed in future haptic 
devices. Finally, the cutting-edge technologies that could be exploited for 
enhancing music perception with haptics are discussed. These include the latest 
micro motor and driver technology, low-power wireless technology, machine 
learning, big data, and cloud computing. New approaches for enhancing music 
perception in hearing-impaired listeners could substantially improve quality of 
life. Furthermore, effective haptic techniques for providing complex sound 
information could offer a non-invasive, affordable means for enhancing listening 
more broadly in hearing-impaired individuals.

Copyright © 2021 Fletcher.

DOI: 10.3389/fnins.2021.723877
PMCID: PMC8439542
PMID: 34531717

Conflict of interest statement: The author declares that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


713. Zebrafish. 2018 Apr;15(2):145-155. doi: 10.1089/zeb.2017.1451. Epub 2018 Jan 30.

Automated High-Throughput Damage Scoring of Zebrafish Lateral Line Hair Cells 
After Ototoxin Exposure.

Philip RC(1), Rodriguez JJ(1), Niihori M(2)(3), Francis RH(2)(4), Mudery 
JA(2)(4), Caskey JS(2)(4), Krupinski E(5), Jacob A(2)(3)(6)(7).

Author information:
(1)1 Department of Electrical and Computer Engineering, The University of 
Arizona , Tucson, Arizona.
(2)2 Department of Otolaryngology, The University of Arizona , Tucson, Arizona.
(3)3 The University of Arizona Cancer Center , Tucson, Arizona.
(4)4 College of Medicine, The University of Arizona , Tucson, Arizona.
(5)5 Department of Radiology and Imaging Sciences, Emory University , Atlanta, 
Georgia .
(6)6 BIO5 Institute, The University of Arizona , Tucson, Arizona.
(7)7 Ear & Hearing, Center for Neurosciences , Tucson, Arizona.

Zebrafish have emerged as a powerful biological system for drug development 
against hearing loss. Zebrafish hair cells, contained within neuromasts along 
the lateral line, can be damaged with exposure to ototoxins, and therefore, 
pre-exposure to potentially otoprotective compounds can be a means of 
identifying promising new drug candidates. Unfortunately, anatomical assays of 
hair cell damage are typically low-throughput and labor intensive, requiring 
trained experts to manually score hair cell damage in fluorescence or confocal 
images. To enhance throughput and consistency, our group has developed an 
automated damage-scoring algorithm based on machine-learning techniques that 
produce accurate damage scores, eliminate potential operator bias, provide more 
fidelity in determining damage scores that are between two levels, and deliver 
consistent results in a fraction of the time required for manual analysis. The 
system has been validated against trained experts using linear regression, 
hypothesis testing, and the Pearson's correlation coefficient. Furthermore, 
performance has been quantified by measuring mean absolute error for each image 
and the time taken to automatically compute damage scores. Coupling automated 
analysis of zebrafish hair cell damage to behavioral assays for ototoxicity 
produces a novel drug discovery platform for rapid translation of candidate 
drugs into preclinical mammalian models of hearing loss.

DOI: 10.1089/zeb.2017.1451
PMID: 29381431 [Indexed for MEDLINE]


714. Front Neurol. 2021 Mar 11;12:594481. doi: 10.3389/fneur.2021.594481. eCollection 
2021.

Endolymphatic Hydrops in Patients With Vestibular Migraine and Concurrent 
Meniere's Disease.

Oh SY(1)(2), Dieterich M(3)(4)(5), Lee BN(1), Boegle R(3)(4), Kang JJ(1), Lee 
NR(2)(6), Gerb J(3)(4), Hwang SB(2)(7), Kirsch V(3)(4).

Author information:
(1)Department of Neurology, School of Medicine, Jeonbuk National University, 
Jeonju, South Korea.
(2)Research Institute of Clinical Medicine, Jeonbuk National University 
Hospital-Biomedical Research Institute, Jeonbuk National University, Jeonju, 
South Korea.
(3)Department of Neurology, University Hospital, Ludwig-Maximilians-Universität, 
Munich, Germany.
(4)German Center for Vertigo and Balance Disorders-IFB, University Hospital, 
Ludwig-Maximilians-Universität, Munich, Germany.
(5)Munich Cluster for Systems Neurology (SyNergy), Munich, Germany.
(6)Division of Oncology and Hematology, Department of Internal Medicine, Jeonbuk 
National University Hospital and School of Medicine, Jeonju, South Korea.
(7)Department of Radiology, Jeonbuk National University Hospital and School of 
Medicine, Jeonju, South Korea.

Objective: Intravenous contrast agent enhanced, high-resolution magnetic 
resonance imaging of the inner ear (iMRI) confirmed that patients with Menière's 
disease (MD) and vestibular migraine (VM) could present with endolymphatic 
hydrops (EH). The present study aimed to investigate EH characteristics and 
their interrelation to neurotologic testing in patients with VM, MD, or VM with 
concurrent MD (VM-MD). Methods: Sixty-two patients (45 females, aged 23-81 
years) with definite or probable VM (n = 25, 19 definite), MD (n = 29, 17 
definite), or showing characteristics of both diseases (n = 8) were included in 
this study. Diagnostic workup included neurotologic assessments including 
video-oculography (VOG) during caloric stimulation and head-impulse test (HIT), 
ocular and cervical vestibular evoked myogenic potentials (o/cVEMP), pure tone 
audiometry (PTA), as well as iMRI. EH's degree was assessed visually and via 
volumetric quantification using a probabilistic atlas-based segmentation of the 
bony labyrinth and volumetric local thresholding (VOLT). Results: Although a 
relevant number of VM patients reported varying auditory symptoms (13 of 25, 
52.0%), EH in VM was only observed twice. In contrast, EH in VM-MD was prevalent 
(2/8, 25%) and in MD frequent [23/29, 79.3%; χ2(2) = 29.1, p < 0.001, φ = 0.7]. 
Location and laterality of EH and neurophysiological testing classifications 
were highly associated (Fisher exact test, p < 0.005). In MD, visual 
semi-quantitative grading and volumetric quantification correlated highly to 
each other (r S = 0.8, p < 0.005, two-sided) and to side differences in VOG 
during caloric irrigation (vestibular EH ipsilateral: r S = 0.6, p < 0.05, 
two-sided). In VM, correlations were less pronounced. VM-MD assumed an 
intermediate position between VM and MD. Conclusion: Cochlear and vestibular 
hydrops can occur in MD and VM patients with auditory symptoms; this suggests 
inner ear damage irrespective of the diagnosis of MD or VM. The EH grades often 
correlated with auditory symptoms such as hearing impairment and tinnitus. 
Further research is required to uncover whether migraine is one causative factor 
of EH or whether EH in VM patients with auditory symptoms suggests an additional 
pathology due to MD.

Copyright © 2021 Oh, Dieterich, Lee, Boegle, Kang, Lee, Gerb, Hwang and Kirsch.

DOI: 10.3389/fneur.2021.594481
PMCID: PMC7991602
PMID: 33776877

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


715. Int J Biochem Cell Biol. 2016 Dec;81(Pt A):208-222. doi: 
10.1016/j.biocel.2015.11.012. Epub 2015 Nov 23.

Induction of differentiation of human embryonic stem cells into functional 
hair-cell-like cells in the absence of stromal cells.

Ding J(1), Tang Z(2), Chen J(2), Shi H(3), Chen J(2), Wang C(2), Zhang C(2), Li 
L(2), Chen P(4), Wang J(5).

Author information:
(1)Institute of Cell and Development, College of Life Sciences, Zhejiang 
University, Hangzhou 310058, PR China; College of Life Sciences, Guizhou 
University, Guiyang 550025, PR China.
(2)Institute of Cell and Development, College of Life Sciences, Zhejiang 
University, Hangzhou 310058, PR China.
(3)Department of Otorhinolaryngology, The Sixth People's Hospital, Shanghai 
Jiaotong University, Shanghai 200233, PR China.
(4)Institute of Cell and Development, College of Life Sciences, Zhejiang 
University, Hangzhou 310058, PR China; Departments of Cell Biology and 
Otolaryngology, Emory University School of Medicine, Atlanta, GA 30322, USA.
(5)Institute of Cell and Development, College of Life Sciences, Zhejiang 
University, Hangzhou 310058, PR China. Electronic address: wjfu@zju.edu.cn.

Sensorineural hearing loss and vestibular dysfunction have become the most 
common forms of sensory defects. Stem cell-based therapeutic strategies for 
curing hearing loss are being developed. Several attempts to develop hair cells 
by using chicken utricle stromal cells as feeder cells have resulted in 
phenotypic conversion of stem cells into inner ear hair-cell-like cells. Here, 
we induced the differentiation of human embryonic stem cells (hESCs) into otic 
epithelial progenitors (OEPs), and further induced the differentiation of OEPs 
into hair-cell-like cells using different substrates. Our results showed that 
OEPs cultured on the chicken utricle stromal cells with the induction medium 
could differentiate into hair-cell-like cells with stereociliary bundles. 
Co-culture with stromal cells, however, may be problematic for subsequent 
examination of the induced hair-cell-like cells. In order to avoid the 
interference from stromal cells, we cultured OEPs on laminin with different 
induction media and examined the effects of the induction medium on the 
differentiation potentials of OEPs into hair-cell-like cells. The results 
revealed that the culture of OEPs on laminin with the conditioned medium from 
chicken utricle stromal cells supplemented with EGF and all-trans retinoic acid 
(RA) could promote the organization of cells into epithelial clusters displaying 
hair-cell-like cells with stereociliary bundles. These cells also displayed the 
expected electrophysiological properties.

Copyright © 2015 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.biocel.2015.11.012
PMID: 26615761 [Indexed for MEDLINE]


716. Diagnostics (Basel). 2023 May 16;13(10):1750. doi: 10.3390/diagnostics13101750.

Vertebrobasilar and Basilar Dolichoectasia Causing Audio-Vestibular 
Manifestations: A Case Series with a Brief Literature Review.

Frosolini A(1)(2), Fantin F(1), Caragli V(3), Franz L(1)(4), Fermo S(1), Inches 
I(5), Lovato A(6), Genovese E(3), Marioni G(1), de Filippis C(1).

Author information:
(1)Phoniatris and Audiology Unit, Department of Neuroscience DNS, University of 
Padova, 31100 Treviso, Italy.
(2)Maxillofacial Surgery Unit, Department of Medical Biotechnologies, University 
of Siena, 53100 Siena, Italy.
(3)Audiology Unit, Department of Diagnostic, Clinical and Public Health 
Medicine, University of Modena and Reggio Emilia, 41100 Modena, Italy.
(4)Artificial Intelligence in Medicine and Innovation in Clinical Research and 
Methodology (PhD Program), Department of Clinical and Experimental Sciences, 
University of Brescia, 25100 Brescia, Italy.
(5)Neuroradiology Unit, Treviso Hospital, 31100 Treviso, Italy.
(6)Otorhinolaryngology Unit, Department of Surgical Specialties, Vicenza Civil 
Hospital, 36100 Vicenza, Italy.

Audio-vestibular symptoms can arise from vertebrobasilar dolichoectasia (VBD) 
and basilar dolichoectasia (BD). Given the dearth of available information, 
herein we reported our experience with different audio-vestibular disorders 
(AVDs) observed in a case series of VBD patients. Furthermore, a literature 
review analyzed the possible relationships between epidemiological, clinical, 
and neuroradiological findings and audiological prognosis. The electronic 
archive of our audiological tertiary referral center was screened. All 
identified patients had a diagnosis of VBD/BD according to Smoker's criteria and 
a comprehensive audiological evaluation. PubMed and Scopus databases were 
searched for inherent papers published from 1 January 2000 to 1 March 2023. 
Three subjects were found; all of them had high blood pressure, and only the 
patient with high-grade VBD showed progressive sensorineural hearing loss 
(SNHL). Seven original studies were retrieved from the literature, overall 
including 90 cases. AVDs were more common in males and present in late adulthood 
(mean age 65 years, range 37-71), with symptoms including progressive and sudden 
SNHL, tinnitus, and vertigo. Diagnosis was made using different audiological and 
vestibular tests and cerebral MRI. Management was hearing aid fitting and 
long-term follow-up, with only one case of microvascular decompression surgery. 
The mechanism by which VBD and BD can cause AVD is debated, with the main 
hypothesis being VIII cranial nerve compression and vascular impairment. Our 
reported cases suggested the possibility of central auditory dysfunction of 
retro-cochlear origin due to VBD, followed by rapidly progressing SNHL and/or 
unnoticed sudden SNHL. More research is needed to better understand this 
audiological entity and achieve an evidence-based effective treatment.

DOI: 10.3390/diagnostics13101750
PMCID: PMC10217288
PMID: 37238234

Conflict of interest statement: The authors declare no conflict of interest.


717. Int J Mol Med. 2015 Mar;35(3):637-44. doi: 10.3892/ijmm.2015.2075. Epub 2015 Jan 
21.

Exposure to acoustic stimuli promotes the development and differentiation of 
neural stem cells from the cochlear nuclei through the clusterin pathway.

Xue T(1), Wei L(2), Zha DJ(1), Qiao L(2), Lu LJ(1), Chen FQ(1), Qiu JH(1).

Author information:
(1)Department of Otolaryngology, Xijing Hospital, The Fourth Military Medical 
University, Xi'an, Shaanxi 710032, P.R. China.
(2)Department of Obstetrics and Gynecology, Xijing Hospital, The Fourth Military 
Medical University, Xi'an, Shaanxi 710032, P.R. China.

Stem cell therapy has attracted widespread attention for a number of diseases. 
Recently, neural stem cells (NSCs) from the cochlear nuclei have been 
identified, indicating a potential direction for the treatment of sensorineural 
hearing loss. Acoustic stimuli play an important role in the development of the 
auditory system. In this study, we aimed to determine whether acoustic stimuli 
induce NSC development and differentiation through the upregulation of clusterin 
(CLU) in NSCs isolated from the cochlear nuclei. To further clarify the 
underlying mechanisms involved in the development and differentiation of NSCs 
exposed to acoustic stimuli, we successfully constructed animal models in which 
was CLU silenced by an intraperitoneal injection of shRNA targeting CLI. As 
expected, the NSCs from rats treated with LV-CLU shRNA exhibited a lower 
proliferation ratio when exposed to an augmented acoustic environment (AAE). 
Furthermore, the inhibition of cell apoptosis induced by exposure to AAE was 
abrogated after silencing the expression of the CLU gene. During the 
differentiation of acoustic stimuli-exposed stem cells into neurons, the number 
of astrocytes was significantly reduced, as evidenced by the expression of the 
cell markers, microtubule associated protein‑2 (MAP-2) and glial fibrillary 
acidic protein (GFAP), which was markedly inhibited when the CLU gene was 
silenced. Our results indicate that acoustic stimuli may induce the development 
and differentiation of NSCs from the cochlear nucleus mainly through the CLU 
pathway. Our study suggests that CLU may be a novel target for the treatment of 
sensorineural hearing loss.

DOI: 10.3892/ijmm.2015.2075
PMCID: PMC4314421
PMID: 25605314 [Indexed for MEDLINE]


718. Mol Ther Nucleic Acids. 2024 Feb 19;35(1):102157. doi: 
10.1016/j.omtn.2024.102157. eCollection 2024 Mar 12.

Protection from cisplatin-induced hearing loss with lentiviral vector-mediated 
ectopic expression of the anti-apoptotic protein BCL-XL.

Nassauer L(1), Staecker H(2), Huang P(2), Renslo B(2), Goblet M(3)(4), Harre 
J(3)(4), Warnecke A(3)(4), Schott JW(1), Morgan M(1), Galla M(1), Schambach 
A(1)(5).

Author information:
(1)Institute of Experimental Hematology, Hannover Medical School, 30625 
Hannover, Germany.
(2)Department of Otolaryngology-Head and Neck Surgery, University of Kansas 
School of Medicine, Kansas City, KS 66160, USA.
(3)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, 30625 Hannover, Germany.
(4)Cluster of Excellence "Hearing4all", Hannover Medical School, 30625 Hannover, 
Germany.
(5)Division of Hematology/Oncology, Boston Children's Hospital, Harvard Medical 
School, Boston, MA 02115, USA.

Cisplatin is a highly effective chemotherapeutic agent, but it can cause 
sensorineural hearing loss (SNHL) in patients. Cisplatin-induced ototoxicity is 
closely related to the accumulation of reactive oxygen species (ROS) and 
subsequent death of hair cells (HCs) and spiral ganglion neurons (SGNs). Despite 
various strategies to combat ototoxicity, only one therapeutic agent has thus 
far been clinically approved. Therefore, we have developed a gene therapy 
concept to protect cochlear cells from cisplatin-induced toxicity. 
Self-inactivating lentiviral (LV) vectors were used to ectopically express 
various antioxidant enzymes or anti-apoptotic proteins to enhance the cellular 
ROS scavenging or prevent apoptosis in affected cell types. In direct 
comparison, anti-apoptotic proteins mediated a stronger reduction in 
cytotoxicity than antioxidant enzymes. Importantly, overexpression of the most 
promising candidate, Bcl-xl, achieved an up to 2.5-fold reduction in 
cisplatin-induced cytotoxicity in HEI-OC1 cells, phoenix auditory neurons, and 
primary SGN cultures. BCL-XL protected against cisplatin-mediated tissue 
destruction in cochlear explants. Strikingly, in vivo application of the LV 
BCL-XL vector improved hearing and increased HC survival in cisplatin-treated 
mice. In conclusion, we have established a preclinical gene therapy approach to 
protect mice from cisplatin-induced ototoxicity that has the potential to be 
translated to clinical use in cancer patients.

© 2024 The Author(s).

DOI: 10.1016/j.omtn.2024.102157
PMCID: PMC10915631
PMID: 38450280

Conflict of interest statement: J.W.S., M.M., A.W., A.S., and H.S. have 
submitted patent applications for LV gene therapy for the inner ear.


719. Indian J Otolaryngol Head Neck Surg. 2024 Feb;76(1):262-267. doi: 
10.1007/s12070-023-04138-w. Epub 2023 Aug 22.

Association Between Metabolic Syndrome and Hearing Impairment: a Study on 200 
Subjects.

Sahni D(1), Bhagat S(1), Bhatia L(1), Singh P(1), Chawla S(1), Kaur A(1).

Author information:
(1)Government Medical College and Rajindra Hospital, Patiala, Punjab 147001 
India.

The metabolic syndrome (MS) is a cluster of conditions that occur. togehther, 
increase risk of heart disease, storke, type 2 diabetes mellitus and 
hypertension as a possible outcome. The previous research has shown a link 
between hearing loss and being overweight, diabetic, or suffering from heart 
disease. However, research on the possible link between hearing loss and 
metabolic syndrome is limited. Hearing loss due to metabolic syndrome was 
evaluated in the present investigation. Two hundred individuals with metabolic 
syndrome were included. All the patients were evaluated on three types of 
audiometry (pure tone, impedence, and DPOAE).Anthropometric data, blood 
pressure, blood sugar, and lipid profiles, were all collected from each patient. 
We also asked about their smoking and drinking habits in the past. SPSS v. 22.0 
was used to conduct the statistical analysis. Overall, SNHL affected 58.5% of 
patients. Patients having moderate hearing loss were the largest demographic 
group (40%), followed by those with mild hearing loss (15% ). Severe hearing 
loss only occurred in 3.5% of patients. Hearing loss was shown to be more 
prevalent in patients with more than three components of metabolic syndrome. 
Significant associations were found between hearing impairment and metabolic 
risk factors as waist circumference, fasting blood sugar, serum high-density 
lipoprotein, serum triglycerides, and systolic and diastolic blood pressure. 
Hearing loss was only marginally connected to smoking and excessive drinking.

© Association of Otolaryngologists of India 2023. Springer Nature or its 
licensor (e.g. a society or other partner) holds exclusive rights to this 
article under a publishing agreement with the author(s) or other 
rightsholder(s); author self-archiving of the accepted manuscript version of 
this article is solely governed by the terms of such publishing agreement and 
applicable law.

DOI: 10.1007/s12070-023-04138-w
PMCID: PMC10909006
PMID: 38440660

Conflict of interest statement: Conflict of interestThe authors declare no 
conflict of interest.


720. Front Neurosci. 2014 Dec 4;8:391. doi: 10.3389/fnins.2014.00391. eCollection 
2014.

Relating hearing loss and executive functions to hearing aid users' preference 
for, and speech recognition with, different combinations of binaural noise 
reduction and microphone directionality.

Neher T(1).

Author information:
(1)Medical Physics and Cluster of Excellence Hearing4all, Oldenburg University 
Germany.

Knowledge of how executive functions relate to preferred hearing aid (HA) 
processing is sparse and seemingly inconsistent with related knowledge for 
speech recognition outcomes. This study thus aimed to find out if (1) 
performance on a measure of reading span (RS) is related to preferred binaural 
noise reduction (NR) strength, (2) similar relations exist for two different, 
non-verbal measures of executive function, (3) pure-tone average hearing loss 
(PTA), signal-to-noise ratio (SNR), and microphone directionality (DIR) also 
influence preferred NR strength, and (4) preference and speech recognition 
outcomes are similar. Sixty elderly HA users took part. Six HA conditions 
consisting of omnidirectional or cardioid microphones followed by inactive, 
moderate, or strong binaural NR as well as linear amplification were tested. 
Outcome was assessed at fixed SNRs using headphone simulations of a frontal 
target talker in a busy cafeteria. Analyses showed positive effects of active NR 
and DIR on preference, and negative and positive effects of, respectively, 
strong NR and DIR on speech recognition. Also, while moderate NR was the most 
preferred NR setting overall, preference for strong NR increased with SNR. No 
relation between RS and preference was found. However, larger PTA was related to 
weaker preference for inactive NR and stronger preference for strong NR for both 
microphone modes. Equivalent (but weaker) relations between worse performance on 
one non-verbal measure of executive function and the HA conditions without DIR 
were found. For speech recognition, there were relations between HA condition, 
PTA, and RS, but their pattern differed from that for preference. Altogether, 
these results indicate that, while moderate NR works well in general, a notable 
proportion of HA users prefer stronger NR. Furthermore, PTA and executive 
functions can account for some of the variability in preference for, and speech 
recognition with, different binaural NR and DIR settings.

DOI: 10.3389/fnins.2014.00391
PMCID: PMC4255521
PMID: 25538547


721. J Laryngol Otol. 2019 Sep;133(9):747-758. doi: 10.1017/S0022215119001531. Epub 
2019 Aug 29.

The future of otology.

Jackler RK(1), Jan TA(1).

Author information:
(1)Department of Otolaryngology - Head and Neck Surgery, Stanford Ear Institute, 
Stanford University School of Medicine, California, USA.

BACKGROUND: The field of otology is increasingly at the forefront of innovation 
in science and medicine. The inner ear, one of the most challenging systems to 
study, has been rendered much more open to inquiry by recent developments in 
research methodology. Promising advances of potential clinical impact have 
occurred in recent years in biological fields such as auditory genetics, 
ototoxic chemoprevention and organ of Corti regeneration. The interface of the 
ear with digital technology to remediate hearing loss, or as a consumer device 
within an intelligent ecosystem of connected devices, is receiving enormous 
creative energy. Automation and artificial intelligence can enhance otological 
medical and surgical practice. Otology is poised to enter a new renaissance 
period, in which many previously untreatable ear diseases will yield to newly 
introduced therapies.
OBJECTIVE: This paper speculates on the direction otology will take in the 
coming decades.
CONCLUSION: Making predictions about the future of otology is a risky endeavour. 
If the predictions are found wanting, it will likely be because of unforeseen 
revolutionary methods.

DOI: 10.1017/S0022215119001531
PMID: 31462337


722. Life (Basel). 2021 Apr 1;11(4):301. doi: 10.3390/life11040301.

In Situ 3D-Imaging of the Inner Ear Synapses with a Cochlear Implant.

Malfeld K(1)(2), Armbrecht N(1), Volk HA(2), Lenarz T(1)(3), Scheper V(1)(3).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Carl-Neuberg-Str. 1, 
30625 Hannover, Germany.
(2)Department of Small Animal Medicine and Surgery, University of Veterinary 
Medicine Hannover, 30559 Hannover, Germany.
(3)Cluster of Excellence "Hearing4all", German Research Foundation, DFG 
(Deutsche Forschungsgemeinschaft), Hannover Medical School, Carl-Neuberg-Str. 1, 
30625 Hannover, Germany.

In recent years sensorineural hearing loss was found to affect not exclusively, 
nor at first, the sensory cells of the inner ear. The sensory cells' synapses 
and subsequent neurites are initially damaged. Auditory synaptopathies also play 
an important role in cochlear implant (CI) care, as they can lead to a loss of 
physiological hearing in patients with residual hearing. These auditory 
synaptopathies and in general the cascades of hearing pathologies have been in 
the focus of research in recent years with the aim to develop more targeted and 
individually tailored therapeutics. In the current study, a method to examine 
implanted inner ears of guinea pigs was developed to examine the synapse level. 
For this purpose, the cochlea is made transparent and scanned with the implant 
in situ using confocal laser scanning microscopy. Three different preparation 
methods were compared to enable both an overview image of the cochlea for 
assessing the CI position and images of the synapses on the same specimen. The 
best results were achieved by dissection of the bony capsule of the cochlea.

DOI: 10.3390/life11040301
PMCID: PMC8066088
PMID: 33915846

Conflict of interest statement: The authors declare no conflict of interest. The 
funders had no role in the design of the study; in the collection, analyses, or 
interpretation of date; in the writing of the manuscript, or in the decision to 
publish the results.


723. Brain Inform. 2024 Jan 14;11(1):3. doi: 10.1186/s40708-023-00214-7.

Synergistic integration of Multi-View Brain Networks and advanced machine 
learning techniques for auditory disorders diagnostics.

Ahmed MAO(1), Satar YA(2), Darwish EM(3)(4), Zanaty EA(5).

Author information:
(1)Department of Computer Science, Faculty of Computers and Information, Luxor 
University, 85951, Luxor, Egypt. mao.khfagy@fci.luxor.edu.eg.
(2)Mathematics Department, Faculty of Science, Sohag University, 82511, Sohag, 
Egypt.
(3)Physics Department, College of Science, Taibah University, Medina, 41411, 
Saudi Arabia.
(4)Physics Department, Faculty of Science, Sohag University, 82524, Sohag, 
Egypt.
(5)Department of Computer Science, Faculty of Computers and Artificial 
Intelligence, Sohag University, 82511, Sohag, Egypt.

In the field of audiology, achieving accurate discrimination of auditory 
impairments remains a formidable challenge. Conditions such as deafness and 
tinnitus exert a substantial impact on patients' overall quality of life, 
emphasizing the urgent need for precise and efficient classification methods. 
This study introduces an innovative approach, utilizing Multi-View Brain Network 
data acquired from three distinct cohorts: 51 deaf patients, 54 with tinnitus, 
and 42 normal controls. Electroencephalogram (EEG) recording data were 
meticulously collected, focusing on 70 electrodes attached to an end-to-end key 
with 10 regions of interest (ROI). This data is synergistically integrated with 
machine learning algorithms. To tackle the inherently high-dimensional nature of 
brain connectivity data, principal component analysis (PCA) is employed for 
feature reduction, enhancing interpretability. The proposed approach undergoes 
evaluation using ensemble learning techniques, including Random Forest, Extra 
Trees, Gradient Boosting, and CatBoost. The performance of the proposed models 
is scrutinized across a comprehensive set of metrics, encompassing 
cross-validation accuracy (CVA), precision, recall, F1-score, Kappa, and 
Matthews correlation coefficient (MCC). The proposed models demonstrate 
statistical significance and effectively diagnose auditory disorders, 
contributing to early detection and personalized treatment, thereby enhancing 
patient outcomes and quality of life. Notably, they exhibit reliability and 
robustness, characterized by high Kappa and MCC values. This research represents 
a significant advancement in the intersection of audiology, neuroimaging, and 
machine learning, with transformative implications for clinical practice and 
care.

© 2023. The Author(s).

DOI: 10.1186/s40708-023-00214-7
PMCID: PMC10788326
PMID: 38219249

Conflict of interest statement: The authors assert no contending interests.


724. Arch Public Health. 2020 Mar 6;78:16. doi: 10.1186/s13690-020-0398-1. 
eCollection 2020.

Field-testing of a rapid survey method to assess the prevalence and causes of 
hearing loss in Gao'an, Jiangxi province, China.

Bright T(1), Shan X(2), Xu J(2), Liang J(2), Xiao B(3), Ensink R(4), Mactaggart 
I(1), Polack S(1), Yip JLY(1).

Author information:
(1)1International Centre for Evidence in Disability, London School of Hygiene & 
Tropical Medicine, Keppel St, London, WC1 E7HT United Kingdom.
(2)Gao'an City People's Hospital, Gao'an, Jiangxi China.
(3)3Zhongshan Opthalmic Centre, Sun Yatsen University, Guangzhou, Guangdong 
China.
(4)4Department of Oto-rhino-laryngology, Gelre Hospitals, Zutphen, The 
Netherlands.

BACKGROUND: The Rapid Assessment of Hearing Loss (RAHL) survey protocol aims to 
measure the prevalence and causes of hearing loss in a low cost and rapid 
manner, to inform planning of ear and hearing services. This paper reports on 
the first field-test of the RAHL in Gao'an County, Jiangxi Province, China. This 
study aimed to 1) To report on the feasibility of RAHL; 2) report on the 
estimated prevalence and causes of hearing loss in Gao'an.
METHODS: A cross-sectional population-based survey was conducted in 
September-October 2018. Forty-seven clusters in Gao'an County were selected 
using probability-proportionate-to-size sampling. Within clusters, compact 
segment sampling was conducted to select 30 people aged 50+. A questionnaire was 
completed covering sociodemographics, hearing health, and risk factors. 
Automated pure-tone audiometry was completed for all participants, using 
smartphone-based audiometry (hearTest), at 0.5, 1, 2, 4 kHz (kHz). All 
participants had their ears examined by an Ear Nose and Throat (ENT) doctor, 
using otoscopy, and probable causes of hearing loss assigned. Prevalence 
estimates were age and sex standardised to the Jiangxi population. Feasibility 
of a cluster size of 30 was examined by assessing the response rate, and the 
proportion of clusters completed in 1 day.
RESULTS: 1344 of 1421 eligible participants completed the survey (94.6%). 100% 
of clusters were completed in 1 day. The survey was completed in 4.5 weeks. The 
prevalence of moderate or greater hearing loss (pure-tone average of 0.5, 1, 2, 
4 kHz of > = 41dBHL in the better ear) was 16.3% (95% CI = 14.3, 18.5) and for 
any level of hearing loss (pure-tone average of > = 26dBHL in the better ear) 
the prevalence was 53.2% (95% CI = 49.2, 57.1). The majority of hearing loss was 
due to acquired sensorineural causes (91.7% left; 92.1% right). Overall 54.0% of 
the population aged 50+ (108,000 people) are in need of diagnostic audiology 
services, 3.4% were in need of wax removal (7000 people), and 4.8% were in need 
of surgical services (9500 people). Hearing aid coverage was 0.4%.
CONCLUSION: The RAHL survey protocol is feasible, demonstrated through the 
number of people examined per day, and the high response rate. The survey was 
completed in a much shorter period than previous all-age surveys in China. Some 
remaining challenges included assignment of causes of probable sensorineural 
loss. The data obtained from this survey can be used to scale-up hearing 
services in Gao'an.

© The Author(s). 2020.

DOI: 10.1186/s13690-020-0398-1
PMCID: PMC7059708
PMID: 32166026

Conflict of interest statement: Competing interestsThe authors declare that they 
have no competing interests.


725. Annu Rev Neurosci. 2019 Jul 8;42:67-86. doi: 
10.1146/annurev-neuro-070918-050428. Epub 2019 Jan 30.

Genes Involved in the Development and Physiology of Both the Peripheral and 
Central Auditory Systems.

Michalski N(1)(2)(3), Petit C(1)(2)(3)(4)(5).

Author information:
(1)Unité de Génétique et Physiologie de l'Audition, Institut Pasteur, 75015 
Paris, France; email: nicolas.michalski@pasteur.fr , christine.petit@pasteur.fr.
(2)Institut National de la Santé et de la Recherche Médicale, UMRS 1120, 75015 
Paris, France.
(3)Sorbonne Universités, 75005 Paris, France.
(4)Syndrome de Usher et Autres Atteintes Rétino-Cochléaires, Institut de la 
Vision, 75012 Paris, France.
(5)Collège de France, 75005 Paris, France.

The genetic approach, based on the study of inherited forms of deafness, has 
proven to be particularly effective for deciphering the molecular mechanisms 
underlying the development of the peripheral auditory system, the cochlea and 
its afferent auditory neurons, and how this system extracts the physical 
parameters of sound. Although this genetic dissection has provided little 
information about the central auditory system, scattered data suggest that some 
genes may have a critical role in both the peripheral and central auditory 
systems. Here, we review the genes controlling the development and function of 
the peripheral and central auditory systems, focusing on those with demonstrated 
intrinsic roles in both systems and highlighting the current underappreciation 
of these genes. Their encoded products are diverse, from transcription factors 
to ion channels, as are their roles in the central auditory system, mostly 
evaluated in brainstem nuclei. We examine the ontogenetic and evolutionary 
mechanisms that may underlie their expression at different sites.

DOI: 10.1146/annurev-neuro-070918-050428
PMID: 30699050 [Indexed for MEDLINE]


726. Front Neurosci. 2023 Mar 24;17:1134153. doi: 10.3389/fnins.2023.1134153. 
eCollection 2023.

Resveratrol prevents hearing loss and a subregion specific- reduction of 
serotonin reuptake transporter induced by noise exposure in the central auditory 
system.

Cheng LQ(1)(2), Shu FQ(3), Zhang M(1)(2), Kai YZ(1), Tang ZQ(1)(2).

Author information:
(1)School of Life Sciences, Anhui University, Hefei, China.
(2)Key Laboratory of Human Microenvironment and Precision Medicine of Anhui 
Higher Education Institutes, Anhui University, Hefei, China.
(3)Institute of Artificial Intelligence, Hefei Comprehensive National Science 
Center, Hefei, China.

Prolonged or excessive exposure to noise can lead to hearing loss, tinnitus and 
hypersensitivity to sound. The effects of noise exposure on main excitatory and 
inhibitory neurotransmitter systems in auditory pathway have been extensively 
investigated. However, little is known about aberrant changes in neuromodulator 
systems caused by noise exposure. In the current study, we exposed 2-month-old 
mice to a narrow band noise at 116 dB SPL for 6 h or sham exposure, assessed 
auditory brainstem responses as well as examined the expression of serotonin 
reuptake transporter (SERT) in the cochlear nucleus (CN), inferior colliculus 
(IC), and primary auditory cortex (Au1) using immunohistochemistry. We found 
that noise exposure resulted in a significant increase in hearing thresholds at 
4, 8, 16, 24, and 32 kHz, as well as led to a significant reduction of SERT in 
dorsal cochlear nucleus (DCN), dorsal IC (ICd), external IC (ICe), and Au1 
layers I-IV. This reduction of SERT in these subregions of central auditory 
system was partially recovered 15 or 30 days after noise exposure. Furthermore, 
we examined efficacy of resveratrol (RSV) on hearing loss and loss of SERT 
induced by noise exposure. The results demonstrated that RSV treatment 
significantly attenuated threshold shifts of auditory brainstem responses and 
loss of SERT in DCN, ICd, ICe, and Au1 layers I-IV. These findings show that 
noise exposure can cause hearing loss and subregion-specific loss of SERT in the 
central auditory system, and RSV treatment could attenuate noise 
exposure-induced hearing loss and loss of SERT in central auditory system.

Copyright © 2023 Cheng, Shu, Zhang, Kai and Tang.

DOI: 10.3389/fnins.2023.1134153
PMCID: PMC10080035
PMID: 37034161

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


727. Front Neurol. 2022 Aug 26;13:933940. doi: 10.3389/fneur.2022.933940. eCollection 
2022.

Profiling hearing aid users through big data explainable artificial intelligence 
techniques.

Iliadou E(1), Su Q(2), Kikidis D(1), Bibas T(1), Kloukinas C(2).

Author information:
(1)1st Department of Otorhinolaryngology-Head and Neck Surgery, National and 
Kapodistrian University of Athens Medical School, Athens, Greece.
(2)Department of Computer Science, University of London, London, United Kingdom.

Debilitating hearing loss (HL) affects ~6% of the human population. Only 20% of 
the people in need of a hearing assistive device will eventually seek and 
acquire one. The number of people that are satisfied with their Hearing Aids 
(HAids) and continue using them in the long term is even lower. Understanding 
the personal, behavioral, environmental, or other factors that correlate with 
the optimal HAid fitting and with users' experience of HAids is a significant 
step in improving patient satisfaction and quality of life, while reducing 
societal and financial burden. In SMART BEAR we are addressing this need by 
making use of the capacity of modern HAids to provide dynamic logging of their 
operation and by combining this information with a big amount of information 
about the medical, environmental, and social context of each HAid user. We are 
studying hearing rehabilitation through a 12-month continuous monitoring of HL 
patients, collecting data, such as participants' demographics, audiometric and 
medical data, their cognitive and mental status, their habits, and preferences, 
through a set of medical devices and wearables, as well as through face-to-face 
and remote clinical assessments and fitting/fine-tuning sessions. Descriptive, 
AI-based analysis and assessment of the relationships between heterogeneous data 
and HL-related parameters will help clinical researchers to better understand 
the overall health profiles of HL patients, and to identify patterns or 
relations that may be proven essential for future clinical trials. In addition, 
the future state and behavioral (e.g., HAids Satisfiability and HAids usage) of 
the patients will be predicted with time-dependent machine learning models to 
assist the clinical researchers to decide on the nature of the interventions. 
Explainable Artificial Intelligence (XAI) techniques will be leveraged to better 
understand the factors that play a significant role in the success of a hearing 
rehabilitation program, constructing patient profiles. This paper is a 
conceptual one aiming to describe the upcoming data collection process and 
proposed framework for providing a comprehensive profile for patients with HL in 
the context of EU-funded SMART BEAR project. Such patient profiles can be 
invaluable in HL treatment as they can help to identify the characteristics 
making patients more prone to drop out and stop using their HAids, using their 
HAids sufficiently long during the day, and being more satisfied by their HAids 
experience. They can also help decrease the number of needed remote sessions 
with their Audiologist for counseling, and/or HAids fine tuning, or the number 
of manual changes of HAids program (as indication of poor sound quality and bad 
adaptation of HAids configuration to patients' real needs and daily challenges), 
leading to reduced healthcare cost.

Copyright © 2022 Iliadou, Su, Kikidis, Bibas and Kloukinas.

DOI: 10.3389/fneur.2022.933940
PMCID: PMC9459083
PMID: 36090867

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


728. J Am Acad Audiol. 2023 Jan 19. doi: 10.1055/a-2015-8524. Online ahead of print.

PTSD is associated with self-perceived hearing handicap: An evaluation of 
comorbidities in Veterans with normal audiometric thresholds.

Jedlicka D(1)(2), Zhen L(3)(4).

Author information:
(1)Audiology, VA Pittsburgh Healthcare System, Pittsburgh, United States.
(2)University of Pittsburgh, Pittsburgh, United States.
(3)Communication Science and Disorders, University of Pittsburgh, Pittsburgh, 
United States.
(4)VA Pittsburgh Healthcare System, Pittsburgh, United States.

Background Cases of self-reported hearing difficulty despite normal audiometric 
results have risen with the return of Veterans from recent conflicts in 
Operation Enduring Freedom, Operation Iraqi Freedom, and Operation New Dawn. 
Auditory outcomes improved despite low compliance among those receiving 
treatment. Medical chart data appeared more comprehensive for Veterans with, 
rather than without, auditory complaints. One possibility is that self-reported 
hearing problems are associated with a subset of these comorbidities, the 
treatment of which improved auditory outcomes. Purpose This study examined the 
relationships between Veterans' self-reported auditory problems and other 
diagnosed medical conditions. Research Design A retrospective chart review was 
used. Study Sample Participants were 286 Veterans, aged 21 - 52 with normal 
hearing. Veterans were dichotomized into a group with either self-reported 
hearing complaints (n = 143) or an aged-matched control group with no auditory 
complaints (n = 143). Data Collection and Analysis A query of the Computerized 
Patient Record System was performed with the date range restricted to 2009 to 
2018. Metrics of self-perceived hearing handicap, APD testing, and hearing aid 
use were collected. All diagnoses and related symptoms were recorded. A best 
subsets regression with principled model selection was performed to investigate 
the role of these comorbidities on self-perceived hearing loss. Results The 
Self-Report group had 16 comorbidities that were classified as prevalent, having 
occurred in ≥33.3% of the group, compared to the age-matched control group, 
which had 2 comorbidities. The number of diagnosed medical conditions was 
associated with self-perceived hearing impairment. Specifically, posttraumatic 
stress disorder (PTSD) and related symptom clusters constituted the largest 
group of comorbidities that were significantly associated with self-reported 
hearing problems. Conclusions The significant association between PTSD and 
self-perceived hearing impairment warrants investigations on whether treatment 
of PTSD would reduce perceived hearing handicap severity. Further, PTSD 
assessments could be useful for audiologists to identify potential candidates 
for auditory complaints with normal audiometric thresholds. Keywords: Auditory 
processing disorder, hidden hearing loss, comorbidities, Veterans, posttraumatic 
stress disorder, traumatic brain injury Abbreviations: APD, auditory processing 
disorder; CAP, central auditory processing; HHIA, Hearing Handicap Inventory for 
Adults; mTBI, mild traumatic brain injury; PTSD, posttraumatic stress disorder; 
TBI, traumatic brain injury; U.S., United States.

American Academy of Audiology. This article is published by Thieme.

DOI: 10.1055/a-2015-8524
PMID: 36657469

Conflict of interest statement: The authors declare that they have no conflict 
of interest.


729. J Clin Med. 2024 Mar 4;13(5):1476. doi: 10.3390/jcm13051476.

Can Multifrequency Tympanometry Be Used in the Diagnosis of Meniere's Disease? A 
Systematic Review and Meta-Analysis.

Tsilivigkos C(1), Vitkos EN(2), Ferekidis E(1), Warnecke A(3)(4).

Author information:
(1)First Department of Otolaryngology, Hippokration General Hospital, National 
and Kapodistrian University of Athens, 15772 Athens, Greece.
(2)Department of Oral and Maxillofacial Surgery, George Papanikolaou General 
Hospital, 56429 Thessaloniki, Greece.
(3)Department of Otorhinolaryngology-Head and Neck Surgery, Hannover Medical 
School, 30625 Hanover, Germany.
(4)Cluster of Excellence Hearing4all, German Research Foundation, 30625 
Hannover, Germany.

(1) Background: Ménière's disease (MD) is a disease of the inner ear, presenting 
with episodes of vertigo, hearing loss, and tinnitus.The aim of this study is to 
examine the role of multifrequency tympanometry (MFT) in the diagnosis of MD. 
(2) Methods: A systematic review of MEDLINE (via PubMed), Scopus, Google 
Scholar, and the Cochrane Library was performed, aligned with the PRISMA 
guidelines. Only studies that directly compare ears affected by Ménière's 
disease with unaffected or control ears were included. Random-effects model 
meta-analyses were performed. (3) Results: Seven prospective case-control 
studies reported a total of 899 ears, 282 of which were affected by Ménière's 
disease (affected ears-AE), 197 unaffected ears in patients with MD (UE), and 
420 control ears (CE) in healthy controls. No statistically significant 
differences between the groups were observed regarding resonant frequency (RF). 
The pure tone audiometry average of the lower frequencies (PTA basic) was 
significantly greater in affected ears when compared with unaffected ears. The 
conductance tympanogram at 2 kHz revealed a statistically significantly greater 
G width of 2 kHz in the affected ears when compared to both unaffected and 
control ears, while control ears had a statistically significant lesser G width 
of 2 kHz compared to both the other two groups. (4) Conclusions: MFT, and 
specifically G width at 2 kHz, could be an important tool in the diagnosis of 
MD.

DOI: 10.3390/jcm13051476
PMCID: PMC10932169
PMID: 38592318

Conflict of interest statement: The authors declare no conflicts of interest.


730. Front Neurosci. 2023 Aug 10;17:1224463. doi: 10.3389/fnins.2023.1224463. 
eCollection 2023.

"Of mice and men": the relevance of Cometin and Erythropoietin origin for its 
effects on murine spiral ganglion neuron survival and neurite outgrowth in 
vitro.

Schwieger J(1)(2)(3), Gao Z(1)(4), Lenarz T(1)(2)(3), Munro G(5), Petersen 
KA(5), Scheper V(1)(2)(3).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(2)Lower Saxony Center for Biomedical Engineering, Implant Research and 
Development (NIFE), Hannover, Germany.
(3)Cluster of Excellence "Hearing4all" EXC 1077/2, Hannover, Germany.
(4)Ear Nose and Throat Institute and Department of Otorhinolaryngology, Eye & 
ENT Hospital, Fudan University, Shanghai, China.
(5)Hoba Therapeutics ApS, Copenhagen, Denmark.

Neurotrophic factors (NTF) play key roles in the survival of neurons, making 
them promising candidates for therapy of neurodegenerative diseases. In the case 
of the inner ear, sensorineural hearing loss (SNHL) is characterized over time 
by a degeneration of the primary auditory neurons, the spiral ganglion neurons 
(SGN). It is well known that selected NTF can protect SGN from degeneration, 
which positively influences the outcome of cochlear implants, the treatment of 
choice for patients with profound to severe SNHL. However, the outcome of 
studies investigating protective effects of NTF on auditory neurons are in some 
cases of high variability. We hypothesize that the factor origin may be one 
aspect that affects the neuroprotective potential. The aim of this study was to 
investigate the neuroprotective potential of human and mouse Erythropoietin 
(EPO) and Cometin on rat SGN. SGN were isolated from neonatal rats (P 2-5) and 
cultured in serum-free medium. EPO and Cometin of mouse and human origin were 
added in concentrations of 0.1, 1, and 10 ng/mL and 0.1, 1, and 10 μg/mL, 
respectively. The SGN survival rate and morphology, and the neurite outgrowth 
were determined and compared to negative (no additives) and positive 
(brain-derived neurotrophic factor, BDNF) controls. A neuroprotective effect of 
10 μg/mL human Cometin comparable to that obtained with BDNF was observed in the 
SGN-culture. In contrast, mouse Cometin was ineffective. A similar influence of 
10 μg/mL human and mouse and 1 μg/mL human Cometin on the length of regenerated 
neurites compared to BDNF was also detected. No other Cometin-conditions, and 
none of the EPO-conditions tested had neuroprotective or neuritogenic effects or 
influenced the neuronal morphology of the SGN. The neuroprotective effect of 
10 μg/mL human Cometin on SGN indicates it is a potentially interesting protein 
for the supportive treatment of inner ear disorders. The finding that mouse 
Cometin had no effect on the SGN in the parallel-performed experiments 
underlines the importance of species origin of molecules being screened for 
therapeutic purpose.

Copyright © 2023 Schwieger, Gao, Lenarz, Munro, Petersen and Scheper.

DOI: 10.3389/fnins.2023.1224463
PMCID: PMC10450246
PMID: 37638326

Conflict of interest statement: Authors GM and KP were employed by company Hoba 
Therapeutics ApS. All authors declare that this study received funding from Hoba 
Therapeutics ApS. This funder had the following involvement in the study: 
contribution of reagents and materials, study design, and preparation of the 
manuscript.


731. Front Mol Neurosci. 2021 Jan 7;13:600051. doi: 10.3389/fnmol.2020.600051. 
eCollection 2020.

Overloaded Adeno-Associated Virus as a Novel Gene Therapeutic Tool for 
Otoferlin-Related Deafness.

Rankovic V(1)(2), Vogl C(1)(3)(4), Dörje NM(1)(3), Bahader I(4)(5), Duque-Afonso 
CJ(1)(6)(7), Thirumalai A(1), Weber T(1), Kusch K(1)(2), Strenzke N(4)(5), Moser 
T(1)(4)(6)(7)(8)(9).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Restorative Cochlear Genomics Group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(3)Presynaptogenesis and Intracellular Transport in Hair Cells Group, Institute 
for Auditory Neuroscience and InnerEarLab, University Medical Center Göttingen, 
Göttingen, Germany.
(4)Collaborative Research Center 889, University of Göttingen, Göttingen, 
Germany.
(5)Auditory Systems Physiology Group, Institute for Auditory Neuroscience and 
Department of Otolaryngology, University Medical Center Göttingen, Göttingen, 
Germany.
(6)Auditory Neuroscience Group, Max Planck Institute of Experimental Medicine, 
Göttingen, Germany.
(7)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
Göttingen, Germany.
(8)Synaptic Nanophysiology Group, Max Planck Institute of Biophysical Chemistry, 
Göttingen, Germany.
(9)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.

Hearing impairment is the most common sensory disorder in humans. So far, 
rehabilitation of profoundly deaf subjects relies on direct stimulation of the 
auditory nerve through cochlear implants. However, in some forms of genetic 
hearing impairment, the organ of Corti is structurally intact and therapeutic 
replacement of the mutated gene could potentially restore near natural hearing. 
In the case of defects of the otoferlin gene (OTOF), such gene therapy is 
hindered by the size of the coding sequence (~6 kb) exceeding the cargo capacity 
(<5 kb) of the preferred viral vector, adeno-associated virus (AAV). Recently, a 
dual-AAV approach was used to partially restore hearing in deaf otoferlin 
knock-out (Otof-KO) mice. Here, we employed in vitro and in vivo approaches to 
assess the gene-therapeutic potential of naturally-occurring and newly-developed 
synthetic AAVs overloaded with the full-length Otof coding sequence. Upon early 
postnatal injection into the cochlea of Otof-KO mice, overloaded AAVs drove 
specific expression of otoferlin in ~30% of all IHCs, as demonstrated by 
immunofluorescence labeling and polymerase chain reaction. Recordings of 
auditory brainstem responses and a behavioral assay demonstrated partial 
restoration of hearing. Together, our results suggest that viral gene therapy of 
DFNB9-using a single overloaded AAV vector-is indeed feasible, reducing the 
complexity of gene transfer compared to dual-AAV approaches.

Copyright © 2021 Rankovic, Vogl, Dörje, Bahader, Duque-Afonso, Thirumalai, 
Weber, Kusch, Strenzke and Moser.

DOI: 10.3389/fnmol.2020.600051
PMCID: PMC7817888
PMID: 33488357

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


732. Front Neurosci. 2022 Mar 28;16:850245. doi: 10.3389/fnins.2022.850245. 
eCollection 2022.

Brain Morphological Modifications in Congenital and Acquired Auditory 
Deprivation: A Systematic Review and Coordinate-Based Meta-Analysis.

Grégoire A(1)(2), Deggouj N(1)(2), Dricot L(2), Decat M(1)(2), Kupers 
R(2)(3)(4).

Author information:
(1)Department of ENT, Cliniques Universitaires Saint-Luc, Brussels, Belgium.
(2)Institute of NeuroScience (IoNS), UCLouvain, Brussels, Belgium.
(3)Department of Neuroscience, Panum Institute, University of Copenhagen, 
Copenhagen, Denmark.
(4)Ecole d'Optométrie, Université de Montréal, Montréal, QC, Canada.

Erratum in
    Front Neurosci. 2024 Jan 22;18:1354571.

Neuroplasticity following deafness has been widely demonstrated in both humans 
and animals, but the anatomical substrate of these changes is not yet clear in 
human brain. However, it is of high importance since hearing loss is a growing 
problem due to aging population. Moreover, knowing these brain changes could 
help to understand some disappointing results with cochlear implant, and 
therefore could improve hearing rehabilitation. A systematic review and a 
coordinate-based meta-analysis were realized about the morphological brain 
changes highlighted by MRI in severe to profound hearing loss, congenital and 
acquired before or after language onset. 25 papers were included in our review, 
concerning more than 400 deaf subjects, most of them presenting prelingual 
deafness. The most consistent finding is a volumetric decrease in gray matter 
around bilateral auditory cortex. This change was confirmed by the 
coordinate-based meta-analysis which shows three converging clusters in this 
region. The visual areas of deaf children is also significantly impacted, with a 
decrease of the volume of both gray and white matters. Finally, deafness is 
responsible of a gray matter increase within the cerebellum, especially at the 
right side. These results are largely discussed and compared with those from 
deaf animal models and blind humans, which demonstrate for example a much more 
consistent gray matter decrease along their respective primary sensory pathway. 
In human deafness, a lot of other factors than deafness could interact on the 
brain plasticity. One of the most important is the use of sign language and its 
age of acquisition, which induce among others changes within the hand motor 
region and the visual cortex. But other confounding factors exist which have 
been too little considered in the current literature, such as the etiology of 
the hearing impairment, the speech-reading ability, the hearing aid use, the 
frequent associated vestibular dysfunction or neurocognitive impairment. Another 
important weakness highlighted by this review concern the lack of papers about 
postlingual deafness, whereas it represents most of the deaf population. Further 
studies are needed to better understand these issues, and finally try to improve 
deafness rehabilitation.

Copyright © 2022 Grégoire, Deggouj, Dricot, Decat and Kupers.

DOI: 10.3389/fnins.2022.850245
PMCID: PMC8995770
PMID: 35418829

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


733. Front Mol Neurosci. 2017 Dec 4;10:401. doi: 10.3389/fnmol.2017.00401. 
eCollection 2017.

Loss of CIB2 Causes Profound Hearing Loss and Abolishes Mechanoelectrical 
Transduction in Mice.

Wang Y(1)(2), Li J(3), Yao X(1)(2), Li W(1)(2), Du H(1)(2), Tang M(4)(5), Xiong 
W(3), Chai R(4)(5)(6), Xu Z(1)(2).

Author information:
(1)Shandong Provincial Key Laboratory of Animal Cells and Developmental Biology, 
School of Life Sciences, Shandong University, Jinan, China.
(2)Shandong Provincial Collaborative Innovation Center of Cell Biology, Shandong 
Normal University, Jinan, China.
(3)School of Life Sciences, IDG/McGovern Institute for Brain Research, Tsinghua 
University, Beijing, China.
(4)Key Laboratory for Developmental Genes and Human Disease, Ministry of 
Education, Institute of Life Sciences, Southeast University, Nanjing, China.
(5)Co-Innovation Center of Neuroregeneration, Nantong University, Nantong, 
China.
(6)Jiangsu Province High-Tech Key Laboratory for Bio-Medical Research, Southeast 
University, Nanjing, China.

Calcium and integrin-binding protein 2 (CIB2) belongs to a protein family with 
four known members, CIB1 through CIB4, which are characterized by multiple 
calcium-binding EF-hand domains. Among the family members, the Cib1 and Cib2 
genes are expressed in mouse cochlear hair cells, and mutations in the human 
CIB2 gene have been associated with nonsyndromic deafness DFNB48 and syndromic 
deafness USH1J. To further explore the function of CIB1 and CIB2 in hearing, we 
established Cib1 and Cib2 knockout mice using the clustered regularly 
interspaced short palindromic repeat (CRISPR)-associated Cas9 nuclease 
(CRISPR/Cas9) genome editing technique. We found that loss of CIB1 protein does 
not affect auditory function, whereas loss of CIB2 protein causes profound 
hearing loss in mice. Further investigation revealed that hair cell stereocilia 
development is affected in Cib2 knockout mice. Noticeably, loss of CIB2 
abolishes mechanoelectrical transduction (MET) currents in auditory hair cells. 
In conclusion, we show here that although both CIB1 and CIB2 are readily 
detected in the cochlea, only loss of CIB2 results in profound hearing loss, and 
that CIB2 is essential for auditory hair cell MET.

DOI: 10.3389/fnmol.2017.00401
PMCID: PMC5722843
PMID: 29255404


734. Ecotoxicol Environ Saf. 2021 Nov 30;228:113047. doi: 
10.1016/j.ecoenv.2021.113047. Online ahead of print.

Auditory evoked potential in stranded melon-headed whales (Peponocephala 
electra): With severe hearing loss and possibly caused by anthropogenic noise 
pollution.

Wang ZT(1), Supin AY(2), Akamatsu T(3), Duan PX(1), Yang YN(1), Wang KX(4), Wang 
D(5).

Author information:
(1)Key Laboratory of Aquatic Biodiversity and Conservation of the Chinese 
Academy of Sciences, Institute of Hydrobiology, Chinese Academy of Sciences, 7 
South Donghu Road, Wuhan 430072, China.
(2)Institute of Ecology and Evolution of the Russian Academy of Sciences, Moscow 
119071, Russia.
(3)Ocean Policy Research Institute, the Sasakawa Peace Foundation, Tokyo, Japan.
(4)Key Laboratory of Aquatic Biodiversity and Conservation of the Chinese 
Academy of Sciences, Institute of Hydrobiology, Chinese Academy of Sciences, 7 
South Donghu Road, Wuhan 430072, China. Electronic address: wangk@ihb.ac.cn.
(5)Key Laboratory of Aquatic Biodiversity and Conservation of the Chinese 
Academy of Sciences, Institute of Hydrobiology, Chinese Academy of Sciences, 7 
South Donghu Road, Wuhan 430072, China. Electronic address: wangd@ihb.ac.cn.

Highly concentrated live mass stranding events of dolphins and whales happened 
in the eastern coast of China between June and October 2021. The current study 
adopted the non-invasive auditory evoked-potential technique to investigate the 
hearing threshold of a stranded melon headed whale (Peponocephala electra) at a 
frequency range of between 9.5 and 181 kHz. It was found that, at the frequency 
range of from 10 to 100 kHz, hearing thresholds for the animal were between 20 
and 65 dB higher than those of its phylogenetically closest species (Pygmy 
killer whale). The severe hearing loss in the melon headed whale was probably 
caused by transient intense anthropogenic sonar or chronic shipping noise 
exposures. The hearing loss could have been the cause for the observed temporal 
and spatial clustered stranding events. Therefore, there is need for noise 
mitigation strategies to reduce noise exposure levels for marine mammals in the 
coastal areas of China.

Copyright © 2021 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ecoenv.2021.113047
PMID: 34861441


735. Hear Res. 2023 Feb;428:108667. doi: 10.1016/j.heares.2022.108667. Epub 2022 Dec 
15.

Universal automated classification of the acoustic startle reflex using machine 
learning.

Fawcett TJ(1), Longenecker RJ(2), Brunelle DL(3), Berger JI(4), Wallace MN(5), 
Galazyuk AV(6), Rosen MJ(6), Salvi RJ(7), Walton JP(8).

Author information:
(1)Global Center for Hearing and Speech Research, University of South Florida, 
Tampa, FL, USA; Research Computing, University of South Florida, Tampa, FL, USA. 
Electronic address: tfawcett@usf.edu.
(2)Sound Pharmaceuticals Inc, 4010 Stone Way N., Suite 120, Seattle, WA 98103, 
USA.
(3)Global Center for Hearing and Speech Research, University of South Florida, 
Tampa, FL, USA.
(4)Department of Neurosurgery, University of Iowa Hospitals and Clinics, Iowa 
City, IA, USA.
(5)Hearing Sciences, School of Medicine, University of Nottingham, Nottingham, 
UK.
(6)Hearing Research Group, Department of Anatomy and Neurobiology, Northeast 
Ohio Medical University, Rootstown, OH, USA.
(7)Center for Hearing and Deafness, University at Buffalo, University of 
Buffalo, USA.
(8)Global Center for Hearing and Speech Research, University of South Florida, 
Tampa, FL, USA; Department of Medical Engineering, University of South Florida, 
Tampa, FL, USA; Department of Communication Sciences and Disorders, University 
of South Florida, Tampa, FL, USA. Electronic address: jwalton1@usf.edu.

The startle reflex (SR), a robust, motor response elicited by an intense 
auditory, visual, or somatosensory stimulus has been widely used as a tool to 
assess psychophysiology in humans and animals for almost a century in diverse 
fields such as schizophrenia, bipolar disorder, hearing loss, and tinnitus. 
Previously, SR waveforms have been ignored, or assessed with basic statistical 
techniques and/or simple template matching paradigms. This has led to 
considerable variability in SR studies from different laboratories, and species. 
In an effort to standardize SR assessment methods, we developed a machine 
learning algorithm and workflow to automatically classify SR waveforms in 
virtually any animal model including mice, rats, guinea pigs, and gerbils 
obtained with various paradigms and modalities from several laboratories. The 
universal features common to SR waveforms of various species and paradigms are 
examined and discussed in the context of each animal model. The procedure 
describes common results using the SR across species and how to fully implement 
the open-source R implementation. Since SR is widely used to investigate 
toxicological or pharmaceutical efficacy, a detailed and universal SR waveform 
classification protocol should be developed to aid in standardizing SR 
assessment procedures across different laboratories and species. This machine 
learning-based method will improve data reliability and translatability between 
labs that use the startle reflex paradigm.

Copyright © 2022. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2022.108667
PMCID: PMC10734095
PMID: 36566642 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interests The authors 
declare that they have no competing financial interests.


736. Otol Neurotol Open. 2023 Mar 9;3(1):e028. doi: 10.1097/ONO.0000000000000028. 
eCollection 2023 Mar.

MRI Screening in Vestibular Schwannoma: A Deep Learning-based Analysis of 
Clinical and Audiometric Data.

Kortebein S(1), Gu S(2), Dai K(1), Zhao E(1), Riska K(1), Kaylie D(1), Hoa M(2).

Author information:
(1)Department of Head and Neck Surgery and Communication Sciences, Duke 
University School of Medicine, Durham, NC.
(2)Auditory Development and Restoration Program, NIDCD Otolaryngology 
Surgeon-Scientist Program, Division of Intramural Research, NIDCD/NIH, Bethesda, 
MD.

OBJECTIVE: To find a more objective method of assessing which patients should be 
screened for a vestibular schwannoma (VS) with magnetic resonance imaging (MRI) 
using a deep-learning algorithm to assess clinical and audiometric data.
MATERIALS AND METHODS: Clinical and audiometric data were collected for 592 
patients who received an audiogram between January 2015 and 2020 at Duke 
University Health Center with and without VS confirmed by MRI. These data were 
analyzed using a deep learning-based analysis to determine if the need for MRI 
screening could be assessed more objectively with adequate sensitivity and 
specificity.
RESULTS: Patients with VS showed slightly elevated, but not statistically 
significant, mean thresholds compared to those without. Tinnitus, gradual 
hearing loss, and aural fullness were more common in patients with VS. Of these, 
only the presence of tinnitus was statistically significant. Several machine 
learning algorithms were used to incorporate and model the collected clinical 
and audiometric data, but none were able to distinguish ears with and without 
confirmed VS. When tumor size was taken into account the analysis was still 
unable to distinguish a difference.
CONCLUSIONS: Using audiometric and clinical data, deep learning-based analyses 
failed to produce an adequately sensitive and specific model for the detection 
of patients with VS. This suggests that a specific pattern of audiometric 
asymmetry and clinical symptoms may not necessarily be predictive of the 
presence/absence of VS to a level that clinicians would be comfortable forgoing 
an MRI.

Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
of Otology & Neurotology, Inc.

DOI: 10.1097/ONO.0000000000000028
PMCID: PMC10950172
PMID: 38516318

Conflict of interest statement: MH is an Associate Editor for Otology & 
Neurotology Open and has been rescued from reviewing or making decisions for 
this manuscript.


737. Hear Res. 2022 Jan;413:108057. doi: 10.1016/j.heares.2020.108057. Epub 2020 Aug 
18.

Late electrically-evoked compound action potentials as markers for acute 
micro-lesions of spiral ganglion neurons.

Konerding W(1), Arenberg JG(2), Kral A(3), Baumhoff P(4).

Author information:
(1)Department of Experimental Otology, Hannover Medical School, Stadtfelddamm 
34, 30625 Hannover, Germany. Electronic address: 
konerding.wiebke@mh-hannover.de.
(2)Massachusetts Eye and Ear Infirmary, Harvard Medical School, 25 Shattuck 
Street, Boston, MA 02115, USA. Electronic address: 
Julie_Arenberg@MEEI.HARVARD.EDU.
(3)Department of Experimental Otology, Hannover Medical School, Stadtfelddamm 
34, 30625 Hannover, Germany; Cluster of Excellence "Hearing4all", Germany. 
Electronic address: kral.andrej@mh-hannover.de.
(4)Department of Experimental Otology, Hannover Medical School, Stadtfelddamm 
34, 30625 Hannover, Germany. Electronic address: baumhoff.peter@mh-hannover.de.

Cochlear implants (CIs) are the treatment of choice for profoundly hearing 
impaired people. It has been proposed that speech perception in CI users is 
influenced by the neural health (deafferentation, demyelination and 
degeneration) of the cochlea, which may be heterogeneous along an individual 
cochlea. Several options have been put forward to account for these local 
differences in neural health when fitting the speech processor settings, however 
with mixed results. The interpretation of the results is hampered by the fact 
that reliable markers of locally restricted changes in spiral ganglion neuron 
(SGN) health are lacking. The aim of the study was (i) to establish mechanical 
micro-lesions in the guinea pig as a model of heterogeneous SGN deafferentation 
and degeneration and (ii) to assess potential electrophysiological markers that 
can also be used in human subjects. First, we defined the extent of 
micro-lesions in normal hearing animals using acoustically-evoked compound 
action potentials (aCAPs); second, we measured electrically-evoked CAPs (eCAPs) 
before and after focal lesioning in neomycin-deafened and implanted animals. 
Therefore, we inserted guinea pig adjusted 6-contact CIs through a cochleostomy 
in the scala tympani. The eCAP was recorded from a ball electrode at the round 
window niche in response to monopolar or bipolar, 50 µs/phase biphasic pulses of 
alternating anodic- and cathodic-leading polarity. To exclude the large 
electrical artifact from the analysis, we focused on the late eCAP component. We 
systematically isolated the eCAP parameter that showed local pre- versus 
post-lesion changes and lesion-target specificity. Histological evaluation of 
the cleared cochleae revealed focal damage of an average size of 0.0036 mm3 with 
an apical-basal span of maximal 440 µm. We found that the threshold of the late 
N2P2 eCAP component was significantly elevated after lesioning when stimulating 
at basal (near the lesion), but not apical (distant to the lesion) CI contacts. 
To circumvent the potentially conflicting influence of the apical-basal gradient 
in eCAP thresholds, we used the polarity effect (PE=cathodic-anodic) as a 
relative measure. During monopolar stimulation, but not bipolar stimulation, the 
PE was sensitive to the lesion target and showed significantly better cathodic 
than anodic thresholds after soma lesions. We conclude that the difference in 
N2P2 thresholds in response to cathodic versus anodic-leading monopolar 
stimulation corresponds to the presence of SGN soma damage, and may therefore be 
a marker for SGN loss. We consider this electrophysiological estimate of local 
neural health a potentially relevant tool for human applications because of the 
temporal separation from the stimulation artifact and possible implementation 
into common eCAP measurements.

Copyright © 2020. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2020.108057
PMID: 32883545 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest None.


738. Audiol Res. 2018 Nov 21;8(2):215. doi: 10.4081/audiores.2018.215. eCollection 
2018 Oct 2.

Effects of directional hearing aid settings on different laboratory measures of 
spatial awareness perception.

Lundbeck M(1)(2), Grimm G(1)(2), Hohmann V(1)(2), Bramsløw L(3), Neher T(4).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all", Oldenburg 
University, Oldenburg, Germany.
(2)HörTech gGmbH, Oldenburg, Germany.
(3)Eriksholm Research Centre, Snekkersten, Denmark.
(4)Institute of Clinical Research, University of Southern Denmark, Odense, 
Denmark.

Hearing loss can negatively influence the spatial hearing abilities of 
hearing-impaired listeners, not only in static but also in dynamic auditory 
environments. Therefore, ways of addressing these deficits with advanced hearing 
aid algorithms need to be investigated. In a previous study based on virtual 
acoustics and a computer simulation of different bilateral hearing aid fittings, 
we investigated auditory source movement detectability in older hearing- 
impaired (OHI) listeners. We found that two directional processing algorithms 
could substantially improve the detectability of left-right and near-far source 
movements in the presence of reverberation and multiple interfering sounds. In 
the current study, we carried out similar measurements with a loudspeaker-based 
setup and wearable hearing aids. We fitted a group of 15 OHI listeners with 
bilateral behind-the-ear devices that were programmed to have three different 
directional processing settings. Apart from source movement detectability, we 
assessed two other aspects of spatial awareness perception. Using a street scene 
with up to five environmental sound sources, the participants had to count the 
number of presented sources or to indicate the movement direction of a single 
target signal. The data analyses showed a clear influence of the number of 
concurrent sound sources and the starting position of the moving target signal 
on the participants' performance, but no influence of the different hearing aid 
settings. Complementary artificial head recordings showed that the acoustic 
differences between the three hearing aid settings were rather small. Another 
explanation for the lack of effects of the tested hearing aid settings could be 
that the simulated street scenario was not sufficiently sensitive. Possible ways 
of improving the sensitivity of the laboratory measures while maintaining high 
ecological validity and complexity are discussed.

DOI: 10.4081/audiores.2018.215
PMCID: PMC6275462
PMID: 30581544

Conflict of interest statement: Conflict of interest: Oticon A/S provided the 
hearing aids, laboratory space, and administrative and technical support for the 
study.


739. Front Digit Health. 2021 Aug 18;3:723533. doi: 10.3389/fdgth.2021.723533. 
eCollection 2021.

Using Machine Learning and the National Health and Nutrition Examination Survey 
to Classify Individuals With Hearing Loss.

Ellis GM(1), Souza PE(1)(2).

Author information:
(1)Department of Communication Sciences and Disorders, Northwestern University, 
Evanston, IL, United States.
(2)Knowles Hearing Center, Evanston, IL, United States.

Even before the COVID-19 pandemic, there was mounting interest in remote testing 
solutions for audiology. The ultimate goal of such work was to improve access to 
hearing healthcare for individuals that might be unable or reluctant to seek 
audiological help in a clinic. In 2015, Diane Van Tasell patented a method for 
measuring an audiogram when the precise signal level was unknown (patent US 
8,968,209 B2). In this method, the slope between pure-tone thresholds measured 
at 2 and 4 kHz is calculated and combined with questionnaire information in 
order to reconstruct the most likely audiograms from a database of options. An 
approach like the Van Tasell method is desirable because it is quick and 
feasible to do in a patient's home where exact stimulus levels are unknown. The 
goal of the present study was to use machine learning to assess the 
effectiveness of such audiogram-estimation methods. The National Health and 
Nutrition Examination Survey (NHANES), a database of audiologic and demographic 
information, was used to train and test several machine learning algorithms. 
Overall, 9,256 cases were analyzed. Audiometric data were classified using the 
Wisconsin Age-Related Hearing Impairment Classification Scale (WARHICS), a 
method that places hearing loss into one of eight categories. Of the algorithms 
tested, a random forest machine learning algorithm provided the best fit with 
only a few variables: the slope between 2 and 4 kHz; gender; age; military 
experience; and self-reported hearing ability. Using this method, 54.79% of the 
individuals were correctly classified, 34.40% were predicted to have a milder 
loss than measured, and 10.82% were predicted to have a more severe loss than 
measured. Although accuracy was low, it is unlikely audibility would be severely 
affected if classifications were used to apply gains. Based on audibility 
calculations, underamplification still provided sufficient gain to achieve ~95% 
correct (Speech Intelligibility Index ≥ 0.45) for sentence materials for 88% of 
individuals. Fewer than 1% of individuals were overamplified by 10 dB for any 
audiometric frequency. Given these results, this method presents a promising 
direction toward remote assessment; however, further refinement is needed before 
use in clinical fittings.

Copyright © 2021 Ellis and Souza.

DOI: 10.3389/fdgth.2021.723533
PMCID: PMC8521948
PMID: 34713189

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


740. J Acoust Soc Am. 2017 Feb;141(2):1051. doi: 10.1121/1.4976054.

Predicting consonant recognition and confusions in normal-hearing listeners.

Zaar J(1), Dau T(1).

Author information:
(1)Hearing Systems Group, Department of Electrical Engineering, Technical 
University of Denmark, DK-2800 Kongens Lyngby, Denmark.

The perception of consonants in background noise has been investigated in 
various studies and was shown to critically depend on fine details in the 
stimuli. In this study, a microscopic speech perception model is proposed that 
represents an extension of the auditory signal processing model by Dau, 
Kollmeier, and Kohlrausch [(1997). J. Acoust. Soc. Am. 102, 2892-2905]. The 
model was evaluated based on the extensive consonant perception data set 
provided by Zaar and Dau [(2015). J. Acoust. Soc. Am. 138, 1253-1267], which was 
obtained with normal-hearing listeners using 15 consonant-vowel combinations 
mixed with white noise. Accurate predictions of the consonant recognition scores 
were obtained across a large range of signal-to-noise ratios. Furthermore, the 
model yielded convincing predictions of the consonant confusion scores, such 
that the predicted errors were clustered in perceptually plausible confusion 
groups. The large predictive power of the proposed model suggests that adaptive 
processes in the auditory preprocessing in combination with a cross-correlation 
based template-matching back end can account for some of the processes 
underlying consonant perception in normal-hearing listeners. The proposed model 
may provide a valuable framework, e.g., for investigating the effects of hearing 
impairment and hearing-aid signal processing on phoneme recognition.

DOI: 10.1121/1.4976054
PMID: 28253684


741. Front Psychol. 2015 Jul 15;6:953. doi: 10.3389/fpsyg.2015.00953. eCollection 
2015.

Mental health problems in adolescents with cochlear implants: peer problems 
persist after controlling for additional handicaps.

Huber M(1), Burger T(2), Illg A(3), Kunze S(4), Giourgas A(3), Braun L(5), 
Kröger S(2), Nickisch A(4), Rasp G(1), Becker A(6), Keilmann A(5).

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Paracelsus Medical 
University Salzburg Salzburg, Austria.
(2)Department of Otorhinolaryngology, Cochlear Implant Center Freiburg, 
University of Freiburg Freiburg, Germany.
(3)Department of Otolaryngology, Hannover Medical School Hannover, Germany.
(4)Socialpediatric Center Munich Munich, Germany.
(5)Section of Communication Disorders, Clinic of Otorhinolaryngology, Head and 
Neck Surgery, University of Mainz Mainz, Germany.
(6)Department of Child and Adolescent Psychiatry, University of Goettingen 
Goettingen, Germany.

The aims of the present multi-center study were to investigate the extent of 
mental health problems in adolescents with a hearing loss and cochlear implants 
(CIs) in comparison to normal hearing (NH) peers and to investigate possible 
relations between the extent of mental health problems of young CI users and 
hearing variables, such as age at implantation, or functional gain of CI. The 
survey included 140 adolescents with CI (mean age = 14.7, SD = 1.5 years) and 
140 NH adolescents (mean age = 14.8, SD = 1.4 years), their parents and 
teachers. Participants were matched by age, gender and social background. Within 
the CI group, 35 adolescents were identified as "risk cases" due to possible and 
manifest additional handicaps, and 11 adolescents were non-classifiable. Mental 
health problems were assessed with the Strengths and Difficulties Questionnaire 
(SDQ) in the versions "Self," "Parent," and "Teacher." The CI group showed 
significantly more "Peer Problems" than the NH group. When the CI group was 
split into a "risk-group" (35 "risk cases" and 11 non-classifiable persons) and 
a "non-risk group" (n = 94), increased peer problems were perceived in both CI 
subgroups by adolescents themselves. However, no further differences between the 
CI non-risk group and the NH group were observed in any rater. The CI risk-group 
showed significantly more hyperactivity compared to the NH group and more 
hyperactivity and conduct problems compared to the CI non-risk group. Cluster 
analyses confirmed that there were significantly more adolescents with high 
problems in the CI risk-group compared to the CI non-risk group and the NH 
group. Adolescents with CI, who were able to understand speech in noise had 
significantly less difficulties compared to constricted CI users. Parents, 
teachers, and clinicians should be aware that CI users with additionally special 
needs may have mental health problems. However, peer problems were also 
experienced by CI adolescents without additional handicaps.

DOI: 10.3389/fpsyg.2015.00953
PMCID: PMC4502340
PMID: 26236251


742. J Zhejiang Univ Sci B. 2023 Feb 15;24(2):172-184. doi: 10.1631/jzus.B2200081.

AIFM1 variants associated with auditory neuropathy spectrum disorder cause 
apoptosis due to impaired apoptosis-inducing factor dimerization.

Qiu Y(1), Wang H(2), Pan H(1), Guan J(2), Yan L(1), Fan M(1)(3), Zhou H(1), Zhou 
X(1), Wu K(2), Jia Z(1), Zhuang Q(1), Lei Z(1), Li M(1), Ding X(1), Lin A(1), Fu 
Y(4), Zhang D(1), Wang Q(5), Yan Q(6)(7)(8).

Author information:
(1)College of Life Sciences, Zhejiang University, Hangzhou 310058, China.
(2)Senior Department of Otolaryngology, Head and Neck Surgery, Chinese PLA 
Institute of Otolaryngology, Chinese PLA General Hospital, Beijing 100853, 
China.
(3)Department of Pediatrics, the First Affiliated Hospital of Zhejiang 
University School of Medicine, Hangzhou 310003, China.
(4)The Children's Hospital of Zhejiang University School of Medicine, Hangzhou 
310052, China.
(5)Senior Department of Otolaryngology, Head and Neck Surgery, Chinese PLA 
Institute of Otolaryngology, Chinese PLA General Hospital, Beijing 100853, 
China. wqcr301@vip.‍sina.com.
(6)College of Life Sciences, Zhejiang University, Hangzhou 310058, China. 
qfyan@zju.edu.cn.
(7)Department of Pediatrics, the First Affiliated Hospital of Zhejiang 
University School of Medicine, Hangzhou 310003, China. qfyan@zju.edu.cn.
(8)Key Laboratory for Cell and Gene Engineering of Zhejiang Province, Hangzhou 
310058, China. qfyan@zju.edu.cn.

Auditory neuropathy spectrum disorder (ANSD) represents a variety of 
sensorineural deafness conditions characterized by abnormal inner hair cells 
and/or auditory nerve function, but with the preservation of outer hair cell 
function. ANSD represents up to 15% of individuals with hearing impairments. 
Through mutation screening, bioinformatic analysis and expression studies, we 
have previously identified several apoptosis-inducing factor (AIF) 
mitochondria-associated 1 (AIFM1) variants in ANSD families and in some other 
sporadic cases. Here, to elucidate the pathogenic mechanisms underlying each 
AIFM1 variant, we generated AIF-null cells using the clustered regularly 
interspersed short palindromic repeats (CRISPR)/CRISPR-associated protein 9 
(Cas9) system and constructed AIF-wild type (WT) and AIF-mutant (mut) (p.‍T260A, 
p.‍R422W, and p.‍R451Q) stable transfection cell lines. We then analyzed AIF 
structure, coenzyme-binding affinity, apoptosis, and other aspects. Results 
revealed that these variants resulted in impaired dimerization, compromising AIF 
function. The reduction reaction of AIF variants had proceeded slower than that 
of AIF-WT. The average levels of AIF dimerization in AIF variant cells were only 
34.5%‍‒‍49.7% of that of AIF-WT cells, resulting in caspase-independent 
apoptosis. The average percentage of apoptotic cells in the variants was 
12.3%‍‒‍17.9%, which was significantly higher than that (6.9%‍‒‍7.4%) in 
controls. However, nicotinamide adenine dinucleotide (NADH) treatment promoted 
the reduction of apoptosis by rescuing AIF dimerization in AIF variant cells. 
Our findings show that the impairment of AIF dimerization by AIFM1 variants 
causes apoptosis contributing to ANSD, and introduce NADH as a potential drug 
for ANSD treatment. Our results help elucidate the mechanisms of ANSD and may 
lead to the provision of novel therapies.

Publisher: 
听神经病谱系障碍（ANSD）属于感音神经性耳聋，其特征为内毛细胞和/或听觉神经元的功能异常，但外毛细胞的功能正常。在听力障碍患者中，听神经病谱系障碍的发病率高达15%。我们前期通过突变筛查、生物信息学分析和蛋白表达等检测，在ANSD家系和某些散发病例中发现了凋亡诱导因子1（AIFM1）基因的几种点突变。为阐明AIFM1突变体的致病机制，本文使用CRISPR/Cas9系统构建了凋亡诱导因子（AIF）蛋白敲除的细胞系，及其稳定转染野生型和突变型AIF 
蛋白（p.T260A、p.R422W和p.R451Q）的细胞系，并且分析了AIF蛋白结构、AIF与辅酶的亲和力及细胞凋亡等情况。结果显示，上述AIF突变体可导致AIF蛋白二聚体形成障碍，损害AIF蛋白的生理功能。突变型AIF蛋白的还原速率显著低于野生型AIF蛋白。且在AIF突变型细胞系中，AIF蛋白的二聚体含量仅为AIF野生型细胞系的34.5%～49.7%，导致非caspase依赖性细胞凋亡。AIF突变型细胞系中凋亡细胞的平均百分比为12.3%~17.9%，显著高于对照组的6.9%~7.4%。特别是，烟酰胺腺嘌呤二核苷酸（NADH）处理显著提高AIF突变型细胞中的AIF蛋白二聚体含量，从而降低细胞凋亡。结果表明：AIFM1突变引起AIF蛋白二聚体形成障碍，使得细胞凋亡增加，导致ANSD发生；NADH是ANSD的潜在治疗药物。我们的研究结果有助于阐明ANSD的发病机制，并可能提供新的治疗方案。.

听神经病谱系障碍（ANSD）属于感音神经性耳聋，其特征为内毛细胞和/或听觉神经元的功能异常，但外毛细胞的功能正常。在听力障碍患者中，听神经病谱系障碍的发病率高达15%。我们前期通过突变筛查、生物信息学分析和蛋白表达等检测，在ANSD家系和某些散发病例中发现了凋亡诱导因子1（AIFM1）基因的几种点突变。为阐明AIFM1突变体的致病机制，本文使用CRISPR/Cas9系统构建了凋亡诱导因子（AIF）蛋白敲除的细胞系，及其稳定转染野生型和突变型AIF 
蛋白（p.T260A、p.R422W和p.R451Q）的细胞系，并且分析了AIF蛋白结构、AIF与辅酶的亲和力及细胞凋亡等情况。结果显示，上述AIF突变体可导致AIF蛋白二聚体形成障碍，损害AIF蛋白的生理功能。突变型AIF蛋白的还原速率显著低于野生型AIF蛋白。且在AIF突变型细胞系中，AIF蛋白的二聚体含量仅为AIF野生型细胞系的34.5%～49.7%，导致非caspase依赖性细胞凋亡。AIF突变型细胞系中凋亡细胞的平均百分比为12.3%~17.9%，显著高于对照组的6.9%~7.4%。特别是，烟酰胺腺嘌呤二核苷酸（NADH）处理显著提高AIF突变型细胞中的AIF蛋白二聚体含量，从而降低细胞凋亡。结果表明：AIFM1突变引起AIF蛋白二聚体形成障碍，使得细胞凋亡增加，导致ANSD发生；NADH是ANSD的潜在治疗药物。我们的研究结果有助于阐明ANSD的发病机制，并可能提供新的治疗方案。

DOI: 10.1631/jzus.B2200081
PMCID: PMC10260280
PMID: 36751702 [Indexed for MEDLINE]


743. Front Neurol. 2022 Sep 15;13:959582. doi: 10.3389/fneur.2022.959582. eCollection 
2022.

A flexible data-driven audiological patient stratification method for deriving 
auditory profiles.

Saak S(1)(2), Huelsmeier D(1)(2), Kollmeier B(1)(2)(3)(4), Buhl M(1)(2).

Author information:
(1)Medical Physics, Carl von Ossietzky Universität Oldenburg, Oldenburg, 
Germany.
(2)Cluster of Excellence Hearing4all, Carl von Ossietky Universität Oldenburg, 
Oldenburg, Germany.
(3)Hörzentrum Oldenburg gGmbH, Oldenburg, Germany.
(4)Hearing Speech and Audio Technology, Fraunhofer Institute of Digital Media 
Technology (IDMT), Oldenburg, Germany.

For characterizing the complexity of hearing deficits, it is important to 
consider different aspects of auditory functioning in addition to the audiogram. 
For this purpose, extensive test batteries have been developed aiming to cover 
all relevant aspects as defined by experts or model assumptions. However, as the 
assessment time of physicians is limited, such test batteries are often not used 
in clinical practice. Instead, fewer measures are used, which vary across 
clinics. This study aimed at proposing a flexible data-driven approach for 
characterizing distinct patient groups (patient stratification into auditory 
profiles) based on one prototypical database (N = 595) containing audiogram 
data, loudness scaling, speech tests, and anamnesis questions. To further 
maintain the applicability of the auditory profiles in clinical routine, we 
built random forest classification models based on a reduced set of audiological 
measures which are often available in clinics. Different parameterizations 
regarding binarization strategy, cross-validation procedure, and evaluation 
metric were compared to determine the optimum classification model. Our 
data-driven approach, involving model-based clustering, resulted in a set of 13 
patient groups, which serve as auditory profiles. The 13 auditory profiles 
separate patients within certain ranges across audiological measures and are 
audiologically plausible. Both a normal hearing profile and profiles with 
varying extents of hearing impairments are defined. Further, a random forest 
classification model with a combination of a one-vs.-all and one-vs.-one 
binarization strategy, 10-fold cross-validation, and the kappa evaluation metric 
was determined as the optimal model. With the selected model, patients can be 
classified into 12 of the 13 auditory profiles with adequate precision (mean 
across profiles = 0.9) and sensitivity (mean across profiles = 0.84). The 
proposed approach, consequently, allows generating of audiologically plausible 
and interpretable, data-driven clinical auditory profiles, providing an 
efficient way of characterizing hearing deficits, while maintaining clinical 
applicability. The method should by design be applicable to all audiological 
data sets from clinics or research, and in addition be flexible to summarize 
information across databases by means of profiles, as well as to expand the 
approach toward aided measurements, fitting parameters, and further information 
from databases.

Copyright © 2022 Saak, Huelsmeier, Kollmeier and Buhl.

DOI: 10.3389/fneur.2022.959582
PMCID: PMC9520582
PMID: 36188360

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


744. Trends Hear. 2021 Jan-Dec;25:23312165211014137. doi: 10.1177/23312165211014137.

Amplitude Growth Functions of Auditory Nerve Responses to Electric Pulse 
Stimulation With Varied Interphase Gaps in Cochlear Implant Users With 
Ipsilateral Residual Hearing.

Imsiecke M(1), Büchner A(1)(2), Lenarz T(1)(2), Nogueira W(1)(2).

Author information:
(1)Clinic for Otorhinolaryngology, Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence "Hearing4All," Hannover, Germany.

Amplitude growth functions (AGFs) of electrically evoked compound action 
potentials (eCAPs) with varying interphase gaps (IPGs) were measured in cochlear 
implant users with ipsilateral residual hearing (electric-acoustic stimulation 
[EAS]). It was hypothesized that IPG effects on AGFs provide an objective 
measure to estimate neural health. This hypothesis was tested in EAS users, as 
residual low-frequency hearing might imply survival of hair cells and hence 
better neural health in apical compared to basal cochlear regions. A total of 16 
MED-EL EAS subjects participated, as well as a control group of 16 deaf cochlear 
implant users. The IPG effect on the AGF characteristics of slope, threshold, 
dynamic range, and stimulus level at 50% maximum eCAP amplitude (level50%) was 
investigated. AGF threshold and level50% were significantly affected by the IPG 
in both EAS and control group. The magnitude of AGF characteristics correlated 
with electrode impedance and electrode-modiolus distance (EMD) in both groups. 
In contrast, the change of the AGF characteristics with increasing IPG was 
independent of these electrode-specific measures. The IPG effect on the AGF 
level50% in both groups, as well as on the threshold in EAS users, correlated 
with the duration of hearing loss, which is a predictor of neural health. In EAS 
users, a significantly different IPG effect on level50% was found between apical 
and medial electrodes. This outcome is consistent with our hypothesis that the 
influence of IPG effects on AGF characteristics provides a sensitive measurement 
and may indicate better neural health in the apex compared to the medial 
cochlear region in EAS users.

DOI: 10.1177/23312165211014137
PMCID: PMC8243142
PMID: 34181493 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting Interests: The 
authors declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


745. J Neurosci. 2021 Aug 11;41(32):6796-6811. doi: 10.1523/JNEUROSCI.0139-20.2021. 
Epub 2021 Jun 30.

Loss of miR-183/96 Alters Synaptic Strength via Presynaptic and Postsynaptic 
Mechanisms at a Central Synapse.

Krohs C(1), Körber C(2), Ebbers L(1), Altaf F(1), Hollje G(1), Hoppe S(2), 
Dörflinger Y(2), Prosser HM(3), Nothwang HG(4)(5).

Author information:
(1)Division of Neurogenetics, Department of Neuroscience, Carl von Ossietzky 
University Oldenburg, Oldenburg 26129, Germany.
(2)Institute of Anatomy und Cell Biology, Department of Functional Neuroanatomy, 
Heidelberg University, Heidelberg 69120, Germany.
(3)Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Cambridge CB10 
1SA, United Kingdom.
(4)Division of Neurogenetics, Department of Neuroscience, Carl von Ossietzky 
University Oldenburg, Oldenburg 26129, Germany hans.g.nothwang@uni-oldenburg.de.
(5)Excellence Cluster Hearing4all, Carl von Ossietzky University Oldenburg, 
26129 Oldenburg, Germany.

A point mutation in miR-96 causes non-syndromic progressive peripheral hearing 
loss and alters structure and physiology of the central auditory system. To gain 
further insight into the functions of microRNAs (miRNAs) within the central 
auditory system, we investigated constitutive Mir-183/96dko mice of both sexes. 
In this mouse model, the genomically clustered miR-183 and miR-96 are 
constitutively deleted. It shows significantly and specifically reduced volumes 
of auditory hindbrain nuclei, because of decreases in cell number and soma size. 
Electrophysiological analysis of the calyx of Held synapse in the medial nucleus 
of the trapezoid body (MNTB) demonstrated strongly altered synaptic transmission 
in young-adult mice. We observed an increase in quantal content and readily 
releasable vesicle pool size in the presynapse while the overall morphology of 
the calyx was unchanged. Detailed analysis of the active zones (AZs) revealed 
differences in its molecular composition and synaptic vesicle (SV) distribution. 
Postsynaptically, altered clustering and increased synaptic abundancy of the 
AMPA receptor subunit GluA1 was observed resulting in an increase in quantal 
amplitude. Together, these presynaptic and postsynaptic alterations led to a 
2-fold increase of the evoked excitatory postsynaptic currents in MNTB neurons. 
None of these changes were observed in deaf Cldn14ko mice, confirming an on-site 
role of miR-183 and miR-96 in the auditory hindbrain. Our data suggest that the 
Mir-183/96 cluster plays a key role for proper synaptic transmission at the 
calyx of Held and for the development of the auditory hindbrain.SIGNIFICANCE 
STATEMENT The calyx of Held is the outstanding model system to study basic 
synaptic physiology. Yet, genetic factors driving its morphologic and functional 
maturation are largely unknown. Here, we identify the Mir-183/96 cluster as an 
important factor to regulate its synaptic strength. Presynaptically, 
Mir-183/96dko calyces show an increase in release-ready synaptic vesicles (SVs), 
quantal content and abundance of the proteins Bassoon and Piccolo. 
Postsynaptically, the quantal size as well as number and size of GluA1 puncta 
were increased. The two microRNAs (miRNAs) are thus attractive candidates for 
regulation of synaptic maturation and long-term adaptations to sound levels. 
Moreover, the different phenotypic outcomes of different types of mutations in 
the Mir-183 cluster corroborate the requirement of mutation-tailored therapies 
in patients with hearing loss.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.0139-20.2021
PMCID: PMC8360680
PMID: 34193555 [Indexed for MEDLINE]


746. Front Aging Neurosci. 2021 Oct 18;13:756449. doi: 10.3389/fnagi.2021.756449. 
eCollection 2021.

Synaptic Release Potentiation at Aging Auditory Ribbon Synapses.

Peineau T(1)(2), Belleudy S(1), Pietropaolo S(3), Bouleau Y(1)(2), Dulon 
D(1)(2).

Author information:
(1)Neurophysiologie de la Synapse Auditive, INSERM UMRS 1120, Bordeaux 
Neurocampus, Université de Bordeaux, Bordeaux, France.
(2)Institut de l'Audition, Centre Institut Pasteur/Inserm, Paris, France.
(3)INCIA, UMR 5287, CNRS, University of Bordeaux, Bat B2, Pessac, France.

Age-related hidden hearing loss is often described as a cochlear synaptopathy 
that results from a progressive degeneration of the inner hair cell (IHC) ribbon 
synapses. The functional changes occurring at these synapses during aging are 
not fully understood. Here, we characterized this aging process in IHCs of 
C57BL/6J mice, a strain which is known to carry a cadherin-23 mutation and 
experiences early hearing loss with age. These mice, while displaying a large 
increase in auditory brainstem thresholds due to 50% loss of IHC synaptic 
ribbons at middle age (postnatal day 365), paradoxically showed enhanced 
acoustic startle reflex suggesting a hyperacusis-like response. The auditory 
defect was associated with a large shrinkage of the IHCs' cell body and a 
drastic enlargement of their remaining presynaptic ribbons which were facing 
enlarged postsynaptic AMPAR clusters. Presynaptic Ca2+ microdomains and the 
capacity of IHCs to sustain high rates of exocytosis were largely increased, 
while on the contrary the expression of the fast-repolarizing BK channels, known 
to negatively control transmitter release, was decreased. This age-related 
synaptic plasticity in IHCs suggested a functional potentiation of synaptic 
transmission at the surviving synapses, a process that could partially 
compensate the decrease in synapse number and underlie hyperacusis.

Copyright © 2021 Peineau, Belleudy, Pietropaolo, Bouleau and Dulon.

DOI: 10.3389/fnagi.2021.756449
PMCID: PMC8558230
PMID: 34733152

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


747. Front Cell Dev Biol. 2021 May 5;9:671364. doi: 10.3389/fcell.2021.671364. 
eCollection 2021.

N-Terminus of GRXCR2 Interacts With CLIC5 and Is Essential for Auditory 
Perception.

Li J(1), Liu C(1), Zhao B(1).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Indiana University School 
of Medicine, Indianapolis, IN, United States.

Stereocilia of cochlear hair cells are specialized mechanosensing organelles 
that convert sound-induced vibration to electrical signals. Glutaredoxin 
domain-containing cysteine-rich protein 2 (GRXCR2) is localized at the base of 
stereocilia and is necessary for stereocilia morphogenesis and auditory 
perception. However, the detailed functions of GRXCR2 in hair cells are still 
largely unknown. Here, we report that GRXCR2 interacts with chloride 
intracellular channel protein 5 (CLIC5) which is also localized at the base of 
stereocilia and required for normal hearing in human and mouse. 
Immunolocalization analyses suggest that GRXCR2 is not required for the 
localization of CLIC5 to the stereociliary base during development, or vice 
versa. Using clustered regularly interspaced short palindromic repeats 
(CRISPR)/Cas9 system, we deleted 60 amino acids near the N-terminus of GRXCR2 
essential for its interaction with CLIC5. Interestingly, mice harboring this 
in-frame deletion in Grxcr2 exhibit moderate hearing loss at lower frequencies 
and severe hearing loss at higher frequencies although the morphogenesis of 
stereocilia is minimally affected. Thus, our findings reveal that the 
interaction between GRXCR2 and CLIC5 is crucial for normal hearing.

Copyright © 2021 Li, Liu and Zhao.

DOI: 10.3389/fcell.2021.671364
PMCID: PMC8131845
PMID: 34026762

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


748. Front Aging Neurosci. 2016 Sep 21;8:221. doi: 10.3389/fnagi.2016.00221. 
eCollection 2016.

Neuroanatomical Alterations in Tinnitus Assessed with Magnetic Resonance 
Imaging.

Allan TW(1), Besle J(1), Langers DR(2), Davies J(2), Hall DA(2), Palmer AR(1), 
Adjamian P(1).

Author information:
(1)Medical Research Council Institute of Hearing Research, The University of 
Nottingham Nottingham, UK.
(2)Nottingham Hearing Biomedical Research Unit, National Institute for Health 
Research (NIHR)Nottingham, UK; Otology and Hearing Group, Division of Clinical 
Neuroscience, School of Medicine, The University of NottinghamNottingham, UK.

Previous studies of anatomical changes associated with tinnitus have provided 
inconsistent results, with some showing significant cortical and subcortical 
changes, while others have found effects due to hearing loss, but not tinnitus. 
In this study, we examined changes in brain anatomy associated with tinnitus 
using anatomical scans from 128 participants with tinnitus and hearing loss, 
tinnitus with clinically normal hearing, and non-tinnitus controls with 
clinically normal hearing. The groups were matched for hearing loss, age and 
gender. We employed voxel- and surface-based morphometry (SBM) to investigate 
gray and white matter volume and thickness within regions-of-interest (ROI) that 
were based on the results of previous studies. The largest overall effects were 
found for age, gender, and hearing loss. With regard to tinnitus, analysis of 
ROI revealed numerous small increases and decreases in gray matter and thickness 
between tinnitus and non-tinnitus controls, in both cortical and subcortical 
structures. For whole brain analysis, the main tinnitus-related significant 
clusters were found outside sensory auditory structures. These include a 
decrease in cortical thickness for the tinnitus group compared to controls in 
the left superior frontal gyrus (SFG), and a decrease in cortical volume with 
hearing loss in left Heschl's gyrus (HG). For masked analysis, we found a 
decrease in gray matter volume in the right Heschle's gyrus for the tinnitus 
group compared to the controls. We found no changes in the subcallosal region as 
reported in some previous studies. Overall, while some of the morphological 
differences observed in this study are similar to previously published findings, 
others are entirely different or even contradict previous results. We highlight 
other discrepancies among previous results and the increasing need for a more 
precise subtyping of the condition.

DOI: 10.3389/fnagi.2016.00221
PMCID: PMC5030287
PMID: 27708577


749. J Med Internet Res. 2020 Sep 22;22(9):e17927. doi: 10.2196/17927.

Effectiveness of a Web-Based SUpport PRogram (SUPR) for Hearing Aid Users Aged 
50+: Two-Arm, Cluster Randomized Controlled Trial.

Meijerink JF(1), Pronk M(1), Lissenberg-Witte BI(2), Jansen V(3), Kramer SE(1).

Author information:
(1)Otolaryngology-Head and Neck Surgery, Ear and Hearing, Amsterdam Public 
Health research institute, Amsterdam UMC, Vrije Universiteit Amsterdam, 
Amsterdam, Netherlands.
(2)Epidemiology and Data Science, Amsterdam UMC, Vrije Universiteit Amsterdam, 
Amsterdam, Netherlands.
(3)Schoonenberg HoorSupport, Dordrecht, Netherlands.

BACKGROUND: Hearing aid (HA) use is known to improve health outcomes for people 
with hearing loss. Despite that, HA use is suboptimal, and communication issues 
and hearing-related activity limitations and participation restrictions often 
remain. Web-based self-management communication programs may support people with 
hearing loss to effectively self-manage the impact of hearing loss in their 
daily lives.
OBJECTIVE: The goal of the research is to examine the short- and long-term 
effects of a web-based self-management SUpport PRogram (SUPR) on communication 
strategy use (primary outcome) and a range of secondary outcomes for HA users 
aged 50 years and older.
METHODS: Clients of 36 HA dispensing practices were randomized to SUPR (SUPR 
recipients; n=180 HA users) and 34 to care as usual (controls; n=163 HA users). 
SUPR recipients received a practical support booklet and online materials 
delivered via email over the course of their 6-month HA rehabilitation 
trajectory. They were encouraged to appoint a communication partner and were 
offered optional email contact with the HA dispensing practice. The online 
materials included 3 instruction videos on HA handling, 5 videos on 
communication strategies, and 3 testimonial videos. Care as usual included a HA 
fitting rehabilitation trajectory only. Measurements were carried out at 
baseline, immediately postintervention, 6 months postintervention, and 12 months 
postintervention. The primary outcome measure was self-reported use of 
communication strategies (3 subscales of the Communication Profile for the 
Hearing Impaired [CPHI]). Secondary outcome measures included self-reported 
personal adjustment to hearing loss (CPHI); use, satisfaction and benefit of HAs 
and SUPR (use questionnaire; International Outcome Inventory for Hearing Aids 
[IOI-HA], Alternative Interventions [IOI-AI]); recommendation of HA dispensing 
services; self-efficacy for HA handling (Measure of Audiologic Rehabilitation 
Self-Efficacy for Hearing Aids [MARS-HA]); readiness to act on hearing loss 
(University of Rhode Island Change Assessment adapted for hearing loss 
[URICA-HL]); and hearing disability (Amsterdam Inventory for Auditory Disability 
and Handicap [AIADH]).
RESULTS: Linear mixed model analyses (intention to treat) showed no significant 
differences between the SUPR and control group in the course of communication 
strategy use (CPHI). Immediately postintervention, SUPR recipients showed 
significantly higher self-efficacy for advanced HA handling than the controls, 
which was sustained at 12 months (MARS-HA; mean difference immediately 
postintervention: 5.3, 95% CI 0.3 to 10.4; P=.04). Also, SUPR recipients showed 
significantly greater HA satisfaction than controls immediately postintervention 
(IOI-HA; 0.3, 95% CI 0.09 to 0.5; P=.006), which was sustained at 12 months, and 
significantly greater HA use than the controls immediately postintervention 
(IOI-HA; 0.3, 95% CI 0.02 to 0.5; P=.03), which was not sustained at 12 months.
CONCLUSIONS: This study provides ground to recommend adding SUPR to standard HA 
dispensing care, as long-term, modest improvements in HA outcomes were observed. 
Further research is needed to evaluate what adjustments to SUPR are needed to 
establish long-term effectiveness on outcomes in the psychosocial domain.
TRIAL REGISTRATION: ISRCTN77340339; http://www.isrctn.com/ISRCTN77340339.
INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): 
RR2-10.1136/bmjopen-2016-015012.

©Janine FJ Meijerink, Marieke Pronk, Birgit I Lissenberg-Witte, Vera Jansen, 
Sophia E Kramer. Originally published in the Journal of Medical Internet 
Research (http://www.jmir.org), 22.09.2020.

DOI: 10.2196/17927
PMCID: PMC7539169
PMID: 32960175 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: Most of JFJM’s 
appointment at the Amsterdam University Medical Center as a PhD student on the 
SUPR project (including completing the tasks related to the submitted work) and 
the design and implementation of the SUPR study were facilitated through a 
research grant sponsored by AudioNova International BV. MP was employed as a 
researcher at Schoonenberg HoorSupport (daughter company of AudioNova 
International BV) for a 6-month period on other research work, received a 
(cofunding) research grant from Sonova AG (mother company of AudioNova 
International BV) for other research work, and has been paid for delivering a 
one-off scientific presentation for Sonova AG. VJ is an employee at Schoonenberg 
HoorSupport and SEK has been paid for delivering a presentation for Sonova AG; 
no other relationships or activities that could appear to have influenced the 
submitted work can be reported.


750. Front Aging Neurosci. 2022 Jan 28;13:772136. doi: 10.3389/fnagi.2021.772136. 
eCollection 2021.

Intrinsic Brain Activity of Inferior Temporal Region Increased in Prodromal 
Alzheimer's Disease With Hearing Loss.

Hong L(1), Zeng Q(1), Li K(1), Luo X(1), Xu X(1), Liu X(1), Li Z(2), Fu Y(2), 
Wang Y(2), Zhang T(3), Chen Y(2), Liu Z(2), Huang P(1), Zhang M(1).

Author information:
(1)Department of Radiology, The 2nd Affiliated Hospital of Zhejiang University 
School of Medicine, Hangzhou, China.
(2)Department of Neurology, The 2nd Affiliated Hospital of Zhejiang University 
School of Medicine, Hangzhou, China.
(3)Department of Neurology, Tongde Hospital of Zhejiang Province, Hangzhou, 
China.

BACKGROUND AND OBJECTIVE: Hearing loss (HL) is one of the modifiable risk 
factors for Alzheimer's disease (AD). However, the underlying mechanism behind 
HL in AD remains elusive. A possible mechanism is cognitive load hypothesis, 
which postulates that over-processing of degraded auditory signals in the 
auditory cortex leads to deficits in other cognitive functions. Given mild 
cognitive impairment (MCI) is a prodromal stage of AD, untangling the 
association between HL and MCI might provide insights for potential mechanism 
behind HL.
METHODS: We included 85 cognitively normal (CN) subjects with no hearing loss 
(NHL), 24 CN with HL, 103 mild cognitive impairment (MCI) patients with NHL, and 
23 MCI with HL from the ADNI database. All subjects underwent resting-state 
functional MRI and neuropsychological scale assessments. Fractional amplitude of 
low-frequency fluctuation (fALFF) was used to reflect spontaneous brain 
activity. The mixed-effects analysis was applied to explore the interactive 
effects between HL and cognitive status (GRF corrected, voxel p-value <0.005, 
cluster p-value < 0.05, two-tailed). Then, the FDG data was included to further 
reflect the regional neuronal abnormalities. Finally, Pearson correlation 
analysis was performed between imaging metrics and cognitive scores to explore 
the clinical significance (Bonferroni corrected, p < 0.05).
RESULTS: The interactive effects primarily located in the left superior temporal 
gyrus (STG) and bilateral inferior temporal gyrus (ITG). Post-hoc analysis 
showed that NC with HL had lower fALFF in bilateral ITG compared to NC with NHL. 
NC with HL had higher fALFF in the left STG and decreased fALFF in bilateral ITG 
compared to MCI with HL. In addition, NC with HL had lower fALFF in the right 
ITG compared to MCI with NHL. Correlation analysis revealed that fALFF was 
associated with MMSE and ADNI-VS, while SUVR was associated with MMSE, MoCA, 
ADNI-EF and ADNI-Lan.
CONCLUSION: HL showed different effects on NC and MCI stages. NC had increased 
spontaneous brain activity in auditory cortex while decreased activity in the 
ITG. Such pattern altered with disease stage changing and manifested as 
decreased activity in auditory cortex along with increased activity in ITG in 
MCI. This suggested that the cognitive load hypothesis may be the underlying 
mechanism behind HL.

Copyright © 2022 Hong, Zeng, Li, Luo, Xu, Liu, Li, Fu, Wang, Zhang, Chen, Liu, 
Huang and Zhang.

DOI: 10.3389/fnagi.2021.772136
PMCID: PMC8831745
PMID: 35153717

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


751. JAMA Otolaryngol Head Neck Surg. 2018 Jan 1;144(1):65-70. doi: 
10.1001/jamaoto.2017.2223.

Prevalence, Characteristics, and Treatment Patterns of Hearing Difficulty in the 
United States.

Mahboubi H(1), Lin HW(1), Bhattacharyya N(2).

Author information:
(1)Division of Neurotology and Skull Base Surgery, Department of 
Otolaryngology-Head and Neck Surgery, University of California, Irvine.
(2)Department of Otology & Laryngology, Harvard Medical School, Boston, 
Massachusetts.

IMPORTANCE: Hearing loss is one of the most prevalent chronic conditions in the 
United States and has been associated with negative physical, social, cognitive, 
economic, and emotional consequences. Despite the high prevalence of hearing 
loss, substantial gaps in the utilization of amplification options, including 
hearing aids and cochlear implants (CI), have been identified.
OBJECTIVE: To investigate the contemporary prevalence, characteristics, and 
patterns of specialty referral, evaluation, and treatment of hearing difficulty 
among adults in the United States.
DESIGN, SETTING, AND PARTICIPANTS: A cross-sectional analysis of responses from 
a nationwide clustered representative sample of adults who participated in the 
2014 National Health Interview Survey and responded to the hearing module 
questions was carried out.
MAIN OUTCOMES AND MEASURES: Data regarding demographics as well as self-reported 
hearing status, functional hearing, laterality, onset, and primary cause of the 
hearing loss were collected. In addition, specific data regarding 
hearing-related clinician visits, hearing tests, referrals to hearing 
specialist, and utilization of hearing aids and CIs were analyzed.
RESULTS: Among 239.6 million adults, 40.3 million (16.8%) indicated their 
hearing was less than "excellent/good," ranging from "a little trouble hearing" 
to "deaf." The mean (SD) age of participants was 47 (0.2) years with 48.2% being 
men and 51.8% women. Approximately 48.8 million (20.6%) had visited a physician 
for hearing problems in the preceding 5 years. Of these, 32.6% were referred to 
an otolaryngologist and 27.3% were referred to an audiologist. Functional 
hearing was reported as the ability to hear "whispering" or "normal voice" 
(225.4 million; 95.5%), to "only hear shouting" (8.0 million; 3.4%), and "not 
appreciating shouting" (2.8 million; 1.1%). Among the last group, 5.3% were 
recommended to have a CI, of which 22.1% had received one. Of the adults who 
indicated their hearing from "a little trouble hearing" to being "deaf," 12.9 
million (32.2%) had never seen a clinician for hearing problems and 11.1 million 
(28.0%) had never had their hearing tested.
CONCLUSIONS AND RELEVANCE: There are considerable gaps between self-reported 
hearing loss and patients receiving medical evaluation and recommended 
treatments for hearing loss. Improved awareness regarding referrals to 
otolaryngologists and audiologists as well as auditory rehabilitative options 
among clinicians may improve hearing loss care.

DOI: 10.1001/jamaoto.2017.2223
PMCID: PMC5833589
PMID: 29167904

Conflict of interest statement: Conflict of Interest Disclosures: All authors 
have completed and submitted the ICMJE Form for Disclosure of Potential 
Conflicts of Interest and none were reported.


752. Synapse. 2015 May;69(5):242-55. doi: 10.1002/syn.21812. Epub 2015 Mar 11.

Resolving the structure of inner ear ribbon synapses with STED microscopy.

Rutherford MA(1).

Author information:
(1)Department of Otolaryngology, Central Institute for the Deaf, Washington 
University School of Medicine, Washington University School of Medicine, St. 
Louis, Missouri, 63110; Inner Ear Lab, Department of Otolaryngology, University 
of Göttingen Medical Center, Göttingen, Germany, D-37077.

Synapses are diverse in form and function; however, the mechanisms underlying 
this diversity are poorly understood. To illuminate structure/function 
relationships, robust analysis of molecular composition and morphology is 
needed. The molecular-anatomical components of synapses-vesicles, clusters of 
voltage-gated ion channels in presynaptic densities, arrays of transmitter 
receptors in postsynaptic densities-are only tens to hundreds of nanometers in 
size. Measuring the topographies of synaptic proteins requires nanoscale 
resolution of their molecularly specific labels. Super-resolution light 
microscopy has emerged to meet this need. Achieving 50 nm resolution in thick 
tissue, we employed stimulated emission depletion (STED) microscopy to image the 
functionally and molecularly unique ribbon-type synapses in the inner ear that 
connect mechano-sensory inner hair cells to cochlear nerve fibers. Synaptic 
ribbons, bassoon protein, voltage-gated Ca(2+) channels, and glutamate receptors 
are inhomogeneous in their spatial distributions within synapses; the protein 
clusters assume variations of shapes typical for each protein specifically at 
cochlear afferent synapses. Heterogeneity of substructure among these synapses 
may contribute to functional differences among auditory nerve fibers. The 
morphology of synaptic voltage-gated Ca(2+) channels matures over development in 
a way that depends upon bassoon protein, which aggregates in similar form. 
Functional properties of synaptic transmission appear to depend on voltage-gated 
Ca(2+) channel cluster morphology and position relative to synaptic vesicles. 
Super-resolution light microscopy is a group of techniques that complement 
electron microscopy and conventional light microscopy. Although technical 
hurdles remain, we are beginning to resolve the details of molecular nanoanatomy 
that relate mechanistically to synaptic function.

© 2015 Wiley Periodicals, Inc.

DOI: 10.1002/syn.21812
PMID: 25682928 [Indexed for MEDLINE]


753. Neuropathology. 2019 Oct;39(5):342-347. doi: 10.1111/neup.12589. Epub 2019 Aug 
21.

A novel mutation in PRPS1 causes X-linked Charcot-Marie-Tooth disease-5.

Meng L(1), Wang K(2), Lv H(1), Wang Z(1), Zhang W(1), Yuan Y(1).

Author information:
(1)Department of Neurology, Peking University First Hospital, Beijing, China.
(2)Peking University-Tsinghua University-National Institute of Biological 
Sciences Joint Graduate Program, School of Life Sciences, Tsinghua University, 
Beijing, China.

X-linked Charcot-Marie-Tooth disease-5 (CMTX5) is a rare hereditary disorder 
caused by mutations in the gene for phosphoribosyl pyrophosphate synthetase-1 
(PRPS1). We investigated a boy with a novel PRPS1 mutation (c.334G>C, p.V112L) 
via genetic, neuropathological and enzymatic tests. The proband was a 
13-year-old boy with congenital non-syndromic sensorineural deafness. At 3 year 
old, he developed progressive distal weakness of all limbs with muscle atrophy 
of both hands and shanks. Nerve conduction study revealed the loss of sensory 
nerve action potentials, and slowing down of motor nerve conduction velocities 
with a decrease of amplitudes of compound motor action potentials. Visual evoked 
potentials and brainstem auditory evoked potentials were not bilaterally 
evocable. Sural biopsy proved the loss of myelinated nerve fibers, with axonal 
degeneration, regenerating clusters and onion bulbs. Enzymatically, PRPS1 
activity was close to zero in the proband and mildly reduced in his mother, 
compared with controls. To our knowledge, this is the first report of CMTX5 in a 
Chinese population. The genetic finding has expanded the genotypic spectrum of 
PRPS1 mutations.

© 2019 Japanese Society of Neuropathology.

DOI: 10.1111/neup.12589
PMID: 31434166 [Indexed for MEDLINE]


754. Cureus. 2023 Jun 5;15(6):e39966. doi: 10.7759/cureus.39966. eCollection 2023 
Jun.

A Rare Case of Angiolymphoid Hyperplasia With Eosinophilia With a New Effective 
Treatment.

Hasan U(1), Ahmed N(2), Malik T(1), Shah SA(1), Subhan U(1).

Author information:
(1)Dermatology, Pakistan Navy Station (PNS) Shifa Hospital, Karachi, PAK.
(2)Dermatology, Bahria University of Health Sciences, Pakistan Navy Station 
(PNS) Shifa Hospital, Karachi, PAK.

Angiolymphoid hyperplasia with eosinophilia (ALHE) is a benign locally 
proliferating lesion of unknown etiology, composed of vascular channels lined by 
endothelial cells, surrounded by lymphocytes and eosinophils. It presents 
clinically as a cluster of skin to violaceous-colored nodules on the head and 
neck, particularly in and around the ear. We present the case of a 50-year-old, 
Pakistani woman with unilateral multiple nodular lesions for eight years in the 
left ear concha and postauricular area causing complete obliteration of the 
external auditory meatus with conductive hearing loss of the left ear for seven 
years. Biopsy showed lymphoid follicles and dilated blood vessels with mixed 
infiltrate predominantly eosinophils corresponding to the diagnosis of 
angiolymphoid hyperplasia with eosinophilia. Surgical excision was not feasible, 
and there was no response to topical steroids. The patient was started on beta 
blockers. After three months, postauricular lesions completely resolved, and the 
size of the rest of the nodules decreased markedly; then hearing loss also 
recovered. Our objective in this study is to emphasize the importance of 
considering beta blockers for the treatment of ALHE.

Copyright © 2023, Hasan et al.

DOI: 10.7759/cureus.39966
PMCID: PMC10320733
PMID: 37415992

Conflict of interest statement: The authors have declared that no competing 
interests exist.


755. Med Biol Eng Comput. 2018 May;56(5):733-747. doi: 10.1007/s11517-017-1720-0. 
Epub 2017 Sep 13.

Numerical analysis of intracochlear mechanical auditory stimulation using 
piezoelectric bending actuators.

Schurzig D(1), Schwarzendahl S(2), Wallaschek J(2), van Drunen WJ(3), Rau TS(3), 
Lenarz T(3), Majdani O(3).

Author information:
(1)Cluster of Excellence Hearing4all, Department of Otolaryngology, Hannover 
Medical School, Carl-Neuberg-Str. 1, 30625, Hannover, Germany. 
schurzig.daniel@mh-hannover.de.
(2)Institute of Dynamics and Vibration Research, Leibniz Universität Hannover, 
Hannover, Germany.
(3)Cluster of Excellence Hearing4all, Department of Otolaryngology, Hannover 
Medical School, Carl-Neuberg-Str. 1, 30625, Hannover, Germany.

Cochlear implantation can restore a certain degree of auditory impression of 
patients suffering from profound hearing loss or deafness. Furthermore, studies 
have shown that in case of residual hearing, patients benefit from the use of a 
hearing aid in addition to the cochlear implant. The presented studies aim at 
the improvement of this electromechanical stimulation (EMS) approach by 
substituting the external hearing aid by an internal stimulus provided by 
miniaturized piezoelectric actuators. Finite element analyses are performed in 
order to derive fundamental guidelines for the actuator layout aiming at maximal 
mechanical stimuli. Further analyses aim at investigating how the actuator 
position inside the cochlea influences the basilar membrane oscillation profile. 
While actuator layout guidelines leading to maximized acoustic stimuli could be 
derived, some of these guidelines are of complementary nature suggesting that 
further studies under realistic boundary conditions must be performed. Actuator 
positioning inside the cochlea is shown to have a significant influence on the 
resulting auditory impression of the patient. Based on the results, the main 
differences of external and internal stimulation of the cochlea mechanism are 
identified. It is shown that if the cochlea tonotopy is considered, the 
frequency selectivity resulting from the mechanical cochlea stimulus may be 
improved.

DOI: 10.1007/s11517-017-1720-0
PMID: 28900873 [Indexed for MEDLINE]


756. Sci Rep. 2018 Dec 21;8(1):18022. doi: 10.1038/s41598-018-36894-z.

The microRNA-183/96/182 Cluster is Essential for Stereociliary Bundle Formation 
and Function of Cochlear Sensory Hair Cells.

Geng R(1)(2), Furness DN(3), Muraleedharan CK(4), Zhang J(5)(6), Dabdoub A(7), 
Lin V(7), Xu S(8).

Author information:
(1)Department of Ophthalmology, Visual and Anatomical Sciences, School of 
Medicine, Wayne State University, Detroit, Michigan, USA. ruishuang@gmail.com.
(2)Department of Otolaryngology, School of Medicine, Wayne State University, 
Detroit, Michigan, USA. ruishuang@gmail.com.
(3)School of Life Sciences, Keele University, Keele, Staffs, ST5 5BG, United 
Kingdom.
(4)Department of Ophthalmology, Visual and Anatomical Sciences, School of 
Medicine, Wayne State University, Detroit, Michigan, USA.
(5)Department of Otolaryngology, School of Medicine, Wayne State University, 
Detroit, Michigan, USA.
(6)Department of Communication Sciences and Disorders, College of Liberal Arts 
and Sciences, Wayne State University, Detroit, Michigan, USA.
(7)Biological Science, Sunnybrook Research Institute, Toronto, Ontario, Canada.
(8)Department of Ophthalmology, Visual and Anatomical Sciences, School of 
Medicine, Wayne State University, Detroit, Michigan, USA. sxu@med.wayne.edu.

The microRNA (miR)-183/96/182 cluster plays important roles in the development 
and functions of sensory organs, including the inner ear. Point-mutations in the 
seed sequence of miR-96 result in non-syndromic hearing loss in both mice and 
humans. However, the lack of a functionally null mutant has hampered the 
evaluation of the cluster's physiological functions. Here we have characterized 
a loss-of-function mutant mouse model (miR-183CGT/GT), in which the 
miR-183/96/182 cluster gene is inactivated by a gene-trap (GT) construct. The 
homozygous mutant mice show profound congenital hearing loss with severe defects 
in cochlear hair cell (HC) maturation, alignment, hair bundle formation and the 
checkboard-like pattern of the cochlear sensory epithelia. The stereociliary 
bundles retain an immature appearance throughout the cochlea at postnatal day 
(P) 3 and degenerate soon after. The organ of Corti of mutant newborn mice has 
no functional mechanoelectrical transduction. Several predicted target genes of 
the miR-183/96/182 cluster that are known to play important roles in HC 
development and function, including Clic5, Rdx, Ezr, Rac1, Myo1c, Pvrl3 and 
Sox2, are upregulated in the cochlea. These results suggest that the 
miR-183/96/182 cluster is essential for stereociliary bundle formation, 
morphogenesis and function of the cochlear HCs.

DOI: 10.1038/s41598-018-36894-z
PMCID: PMC6303392
PMID: 30575790 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


757. Front Cell Dev Biol. 2021 Oct 25;9:750271. doi: 10.3389/fcell.2021.750271. 
eCollection 2021.

Tlr2/4 Double Knockout Attenuates the Degeneration of Primary Auditory Neurons: 
Potential Mechanisms From Transcriptomic Perspectives.

Wang Q(1)(2), Shen Y(1)(2), Pan Y(1)(2), Chen K(1)(2), Ding R(1)(2), Zou 
T(1)(2), Zhang A(1)(2), Guo D(1)(2), Ji P(1)(2), Fan C(1)(2), Mei L(2), Hu 
H(1)(2), Ye B(1)(2), Xiang M(1)(2).

Author information:
(1)Department of Otolaryngology and Head and Neck Surgery, Ruijin Hospital, 
Shanghai Jiao Tong University School of Medicine, Shanghai, China.
(2)Ear Institute, Shanghai Jiao Tong University School of Medicine, Shanghai, 
China.

The transcriptomic landscape of mice with primary auditory neurons degeneration 
(PAND) indicates key pathways in its pathogenesis, including complement 
cascades, immune responses, tumor necrosis factor (TNF) signaling pathway, and 
cytokine-cytokine receptor interaction. Toll-like receptors (TLRs) are important 
immune and inflammatory molecules that have been shown to disrupt the disease 
network of PAND. In a PAND model involving administration of kanamycin combined 
with furosemide to destroy cochlear hair cells, Tlr 2/4 double knockout (DKO) 
mice had auditory preservation advantages, which were mainly manifested at 4-16 
kHz. DKO mice and wild type (WT) mice had completely damaged cochlear hair cells 
on the 30th day, but the density of spiral ganglion neurons (SGN) in the 
Rosenthal canal was significantly higher in the DKO group than in the WT group. 
The results of immunohistochemistry for p38 and p65 showed that the attenuation 
of SGN degeneration in DKO mice may not be mediated by canonical Tlr signaling 
pathways. The SGN transcriptome of DKO and WT mice indicated that there was an 
inverted gene set enrichment relationship between their different transcriptomes 
and the SGN degeneration transcriptome, which is consistent with the morphology 
results. Core module analysis suggested that DKO mice may modulate SGN 
degeneration by activating two clusters, and the involved molecules include EGF, 
STAT3, CALB2, LOX, SNAP25, CAV2, SDC4, MYL1, NCS1, PVALB, TPM4, and TMOD4.

Copyright © 2021 Wang, Shen, Pan, Chen, Ding, Zou, Zhang, Guo, Ji, Fan, Mei, Hu, 
Ye and Xiang.

DOI: 10.3389/fcell.2021.750271
PMCID: PMC8573328
PMID: 34760891

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


758. Front Psychol. 2017 Jun 13;8:689. doi: 10.3389/fpsyg.2017.00689. eCollection 
2017.

A Deficit in Movement-Derived Sentences in German-Speaking Hearing-Impaired 
Children.

Ruigendijk E(1), Friedmann N(2).

Author information:
(1)Department of Dutch and Cluster of Excellence "Hearing for All", University 
of OldenburgOldenburg, Germany.
(2)Language and Brain Lab, Tel Aviv UniversityTel Aviv, Israel.

Children with hearing impairment (HI) show disorders in syntax and morphology. 
The question is whether and how these disorders are connected to problems in the 
auditory domain. The aim of this paper is to examine whether moderate to severe 
hearing loss at a young age affects the ability of German-speaking orally 
trained children to understand and produce sentences. We focused on sentence 
structures that are derived by syntactic movement, which have been identified as 
a sensitive marker for syntactic impairment in other languages and in other 
populations with syntactic impairment. Therefore, our study tested subject and 
object relatives, subject and object Wh-questions, passive sentences, and 
topicalized sentences, as well as sentences with verb movement to second 
sentential position. We tested 19 HI children aged 9;5-13;6 and compared their 
performance with hearing children using comprehension tasks of sentence-picture 
matching and sentence repetition tasks. For the comprehension tasks, we included 
HI children who passed an auditory discrimination task; for the sentence 
repetition tasks, we selected children who passed a screening task of simple 
sentence repetition without lip-reading; this made sure that they could perceive 
the words in the tests, so that we could test their grammatical abilities. The 
results clearly showed that most of the participants with HI had considerable 
difficulties in the comprehension and repetition of sentences with syntactic 
movement: they had significant difficulties understanding object relatives, 
Wh-questions, and topicalized sentences, and in the repetition of object who and 
which questions and subject relatives, as well as in sentences with verb 
movement to second sentential position. Repetition of passives was only 
problematic for some children. Object relatives were still difficult at this age 
for both HI and hearing children. An additional important outcome of the study 
is that not all sentence structures are impaired-passive structures were not 
problematic for most of the HI children.

DOI: 10.3389/fpsyg.2017.00689
PMCID: PMC5468451
PMID: 28659836


759. EMBO Rep. 2019 Sep;20(9):e47097. doi: 10.15252/embr.201847097. Epub 2019 Jul 19.

Proteostasis is essential during cochlear development for neuron survival and 
hair cell polarity.

Freeman S(1), Mateo Sánchez S(1), Pouyo R(1), Van Lerberghe PB(1), Hanon K(1), 
Thelen N(1), Thiry M(1), Morelli G(1)(2), Van Hees L(1), Laguesse S(1), Chariot 
A(1)(3)(4), Nguyen L(1), Delacroix L(1), Malgrange B(1).

Author information:
(1)GIGA-Neurosciences, Interdisciplinary Cluster for Applied Genoproteomics 
(GIGA-R), C.H.U. Sart Tilman, University of Liège, Liège, Belgium.
(2)UHasselt, BIOMED, Hasselt, Belgium.
(3)GIGA-Molecular Biology of Diseases, Interdisciplinary Cluster for Applied 
Genoproteomics (GIGA-R), C.H.U. Sart Tilman, University of Liège, Liège, 
Belgium.
(4)Walloon Excellence in Life Sciences and Biotechnology (WELBIO), Wavre, 
Belgium.

Protein homeostasis is essential to cell function, and a compromised ability to 
reduce the load of misfolded and aggregated proteins is linked to numerous 
age-related diseases, including hearing loss. Here, we show that altered 
proteostasis consequent to Elongator complex deficiency also impacts the proper 
development of the cochlea and results in deafness. In the absence of the 
catalytic subunit Elp3, differentiating spiral ganglion neurons display large 
aggresome-like structures and undergo apoptosis before birth. The cochlear 
mechanosensory cells are able to survive proteostasis disruption but suffer 
defects in polarity and stereociliary bundle morphogenesis. We demonstrate that 
protein aggregates accumulate at the apical surface of hair cells, where they 
cause a local slowdown of microtubular trafficking, altering the distribution of 
intrinsic polarity proteins and affecting kinocilium position and length. 
Alleviation of protein misfolding using the chemical chaperone 4-phenylbutyric 
acid during embryonic development ameliorates hair cell polarity in 
Elp3-deficient animals. Our study highlights the importance of developmental 
proteostasis in the cochlea and unveils an unexpected link between proteome 
integrity and polarized organization of cellular components.

© 2019 The Authors.

DOI: 10.15252/embr.201847097
PMCID: PMC6726910
PMID: 31321879 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no conflict 
of interest.


760. Trends Hear. 2024 Jan-Dec;28:23312165241245219. doi: 10.1177/23312165241245219.

Remixing Preferences for Western Instrumental Classical Music of Bilateral 
Cochlear Implant Users.

Althoff J(1)(2), Gajecki T(1)(2), Nogueira W(1)(2).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, Hannover, Germany.
(2)Cluster of Excellence Hearing4all, Hanover, Germany.

For people with profound hearing loss, a cochlear implant (CI) is able to 
provide access to sounds that support speech perception. With current 
technology, most CI users obtain very good speech understanding in quiet 
listening environments. However, many CI users still struggle when listening to 
music. Efforts have been made to preprocess music for CI users and improve their 
music enjoyment. This work investigates potential modifications of instrumental 
music to make it more accessible for CI users. For this purpose, we used two 
datasets with varying complexity and containing individual tracks of 
instrumental music. The first dataset contained trios and it was newly created 
and synthesized for this study. The second dataset contained orchestral music 
with a large number of instruments. Bilateral CI users and normal hearing 
listeners were asked to remix the multitracks grouped into melody, bass, 
accompaniment, and percussion. Remixes could be performed in the amplitude, 
spatial, and spectral domains. Results showed that CI users preferred tracks 
being panned toward the right side, especially the percussion component. When CI 
users were grouped into frequent or occasional music listeners, significant 
differences in remixing preferences in all domains were observed.

DOI: 10.1177/23312165241245219
PMID: 38613359 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Conflicting InterestsThe authors 
declared no potential conflicts of interest with respect to the research, 
authorship, and/or publication of this article.


761. Mol Syndromol. 2021 Apr;12(2):127-132. doi: 10.1159/000513224. Epub 2021 Mar 2.

A Recurrent Variant in POLR1B, c.3007C>T; p.Arg1003Cys, Associated with Atresia 
of the External Canal and Microtia in Treacher Collins Syndrome Type 4.

Enomoto Y(1), Tsurusaki Y(1), Tominaga M(2), Kobayashi S(3), Inoue M(4), Fujita 
K(5), Kumaki T(2), Murakami H(2), Kurosawa K(1)(2).

Author information:
(1)Clinical Research Institute, Kanagawa Children's Medical Center, Yokohama, 
Japan.
(2)Division of Medical Genetics, Kanagawa Children's Medical Center, Yokohama, 
Japan.
(3)Department of Plastic and Reconstructive Surgery, Kanagawa Children's Medical 
Center, Yokohama, Japan.
(4)Department of Otolaryngology, Kanagawa Children's Medical Center, Yokohama, 
Japan.
(5)Department of Radiology, Kanagawa Children's Medical Center, Yokohama, Japan.

Treacher Collins syndrome (TCS) is a heterogenous malformation syndrome 
characterized by a distinct facial appearance including downslanting palpebral 
fissures, malar hypoplasia, conductive hearing loss, and mandibular hypoplasia. 
Recently, a new causative gene, POLR1B, encoding DNA-directed RNA polymerase I 
subunit RPA2, was identified as a fourth type of TCS (TCS4). We describe another 
patient with TCS4 caused by a recurrent POLR1B variant, c.3007C>T; p.Arg1003Cys. 
Including our patient, all 4 patients with p.(Arg1003Cys) had atresia of the 
external auditory canal and microtia. All of the reported pathogenic variants in 
POLR1B were clustered at only 2 residues. Our patient highlights the 
genotype-phenotype correlation in TCS4 associated with POLR1B.

Copyright © 2021 by S. Karger GmbH, Freiburg.

DOI: 10.1159/000513224
PMCID: PMC8114036
PMID: 34012383

Conflict of interest statement: The authors declare no conflict of interest.


762. Front Artif Intell. 2024 Feb 16;7:1349668. doi: 10.3389/frai.2024.1349668. 
eCollection 2024.

Digital accessibility in the era of artificial intelligence-Bibliometric 
analysis and systematic review.

Chemnad K(1), Othman A(1).

Author information:
(1)Mada Qatar Assistive Technology Center, Doha, Qatar.

INTRODUCTION: Digital accessibility involves designing digital systems and 
services to enable access for individuals, including those with disabilities, 
including visual, auditory, motor, or cognitive impairments. Artificial 
intelligence (AI) has the potential to enhance accessibility for people with 
disabilities and improve their overall quality of life.
METHODS: This systematic review, covering academic articles from 2018 to 2023, 
focuses on AI applications for digital accessibility. Initially, 3,706 articles 
were screened from five scholarly databases-ACM Digital Library, IEEE Xplore, 
ScienceDirect, Scopus, and Springer.
RESULTS: The analysis narrowed down to 43 articles, presenting a classification 
framework based on applications, challenges, AI methodologies, and accessibility 
standards.
DISCUSSION: This research emphasizes the predominant focus on AI-driven digital 
accessibility for visual impairments, revealing a critical gap in addressing 
speech and hearing impairments, autism spectrum disorder, neurological 
disorders, and motor impairments. This highlights the need for a more balanced 
research distribution to ensure equitable support for all communities with 
disabilities. The study also pointed out a lack of adherence to accessibility 
standards in existing systems, stressing the urgency for a fundamental shift in 
designing solutions for people with disabilities. Overall, this research 
underscores the vital role of accessible AI in preventing exclusion and 
discrimination, urging a comprehensive approach to digital accessibility to 
cater to diverse disability needs.

Copyright © 2024 Chemnad and Othman.

DOI: 10.3389/frai.2024.1349668
PMCID: PMC10905618
PMID: 38435800

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


763. Front Digit Health. 2021 Aug 13;3:723348. doi: 10.3389/fdgth.2021.723348. 
eCollection 2021.

Bayesian Pure-Tone Audiometry Through Active Learning Under Informed Priors.

Cox M(1), de Vries B(1)(2).

Author information:
(1)Signal Processing Systems Group, Department of Electrical Engineering, 
Eindhoven University of Technology, Eindhoven, Netherlands.
(2)GN Hearing, Eindhoven, Netherlands.

Pure-tone audiometry-the process of estimating a person's hearing threshold from 
"audible" and "inaudible" responses to tones of varying frequency and 
intensity-is the basis for diagnosing and quantifying hearing loss. By taking a 
probabilistic modeling approach, both optimal tone selection (in terms of 
expected information gain) and hearing threshold estimation can be derived 
through Bayesian inference methods. The performance of probabilistic model-based 
audiometry methods is directly linked to the quality of the underlying model. In 
recent years, Gaussian process (GP) models have been shown to provide good 
results in this context. We present methods to improve the efficiency of 
GP-based audiometry procedures by improving the underlying model. Instead of a 
single GP, we propose to use a GP mixture model that can be conditioned on 
side-information about the subject. The underlying idea is that one can 
typically distinguish between different types of hearing thresholds, enabling a 
mixture model to better capture the statistical properties of hearing thresholds 
among a population. Instead of modeling all hearing thresholds by a single GP, a 
mixture model allows specific types of hearing thresholds to be modeled by 
independent GP models. Moreover, the mixing coefficients can be conditioned on 
side-information such as age and gender, capturing the correlations between age, 
gender, and hearing threshold. We show how a GP mixture model can be optimized 
for a specific target population by learning the parameters from a data set 
containing annotated audiograms. We also derive an optimal tone selection method 
based on greedy information gain maximization, as well as hearing threshold 
estimation through Bayesian inference. The proposed models are fitted to a data 
set containing roughly 176 thousand annotated audiograms collected in the Nordic 
countries. We compare the predictive accuracies of optimized mixture models of 
varying sizes with that of an optimized single-GP model. The usefulness of the 
optimized models is tested in audiometry simulations. Simulation results 
indicate that an optimized GP mixture model can significantly outperform an 
optimized single-GP model in terms of predictive accuracy, and leads to 
significant increases the efficiency of the resulting Bayesian audiometry 
procedure.

Copyright © 2021 Cox and de Vries.

DOI: 10.3389/fdgth.2021.723348
PMCID: PMC8521968
PMID: 34713188

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


764. Neuroradiol J. 2024 Jan 16:19714009231224415. doi: 10.1177/19714009231224415. 
Online ahead of print.

Prevalence of Scarpa's ganglion enhancement on high-resolution MRI imaging.

Siminski C(1), Benson JC(1), Carlson ML(2), Lane JI(1).

Author information:
(1)Department of Radiology, Mayo Clinic, Rochester, MN, USA.
(2)Department of Otolaryngology-Head and Neck Surgery, Mayo Clinic, Rochester, 
MN, USA.

BACKGROUND AND PURPOSE: The vestibular ganglion, or Scarpa's ganglion, is a 
cluster of afferent vestibular neurons within the internal auditory canal (IAC). 
There is minimal literature describing enhancement of this region on magnetic 
resonance imaging (MRI) and its correlation to clinical symptoms. Here, we 
sought to find the prevalence of enhancement at Scarpa's ganglion, and determine 
whether such enhancement correlates with demographics or clinical symptoms.
MATERIALS AND METHODS: A retrospective review was performed of consecutive 
patients with an MRI of the IAC between 3/1/2021 and 5/20/2021. Two 
neuroradiologists independently reviewed for T1 and FLAIR enhancement of the 
Scarpa's ganglion on post-contrast fat-saturated T1 and post-contrast FLAIR 
images. Discrepancies were agreed upon by consensus. Clinical variables (hearing 
loss, vestibular symptoms, tinnitus, and MRI indication) were gathered from a 
retrospective chart review.
RESULTS: Eighty-nine patients were included (51 female); the mean age was 58 
(range 19-85). The most common MRI indication was hearing loss (n = 53). FLAIR 
enhancement was present on the right in 7 patients, on the left in 7 patients, 
and bilaterally in 6 patients. No enhancement was seen on post-contrast T1 
images. There was no statistically significant correlation between consensus 
FLAIR on at least one side and age (p = .74), gender (p = .29), hearing loss (p 
= .32), hearing loss side (p = .39), type of hearing loss (p = .87), vestibular 
symptoms (p = .71), or tinnitus (p = .81).
CONCLUSIONS: Enhancement is present in the minority of patients on post-contrast 
FLAIR images. If seen, it should be considered an uncommon but not unexpected 
finding with no clinical significance.

DOI: 10.1177/19714009231224415
PMID: 38226489

Conflict of interest statement: Declaration of conflicting interestsThe 
author(s) declared no potential conflicts of interest with respect to the 
research, authorship, and/or publication of this article.


765. Front Digit Health. 2022 Jul 13;4:959761. doi: 10.3389/fdgth.2022.959761. 
eCollection 2022.

Editorial: Digital hearing healthcare.

Meng Q(1)(2), Chen J(3)(4), Zhang C(5), Wasmann JA(6), Barbour DL(7), Zeng 
FG(8).

Author information:
(1)Acoustics Laboratory, School of Physics and Optoelectronics, South China 
University of Technology, Guangzhou, China.
(2)n3 Hearing Laboratory, Guangzhou, China.
(3)Key Laboratory of Machine Perception (Ministry of Education), School of 
Artificial Intelligence, Speech and Hearing Research Center, Peking University, 
Beijing, China.
(4)National Biomedical Imaging Center, College of Future Technology, Peking 
University, Beijing, China.
(5)Faculty of Education, East China Normal University, Shanghai, China.
(6)Department of Otorhinolaryngology, Donders Institute for Brain, Cognition and 
Behaviour, Radboud University Medical Center Nijmegen, Nijmegen, Netherlands.
(7)Laboratory of Sensory Neuroscience and Neuroengineering, Department of 
Biomedical Engineering, Washington University in St. Louis, St. Louis, MO, 
United States.
(8)Department of Otolaryngology - Head and Neck Surgery, Center for Hearing 
Research, University of California, Irvine, Irvine, CA, United States.

Comment on
    Editorial on the Research Topic Digital Hearing Healthcare.

DOI: 10.3389/fdgth.2022.959761
PMCID: PMC9326398
PMID: 35911617


766. Laryngoscope. 2005 Jul;115(7):1136-44. doi: 10.1097/01.MLG.0000165369.65046.CD.

Frequency map variations in squirrel monkey primary auditory cortex.

Cheung SW(1).

Author information:
(1)Coleman Memorial Laboratory and W. M. Keck Center for Integrative 
Neuroscience, Division of Otology, Neurotology and Skull Base Surgery, 
University of California, San Francisco, California 94143, USA. 
scheung@ohns.ucsf.edu

OBJECTIVE: The goal of this work is to understand the neural basis for cortical 
representation of hearing in highly vocal primates to gain insights into the 
substrates for communication. Variation patterns in frequency representation 
among animals are incorporated into an explanatory model to reconcile 
heterogeneous observations.
STUDY DESIGN: Prospective.
METHODS: Thirty-four squirrel monkeys underwent microelectrode mapping 
experiments in primary auditory cortex (AI) using tone pip stimuli. 
Characteristic frequency (CF) was extracted from the excitatory frequency 
receptive field. Frequency maps were reconstructed using Voronoi-Dirichlet 
tessellation. The spatial locations (rostral vs. caudal) of highest CF 
isofrequency contours (minimum length 1 mm) and highest CF neuronal clusters on 
the temporal gyral surface were analyzed.
RESULTS: Isofrequency contours at least 1 mm long with CFs greater than 2.9 kHz 
(75% cases) are accessible on the temporal gyrus. Variability of the highest CF 
isofrequency contours accessible on the temporal gyrus has an interquartile 
range from 2.9 to 5.1 (mean 4.3) kHz. The highest CF isofrequency contours are 
located mainly in rostral AI, whereas the highest CF neuronal clusters flanking 
fully expressed isofrequency contours are equally distributed in rostral and 
caudal locations.
CONCLUSIONS: Squirrel monkey AI frequency map variations are sizeable across 
animals and small within single animals (interhemispheric comparison). AI 
frequency map variations, modeled as translations and rotations relative to the 
lateral sulcus, are independent transfers. Caution must be exercised when 
interpreting nominal frequency map changes that are attributed to hearing loss 
and auditory learning effects.

DOI: 10.1097/01.MLG.0000165369.65046.CD
PMID: 15995498 [Indexed for MEDLINE]


767. Front Neuroergon. 2022 Jan 6;2:802486. doi: 10.3389/fnrgo.2021.802486. 
eCollection 2021.

Benchmarking cEEGrid and Solid Gel-Based Electrodes to Classify Inattentional 
Deafness in a Flight Simulator.

Somon B(1)(2), Giebeler Y(2)(3), Darmet L(2), Dehais F(1)(2)(4).

Author information:
(1)Artificial and Natural Intelligence Toulouse Institute, Université de 
Toulouse, Toulouse, France.
(2)Department for Aerospace Vehicles Design and Control, ISAE-SUPAERO, 
Université de Toulouse, Toulouse, France.
(3)Department of Psychology and Ergonomics, Technische Universität Berlin, 
Berlin, Germany.
(4)School of Biomedical Engineering, Science and Health Systems, Drexel 
University, Philadelphia, PA, United States.

Transfer from experiments in the laboratory to real-life tasks is challenging 
due notably to the inability to reproduce the complexity of multitasking dynamic 
everyday life situations in a standardized lab condition and to the bulkiness 
and invasiveness of recording systems preventing participants from moving freely 
and disturbing the environment. In this study, we used a motion flight simulator 
to induce inattentional deafness to auditory alarms, a cognitive difficulty 
arising in complex environments. In addition, we assessed the possibility of two 
low-density EEG systems a solid gel-based electrode Enobio (Neuroelectrics, 
Barcelona, Spain) and a gel-based cEEGrid (TMSi, Oldenzaal, Netherlands) to 
record and classify brain activity associated with inattentional deafness 
(misses vs. hits to odd sounds) with a small pool of expert participants. In 
addition to inducing inattentional deafness (missing auditory alarms) at much 
higher rates than with usual lab tasks (34.7% compared to the usual 5%), we 
observed typical inattentional deafness-related activity in the time domain but 
also in the frequency and time-frequency domains with both systems. Finally, a 
classifier based on Riemannian Geometry principles allowed us to obtain more 
than 70% of single-trial classification accuracy for both mobile EEG, and up to 
71.5% for the cEEGrid (TMSi, Oldenzaal, Netherlands). These results open 
promising avenues toward detecting cognitive failures in real-life situations, 
such as real flight.

Copyright © 2022 Somon, Giebeler, Darmet and Dehais.

DOI: 10.3389/fnrgo.2021.802486
PMCID: PMC10790867
PMID: 38235232

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


768. Otol Neurotol. 2012 Dec;33(9):1656-63. doi: 10.1097/MAO.0b013e31826bedd9.

Mannitol protects hair cells against tumor necrosis factor α-induced loss.

Infante EB(1), Channer GA, Telischi FF, Gupta C, Dinh JT, Vu L, Eshraghi AA, Van 
De Water TR.

Author information:
(1)Cochlear Implant Research Program, University of Miami Ear Institute, Miami, 
Florida 33136-1015, USA.

HYPOTHESIS: Mannitol has otoprotective effects against tumor necrosis factor 
(TNF) α-induced auditory hair cell (HC) loss.
BACKGROUND: Mannitol has been demonstrated to possess cytoprotective effects in 
several organ systems. Its protective effect on postischemic hearing loss has 
also been shown. Mannitol's otoprotective mechanism and site of action are at 
present unknown.
MATERIALS AND METHODS: Organ of Corti (OC) explants were dissected from 3 
day-old rat pups. The safety (nonototoxicity) of mannitol was assessed at 4 
different concentrations (1-100 mM). Three experimental arms were designed 
including: a control group, TNFα group, and TNFα + mannitol group. Cell 
viability was determined by counts of fluorescein isothiocyanate (FITC) 
phalloidin stained HC. Immunofluorescence assay of phospho-c-Jun and the 
proapoptotic mediators, cleaved caspase-3, apoptosis inducing factor (AIF), and 
endonuclease G (Endo G) were performed.
RESULTS: Analysis of HC density confirmed the safety of mannitol at 
concentration ranges of 1 to 100 mM. The ototoxic effect of TNFα was 
demonstrated (p < 0.05). The otoprotective effect of 100 mM mannitol in 
TNFα-challenged OC explants was also demonstrated (p < 0.001). Mannitol 
treatment reduced the high levels of phospho-c-Jun observed in the 
TNFα-challenged group. AIF cluster formation and EndoG translocation into the 
nuclei of HCs were also reduced by mannitol treatment.
CONCLUSION: Mannitol significantly reduces the ototoxic effects of TNFα against 
auditory HC's potentially by inhibiting c-Jun N terminal kinase (JNK) activation 
pathway and AIF, EndoG nuclear translocation. This local otoprotective effect 
may have therapeutic implications in inner ear surgery, for example, cochlear 
implants, protection of residual hearing, as well as implications for 
postischemic inner ear insults.

DOI: 10.1097/MAO.0b013e31826bedd9
PMID: 22996158 [Indexed for MEDLINE]


769. PeerJ Comput Sci. 2022 Feb 18;8:e883. doi: 10.7717/peerj-cs.883. eCollection 
2022.

Recognition of Urdu sign language: a systematic review of the machine learning 
classification.

Zahid H(1), Rashid M(2), Hussain S(3), Azim F(4), Syed SA(5), Saad A(6).

Author information:
(1)Faculty of Engineering Science Technology and Management, Department of 
Biomedical Engineering and Department of Electrical Engineering, Ziauddin 
University, Karachi, Pakistan.
(2)Faculty of Engineering Science Technology and Management, Department of 
Electrical Engineering and Department of Software Engineering, Ziauddin 
University, Karachi, Pakistan.
(3)HESSA Project, US AID Program, Karachi, Pakistan.
(4)Faculty of Engineering Science Technology and Management, Electrical 
Engineering Department, Ziauddin University, Karachi, Pakistan.
(5)Faculty of Engineering Science Technology and Management, Department of 
Biomedical Engineering, Ziauddin University, Karachi, Pakistan.
(6)Computer Science Department, Muhammad Ali Jinnah University, Karachi, 
Pakistan.

BACKGROUND AND OBJECTIVE: Humans communicate with one another using language 
systems such as written words or body language (movements), hand motions, head 
gestures, facial expressions, lip motion, and many more. Comprehending sign 
language is just as crucial as learning a natural language. Sign language is the 
primary mode of communication for those who have a deaf or mute impairment or 
are disabled. Without a translator, people with auditory difficulties have 
difficulty speaking with other individuals. Studies in automatic recognition of 
sign language identification utilizing machine learning techniques have recently 
shown exceptional success and made significant progress. The primary objective 
of this research is to conduct a literature review on all the work completed on 
the recognition of Urdu Sign Language through machine learning classifiers to 
date.
MATERIALS AND METHODS: All the studies have been extracted from databases, i.e., 
PubMed, IEEE, Science Direct, and Google Scholar, using a structured set of 
keywords. Each study has gone through proper screening criteria, i.e., exclusion 
and inclusion criteria. PRISMA guidelines have been followed and implemented 
adequately throughout this literature review.
RESULTS: This literature review comprised 20 research articles that fulfilled 
the eligibility requirements. Only those articles were chosen for additional 
full-text screening that follows eligibility requirements for peer-reviewed and 
research articles and studies issued in credible journals and conference 
proceedings until July 2021. After other screenings, only studies based on Urdu 
Sign language were included. The results of this screening are divided into two 
parts; (1) a summary of all the datasets available on Urdu Sign Language. (2) a 
summary of all the machine learning techniques for recognizing Urdu Sign 
Language.
CONCLUSION: Our research found that there is only one publicly-available USL 
sign-based dataset with pictures versus many character-, number-, or 
sentence-based publicly available datasets. It was also concluded that besides 
SVM and Neural Network, no unique classifier is used more than once. 
Additionally, no researcher opted for an unsupervised machine learning 
classifier for detection. To the best of our knowledge, this is the first 
literature review conducted on machine learning approaches applied to Urdu sign 
language.

©2022 Zahid et al.

DOI: 10.7717/peerj-cs.883
PMCID: PMC9044266
PMID: 35494799

Conflict of interest statement: The authors declare there are no competing 
interests.


770. Hear Res. 2021 Sep 1;408:108305. doi: 10.1016/j.heares.2021.108305. Epub 2021 
Jul 9.

Sensitivity to interaural time differences in the inferior colliculus of 
cochlear implanted rats with or without hearing experience.

Buck AN(1), Rosskothen-Kuhl N(2), Schnupp JW(3).

Author information:
(1)Department of Neouroscience, City University of Hong Kong, 31 To Yuen Street, 
Kowloon, Hong Kong SAR, China; City University of Hong Kong Shenzhen Research 
Institute, Shenzhen, China. Electronic address: alexanbuck@gmail.com.
(2)Department of Neouroscience, City University of Hong Kong, 31 To Yuen Street, 
Kowloon, Hong Kong SAR, China; Neurobiological Research Laboratory, Section for 
Clinical and Experimental Otology, University Medical Center Freiburg, 
Killianstr. 5, 79106 Freiburg i. Br., Freiburg, Germany. Electronic address: 
nicole.rosskothen-kuhl@uniklinik-freiburg.de.
(3)Department of Neouroscience, City University of Hong Kong, 31 To Yuen Street, 
Kowloon, Hong Kong SAR, China; City University of Hong Kong Shenzhen Research 
Institute, Shenzhen, China. Electronic address: wschnupp@cityu.edu.hk.

For deaf patients cochlear implants (CIs) can restore substantial amounts of 
functional hearing. However, binaural hearing, and in particular, the perception 
of interaural time differences (ITDs) with current CIs has been found to be 
notoriously poor, especially in the event of early hearing loss. One popular 
hypothesis for these deficits posits that a lack of early binaural experience 
may be a principal cause of poor ITD perception in pre-lingually deaf CI 
patients. This is supported by previous electrophysiological studies done in 
neonatally deafened, bilateral CI-stimulated animals showing reduced ITD 
sensitivity. However, we have recently demonstrated that neonatally deafened CI 
rats can quickly learn to discriminate microsecond ITDs under optimized 
stimulation conditions which suggests that the inability of human CI users to 
make use of ITDs is not due to lack of binaural hearing experience during 
development. In the study presented here, we characterized ITD sensitivity and 
tuning of inferior colliculus neurons under bilateral CI stimulation of 
neonatally deafened and hearing experienced rats. The hearing experienced rats 
were not deafened prior to implantation. Both cohorts were implanted bilaterally 
between postnatal days 64-77 and recorded immediately following surgery. Both 
groups showed comparably large proportions of ITD sensitive multi-units in the 
inferior colliculus (Deaf: 84.8%, Hearing: 82.5%), and the strength of ITD 
tuning, quantified as mutual information between response and stimulus ITD, was 
independent of hearing experience. However, the shapes of tuning curves differed 
substantially between both groups. We observed four main clusters of tuning 
curves - trough, contralateral, central, and ipsilateral tuning. Interestingly, 
over 90% of multi-units for hearing experienced rats showed predominantly 
contralateral tuning, whereas as many as 50% of multi-units in neonatally 
deafened rats were centrally tuned. However, when we computed neural d' scores 
to predict likely limits on performance in sound lateralization tasks, we did 
not find that these differences in tuning shapes predicted worse psychoacoustic 
performance for the neonatally deafened animals. We conclude that, at least in 
rats, substantial amounts of highly precise, "innate" ITD sensitivity can be 
found even after profound hearing loss throughout infancy. However, ITD tuning 
curve shapes appear to be strongly influenced by auditory experience although 
substantial lateralization encoding is present even in its absence.

Copyright © 2021. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2021.108305
PMID: 34315027 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no competing interests.


771. bioRxiv [Preprint]. 2024 Jan 23:2023.12.21.572886. doi: 
10.1101/2023.12.21.572886.

Fast inhibition slows and desynchronizes mouse auditory efferent neuron 
activity.

Fischl M(1)(2), Pederson A(1)(3), Voglewede R(1), Cheng H(4), Drew J(1)(5), 
Cadenas LT(1), Weisz CJC(1).

Author information:
(1)Section on Neuronal Circuitry, National Institute on Deafness and Other 
Communication Disorders, NIH, Bethesda, MD 20892, USA.
(2)Current affiliation: Lafayette College, Neuroscience Program, Easton, PA 
18042, USA.
(3)Current affiliation: The University of Texas at Austin Dell Medical School, 
Austin, TX 78712, USA.
(4)Bioinformatics and Biostatistics Collaboration Core, National Institute on 
Deafness and Other Communication Disorders, NIH, Bethesda, MD 20892, USA.
(5)Current affiliation: Institute for Learning and Brain Sciences, University of 
Washington, Seattle, WA, 98195, USA.

The encoding of acoustic stimuli requires precise neuron timing. Auditory 
neurons in the cochlear nucleus (CN) and brainstem are well-suited for accurate 
analysis of fast acoustic signals, given their physiological specializations of 
fast membrane time constants, fast axonal conduction, and reliable synaptic 
transmission. The medial olivocochlear (MOC) neurons that provide efferent 
inhibition of the cochlea reside in the ventral brainstem and participate in 
these fast neural circuits. However, their modulation of cochlear function 
occurs over time scales of a slower nature. This suggests the presence of 
mechanisms that restrict MOC inhibition of cochlear function. To determine how 
monaural excitatory and inhibitory synaptic inputs integrate to affect the 
timing of MOC neuron activity, we developed a novel in vitro slice preparation 
('wedge-slice'). The wedge-slice maintains the ascending auditory nerve root, 
the entire CN and projecting axons, while preserving the ability to perform 
visually guided patch-clamp electrophysiology recordings from genetically 
identified MOC neurons. The 'in vivo-like' timing of the wedge-slice 
demonstrates that the inhibitory pathway accelerates relative to the excitatory 
pathway when the ascending circuit is intact, and the CN portion of the 
inhibitory circuit is precise enough to compensate for reduced precision in 
later synapses. When combined with machine learning PSC analysis and 
computational modeling, we demonstrate a larger suppression of MOC neuron 
activity when the inhibition occurs with in vivo-like timing. This delay of MOC 
activity may ensure that the MOC system is only engaged by sustained background 
sounds, preventing a maladaptive hyper-suppression of cochlear activity.

DOI: 10.1101/2023.12.21.572886
PMCID: PMC10836066
PMID: 38313270

Conflict of interest statement: Conflicts of Interest: The authors declare no 
competing financial interests.


772. Hear Res. 2020 Jun;391:107950. doi: 10.1016/j.heares.2020.107950. Epub 2020 Mar 
16.

Loss of inner hair cell ribbon synapses and auditory nerve fiber regression in 
Cldn14 knockout mice.

Claußen M(1), Schulze J(2), Nothwang HG(3).

Author information:
(1)Division of Neurogenetics, Department of Neurosciences, Faculty for Medicine 
and Health Sciences, Carl von Ossietzky University Oldenburg, Oldenburg, 
Germany; Cluster of Excellence "Hearing4all", Germany. Electronic address: 
maike.claussen@uol.de.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, Hannover, Germany; Cluster of Excellence "Hearing4all", Germany.
(3)Division of Neurogenetics, Department of Neurosciences, Faculty for Medicine 
and Health Sciences, Carl von Ossietzky University Oldenburg, Oldenburg, 
Germany; Cluster of Excellence "Hearing4all", Germany.

Proper functioning of the auditory nerve is of critical importance for auditory 
rehabilitation by cochlear implants. Here we used the Cldn14-/- mouse to study 
in detail the effects of Claudin 14 loss on auditory synapses and the auditory 
nerve. Mutations in the tight junction protein Claudin 14 cause autosomal 
recessive non-syndromic hearing loss (DFNB29) in humans and mice, due to 
extensive degeneration of outer and inner hair cells. Here we show that massive 
inner hair cell loss in Cldn14-/- mice starts after the third postnatal week. 
Immunohistochemical analysis, using presynaptic Ribeye and postsynaptic GluR2 or 
PSD 95 as markers, revealed the degeneration of full ribbon synapses in inner 
hair cells from apical cochlear regions already at postnatal day 12 (P12). At 
P20, significant reduction in number of ribbon synapses has been observed for 
all cochlear regions and the loss of synaptic ribbons becomes even more 
prominent in residual inner hair cells from middle and apical cochlear regions 
at P45, which by then lost more than 40% of all ribbon synapses. In contrast to 
excessive noise exposure, loss of Claudin 14 does not cause an increase in 
"orphan" ribbons with no postsynaptic counterpart due to a reduction of 
postsynaptic structures. Hair cell loss in Cldn14-/- mice is associated with 
regression of peripheral auditory nerve processes, especially of outer radial 
fibers, which normally innervate the outer hair cells. The number of spiral 
ganglion neurons per area, however, was unchanged between the genotypes. 
Different effects were observed in the cochlear nucleus complex (CNC), the 
central projection area of the auditory nerve. While the dorsal cochlear nucleus 
(DCN) showed a significant 19.7% volume reduction, VGLUT-1 input was reduced by 
34.4% in the ventral cochlear nucleus (VCN) but not in the DCN of Cldn14-/- 
mice. Taken together, massive inner hair cell loss starts after the third 
postnatal week in Cldn14-/- mice, but is preceded by the loss of ribbon 
synapses, which may be a first sign of an ongoing degeneration process in 
otherwise morphologically inconspicuously inner hair cells. In addition to the 
regression of peripheral nerve processes, reduced levels of VGLUT-1 in the VCN 
of Cldn14-/- mice suggests that Claudin 14 loss does not only cause hair cell 
loss but also affects peripheral and central connectivity of the auditory nerve.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2020.107950
PMID: 32251970 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare no competing financial interests.


773. PLoS One. 2009 Sep 23;4(9):e7144. doi: 10.1371/journal.pone.0007144.

Genomic analysis of the function of the transcription factor gata3 during 
development of the mammalian inner ear.

Milo M(1), Cacciabue-Rivolta D, Kneebone A, Van Doorninck H, Johnson C, 
Lawoko-Kerali G, Niranjan M, Rivolta M, Holley M.

Author information:
(1)NIHR Cardiovascular Biomedical Research Unit, Sheffield Teaching Hospitals 
NHS Trust, Sheffield, United Kingdom.

We have studied the function of the zinc finger transcription factor gata3 in 
auditory system development by analysing temporal profiles of gene expression 
during differentiation of conditionally immortal cell lines derived to model 
specific auditory cell types and developmental stages. We tested and applied a 
novel probabilistic method called the gamma Model for Oligonucleotide Signals to 
analyse hybridization signals from Affymetrix oligonucleotide arrays. Expression 
levels estimated by this method correlated closely (p<0.0001) across a 10-fold 
range with those measured by quantitative RT-PCR for a sample of 61 different 
genes. In an unbiased list of 26 genes whose temporal profiles clustered most 
closely with that of gata3 in all cell lines, 10 were linked to Insulin-like 
Growth Factor signalling, including the serine/threonine kinase Akt/PKB. 
Knock-down of gata3 in vitro was associated with a decrease in expression of 
genes linked to IGF-signalling, including IGF1, IGF2 and several IGF-binding 
proteins. It also led to a small decrease in protein levels of the 
serine-threonine kinase Akt2/PKBbeta, a dramatic increase in Akt1/PKBalpha 
protein and relocation of Akt1/PKBalpha from the nucleus to the cytoplasm. The 
cyclin-dependent kinase inhibitor p27(kip1), a known target of PKB/Akt, 
simultaneously decreased. In heterozygous gata3 null mice the expression of 
gata3 correlated with high levels of activated Akt/PKB. This functional 
relationship could explain the diverse function of gata3 during development, the 
hearing loss associated with gata3 heterozygous null mice and the broader 
symptoms of human patients with Hearing-Deafness-Renal anomaly syndrome.

DOI: 10.1371/journal.pone.0007144
PMCID: PMC2742898
PMID: 19774072 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


774. Front Bioeng Biotechnol. 2016 Nov 23;4:84. doi: 10.3389/fbioe.2016.00084. 
eCollection 2016.

Validation of a Cochlear Implant Patient-Specific Model of the Voltage 
Distribution in a Clinical Setting.

Nogueira W(1), Schurzig D(1), Büchner A(1), Penninger RT(1), Würfel W(1).

Author information:
(1)Department of Otolaryngology, Cluster of Excellence "Hearing4all", Medical 
University Hannover , Hannover , Germany.

Cochlear Implants (CIs) are medical implantable devices that can restore the 
sense of hearing in people with profound hearing loss. Clinical trials assessing 
speech intelligibility in CI users have found large intersubject variability. 
One possibility to explain the variability is the individual differences in the 
interface created between electrodes of the CI and the auditory nerve. In order 
to understand the variability, models of the voltage distribution of the 
electrically stimulated cochlea may be useful. With this purpose in mind, we 
developed a parametric model that can be adapted to each CI user based on 
landmarks from individual cone beam computed tomography (CBCT) scans of the 
cochlea before and after implantation. The conductivity values of each cochlea 
compartment as well as the weighting factors of different grounding modes have 
also been parameterized. Simulations were performed modeling the cochlea and 
electrode positions of 12 CI users. Three models were compared with different 
levels of detail: a homogeneous model (HM), a non-patient-specific model (NPSM), 
and a patient-specific model (PSM). The model simulations were compared with 
voltage distribution measurements obtained from the backward telemetry of the 12 
CI users. Results show that the PSM produces the lowest error when predicting 
individual voltage distributions. Given a patient-specific geometry and 
electrode positions, we show an example on how to optimize the parameters of the 
model and how to couple it to an auditory nerve model. The model here presented 
may help to understand speech performance variability and support the 
development of new sound coding strategies for CIs.

DOI: 10.3389/fbioe.2016.00084
PMCID: PMC5120131
PMID: 27933290


775. Prog Brain Res. 2021;262:189-207. doi: 10.1016/bs.pbr.2021.01.026. Epub 2021 Mar 
10.

Altered brain responses to emotional facial expressions in tinnitus patients.

Rosengarth K(1), Kleinjung T(2), Langguth B(3), Landgrebe M(4), Lohaus F(5), 
Greenlee MW(6), Hajak G(7), Schmidt NO(8), Schecklmann M(3).

Author information:
(1)Department of Neurosurgery, University of Regensburg, Regensburg, Germany; 
Department of Experimental Psychology, University of Regensburg, Regensburg, 
Germany. Electronic address: katharina.rosengarth@ukr.de.
(2)Department of Otorhinolaryngology, University of Zurich, Zürich, Switzerland; 
Department of Otorhinolaryngology, University of Regensburg, Regensburg, 
Germany.
(3)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany.
(4)Department of Psychiatry, Psychosomatics and Psychotherapy, kbo 
Lech-Mangfall-Hospital Agatharied, Hausham, Germany.
(5)Department of Radiotherapy and Radiation Oncology, Faculty of Medicine and 
University Hospital Carl Gustav Carus, Dresden, Germany.
(6)Department of Experimental Psychology, University of Regensburg, Regensburg, 
Germany.
(7)Department of Psychiatry, Psychosomatics and Psychotherapy, Sozialstiftung 
Bamberg, Bamberg, Germany.
(8)Department of Neurosurgery, University of Regensburg, Regensburg, Germany.

Tinnitus, the phantom perception of sound, is a frequent disorder that can lead 
to severe distress and stress-related comorbidity. The pathophysiological 
mechanisms involved in the etiology of tinnitus are still under exploration. 
Electrophysiological and functional neuroimaging studies provide increasing 
evidence for abnormal functioning in auditory but also in non-auditory, e.g., 
emotional, brain areas. In order to elucidate alterations of affective 
processing in patients with chronic tinnitus, we used functional magnetic 
resonance imaging (fMRI) to measure neural responses to emotionally expressive 
and neutral faces. Twelve patients with chronic tinnitus and a group of 11 
healthy controls, matched for age, sex, hearing loss and depressive symptoms 
were investigated. While viewing emotionally expressive faces compared to 
neutral faces brain activations in the tinnitus patients differed from those of 
the controls in a cluster that encompasses the amygdala, the hippocampus and the 
parahippocampal gyrus bilaterally. Whereas in controls affective faces induced 
higher brain activation in these regions than neutral faces, these regions in 
tinnitus patients were deactivated. Our results (1) provide evidence for 
alterations of affective processing of facial expressions in tinnitus patients 
indicating general domain-unspecific dysfunctions in emotion processing and (2) 
indicate the involvement of medial temporal areas in the pathophysiology of 
tinnitus.

Copyright © 2021 Elsevier B.V. All rights reserved.

DOI: 10.1016/bs.pbr.2021.01.026
PMID: 33931179 [Indexed for MEDLINE]


776. Cell. 2010 May 14;141(4):704-16. doi: 10.1016/j.cell.2010.03.035.

Mechanosensitive hair cell-like cells from embryonic and induced pluripotent 
stem cells.

Oshima K(1), Shin K, Diensthuber M, Peng AW, Ricci AJ, Heller S.

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Stanford University 
School of Medicine, Stanford, CA 94305, USA.

Mechanosensitive sensory hair cells are the linchpin of our senses of hearing 
and balance. The inability of the mammalian inner ear to regenerate lost hair 
cells is the major reason for the permanence of hearing loss and certain balance 
disorders. Here, we present a stepwise guidance protocol starting with mouse 
embryonic stem and induced pluripotent stem cells, which were directed toward 
becoming ectoderm capable of responding to otic-inducing growth factors. The 
resulting otic progenitor cells were subjected to varying differentiation 
conditions, one of which promoted the organization of the cells into epithelial 
clusters displaying hair cell-like cells with stereociliary bundles. 
Bundle-bearing cells in these clusters responded to mechanical stimulation with 
currents that were reminiscent of immature hair cell transduction currents.

Copyright (c) 2010 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cell.2010.03.035
PMCID: PMC2873974
PMID: 20478259 [Indexed for MEDLINE]


777. Cell Rep. 2024 Apr 1;43(4):114025. doi: 10.1016/j.celrep.2024.114025. Online 
ahead of print.

BAI1 localizes AMPA receptors at the cochlear afferent post-synaptic density and 
is essential for hearing.

Carlton AJ(1), Jeng JY(1), Grandi FC(2), De Faveri F(1), Amariutei AE(1), De 
Tomasi L(1), O'Connor A(1), Johnson SL(3), Furness DN(4), Brown SDM(5), Ceriani 
F(1), Bowl MR(5), Mustapha M(3), Marcotti W(6).

Author information:
(1)School of Biosciences, University of Sheffield, Sheffield S10 2TN, UK.
(2)Sorbonne Université, INSERM, Institute de Myologie, Centre de Recherche en 
Myologie, 75013 Paris, France.
(3)School of Biosciences, University of Sheffield, Sheffield S10 2TN, UK; 
Neuroscience Institute, University of Sheffield, Sheffield S10 2TN, UK.
(4)School of Life Sciences, Keele University, Keele ST5 5BG, UK.
(5)Mammalian Genetics Unit, MRC Harwell Institute, Harwell Campus, Oxfordshire 
OX11 0RD, UK.
(6)School of Biosciences, University of Sheffield, Sheffield S10 2TN, UK; 
Neuroscience Institute, University of Sheffield, Sheffield S10 2TN, UK. 
Electronic address: w.marcotti@sheffield.ac.uk.

Type I spiral ganglion neurons (SGNs) convey sound information to the central 
auditory pathway by forming synapses with inner hair cells (IHCs) in the 
mammalian cochlea. The molecular mechanisms regulating the formation of the 
post-synaptic density (PSD) in the SGN afferent terminals are still unclear. 
Here, we demonstrate that brain-specific angiogenesis inhibitor 1 (BAI1) is 
required for the clustering of AMPA receptors GluR2-4 (glutamate receptors 2-4) 
at the PSD. Adult Bai1-deficient mice have functional IHCs but fail to transmit 
information to the SGNs, leading to highly raised hearing thresholds. Despite 
the almost complete absence of AMPA receptor subunits, the SGN fibers 
innervating the IHCs do not degenerate. Furthermore, we show that AMPA receptors 
are still expressed in the cochlea of Bai1-deficient mice, highlighting a role 
for BAI1 in trafficking or anchoring GluR2-4 to the PSDs. These findings 
identify molecular and functional mechanisms required for sound encoding at 
cochlear ribbon synapses.

Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.celrep.2024.114025
PMID: 38564333

Conflict of interest statement: Declaration of interests The authors declare no 
competing interests.


778. Int J Exp Pathol. 2012 Dec;93(6):450-7. doi: 10.1111/j.1365-2613.2012.00840.x.

Analysis of miR-376 RNA cluster members in the mouse inner ear.

Yan D(1), Xing Y, Ouyang X, Zhu J, Chen ZY, Lang H, Liu XZ.

Author information:
(1)Department of Otolaryngology, University of Miami, Miami, FL 33136, USA.

Mutations in phosphoribosyl pyrophosphate synthetase 1 (PRPS1) are associated 
with a spectrum of non-syndromic to syndromic hearing loss. PRPS1 transcript 
levels have been shown to be regulated by the microRNA-376 genes. The long 
primary RNA transcript of the miR-376 RNA cluster members undergo extensive and 
simultaneous A → I editing at one or both of two specific sites (+4 and +44) in 
particular human and mouse tissues. The PRPS1 gene, which contains target sites 
for the edited version of miR-376a-5p within its 3'UTR, has been shown to be 
repressed in a tissue-specific manner. To investigate whether the transcription 
of Prps1 is regulated by miR-376 cluster members in the mouse inner ear, we 
first quantified the expression of the mature miR-376 RNAs by quantitative 
real-time-PCR. The spatio-temporal patterns of miR-376 expression were assessed 
by in situ hybridization. Finally, we examined whether A →I editing of 
pri-miR-376 RNAs occurs in mouse inner ear by direct sequencing. Our data showed 
that the miR-376a-3p, b-3p, c-3p are present in mouse embryonic inner ears and 
intensive expression of miR-376a-3p/b-3p was detected in the sensory epithelia 
and ganglia of both auditory and vestibular portions of the inner ear. In adult 
inner ear, the expression of miR-376a-3p/b-3p is restricted within ganglion 
neurons of auditory and vestibular systems as well as the cells in the stria 
vascularis. Only unedited pri-miR-376 RNAs were detected in the cochlea 
suggesting that the activity of PRPS1 in the inner ear may not be regulated 
through the editing of miR-376 cluster.

© 2012 The Authors. International Journal of Experimental Pathology © 2012 
International Journal of Experimental Pathology.

DOI: 10.1111/j.1365-2613.2012.00840.x
PMCID: PMC3521901
PMID: 23136997 [Indexed for MEDLINE]


779. Interspeech. 2019 Sep;2019:2325-2329. doi: 10.21437/interspeech.2019-3091.

A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial 
Configurations from Pure-Tone Audiograms.

Belitz C(1), Ali H(1), Hansen JHL(1).

Author information:
(1)CRSS: Center for Robust Speech Systems, The University of Texas at Dallas, 
Richardson, TX, USA.

Of the nearly 35 million people in the USA who are hearing impaired, only an 
estimated 25% use hearing aids (HA). A good number of HAs are prescribed but not 
used partially because of the time to convergence for best operation between the 
audiologist and user. To improve HA retention, it is suggested that a machine 
learning (ML) protocol could be established which improves initial HA 
configurations given a user's pure-tone audiogram. This study examines a ML 
clustering method to predict the best initial HA fitting from a corpus of over 
90,000 audiogram-fitting pairs collected from hearing centers throughout the 
USA. We first examine the final HA comfort targets to determine a limited number 
of preset configurations using several multi-dimensional clustering methods 
(Birch, Ward, and k-means). The goal is to reduce the amount of adjustments 
between the centroid, selected as a fitting configuration to represent the 
cluster, and the final HA configurations. This may be used to reduce the 
adjustment cycles for HAs or as preset starting configurations for personal 
sound amplification products (PSAPs). Using various classification methods, 
audiograms are mapped to a limited number of potential preset configurations. 
Finally, the average adjustment between the preset fitting targets and the final 
fitting targets is examined.

DOI: 10.21437/interspeech.2019-3091
PMCID: PMC8299699
PMID: 34307641


780. Otol Neurotol Open. 2023 Mar 9;3(1):e027. doi: 10.1097/ONO.0000000000000027. 
eCollection 2023 Mar.

In Silico Localization of Perilymph Proteins Enriched in Meńier̀e Disease Using 
Mammalian Cochlear Single-cell Transcriptomics.

Arambula AM(1), Gu S(2), Warnecke A(3), Schmitt HA(3), Staecker H(1), Hoa 
M(2)(4).

Author information:
(1)Department of Otolaryngology-Head & Neck Surgery, University of Kansas 
Medical Center, Kansas City, KS.
(2)Auditory Development and Restoration Program, National Institute on Deafness 
and Other Communication Disorders, Bethesda, MD.
(3)Department of Otolaryngology and Cluster of Excellence of the German Research 
Foundation (DFG; "Deutsche Forschungsgemeinschaft") "Hearing4all," Hannover 
Medical School, Hannover, Germany.
(4)Department of Otolaryngology-Head and Neck Surgery, Georgetown University 
Medical Center, Washington, DC.

HYPOTHESIS: Proteins enriched in the perilymph proteome of Meńier̀e disease (MD) 
patients may identify affected cell types. Utilizing single-cell transcriptome 
datasets from the mammalian cochlea, we hypothesize that these enriched 
perilymph proteins can be localized to specific cochlear cell types.
BACKGROUND: The limited understanding of human inner ear pathologies and their 
associated biomolecular variations hinder efforts to develop disease-specific 
diagnostics and therapeutics. Perilymph sampling and analysis is now enabling 
further characterization of the cochlear microenvironment. Recently, enriched 
inner ear protein expression has been demonstrated in patients with MD compared 
to patients with other inner ear diseases. Localizing expression of these 
proteins to cochlear cell types can further our knowledge of potential disease 
pathways and subsequent development of targeted therapeutics.
METHODS: We compiled previously published data regarding differential perilymph 
proteome profiles amongst patients with MD, otosclerosis, enlarged vestibular 
aqueduct, sudden hearing loss, and hearing loss of undefined etiology 
(controls). Enriched proteins in MD were cross-referenced against published 
single-cell/single-nucleus RNA-sequencing datasets to localize gene expression 
to specific cochlear cell types.
RESULTS: In silico analysis of single-cell transcriptomic datasets demonstrates 
enrichment of a unique group of perilymph proteins associated with MD in a 
variety of intracochlear cells, and some exogeneous hematologic and immune 
effector cells. This suggests that these cell types may play an important role 
in the pathology associated with late MD, suggesting potential future areas of 
investigation for MD pathophysiology and treatment.
CONCLUSIONS: Perilymph proteins enriched in MD are expressed by specific 
cochlear cell types based on in silico localization, potentially facilitating 
development of disease-specific diagnostic markers and therapeutics.

Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
of Otology & Neurotology, Inc.

DOI: 10.1097/ONO.0000000000000027
PMCID: PMC10950140
PMID: 38516320

Conflict of interest statement: M.H. holds the position of Associate Editor for 
Otology and Neurotology Open and has been recused from reviewing or making 
decisions for the article. The remaining authors disclose no conflicts of 
interest.


781. Neurosurgery. 2004 Feb;54(2):381-8; discussion 388-90. doi: 
10.1227/01.neu.0000103420.53487.79.

Functional anatomy of the human cochlear nerve and its role in microvascular 
decompressions for tinnitus.

De Ridder D(1), Ryu H, Møller AR, Nowé V, Van de Heyning P, Verlooy J.

Author information:
(1)Department of Neurosurgery and Otorhinolaryngology, University Hospital 
Antwerp, Wilrijkstraat 10, 2650 Edegem, Antwerp, Belgium. dirk.de.ridder@uza.be

OBJECTIVE: The functional anatomy (i.e., tonotopy) of the human cochlear nerve 
is unknown. A better understanding of the tonotopy of the central nervous system 
segment of the cochlear nerve and of the pathophysiology of tinnitus might help 
to ameliorate the disappointing results obtained with microvascular 
decompressions in patients with tinnitus.
METHODS: We assume that vascular compression of the cochlear nerve can induce a 
frequency-specific form of hearing loss and that when the nerve is successfully 
decompressed, this hearing loss can recuperate. Thirty-one patients underwent a 
microvascular decompression of the vestibulocochlear nerve for vertigo or 
tinnitus. Preoperative audiograms were subtracted from postoperative audiograms, 
regardless of the surgical result with regard to the tinnitus and vertigo, 
because the hearing improvement could be the only sign of the vascular 
compression. The frequency of maximal improvement was then correlated to the 
site of vascular compression. A tonotopy of the cochlear nerve was thus 
obtained.
RESULTS: A total of 18 correlations can be made between the site of compression 
and postoperative maximal hearing improvement frequency when 5-dB hearing 
improvement is used as threshold, 13 when 10-dB improvement is used as 
threshold. A clear distribution can be seen, with clustering of low frequencies 
at the posterior and inferior side of the cochlear nerve, close to the 
brainstem, and close to the root exit zone of the facial nerve. High frequencies 
are distributed closer to the internal acoustic meatus and more superiorly along 
the posterior aspect of the cochlear nerve.
CONCLUSION: The tonotopic organization of the cisternal segment of the cochlear 
nerve has an oblique rotatory structure as a result of the rotatory course of 
the cochlear nerve in the posterior fossa. Knowledge of this tonotopic 
organization of the auditory nerve in its cisternal course might benefit 
surgeons who perform microvascular decompression operations for the 
vestibulocochlear compression syndrome, especially in the treatment of 
unilateral severe tinnitus.

DOI: 10.1227/01.neu.0000103420.53487.79
PMID: 14744285 [Indexed for MEDLINE]


782. PLoS One. 2013 Jul 25;8(7):e69314. doi: 10.1371/journal.pone.0069314. Print 
2013.

Lineage analysis of the late otocyst stage mouse inner ear by transuterine 
microinjection of a retroviral vector encoding alkaline phosphatase and an 
oligonucleotide library.

Jiang H(1), Wang L, Beier KT, Cepko CL, Fekete DM, Brigande JV.

Author information:
(1)Department of Otolaryngology, Oregon Hearing Research Center, Oregon Health & 
Science University, Portland, Oregon, United States of America.

The mammalian inner ear subserves the special senses of hearing and balance. The 
auditory and vestibular sensory epithelia consist of mechanically sensitive hair 
cells and associated supporting cells. Hearing loss and balance dysfunction are 
most frequently caused by compromise of hair cells and/or their innervating 
neurons. The development of gene- and cell-based therapeutics will benefit from 
a thorough understanding of the molecular basis of patterning and cell fate 
specification in the mammalian inner ear. This includes analyses of cell 
lineages and cell dispersals across anatomical boundaries (such as sensory 
versus nonsensory territories). The goal of this study was to conduct retroviral 
lineage analysis of the embryonic day 11.5(E11.5) mouse otic vesicle. A 
replication-defective retrovirus encoding human placental alkaline phosphatase 
(PLAP) and a variable 24-bp oligonucleotide tag was microinjected into the E11.5 
mouse otocyst. PLAP-positive cells were microdissected from cryostat sections of 
the postnatal inner ear and subjected to nested PCR. PLAP-positive cells sharing 
the same sequence tag were assumed to have arisen from a common progenitor and 
are clonally related. Thirty five multicellular clones consisting of an average 
of 3.4 cells per clone were identified in the auditory and vestibular sensory 
epithelia, ganglia, spiral limbus, and stria vascularis. Vestibular hair cells 
in the posterior crista were related to one another, their supporting cells, and 
nonsensory epithelial cells lining the ampulla. In the organ of Corti, outer 
hair cells were related to a supporting cell type and were tightly clustered. By 
contrast, spiral ganglion neurons, interdental cells, and Claudius' cells were 
related to cells of the same type and could be dispersed over hundreds of 
microns. These data contribute new information about the developmental potential 
of mammalian otic precursors in vivo.

DOI: 10.1371/journal.pone.0069314
PMCID: PMC3723842
PMID: 23935981 [Indexed for MEDLINE]

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


783. Front Neurosci. 2023 Jul 26;17:1202429. doi: 10.3389/fnins.2023.1202429. 
eCollection 2023.

Deep intracochlear injection of triamcinolone-acetonide with an inner ear 
catheter in patients with residual hearing.

Prenzler NK(1), Salcher R(1), Lenarz T(1)(2), Gaertner L(1), Lesinski-Schiedat 
A(1), Warnecke A(1)(2).

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, Hanover, Germany.
(2)Cluster of Excellence "Hearing 4 All" (DFG Exc. 2177), Hannover Medical 
School, Hanover, Germany.

INTRODUCTION: In a previous study, an inner ear catheter was used to deliver 
low- and high-dose steroids into the cochlea prior to cochlear implant electrode 
insertion. With this approach, more apical regions of the cochlea could be 
reached and a reduction of electrode impedances in the short term was achieved 
in cochlear implant recipients. Whether intracochlear application of drugs via 
the catheter is a safe method also for patients with residual hearing has not 
been investigated hitherto. The aim of the present study was therefore to 
investigate the effect of intracochlear triamcinolone application in cochlear 
implant recipients with residual hearing.
PATIENTS AND METHODS: Patients with residual hearing were administered 
triamcinolone-acetonide (4 mg/ml; n = 10) via an inner ear catheter just prior 
to insertion of a MED-EL FLEX28 electrode. Impedances were measured at defined 
time points (intra-operatively, post-operatively and at first fitting) and 
retrospectively compared with a control group (no steroid application) and low- 
and high-dose group. Hearing thresholds were measured preoperatively, 3 days 
after surgery and at first fitting by pure tone audiometry. Pre- to 
postoperative hearing loss was determined at first fitting and compared to 
results from a previous study.
RESULTS: The median hearing loss after implantation (125-1,500 Hz) was 20.6 dB. 
Four patients (40%) showed a median hearing loss of less than 15 dB, three 
patients (30%) between 15 and 30 dB and three patients (30%) more than 30 dB. 
The median hearing loss was similar to the results obtained from our previous 
study showing a median hearing loss of 24 dB when using FLEX28 electrode arrays.
CONCLUSION: No difference in residual hearing loss was found when comparing 
application of triamcinolone-acetonide using an inner ear catheter prior to the 
insertion of a FLEX28 electrode array to the use of the FLEX28 electrode array 
without the catheter. Thus, we conclude that application of drugs to the cochlea 
with an inner ear catheter could be a feasible approach in patients with 
residual hearing.

Copyright © 2023 Prenzler, Salcher, Lenarz, Gaertner, Lesinski-Schiedat and 
Warnecke.

DOI: 10.3389/fnins.2023.1202429
PMCID: PMC10410142
PMID: 37564369

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


784. Front Med (Lausanne). 2021 Mar 25;8:662045. doi: 10.3389/fmed.2021.662045. 
eCollection 2021.

Audiometric Phenotypes of Noise-Induced Hearing Loss by Data-Driven Cluster 
Analysis and Their Relevant Characteristics.

Wang Q(1)(2)(3), Qian M(1)(2)(3), Yang L(1)(4), Shi J(1)(4), Hong Y(1)(4), Han 
K(1)(2)(3), Li C(5), Lin J(5), Huang Z(1)(2)(3)(4), Wu H(1)(2)(3).

Author information:
(1)Department of Otolaryngology-Head and Neck Surgery, Ninth People's Hospital, 
Shanghai Jiao Tong University School of Medicine, Shanghai, China.
(2)Ear Institute, Shanghai Jiao Tong University School of Medicine, Shanghai, 
China.
(3)Shanghai Key Laboratory of Translational Medicine on Ear and Nose Diseases, 
Shanghai, China.
(4)Hearing and Speech Center, Ninth People's Hospital, Shanghai Jiao Tong 
University School of Medicine, Shanghai, China.
(5)Network and Information Center, Shanghai Jiao Tong University, Shanghai, 
China.

Background: The definition of notched audiogram for noise-induced hearing loss 
(NIHL) is presently based on clinical experience, but audiometric phenotypes of 
NIHL are highly heterogeneous. The data-driven clustering of subtypes could 
provide refined characteristics of NIHL, and help identify individuals with 
typical NIHL at diagnosis. Methods: This cross-sectional study initially 
recruited 12,218 occupational noise-exposed employees aged 18-60 years from two 
factories of a shipyard in Eastern China. Of these, 10,307 subjects with no 
history of otological injurie or disease, family history of hearing loss, or 
history of ototoxic drug use were eventually enrolled. All these subjects 
completed health behavior questionnaires, cumulative noise exposure (CNE) 
measurement, and pure-tone audiometry. We did data-driven cluster analysis 
(k-means clustering) in subjects with hearing loss audiograms (n = 6,599) 
consist of two independent datasets (n = 4,461 and n = 2,138). Multinomial 
logistic regression was performed to analyze the relevant characteristics of 
subjects with different audiometric phenotypes compared to those subjects with 
normal hearing audiograms (n = 3,708). Results: A total of 10,307 subjects 
(9,165 males [88.9%], mean age 34.5 [8.8] years, mean CNE 91.2 [22.7] dB[A]) 
were included, 3,708 (36.0%) of them had completely normal hearing, the other 
6,599 (64.0%) with hearing loss audiograms were clustered into four audiometric 
phenotypes, which were replicable in two distinct datasets. We named the four 
clusters as the 4-6 kHz sharp-notched, 4-6 kHz flat-notched, 3-8 kHz notched, 
and 1-8 kHz notched audiogram. Among them, except for the 4-6 kHz flat-notched 
audiogram which was not significantly related to NIHL, the other three 
phenotypes with different relevant characteristics were strongly associated with 
noise exposure. In particular, the 4-6 kHz sharp-notched audiogram might be a 
typical subtype of NIHL. Conclusions: By data-driven cluster analysis of the 
large-scale noise-exposed population, we identified three audiometric phenotypes 
associated with distinct NIHL subtypes. Data-driven sub-stratification of 
audiograms might eventually contribute to the precise diagnosis and treatment of 
NIHL.

Copyright © 2021 Wang, Qian, Yang, Shi, Hong, Han, Li, Lin, Huang and Wu.

DOI: 10.3389/fmed.2021.662045
PMCID: PMC8027076
PMID: 33842516

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


785. Audit Neurosci. 1996;3(1):57-78.

Increases in Spontaneous Activity in the Dorsal Cochlear Nucleus Following 
Exposure to High Intensity Sound: A Possible Neural Correlate of Tinnitus.

Kaltenbach JA(1), McCaslin DL.

Author information:
(1)Department of Otolaryngology/Head and Neck Surgery, 5E-UHC Wayne State 
University School of Medicine, Detroit, Michigan 48201.

The purpose of this study was to test the effects of intense tone exposure on 
the spontaneous activity of multiunit clusters in the mammalian dorsal cochlear 
nucleus (DCN). Adult hamsters (60-101 days of age) were exposed to a 10 kHz tone 
at levels between 125 and 130 dB SPL for a period of 4 hours. The effects of 
tone exposure were studied following a recovery period of 30-58 days and were 
quantified by measuring the spontaneous rates, response thresholds and frequency 
tuning properties of neural clusters at the surface of the DCN. Measures were 
performed at each of 10-15 sites along the tonotopic axis of the DCN. The 
effects of the tone exposure were examined by comparison with identical measures 
obtained from normal unexposed animals. Results indicate that tone exposure 
induced major chronic increases in the spontaneous activity of the DCN. Such 
increases were broadly distributed across the tonotopic range of the DCN and 
were generally found in tonotopic map areas characterized by tone-induced 
elevations of neural thresholds. Mean spontaneous rate reached its maximum value 
at or close to the tonotopic locus which normally represents the frequency of 
the exposure tone. The increased activity induced by tone exposure resembled the 
heightened activity in normal animals during presentation of a moderate level 
continuous tone. These changes in spontaneous activity indicate that central 
auditory neurons are in a state of elevated activity for extended periods 
following intense sound exposure and suggest that the affected neurons may 
signal the presence of acoustic stimulation even though such stimulation is not 
present. Possible mechanisms of these changes and their relation to the clinical 
problem of tinnitus are discussed.

PMCID: PMC3826462
PMID: 24244077


786. Clin Neurophysiol. 2021 Sep;132(9):2290-2305. doi: 10.1016/j.clinph.2021.03.055. 
Epub 2021 May 20.

An event-related brain potential study of auditory attention in cochlear implant 
users.

Schierholz I(1), Schönermark C(2), Ruigendijk E(3), Kral A(4), Kopp B(5), 
Büchner A(6).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Germany; Department of 
Otorhinolaryngology, University of Cologne, Cologne, Germany. Electronic 
address: irina.schierholz@uk-koeln.de.
(2)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany.
(3)Cluster of Excellence "Hearing4all", Germany; Department for Dutch Studies, 
Carl von Ossietzky University Oldenburg, Oldenburg, Germany.
(4)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Germany; Department of 
Experimental Otology, Institute for AudioNeuroTechnology (VIANNA), Hannover 
Medical School, Hannover, Germany.
(5)Department of Neurology, Hannover Medical School, Hannover, Germany.
(6)Department of Otorhinolaryngology, Hannover Medical School, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Germany.

Comment in
    Clin Neurophysiol. 2021 Sep;132(9):2257-2258.

OBJECTIVE: Cochlear implants (CIs) provide access to the auditory world for deaf 
individuals. We investigated whether CIs enforce attentional alterations of 
auditory cortical processing in post-lingually deafened CI users compared to 
normal-hearing (NH) controls.
METHODS: Event-related potentials (ERPs) were recorded in 40 post-lingually 
deafened CI users and in a group of 40 NH controls using an auditory 
three-stimulus oddball task, which included frequent standard tones (Standards) 
and infrequent deviant tones (Targets), as well as infrequently occurring unique 
sounds (Novels). Participants were exposed twice to the three-stimulus oddball 
task, once under the instruction to ignore the stimuli (ignore condition), and 
once under the instruction to respond to infrequently occurring deviant tones 
(attend condition).
RESULTS: The allocation of attention to auditory oddball stimuli exerted 
stronger effects on N1 amplitudes at posterior electrodes in response to 
Standards and to Targets in CI users than in NH controls. Other ERP amplitudes 
showed similar attentional modulations in both groups (P2 in response to 
Standards, N2 in response to Targets and Novels, P3 in response to Targets). We 
also observed a statistical trend for an attenuated attentional modulation of 
Novelty P3 amplitudes in CI users compared to NH controls.
CONCLUSIONS: ERP correlates of enhanced CI-mediated auditory attention are 
confined to the latency range of the auditory N1, suggesting that enhanced 
attentional modulation during auditory stimulus discrimination occurs primarily 
in associative auditory cortices of CI users.
SIGNIFICANCE: The present ERP data support the hypothesis of attentional 
alterations of auditory cortical processing in CI users. These findings may be 
of clinical relevance for the CI rehabilitation.

Copyright © 2021 International Federation of Clinical Neurophysiology. Published 
by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.clinph.2021.03.055
PMID: 34120838 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


787. Front Neurosci. 2017 Mar 24;11:148. doi: 10.3389/fnins.2017.00148. eCollection 
2017.

Brain Metabolic Changes in Rats following Acoustic Trauma.

He J(1), Zhu Y(1), Aa J(1), Smith PF(2), De Ridder D(3), Wang G(1), Zheng Y(2).

Author information:
(1)Key Laboratory of Drug Metabolism and Pharmacokinetics, China Pharmaceutical 
University Nanjing, Jiangsu, China.
(2)Department of Pharmacology and Toxicology, School of Biomedical Sciences, 
University of OtagoDunedin, New Zealand; Brain Health Research Centre, 
University of OtagoDunedin, New Zealand; Brain Research New ZealandDunedin, New 
Zealand; Eisdell Moore Centre for Hearing and Balance Research, University of 
AucklandAuckland, New Zealand.
(3)Brain Health Research Centre, University of OtagoDunedin, New Zealand; Brain 
Research New ZealandDunedin, New Zealand; Eisdell Moore Centre for Hearing and 
Balance Research, University of AucklandAuckland, New Zealand; Department of 
Neurosurgery, Dunedin Medical School, University of OtagoOtago, New Zealand.

Erratum in
    Front Neurosci. 2017 May 08;11:260.

Acoustic trauma is the most common cause of hearing loss and tinnitus in humans. 
However, the impact of acoustic trauma on system biology is not fully 
understood. It has been increasingly recognized that tinnitus caused by acoustic 
trauma is unlikely to be generated by a single pathological source, but rather a 
complex network of changes involving not only the auditory system but also 
systems related to memory, emotion and stress. One obvious and significant gap 
in tinnitus research is a lack of biomarkers that reflect the consequences of 
this interactive "tinnitus-causing" network. In this study, we made the first 
attempt to analyse brain metabolic changes in rats following acoustic trauma 
using metabolomics, as a pilot study prior to directly linking metabolic changes 
to tinnitus. Metabolites in 12 different brain regions collected from either 
sham or acoustic trauma animals were profiled using a gas chromatography mass 
spectrometry (GC/MS)-based metabolomics platform. After deconvolution of mass 
spectra and identification of the molecules, the metabolomic data were processed 
using multivariate statistical analysis. Principal component analysis showed 
that metabolic patterns varied among different brain regions; however, brain 
regions with similar functions had a similar metabolite composition. Acoustic 
trauma did not change the metabolite clusters in these regions. When analyzed 
within each brain region using the orthogonal projection to latent structures 
discriminant analysis sub-model, 17 molecules showed distinct separation between 
control and acoustic trauma groups in the auditory cortex, inferior colliculus, 
superior colliculus, vestibular nucleus complex (VNC), and cerebellum. Further 
metabolic pathway impact analysis and the enrichment overview with network 
analysis suggested the primary involvement of amino acid metabolism, including 
the alanine, aspartate and glutamate metabolic pathways, the arginine and 
proline metabolic pathways and the purine metabolic pathway. Our results provide 
the first metabolomics evidence that acoustic trauma can induce changes in 
multiple metabolic pathways. This pilot study also suggests that the metabolomic 
approach has the potential to identify acoustic trauma-specific metabolic shifts 
in future studies where metabolic changes are correlated with the animal's 
tinnitus status.

DOI: 10.3389/fnins.2017.00148
PMCID: PMC5364180
PMID: 28392756


788. Int J Audiol. 2023 Sep;62(9):868-876. doi: 10.1080/14992027.2022.2095538. Epub 
2022 Jul 23.

Conversation success in one-to-one and group conversation: a group concept 
mapping study of adults with normal and impaired hearing.

Nicoras R(1), Gotowiec S(2), Hadley LV(1), Smeds K(1)(2), Naylor G(1).

Author information:
(1)Hearing Sciences - Scottish Section, School of Medicine, University of 
Nottingham, Nottingham, UK.
(2)ORCA Europe, WS Audiology, Stockholm, Sweden.

OBJECTIVE: The concept of conversation success is undefined, although prior work 
has variously related it to accurate exchange of information, alignment between 
interlocutors, and good management of misunderstandings. This study aimed (1) to 
identify factors of conversation success and (2) to explore the importance of 
these factors in one-to-one versus group conversations.
DESIGN: Group concept mapping method was applied. Participants responded to two 
brainstorming prompts ("What does 'successful conversation' look like?" and 
"Think about a successful conversation you have taken part in. What aspects of 
that conversation contributed to its success?"). The resulting statements were 
sorted into related clusters and rated in importance for one-to-one and group 
conversation.
STUDY SAMPLE: Thirty-five adults with normal and impaired hearing.
RESULTS: Seven clusters were identified: (1) Being able to listen easily; (2) 
Being spoken to in a helpful way; (3) Being engaged and accepted; (4) Sharing 
information as desired; (5) Perceiving flowing and balanced interaction; (6) 
Feeling positive emotions; (7) Not having to engage coping mechanisms. Three 
clusters (1, 2, and 4) were more important in group than in one-to-one 
conversation. There were no differences by hearing group.
CONCLUSIONS: These findings emphasise that conversation success is a 
multifaceted concept.

DOI: 10.1080/14992027.2022.2095538
PMID: 35875851 [Indexed for MEDLINE]


789. Cereb Cortex. 2024 Jan 31;34(2):bhad517. doi: 10.1093/cercor/bhad517.

Neural response properties predict perceived contents and locations elicited by 
intracranial electrical stimulation of human auditory cortex.

Wang Q(1)(2)(3), Luo L(4), Xu N(5), Wang J(6), Yang R(1)(2)(7), Chen G(1)(2)(7), 
Ren J(8)(9), Luan G(8)(10), Fang F(1)(2)(7).

Author information:
(1)School of Psychological and Cognitive Sciences and Beijing Key Laboratory of 
Behavior and Mental Health, Peking University, Beijing 100871, China.
(2)IDG/McGovern Institute for Brain Research, Peking University, Beijing 100871, 
China.
(3)National Key Laboratory of General Artificial Intelligence, Peking 
University, Beijing 100871, China.
(4)School of Psychology, Beijing Sport University, Beijing 100084, China.
(5)Division of Brain Sciences, Changping Laboratory, Beijing 102206, China.
(6)Department of Neurology, Sanbo Brain Hospital, Capital Medical University, 
Beijing 100093, China.
(7)Peking-Tsinghua Center for Life Sciences, Peking University, Beijing 100871, 
China.
(8)Department of Functional Neurosurgery, Beijing Key Laboratory of Epilepsy, 
Sanbo Brain Hospital, Capital Medical University, Beijing 100093, China.
(9)Epilepsy Center, Kunming Sanbo Brain Hospital, Kunming 650100 China.
(10)Beijing Institute for Brain Disorders, Beijing 100069, China.

Intracranial electrical stimulation (iES) of auditory cortex can elicit sound 
experiences with a variety of perceived contents (hallucination or illusion) and 
locations (contralateral or bilateral side), independent of actual acoustic 
inputs. However, the neural mechanisms underlying this elicitation heterogeneity 
remain undiscovered. Here, we collected subjective reports following iES at 3062 
intracranial sites in 28 patients (both sexes) and identified 113 auditory 
cortical sites with iES-elicited sound experiences. We then decomposed the 
sound-induced intracranial electroencephalogram (iEEG) signals recorded from all 
113 sites into time-frequency features. We found that the iES-elicited perceived 
contents can be predicted by the early high-γ features extracted from 
sound-induced iEEG. In contrast, the perceived locations elicited by stimulating 
hallucination sites and illusion sites are determined by the late high-γ and 
long-lasting α features, respectively. Our study unveils the crucial neural 
signatures of iES-elicited sound experiences in human and presents a new 
strategy to hearing restoration for individuals suffering from deafness.

© The Author(s) 2024. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhad517
PMID: 38185991 [Indexed for MEDLINE]


790. J Laryngol Otol. 1993 May;107(5):395-400. doi: 10.1017/s0022215100123278.

Hearing impairment and ear pathology in Nepal.

Little P(1), Bridges A, Guragain R, Friedman D, Prasad R, Weir N.

Author information:
(1)Aldermoor Health Centre, Southampton.

A stratified random cluster sample of 15,845 subjects was performed in two 
regions of Nepal to determine the prevalence and main causes of hearing 
impairment (the most common disability) and the prevalence of ear disease. 
Subjects reporting current ear pain, or ear discharge, or hearing impairment on 
direct questioning by a Nepali health worker (primary screening failed), had 
otoscopy and audiometry (using the Liverpool Field Audiometer) performed, and a 
questionnaire administered relating to past history. In every fifth house 
subjects who passed the primary screening (1,716 subjects) were examined to 
assess the false negative rate of screening. An estimated 16.6 per cent of the 
study population have hearing impairment (either ear worse than 30 dB hearing 
threshold level (HTL) 1.0-4.0 kHz, or 50 dB HTL 0.5 kHz), and 7.4 per cent ear 
drum pathology, equivalent to respectively 2.71 and 1.48 million people 
extrapolated to the whole of Nepal. Most hearing impairment in the school age 
group (55.2 per cent) is associated with otitis media or its sequelae. Probably 
at least 14 per cent of sensorineural deafness is preventable (7 per cent 
infectious disease, 3.9 per cent trauma, 0.8 per cent noise exposure, 1 per cent 
cretinism, and 1 per cent abnormal pregnancy or labour). Most individuals 
reporting current ear pathology (61 per cent) had never attended a health post, 
and of those receiving ear drop treatment, 84 per cent still had serious 
pathology. Of subjects who reported ear drop treatment at any time, 31 per cent 
still had serious pathology. The use of traditional remedies was 
prevalent.(ABSTRACT TRUNCATED AT 250 WORDS)

DOI: 10.1017/s0022215100123278
PMID: 8326217 [Indexed for MEDLINE]


791. Hear Res. 2020 Apr;389:107908. doi: 10.1016/j.heares.2020.107908. Epub 2020 Feb 
6.

Functional magnetic resonance imaging of enhanced central auditory gain and 
electrophysiological correlates in a behavioral model of hyperacusis.

Wong E(1), Radziwon K(2), Chen GD(2), Liu X(2), Manno FA(3), Manno SH(4), 
Auerbach B(2), Wu EX(5), Salvi R(6), Lau C(7).

Author information:
(1)Department of Physics, City University of Hong Kong, Hong Kong, China; 
Department of Electrical and Electronic Engineering, The University of Hong 
Kong, Hong Kong, China; Laboratory of Biomedical Imaging and Signal Processing, 
The University of Hong Kong, Hong Kong, China.
(2)Center for Hearing & Deafness, Department of Communicative Disorders and 
Sciences, SUNY at Buffalo, 137 Cary Hall, Buffalo, NY, 14214, USA.
(3)Department of Physics, City University of Hong Kong, Hong Kong, China; School 
of Biomedical Engineering, University of Sydney, Sydney, New South Wales, 
Australia.
(4)Department of Biomedical Sciences, City University of Hong Kong, Hong Kong, 
China.
(5)Department of Electrical and Electronic Engineering, The University of Hong 
Kong, Hong Kong, China; Laboratory of Biomedical Imaging and Signal Processing, 
The University of Hong Kong, Hong Kong, China.
(6)Center for Hearing & Deafness, Department of Communicative Disorders and 
Sciences, SUNY at Buffalo, 137 Cary Hall, Buffalo, NY, 14214, USA; Department of 
Audiology and Speech-Language Pathology, Asia University, Taichung, Taiwan, ROC. 
Electronic address: salvi@buffalo.edu.
(7)Department of Physics, City University of Hong Kong, Hong Kong, China. 
Electronic address: condon.lau@cityu.edu.hk.

Hyperacusis is a debilitating hearing condition in which normal everyday sounds 
are perceived as exceedingly loud, annoying, aversive or even painful. The 
prevalence of hyperacusis approaches 10%, making it an important, but 
understudied medical condition. To noninvasively identify the neural correlates 
of hyperacusis in an animal model, we used sound-evoked functional magnetic 
resonance imaging (fMRI) to locate regions of abnormal activity in the central 
nervous system of rats with behavioral evidence of hyperacusis induced with an 
ototoxic drug (sodium salicylate, 250 mg/kg, i.p.). Reaction time-intensity 
measures of loudness-growth revealed behavioral evidence of salicylate-induced 
hyperacusis at high intensities. fMRI revealed significantly enhanced 
sound-evoked responses in the auditory cortex (AC) to 80 dB SPL tone bursts 
presented at 8 and 16 kHz. Sound-evoked responses in the inferior colliculus 
(IC) were also enhanced, but to a lesser extent. To confirm the main results, 
electrophysiological recordings of spike discharges from multi-unit clusters 
were obtained from the central auditory pathway. Salicylate significantly 
enhanced tone-evoked spike-discharges from multi-unit clusters in the AC from 4 
to 30 kHz at intensities ≥60 dB SPL; less enhancement occurred in the medial 
geniculate body (MGB), and even less in the IC. Our results demonstrate for the 
first time that non-invasive sound-evoked fMRI can be used to identify regions 
of neural hyperactivity throughout the brain in an animal model of hyperacusis.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2020.107908
PMCID: PMC7080601
PMID: 32062293 [Indexed for MEDLINE]


792. Mol Cell Proteomics. 2024 Feb;23(2):100704. doi: 10.1016/j.mcpro.2023.100704. 
Epub 2023 Dec 20.

Proteomic Analysis Reveals the Composition of Glutamatergic Organelles of 
Auditory Inner Hair Cells.

Cepeda AP(1), Ninov M(2), Neef J(3), Parfentev I(1), Kusch K(4), Reisinger E(5), 
Jahn R(6), Moser T(7), Urlaub H(8).

Author information:
(1)Bioanalytical Mass Spectrometry Group, Max Planck Institute for 
Multidisciplinary Sciences, Göttingen, Germany.
(2)Bioanalytical Mass Spectrometry Group, Max Planck Institute for 
Multidisciplinary Sciences, Göttingen, Germany; Department of Clinical 
Chemistry, University Medical Center Göttingen, Göttingen, Germany.
(3)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany; Auditory Neuroscience & Synaptic 
Nanophysiology Group Max-Planck-Institute for Multidisciplinary Sciences, 
Göttingen, Germany.
(4)Functional Auditory Genomics Group, Institute for Auditory Neuroscience and 
InnerEarLab, University Medical Center Göttingen, Göttingen, Germany.
(5)Gene Therapy for Hearing Impairment and Deafness, Department for 
Otolaryngology, Head & Neck Surgery, University Hospital Tübingen, Tübingen, 
Germany.
(6)Laboratory of Neurobiology, Max Planck Institute for Multidisciplinary 
Sciences, Göttingen, Germany; Cluster of Excellence "Multiscale Bioimaging: from 
Molecular Machines to Networks of Excitable Cells" (MBExC), University of 
Göttingen, Göttingen, Germany. Electronic address: reinhard.jahn@mpinat.mpg.de.
(7)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany; Auditory Neuroscience & Synaptic 
Nanophysiology Group Max-Planck-Institute for Multidisciplinary Sciences, 
Göttingen, Germany; Cluster of Excellence "Multiscale Bioimaging: from Molecular 
Machines to Networks of Excitable Cells" (MBExC), University of Göttingen, 
Göttingen, Germany. Electronic address: tmoser@gwdg.de.
(8)Bioanalytical Mass Spectrometry Group, Max Planck Institute for 
Multidisciplinary Sciences, Göttingen, Germany; Department of Clinical 
Chemistry, University Medical Center Göttingen, Göttingen, Germany; Cluster of 
Excellence "Multiscale Bioimaging: from Molecular Machines to Networks of 
Excitable Cells" (MBExC), University of Göttingen, Göttingen, Germany. 
Electronic address: henning.urlaub@mpinat.mpg.de.

In the ear, inner hair cells (IHCs) employ sophisticated glutamatergic ribbon 
synapses with afferent neurons to transmit auditory information to the brain. 
The presynaptic machinery responsible for neurotransmitter release in IHC 
synapses includes proteins such as the multi-C2-domain protein otoferlin and the 
vesicular glutamate transporter 3 (VGluT3). Yet, much of this likely unique 
molecular machinery remains to be deciphered. The scarcity of material has so 
far hampered biochemical studies which require large amounts of purified 
samples. We developed a subcellular fractionation workflow combined with 
immunoisolation of VGluT3-containing membrane vesicles, allowing for the 
enrichment of glutamatergic organelles that are likely dominated by synaptic 
vesicles (SVs) of IHCs. We have characterized their protein composition in mice 
before and after hearing onset using mass spectrometry and confocal imaging and 
provide a fully annotated proteome with hitherto unidentified proteins. Despite 
the prevalence of IHC marker proteins across IHC maturation, the profiles of 
trafficking proteins differed markedly before and after hearing onset. Among the 
proteins enriched after hearing onset were VAMP-7, syntaxin-7, syntaxin-8, 
syntaxin-12/13, SCAMP1, V-ATPase, SV2, and PKCα. Our study provides an inventory 
of the machinery associated with synaptic vesicle-mediated trafficking and 
presynaptic activity at IHC ribbon synapses and serves as a foundation for 
future functional studies.

Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.mcpro.2023.100704
PMCID: PMC10832297
PMID: 38128648 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of interest The authors declare that 
they have no conflicts of interest with the contents of this article.


793. Alcohol Clin Exp Res. 2007 Feb;31(2):336-44. doi: 
10.1111/j.1530-0277.2006.00309.x.

Ethanol inhibits the sensory responses of cerebellar granule cells in 
anesthetized cats.

Huang CM(1), Huang RH.

Author information:
(1)Division of Molecular Biology and Biochemistry, School of Biological 
Sciences, University of Missouri, Kansas City 64110-2499, USA. huangc@umkc.edu

BACKGROUND: Granule cells occupy a strategic position in the transmission of 
afferent information to the cerebellar cortex. They are also the most abundant 
type of neurons in the cerebellum. The functions of the cerebellum are thought 
to be sensitive to acute alcohol intoxication. The effects of acute alcohol 
intoxication on the in vivo physiology of cerebellar granule cells are, however, 
not completely known.
METHODS: We studied chloralose-anesthetized cats at ethanol doses relevant to 
human drinking (0.3-1.2 g/kg). We recorded the electrophysiological responses of 
granule cell clusters to auditory and visual stimulation, and simultaneously 
monitored the concentration of ethanol in the cerebrospinal fluid (CSF).
RESULTS: At an intravenous ethanol dose of 0.3 g/kg, CSF ethanol concentration 
peaked in 10 minutes at 17 mM, equivalent to a blood alcohol concentration (BAC) 
of about 0.08 g/dL. Ethanol quickly and almost completely abolished both 
auditory and visual responses from granule cells. Complete or near-complete 
inhibition lasted 15 to 20 minutes; approximately 50% recovery required an 
additional 15 minutes, and a full recovery yet another 15 minutes. A higher 
ethanol dose at 1.2 g/kg resulted in a more severe inhibition and required 
longer time for recovery. The relationship between ethanol dose, CSF ethanol 
concentration, and granule cell responses was dynamic and nonlinear, critically 
depending upon the elapsed time.
CONCLUSIONS: Cerebellar granule cell sensory responses are highly sensitive to 
ethanol inhibition. A rapid development of acute tolerance appears to be a major 
factor contributing to the dynamic and nonlinear relationship among ethanol 
dosage, CSF ethanol concentration, and granule cell responses. It is likely that 
a generalized de-afferentation of the cerebellum from its mossy fiber afferents, 
followed by the subsequent development of acute tolerance may play major roles 
by which alcohol intoxication affects cerebellar functions.

DOI: 10.1111/j.1530-0277.2006.00309.x
PMID: 17250627 [Indexed for MEDLINE]


794. Biomolecules. 2022 Apr 17;12(4):589. doi: 10.3390/biom12040589.

3D Printed Cell Culture Chamber for Testing the Effect of Pump-Based Chronic 
Drug Delivery on Inner Ear Tissue.

Schwieger J(1)(2)(3), Frisch AS(1)(2), Rau TS(1)(2)(3), Lenarz T(1)(2)(3), Hügl 
S(1)(2)(3), Scheper V(1)(2)(3).

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, 30625 Hannover, Germany.
(2)Lower Saxony Center for Biomedical Engineering, Implant Research and 
Development (NIFE), Stadtfelddamm 34, 30625 Hannover, Germany.
(3)Cluster of Excellence "Hearing4all" EXC 1077/2, 30625 Hannover, Germany.

Cochlear hair cell damage and spiral ganglion neuron (SGN) degeneration are the 
main causes of sensory neural hearing loss. Cochlear implants (CIs) can replace 
the function of the hair cells and stimulate the SGNs electrically. The 
condition of the SGNs and their spatial distance to the CI are key factors for 
CI-functionality. For a better performance, a high number of neurons and a 
closer contact to the electrode are intended. Neurotrophic factors are able to 
enhance SGN survival and neurite outgrowth, and thereby might optimize the 
electrode-nerve interaction. This would require chronic factor treatment, which 
is not yet established for the inner ear. Investigations on chronic drug 
delivery to SGNs could benefit from an appropriate in vitro model. Thus, an 
inner ear inspired Neurite Outgrowth Chamber (NOC), which allows the 
incorporation of a mini-osmotic pump for long-term drug delivery, was designed 
and three-dimensionally printed. The NOC's function was validated using spiral 
ganglion explants treated with ciliary neurotrophic factor, neurotrophin-3, or 
control fluid released via pumps over two weeks. The NOC proved to be suitable 
for explant cultivation and observation of pump-based drug delivery over the 
examined period, with neurotrophin-3 significantly increasing neurite outgrowth 
compared to the other groups.

DOI: 10.3390/biom12040589
PMCID: PMC9032916
PMID: 35454178 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


795. RETRACTED ARTICLE

J Healthc Eng. 2022 Feb 21;2022:3978627. doi: 10.1155/2022/3978627. eCollection 
2022.

CNN-LSTM Hybrid Real-Time IoT-Based Cognitive Approaches for ISLR with WebRTC: 
Auditory Impaired Assistive Technology.

Gupta M(1), Thakur N(2), Bansal D(3), Chaudhary G(4), Davaasambuu B(5), Hua 
Q(6).

Author information:
(1)Department of Computer Science and Engineering, Chandigarh University, 
Punjab, India.
(2)CSE Department, Bhagwan Parshuram Institute of Technology, New Delhi, India.
(3)Department of Electrical and Electronics Engineering Department, Bharati 
Vidyapeeth's College of Engineering New Delhi, New Delhi, India.
(4)Bharati Vidyapeeth's College of Engineering, New Delhi, India.
(5)Department of Electronics and Communication Engineering, School of 
Engineering and Applied Sciences, National University of Mongolia, Ulan Bator, 
Mongolia.
(6)Computer School, Hubei University of Arts and Science, Xiangyang 441000, 
China.

Retraction in
    J Healthc Eng. 2023 Dec 13;2023:9894609.

In the era of modern technology, people may readily communicate through facial 
expressions, body language, and other means. As the use of the Internet evolves, 
it may be a boon to the medical fields. Recently, the Internet of Medical Things 
(IoMT) has provided a broader platform to handle difficulties linked to 
healthcare, including people's listening and hearing impairment. Although there 
are many translators that exist to help people of various linguistic backgrounds 
communicate more effectively. Using kinesics linguistics, one may assess or 
comprehend the communications of auditory and hearing-impaired persons who are 
standing next to each other. When looking at the present COVID-19 scenario, 
individuals are still linked in some way via online platforms; however, persons 
with disabilities have communication challenges with online platforms. The work 
provided in this research serves as a communication bridge inside the challenged 
community and the rest of the globe. The proposed work for Indian Sign 
Linguistic Recognition (ISLR) uses three-dimensional convolutional neural 
networks (3D-CNNs) and long short-term memory (LSTM) technique for analysis. A 
conventional hand gesture recognition system involves identifying the hand and 
its location or orientation, extracting certain essential features and applying 
an appropriate machine learning algorithm to recognise the completed action. In 
the calling interface of the web application, WebRTC has been implemented. A 
teleprompting technology is also used in the web app, which transforms sign 
language into audible sound. The proposed web app's average recognition rate is 
97.21%.

Copyright © 2022 Meenu Gupta et al.

DOI: 10.1155/2022/3978627
PMCID: PMC8885272
PMID: 35237390 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that there are no conflicts 
of interest regarding the publication of this article.


796. JASA Express Lett. 2021 Nov;1(11):115204. doi: 10.1121/10.0007149. Epub 2021 Nov 
19.

Estimating hearing aid fitting presets with machine learning-based clustering 
strategies.

Belitz C(1), Ali H(1), Hansen JHL(1).

Author information:
(1)Center for Robust Speech Systems, The University of Texas at Dallas, 
Richardson, Texas, 75075 USA.

Although there exist nearly 35 × 106 hearing impaired people in the U.S., only 
an estimated 25% use hearing aids (HA), while others elect not to use prescribed 
HAs. Lack of HA acceptance can be attributed to several factors including (i) 
performance variability in diverse environments, (ii) time-to-convergence for 
best HA operating configuration, (iii) unrealistic expectations, and (iv) 
cost/insurance. This study examines a nationwide dataset of pure-tone audiograms 
and HA fitting configurations. An overview of data characteristics is presented, 
followed by use of machine learning clustering to suggest ways of obtaining 
effective starting configurations, thereby reducing time-to-convergence to 
improve HA retention.

DOI: 10.1121/10.0007149
PMCID: PMC9245508
PMID: 35784455


797. Ear Hear. 2018 Sep/Oct;39(5):1025-1034. doi: 10.1097/AUD.0000000000000583.

Psychometric Properties and Factor Structure of a New Scale to Measure 
Hyperacusis: Introducing the Inventory of Hyperacusis Symptoms.

Greenberg B(1)(2), Carlos M(1).

Author information:
(1)School of Clinical Psychology, American School of Professional Psychology at 
Argosy University, Alameda, California, USA.
(2)Adult Outpatient Psychiatry Department, California Pacific Medical Center, 
San Francisco, California.

OBJECTIVES: Despite increasing interest in hyperacusis and other disorders of 
auditory sensitivity, there is still a lack of valid, standardized assessment 
tools to measure symptom severity, treatment outcomes, and diagnostic 
differentiation. Accordingly, this study sought to create a new scale that is 
reliable, valid, brief, and easy to score with the purpose of filling this gap.
DESIGN: Original items were constructed through review of currently existing 
models of hyperacusis measurement, as well as qualitative data collected from 
professional audiologists and individuals reporting heightened audiological 
sensitivity with tinnitus. An initial 26-item scale yielded sound reliability 
and validity properties. Refinement based on review of initial data resulted in 
a 25-question second version with a maximum score of 100. A total of 450 
completed survey protocols were analyzed from 469 refined Inventory of 
Hyperacusis Symptoms (IHS) administrations collected online, representing 
individuals from 37 countries with a mean age of 34.8 years.
RESULTS: Internal consistency reliability analysis yielded a Cronbach's α of 
0.93, indicating excellent reliability. Furthermore, the IHS showed sound 
convergent validity with established measures of quality of life, anxiety, and 
depression in bivariate correlation analysis of Pearson's r. Factor analysis 
revealed a dimensional structure containing five factors, which were designated 
psychosocial impact, emotional arousal, functional impact, general loudness, and 
communication. Analysis of variance between perceived global hyperacusis 
severity categories provided a preliminary framework for scoring thresholds. 
Although the level of hearing loss did not correlate with IHS scores, increased 
tinnitus symptoms were a significant factor in predicting hyperacusis distress 
and severity.
CONCLUSIONS: These initial results demonstrated sound statistical properties of 
the IHS and usefulness as a hyperacusis measurement tool in research and 
clinical practice. Factor structure and scale dimensions allow for 
differentiation between subtypes of loudness, annoyance, fear, and pain based on 
responses to clusters of specific items within the dimensional factor structure 
of the scale, and may thus prove useful in clinical practice and research.

DOI: 10.1097/AUD.0000000000000583
PMID: 29742543 [Indexed for MEDLINE]


798. Front Mol Neurosci. 2021 Mar 23;14:651935. doi: 10.3389/fnmol.2021.651935. 
eCollection 2021.

RIM-Binding Proteins Are Required for Normal Sound-Encoding at Afferent Inner 
Hair Cell Synapses.

Krinner S(1)(2)(3), Predoehl F(1), Burfeind D(4), Vogl C(3)(4), Moser 
T(1)(2)(3)(5).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Collaborative Research Center 1286, University of Göttingen, Göttingen, 
Germany.
(3)Auditory Neuroscience Group, Max Planck Institute of Experimental Medicine, 
Göttingen, Germany.
(4)Presynaptogenesis and Intracellular Transport in Hair Cells Group, Institute 
for Auditory Neuroscience and InnerEarLab, University Medical Center Göttingen, 
Göttingen, Germany.
(5)Multiscale Bioimaging Cluster of Excellence, University of Göttingen, 
Göttingen, Germany.

The afferent synapses between inner hair cells (IHC) and spiral ganglion neurons 
are specialized to faithfully encode sound with sub-millisecond precision over 
prolonged periods of time. Here, we studied the role of Rab3 interacting 
molecule-binding proteins (RIM-BP) 1 and 2 - multidomain proteins of the active 
zone known to directly interact with RIMs, Bassoon and Ca V 1.3 - in IHC 
presynaptic function and hearing. Recordings of auditory brainstem responses and 
otoacoustic emissions revealed that genetic disruption of RIM-BPs 1 and 2 in 
mice (RIM-BP1/2-/- ) causes a synaptopathic hearing impairment exceeding that 
found in mice lacking RIM-BP2 (RIM-BP2-/- ). Patch-clamp recordings from 
RIM-BP1/2-/- IHCs indicated a subtle impairment of exocytosis from the readily 
releasable pool of synaptic vesicles that had not been observed in RIM-BP2-/- 
IHCs. In contrast, the reduction of Ca2+-influx and sustained exocytosis was 
similar to that in RIMBP2-/- IHCs. We conclude that both RIM-BPs are required 
for normal sound encoding at the IHC synapse, whereby RIM-BP2 seems to take the 
leading role.

Copyright © 2021 Krinner, Predoehl, Burfeind, Vogl and Moser.

DOI: 10.3389/fnmol.2021.651935
PMCID: PMC8044855
PMID: 33867935

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


799. Brain Res. 2012 Nov 16;1485:63-76. doi: 10.1016/j.brainres.2012.03.016. Epub 
2012 Mar 13.

Amygdala hyperactivity and tonotopic shift after salicylate exposure.

Chen GD(1), Manohar S, Salvi R.

Author information:
(1)Center for Hearing and Deafness, State University of New York at Buffalo, 137 
Cary Hall, 3435 Main Street, Buffalo, NY 14214, USA. gchen7@buffalo.edu

The amygdala, important in forming and storing memories of aversive events, is 
believed to play a major role in debilitating tinnitus and hyperacusis. To 
explore this hypothesis, we recorded from the lateral amygdala (LA) and auditory 
cortex (AC) before and after treating rats with a dose of salicylate that 
induces tinnitus and hyperacusis-like behavior. Salicylate unexpectedly 
increased the amplitude of the local field potential (LFP) in the LA making it 
hyperactive to sounds≥60 dB SPL. Frequency receptive fields (FRFs) of multiunit 
(MU) clusters in the LA were also dramatically altered by salicylate. Neuronal 
activity at frequencies below 10 kHz and above 20 kHz was depressed at low 
intensities, but was greatly enhanced for stimuli between 10 and 20 kHz 
(frequencies near the pitch of the salicylate-induced tinnitus in the rat). 
These frequency-dependent changes caused the FRF of many LA neurons to migrate 
towards 10-20 kHz thereby amplifying activity from this region. To determine if 
salicylate-induced changes restricted to the LA would remotely affect neural 
activity in the AC, we used a micropipette to infuse salicylate (20 μl, 2.8 mM) 
into the amygdala. Local delivery of salicylate to the amygdala significantly 
increased the amplitude of the LFP recorded in the AC and selectively enhanced 
the neuronal activity of AC neurons at the mid-frequencies (10-20 kHz), 
frequencies associated with the tinnitus pitch. Taken together, these results 
indicate that systemic salicylate treatment can induce hyperactivity and 
tonotopic shift in the amygdala and infusion of salicylate into the amygdala can 
profoundly enhance sound-evoked activity in AC, changes likely to increase the 
perception and emotional salience of tinnitus and loud sounds. This article is 
part of a Special Issue entitled: Tinnitus Neuroscience.

Copyright © 2012 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.brainres.2012.03.016
PMCID: PMC5319430
PMID: 22464181 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


800. Braz J Otorhinolaryngol. 2022 Jul-Aug;88(4):546-555. doi: 
10.1016/j.bjorl.2020.07.017. Epub 2020 Sep 20.

Cochlear implantation in an animal model documents cochlear damage at the tip of 
the implant.

Andrade JSC(1), Baumhoff P(2), Cruz OLM(3), Lenarz T(2), Kral A(2).

Author information:
(1)Universidade Federal de São Paulo (UNIFESP), Departamento de 
Otorrinolaringologia e Cirurgia de Cabeça e Pescoço, São Paulo, SP, Brazil; 
Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (Capes), Brasília, 
DF, Brazil; Institute of Audioneurotechnology (VIANNA) & Department of 
Experimental Otology, Department of Otolaryngology, Medical University Hannover, 
Hannover, Germany. Electronic address: zedmed@gmail.com.
(2)Institute of Audioneurotechnology (VIANNA) & Department of Experimental 
Otology, Department of Otolaryngology, Medical University Hannover, Hannover, 
Germany; Cluster of Excellence "Hearing4all", Hannover, Germany.
(3)Universidade Federal de São Paulo (UNIFESP), Departamento de 
Otorrinolaringologia e Cirurgia de Cabeça e Pescoço, São Paulo, SP, Brazil; 
Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (Capes), Brasília, 
DF, Brazil.

INTRODUCTION: Electrocochleography has recently emerged as a diagnostic tool in 
cochlear implant surgery, purposing hearing preservation and optimal electrode 
positioning.
OBJECTIVE: In this experimental study, extra-cochlear potentials were obtained 
during cochlear implant surgery in guinea pigs. The aim was to determine 
electrophysiological changes indicating cochlear trauma after cochleostomy and 
after electrode implantation in different insertion depths.
METHODS: Normal-hearing guinea pigs (n = 14) were implanted uni- or bilaterally 
with a multichannel electrode. The extra-cochlear cochlear nerve action 
potentials were obtained in response to acoustic stimuli at specific frequencies 
before and after cochleostomy, and after introduction of the electrode bundle. 
After the electrophysiological experiments, the guinea pigs were euthanized and 
microtomography was performed, in order to determine the position of the 
electrode and to calculate of the depth of insertion. Based on the changes of 
amplitude and thresholds in relation to the stimulus frequency, the 
electrophysiological data and the position obtained by the microtomography 
reconstruction were compared.
RESULTS: Cochleostomy promoted a small electrophysiological impact, while 
electrode insertion caused changes in the amplitude of extra-cochlear 
electrophysiological potentials over a wide range of frequencies, especially in 
the deepest insertions. There was, however, preservation of the electrical 
response to low frequency stimuli in most cases, indicating a limited auditory 
impact in the intraoperative evaluation. The mean insertion depth of the apical 
electrodes was 5339.56 μm (±306.45 - 6 inserted contacts) and 4447.75 μm 
(±290.23 - 5 inserted contacts).
CONCLUSIONS: The main electrophysiological changes observed during surgical 
procedures occurred during implantation of the electrode, especially the deepest 
insertions, whereas the cochleostomy disturbed the potentials to a lesser 
extent. While hearing loss was often observed apical to the cochlear implant, it 
was possible to preserve low frequencies after insertion.

Copyright © 2020 Associação Brasileira de Otorrinolaringologia e Cirurgia 
Cérvico-Facial. Published by Elsevier Editora Ltda. All rights reserved.

DOI: 10.1016/j.bjorl.2020.07.017
PMCID: PMC9422412
PMID: 33039317 [Indexed for MEDLINE]


801. Cold Spring Harb Mol Case Stud. 2020 Jun 12;6(3):a005108. doi: 
10.1101/mcs.a005108. Print 2020 Jun.

Early-onset cerebellar ataxia in a patient with CMT2A2.

Madrid R(1), Guariglia SR(1), Haworth A(2), Korosh W(1), Gavin M(1), Lyon GJ(1).

Author information:
(1)Jervis Clinic, NYS Institute for Basic Research in Developmental Disabilities 
(IBR), Staten Island, New York 10314, USA.
(2)Congenica Ltd, Biodata Innovation Centre, Wellcome Genome Campus, Hinxton, 
Cambridge CB10 1SA, United Kingdom.

A 9-yr 8-mo-old right-handed female presented with a history of gait 
difficulties, which first became apparent at age 9 mo of age, along with slurred 
speech and hand tremors while holding a tray. Her past medical history was 
significant for global developmental delay, and she was attending fourth grade 
special education classes. On examination, she had an ataxic gait, dysarthria, 
absent deep tendon reflexes, and flexor plantar responses. There were no signs 
of optic atrophy or hearing loss. Nerve conduction studies were consistent with 
an axonal neuropathy. A fascicular sural nerve biopsy showed a marked decrease 
of myelinated fibers larger than 6 µm in diameter as compared with an 
age-matched control. By electron microscopy, clusters of degenerating axonal 
mitochondria in both myelinated and unmyelinated fibers were frequently found. 
Whole-exome sequencing revealed a heterozygous c.314C > T (p.Thr105Met) missense 
variant in MFN2 in the patient but not in her mother. The father was unavailable 
for testing. The phenotypes with MFN2 variants can be quite variable, including 
intellectual disability, optic atrophy, auditory impairment, spinal atrophy with 
or without hydromyelia, and hydrocephalus. We report here that early onset 
ataxia with intellectual disability can also be associated with MFN2-related 
Charcot-Marie-Tooth, Type 2A2A diagnosis, the most common type of autosomal 
dominant axonal neuropathy.

© 2020 Madrid et al.; Published by Cold Spring Harbor Laboratory Press.

DOI: 10.1101/mcs.a005108
PMCID: PMC7304361
PMID: 32532879 [Indexed for MEDLINE]


802. Sci Rep. 2018 May 4;8(1):7028. doi: 10.1038/s41598-018-25576-5.

Nationwide analysis of the relationships between mental health, body mass index 
and tinnitus in premenopausal female adults in Korea: 2010-2012 KNHANES.

Lee DH(1)(2), Kim YS(3)(4), Chae HS(3)(4), Han K(5).

Author information:
(1)Epidemiology Study Cluster of Uijeongbu St. Mary's Hospital, Uijeongbu St. 
Mary's Hospital, College of Medicine, The Catholic University of Korea, 
Uijeongbu, Korea. leedh0814@catholic.ac.kr.
(2)Department of Otolaryngology-HNS, College of Medicine, The Catholic 
University of Korea, Seoul, Korea. leedh0814@catholic.ac.kr.
(3)Epidemiology Study Cluster of Uijeongbu St. Mary's Hospital, Uijeongbu St. 
Mary's Hospital, College of Medicine, The Catholic University of Korea, 
Uijeongbu, Korea.
(4)Department of Internal medicine, College of Medicine, The Catholic University 
of Korea, Seoul, Korea.
(5)Department of Biostatistics, College of Medicine, The Catholic University of 
Korea, Seoul, Korea.

Tinnitus is related to serious comorbidities such as suicidal ideation and 
attempts. Body mass index (BMI) is associated with auditory symptoms including 
hearing loss. The aim of this nationwide, population-based, cross-sectional 
study was to evaluate the relationship between mental health, body mass index 
and tinnitus in a Korean premenopausal female population. This study analyzed 
data from the Korea National Health and Nutrition Examination Surveys in 
2010-2012. Data were collected from 4628 19 years or older, premenopausal women. 
After adjustments, underweight premenopausal women exhibited a higher odds ratio 
for tinnitus (odd ratio = 1.54; 95% confidence interval = 1.14-2.08) compared 
with women of normal weight. Moderate and severe tinnitus was highly prevalent 
in underweight as well as extremely obese women. The prevalence of perceived 
stress, melancholy, and suicide ideation was significantly higher in women with 
tinnitus. The prevalence of perceived stress and suicide ideation was 
significantly higher in underweight women with tinnitus, but that of melancholy 
was significantly lower. This study demonstrated that underweight premenopausal 
Korean women had a higher risk of tinnitus, which has grown in importance as a 
public health issue. Women with tinnitus experience perceived stress and suicide 
ideation more frequently, but melancholy less frequently than women without.

DOI: 10.1038/s41598-018-25576-5
PMCID: PMC5935674
PMID: 29728692 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


803. Laryngoscope Investig Otolaryngol. 2022 Dec 1;8(1):269-278. doi: 
10.1002/lio2.973. eCollection 2023 Feb.

Hearing-related quality of life in children and adolescents in rural Alaska.

Hicks KL(1), Robler SK(2)(3), Simmons RA(4)(5), Ross A(6)(7), Egger JR(5), 
Emmett SD(3)(5)(6)(7)(8).

Author information:
(1)Department of Otolaryngology/Head and Neck Surgery University of North 
Carolina-Chapel Hill Chapel Hill North Carolina USA.
(2)Department of Audiology Norton Sound Health Corporation Nome Alaska USA.
(3)Department of Otolaryngology-Head and Neck Surgery University of Arkansas for 
Medical Sciences Little Rock Arkansas USA.
(4)Department of Biostatistics & Bioinformatics Duke University Durham North 
Carolina USA.
(5)Duke Global Health Institute Durham North Carolina USA.
(6)Department of Head and Neck Surgery and Communication Sciences Duke 
University School of Medicine Durham North Carolina USA.
(7)Center for Health Policy and Inequalities Research, Duke University Durham 
North Carolina USA.
(8)Department of Epidemiology Fay W. Boozman College of Public Health, 
University of Arkansas for Medical Sciences Little Rock Arkansas USA.

OBJECTIVE: This study evaluated the Hearing Environments and Reflection on 
Quality of Life (HEAR-QL) questionnaire in rural Alaska, including an addendum 
crafted through community feedback to reflect the local context. The objectives 
were to assess whether HEAR-QL score was inversely correlated with hearing loss 
and middle ear disease in an Alaska Native population.
METHODS: The HEAR-QL questionnaires for children and adolescents were 
administered as part of a cluster randomized trial in rural Alaska from 2017 to 
2019. Enrolled students completed an audiometric evaluation and HEAR-QL 
questionnaire on the same day. A cross-sectional evaluation of questionnaire 
data was utilized.
RESULTS: A total of 733 children (ages 7-12 years) and 440 adolescents (ages 
≥13 years) completed the questionnaire. Median HEAR-QL scores were similar among 
children with and without hearing loss (Kruskal-Wallis, p = .39); however, 
adolescent HEAR-QL scores significantly decreased with increasing hearing loss 
(p < .001). Median HEAR-QL scores were significantly lower in both children 
(p = .02) and adolescents (p < .001) with middle ear disease compared with those 
without. In both children and adolescents, the addendum scores were strongly 
correlated with total HEAR-QL score (ρSpearman = 0.72 and 0.69, respectively).
CONCLUSIONS: The expected negative association between hearing loss and HEAR-QL 
score was observed in adolescents. However, there was significant variability 
that could not be explained by hearing loss, and further investigation is 
warranted. The expected negative association was not observed in children. 
HEAR-QL scores were associated with middle ear disease in both children and 
adolescents, making it potentially valuable in populations where the prevalence 
of ear infections is high.
LEVEL OF EVIDENCE: Level 2 Clinicaltrials.gov registration numbers: NCT03309553.

© 2022 The Authors. Laryngoscope Investigative Otolaryngology published by Wiley 
Periodicals LLC on behalf of The Triological Society.

DOI: 10.1002/lio2.973
PMCID: PMC9948564
PMID: 36846414


804. Brain Stimul. 2023 Sep-Oct;16(5):1486-1500. doi: 10.1016/j.brs.2023.09.018. Epub 
2023 Sep 29.

Devising a framework of optogenetic coding in the auditory pathway: Insights 
from auditory midbrain recordings.

Michael M(1), Wolf BJ(2), Klinge-Strahl A(3), Jeschke M(4), Moser T(5), Dieter 
A(6).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany.
(2)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany; Auditory Neuroscience and 
Optogenetics Laboratory, German Primate Center, 37077, Göttingen, Germany; 
Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, 37075, Göttingen, 
Germany.
(3)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany; Department of Otolaryngology, 
University Medical Center Göttingen, 37075, Göttingen, Germany.
(4)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany; Auditory Neuroscience and 
Optogenetics Laboratory, German Primate Center, 37077, Göttingen, Germany; 
Cognitive Hearing in Primates (CHiP) Group, German Primate Center, 37077, 
Göttingen, Germany.
(5)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany; Auditory Neuroscience and 
Optogenetics Laboratory, German Primate Center, 37077, Göttingen, Germany; 
Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, 37075, Göttingen, 
Germany; Auditory Neuroscience and Synaptic Nanophysiology Group, Max Planck 
Institute for Multidisciplinary Science, Göttingen, Germany. Electronic address: 
tmoser@gwdg.de.
(6)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075, Göttingen, Germany; Göttingen Graduate Center for 
Neurosciences, Biophysic, and Molecular Biosciences, 37077, Göttingen, Germany; 
Department of Neurophysiology, MCTN, Medical Faculty Mannheim, Heidelberg 
University, 68167, Mannheim, Germany. Electronic address: 
alexander.dieter@medma.uni-heidelberg.de.

Cochlear implants (CIs) restore activity in the deafened auditory system via 
electrical stimulation of the auditory nerve. As the spread of electric current 
in biological tissues is rather broad, the spectral information provided by 
electrical CIs is limited. Optogenetic stimulation of the auditory nerve has 
been suggested for artificial sound coding with improved spectral selectivity, 
as light can be conveniently confined in space. Yet, the foundations for 
optogenetic sound coding strategies remain to be established. Here, we 
parametrized stimulus-response-relationships of the auditory pathway in gerbils 
for optogenetic stimulation. Upon activation of the auditory pathway by 
waveguide-based optogenetic stimulation of the spiral ganglion, we recorded 
neuronal activity of the auditory midbrain, in which neural representations of 
spectral, temporal, and intensity information can be found. Screening a wide 
range of optical stimuli and taking the properties of optical CI emitters into 
account, we aimed to optimize stimulus paradigms for potent and energy-efficient 
activation of the auditory pathway. We report that efficient optogenetic coding 
builds on neural integration of millisecond stimuli built from microsecond light 
pulses, which optimally accommodate power-efficient laser diode operation. 
Moreover, we performed an activity-level-dependent comparison of optogenetic and 
acoustic stimulation in order to estimate the dynamic range and the maximal 
stimulation intensity amenable to single channel optogenetic sound encoding, and 
indicate that it complies well with speech comprehension in a typical 
conversation (65 dB). Our results provide a first framework for the development 
of coding strategies for future optogenetic hearing restoration.

Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.brs.2023.09.018
PMID: 37778456 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare the following financial interests/personal relationships which may be 
considered as potential competing interests: TM is co-founder of the OptoGenTech 
Company. Remaining authors declare no conflict of interest.


805. Front Neurosci. 2023 Jan 23;17:1105562. doi: 10.3389/fnins.2023.1105562. 
eCollection 2023.

Patient perspectives on the need for improved hearing rehabilitation: A 
qualitative survey study of German cochlear implant users.

Hunniford V(1)(2), Kühler R(3), Wolf B(1)(4)(5), Keppeler D(1), Strenzke 
N(1)(3)(6), Moser T(1)(4)(5)(6)(7).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Sensory and Motor Neuroscience, Göttingen Graduate Center for Neurosciences, 
Biophysics, and Molecular Biosciences, Göttingen, Germany.
(3)Department of Otolaryngology, University Medical Center Göttingen, Göttingen, 
Germany.
(4)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(5)Cluster of Excellence "Multiscale Bioimaging: From Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, Göttingen, 
Germany.
(6)Collaborative Research Center 889, University of Göttingen, Göttingen, 
Germany.
(7)Auditory Neuroscience and Synaptic Nanophysiology Group, Max Planck Institute 
for Multidisciplinary Sciences, Göttingen, Germany.

BACKGROUND: The electrical cochlear implant (eCI) partially restores hearing in 
individuals affected by profound hearing impairment (HI) or deafness. However, 
the limited resolution of sound frequency coding with eCIs limits hearing in 
daily situations such as group conversations. Current research promises future 
improvements in hearing restoration which may involve gene therapy and optical 
stimulation of the auditory nerve, using optogenetics. Prior to the potential 
clinical translation of these technologies, it is critical that patients are 
engaged in order to align future research agendas and technological advancements 
with their needs.
METHODS: Here, we performed a survey study with hearing impaired, using an eCI 
as a means of hearing rehabilitation. We distributed a questionnaire to 180 
adult patients from the University Medical Center Göttingen's Department of 
Otolaryngology who were actively using an eCI for 6 months or more during the 
time of the survey period. Questions revolved around patients needs, and 
willingness to accept hypothetical risks or drawbacks associated with an optical 
CI (oCI).
RESULTS: Eighty-one participants responded to the questionnaire; 68% were 
greater than 60 years of age and 26% had bilateral eCIs. Participants expressed 
a need for improving the performance beyond that experienced with their current 
eCI. Primarily, they desired improved speech comprehension in background noise, 
greater ability to appreciate music, and more natural sound impression. They 
expressed a willingness for engaging with new technologies for improved hearing 
restoration. Notably, participants were least concerned about hypothetically 
receiving a gene therapy necessary for the oCI implant; but expressed greater 
reluctance to hypothetically receiving an implant that had yet to be evaluated 
in a human clinical trial.
CONCLUSION: This work provides a preliminary step in engaging patients in the 
development of a new technology that has the potential to address the 
limitations of electrical hearing rehabilitation.

Copyright © 2023 Hunniford, Kühler, Wolf, Keppeler, Strenzke and Moser.

DOI: 10.3389/fnins.2023.1105562
PMCID: PMC9899842
PMID: 36755736

Conflict of interest statement: DK and TM are co-founders of the OptoGenTech 
company that works toward clinical translation of the optical cochlear implant. 
The remaining authors declare that the research was conducted in the absence of 
any commercial or financial relationships that could be construed as a potential 
conflict of interest.


806. Sci Rep. 2017 Aug 30;7(1):10043. doi: 10.1038/s41598-017-10792-2.

Increased cross-modal functional connectivity in cochlear implant users.

Chen LC(1)(2), Puschmann S(3)(4), Debener S(5)(3)(6).

Author information:
(1)Neuropsychology Lab, Department of Psychology, European Medical School, 
University of Oldenburg, Oldenburg, Germany. ling-chia.chen@uni-oldenburg.de.
(2)Cluster of Excellence Hearing4all, Oldenburg, Germany. 
ling-chia.chen@uni-oldenburg.de.
(3)Cluster of Excellence Hearing4all, Oldenburg, Germany.
(4)Biological Psychology Lab, Department of Psychology, European medical school, 
University of Oldenburg, Oldenburg, Germany.
(5)Neuropsychology Lab, Department of Psychology, European Medical School, 
University of Oldenburg, Oldenburg, Germany.
(6)Research Center Neurosensory Science, University of Oldenburg, Oldenburg, 
Germany.

Previous studies have reported increased cross-modal auditory and visual 
cortical activation in cochlear implant (CI) users, suggesting cross-modal 
reorganization of both visual and auditory cortices in CI users as a consequence 
of sensory deprivation and restoration. How these processes affect the 
functional connectivity of the auditory and visual system in CI users is however 
unknown. We here investigated task-induced intra-modal functional connectivity 
between hemispheres for both visual and auditory cortices and cross-modal 
functional connectivity between visual and auditory cortices using functional 
near infrared spectroscopy in post-lingually deaf CI users and age-matched 
normal hearing controls. Compared to controls, CI users exhibited decreased 
intra-modal functional connectivity between hemispheres and increased 
cross-modal functional connectivity between visual and left auditory cortices 
for both visual and auditory stimulus processing. Importantly, the difference 
between cross-modal functional connectivity for visual and for auditory stimuli 
correlated with speech recognition outcome in CI users. Higher cross-modal 
connectivity for auditory than for visual stimuli was associated with better 
speech recognition abilities, pointing to a new pattern of functional 
reorganization that is related to successful hearing restoration with a CI.

DOI: 10.1038/s41598-017-10792-2
PMCID: PMC5577186
PMID: 28855675 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


807. Clin Transl Med. 2020 Dec;10(8):e262. doi: 10.1002/ctm2.262.

Extracellular vesicles from human multipotent stromal cells protect against 
hearing loss after noise trauma in vivo.

Warnecke A(1), Harre J(1), Staecker H(2), Prenzler N(1), Strunk D(3), 
Couillard-Despres S(4)(5), Romanelli P(4), Hollerweger J(6), Lassacher T(6), 
Auer D(6), Pachler K(7), Wietzorrek G(8), Köhl U(9), Lenarz T(1), Schallmoser 
K(6)(10), Laner-Plamberger S(10), Falk CS(11), Rohde E(6)(10), Gimona M(6)(7).

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, Hannover, Germany.
(2)Department of Otolaryngology, Head and Neck Surgery, University of Kansas 
School of Medicine, Kansas City, Kansas.
(3)Institute of Experimental and Clinical Cell Therapy, Spinal Cord Injury and 
Tissue Regeneration Centre Salzburg (SCI-TReCS), Paracelsus Medical University, 
Salzburg, Austria.
(4)Institute of Experimental Neuroregeneration, Spinal Cord Injury and Tissue 
Regeneration Centre Salzburg (SCI-TReCS), Paracelsus Medical University, 
Salzburg, Austria.
(5)Austrian Cluster for Tissue Regeneration, Vienna, Austria.
(6)GMP Unit, Spinal Cord Injury and Tissue Regeneration Centre Salzburg 
(SCI-TReCS), Paracelsus Medical University (PMU), Salzburg, Austria.
(7)Research Program "Nanovesicular Therapies,", Paracelsus Medical University 
(PMU), Salzburg, Austria.
(8)Institute of Molecular and Cellular Pharmacology, Medical University of 
Innsbruck, Innsbruck, Austria.
(9)Institute of Cellular Therapeutics, Hannover Medical School and Clinical 
Immunology, University Leipzig, Fraunhofer Institute for Cell Therapy and 
Immunology, Leipzig, Germany.
(10)Department of Transfusion Medicine, University Hospital, Salzburger 
Landeskliniken GesmbH (SALK) and Paracelsus Medical University (PMU), Salzburg, 
Austria.
(11)Institute of Transplant Immunology, Hannover Medical School, Hannover, 
Germany.

The lack of approved anti-inflammatory and neuroprotective therapies in otology 
has been acknowledged in the last decades and recent approaches are heralding a 
new era in the field. Extracellular vesicles (EVs) derived from human 
multipotent (mesenchymal) stromal cells (MSC) can be enriched in vesicular 
secretome fractions, which have been shown to exert effects (eg, neuroprotection 
and immunomodulation) of their parental cells. Hence, MSC-derived EVs may serve 
as novel drug candidates for several inner ear diseases. Here, we provide first 
evidence of a strong neuroprotective potential of human stromal cell-derived EVs 
on inner ear physiology. In vitro, MSC-EV preparations exerted immunomodulatory 
activity on T cells and microglial cells. Moreover, local application of MSC-EVs 
to the inner ear significantly attenuated hearing loss and protected auditory 
hair cells from noise-induced trauma in vivo. Thus, EVs derived from the 
vesicular secretome of human MSC may represent a next-generation biological drug 
that can exert protective therapeutic effects in a complex and nonregenerating 
organ like the inner ear.

© 2020 The Authors. Clinical and Translational Medicine published by John Wiley 
& Sons Australia, Ltd on behalf of Shanghai Institute of Clinical 
Bioinformatics.

DOI: 10.1002/ctm2.262
PMCID: PMC7752163
PMID: 33377658

Conflict of interest statement: Eva Rohde is the CEO of PMU Innovations GmbH 
(Salzburg) and Medical Consultant of MDimune Inc. (Seoul, Korea). Mario Gimona 
is the Consulting Chief Manufacturing Officer of MDimune Inc. (Seoul, Korea). 
Athanasia Warnecke and Jennifer Harre: Conception/design, financial support, 
performing the in vitro experiments, collection and/or assembly of data, data 
analysis and interpretation, manuscript writing, and final approval of the 
manuscript. Hinrich Staecker: Performing the in vivo experiments, collection 
and/or assembly of data, data analysis and interpretation, and final approval of 
the manuscript. Nils Prenzler: Collection and/or assembly of data, final 
approval of the manuscript. Dirk Strunk, Sebastien Couillard‐Despres, and 
Pasquale Romanelli: In vitro testing and final approval of the manuscript. Julia 
Hollerweger and Teresa Lassacher: EV manufacturing under good manufacturing 
practice (GMP) and in vitro testing. Daniela Auer: In vitro testing, quality 
control under GMP. Karin Pachler: EV manufacturing and in vitro testing. Georg 
Wietzorrek: Data analysis and final interpretation, and final approval of the 
manuscript. Ulrike Köhl: Handling and storage of clinical EV preparations under 
GMP and good distribution practice, and final approval of the manuscript. Thomas 
Lenarz: Administrative support, manuscript writing, and final approval of the 
manuscript. Katharina Schallmoser: pHLP manufacturing GMP and final approval of 
the manuscript. Christine S. Falk: Performance of the Luminex‐based multiplex 
protein arrays, data analysis, final approval of the manuscript. Sandra 
Laner‐Plamberger: Primary stromal cell isolation, in vitro testing, and final 
approval of the manuscript. Eva Rohde: Conception and design, administrative 
support, manuscript writing, and final approval of the manuscript. Mario Gimona: 
Conception and design of EV manufacturing strategy, EV manufacturing, financial 
and administrative support, manuscript writing, and final approval of the 
manuscript.


808. Front Neurol. 2017 Feb 20;8:46. doi: 10.3389/fneur.2017.00046. eCollection 2017.

Different Patterns of Hearing Loss among Tinnitus Patients: A Latent Class 
Analysis of a Large Sample.

Langguth B(1), Landgrebe M(2), Schlee W(1), Schecklmann M(1), Vielsmeier V(3), 
Steffens T(3), Staudinger S(4), Frick H(5), Frick U(6).

Author information:
(1)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany; Interdisciplinary Tinnitus Center of the University of 
Regensburg, Regensburg, Germany.
(2)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany; kbo Lech-Mangfall-Klinik Agatharied, Hausham, Germany.
(3)Interdisciplinary Tinnitus Center of the University of Regensburg, 
Regensburg, Germany; Department of Otorhinolaryngology, University of 
Regensburg, Regensburg, Germany.
(4)Interdisciplinary Tinnitus Center of the University of Regensburg , 
Regensburg , Germany.
(5)Department of Statistical Science, University College London , London , UK.
(6)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany; HSD University of Applied Sciences, Cologne, Germany.

BACKGROUND: The heterogeneity of tinnitus is a major challenge for tinnitus 
research. Even if a complex interaction of many factors is involved in the 
etiology of tinnitus, hearing loss (HL) has been identified as the most relevant 
etiologic factor. Here, we used a data-driven approach to identify patterns of 
hearing function in a large sample of tinnitus patients presenting in a tinnitus 
clinic.
METHODS: Data from 2,838 patients presenting at the Tinnitus Center of the 
University Regensburg between 2007 and 2014 have been analyzed. Standard 
audiometric data were frequency-wise categorized in four categories [a: normal 
hearing (0-20 dB HL); b: moderate HL (25-50 dB HL; representing outer hair cell 
loss); c: severe HL (>50 dB HL; representing outer and inner hair cell loss); d: 
no data available] and entered in a latent class analysis, a statistical method 
to find subtypes of cases in multivariate categorical data. To validate the 
clinical relevance of the identified latent classes, they were compared with 
respect to clinical and demographic characteristics of their members.
RESULTS: The classification algorithm identified eight distinct latent classes 
with an excellent separation. Patient classes differed with respect to 
demographic (e.g., age, gender) and clinical characteristics (e.g., tinnitus 
location, tinnitus severity, gradual, or abrupt onset, etc.).
DISCUSSION: Our results demonstrate that data-driven categorization of hearing 
function seems to be a promising approach for profiling tinnitus patients, as it 
revealed distinct subtypes that reflect prototypic forms of HL and that differ 
in several relevant clinical characteristics.

DOI: 10.3389/fneur.2017.00046
PMCID: PMC5316929
PMID: 28265258


809. Exp Brain Res. 2019 Sep;237(9):2137-2143. doi: 10.1007/s00221-019-05578-z. Epub 
2019 Jun 14.

Peripheral visual localization is degraded by globally incongruent 
auditory-spatial attention cues.

Ahveninen J(1), Ingalls G(2), Yildirim F(2), Calabro FJ(2)(3), Vaina 
LM(4)(2)(5).

Author information:
(1)Harvard Medical School, Athinoula A. Martinos Center for Biomedical Imaging, 
Department of Radiology, Massachusetts General Hospital, Charlestown, MA, USA. 
jyrki@nmr.mgh.harvard.edu.
(2)Brain and Vision Research Laboratory, Department of Biomedical Engineering, 
Boston University, Boston, MA, USA.
(3)Department of Psychiatry and Bioengineering, University of Pittsburgh, 
Pittsburgh, PA, USA.
(4)Harvard Medical School, Athinoula A. Martinos Center for Biomedical Imaging, 
Department of Radiology, Massachusetts General Hospital, Charlestown, MA, USA.
(5)Department of Neurology, Harvard Medical School, Massachusetts General 
Hospital and Brigham and Women's Hospital, Boston, MA, USA.

Global auditory-spatial orienting cues help the detection of weak visual 
stimuli, but it is not clear whether crossmodal attention cues also enhance the 
resolution of visuospatial discrimination. Here, we hypothesized that if 
anywhere, crossmodal modulations of visual localization should emerge in the 
periphery where the receptive fields are large. Subjects were presented with 
trials where a Visual Target, defined by a cluster of low-luminance dots, was 
shown for 220 ms at 25°-35° eccentricity in either the left or right hemifield. 
The Visual Target was either Uncued or it was presented 250 ms after a 
crossmodal Auditory Cue that was simulated either from the same or the opposite 
hemifield than the Visual Target location. After a whole-screen visual mask 
displayed for 800 ms, a pair of vertical Reference Bars was presented 
ipsilateral to the Visual Target. In a two-alternative forced choice task, 
subjects were asked to determine which of these two bars was closer to the 
center of the Visual Target. When the Auditory Cue and Visual Target were 
hemispatially incongruent, the speed and accuracy of visual localization 
performance was significantly impaired. However, hemispatially congruent 
Auditory Cues did not improve the localization of Visual Targets when compared 
to the Uncued condition. Further analyses suggested that the crossmodal Auditory 
Cues decreased the sensitivity (d') of the Visual Target localization without 
affecting post-perceptual decision biases. Our results suggest that in the 
visual periphery, the detrimental effect of hemispatially incongruent Auditory 
Cues is far greater than the benefit produced by hemispatially congruent cues. 
Our working hypothesis for future studies is that auditory-spatial attention 
cues suppress irrelevant visual locations in a global fashion, without 
modulating the local visual precision at relevant sites.

DOI: 10.1007/s00221-019-05578-z
PMCID: PMC6677609
PMID: 31201472 [Indexed for MEDLINE]


810. Front Neurosci. 2019 Oct 30;13:1165. doi: 10.3389/fnins.2019.01165. eCollection 
2019.

Decoding Task-Related Functional Brain Imaging Data to Identify Developmental 
Disorders: The Case of Congenital Amusia.

Albouy P(1)(2), Caclin A(3)(4), Norman-Haignere SV(5)(6), Lévêque Y(4)(7), 
Peretz I(2), Tillmann B(4)(7), Zatorre RJ(1)(2).

Author information:
(1)Cognitive Neuroscience Unit, Montreal Neurological Institute, McGill 
University, Montreal, QC, Canada.
(2)International Laboratory for Brain, Music and Sound Research, Montreal, QC, 
Canada.
(3)INSERM, U1028, CNRS, UMR 5292, Lyon Neuroscience Research Center, Brain 
Dynamics and Cognition Team, Lyon, France.
(4)University Lyon 1, Lyon, France.
(5)Zuckerman Institute of Mind, Brain and Behavior, Columbia University, New 
York, NY, United States.
(6)CNRS, Laboratoire des Sytèmes Perceptifs, Département d'Études Cognitives, 
ENS, PSL University, Paris, France.
(7)CNRS, UMR 5292, INSERM, U1028, Lyon Neuroscience Research Center, Auditory 
Cognition and Psychoacoustics Team, Lyon, France.

Machine learning classification techniques are frequently applied to structural 
and resting-state fMRI data to identify brain-based biomarkers for developmental 
disorders. However, task-related fMRI has rarely been used as a diagnostic tool. 
Here, we used structural MRI, resting-state connectivity and task-based fMRI 
data to detect congenital amusia, a pitch-specific developmental disorder. All 
approaches discriminated amusics from controls in meaningful brain networks at 
similar levels of accuracy. Interestingly, the classifier outcome was specific 
to deficit-related neural circuits, as the group classification failed for fMRI 
data acquired during a verbal task for which amusics were unimpaired. Most 
importantly, classifier outputs of task-related fMRI data predicted individual 
behavioral performance on an independent pitch-based task, while this 
relationship was not observed for structural or resting-state data. These 
results suggest that task-related imaging data can potentially be used as a 
powerful diagnostic tool to identify developmental disorders as they allow for 
the prediction of symptom severity.

Copyright © 2019 Albouy, Caclin, Norman-Haignere, Lévêque, Peretz, Tillmann and 
Zatorre.

DOI: 10.3389/fnins.2019.01165
PMCID: PMC6831619
PMID: 31736698


811. Am J Med Genet A. 2007 May 15;143A(10):1053-9. doi: 10.1002/ajmg.a.31715.

Mandibulofacial dysostosis in a patient with a de novo 2;17 translocation that 
disrupts the HOXD gene cluster.

Stevenson DA(1), Bleyl SB, Maxwell T, Brothman AR, South ST.

Author information:
(1)Division of Medical Genetics, Department of Pediatrics, University of Utah, 
Salt Lake City, Utah 84132, USA. david.stevenson@hsc.utah.edu

Treacher Collins syndrome (TCS) is the prototypical mandibulofacial dysostosis 
syndrome, but other mandibulofacial dysostosis syndromes have been described. We 
report an infant with mandibulofacial dysostosis and an apparently balanced de 
novo 2;17 translocation. She presented with severe lower eyelid colobomas 
requiring skin grafting, malar and mandibular hypoplasia, bilateral microtia 
with external auditory canal atreasia, dysplastic ossicles, hearing loss, 
bilateral choanal stenosis, cleft palate without cleft lip, several oral frenula 
of the upper lip/gum, and micrognathia requiring tracheostomy. Her limbs were 
normal. Chromosome analysis at the 600-band level showed a 
46,XX,t(2;17)(q24.3;q23) karyotype. Sequencing of the entire TCOF1 coding region 
did not show evidence of a sequence variation. High-resolution genomic 
microarray analysis did not identify a cryptic imbalance. FISH mapping refined 
the breakpoints to 2q31.1 and 17q24.3-25.1 and showed the 2q31.1 breakpoint 
likely affects the HOXD gene cluster. Several atypical findings and lack of an 
identifiable TCOF1 mutation suggest that this child has a provisionally unique 
mandibulofacial dysostosis syndrome. The apparently balanced de novo 
translocation provides candidate loci for atypical and TCOF1 mutation negative 
cases of TCS. Based on the agreement of our findings with one previous case of 
mandibulofacial dysostosis with a 2q31.1 transocation, we hypothesize that 
misexpression of genes in the HOXD gene cluster produced the described phenotype 
in this patient.

DOI: 10.1002/ajmg.a.31715
PMCID: PMC3243067
PMID: 17431905 [Indexed for MEDLINE]


812. Magn Reson Med. 2021 Nov;86(5):2577-2588. doi: 10.1002/mrm.28902. Epub 2021 Jul 
1.

Comparison of continuous sampling with active noise cancelation and sparse 
sampling for cortical and subcortical auditory functional MRI.

Dewey RS(1)(2)(3), Hall DA(2)(3)(4), Plack CJ(5)(6)(7), Francis ST(1).

Author information:
(1)Sir Peter Mansfield Imaging Centre, School of Physics and Astronomy, 
University of Nottingham, Nottingham, United Kingdom.
(2)National Institute for Health Research (NIHR) Nottingham Biomedical Research 
Centre, Nottingham, United Kingdom.
(3)Hearing Sciences, Division of Mental Health and Clinical Neurosciences, 
School of Medicine, University of Nottingham, Nottingham, United Kingdom.
(4)Heriot-Watt University Malaysia, Putrajaya, Malaysia.
(5)Manchester Centre for Audiology and Deafness, University of Manchester, 
Manchester Academic Health Science Centre, Manchester, United Kingdom.
(6)National Institute for Health Research Manchester Biomedical Research Centre, 
Central Manchester University Hospitals NHS Foundation Trust, Manchester, United 
Kingdom.
(7)Department of Psychology, Lancaster University, Lancaster, United Kingdom.

PURPOSE: Detecting sound-related activity using functional MRI requires the 
auditory stimulus to be more salient than the intense background scanner 
acoustic noise. Various strategies can reduce the impact of scanner acoustic 
noise, including "sparse" temporal sampling with single/clustered acquisitions 
providing intervals without any background scanner acoustic noise, or active 
noise cancelation (ANC) during "continuous" temporal sampling, which generates 
an acoustic signal that adds destructively to the scanner acoustic noise, 
substantially reducing the acoustic energy at the participant's eardrum. 
Furthermore, multiband functional MRI allows multiple slices to be collected 
simultaneously, thereby reducing scanner acoustic noise in a given sampling 
period.
METHODS: Isotropic multiband functional MRI (1.5 mm) with sparse sampling 
(effective TR = 9000 ms, acquisition duration = 1962 ms) and continuous sampling 
(TR = 2000 ms) with ANC were compared in 15 normally hearing participants. A 
sustained broadband noise stimulus was presented to drive activation of both 
sustained and transient auditory responses within subcortical and cortical 
auditory regions.
RESULTS: Robust broadband noise-related activity was detected throughout the 
auditory pathways. Continuous sampling with ANC was found to give a 
statistically significant advantage over sparse sampling for the detection of 
the transient (onset) stimulus responses, particularly in the auditory cortex (P 
< .001) and inferior colliculus (P < .001), whereas gains provided by sparse 
over continuous ANC for detecting offset and sustained responses were marginal 
(p ~ 0.05 in superior olivary complex, inferior colliculus, medial geniculate 
body, and auditory cortex).
CONCLUSIONS: Sparse and continuous ANC multiband functional MRI protocols 
provide differing advantages for observing the transient (onset and offset) and 
sustained stimulus responses.

© 2021 The Authors. Magnetic Resonance in Medicine published by Wiley 
Periodicals LLC on behalf of International Society for Magnetic Resonance in 
Medicine.

DOI: 10.1002/mrm.28902
PMID: 34196020 [Indexed for MEDLINE]


813. Hear Res. 2007 Apr;226(1-2):244-53. doi: 10.1016/j.heares.2006.06.013. Epub 2006 
Aug 14.

Salicylate induced tinnitus: behavioral measures and neural activity in auditory 
cortex of awake rats.

Yang G(1), Lobarinas E, Zhang L, Turner J, Stolzberg D, Salvi R, Sun W.

Author information:
(1)Center for Hearing and Deafness, Department of Communicative Disorders and 
Sciences, University at Buffalo, Buffalo, NY 14214, USA.

Neurophysiological studies of salicylate-induced tinnitus have generally been 
carried out under anesthesia, a condition that abolishes the perception of 
tinnitus and depresses neural activity. To overcome these limitations, 
measurement of salicylate induced tinnitus were obtained from rats using 
schedule induced polydipsia avoidance conditioning (SIPAC) and gap pre-pulse 
inhibition of acoustic startle (GPIAS). Both behavioral measures indicated that 
tinnitus was present after treatment with 150 and 250 mg/kg of salicylate; 
measurements with GPIAS indicated that the pitch of the tinnitus was near 16 
kHz. Chronically implanted microwire electrode arrays were used to monitor the 
local field potentials and spontaneous discharge rate from multiunit clusters in 
the auditory cortex of awake rats before and after treatment with 150 mg/kg of 
salicylate. The amplitude of the local field potential elicited with 60 dB SPL 
tone bursts increased significantly 2h after salicylate treatment particularly 
at 16-20 kHz; frequencies associated with the tinnitus pitch. Field potential 
amplitudes had largely recovered 1-2 days post-salicylate when behavioral 
results showed that tinnitus was absent. The mean spontaneous spike recorded 
from the same multiunit cluster pre- and post-salicylate decreased from 22 
spikes/s before treatment to 14 spikes/s 2h post-salicylate and recovered 1 day 
post-treatment. These preliminary physiology data suggest that salicylate 
induced tinnitus is associated with sound evoked hyperactivity in auditory 
cortex and spontaneous hypoactivity.

DOI: 10.1016/j.heares.2006.06.013
PMID: 16904853 [Indexed for MEDLINE]


814. Semin Cell Dev Biol. 2013 May;24(5):460-9. doi: 10.1016/j.semcdb.2013.04.003. 
Epub 2013 May 6.

Making connections in the inner ear: recent insights into the development of 
spiral ganglion neurons and their connectivity with sensory hair cells.

Coate TM(1), Kelley MW.

Author information:
(1)Laboratory of Cochlear Development, National Institute on Deafness and Other 
Communication Disorders, National Institutes of Health, Bethesda, MD 20892, USA. 
coatet@nidcd.nih.gov

In mammals, auditory information is processed by the hair cells (HCs) located in 
the cochlea and then rapidly transmitted to the CNS via a specialized cluster of 
bipolar afferent connections known as the spiral ganglion neurons (SGNs). 
Although many anatomical aspects of SGNs are well described, the molecular and 
cellular mechanisms underlying their genesis, how they are precisely arranged 
along the cochlear duct, and the guidance mechanisms that promote the 
innervation of their hair cell targets are only now being understood. Building 
upon foundational studies of neurogenesis and neurotrophins, we review here new 
concepts and technologies that are helping to enrich our understanding of the 
development of the nervous system within the inner ear.

Published by Elsevier Ltd.

DOI: 10.1016/j.semcdb.2013.04.003
PMCID: PMC3690159
PMID: 23660234 [Indexed for MEDLINE]


815. J Neurosci. 2016 Mar 9;36(10):2986-94. doi: 10.1523/JNEUROSCI.2705-15.2016.

Pitch-Responsive Cortical Regions in Congenital Amusia.

Norman-Haignere SV(1), Albouy P(2), Caclin A(3), McDermott JH(4), Kanwisher 
NG(5), Tillmann B(3).

Author information:
(1)Department of Brain and Cognitive Sciences and snormanhaignere@gmail.com.
(2)Lyon Neuroscience Research Centre, Centre National de la Recherche 
Scientifique UMR5292, INSERM U1028, Lyon 1 University, F-69000 Lyon, France, and 
Montreal Neurological Institute, McGill University, Quebec H3A 0G4, Canada.
(3)Lyon Neuroscience Research Centre, Centre National de la Recherche 
Scientifique UMR5292, INSERM U1028, Lyon 1 University, F-69000 Lyon, France, 
and.
(4)Department of Brain and Cognitive Sciences and.
(5)Department of Brain and Cognitive Sciences and McGovern Institute for Brain 
Science, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139.

Congenital amusia is a lifelong deficit in music perception thought to reflect 
an underlying impairment in the perception and memory of pitch. The neural basis 
of amusic impairments is actively debated. Some prior studies have suggested 
that amusia stems from impaired connectivity between auditory and frontal 
cortex. However, it remains possible that impairments in pitch coding within 
auditory cortex also contribute to the disorder, in part because prior studies 
have not measured responses from the cortical regions most implicated in pitch 
perception in normal individuals. We addressed this question by measuring fMRI 
responses in 11 subjects with amusia and 11 age- and education-matched controls 
to a stimulus contrast that reliably identifies pitch-responsive regions in 
normal individuals: harmonic tones versus frequency-matched noise. Our findings 
demonstrate that amusic individuals with a substantial pitch perception deficit 
exhibit clusters of pitch-responsive voxels that are comparable in extent, 
selectivity, and anatomical location to those of control participants. We 
discuss possible explanations for why amusics might be impaired at perceiving 
pitch relations despite exhibiting normal fMRI responses to pitch in their 
auditory cortex: (1) individual neurons within the pitch-responsive region might 
exhibit abnormal tuning or temporal coding not detectable with fMRI, (2) 
anatomical tracts that link pitch-responsive regions to other brain areas (e.g., 
frontal cortex) might be altered, and (3) cortical regions outside of 
pitch-responsive cortex might be abnormal. The ability to identify 
pitch-responsive regions in individual amusic subjects will make it possible to 
ask more precise questions about their role in amusia in future work.

Copyright © 2016 the authors 0270-6474/16/362986-09$15.00/0.

DOI: 10.1523/JNEUROSCI.2705-15.2016
PMCID: PMC6601753
PMID: 26961952 [Indexed for MEDLINE]


816. Mol Ther Methods Clin Dev. 2023 Mar 21;29:202-212. doi: 
10.1016/j.omtm.2023.03.009. eCollection 2023 Jun 8.

Channelrhodopsin fluorescent tag replacement for clinical translation of 
optogenetic hearing restoration.

Zerche M(1)(2)(3)(4), Wrobel C(2)(5), Kusch K(1)(6), Moser T(1)(7)(8)(4), Mager 
T(1)(3)(4).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37075 Göttingen, Germany.
(2)Department of Otolaryngology, University Medical Center Göttingen, 37075 
Göttingen, Germany.
(3)Advanced Optogenes Group, Institute for Auditory Neuroscience, University 
Medical Center Göttingen, 37075 Göttingen, Germany.
(4)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Göttingen, 37075 Göttingen, 
Germany.
(5)Translational Inner Ear Research Group, InnerEarLab, University Medical 
Center Göttingen, 37075 Göttingen, Germany.
(6)Functional Auditory Genomics, Institute for Auditory Neuroscience, University 
Medical Center Göttingen, 37075 Göttingen, Germany.
(7)Auditory Neuroscience and Optogenetics laboratory, German Primate Center, 
37077 Göttingen, Germany.
(8)Auditory Neuroscience and Synaptic Nanophysiology Group, Max-Planck-Institute 
for Multidisciplinary Sciences, 37075 Göttingen, Germany.

Sensory restoration by optogenetic neurostimulation provides a promising future 
alternative to current electrical stimulation approaches. So far, 
channelrhodopsins (ChRs) typically contain a C-terminal fluorescent protein (FP) 
tag for visualization that potentially poses an additional risk for clinical 
translation. Previous work indicated a reduction of optogenetic stimulation 
efficacy upon FP removal. Here, we further optimized the fast-gating, 
red-light-activated ChR f-Chrimson to achieve efficient optogenetic stimulation 
in the absence of the C-terminal FP. Upon FP removal, we observed a massive 
amplitude reduction of photocurrents in transfected cells in vitro and of 
optogenetically evoked activity of the adeno-associated virus (AAV) 
vector-transduced auditory nerve in mice in vivo. Increasing the AAV vector dose 
restored optogenetically evoked auditory nerve activity but was confounded by 
neural loss. Of various C-terminal modifications, we found the replacement of 
the FP by the Kir2.1 trafficking sequence (TSKir2.1) to best restore both 
photocurrents and optogenetically evoked auditory nerve activity with only mild 
neural loss few months after dosing. In conclusion, we consider 
f-Chrimson-TSKir2.1 to be a promising candidate for clinical translation of 
optogenetic neurostimulation such as by future optical cochlear implants.

© 2023 The Authors.

DOI: 10.1016/j.omtm.2023.03.009
PMCID: PMC10111946
PMID: 37081855

Conflict of interest statement: The authors declare no competing interests.


817. Front Neurosci. 2021 Jan 21;14:625721. doi: 10.3389/fnins.2020.625721. 
eCollection 2020.

Deafness Weakens Interareal Couplings in the Auditory Cortex.

Yusuf PA(1)(2)(3), Hubka P(2)(3), Tillein J(2)(3)(4)(5), Vinck M(6)(7), Kral 
A(2)(3)(8).

Author information:
(1)Department of Medical Physics/Medical Technology Core Cluster IMERI, Faculty 
of Medicine, University of Indonesia, Jakarta, Indonesia.
(2)Institute of AudioNeuroTechnology, Hannover Medical School, Hanover, Germany.
(3)Department of Experimental Otology of the ENT Clinics, Hannover Medical 
School, Hanover, Germany.
(4)Department of Otorhinolaryngology, Goethe University, Frankfurt am Main, 
Germany.
(5)MedEL Company, Innsbruck, Austria.
(6)Ernst Strüngmann Institut for Neuroscience in Cooperation with Max Planck 
Society, Frankfurt, Germany.
(7)Donders Centre for Neuroscience, Radboud University, Department of 
Neuroinformatics, Nijmegen, Netherlands.
(8)Department of Biomedical Sciences, School of Medicine and Health Sciences, 
Macquarie University, Sydney, NSW, Australia.

The function of the cerebral cortex essentially depends on the ability to form 
functional assemblies across different cortical areas serving different 
functions. Here we investigated how developmental hearing experience affects 
functional and effective interareal connectivity in the auditory cortex in an 
animal model with years-long and complete auditory deprivation (deafness) from 
birth, the congenitally deaf cat (CDC). Using intracortical multielectrode 
arrays, neuronal activity of adult hearing controls and CDCs was registered in 
the primary auditory cortex and the secondary posterior auditory field (PAF). 
Ongoing activity as well as responses to acoustic stimulation (in adult hearing 
controls) and electric stimulation applied via cochlear implants (in adult 
hearing controls and CDCs) were analyzed. As functional connectivity measures 
pairwise phase consistency and Granger causality were used. While the number of 
coupled sites was nearly identical between controls and CDCs, a reduced coupling 
strength between the primary and the higher order field was found in CDCs under 
auditory stimulation. Such stimulus-related decoupling was particularly 
pronounced in the alpha band and in top-down direction. Ongoing connectivity did 
not show such a decoupling. These findings suggest that developmental experience 
is essential for functional interareal interactions during sensory processing. 
The outcomes demonstrate that corticocortical couplings, particularly top-down 
connectivity, are compromised following congenital sensory deprivation.

Copyright © 2021 Yusuf, Hubka, Tillein, Vinck and Kral.

DOI: 10.3389/fnins.2020.625721
PMCID: PMC7858676
PMID: 33551733

Conflict of interest statement: JT was employed by MedEl Company, Innsbruck, 
Austria. The remaining authors declare that the research was conducted in the 
absence of any commercial or financial relationships that could be construed as 
a potential conflict of interest.


818. Iran J Public Health. 2017 Sep;46(9):1237-1246.

The Prevalence of Hearing Impairment by Age and Gender in a Population-based 
Study.

Asghari A(1)(2), Farhadi M(1), Daneshi A(1), Khabazkhoob M(3), Mohazzab-Torabi 
S(4), Jalessi M(2), Emamjomeh H(1).

Author information:
(1)ENT and Head & Neck Research Center, Hazrat Rasoul Akram Hospital, Iran 
University of Medical Sciences, Tehran, Iran.
(2)Skull Base Research Center, Iran University of Medical Sciences, Tehran, 
Iran.
(3)Dept. of Medical Surgical Nursing, School of Nursing and Midwifery, Shahid 
Beheshti University of Medical Sciences, Tehran, Iran.
(4)Noor Research Center for Ophthalmic Epidemiology, Noor Eye Hospital, Tehran, 
Iran.

BACKGROUND: This study aimed to determine the prevalence of hearing impairment 
(HI) by age and gender in a population aged 5 yr and older residing in Tehran, 
Iran.
METHODS: In this cross-sectional study, 140 clusters each including 10 
households from Tehran, Iran were sampled between 2012 and 2013 using cluster 
random sampling. Trained audiologists examined the participants during 
face-to-face interviews. The hearing of the participants was evaluated before 
the removal of wax or other foreign bodies. In this study, HI was categorized as 
mild (grade 1, 26-40 db), moderate (grade 2, 41-60 db), severe (grade 3, 61-80 
db), and deaf (grade 5, 81 db or more). All participants signed informed consent 
forms. The SATA software was used for data analysis.
RESULTS: Of 6521 individuals, 4370 (67%) were interviewed. The prevalence of HI 
(auditory threshold of 0.5, 1, 2, 4 KHz and more than 25 db in the better ear) 
was 14.27 (11.53-17.91) of whom 9.52 (7.07-11.98) had grade 1, 4.04 (3.02-5.06) 
had grade 2, 0.67 (0.33-1.02) had grade 3 HI and 0.48 (0.16-0.8) were deaf. 
About 5.19% of the participants had disabling hearing impairment. All HI grades 
increased significantly with age but no significant difference was observed 
between men and women.
CONCLUSION: The considerable prevalence of HI in Iran in comparison with other 
developing countries, with regards to the trend of aging in the population, 
seems concerning. The results of the study could be used as a treatment and 
research guideline for future works in the area of policymaking and plan to 
decrease these disorders.

PMCID: PMC5632326
PMID: 29026790

Conflict of interest statement: Conflict of Interests The authors declare that 
there is no conflict of interest.


819. EMBO Mol Med. 2020 Aug 7;12(8):e12387. doi: 10.15252/emmm.202012387. Epub 2020 
Jun 29.

μLED-based optical cochlear implants for spectrally selective activation of the 
auditory nerve.

Dieter A(#)(1)(2), Klein E(#)(3), Keppeler D(1), Jablonski L(1)(4), Harczos 
T(1)(4), Hoch G(1)(4), Rankovic V(1)(4)(5), Paul O(3)(6), Jeschke M(1)(4)(7), 
Ruther P(3)(6), Moser T(1)(2)(4)(8)(9).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Göttingen Graduate School for Neurosciences and Molecular Biosciences, 
University of Göttingen, Göttingen, Germany.
(3)Department of Microsystems Engineering (IMTEK), University of Freiburg, 
Freiburg, Germany.
(4)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Göttingen, Germany.
(5)Restorative Cochlear Genomics Group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(6)BrainLinks-BrainTools, Cluster of Excellence, University of Freiburg, 
Freiburg, Germany.
(7)Cognitive Hearing in Primates Group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(8)Auditory Neuroscience Group, Max Planck Institute for Experimental Medicine, 
Göttingen, Germany.
(9)Cluster of Excellence "Multiscale Bioimaging: from Molecular Machines to 
Networks of Excitable Cells" (MBExC), University of Goettingen, Goettingen, 
Germany.
(#)Contributed equally

Electrical cochlear implants (eCIs) partially restore hearing and enable speech 
comprehension to more than half a million users, thereby re-connecting deaf 
patients to the auditory scene surrounding them. Yet, eCIs suffer from limited 
spectral selectivity, resulting from current spread around each electrode 
contact and causing poor speech recognition in the presence of background noise. 
Optogenetic stimulation of the auditory nerve might overcome this limitation as 
light can be conveniently confined in space. Here, we combined virus-mediated 
optogenetic manipulation of cochlear spiral ganglion neurons (SGNs) and 
microsystems engineering to establish acute multi-channel optical cochlear 
implant (oCI) stimulation in adult Mongolian gerbils. oCIs based on 16 
microscale thin-film light-emitting diodes (μLEDs) evoked tonotopic activation 
of the auditory pathway with high spectral selectivity and modest power 
requirements in hearing and deaf gerbils. These results prove the feasibility of 
μLED-based oCIs for spectrally selective activation of the auditory nerve.

© 2020 The Authors. Published under the terms of the CC BY 4.0 license.

DOI: 10.15252/emmm.202012387
PMCID: PMC7411546
PMID: 32596983 [Indexed for MEDLINE]

Conflict of interest statement: TM and DK are co‐founders of the company 
OptoGenTech.


820. Head Neck Pathol. 2024 Feb 9;18(1):5. doi: 10.1007/s12105-023-01606-1.

Fungal Otitis Externa (Otomycosis) Associated with Aspergillus Flavus: A Case 
Image.

MacDonald WW(1), Wakely PE Jr(1), Kalmar JR(2), Argyris PP(3).

Author information:
(1)Department of Pathology, The Ohio State University Wexner Medical Center, 
James Cancer Hospital and Solove Research Institute, Columbus, OH, USA.
(2)Division of Oral and Maxillofacial Pathology, The Ohio State University 
College of Dentistry, Postle Hall, Room 2191 305 W. 12th Ave, Columbus, OH, USA.
(3)Division of Oral and Maxillofacial Pathology, The Ohio State University 
College of Dentistry, Postle Hall, Room 2191 305 W. 12th Ave, Columbus, OH, USA. 
argyris.2@osu.edu.

A 48-year-old man presented with a chief complaint of intermittent right ear 
otorrhea of several-month duration, occasional otalgia and progressive 
unilateral hearing impairment. He also reported frequent episodes of headache 
and pressure in the sinuses and maxilla. Previous systemic treatment with 
antibiotics failed to alleviate the symptoms. A head/neck CT showed completely 
normal mastoid, middle ear and external auditory canal regions without any 
evidence of opacification or bone erosion. Otoscopic examination of the right 
ear disclosed aggregates of dried, brown, fibrillar material and debris 
occluding the external auditory canal and obstructing the otherwise intact 
tympanic membrane. Dilation of the external auditory canal or thickening of the 
tympanic membrane were not appreciated. The canal was debrided and the fibrillar 
material was placed in formalin. Histopathologic examination revealed numerous 
branching, septated fungal hyphae organized in densely-packed clusters. In other 
areas, the fungal hyphae abutted or were attached to lamellated collections of 
orthokeratin. As highlighted by GMS staining, the fungi were morphologically 
compatible with Aspergillus species. The clinicopathologic findings supported a 
diagnosis of fungal otitis externa, while the numerous anucleate squamous cells 
were compatible with colonization of an underlying, probably developing, 
cholesteatoma. Culture of material isolated from the external auditory canal 
confirmed the presence of Aspergillus flavus. In this illustrative case, we 
present the main clinical and microscopic characteristics of Aspergillus-related 
otomycosis developing in the setting of a tautochronous cholesteatoma.

© 2024. The Author(s).

DOI: 10.1007/s12105-023-01606-1
PMCID: PMC10858010
PMID: 38334859 [Indexed for MEDLINE]

Conflict of interest statement: No conflict of interest to disclose.


821. Proc Natl Acad Sci U S A. 2017 May 23;114(21):E4271-E4280. doi: 
10.1073/pnas.1619442114. Epub 2017 May 8.

Maturation arrest in early postnatal sensory receptors by deletion of the 
miR-183/96/182 cluster in mouse.

Fan J(1), Jia L(2), Li Y(3), Ebrahim S(4), May-Simera H(5), Wood A(6), Morell 
RJ(7), Liu P(3), Lei J(3), Kachar B(4), Belluscio L(6), Qian H(8), Li T(5), Li 
W(9), Wistow G(10), Dong L(11).

Author information:
(1)Molecular Structure and Functional Genomics Section, National Eye Institute, 
NIH, Bethesda, MD 20892.
(2)Retinal Neurophysiology Section, National Eye Institute, NIH, Bethesda, MD 
20892.
(3)Genetic Engineering Core, National Eye Institute, NIH, Bethesda, MD 20892.
(4)Section on Structural Cell Biology, National Institute on Deafness and Other 
Communication Disorders, NIH, Bethesda, MD 20892.
(5)Retinal Cell Biology and Degeneration, National Eye Institute, NIH, Bethesda, 
MD 20892.
(6)Developmental Neural Plasticity Section, National Institute of Neurological 
Disorders and Stroke, NIH, Bethesda, MD 20892.
(7)Laboratory of Molecular Genetics, National Institute on Deafness and Other 
Communication Disorders, NIH, Bethesda, MD 20892.
(8)Visual Function Core, National Eye Institute, NIH, Bethesda, MD 20892.
(9)Retinal Neurophysiology Section, National Eye Institute, NIH, Bethesda, MD 
20892; graeme@helix.nih.gov liwei2@nei.nih.gov dongl@nei.nih.gov.
(10)Molecular Structure and Functional Genomics Section, National Eye Institute, 
NIH, Bethesda, MD 20892; graeme@helix.nih.gov liwei2@nei.nih.gov 
dongl@nei.nih.gov.
(11)Genetic Engineering Core, National Eye Institute, NIH, Bethesda, MD 20892; 
graeme@helix.nih.gov liwei2@nei.nih.gov dongl@nei.nih.gov.

The polycistronic miR-183/96/182 cluster is preferentially and abundantly 
expressed in terminally differentiating sensory epithelia. To clarify its roles 
in the terminal differentiation of sensory receptors in vivo, we deleted the 
entire gene cluster in mouse germline through homologous recombination. The 
miR-183/96/182 null mice display impairment of the visual, auditory, vestibular, 
and olfactory systems, attributable to profound defects in sensory receptor 
terminal differentiation. Maturation of sensory receptor precursors is delayed, 
and they never attain a fully differentiated state. In the retina, delay in 
up-regulation of key photoreceptor genes underlies delayed outer segment 
elongation and possibly mispositioning of cone nuclei in the retina. Incomplete 
maturation of photoreceptors is followed shortly afterward by early-onset 
degeneration. Cell biologic and transcriptome analyses implicate dysregulation 
of ciliogenesis, nuclear translocation, and an epigenetic mechanism that may 
control timing of terminal differentiation in developing photoreceptors. In both 
the organ of Corti and the vestibular organ, impaired terminal differentiation 
manifests as immature stereocilia and kinocilia on the apical surface of hair 
cells. Our study thus establishes a dedicated role of the miR-183/96/182 cluster 
in driving the terminal differentiation of multiple sensory receptor cells.

DOI: 10.1073/pnas.1619442114
PMCID: PMC5448201
PMID: 28484004 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


822. Acta Otolaryngol Suppl. 1996;524:43-9. doi: 10.3109/00016489609124348.

Initial symptoms and retrospective evaluation of prognosis in Menière's disease.

Tokumasu K(1), Fujino A, Naganuma H, Hoshino I, Arai M.

Author information:
(1)Department of Otorhinolaryngology, Kitasato University School of Medicine, 
Kanagawa, Japan.

Clinical studies on an initial symptom and a long-term course of vertigo and 
hearing impairment and retrospective evaluation of the prognosis were performed 
in Menière's disease. One hundred and fifty-one patients (67 males and 84 
females) with Meniere's disease were treated in the Neuro-otological clinic, 
Kitasato University Hospital from 1990 to 1995. Ages ranged from 17 to 77 years 
(mean 47.3 years) at the onset of the disease when the first vertigo attack 
occurred. There were 106 (70.1%) in their 30s, 40s and 50s, and 28 (18.5%) aged 
60 years or over. Seventy-eight patients visited the clinic within one year of 
the onset of the disease, but the mean interval was 4 years and 5 months (the 
longest was 25 years). The mean duration time for the follow-up studies from the 
time of their first visit to the hospital was 2 years and 5 months. The 
bilateral ears were invaded in 19 patients (12.6%) and the mean length of their 
time course was 9 years and 10 months which is longer than the length in 
unilateral cases. Several important key points for diagnosis of Menière's 
disease were investigated in 28 of the 151 cases who had been followed up 
successfully over a relatively long time course (the mean follow-up time was 7 
years and 3 months). Fluctuated or stational cochlear signs, such as tinnitus, 
hearing impairment and/or fullness in the ear, had started prior to the onset of 
the first vertigo attack in 17 (61%) of 28 cases. Vertigo without cochlear sign 
appearing at the onset and cochlear signs were combined later in six (21%) of 
the 28 cases. Only five (18%) of the 28 cases had vertigo combined with a 
cochlear sign simultaneously at the onset of the disease. The affected ear was 
on the left in 15 cases and on the right in seven of 22 unilateral cases. In six 
bilateral cases the left ear was the first to be invaded in four out of six 
cases. The interval between the first and second attacks was over 1 year in six 
of the 28 cases and over 6 months in 10 of the 28 cases. Nine out of the 28 
patients had recurrence of vertigo attacks during the first month and five of 
the nine had a cluster of attacks in the first month. Our study of 28 patients 
over a long time course revealed eight patients (28.6%) free from the disease. 
These patients had no recurrence of vertigo for more than 2 years after their 
last attack, and sixteen (57.1%) of the 28 patients had no recurrence of vertigo 
for more than 1 year. However, a long period of relief time of more than 2 years 
in 11 of the 28 patients and a period of more than 1 year was noticed in 16 of 
the 28 patients. Hearing levels at the middle and low frequencies in the first 
hearing test were compared with the last test. The mean of hearing levels 
changed from 38.1 to 36.2 dB after 2 years and 1 month in six cases with the 
right ear affected and from 34.1 to 45.3 dB after 5 years and 3 months in 15 
cases with the left ear affected, but in seven cases with bilateral diseased 
ears the hearing in both ears became worse, from 25.5 to 57.1 dB in the right 
ear and from 30.5 to 53.6 dB in the left ear during a period of more than 10 
years. These clinical findings should be utilized for diagnosis at the onset of 
Menière's disease to determine the interval for observation in order to evaluate 
the efficacy of treatment.

DOI: 10.3109/00016489609124348
PMID: 8790762 [Indexed for MEDLINE]


823. Sci Transl Med. 2020 Jul 22;12(553):eabb8086. doi: 10.1126/scitranslmed.abb8086.

Multichannel optogenetic stimulation of the auditory pathway using 
microfabricated LED cochlear implants in rodents.

Keppeler D(1)(2), Schwaerzle M(3)(4), Harczos T(1)(5), Jablonski L(1)(5), Dieter 
A(1)(2), Wolf B(1)(5), Ayub S(3)(4), Vogl C(1)(6), Wrobel C(1)(7), Hoch G(1)(5), 
Abdellatif K(1)(5), Jeschke M(1)(5), Rankovic V(1)(5), Paul O(3)(4), Ruther 
P(8)(4), Moser T(9)(2)(5)(6)(10)(11).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany.
(2)Göttingen Graduate Center for Neurosciences and Molecular Biosciences, 
University of Göttingen, 37075 Göttingen, Germany.
(3)University of Freiburg, Department of Microsystems Engineering (IMTEK), 79110 
Freiburg, Germany.
(4)Cluster of Excellence BrainLinks-BrainTools, University of Freiburg, 79110 
Freiburg, Germany.
(5)Auditory Neuroscience and Optogenetics Laboratory, German Primate Center, 
Kellnerweg 4, 37077 Göttingen, Germany.
(6)Collaborative Research Center 889, University of Göttingen, 37075 Göttingen, 
Germany.
(7)Department of Otorhinolaryngology, Head and Neck Surgery, University Medical 
Center Göttingen, 37099 Göttingen, Germany.
(8)University of Freiburg, Department of Microsystems Engineering (IMTEK), 79110 
Freiburg, Germany. ruther@imtek.de tmoser@gwdg.de.
(9)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, 37099 Göttingen, Germany. ruther@imtek.de tmoser@gwdg.de.
(10)Multiscale Bioimaging Cluster of Excellence, University Medical Center 
Göttingen, 37075 Göttingen, Germany.
(11)MPI for Biophysical Chemistry, 37077 Göttingen, Germany.

When hearing fails, electrical cochlear implants (eCIs) provide the brain with 
auditory information. One important bottleneck of CIs is the poor spectral 
selectivity that results from the wide current spread from each of the electrode 
contacts. Optical CIs (oCIs) promise to make better use of the tonotopic order 
of spiral ganglion neurons (SGNs) inside the cochlea by spatially confined 
stimulation. Here, we established multichannel oCIs based on light-emitting 
diode (LED) arrays and used them for optical stimulation of channelrhodopsin 
(ChR)-expressing SGNs in rodents. Power-efficient blue LED chips were integrated 
onto microfabricated 15-μm-thin polyimide-based carriers comprising 
interconnecting lines to address individual LEDs by a stationary or mobile 
driver circuitry. We extensively characterized the optoelectronic, thermal, and 
mechanical properties of the oCIs and demonstrated stability over weeks in 
vitro. We then implanted the oCIs into ChR-expressing rats and gerbils, and 
characterized multichannel optogenetic SGN stimulation by electrophysiological 
and behavioral experiments. Improved spectral selectivity was directly 
demonstrated by recordings from the auditory midbrain. Long-term experiments in 
deafened ChR-expressing rats and in nontreated control animals demonstrated 
specificity of optogenetic stimulation. Behavioral studies on animals carrying a 
wireless oCI sound processor revealed auditory percepts. This study demonstrates 
hearing restoration with improved spectral selectivity by an LED-based 
multichannel oCI system.

Copyright © 2020 The Authors, some rights reserved; exclusive licensee American 
Association for the Advancement of Science. No claim to original U.S. Government 
Works.

DOI: 10.1126/scitranslmed.abb8086
PMCID: PMC7611895
PMID: 32718992 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests: T.M. and D.K. are 
co-founders of the OptoGenTech Company.


824. Sci Rep. 2016 May 23;6:26505. doi: 10.1038/srep26505.

Abnormal topological organization of the white matter network in Mandarin 
speakers with congenital amusia.

Zhao Y(1), Chen X(1), Zhong S(1), Cui Z(1), Gong G(1), Dong Q(1), Nan Y(1).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning &IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, China.

Erratum in
    Sci Rep. 2016 Jul 22;6:30102.

Congenital amusia is a neurogenetic disorder that mainly affects the processing 
of musical pitch. Brain imaging evidence indicates that it is associated with 
abnormal structural and functional connections in the fronto-temporal region. 
However, a holistic understanding of the anatomical topology underlying amusia 
is still lacking. Here, we used probabilistic diffusion tensor imaging 
tractography and graph theory to examine whole brain white matter structural 
connectivity in 31 Mandarin-speaking amusics and 24 age- and IQ-matched 
controls. Amusics showed significantly reduced global connectivity, as indicated 
by the abnormally decreased clustering coefficient (Cp) and increased normalized 
shortest path length (λ) compared to the controls. Moreover, amusics exhibited 
enhanced nodal strength in the right inferior parietal lobule relative to 
controls. The co-existence of the lexical tone deficits was associated with even 
more deteriorated global network efficiency in amusics, as suggested by the 
significant correlation between the increments in normalized shortest path 
length (λ) and the insensitivity in lexical tone perception. Our study is the 
first to reveal reduced global connectivity efficiency in amusics as well as an 
increase in the global connectivity cost due to the co-existed lexical tone 
deficits. Taken together these results provide a holistic perspective on the 
anatomical substrates underlying congenital amusia.

DOI: 10.1038/srep26505
PMCID: PMC4876438
PMID: 27211239 [Indexed for MEDLINE]


825. Nat Commun. 2015 Oct 15;6:8557. doi: 10.1038/ncomms9557.

Single-cell RNA-Seq resolves cellular complexity in sensory organs from the 
neonatal inner ear.

Burns JC(1), Kelly MC(1), Hoa M(1), Morell RJ(2), Kelley MW(1).

Author information:
(1)Laboratory of Cochlear Development, National Institute on Deafness and Other 
Communication Disorders, National Institutes of Health, Bethesda, Maryland 
20892, USA.
(2)Genomics and Computational Biology Core, National Institute on Deafness and 
Other Communication Disorders, National Institutes of Health, Bethesda, Maryland 
20892, USA.

In the inner ear, cochlear and vestibular sensory epithelia utilize grossly 
similar cell types to transduce different stimuli: sound and acceleration. Each 
individual sensory epithelium is composed of highly heterogeneous populations of 
cells based on physiological and anatomical criteria. However, limited numbers 
of each cell type have impeded transcriptional characterization. Here we 
generated transcriptomes for 301 single cells from the utricular and cochlear 
sensory epithelia of newborn mice to circumvent this challenge. Cluster analysis 
indicates distinct profiles for each of the major sensory epithelial cell types, 
as well as less-distinct sub-populations. Asynchrony within utricles allows 
reconstruction of the temporal progression of cell-type-specific differentiation 
and suggests possible plasticity among cells at the sensory-nonsensory boundary. 
Comparisons of cell types from utricles and cochleae demonstrate divergence 
between auditory and vestibular cells, despite a common origin. These results 
provide significant insights into the developmental processes that form unique 
inner ear cell types.

DOI: 10.1038/ncomms9557
PMCID: PMC4634134
PMID: 26469390 [Indexed for MEDLINE]


826. Front Psychol. 2021 Apr 14;12:608684. doi: 10.3389/fpsyg.2021.608684. 
eCollection 2021.

Tracking Musical Voices in Bach's The Art of the Fugue: Timbral Heterogeneity 
Differentially Affects Younger Normal-Hearing Listeners and Older Hearing-Aid 
Users.

Siedenburg K(1), Goldmann K(1), van de Par S(1).

Author information:
(1)Department of Medical Physics and Acoustics and Cluster of Excellence 
Hearing4all, Carl von Ossietzky University of Oldenburg, Oldenburg, Germany.

Auditory scene analysis is an elementary aspect of music perception, yet only 
little research has scrutinized auditory scene analysis under realistic musical 
conditions with diverse samples of listeners. This study probed the ability of 
younger normal-hearing listeners and older hearing-aid users in tracking 
individual musical voices or lines in JS Bach's The Art of the Fugue. 
Five-second excerpts with homogeneous or heterogenous instrumentation of 2-4 
musical voices were presented from spatially separated loudspeakers and preceded 
by a short cue for signaling the target voice. Listeners tracked the cued voice 
and detected whether an amplitude modulation was imposed on the cued voice or a 
distractor voice. Results indicated superior performance of young normal-hearing 
listeners compared to older hearing-aid users. Performance was generally better 
in conditions with fewer voices. For young normal-hearing listeners, there was 
interaction between the number of voices and the instrumentation: performance 
degraded less drastically with an increase in the number of voices for timbrally 
heterogeneous mixtures compared to homogeneous mixtures. Older hearing-aid users 
generally showed smaller effects of the number of voices and instrumentation, 
but no interaction between the two factors. Moreover, tracking performance of 
older hearing aid users did not differ when these participants did or did not 
wear hearing aids. These results shed light on the role of timbral 
differentiation in musical scene analysis and suggest reduced musical scene 
analysis abilities of older hearing-impaired listeners in a realistic musical 
scenario.

Copyright © 2021 Siedenburg, Goldmann and van de Par.

DOI: 10.3389/fpsyg.2021.608684
PMCID: PMC8079728
PMID: 33935864

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


827. J Neural Eng. 2016 Feb;13(1):016011. doi: 10.1088/1741-2560/13/1/016011. Epub 
2015 Dec 14.

Response profiles of murine spiral ganglion neurons on multi-electrode arrays.

Hahnewald S(1), Tscherter A, Marconi E, Streit J, Widmer HR, Garnham C, Benav H, 
Mueller M, Löwenheim H, Roccio M, Senn P.

Author information:
(1)Inner Ear Research Laboratory, University Departments of Clinical Research 
and Otorhinolaryngology, Head & Neck Surgery, Inselspital, University of Bern, 
Switzerland. Regenerative Neuroscience Cluster, Department of Clinical Research, 
University of Bern, Switzerland.

OBJECTIVE: Cochlear implants (CIs) have become the gold standard treatment for 
deafness. These neuroprosthetic devices feature a linear electrode array, 
surgically inserted into the cochlea, and function by directly stimulating the 
auditory neurons located within the spiral ganglion, bypassing lost or 
not-functioning hair cells. Despite their success, some limitations still 
remain, including poor frequency resolution and high-energy consumption. In both 
cases, the anatomical gap between the electrode array and the spiral ganglion 
neurons (SGNs) is believed to be an important limiting factor. The final goal of 
the study is to characterize response profiles of SGNs growing in intimate 
contact with an electrode array, in view of designing novel CI devices and 
stimulation protocols, featuring a gapless interface with auditory neurons.
APPROACH: We have characterized SGN responses to extracellular stimulation using 
multi-electrode arrays (MEAs). This setup allows, in our view, to optimize in 
vitro many of the limiting interface aspects between CIs and SGNs.
MAIN RESULTS: Early postnatal mouse SGN explants were analyzed after 6-18 days 
in culture. Different stimulation protocols were compared with the aim to lower 
the stimulation threshold and the energy needed to elicit a response. In the 
best case, a four-fold reduction of the energy was obtained by lengthening the 
biphasic stimulus from 40 μs to 160 μs. Similarly, quasi monophasic pulses were 
more effective than biphasic pulses and the insertion of an interphase gap 
moderately improved efficiency. Finally, the stimulation with an external 
electrode mounted on a micromanipulator showed that the energy needed to elicit 
a response could be reduced by a factor of five with decreasing its distance 
from 40 μm to 0 μm from the auditory neurons.
SIGNIFICANCE: This study is the first to show electrical activity of SGNs on 
MEAs. Our findings may help to improve stimulation by and to reduce energy 
consumption of CIs and thereby contribute to the development of fully 
implantable devices with better auditory resolution in the future.

DOI: 10.1088/1741-2560/13/1/016011
PMID: 26656212 [Indexed for MEDLINE]


828. Front Mol Neurosci. 2023 Dec 12;16:1299509. doi: 10.3389/fnmol.2023.1299509. 
eCollection 2023.

Probing the role of the C(2)F domain of otoferlin.

Chen H(1)(2)(3)(4), Fang Q(1)(2)(3), Benseler F(5), Brose N(2)(5)(6), Moser 
T(1)(2)(3)(6).

Author information:
(1)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(2)Collaborative Research Center 889, University of Göttingen, Göttingen, 
Germany.
(3)Auditory Neuroscience and Synaptic Nanophysiology Group, Max Planck Institute 
for Multidisciplinary Sciences, Göttingen, Germany.
(4)Göttingen Graduate Center for Neurosciences, Biophysics and Molecular 
Biosciences, University of Göttingen, Göttingen, Germany.
(5)Department of Molecular Neurobiology, Max Planck Institute for 
Multidisciplinary Sciences, Göttingen, Germany.
(6)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
Göttingen, Germany.

Afferent synapses of cochlear inner hair cells (IHCs) employ a unique molecular 
machinery. Otoferlin is a key player in this machinery, and its genetic defects 
cause human auditory synaptopathy. We employed site-directed mutagenesis in mice 
to investigate the role of Ca2+ binding to the C2F domain of otoferlin. 
Substituting two aspartate residues of the C2F top loops, which are thought to 
coordinate Ca2+-ions, by alanines (OtofD1841/1842A) abolished 
Ca2+-influx-triggered IHC exocytosis and synchronous signaling in the auditory 
pathway despite substantial expression (~60%) of the mutant otoferlin in the 
basolateral IHC pole. Ca2+ influx of IHCs and their resting membrane 
capacitance, reflecting IHC size, as well as the number of IHC synapses were 
maintained. The mutant otoferlin showed a strong apex-to-base abundance gradient 
in IHCs, suggesting impaired protein targeting. Our results indicate a role of 
the C2F domain in otoferlin targeting and of Ca2+ binding by the C2F domain for 
IHC exocytosis and hearing.

Copyright © 2023 Chen, Fang, Benseler, Brose and Moser.

DOI: 10.3389/fnmol.2023.1299509
PMCID: PMC10751786
PMID: 38152587

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


829. Nat Neurosci. 2004 Dec;7(12):1310-8. doi: 10.1038/nn1349. Epub 2004 Nov 7.

Math1 regulates development of the sensory epithelium in the mammalian cochlea.

Woods C(1), Montcouquiol M, Kelley MW.

Author information:
(1)Section on Developmental Neuroscience, National Institute on Deafness and 
other Communication Disorders, National Institutes of Health, Porter 
Neuroscience Research Center, Building 35, Bethesda, Maryland 20892, USA.

The transcription factor Math1 (encoded by the gene Atoh1, also called Math1) is 
required for the formation of mechanosensory hair cells in the inner ear; 
however, its specific molecular role is unknown. Here we show that absence of 
Math1 in mice results in a complete disruption of formation of the sensory 
epithelium of the cochlea, including the development of both hair cells and 
associated supporting cells. In addition, ectopic expression of Math1 in 
nonsensory regions of the cochlea is sufficient to induce the formation of 
sensory clusters that contain both hair cells and supporting cells. The 
formation of these clusters is dependent on inhibitory interactions mediated, 
most probably, through the Notch pathway, and on inductive interactions that 
recruit cells to develop as supporting cells through a pathway independent of 
Math1. These results show that Math1 functions in the developing cochlea to 
initiate both inductive and inhibitory signals that regulate the overall 
formation of the sensory epithelia.

DOI: 10.1038/nn1349
PMID: 15543141 [Indexed for MEDLINE]


830. Front Neurosci. 2020 May 27;14:541. doi: 10.3389/fnins.2020.00541. eCollection 
2020.

Altered Topological Patterns of Gray Matter Networks in Tinnitus: A 
Graph-Theoretical-Based Study.

Lin X(1)(2), Chen Y(3), Wang M(4), Song C(5), Lin B(6), Yuan X(5), Liu Q(5), 
Yang H(7), Jiang N(1)(2).

Author information:
(1)Department of Nuclear Medicine, Sun Yat-sen Memorial Hospital, Sun Yat-sen 
University, Guangzhou, China.
(2)Department of Nuclear Medicine, The Seventh Affiliated Hospital, Sun Yat-sen 
University, Shenzhen, China.
(3)Department of Radiology, Shenzhen Traditional Chinese Medicine Hospital, 
Shenzhen, China.
(4)Department of Hearing and Speech Sciences, Xinhua College of Sun Yat-sen 
University, Guangzhou, China.
(5)Department of Radiology, Sun Yat-sen Memorial Hospital, Sun Yat-sen 
University, Guangzhou, China.
(6)Department of Radiology, Peking University Shen Zhen Hospital, Shenzhen, 
China.
(7)Department of Otolaryngology, Sun Yat-sen Memorial Hospital, Sun Yat-sen 
University, Guangzhou, China.

OBJECTIVE: Tinnitus is a prevalent hearing disorder, which could have a 
devastating impact on a patient's life. Functional studies have revealed 
connectivity pattern changes in the tinnitus brains that suggested a change of 
network dynamics as well as topological organization. However, no studies have 
yet provided evidence for the topological network changes in the gray matter. In 
this research, we aim to use the graph-theoretical approach to investigate the 
changes of topology in the tinnitus brain using structural MRI data, which could 
provide insights into the underlying anatomical basis for the neural mechanism 
in generating phantom sounds.
METHODS: We collected 3D MRI images on 46 bilateral tinnitus patients and 46 age 
and gender-matched healthy controls. Brain networks were constructed with 
correlation matrices of the cortical thickness and subcortical volumes of 80 
cortical/subcortical regions of interests. Global network properties were 
analyzed using local and global efficiency, clustering coefficient, and 
small-world coefficient, and regional network properties were evaluated using 
the betweenness coefficient for hub connectivity, and interregional correlations 
for edge properties. Between-group differences in cortical thickness and 
subcortical volumes were assessed using independent sample t-tests, and local 
efficiency, global efficiency, clustering coefficient, sigma, and interregional 
correlation were compared using non-parametric permutation tests.
RESULTS: Tinnitus was found to have increased global efficiency, local 
efficiency, and cluster coefficient, indicating generally heightened 
connectivity of the network. The small-world coefficient remained normal for 
tinnitus, indicating intact small-worldness. Betweenness centrality analysis 
showed that hubs in the amygdala and parahippocampus were only found for 
tinnitus but not controls. In contrast, hubs in the auditory cortex, insula, and 
thalamus were only found for controls but not tinnitus. Interregional 
correlation analysis further found in tinnitus enhanced connectivity between the 
auditory cortex and prefrontal lobe, and decreased connectivity of the insula 
with anterior cingulate gyrus and parahippocampus.
CONCLUSION: These findings provided the first morphological evidence of altered 
topological organization of the brain networks in tinnitus. These alterations 
suggest that heightened efficiency of the brain network and altered 
auditory-limbic connection for tinnitus, which could be developed in 
compensation for the auditory deafferentation, leading to overcompensation and, 
ultimately, an emotional and cognitive burden.

Copyright © 2020 Lin, Chen, Wang, Song, Lin, Yuan, Liu, Yang and Jiang.

DOI: 10.3389/fnins.2020.00541
PMCID: PMC7267018
PMID: 32536854


831. Front Hum Neurosci. 2015 Feb 6;9:7. doi: 10.3389/fnhum.2015.00007. eCollection 
2015.

Brain responses to musical feature changes in adolescent cochlear implant users.

Petersen B(1), Weed E(2), Sandmann P(3), Brattico E(4), Hansen M(5), Sørensen 
SD(6), Vuust P(1).

Author information:
(1)Center for Functionally Integrative Neuroscience, Aarhus University Hospital 
, Aarhus , Denmark ; Royal Academy of Music , Aarhus , Denmark.
(2)Center for Functionally Integrative Neuroscience, Aarhus University Hospital 
, Aarhus , Denmark ; Department of Aesthetics and Communication - Linguistics, 
Aarhus University , Aarhus , Denmark.
(3)Central Auditory Diagnostics Lab, Department of Neurology, Cluster of 
Excellence "Hearing4all", Hannover Medical School , Hannover , Germany.
(4)Brain and Mind Laboratory, Department of Biomedical Engineering and 
Computational Science, Aalto University , Aalto , Finland ; Cognitive Brain 
Research Unit, Institute of Behavioral Sciences, University of Helsinki , 
Helsinki , Finland.
(5)Center for Functionally Integrative Neuroscience, Aarhus University Hospital 
, Aarhus , Denmark ; Department of Psychology and Behavioural Sciences, Aarhus 
University , Aarhus , Denmark.
(6)Department of Aesthetics and Communication - Linguistics, Aarhus University , 
Aarhus , Denmark.

Cochlear implants (CIs) are primarily designed to assist deaf individuals in 
perception of speech, although possibilities for music fruition have also been 
documented. Previous studies have indicated the existence of neural correlates 
of residual music skills in postlingually deaf adults and children. However, 
little is known about the behavioral and neural correlates of music perception 
in the new generation of prelingually deaf adolescents who grew up with CIs. 
With electroencephalography (EEG), we recorded the mismatch negativity (MMN) of 
the auditory event-related potential to changes in musical features in 
adolescent CI users and in normal-hearing (NH) age mates. EEG recordings and 
behavioral testing were carried out before (T1) and after (T2) a 2-week music 
training program for the CI users and in two sessions equally separated in time 
for NH controls. We found significant MMNs in adolescent CI users for deviations 
in timbre, intensity, and rhythm, indicating residual neural prerequisites for 
musical feature processing. By contrast, only one of the two pitch deviants 
elicited an MMN in CI users. This pitch discrimination deficit was supported by 
behavioral measures, in which CI users scored significantly below the NH level. 
Overall, MMN amplitudes were significantly smaller in CI users than in NH 
controls, suggesting poorer music discrimination ability. Despite compliance 
from the CI participants, we found no effect of the music training, likely 
resulting from the brevity of the program. This is the first study showing 
significant brain responses to musical feature changes in prelingually deaf 
adolescent CI users and their associations with behavioral measures, implying 
neural predispositions for at least some aspects of music processing. Future 
studies should test any beneficial effects of a longer lasting music 
intervention in adolescent CI users.

DOI: 10.3389/fnhum.2015.00007
PMCID: PMC4319402
PMID: 25705185


832. Antioxidants (Basel). 2022 Sep 6;11(9):1759. doi: 10.3390/antiox11091759.

Kanamycin and Cisplatin Ototoxicity: Differences in Patterns of Oxidative 
Stress, Antioxidant Enzyme Expression and Hair Cell Loss in the Cochlea.

Gibaja A(1), Alvarado JC(1), Scheper V(2)(3), Carles L(4), Juiz JM(1)(2)(3)(5).

Author information:
(1)Instituto de Investigación en Discapacidades Neurológicas (IDINE), School of 
Medicine, Universidad de Castilla-La Mancha (UCLM), Campus in Albacete, 02008 
Albacete, Spain.
(2)Department of Otorhinolaryngology, Head and Neck Surgery, Hannover Medical 
School, 30625 Hannover, Germany.
(3)Cluster of Excellence "Hearing4all" of the German Research Foundation, DFG, 
MHH, 30625 Hannover, Germany.
(4)Department of Otolaryngology, University Hospital "Doce de Octubre", 28041 
Madrid, Spain.
(5)IDINE/Med School, UCLM-Campus in Albacete, C/Almansa 14, 02008 Albacete, 
Spain.

Kanamycin and cisplatin are ototoxic drugs. The mechanisms are incompletely 
known. With subcutaneous kanamycin (400 mg/kg, 15 days), auditory threshold 
shifts were detected at days 12-13 at 16 and 32 kHz, extending to 8 and 4 kHz at 
days 14-15. The outer hair cell (OHC) loss was concentrated past day 12. The 
maximum cochlear length showing apoptotic cells, tested with TUNEL, was at day 
13. At day 15, 1/5 of the apical cochlea contained preserved OHCs. 
3-nitrotyrosine (3-NT) immunolabeling, showing oxidative stress, was found in 
surviving OHCs and in basal and middle portions of the stria vascularis (SV). 
The antioxidant Gpx1 gene expression was decreased. The immunocytochemistry 
showed diminished Gpx1 in OHCs. With intraperitoneal cisplatin (16 mg/kg, single 
injection), no evoked auditory activity was recorded at the end of treatment, at 
72 h. The basal third of the cochlea lacked OHCs. Apoptosis occupied the 
adjacent 1/3, and the apical third contained preserved OHCs. 3-NT immunolabeling 
was extensive in OHCs and the SV. Gpx1 and Sod1 gene expression was 
downregulated. Gpx1 immunostaining diminished in middle and basal SV. More OHCs 
survived cisplatin than kanamycin towards the apex, despite undetectable evoked 
activity. Differential regulation of antioxidant enzyme levels suggests 
differences in the antioxidant response for both drugs.

DOI: 10.3390/antiox11091759
PMCID: PMC9495324
PMID: 36139833

Conflict of interest statement: The authors have no relevant affiliation or 
involvement with any organization or entity with a financial interest in or 
financial conflict with the subject matter, materials, or data in the present 
study.


833. Genes Dev. 2023 Dec 26;37(21-24):1041-1051. doi: 10.1101/gad.351052.123.

A nonneural miRNA cluster mediates hearing via repression of two neural targets.

Zhang B(1), Duan H(1), Kavaler J(2), Wei L(1), Eberl DF(3), Lai EC(4).

Author information:
(1)Developmental Biology Program, Sloan Kettering Institute, New York, New York 
10065, USA.
(2)Department of Biology, Colby College, Waterville, Maine 04901, USA.
(3)Department of Biology, University of Iowa, Iowa City, Iowa 52242, USA.
(4)Developmental Biology Program, Sloan Kettering Institute, New York, New York 
10065, USA; laie@mskcc.org.

We show here that mir-279/996 are absolutely essential for development and 
function of Johnston's organ (JO), the primary proprioceptive and auditory organ 
in Drosophila Their deletion results in highly aberrant cell fate determination, 
including loss of scolopale cells and ectopic neurons, and mutants are 
electrophysiologically deaf. In vivo activity sensors and mosaic analyses 
indicate that these seed-related miRNAs function autonomously to suppress neural 
fate in nonneuronal cells. Finally, genetic interactions pinpoint two neural 
targets (elav and insensible) that underlie miRNA mutant JO phenotypes. This 
work uncovers how critical post-transcriptional regulation of specific miRNA 
targets governs cell specification and function of the auditory system.

© 2023 Zhang et al.; Published by Cold Spring Harbor Laboratory Press.

DOI: 10.1101/gad.351052.123
PMCID: PMC10760640
PMID: 38110249 [Indexed for MEDLINE]


834. Front Mol Neurosci. 2021 Aug 19;14:689415. doi: 10.3389/fnmol.2021.689415. 
eCollection 2021.

Cabp2-Gene Therapy Restores Inner Hair Cell Calcium Currents and Improves 
Hearing in a DFNB93 Mouse Model.

Oestreicher D(1)(2), Picher MM(3), Rankovic V(3)(4), Moser T(2)(3)(5)(6), 
Pangrsic T(1)(2)(5)(6).

Author information:
(1)Experimental Otology Group, InnerEarLab, Department of Otolaryngology, 
University Medical Center Göttingen, Göttingen, Germany.
(2)Auditory Neuroscience Group, Max Planck Institute of Experimental Medicine, 
Göttingen, Germany.
(3)Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(4)Restorative Cochlear Genomics Group, Auditory Neuroscience and Optogenetics 
Laboratory, German Primate Center, Göttingen, Germany.
(5)Collaborative Research Center 889, University of Göttingen, Göttingen, 
Germany.
(6)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
Göttingen, Germany.

Clinical management of auditory synaptopathies like other genetic hearing 
disorders is currently limited to the use of hearing aids or cochlear implants. 
However, future gene therapy promises restoration of hearing in selected forms 
of monogenic hearing impairment, in which cochlear morphology is preserved over 
a time window that enables intervention. This includes non-syndromic autosomal 
recessive hearing impairment DFNB93, caused by defects in the CABP2 gene. 
Calcium-binding protein 2 (CaBP2) is a potent modulator of inner hair cell (IHC) 
voltage-gated calcium channels CaV1.3. Based on disease modeling in Cabp2-/- 
mice, DFNB93 hearing impairment has been ascribed to enhanced steady-state 
inactivation of IHC CaV1.3 channels, effectively limiting their availability to 
trigger synaptic transmission. This, however, does not seem to interfere with 
cochlear development and does not cause early degeneration of hair cells or 
their synapses. Here, we studied the potential of a gene therapeutic approach 
for the treatment of DFNB93. We used AAV2/1 and AAV-PHP.eB viral vectors to 
deliver the Cabp2 coding sequence into IHCs of early postnatal Cabp2-/- mice and 
assessed the level of restoration of hair cell function and hearing. Combining 
in vitro and in vivo approaches, we observed high transduction efficiency, and 
restoration of IHC CaV1.3 function resulting in improved hearing of Cabp2-/- 
mice. These preclinical results prove the feasibility of DFNB93 gene therapy.

Copyright © 2021 Oestreicher, Picher, Rankovic, Moser and Pangrsic.

DOI: 10.3389/fnmol.2021.689415
PMCID: PMC8417311
PMID: 34489639

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


835. Brain Sci. 2020 Aug 15;10(8):559. doi: 10.3390/brainsci10080559.

Consecutive Treatment with Brain-Derived Neurotrophic Factor and Electrical 
Stimulation Has a Protective Effect on Primary Auditory Neurons.

Scheper V(1)(2), Seidel-Effenberg I(1), Lenarz T(1)(2), Stöver T(1)(3), Paasche 
G(1)(2).

Author information:
(1)Department of Otorhinolaryngology, Hannover Medical School, Carl-Neuberg-Str. 
1, 30625 Hannover, Germany.
(2)Hearing4all Cluster of Excellence, Hannover Medical School, Carl-Neuberg-Str. 
1, 30625 Hannover, Germany.
(3)Department of Otorhinolaryngology, Johann Wolfgang Goethe-University, 
Theodor-Stern-Kai 7, 60590 Frankfurt am Main, Germany.

Degeneration of neurons, such as the inner ear spiral ganglion neurons (SGN), 
may be decelerated or even stopped by neurotrophic factor treatment, such as 
brain-derived neurotrophic factor (BDNF), as well as electrical stimulation 
(ES). In a clinical setting, drug treatment of the SGN could start directly 
during implantation of a cochlear implant, whereas electrical stimulation begins 
days to weeks later. The present study was conducted to determine the effects of 
consecutive BDNF and ES treatments on SGN density and electrical responsiveness. 
An electrode drug delivery device was implanted in guinea pigs 3 weeks after 
deafening and five experimental groups were established: two groups received 
intracochlear infusion of artificial perilymph (AP) or BDNF; two groups were 
treated with AP respectively BDNF in addition to ES (AP + ES, BDNF + ES); and 
one group received BDNF from the day of implantation until day 34 followed by ES 
(BDNF ⇨ ES). Electrically evoked auditory brainstem responses were recorded. 
After one month of treatment, the tissue was harvested and the SGN density was 
assessed. The results show that consecutive treatment with BDNF and ES was as 
successful as the simultaneous combined treatment in terms of enhanced SGN 
density compared to the untreated contralateral side but not in regard to the 
numbers of protected cells.

DOI: 10.3390/brainsci10080559
PMCID: PMC7464901
PMID: 32824176

Conflict of interest statement: The authors declare no conflict of interest.


836. Philos Trans R Soc Lond B Biol Sci. 2015 Mar 19;370(1664):20140092. doi: 
10.1098/rstb.2014.0092.

Defining the biological bases of individual differences in musicality.

Gingras B(1), Honing H(2), Peretz I(3), Trainor LJ(4), Fisher SE(5).

Author information:
(1)Department of Cognitive Biology, University of Vienna, Vienna, Austria.
(2)Amsterdam Brain and Cognition (ABC), Institute of Logic, Language and 
Computation (ILLC), University of Amsterdam, Amsterdam, The Netherlands.
(3)International Laboratory for Brain, Music and Sound Research, Department of 
Psychology, University of Montreal, Quebec, Canada.
(4)Department of Psychology, Neuroscience and Behaviour, McMaster University, 
Ontario, Canada.
(5)Language and Genetics Department, Max Planck Institute for Psycholinguistics, 
Nijmegen, The Netherlands Donders Institute for Brain, Cognition and Behaviour, 
Radboud University, Nijmegen, The Netherlands simon.fisher@mpi.nl.

Advances in molecular technologies make it possible to pinpoint genomic factors 
associated with complex human traits. For cognition and behaviour, 
identification of underlying genes provides new entry points for deciphering the 
key neurobiological pathways. In the past decade, the search for genetic 
correlates of musicality has gained traction. Reports have documented familial 
clustering for different extremes of ability, including amusia and absolute 
pitch (AP), with twin studies demonstrating high heritability for some 
music-related skills, such as pitch perception. Certain chromosomal regions have 
been linked to AP and musical aptitude, while individual candidate genes have 
been investigated in relation to aptitude and creativity. Most recently, 
researchers in this field started performing genome-wide association scans. Thus 
far, studies have been hampered by relatively small sample sizes and limitations 
in defining components of musicality, including an emphasis on skills that can 
only be assessed in trained musicians. With opportunities to administer 
standardized aptitude tests online, systematic large-scale assessment of musical 
abilities is now feasible, an important step towards high-powered genome-wide 
screens. Here, we offer a synthesis of existing literatures and outline concrete 
suggestions for the development of comprehensive operational tools for the 
analysis of musical phenotypes.

© 2015 The Author(s) Published by the Royal Society. All rights reserved.

DOI: 10.1098/rstb.2014.0092
PMCID: PMC4321133
PMID: 25646515 [Indexed for MEDLINE]


837. BMJ Open. 2017 Oct 11;7(10):e016457. doi: 10.1136/bmjopen-2017-016457.

Feasibility and acceptability of training community health workers in ear and 
hearing care in Malawi: a cluster randomised controlled trial.

Mulwafu W(1), Kuper H(2), Viste A(3), Goplen FK(3).

Author information:
(1)Department of Surgery, College of Medicine Blantyre Malawi, Blantyre, Malawi.
(2)Department of Clinical Research, The London School of Hygiene & Tropical 
Medicine, London, UK.
(3)Haukeland Universitetssjukehus, Bergen, Norway.

OBJECTIVE: To assess the feasibility and acceptability of training community 
health workers (CHWs) in ear and hearing care, and their ability to identify 
patients with ear and hearing disorders.
DESIGN: Cluster randomised controlled trial (RCT).
SETTING: Health centres in Thyolo district, Malawi.
PARTICIPANTS: Ten health centres participated, 5 intervention (29 CHWs) and 5 
control (28 CHWs).
INTERVENTION: Intervention CHWs received 3 days of training in primary ear and 
hearing care, while among control CHWs, training was delayed for 6 months. Both 
groups were given a pretest that assessed knowledge about ear and hearing care, 
only the intervention group was given the posttest on the third day of training. 
The intervention group was given 1 month to identify patients with ear and 
hearing disorders in their communities, and these people were screened for 
hearing disorders by ear, nose and throat clinical specialists.
OUTCOME MEASURES: Primary outcome measure was improvement in knowledge of ear 
and hearing care among CHWs after the training. Secondary outcome measures were 
number of patients with ear or hearing disorders identified by CHWs and number 
recorded at health centres during routine activities, and the perceived 
feasibility and acceptability of the intervention.
RESULTS: The average overall correct answers increased from 55% to 68% (95% CI 
65 to 71) in the intervention group (p<0.001). A total of 1739 patients with 
potential ear and hearing disorders were identified by CHWs and 860 patients 
attended the screening camps, of whom 400 had hearing loss (73 patients 
determined through bilateral fail on otoacoustic emissions, 327 patients through 
audiometry). Where cause could be determined, the most common cause of ear and 
hearing disorders was chronic suppurative otitis media followed by impacted wax. 
The intervention was perceived as feasible and acceptable to implement.
CONCLUSIONS: Training was effective in improving the knowledge of CHW in ear and 
hearing care in Malawi and allowing them to identify patients with ear and 
hearing disorders. This intervention could be scaled up to other CHWs in 
low-income and middle-income countries.
TRIAL REGISTRATION NUMBER: Pan African Clinical Trial Registry 
(201705002285194); Results.

© Article author(s) (or their employer(s) unless otherwise stated in the text of 
the article) 2017. All rights reserved. No commercial use is permitted unless 
otherwise expressly granted.

DOI: 10.1136/bmjopen-2017-016457
PMCID: PMC5652500
PMID: 29025832 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests: None declared.


838. iScience. 2023 Dec 8;27(1):108700. doi: 10.1016/j.isci.2023.108700. eCollection 
2024 Jan 19.

Developmental changes of the mitochondria in the murine anteroventral cochlear 
nucleus.

Hintze A(1), Lange F(2)(3), Steyer AM(4)(5), Anstatt J(2)(3), Möbius W(4)(5), 
Jakobs S(2)(3)(4)(6), Wichmann C(1)(4).

Author information:
(1)Molecular Architecture of Synapses Group, Institute for Auditory 
Neuroscience, InnerEarLab and Center for Biostructural Imaging of 
Neurodegeneration, University Medical Center Göttingen, 37075 Göttingen, 
Germany.
(2)Department of NanoBiophotonics, Max Planck Institute for Multidisciplinary 
Sciences, 37077 Göttingen, Germany.
(3)Clinic of Neurology, University Medical Center Göttingen, 37075 Göttingen, 
Germany.
(4)Multiscale Bioimaging Cluster of Excellence (MBExC), University of Göttingen, 
37075 Göttingen, Germany.
(5)Electron Microscopy-City Campus, Department of Neurogenetics, Max Planck 
Institute for Multidisciplinary Sciences, 37075 Göttingen, Germany.
(6)Translational Neuroinflammation and Automated Microscopy, Fraunhofer 
Institute for Translational Medicine and Pharmacology ITMP, Göttingen, Germany.

Mitochondria are key organelles to provide ATP for synaptic transmission. This 
study aims to unravel the structural adaptation of mitochondria to an increase 
in presynaptic energy demand and upon the functional impairment of the auditory 
system. We use the anteroventral cochlear nucleus (AVCN) of wild-type and 
congenital deaf mice before and after hearing onset as a model system for 
presynaptic states of lower and higher energy demands. We combine focused ion 
beam scanning electron microscopy and electron tomography to investigate 
mitochondrial morphology. We found a larger volume of synaptic boutons and 
mitochondria after hearing onset with a higher crista membrane density. In deaf 
animals lacking otoferlin, we observed a shallow increase of mitochondrial 
volumes toward adulthood in endbulbs, while in wild-type animals mitochondria 
further enlarged. We propose that in the AVCN, presynaptic mitochondria undergo 
major structural changes likely to serve higher energy demands upon the onset of 
hearing and further maturation.

© 2023 The Author(s).

DOI: 10.1016/j.isci.2023.108700
PMCID: PMC10783593
PMID: 38213623

Conflict of interest statement: The authors declare no conflict of interest.


839. Front Neurosci. 2023 Jan 4;16:1021541. doi: 10.3389/fnins.2022.1021541. 
eCollection 2022.

Temporal hyper-precision of brainstem neurons alters spatial sensitivity of 
binaural auditory processing with cochlear implants.

Müller M(1), Hu H(2)(3), Dietz M(2)(3), Beiderbeck B(1), Ferreiro DN(4)(5), 
Pecka M(1)(4).

Author information:
(1)Graduate School of Systemic Neurosciences, Ludwig-Maximilians-Universität, 
Munich, Germany.
(2)Department of Medical Physics and Acoustics, Carl von Ossietzky University of 
Oldenburg, Oldenburg, Germany.
(3)Cluster of Excellence "Hearing4All", Universität Oldenburg, Oldenburg, 
Germany.
(4)Section of Neurobiology, Faculty of Biology, LMU Biocenter, 
Ludwig-Maximilians-Universität, Munich, Germany.
(5)Department of General Psychology and Education, 
Ludwig-Maximilians-Universität, Munich, Germany.

The ability to localize a sound source in complex environments is essential for 
communication and navigation. Spatial hearing relies predominantly on the 
comparison of differences in the arrival time of sound between the two ears, the 
interaural time differences (ITDs). Hearing impairments are highly detrimental 
to sound localization. While cochlear implants (CIs) have been successful in 
restoring many crucial hearing capabilities, sound localization via ITD 
detection with bilateral CIs remains poor. The underlying reasons are not well 
understood. Neuronally, ITD sensitivity is generated by coincidence detection 
between excitatory and inhibitory inputs from the two ears performed by 
specialized brainstem neurons. Due to the lack of electrophysiological brainstem 
recordings during CI stimulation, it is unclear to what extent the apparent 
deficits are caused by the binaural comparator neurons or arise already on the 
input level. Here, we use a bottom-up approach to compare response features 
between electric and acoustic stimulation in an animal model of CI hearing. 
Conducting extracellular single neuron recordings in gerbils, we find severe 
hyper-precision and moderate hyper-entrainment of both the excitatory and 
inhibitory brainstem inputs to the binaural comparator neurons during electrical 
pulse-train stimulation. This finding establishes conclusively that the binaural 
processing stage must cope with highly altered input statistics during CI 
stimulation. To estimate the consequences of these effects on ITD sensitivity, 
we used a computational model of the auditory brainstem. After tuning the model 
parameters to match its response properties to our physiological data during 
either stimulation type, the model predicted that ITD sensitivity to electrical 
pulses is maintained even for the hyper-precise inputs. However, the model 
exhibits severely altered spatial sensitivity during electrical stimulation 
compared to acoustic: while resolution of ITDs near midline was increased, more 
lateralized adjacent source locations became inseparable. These results directly 
resemble recent findings in rodent and human CI listeners. Notably, decreasing 
the phase-locking precision of inputs during electrical stimulation recovered a 
wider range of separable ITDs. Together, our findings suggest that a central 
problem underlying the diminished ITD sensitivity in CI users might be the 
temporal hyper-precision of inputs to the binaural comparator stage induced by 
electrical stimulation.

Copyright © 2023 Müller, Hu, Dietz, Beiderbeck, Ferreiro and Pecka.

DOI: 10.3389/fnins.2022.1021541
PMCID: PMC9846145
PMID: 36685222

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


840. Data Brief. 2023 May 11;48:109205. doi: 10.1016/j.dib.2023.109205. eCollection 
2023 Jun.

Database description: Russian fricatives recorded in 198 real speech sentences 
from 59 speakers.

Ulrich N(1).

Author information:
(1)Lab Dynamics of Language UMR 5596, CNRS and University Lyon 2, France.

This speech dataset is primarily designed to investigate linguistic and speaker 
information in fricative sounds in Russian. Acoustic recordings were obtained 
from 59 students (30 females and 29 males) between 18 and 30 years. Eighteen 
participants were recorded in a second session. The participants were born and 
lived since their early childhood in St. Petersburg. The participants did not 
report any speech or hearing impairment. The recording sessions were conducted 
at the phonetic laboratory of the Phonetic Institute in St. Petersburg, in an 
audiometric booth using the recording program Speech-Recorder version 3.28.0 at 
a sample rate of 44.1 kHz (16-bit encoding). During the recordings, a clip-on 
microphone (Sennheiser MKE 2-P) was placed at a distance of 15cm from the 
speakers' mouth and connected through an audio interface (Zoom U-22) to a laptop 
computer. The participants were instructed to read 198 randomized sentences from 
a computer screen. The fricatives [f], [s], [ʃ], [x], [v], [z], [ʒ], [sʲ], [ɕ], 
[vʲ], [zʲ] were embedded into those sentences. Two sentence structures were 
designed to obtain each real-word lexemes produced in three different contexts. 
The first type of sentence is a so-called carrier sentence with the structure of 
"She said "X" and not "Y" ". Minimal pairs of real words, containing one of the 
11 tested fricatives were placed in both "X" and "Y" positions. The second type 
of pre-designed sentence was a natural language sentence including each of the 
lexemes. All raw audio files were first automatically pre-processed by applying 
the online tool Munich Automatic Segmentation system. Then, the files of the 
first recording session were filtered below 80 and above 20050 Hz, and the 
boundaries were manually corrected using Praat. The dataset consists of 22,561 
fricative tokens. The number of observations per sound differs across 
categories, because of their natural distribution. The dataset is made available 
as a collection of audio files in wav format along with companion Praat TextGrid 
files for each sentence. Target fricatives are furthermore available as 
individual wav files. The whole dataset can be accessed with the DOI 
https://doi.org/10.48656/4q9c-gz16. Additionally, the experimental design allows 
the investigation of other sound categories. The number of speakers recorded 
gives further possibilities for phonetic-oriented speaker identification 
studies.

© 2023 The Author(s).

DOI: 10.1016/j.dib.2023.109205
PMCID: PMC10293980
PMID: 37383770

Conflict of interest statement: The authors declare that they have no known 
competing financial interests or personal relationships that could have appeared 
to influence the work reported in this paper.


841. Headache. 1990 Jun;30(7):401-6. doi: 10.1111/j.1526-4610.1990.hed3007401.x.

Chronic cluster headache managed by nervus intermedius section.

Rowed DW(1).

Author information:
(1)Sunnybrook Health Sciences Centre, University of Toronto, Ontario, Canada.

Cluster headache sufferers who become candidates for surgical treatment are 
those relatively rare patients who are refractory to all attempts at 
pharmacological relief. Ablative surgical procedures have been directed against 
either the trigeminal nerve or the nervus intermedius/greater superficial 
petrosal (NI/GSP) pathway. Both carry nociceptive impulses from the head and 
face, and the NI also carries parasympathetic fibres which appear to be 
responsible for the autonomic concomitants of cluster headache. Trigeminal 
operative procedures are not consistently helpful in chronic cluster headache, 
while NI section has been shown to give potentially long lasting relief but 
carries the potential risks of cerebellopontine angle surgery. In eight selected 
cases of chronic cluster headache we have demonstrated a high early success rate 
for pain relief, with few complications, in the performance of NI section, 
combined, when indicated, with microvascular decompression of the trigeminal 
main sensory root. We believe that cochlear nerve monitoring helps prevent 
postoperative hearing impairment. An intimate relationship between the NI and 
arterial loops of the anterior inferior cerebellar artery (AICA) or the internal 
auditory artery has been frequently observed in our chronic cluster headache 
patients.

DOI: 10.1111/j.1526-4610.1990.hed3007401.x
PMID: 2401621 [Indexed for MEDLINE]


842. Biostatistics. 2022 Oct 14;23(4):1056-1073. doi: 10.1093/biostatistics/kxac027.

Marginal structural models for multilevel clustered data.

Wu Y(1), Langworthy B(2), Wang M(3).

Author information:
(1)Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
Boston, MA 02215, USA.
(2)Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
Boston, MA 02215, USA and Department of Epidemiology, Harvard T.H. Chan School 
of Public Health, Boston, MA 02215, USA.
(3)Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
Boston, MA 02215, USA, Department of Epidemiology, Harvard T.H. Chan School of 
Public Health, Boston, MA 02215, USA, and Channing Division of Network Medicine, 
Department of Medicine, Brigham and Women's Hospital, Boston, MA, 02215, USA and 
Harvard Medical School, Boston, MA 02115, USA.

Marginal structural models (MSMs), which adopt inverse probability treatment 
weighting in the estimating equations, are powerful tools to estimate the causal 
effects of time-varying exposures in the presence of time-dependent confounders. 
Motivated by the Conservation of Hearing Study (CHEARS) Audiology Assessment Arm 
(AAA) where repeated hearing measurements were clustered by study participants, 
time, and testing sites, we propose two methods to account for the multilevel 
correlation structure when fitting the MSMs. The first method directly models 
the covariance of the repeated outcomes when solving the weighted generalized 
estimating equations for MSMs, while the second two-stage analysis approach fits 
cluster-specific MSMs first and then combines the estimated parameters using 
mixed-effects meta-analysis. Finite sample simulation results suggest that our 
methods can obtain less biased and more efficient estimates of the parameters by 
accounting for the multilevel correlation. Moreover, we explore the effects of 
using fixed- or mixed-effects model to estimate the treatment probability on the 
parameter estimates of the MSMs in the presence of unmeasured cluster-level 
confounders. Lastly, we apply our methods to the CHEARS AAA data set, to 
estimate the causal effects of aspirin use on hearing loss.

© The Author 2022. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/biostatistics/kxac027
PMCID: PMC9802195
PMID: 35904119 [Indexed for MEDLINE]


843. Vet Anim Sci. 2020 May 12;9:100118. doi: 10.1016/j.vas.2020.100118. eCollection 
2020 Jun.

STRING data mining of GWAS data in canine hereditary pigment-associated 
deafness.

Kelly-Smith M(1), Strain GM(1).

Author information:
(1)Comparative Biomedical Sciences, School of Veterinary Medicine, Louisiana 
State University, Baton Rouge, LA 70803 USA.

Most canine deafness is linked to white pigmentation caused by the piebald 
locus, shown to be the gene MITF (melanocyte inducing transcription factor), but 
studies have failed to identify a deafness cause. The coding regions of MITF 
have not been shown to be mutated in deaf dogs, leading us to pursue genes 
acting on or controlled by MITF. We have genotyped DNA from 502 deaf and hearing 
Australian cattle dogs, Dalmatians, and English setters, breeds with a high 
deafness prevalence. Genome-wide significance was not attained in any of our 
analyses, but we did identify several suggestive associations. Genome-wide 
association studies (GWAS) in complex hereditary disorders frequently fail to 
identify causative gene variants, so advanced bioinformatics data mining 
techniques are needed to extract information to guide future studies. STRING 
diagrams are graphical representations of known and predicted networks of 
protein-protein interactions, identifying documented relationships between gene 
proteins based on the scientific literature, to identify functional gene 
groupings to pursue for further scrutiny. The STRING program predicts 
associations at a preset confidence level and suggests biological functions 
based on the identified genes. Starting with (1) genes within 500 kb of 
GWAS-suggested SNPs, (2) known pigmentation genes, (3) known human deafness 
genes, and (4) genes identified from proteomic analysis of the cochlea, we 
generated STRING diagrams that included these genes. We then reduced the number 
of genes by excluding genes with no relationship to auditory function, 
pigmentation, or relevant structures, and identified clusters of genes that 
warrant further investigation.

© 2020 The Authors.

DOI: 10.1016/j.vas.2020.100118
PMCID: PMC7386748
PMID: 32734119

Conflict of interest statement: None.


844. Front Integr Neurosci. 2015 Jan 21;8:98. doi: 10.3389/fnint.2014.00098. 
eCollection 2014.

Visuo-tactile interactions in the congenitally deaf: a behavioral and 
event-related potential study.

Hauthal N(1), Debener S(2), Rach S(3), Sandmann P(4), Thorne JD(1).

Author information:
(1)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all," European Medical School, University of Oldenburg Oldenburg, 
Germany.
(2)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all," European Medical School, University of Oldenburg Oldenburg, 
Germany ; Research Center Neurosensory Science, University of Oldenburg 
Oldenburg, Germany.
(3)Research Center Neurosensory Science, University of Oldenburg Oldenburg, 
Germany ; Experimental Psychology Lab, Department of Psychology, European 
Medical School, University of Oldenburg Oldenburg, Germany ; Department of 
Epidemiological Methods and Etiologic Research, Leibniz Institute for Prevention 
Research and Epidemiology - BIPS Bremen, Germany.
(4)Neuropsychology Lab, Department of Psychology, Cluster of Excellence 
"Hearing4all," European Medical School, University of Oldenburg Oldenburg, 
Germany ; Department of Neurology, Cluster of Excellence "Hearing4all," Hannover 
Medical School Hannover, Germany.

Auditory deprivation is known to be accompanied by alterations in visual 
processing. Yet not much is known about tactile processing and the interplay of 
the intact sensory modalities in the deaf. We presented visual, tactile, and 
visuo-tactile stimuli to congenitally deaf and hearing individuals in a speeded 
detection task. Analyses of multisensory responses showed a redundant signals 
effect that was attributable to a coactivation mechanism in both groups, 
although the redundancy gain was less in the deaf. In line with these behavioral 
results, on a neural level, there were multisensory interactions in both groups 
that were again weaker in the deaf. In hearing but not deaf participants, 
somatosensory event-related potential N200 latencies were modulated by 
simultaneous visual stimulation. A comparison of unisensory responses between 
groups revealed larger N200 amplitudes for visual and shorter N200 latencies for 
tactile stimuli in the deaf. Furthermore, P300 amplitudes were also larger in 
the deaf. This group difference was significant for tactile and approached 
significance for visual targets. The differences in visual and tactile 
processing between deaf and hearing participants, however, were not reflected in 
behavior. Both the behavioral and electroencephalography (EEG) results suggest 
more pronounced multisensory interaction in hearing than in deaf individuals. 
Visuo-tactile enhancements could not be explained by perceptual deficiency, but 
could be partly attributable to inverse effectiveness.

DOI: 10.3389/fnint.2014.00098
PMCID: PMC4300915
PMID: 25653602


845. Front Syst Neurosci. 2013 Nov 27;7:93. doi: 10.3389/fnsys.2013.00093. 
eCollection 2013.

Unilateral hearing during development: hemispheric specificity in plastic 
reorganizations.

Kral A(1), Heid S(2), Hubka P(1), Tillein J(2).

Author information:
(1)Cluster of Excellence, Department of Experimental Otology, Institute of 
Audioneurotechnology, ENT Clinics, Hannover Medical School Hannover, Germany.
(2)Cluster of Excellence, Department of Experimental Otology, Institute of 
Audioneurotechnology, ENT Clinics, Hannover Medical School Hannover, Germany ; 
Department of Physiology and Otolaryngology, J. W. Goethe University Frankfurt 
am Main, Germany.

The present study investigates the hemispheric contributions of neuronal 
reorganization following early single-sided hearing (unilateral deafness). The 
experiments were performed on ten cats from our colony of deaf white cats. Two 
were identified in early hearing screening as unilaterally congenitally deaf. 
The remaining eight were bilaterally congenitally deaf, unilaterally implanted 
at different ages with a cochlear implant. Implanted animals were chronically 
stimulated using a single-channel portable signal processor for two to five 
months. Microelectrode recordings were performed at the primary auditory cortex 
under stimulation at the hearing and deaf ear with bilateral cochlear implants. 
Local field potentials (LFPs) were compared at the cortex ipsilateral and 
contralateral to the hearing ear. The focus of the study was on the morphology 
and the onset latency of the LFPs. With respect to morphology of LFPs, 
pronounced hemisphere-specific effects were observed. Morphology of 
amplitude-normalized LFPs for stimulation of the deaf and the hearing ear was 
similar for responses recorded at the same hemisphere. However, when comparisons 
were performed between the hemispheres, the morphology was more dissimilar even 
though the same ear was stimulated. This demonstrates hemispheric specificity of 
some cortical adaptations irrespective of the ear stimulated. The results 
suggest a specific adaptation process at the hemisphere ipsilateral to the 
hearing ear, involving specific (down-regulated inhibitory) mechanisms not found 
in the contralateral hemisphere. Finally, onset latencies revealed that the 
sensitive period for the cortex ipsilateral to the hearing ear is shorter than 
that for the contralateral cortex. Unilateral hearing experience leads to a 
functionally-asymmetric brain with different neuronal reorganizations and 
different sensitive periods involved.

DOI: 10.3389/fnsys.2013.00093
PMCID: PMC3841817
PMID: 24348345


846. Hear Res. 2019 Oct;382:107784. doi: 10.1016/j.heares.2019.107784. Epub 2019 Aug 
20.

Morphological development of the human cochlear nucleus.

Saini S(1), Kaur C(1), Pal I(1), Kumar P(1), Jacob TG(1), Thakar A(2), Roy 
KK(3), Roy TS(4).

Author information:
(1)Department of Anatomy, All India Institute of Medical Sciences, New Delhi, 
110029, India.
(2)Department of Otorhinolaryngology, All India Institute of Medical Sciences, 
New Delhi, 110029, India.
(3)Department of Obstetrics and Gynecology, All India Institute of Medical 
Sciences, New Delhi, 110029, India.
(4)Department of Anatomy, All India Institute of Medical Sciences, New Delhi, 
110029, India. Electronic address: tarasankar@hotmail.com.

Morphological studies in developing brain determine critical periods of 
proliferation, neurogenesis, gliogenesis, and apoptosis. During these periods 
both intrinsic and extrinsic pathological factors can hamper development. These 
time points are not available for the human cochlear nucleus (CN). We have used 
design-based stereology and determined that 18-22 weeks of gestation (WG) are 
critical in the development of the human CN. Twenty-three fetuses and seven 
postnatal brainstems were processed for cresyl violet (CV) staining and 
immunoexpression of NeuN (neurons), GFAP (astrocytes), Ki-67 (proliferation) and 
TUNEL (apoptosis) and 3-D reconstruction. The volume of CN, total number of 
neurons selected profiles and the volume of neurons and their nuclei were 
estimated. Data were grouped (G) into: G1:18-20 WG, G2: 21-24 WG, G3: 25-28 WG 
and G4 >29 WG. The dimensions of morphologically identified neurons were also 
measured. The CN primordium was first identifiable at 10WG. Definitive DCN 
(Dorsal cochlear nucleus) and VCN (ventral cochlear nucleus) were identifiable 
at 16 WG. There was a sudden growth spurt in total volume of CN, number of 
neurons and astrocytes from 18 WG. We also observed an increase in proliferation 
and apoptosis after 22 WG. The number of neurons identifiable by CV was 
significantly lower than that by NeuN-immunostaining till 25 WG (p = 0.020), 
after which, both methods were equivalent. Eight morphological types of neurons 
were identifiable by 26 WG and could be resolved into four clusters by volume 
and diameter. The CN changed orientation from small, flat and horizontal at 
10-16 WG to larger and oblique from 18WG onwards. Prevention of exposure to 
noxious factors at 18-22 WG may be important in preventing congenital deafness.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.heares.2019.107784
PMID: 31522073 [Indexed for MEDLINE]


847. J Acoust Soc Am. 2017 Mar;141(3):1862. doi: 10.1121/1.4977014.

Differences in the temporal course of interaural time difference sensitivity 
between acoustic and electric hearing in amplitude modulated stimuli.

Hu H(1), Ewert SD(1), McAlpine D(2), Dietz M(1).

Author information:
(1)Medizinische Physik and Cluster of Excellence "Hearing4all," Universität 
Oldenburg, D-26111 Oldenburg, Germany.
(2)Department of Linguistics, Australian Hearing Hub, Macquarie University, New 
South Wales 2109, Australia.

Previous studies have shown that normal-hearing (NH) listeners' spatial 
perception of non-stationary interaural time differences (ITDs) is dominated by 
the carrier ITD during rising amplitude segments. Here, ITD sensitivity 
throughout the amplitude-modulation cycle in NH listeners and bilateral cochlear 
implant (CI) subjects is compared, the latter by means of direct stimulation of 
a single electrode pair. The data indicate that, while NH listeners are most 
sensitive to ITDs applied toward the beginning of a modulation cycle at 600 Hz, 
NH listeners at 200 Hz and especially bilateral CI subjects at 200 pulses per 
second (pps) are more sensitive to ITDs applied to the modulation maximum. This 
has implications for spatial-hearing in complex environments: NH listeners' 
dominant 600-Hz ITD information from the rising amplitude segments comprises 
direct sound information. The 200-pps low rate required to get ITD sensitivity 
in CI users results in a higher weight of pulses later in the modulation cycle 
where the source ITDs are more likely corrupted by reflections. This indirectly 
indicates that even if future binaural CI processors are able to provide 
perceptually exploitable ITD information, CI users will likely not get the full 
benefit from such pulse-based ITD cues in reverberant and other complex 
environments.

DOI: 10.1121/1.4977014
PMID: 28372072 [Indexed for MEDLINE]


848. Trends Hear. 2016 Feb 15;20:2331216516631741. doi: 10.1177/2331216516631741.

Open Versus Closed Hearing-Aid Fittings: A Literature Review of Both Fitting 
Approaches.

Winkler A(1), Latzel M(2), Holube I(3).

Author information:
(1)Insitute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4All", Oldenburg, Germany 
alexandra.winkler@jade-hs.de.
(2)Phonak AG, Staefa, Switzerland.
(3)Insitute of Hearing Technology and Audiology, Jade University of Applied 
Sciences and Cluster of Excellence "Hearing4All", Oldenburg, Germany.

One of the main issues in hearing-aid fittings is the abnormal perception of the 
user's own voice as too loud, "boomy," or "hollow." This phenomenon known as the 
occlusion effect be reduced by large vents in the earmolds or by open-fit 
hearing aids. This review provides an overview of publications related to open 
and closed hearing-aid fittings. First, the occlusion effect and its 
consequences for perception while using hearing aids are described. Then, the 
advantages and disadvantages of open compared with closed fittings and their 
impact on the fitting process are addressed. The advantages include less 
occlusion, improved own-voice perception and sound quality, and increased 
localization performance. The disadvantages associated with open-fit hearing 
aids include reduced benefits of directional microphones and noise reduction, as 
well as less compression and less available gain before feedback. The final part 
of this review addresses the need for new approaches to combine the advantages 
of open and closed hearing-aid fittings.

© The Author(s) 2016.

DOI: 10.1177/2331216516631741
PMCID: PMC4765810
PMID: 26879562 [Indexed for MEDLINE]


849. J Neurosci. 2017 Jun 28;37(26):6299-6313. doi: 10.1523/JNEUROSCI.2878-16.2017. 
Epub 2017 May 25.

Enlargement of Ribbons in Zebrafish Hair Cells Increases Calcium Currents But 
Disrupts Afferent Spontaneous Activity and Timing of Stimulus Onset.

Sheets L(1)(2), He XJ(3), Olt J(4), Schreck M(3), Petralia RS(5), Wang YX(5), 
Zhang Q(3), Beirl A(3), Nicolson T(6), Marcotti W(4), Trapani JG(7), Kindt 
KS(8).

Author information:
(1)Department of Otolaryngology, Harvard Medical School, Boston, Massachusetts 
02115.
(2)Eaton-Peabody Laboratory, Massachusetts Eye and Ear, Boston, Massachusetts 
02114.
(3)Section on Sensory Cell Development and Function, National Institute on 
Deafness and Other Communication Disorders/National Institutes of Health, 
Bethesda, Maryland 20892.
(4)Department of Biomedical Science, University of Sheffield, Sheffield S10 2TN, 
United Kingdom, and.
(5)Advanced Imaging Core, National Institute on Deafness and Other Communication 
Disorders/National Institutes of Health, Bethesda, Maryland 20892.
(6)Oregon Hearing Research Center and Vollum Institute, Oregon Health and 
Science University, Portland, Oregon 97239.
(7)Department of Biology and Neuroscience Program, Amherst College, Amherst, 
Massachusetts 01002.
(8)Section on Sensory Cell Development and Function, National Institute on 
Deafness and Other Communication Disorders/National Institutes of Health, 
Bethesda, Maryland 20892, katie.kindt@nih.gov.

In sensory hair cells of auditory and vestibular organs, the ribbon synapse is 
required for the precise encoding of a wide range of complex stimuli. Hair cells 
have a unique presynaptic structure, the synaptic ribbon, which organizes both 
synaptic vesicles and calcium channels at the active zone. Previous work has 
shown that hair-cell ribbon size is correlated with differences in postsynaptic 
activity. However, additional variability in postsynapse size presents a 
challenge to determining the specific role of ribbon size in sensory encoding. 
To selectively assess the impact of ribbon size on synapse function, we examined 
hair cells in transgenic zebrafish that have enlarged ribbons, without 
postsynaptic alterations. Morphologically, we found that enlarged ribbons had 
more associated vesicles and reduced presynaptic calcium-channel clustering. 
Functionally, hair cells with enlarged ribbons had larger global and 
ribbon-localized calcium currents. Afferent neuron recordings revealed that hair 
cells with enlarged ribbons resulted in reduced spontaneous spike rates. 
Additionally, despite larger presynaptic calcium signals, we observed fewer 
evoked spikes with longer latencies from stimulus onset. Together, our work 
indicates that hair-cell ribbon size influences the spontaneous spiking and the 
precise encoding of stimulus onset in afferent neurons.SIGNIFICANCE STATEMENT 
Numerous studies support that hair-cell ribbon size corresponds with functional 
sensitivity differences in afferent neurons and, in the case of inner hair cells 
of the cochlea, vulnerability to damage from noise trauma. Yet it is unclear 
whether ribbon size directly influences sensory encoding. Our study reveals that 
ribbon enlargement results in increased ribbon-localized calcium signals, yet 
reduces afferent spontaneous activity and disrupts the timing of stimulus onset, 
a distinct aspect of auditory and vestibular encoding. These observations 
suggest that varying ribbon size alone can influence sensory encoding, and give 
further insight into how hair cells transduce signals that cover a wide dynamic 
range of stimuli.

Copyright © 2017 Sheets et al.

DOI: 10.1523/JNEUROSCI.2878-16.2017
PMCID: PMC5490065
PMID: 28546313 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing financial 
interests.


850. Hear Res. 2020 Oct;396:108070. doi: 10.1016/j.heares.2020.108070. Epub 2020 Sep 
4.

Level coding by phase duration and asymmetric pulse shape reduce channel 
interactions in cochlear implants.

Quass GL(1), Baumhoff P(2), Gnansia D(3), Stahl P(3), Kral A(4).

Author information:
(1)Institute for AudioNeuroTechnology (VIANNA), ENT Clinics, Hannover Medical 
School, 30625 Hannover, Germany; Cluster of Excellence "Hearing4All" (EXC 2177). 
Electronic address: quass.gunnar@mh-hannover.de.
(2)Institute for AudioNeuroTechnology (VIANNA), ENT Clinics, Hannover Medical 
School, 30625 Hannover, Germany.
(3)Oticon Medical, 06220 Vallauris, France.
(4)Institute for AudioNeuroTechnology (VIANNA), ENT Clinics, Hannover Medical 
School, 30625 Hannover, Germany; Cluster of Excellence "Hearing4All" (EXC 2177).

Conventional loudness coding with CIs by pulse current amplitude has a 
disadvantage: Increasing the stimulation current increases the spread of 
excitation in the auditory nerve, resulting in stronger channel interactions at 
high stimulation levels. These limit the number of effective information 
channels that a CI user can perceive. Stimulus intensity information (loudness) 
can alternatively be transmitted via pulse phase duration. We hypothesized that 
loudness coding by phase duration avoids the increase in the spread of the 
electric field and thus leads to less channel interactions at high stimulation 
levels. To avoid polarity effects, we combined this coding with pseudomonophasic 
stimuli. To test whether this affects the spread of excitation, 16 acutely 
deafened guinea pigs were implanted with CIs and neural activity from the 
inferior colliculus was recorded while stimulating with either biphasic, 
amplitude-coded pulses, or pseudomonophasic, duration- or amplitude-coded 
pulses. Pseudomonophasic stimuli combined with phase duration loudness coding 
reduced the lowest response thresholds and the spread of excitation. We 
investigated the channel interactions at suprathreshold levels by computing the 
phase-locking to a pulse train in the presence of an interacting pulse train on 
a different electrode on the CI. Pseudomonophasic pulses coupled with phase 
duration loudness coding reduced the interference by 4-5% compared to biphasic 
pulses, depending on the place of stimulation. This effect of pseudomonophasic 
stimuli was achieved with amplitude coding only in the basal cochlea, indicating 
a distance- or volume dependent effect. Our results show that pseudomonophasic, 
phase-duration-coded stimuli slightly reduce channel interactions, suggesting a 
potential benefit for speech understanding in humans.

Copyright © 2020. Published by Elsevier B.V.

DOI: 10.1016/j.heares.2020.108070
PMID: 32950954 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest Research CIs 
were supplied by Oticon medical. Authors DG and PS are employees of Oticon 
medical. All other authors have nothing to declare.


851. Neuron. 2007 Mar 1;53(5):663-75. doi: 10.1016/j.neuron.2007.02.010.

Structural insight into KCNQ (Kv7) channel assembly and channelopathy.

Howard RJ(1), Clark KA, Holton JM, Minor DL Jr.

Author information:
(1)Chemistry and Chemical Biology Graduate Program, University of California, 
San Francisco, CA 94158-2330, USA.

Kv7.x (KCNQ) voltage-gated potassium channels form the cardiac and auditory 
I(Ks) current and the neuronal M-current. The five Kv7 subtypes have distinct 
assembly preferences encoded by a C-terminal cytoplasmic assembly domain, the 
A-domain Tail. Here, we present the high-resolution structure of the Kv7.4 
A-domain Tail together with biochemical experiments that show that the domain is 
a self-assembling, parallel, four-stranded coiled coil. Structural analysis and 
biochemical studies indicate conservation of the coiled coil in all Kv7 subtypes 
and that a limited set of interactions encode assembly specificity determinants. 
Kv7 mutations have prominent roles in arrhythmias, deafness, and epilepsy. The 
structure together with biochemical data indicate that A-domain Tail arrhythmia 
mutations cluster on the solvent-accessible surface of the subunit interface at 
a likely site of action for modulatory proteins. Together, the data provide a 
framework for understanding Kv7 assembly specificity and the molecular basis of 
a distinct set of Kv7 channelopathies.

DOI: 10.1016/j.neuron.2007.02.010
PMCID: PMC3011230
PMID: 17329207 [Indexed for MEDLINE]


852. Psychol Med. 1994 May;24(2):397-410. doi: 10.1017/s0033291700027379.

Phenomenology, demography and diagnosis in late paraphrenia.

Howard R(1), Almeida O, Levy R.

Author information:
(1)Section of Old Age Psychiatry, Institute of Psychiatry, London.

One hundred and one patients with late paraphrenia were examined using the 
Present State Examination. The established high prevalence rates of female 
gender, the unmarried state and sensory impairment were confirmed. All of the 
symptoms of schizophrenia, with the exception of formal thought disorder, were 
found in the subjects with approximately the same prevalence as reported in 
schizophrenics with a symptom onset in younger life. The presence of visual 
hallucinosis was significantly associated with visual impairment, but the same 
association was not found between auditory hallucinations and deafness. Mean age 
at onset of symptoms was high at 74.1 years. Using ICD-10 diagnostic criteria 
the patients were categorized as schizophrenia (61.4%), delusional disorder 
(30.7%) and schizoaffective disorder (7.9%). Patients in these diagnostic 
categories differed in their pre-morbid IQ estimations, current cognitive state 
measured by the Mini-Mental State Examination and in the number of scored 
positive psychotic PSE symptoms and their systematization of and preoccupation 
with delusions and hallucinations. There were no significant differences between 
the patients in the ICD-10 schizophrenia and delusional disorder groups in terms 
of age at symptom onset, sex ratio, response to treatment, being unmarried, the 
presence of insight or sensory impairment. The high degree of clinical 
similarity between patients with late paraphrenia combined with the inability of 
ICD-10 to define diagnostic subgroups that correspond to patient clusters 
derived from clinical symptoms or which are meaningfully different from each 
other in terms of demographic and prognostic factors provide a strong argument 
for the retention of late paraphrenia as the most appropriate diagnosis for such 
patients.

DOI: 10.1017/s0033291700027379
PMID: 8084935 [Indexed for MEDLINE]


853. Sci Rep. 2020 Apr 7;10(1):5995. doi: 10.1038/s41598-020-62879-y.

Otoferlin gene editing in sheep via CRISPR-assisted ssODN-mediated Homology 
Directed Repair.

Menchaca A(1), Dos Santos-Neto PC(2), Souza-Neves M(2), Cuadro F(2), Mulet 
AP(3), Tesson L(4)(5), Chenouard V(4)(5), Guiffès A(4)(5), Heslan JM(4)(6), 
Gantier M(4)(6), Anegón I(7)(8)(9), Crispo M(10).

Author information:
(1)Instituto de Reproducción Animal Uruguay, Fundación IRAUy, Montevideo, 
Uruguay. menchaca.alejo@gmail.com.
(2)Instituto de Reproducción Animal Uruguay, Fundación IRAUy, Montevideo, 
Uruguay.
(3)Unidad de Animales Transgénicos y de Experimentación (UATE), Institut Pasteur 
de Montevideo, Montevideo, Uruguay.
(4)Inserm, Centre de Recherche en Transplantation et Immunologie, UMR 1064, 
F-44000, Nantes, France.
(5)Transgenesis Rat ImmunoPhenomic facility (TRIP), F-44000, Nantes, France.
(6)GenoCellEdit facility, F-44000, Nantes, France.
(7)Inserm, Centre de Recherche en Transplantation et Immunologie, UMR 1064, 
F-44000, Nantes, France. ianegon@nantes.inserm.fr.
(8)Transgenesis Rat ImmunoPhenomic facility (TRIP), F-44000, Nantes, France. 
ianegon@nantes.inserm.fr.
(9)GenoCellEdit facility, F-44000, Nantes, France. ianegon@nantes.inserm.fr.
(10)Unidad de Animales Transgénicos y de Experimentación (UATE), Institut 
Pasteur de Montevideo, Montevideo, Uruguay. crispo@pasteur.edu.uy.

Different mutations of the OTOF gene, encoding for otoferlin protein expressed 
in the cochlear inner hair cells, induces a form of deafness that is the major 
cause of nonsyndromic recessive auditory neuropathy spectrum disorder in humans. 
We report the generation of the first large animal model of OTOF mutations using 
the CRISPR system associated with different Cas9 components (mRNA or protein) 
assisted by single strand oligodeoxynucleotides (ssODN) to induce 
homology-directed repair (HDR). Zygote microinjection was performed with two 
sgRNA targeting exon 5 and 6 associated to Cas9 mRNA or protein (RNP) at 
different concentrations in a mix with an ssODN template targeting HDR in exon 5 
containing two STOP sequences. A total of 73 lambs were born, 13 showing indel 
mutations (17.8%), 8 of which (61.5%) had knock-in mutations by HDR. Higher 
concentrations of Cas9-RNP induced targeted mutations more effectively, but 
negatively affected embryo survival and pregnancy rate. This study reports by 
the first time the generation of OTOF disrupted sheep, which may allow better 
understanding and development of new therapies for human deafness related to 
genetic disorders. These results support the use of CRISPR/Cas system assisted 
by ssODN as an effective tool for gene editing in livestock.

DOI: 10.1038/s41598-020-62879-y
PMCID: PMC7138848
PMID: 32265471 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


854. Prog Brain Res. 2021;260:51-78. doi: 10.1016/bs.pbr.2020.10.001. Epub 2021 Feb 
4.

Subjective hearing ability, physical and mental comorbidities in individuals 
with bothersome tinnitus in a Swedish population sample.

Basso L(1), Boecking B(1), Brueggemann P(1), Pedersen NL(2), Canlon B(3), 
Cederroth CR(4), Mazurek B(5).

Author information:
(1)Tinnitus Center, Charité-Universitätsmedizin Berlin, Berlin, Germany.
(2)Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, 
Stockholm, Sweden.
(3)Laboratory of Experimental Audiology, Department of Physiology and 
Pharmacology, Karolinska Institutet, Stockholm, Sweden.
(4)Laboratory of Experimental Audiology, Department of Physiology and 
Pharmacology, Karolinska Institutet, Stockholm, Sweden; National Institute for 
Health Research (NIHR) Nottingham Biomedical Research Centre, Nottingham 
University Hospitals NHS Trust, Nottingham, United Kingdom; Hearing Sciences, 
Division of Clinical Neuroscience, School of Medicine, University of Nottingham, 
Nottingham, United Kingdom.
(5)Tinnitus Center, Charité-Universitätsmedizin Berlin, Berlin, Germany. 
Electronic address: birgit.mazurek@charite.de.

OBJECTIVE: This study investigates associations of subjective hearing ability, 
physical comorbidities, and mental comorbidities with bothersome (vs. 
non-bothersome) tinnitus and mediating effects between these influences.
METHODS: The Swedish LifeGene cohort was used to sample cross-sectional survey 
data (collected 2009-2016) of 7615 participants with tinnitus, 697 (9.2%) of 
whom rated their tinnitus as bothersome. Associations between bothersome 
tinnitus and subjective hearing ability, physical and mental comorbidities were 
investigated by separate age- and gender-adjusted multiple logistic regression 
models. Interrelationships between these associations were investigated by 
logistic mediation models.
RESULTS: Compared to non-bothersome tinnitus, bothersome tinnitus was associated 
with higher age, reduced subjective hearing ability, hearing-related 
difficulties in social situations, cardiovascular disease, chronic shoulder 
pain, thyroid disease, Ménière's disease, depression, anxiety syndrome, and 
social anxiety. Subjective hearing impairment or hearing-related difficulties 
mediated 13-36% of the effects of mental comorbidities on bothersome tinnitus. 
Depression or anxiety syndrome mediated 5-8% of most relationships between 
physical comorbidities and bothersome tinnitus. Depression, anxiety syndrome, or 
social anxiety mediated 2-4% of the effects of subjective hearing impairment or 
hearing-related difficulties on bothersome tinnitus.
CONCLUSION: Psychological factors, subjective hearing impairment, and 
hearing-related difficulties in social situations play key roles in predicting 
bothersome (vs. non-bothersome) tinnitus in a large population sample. 
Psychological factors contribute to explaining the impact of physical 
comorbidities and hearing-related effects on bothersome tinnitus. This 
highlights their transdiagnostic importance for aggravating varied physical 
symptom clusters. Interventions to improve or prevent high tinnitus burden 
should be interdisciplinary/multimodal and target auditory, physical, and 
psychological factors.

© 2021 Elsevier B.V. All rights reserved.

DOI: 10.1016/bs.pbr.2020.10.001
PMID: 33637232 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of interest CC is supported by the UK 
National Institute for Health Research (NIHR) Biomedical Research Centre but the 
views expressed herein are his own and do not represent those of NIHR nor the UK 
Department of Health and Social Care. The remaining authors declare that the 
research was conducted in the absence of any commercial or financial 
relationships that could be construed as a potential conflict of interest.


855. Front Neurosci. 2020 Aug 11;14:787. doi: 10.3389/fnins.2020.00787. eCollection 
2020.

Combined Brain-Perfusion SPECT and EEG Measurements Suggest Distinct Strategies 
for Speech Comprehension in CI Users With Higher and Lower Performance.

Kessler M(1)(2), Schierholz I(2)(3)(4), Mamach M(2)(5), Wilke F(5), Hahne A(6), 
Büchner A(2)(3), Geworski L(5), Bengel FM(1), Sandmann P(4), Berding G(1)(2).

Author information:
(1)Department of Nuclear Medicine, Hannover Medical School, Hanover, Germany.
(2)Cluster of Excellence Hearing4all, Hannover Medical School, University of 
Oldenburg, Oldenburg, Germany.
(3)Department of Otorhinolaryngology, Hannover Medical School, Hanover, Germany.
(4)Department of Otorhinolaryngology, University of Cologne, Cologne, Germany.
(5)Department of Medical Physics and Radiation Protection, Hannover Medical 
School, Hanover, Germany.
(6)Department of Otorhinolaryngology, Faculty of Medicine Carl Gustav Carus, 
Saxonian Cochlear Implant Center, Technical University Dresden, Dresden, 
Germany.

Cochlear implantation constitutes a successful therapy of inner ear deafness, 
with the majority of patients showing good outcomes. There is, however, still 
some unexplained variability in outcomes with a number of cochlear-implant (CI) 
users, showing major limitations in speech comprehension. The current study used 
a multimodal diagnostic approach combining single-photon emission computed 
tomography (SPECT) and electroencephalography (EEG) to examine the mechanisms 
underlying speech processing in postlingually deafened CI users (N = 21). In one 
session, the participants performed a speech discrimination task, during which a 
96-channel EEG was recorded and the perfusions marker 99mTc-HMPAO was injected 
intravenously. The SPECT scan was acquired 1.5 h after injection to measure the 
cortical activity during the speech task. The second session included a SPECT 
scan after injection without stimulation at rest. Analysis of EEG and SPECT data 
showed N400 and P600 event-related potentials (ERPs) particularly evoked by 
semantic violations in the sentences, and enhanced perfusion in a 
temporo-frontal network during task compared to rest, involving the auditory 
cortex bilaterally and Broca's area. Moreover, higher performance in testing for 
word recognition and verbal intelligence strongly correlated to the activation 
in this network during the speech task. However, comparing CI users with lower 
and higher speech intelligibility [median split with cutoff + 7.6 dB 
signal-to-noise ratio (SNR) in the Göttinger sentence test] revealed for CI 
users with higher performance additional activations of parietal and occipital 
regions and for those with lower performance stronger activation of superior 
frontal areas. Furthermore, SPECT activity was tightly coupled with EEG and 
cognitive abilities, as indicated by correlations between (1) cortical 
activation and the amplitudes in EEG, N400 (temporal and occipital areas)/P600 
(parietal and occipital areas) and (2) between cortical activation in left-sided 
temporal and bilateral occipital/parietal areas and working memory capacity. 
These results suggest the recruitment of a temporo-frontal network in CI users 
during speech processing and a close connection between ERP effects and cortical 
activation in CI users. The observed differences in speech-evoked cortical 
activation patterns for CI users with higher and lower speech intelligibility 
suggest distinct processing strategies during speech rehabilitation with CI.

Copyright © 2020 Kessler, Schierholz, Mamach, Wilke, Hahne, Büchner, Geworski, 
Bengel, Sandmann and Berding.

DOI: 10.3389/fnins.2020.00787
PMCID: PMC7431776
PMID: 32848560


856. J Am Med Dir Assoc. 2023 Feb;24(2):192-198.e5. doi: 10.1016/j.jamda.2022.11.010. 
Epub 2022 Dec 14.

Soundscape Awareness Intervention Reduced Neuropsychiatric Symptoms in Nursing 
Home Residents With Dementia: A Cluster-Randomized Trial With MoSART.

Kosters J(1), Janus SIM(1), van den Bosch KA(2), Andringa TC(3), Hoop EO(4), de 
Boer MR(1), Elburg RAJ(5), Warmelink S(5), Zuidema SU(1), Luijendijk HJ(6).

Author information:
(1)Department of General Practice and Elderly Care Medicine, University of 
Groningen, University Medical Center Groningen, Groningen, the Netherlands.
(2)Department of Youth Studies, University of Groningen, Groningen, the 
Netherlands.
(3)Department of General Practice and Elderly Care Medicine, University of 
Groningen, University Medical Center Groningen, Groningen, the Netherlands; 
SoundAppraisal Ltd., Groningen, the Netherlands.
(4)Department of Medical Oncology, Erasmus MC Cancer Institute, Rotterdam, the 
Netherlands.
(5)SoundAppraisal Ltd., Groningen, the Netherlands.
(6)Department of General Practice and Elderly Care Medicine, University of 
Groningen, University Medical Center Groningen, Groningen, the Netherlands. 
Electronic address: h.j.luijendijk@umcg.nl.

OBJECTIVES: Auditory environments as perceived by an individual, also called 
soundscapes, are often suboptimal for nursing home residents. Poor soundscapes 
have been associated with neuropsychiatric symptoms (NPS). We evaluated the 
effect of the Mobile Soundscape Appraisal and Recording Technology sound 
awareness intervention (MoSART+) on NPS in nursing home residents with dementia.
DESIGN: A 15-month, stepped-wedge, cluster-randomized trial. Every 3 months, a 
nursing home switched from care as usual to the use of the intervention.
INTERVENTION: The 3-month MoSART+ intervention involved ambassador training, 
staff performing sound measurements with the MoSART application, meetings, and 
implementation of microinterventions. The goal was to raise awareness about 
soundscapes and their influence on residents.
SETTING AND PARTICIPANTS: We included 110 residents with dementia in 5 Dutch 
nursing homes. Exclusion criteria were palliative sedation and deafness.
METHODS: The primary outcome was NPS severity measured with the Neuropsychiatric 
Inventory-Nursing Home version (NPI-NH) by the resident's primary nurse. 
Secondary outcomes were quality of life (QUALIDEM), psychotropic drug use (ATC), 
staff workload (workload questionnaire), and staff job satisfaction (Maastricht 
Questionnaire of Job Satisfaction).
RESULTS: The mean age of the residents (n = 97) at enrollment was 86.5 ± 
6.7 years, and 76 were female (76.8%). The mean NPI-NH score was 17.5 ± 17.3. 
One nursing home did not implement the intervention because of staff shortages. 
Intention-to-treat analysis showed a clinically relevant reduction in NPS 
between the study groups (-8.0, 95% CI -11.7, -2.6). There was no clear effect 
on quality of life [odds ratio (OR) 2.8, 95% CI -0.7, 6.3], psychotropic drug 
use (1.2, 95% CI 0.9, 1.7), staff workload (-0.3, 95% CI -0.3, 0.8), or staff 
job satisfaction (-0.2, 95% CI -1.2, 0.7).
CONCLUSIONS AND IMPLICATIONS: MoSART+ empowered staff to adapt the local 
soundscape, and the intervention effectively reduced staff-reported levels of 
NPS in nursing home residents with dementia. Nursing homes should consider 
implementing interventions to improve the soundscape.

Copyright © 2022 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jamda.2022.11.010
PMID: 36528077 [Indexed for MEDLINE]


857. Pharmaceutics. 2023 Feb 22;15(3):726. doi: 10.3390/pharmaceutics15030726.

Dual Drug Delivery in Cochlear Implants: In Vivo Study of Dexamethasone Combined 
with Diclofenac or Immunophilin Inhibitor MM284 in Guinea Pigs.

Behrends W(1)(2), Wulf K(3), Raggl S(4), Fröhlich M(1)(5), Eickner T(3), Dohr 
D(6), Esser KH(2), Lenarz T(1)(7), Scheper V(1)(7), Paasche G(1)(7).

Author information:
(1)Department of Otolaryngology, Hannover Medical School, 30625 Hannover, 
Germany.
(2)Auditory Neuroethology and Neurobiology, Institute of Zoology, University of 
Veterinary Medicine Hannover Foundation, 30559 Hannover, Germany.
(3)Institute for Biomedical Engineering, Rostock University Medical Center, 
18119 Rostock, Germany.
(4)MED-EL Medical Electronics, 6020 Innsbruck, Austria.
(5)MED-EL Research Center, 30625 Hannover, Germany.
(6)Department of Otorhinolaryngology, Head and Neck Surgery "Otto Körner", 
Rostock University Medical Center, 18057 Rostock, Germany.
(7)Hearing4all Cluster of Excellence, Hannover Medical School, 30625 Hannover, 
Germany.

Cochlear implants are well established to treat severe hearing impairments. 
Despite many different approaches to reduce the formation of connective tissue 
after electrode insertion and to keep electrical impedances low, results are not 
yet satisfying. Therefore, the aim of the current study was to combine the 
incorporation of 5% dexamethasone in the silicone body of the electrode array 
with an additional polymeric coating releasing diclofenac or the immunophilin 
inhibitor MM284, some anti-inflammatory substances not yet tested in the inner 
ear. Guinea pigs were implanted for four weeks and hearing thresholds were 
determined before implantation and after the observation time. Impedances were 
monitored over time and, finally, connective tissue and the survival of spiral 
ganglion neurons (SGNs) were quantified. Impedances increased in all groups to a 
similar extent but this increase was delayed in the groups with an additional 
release of diclofenac or MM284. Using Poly-L-lactide (PLLA)-coated electrodes, 
the damage caused during insertion was much higher than without the coating. 
Only in these groups, connective tissue could extend to the apex of the cochlea. 
Despite this, numbers of SGNs were only reduced in PLLA and PLLA plus diclofenac 
groups. Even though the polymeric coating was not flexible enough, MM284 seems 
to especially have potential for further evaluation in connection with cochlear 
implantation.

DOI: 10.3390/pharmaceutics15030726
PMCID: PMC10058822
PMID: 36986587

Conflict of interest statement: The authors declare no conflict of interest. The 
funders had no role in the design of the study; in the collection, analyses, or 
interpretation of data; in the writing of the manuscript; or in the decision to 
publish the results.


858. Lin Chuang Er Bi Yan Hou Tou Jing Wai Ke Za Zhi. 2010 Jan;24(1):19-20, 24.

[The application of improved CHQS for mass epidemiology study on hearing 
impairment].

[Article in Chinese]

Liu C(1), Xing G, Xu X, Chen Z, Zhou H, Wang D, Tian H, Bu X.

Author information:
(1)Department of Otorhinolaryngology, the First Affiliated Hospital of Nanjing 
Medical University, Nanjing, 210029, China.

OBJECTIVE: To develop and evaluate the improved Chinese hearing questionnaire 
for school children (CHQS) for mass epidemiology study on hearing impairment in 
China.
METHOD: Using the probability proportion to size (PPS) method, 8412 residents 
were investigated in 40 clusters in Jiangsu province with the WHO ear diseases 
and hearing disorders survey protocol. 87.9% of the residents aged 7 years and 
over answered the questionnaire and accepted the pure tone audiometry.
RESULT: The prevalence of hearing impairment was 12.9% by the questionnaire. 
Compared with "golden standard" (pure tone audiometry), Sen = 58.5%, Spe = 
96.7%, PV+ = 78.9%, PV- = 91.7%, overall accuracy = 90.0%. The sensitivity for 
women was higher than men.
CONCLUSION: The questionnaire produced high efficiency and specificity values. 
It could be used in mass hearing screening, particularly in remote and rural 
area, although the sensitivity was as low as most questionnaires.

PMID: 20235451 [Indexed for MEDLINE]


859. Genet Med. 2024 Mar;26(3):101034. doi: 10.1016/j.gim.2023.101034. Epub 2023 Dec 
3.

Biallelic variants in SLC4A10 encoding a sodium-dependent bicarbonate 
transporter lead to a neurodevelopmental disorder.

Maroofian R(1), Zamani M(2), Kaiyrzhanov R(3), Liebmann L(4), Karimiani EG(5), 
Vona B(6), Huebner AK(4), Calame DG(7), Misra VK(8), Sadeghian S(9), 
Azizimalamiri R(9), Mohammadi MH(10), Zeighami J(11), Heydaran S(12), Toosi 
MB(13), Akhondian J(14), Babaei M(15), Hashemi N(16), Schnur RE(17), Suri M(18), 
Setzke J(6), Wagner M(19), Brunet T(20), Grochowski CM(21), Emrick L(7), Chung 
WK(22), Hellmich UA(23), Schmidts M(24), Lupski JR(25), Galehdari H(12), 
Severino M(26), Houlden H(3), Hübner CA(27).

Author information:
(1)Department of Neuromuscular Diseases, UCL Queen Square Institute of 
Neurology, London, United Kingdom. Electronic address: r.maroofian@ucl.ac.uk.
(2)Department of Biology, Faculty of Science, Shahid Chamran University of 
Ahvaz, Ahvaz, Iran; Narges Medical Genetics and Prenatal Diagnosis Laboratory, 
Kianpars, Ahvaz, Iran.
(3)Department of Neuromuscular Diseases, UCL Queen Square Institute of 
Neurology, London, United Kingdom.
(4)Institute of Human Genetics, Jena University Hospital, Friedrich Schiller 
Universität, Am Klinikum 1, Jena, Germany.
(5)Molecular and Clinical Sciences Institute, St. George's, University of 
London, Cranmer Terrace, London, United Kingdom.
(6)Institute of Human Genetics, University Medical Center Göttingen, Göttingen, 
Germany; Institute for Auditory Neuroscience and InnerEarLab, University Medical 
Center Göttingen, Göttingen, Germany.
(7)Division of Neurology and Developmental Neuroscience, Department of 
Pediatrics, Baylor College of Medicine, Houston, TX; Texas Children's Hospital, 
Houston, TX; Department of Molecular and Human Genetics, Baylor College of 
Medicine, Houston, TX.
(8)Division of Genetic, Genomic & Metabolic Disorders, Discipline of Pediatrics, 
College of Medicine, Central Michigan University, Mount Pleasant, MI.
(9)Department of Pediatric Neurology, Golestan Medical, Educational, and 
Research Center, Ahvaz Jundishapur University of Medical Sciences, Ahvaz, Iran.
(10)Department of Pediatrics, Zabol University of Medical Sciences, Zabol, Iran.
(11)Narges Medical Genetics and Prenatal Diagnosis Laboratory, Kianpars, Ahvaz, 
Iran.
(12)Department of Biology, Faculty of Science, Shahid Chamran University of 
Ahvaz, Ahvaz, Iran.
(13)Pediatric Neurology Department, Ghaem Hospital, Mashhad University of 
Medical Sciences, Mashhad, Iran; Neuroscience Research Center, Mashhad 
University of Medical Science, Mashhad, Iran.
(14)Pediatric Neurology Department, Ghaem Hospital, Mashhad University of 
Medical Sciences, Mashhad, Iran.
(15)Department of Pediatrics, North Khorasan University of Medical Sciences, 
Bojnurd, Iran.
(16)Department of Pediatrics, School of Medicine, Mashhad University of Medical 
Sciences, Mashhad, Iran.
(17)GeneDx, Gaithersburg, MD.
(18)Clinical Genetics Service, Nottingham University Hospitals NHS Trust, 
Nottingham, United Kingdom.
(19)Institute of Human Genetics, Klinikum rechts der Isar, School of Medicine, 
Technical University of Munich, Munich, Germany; Institute of Neurogenomics, 
Helmholtz Zentrum München, Neuherberg, Germany; Department of Pediatric 
Neurology and Developmental Medicine and LMU Center for Children with Medical 
Complexity, Dr. von Hauner Children's Hospital, LMU Hospital, 
Ludwig-Maximilians-University, Munich, Germany.
(20)Institute of Human Genetics, Klinikum rechts der Isar, School of Medicine, 
Technical University of Munich, Munich, Germany; Institute of Neurogenomics, 
Helmholtz Zentrum München, Neuherberg, Germany.
(21)Department of Molecular and Human Genetics, Baylor College of Medicine, 
Houston, TX.
(22)Department of Pediatrics, Boston Children's Hospital, Harvard Medical 
School, Boston, MA.
(23)Friedrich Schiller University Jena, Faculty of Chemistry and Earth Sciences, 
Institute of Organic Chemistry and Macromolecular Chemistry, Jena, Germany; 
Center for Biomolecular Magnetic Resonance (BMRZ), Goethe University, Frankfurt, 
Germany; Cluster of Excellence Balance of the Microverse, Friedrich Schiller 
University Jena, Jena, Germany.
(24)Pediatrics Genetics Division, Center for Pediatrics and Adolescent Medicine, 
Faculty of Medicine, Freiburg University, Freiburg, Germany; Genome Research 
Division, Human Genetics Department, Radboud University Medical Center, 
Nijmegen, The Netherlands; CIBSS-Centre for Integrative Biological Signalling 
Studies, University of Freiburg, Freiburg, Germany.
(25)Texas Children's Hospital, Houston, TX; Department of Molecular and Human 
Genetics, Baylor College of Medicine, Houston, TX; Human Genome Sequencing 
Center, Baylor College of Medicine, Houston, TX.
(26)Neuroradiology Unit, IRCCS Istituto Giannina Gaslini, Genoa, Italy.
(27)Institute of Human Genetics, Jena University Hospital, Friedrich Schiller 
Universität, Am Klinikum 1, Jena, Germany; Center for Rare Diseases, Jena 
University Hospital, Jena, Germany.

PURPOSE: SLC4A10 encodes a plasma membrane-bound transporter, which mediates 
Na+-dependent HCO3- import, thus mediating net acid extrusion. Slc4a10 knockout 
mice show collapsed brain ventricles, an increased seizure threshold, mild 
behavioral abnormalities, impaired vision, and deafness.
METHODS: Utilizing exome/genome sequencing in families with undiagnosed 
neurodevelopmental disorders and international data sharing, 11 patients from 6 
independent families with biallelic variants in SLC4A10 were identified. 
Clinico-radiological and dysmorphology assessments were conducted. A minigene 
assay, localization studies, intracellular pH recordings, and protein modeling 
were performed to study the possible functional consequences of the variant 
alleles.
RESULTS: The families harbor 8 segregating ultra-rare biallelic SLC4A10 variants 
(7 missense and 1 splicing). Phenotypically, patients present with global 
developmental delay/intellectual disability and central hypotonia, accompanied 
by variable speech delay, microcephaly, cerebellar ataxia, facial dysmorphism, 
and infrequently, epilepsy. Neuroimaging features range from some non-specific 
to distinct neuroradiological findings, including slit ventricles and a peculiar 
form of bilateral curvilinear nodular heterotopia. In silico analyses showed 6 
of 7 missense variants affect evolutionarily conserved residues. Functional 
analyses supported the pathogenicity of 4 of 7 missense variants.
CONCLUSION: We provide evidence that pathogenic biallelic SLC4A10 variants can 
lead to neurodevelopmental disorders characterized by variable abnormalities of 
the central nervous system, including altered brain ventricles, thus resembling 
several features observed in knockout mice.

Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.gim.2023.101034
PMID: 38054405 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of Interest James R. Lupski owns stock 
in 23andMe and is a paid consultant for Genome International. Rhonda E. Schnur 
is an employee of GeneDx, LLC. The other authors declare no conflicts of 
interest.